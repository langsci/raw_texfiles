\documentclass[output=paper,hidelinks]{langscibook}
\ChapterDOI{10.5281/zenodo.13208540}
\author{Adam J. R. Tallman\affiliation{Friedrich Schiller Universität}}

\title[Introduction]{Introduction: Phonological and morphosyntactic constituency in cross-linguistic perspective}

\abstract{I provide a brief history of the development of the ideas for the ``Constituency-Convergence project'', which this volume is a product of. I also motivate the project by discussing the shortcomings of Basic Linguistic Theory and Prosodic Phonology as description languages for studying constituency cross-linguistically. Finally, I briefly summarize the principles of the planar-fractal method and then provide an overview of the chapters in this volume.}

\IfFileExists{../localcommands.tex}{
   \addbibresource{../localbibliography.bib}
   \addbibresource{../collection_tmp.bib}
   \input{../localpackages}
   \input{../localcommands}
   \input{../localhyphenation}
   \boolfalse{bookcompile}
   \togglepaper[1]%%chapternumber
}{}

\begin{document}
\maketitle

\section{Introduction}

This volume presents a number of studies on constituency (phonological and morphosyntactic) in the languages of the Americas from a novel perspective. Constituency analyses, whether morphosyntactic or phonological, are typically conceptualized as being based on ``constituency tests.'' Generally the constituency tests are used as a means to an end, a tool or a justification, to get at a particular constituency analysis - or more commonly to argue in favor of one constituency analysis over another where the constituency analyses are arrived through theoretical assumptions and intuition (``the factor of judgement'', \citealt[75]{pike1943taxemes}). In this perspective, constituency tests might be ``clues" to constituents (at best), but constituents are the units of description and comparison (e.g. \citealt[44]{wiltschko2014universal}).

In this volume a group of researchers consider phenomena from a variety of languages of the Americas to explore, critique and develop the notion of ``constituency \textit{test}'' as a unit for language description and comparison. Comparing languages in terms  of constituency tests (or domains) is not the same as comparing languages in terms of constituents. Constituents are embedded in constituency analyses which are arrived at by smoothing over (discarding, reinterpreting etc.) constituency tests to fit a set of theoretical positions or assumptions (e.g. binary branching, no-branch crossing, nesting, etc.).

The data are based on original field research by all of the authors and in some cases native speaker judgments. Participants of the volume approach linguistic phenomena from a variety of perspectives, but share the view that cross-linguistic study of constituent structure might be profitably engaged with by comparing languages in terms of constituency test results themselves, rather than only abstract constituency structures proposed in the linguistics literature. This volume was also brought on by a sense that there is a gap in the literature on the relationship between constituent structure and constituency test as a problem in cross-linguistic comparison. The vast majority of introductory syntax texts that introduce and explain the notion of constituency test rely only on examples from (standard) English, for example.

This does not mean that abstract constituency structures are rejected \textit{per se}. Rather the volume is interested in critically engaging with the empirical basis for such constituency structures. Given the ever expanding panoply of competing morphosyntactic geometries found in the literature today, I would suggest that such a methodological orientation is helpful, if not necessary, for getting our bearings. 

The notion of constituency test is presented in a deceptively simple way in introductory syntax texts. When one recognizes the possibility that constituency tests can be and have been used in a biased manner in the linguistic literature \citep{Croft2001, croft:tenunwarranted}, attempting to overcome this bias opens up a world of intricate complexity with competing structural analyses for language description and comparison. The intuition underlying this project is that this complexity is worth exploring and may lead us to overcome some longstanding epistemic and theoretical impasses in the field. It could lead us to abandon some longstanding, but inhibiting assumptions, and articulate new hypotheses concerning linguistic universals and diversity.

Historically, but especially since the development of (American) structural linguistics, the languages of Americas have been an important source of inspiration for understanding the nature of language variation. Languages of the Americas have not simply served as testing grounds for already established hypotheses, but as laboratories for the development of new perspectives on linguistic architecture. In my view the latter tradition has been attenuated in recent years, because of a strong tendency to presume that ``universal'' architectures can be derived from studying a few European languages. Novel phenomena from other languages are studied as expressing deviations from the ``basic'' patterns, but could not be used to challenge the fundamental architecture over which these patterns are described, compared and conceptualized.

It was a staple of the Boasian tradition to criticize traditional linguistic categories for their potential to be implicitly biased towards describing languages and cultures in the terms of languages and cultures which are dominant in European institutions \citep{stockingjr.1974introduction, rodseth2022reality}. This critical attitude was applied to traditional grammatical terminology. The issue of ``word'' and ``constituent'' are a classic concerns of Americanist linguistics (Boasian, Bloomfieldian, Post-Bloomfieldian) in this regard \citep{boas1911introduction, bloomfield1914sentence, hockett1947morphology, pike1972problem}. In a sense, therefore, this volume attempts to reinvigorate the Boasian tradition of empirically based criticism of traditional categories, directing the criticism at the ``established'' or ``basic'' categories of general linguistics (phonological and morphosyntactic) ``word'' and ``phrase.''\footnote{Whether the Boasians consistently approached all problems with such a critical stance is another matter (see \citealt{anderson2019boas} for an important discussion of the shortcomings of the Boasian approach).} The strategy is to take a look at the ``diagnostics'' for our presupposed structures and assess whether these really support the presumed grammatical architectures.

To avoid descending into a cacophony of conflicting terminologies, multivariate autotypologizing methodology \citep{bickel2002autotypologizing} is leveraged and modified in service of this goal. The chapters in this volume apply the \textsc{planar-fractal method}, a typological description language coupled with a coding technique developed to visualize, critique, commensurate and measure constituency tests and their interrelations cross-linguistically. This method is not itself unproblematic, and it should be emphasized that it is a tool with its own biases and pitfalls (see \citealt{wimsatt2007re} for relevant discussion). Used in conjunction with other approaches, I think it can be a powerful technique for comparing and testing certain aspects of language structure. Moreover, for language description, the growing impression is that it has an obvious heuristic value.

Below I provide a brief history of how this volume came into being (\sectref{sec:introduction}). The chapters in this volume reconceptualize some fundamental notions in linguistics and I think that providing a brief history of how the perspective developed is a useful entry point.

The rest of the sections provide brief discussions of the some theoretical ideas, concepts and distinctions that the approach discussed in this volume engages with. Basic Linguistic Theory is discussed in \sectref{sec:blt}. The Prosodic Hierarchy Hypothesis is discussed in \sectref{sec:theprosodichierarchyhypothesis} and \sectref{sec:descriptionlanguages} briefly discusses some methodological issues in typology.

Then I turn to providing a brief description of the planar-fractal method. A description of planar structures is provided in \sectref{sec:planartsructures}. The fractal method for describing constituency tests is provided in \sectref{sec:fracturing} and a brief summary of the type of domains (constituency tests) used in this study is provided in \sectref{sec:domainsintroduction}. I then describe the chapters of this volume in \sectref{sec:chapters}.

\section{Where these ideas come from}
\label{sec:introduction}

This volume came about through ongoing collaboration and conversations between a number of researchers engaged in language description starting in about 2017. The smoothest entry point into understanding the perspective adopted in the volume might be from my own failure to analyze Chácobo, a southern Pano language of Bolivia, according to certain prescribed orthodoxies: Basic Linguistic Theory \citep{dixonaikhenvald02}, and prosodic phonology \citep{nespor2007prosodic, Anderson2005}.

Verbal word structure or word formation in Pano languages is modelled and described according to the following template \citep{loos1999pano, fleck2003grammar, valenzuela2003transitivity, fleck2013panoan, neely2019linguistic, souza2020switch}. 

\ea \label{ex:panoverbalword}
    Pano verbal ``word'' \\
    \textsc{prefix} - \textsc{verb root} - \textsc{deriv. suffixes} - \textsc{infl. suffixes}
\z 

Nouns follow a similar template except that inflectional and many derivational elements are understood as occurring at the end of \textit{phrases} rather than words. In the verb complex the prefix codes the body-part (or something analogous for like a ``trunk'' for a tree) of an S or P argument (typically). The derivational suffixes code a number of concepts such as valence, aspect, emotion, modality, and associated motion. Inflectional suffixes code aspect, tense, evidentiality, temporal distance and (depending on the language) person and number. An example comes from the verb \textit{da-daɨʃ-tsɨk-kid} `habitually gnawing on trunks' provided in \REF{ex:fleck}: \textit{da-} `trunk' is the prefix; \textit{daɨʃ} `eat gnawing' is the verbal root; \textit{tsɨk} `diminutive' is a derivational suffix; \textit{-kid} `habitual is an inflectional suffix.

\newpage
\ea \label{ex:fleck}
    Matses: \\
    \gll kwɨte \fbox{da-daɨʃ-tsɨk-kid} madu-n sipi-n \\
    dicot.tree \fbox{trunk-eat.gnawing-\Dim{}-\Hab{}} demon-\Gen{} tamarin-\Erg{} \\
    \glt `Pygmy marmosets gnaw the trunks of dicot trees.' \citep[342]{fleck2003grammar}
\z 

From Fleck's description one can discern that the verbal ``word'' in Matses is itself a minimal free form, cannot be interrupted by another free form or any distributionally ``promiscuous'' elements such as adverbial clitics and is the domain for stress. 
There is evidence that in other Pano languages the verbal word has a somewhat ``looser'' constituency, however. In Shipibo, the verbal word (which has the same \textit{basic} structure as that of Matses) can be interrupted by bound adverbial clitics and second position clitics. \citet[145--146]{valenzuela2003transitivity} refers to the relevant adverbial morphemes as ``less-fixed clitics.'' An example of a less-fixed clitic is provided with \textit{=ribi} `also' in \REF{ex:shipibo1}.

\ea \label{ex:shipibo1}
    Shipibo-Konibo: \\
    \gll ɨ-a ka-i-tian resto no-n kaibo-baon\textbf{-ribi} ɨ-a tʃiban-a iki, onan-kas-kin\textbf{-ribi} \\
    1-\Abs{} go-S-DS rest 1\Pl{}-\Gen{} fellow.Shipibo-\Pl{}:\Erg{}\textbf{-also} 1-\Abs{} follow-PP2 \Aux{} know-want-SSSA-\textbf{also} \\
    \glt   `When I was going (to the Salt Mountain),the rest of my fellow Shipibo follows me, wanting to know (the way) too.' \citep[145]{valenzuela:phd}
\z

Evidence for the looser constituency comes from the fact that some less-fixed clitics such as \textit{=ribi$\sim$=riba} `also' can interrupt the verbal word. This poses problems for some definitions of wordhood, insofar as the word-internal form is regarded as the same morpheme (it is unclear why it should not be); words should be non-interruptable (\cite[92]{martinet1962functional} \cite[17]{bauer2017compounds}).

\ea \label{ex:shipibo2}
    Shipibo-Konibo: \\
    \gll moa icha baritia pekao, Shipibo joni-bo moa \fbox{kai\textbf{-ribi}-kan-a} iki ja kimisha joni-nko-ni-a-x \\
    already many time after Shipibo person-\Pl{}:\Abs{} already \fbox{reproduce\textbf{-also}-\Pl{}-PP1} \Aux{} that three person-\Loc{}-ligature-\Abl{}-S    \\
    \glt `After many years, the Shipibo reproduced again from these three people.' \citep[146]{valenzuela:phd}
\z 

Still, the verbal word in Shipibo is a stress domain and cannot be interrupted by any \textit{free form}. It also passes the ``free utterance'' or minimal free form test \citep{bloomfield1933language, hockett1958course} (as far as I can discern from the available descriptions).

In Chácobo an analogous span of structure is also a minimal free form (boxed in the example below). 

\ea
    Chácobo: \\
    \gll ina hoʂo tsi kiá \fbox{ta-nɨʂ-ɨ-tɨkɨ(n)-yamɨ(t)-kɨ} \\
    dog white \Lnk{} \Rep{} \fbox{foot-tie-\Itr{}-again-\Dst-\Decl{}:\Pst{}} \\
    \glt ‘The white dog got its feet tied up again.’
\z 

In Chácobo, however, the verbal word is interruptable, not just by a free form, but by a whole noun phrase. The prefix and root can front leaving behind the ``inflectional suffixes.'' This is illustrated in the example below.

\ea 
    Chácobo: \\
    \gll \fbox{ta-nɨʂ-ɨ} tsi kia ina hoʂo \fbox{-tɨkɨ-yamɨt-kɨ} \\
    \fbox{foot-tie-\Itr{}} \Lnk{} \Rep{} dog white \fbox{-again \Dst-\Decl{}:\Pst{}} \\
    \glt ‘The white dog got its feet tied up again.’
\z 

The question then arises as to how we characterize Chácobo and Matses in terms of their morphological profiles. Perhaps, we should say that Chácobo and Matses display radically different structural organizations vis-à-vis the distribution of elements within morphology or syntax. Chácobo would be isolating and Matses polysynthetic. Such a position, however, ignores the fact that Chácobo is just one step more extreme than Shipibo in terms of the looseness of the analogous span of structure from prefix to inflection. The difference between Matses, Shipibo and Chácobo is not one of drastic differences in structure from one language to the next, but rather a matter of degree regarding how well wordhood tests, or perhaps constituency tests in general, align around a particular domain of structure. Claiming that Chácobo or Matses has taken a drastic jump from polysynthetic to analytic or analytic to polysynthetic structure obscures the structural similarities between the two languages and the fact that Shipibo-Konibo stands somewhere in between.\footnote{It is not yet known whether Proto-Pano should be regarded as polysynthetic or not, but in a recent talk on Amawaka, another Pano language, at the Association for Linguistic Typology (2022, UT Austin), Pilar Valenzuela suggested that the proto-language was likely more analytic.}

Perhaps we should claim that all Pano languages are actually like Chácobo and that the relative tightness of the Matses verbal constituent is ``superficial.'' Such a move would obscure interesting typological differences between the languages, however. Yet another approach would be to claim that non-interruption is not a useful test for wordhood \citep{dixonaikhenvald02}, but such a claim suffers from arbitrariness. It seems that our ``basic'' categories for linguistic description obfuscate rather than clarify variation and similarity in the Pano languages.

Another take would be to claim that the above discussion focuses too much on non-convergences between specific wordhood tests, rather than looking at how diagnostics for wordhood pattern for a particular language \citep{tallmancoincidence:2020}. The tests might show a \textit{tendency to align} over a tendency not to. This is sometimes claimed in the case of wordhood tests \citep{matthews:words} and constituency tests in general \citep{carnie2008constituent, bennett2019syntax}. But the claims have been made \textit{ex cathedra} in the absence of a systematic typological study.\footnote{As reviewed below, the one typological study that investigated the question provides the opposite result from what is typically claimed regarding convergence \citep{schiering2012stress, bickel2009distribution}} 

And a more serious problem arises for language comparison. Even if a meta-study were to be conducted showing that in case after case, researchers did not show a tendency to report nonconvergences, such a result could plausibly arise from ``selection bias'' - picking just those results and focusing on just those constructions that illustrate convergence and discarding those that do not as irrelevant \citep{Croft2001, haspelmathword:2011}. If a linguist is told that all languages have words as long as one finds the right criteria \citep{dixonaikhenvald02}, they are going to find them insofar as there are criteria to be found at all, under reporting, if not missing, contradictory results so as not to provoke eye-brow raising from reviewers.\footnote{The issues brought up by \citet{Croft2001} and \citet{haspelmathword:2011} about the possibility that diagnostics are cherry-picked just so they support a favored theory is reminiscent of debates about p-hacking and data dredging in discussions of replicability in the sciences in general \citep{tallman2021analysis}, which is why I refer to the phenomenon as ``selection bias'', rather than using Croft´s term ``methodological opportunism.''}

In an attempt to assess the issue of wordhood in Chácobo more globally, I culled the literature for all wordhood tests I could find (\cite{haspelmathword:2011} for a useful, but preliminary review). But two problems became apparent. The first is that wordhood diagnostics are often stated in highly ambiguous ways in the literature. A given wordhood test is often vague such that it has multiple interpretations. For instance, when we consider non-interruption, the question arises as to what the interrupting element should be: a free-form \citep{haspelmathword:2011}, or some ``promiscuous'' clitic-like element that can be bound \citep{bauer2017compounds}. Insofar as these versions of the same test do not give us the same result, which one do we apply? This problem is not necessarily fatal if one rigorously reports all available interpretations of wordhood results in the literature.

The second problem is more fatal for a description language that presupposes words versus phrases. It is not clear that there is a distinction between wordhood test and constituency test in general. The latter problem became apparent when I started comparing notes with other field researchers from UT and began to take a closer look at tests for phrase-level constituency. To give one example, non-interruption as a wordhood test is actually not clearly distinct from ``movement'' or ``discontinuity'' as a phrasehood test. The difference appears to be one of conceptualization, not empirical reality.\footnote{In the literature on syntax, (non)displacement might be considered an analogue to non-interruption. A phrasal constituent is one that can be displaced with all of its elements remaining adjacent (\cite[25]{kroeger2005analyzing}, \cite[8]{levine2017syntactic}), or a phrasal constituent is one which cannot be ``discontinuous'' \citep[114]{louagie2021nouna} — distinct formulations which mean the same thing as far as I can see. To illustrate the basic empirical identity between these formulations consider a grammar with just three elements: \textit{a}, \textit{b} and \textit{c}. the grammar outputs the following strings.

\ea \label{toygrammar1}
    a, b, c, ab, ac, ba, ca, bc, abc, bca   
\z 

We know that all cases where \textit{b} and \textit{c} occur they cannot be interrupted by \textit{a}. We can formulate the generalization in two ways.

\ea \label{non-interruptionvsdisplacement}
    \ea Non-interruption: \textit{ab} is a constituent because it cannot be interrupted (by \textit{a} for example);
    \ex Displacement: \textit{ab} is a constituent because it can be displaced to the left (or right) side of.
    \z
\z 

With some reflection, therefore, we can see that (non)displacement or (non)discontinuity can be regarded as formulations of non-interruptability, albeit with a different focus. ``Displacement'' evokes a metaphor where the candidate constituent  ``moves'' without breaking into pieces.  ``non-interruption'' evokes a metaphor where the candidate constituent does not break to pieces when subjected to the movement of extraneous elements. Likewise in displacement, extraneous elements stand still, whereas in non-interruption the pieces of the candidate constituent stand still.}

Putting the second problem aside, the results of Chácobo reveal very few convergences given the number of tests applied. To give the reader an idea of how tests decompose the traditional ``word'', consider the example sentence from Chácobo in \REF{ex:chacobo3}.

\ea \label{ex:chacobo3}
    Chácobo: \\
    \gll (ta) nɨʂ ɨ (βɨki) (βona) (tɨkɨ) kɨ (ɾá)  \\
    (foot) tie \Itr{} (\Intrc{}) (going:\Tr{}/\Pl{}) (again) \Decl{}:\Pst{} (\Asr{})  \\
    \glt `Again, they (e.g. the dogs) were tying each other by their feet as they went. (e.g. on a leash).'
\z 

\largerpage
The traditional Panoanist analysis would posit the structure in \REF{panotree} (see \cite{zingg1998diccionario} for example) (where Deriv is `derivational' and Infl is `inflectional').\footnote{Note that in the following discussion trees which have straight rectangular edges are used for representing constituency tests and those with triangular edges are used for representing constituency analyses.}

\tikzset{edge from parent/.style={draw,edge from parent path={(\tikzparentnode.south)--
+(0,-12pt)-| (\tikzchildnode)}}}

\ea \label{panotree}
    \begin{forest} for tree={
    edge path={\noexpand\path[\forestoption{edge}] (\forestOve{\forestove{@parent}}{name}.parent anchor) -- +(0,-8pt)-| (\forestove{name}.child anchor)\forestoption{edge label};}
} 
        [{Minimal free form}
        [{Deriv}, l*=2
        [foot, tier=word]]
        [{Root}, l*=2
        [tie, tier=word]]
        [{Deriv}, l*=2
        [together, tier=word]]
        [{Deriv}, l*=2
        [going, tier=word]]
        [{Deriv}, l*=2
        [again, tier=word]]
        [{Infl}, l*=2
        [\textsc{decl:past}, tier=word]]
        [{Infl}, l*=2
        [\textsc{assert}, tier=word]]]
    \end{forest}
\z 

    % \Tree [.{Minimal free form} [.deriv. foot ] [.root tie ] [.deriv. \textsc{intr} ] [.deriv. together ] [.deriv. going ] [.deriv. again ] [.infl \textsc{decl:past} ] [.infl assert ]  ]

% \ea \label{panotree}
% \begin{tikzpicture}
% This text uses a different font typeface
% \tikzset{frontier/.style={distance from root=70pt}}
% \tikzset{edge from parent/.append style={very thick}}
% \Tree [.{Minimal free form} [.deriv. foot ] [.root tie ] [.deriv. \textsc{intr} ] [.deriv. together ] [.deriv. going ] [.deriv. again ] [.infl \textsc{decl:past} ] [.infl assert ]  ]
% \end{tikzpicture}
% \z 

Wordhood (or constituency) tests parse the sentence up as in \REF{tree:chacobo2} (see \cite{tallman2021constituency} for relevant terminology). Thus, if one prioritizes deviations from biuniqueness, Chácobo is analytic, actually close to isolating. If one considers the minimum free form test, Chácobo is polysynthetic.

\ea \label{tree:chacobo2}
    \begin{forest} for tree={
    edge path={\noexpand\path[\forestoption{edge}] (\forestOve{\forestove{@parent}}{name}.parent anchor) -- +(0,-12pt)-| (\forestove{name}.child anchor)\forestoption{edge label};}
}
        [{Minimal free form}
        [{Selection}
        [{Maximal reduplication}
        [{Non-interruption by NP}
        [{Non-interruption by \textsc{neg}}
        [{Deviations} [foot, tier=word] [tie, tier=word] [ \textsc{intr}, tier=word]
        ][together, tier=word]
        ][going, tier=word]
        ][again, tier=word]
        ][\textsc{decl:past}, tier=word]
        ][\textsc{assert}, tier=word]
        ]
    \end{forest}
\z 

    % \Tree [.{Minimal free form} [.Selection [.{Maximal reduplication} [.{Non-interruptability by NP} [.{Non-interruption by \textsc{neg}} [.{Deviations} [ foot ] [ tie ] [ \textsc{intr} ] ] [ together ] ] [ going ] ] [ again ] ]  [ \textsc{decl:past} ] ] [ assert ] ]

% \ea \label{tree:chacobo2}
% \begin{tikzpicture}
% This text uses a different font typeface
% \tikzset{frontier/.style={distance from root=190pt}}
% \tikzset{edge from parent/.append style={very thick}}
% \Tree [.{Minimal free form} [.Selection [.{Maximal reduplication} [.{Non-interruptability by NP} [.{Non-interruption by \textsc{neg}} [.{Deviations} [ foot ] [ tie ] [ \textsc{intr} ] ] [ together ] ] [ going ] ] [ again ] ]  [ \textsc{decl:past} ] ] [ assert ] ]
% \end{tikzpicture}
% \z 

% \ea \label{tree:chacobo3}
% \begin{tikzpicture}
% \tikzset{frontier/.style={distance from root=170pt}}
% \tikzset{edge from parent/.append style={very thick}}
% \Tree [.{H tone reduction} [.{H boundary tone II} [.{H boundary tone I}  [.Minimality [.{ʔ-insertion} [.σ ta ] [.σ nɨ ] ] [ [.σ ʂɨ ] ] ]  [ [.σ βɨ̀ ] ] [ [.σ kí ] ] ] [ [.σ βò ] ] [ [.σ ná ] ] [ [.σ tɨ̀ ] ] [ [.σ kɨ́ ] ] [ [.σ kɨ ] ] ] [ [.σ ɾá ] ] ]
% \end{tikzpicture}
% \z 

\ea \label{tree:chacobo3}
    \begin{forest} for tree={
    edge path={\noexpand\path[\forestoption{edge}] (\forestOve{\forestove{@parent}}{name}.parent anchor) -- +(0,-12pt)-| (\forestove{name}.child anchor)\forestoption{edge label};}
}
        [{H tone reduction} 
        [{H boundary tone II}
        [{H boundary tone I}  
        [Minimality 
        [{ʔ-insertion} [σ [ta, tier=word] ] [σ [nɨ, tier=word] ] ] 
        [ [σ [ʂɨ, tier=word] ] ] 
        ] [σ [βi, tier=word] ] [σ [ki, tier=word] ]
        ] [σ [βò, tier=word] ] [σ [ná, tier=word] ] [σ [tɨ̀, tier=word] ] [σ [kɨ́, tier=word] ] [σ [kɨ, tier=word] ]
        ] [σ [ɾa, tier=word] ]
        ]
    \end{forest}
\z 

The situation is not obviously less ambiguous with phonological domains. The diagram in \REF{tree:chacobo3} depicts phonological domains in Chácobo showing that the language has relatively small phonological words if glottal stop insertion is chosen as word-identifying and large ones if H-tone reduction is chosen (see \citealt{tallman2018grammar} for a complete description of the relevant phonological processes).\footnote{One could question this argument on the grounds that the smallest domain should be the ``phonological word''. But then the question arises as to which domain is the phonological phrase. Domains smaller than the phonological word (the ``Pstem'') have also been argued to be necessary for some languages \citep{downing2020re}, which reintroduces the ambiguity. Such problems are discussed in detail in \sectref{sec:theprosodichierarchyhypothesis}.}
The few convergences that can be found could be attributed to chance. With 22 constituency tests and 28 sentence level structural positions, the probability of two tests converging by accident is relatively high \citep{tallman2021constituency}. 

The ambiguity here matters for linguistic theory generally. Claims about lexical integrity are not meaningfully testable, or just incoherent, if they  are highly contingent on which of an open ended set of competing wordhood candidates are chosen \citep{tallman2021analysis}. We cannot discern how Chácobo data relate to the prosodic hierarchy if labeling of the relevant domains is arbitrary \citep{tallman2021caroline}. Claims about the relative autonomy of morphology and what distinguishes morphology from syntax \citep{anderson2015dimensions} are likewise meaningless if they rest on arbitrary choices about where to cut the division between these domains \citep{tallman2023measuring}. We cannot felicitously compare the phonetics of boundary phenomena in cross-linguistic perspective \citep{sonderegger2018boundary,seifart2021extent}, if it is not clear what level the boundaries identify.   
 
A question arises at this point as to how general the problem of non-conver\-gence really is cross-linguistically. This is where the larger collaboration between more researchers begins. A methodology for reporting and coding constituency test results was developed in collaboration with linguists doing fieldwork on native languages of the Americas, some of them native speakers of these languages, at the University of Texas at Austin. The collaboration began in the context of a seminar on Morphological Typology taught by Patience Epps and Anthony C. Woodbury. In fact, many of the tests that were applied to Chácobo in \citet{tallman2021constituency} were suggested by other fieldworkers while we attempted to operationalize wordhood tests in language after language. I did not invent the variety of tests myself, rather they gradually emerged from discussing how different linguists would apply the tests in languages they specialized in.

The notion of a planar structure and test fracturing grew out of this collaboration. A planar structure is an array of structural positions that code the relative ordering of elements in a referential (nominal) or predicate (verbal) domain. The planar structure is a hypothesis space for coding constituency test results as spans over adjacent positions. The hypothesis space homogenizes morphological  and syntactic representations \textit{pro tempore}. If ``words'' or the word-phrase distinction are valid constituents they do not emerge from the planar structure itself, but from the patterning of constituency test results over the planar structure. The planar structure codes positions with sequential numbers and constituency test results are coded as spans over those positions.

Fracturing is the methodology employed to deal with the ambiguity of relatively abstract constituency tests or domains in their application to real empirical phenomena. When ambiguity is recognized, the researcher decomposes (fractures) the test into multiple versions. For instance, consider the case described above with non-interruptability. Rather than choosing a single ``correct'' interpretation of non-interruption, we fracture the non-interruption domain into a domain not interruptable by a free form and a different domain that is not interruptable by a ``promiscuous'' element. If linguist A discovers a version of a test not identified by linguist B, then the latter makes an attempt to apply the new version of the test to their language data as well. Thus the variables of constituenthood evolve through the reciprocal interaction of fieldworkers and become increasingly fine-grained and more comparable in the process. The research conducted in this fashion also benefits from the fact that researchers approach the issue of constituency from different intellectual traditions, further enriching the variables (see Sections \ref{sec:planartsructures} and \ref{sec:fracturing}).

A researcher might suspect that the nonconvergences found with Chácobo would be common cross-linguistically \citep{Bickel2017}. However, application of the methodology revealed that there are apparently radical differences between languages with respect to the degree to which independent morphosyntactic and phonological principles tend to cluster. Consider the following two orthographic ``words'' in Chácobo and Central Alaskan Yupik. The elements in numbers are positions in the respective planar structures (see below).

\ea \label{ex:chacobo4}
    Chácobo (Pano): \\
    \gll tɨpas$_8$ wɨni$_{16}$ -tsa$_{16}$ -kas$_{17}$ -i$_{24}$ -kiá$_{25}$  \\
    murder -before.someone immediately:\Itr{}:\Sg{} -want -\Decl{} -\Rep{} \\
    \glt `He wanted to murder him immediately before it was too late (it is said).’  
    \citep[54]{tallman2017nahuapaxahua}
\z 

\ea \label{ex:cupik1}
    Central Alaskan Yupik (Inuit-Yupik-Unangan): \\
    \gll quuyurni$_2$-arte$_3$-llru$_6$-yaaqe$_8$-llini$_9$-u$_{12}$-q$_{16}$  \\
    smile-suddenly-did-alas-evidently\Ind{}-\Third{}\Sg{}.S \\
    \glt `Evidently, s/he suddenly smiled, but alas.' \citep[85]{Woodbury2002}
\z 

In Chácobo, the relevant orthographic word is identified only by a version of the minimal free occurrence test. The orthographic word is also identified by free occurrence in Central Alaskan Yupik. However, in the Central Alaskan Yupik case, the orthographic word is identified by stress prominence, segmental allomorphy, `say' conjunction, selection, fixedness and is furthermore a repair domain.

\begin{figure}
    \subfigure[Chácobo (Pano), see \citet{tallman2021constituency} for details.]{
    \label{fig:chacobo_convergenceplot}
    \includegraphics[width=.9\textwidth]{figures/cha_pooled_plot_simplified.pdf}
    }
\subfigure[Central Alaskan Yupik, see \textcitetv{chapters/02-Cupik} for details.]{
 \label{fig:ccupikconvergenceplot}
    \includegraphics[width=.9\textwidth]{figures/cupik_pooled_plot.pdf}
    }
    \caption{Constituency convergence plots. See list of abbreviations at the end for full labels.}
\end{figure}



Planar structures were constructed for Chácobo and Central Alaskan Yupik (see \cite{tallman2021constituency} and \citetv{chapters/02-Cupik} respectively). One way of displaying the results of constituency tests over the planar structure is by a convergence plot. A convergence plot is a strip plot that has the positions of the planar structure on the x-axis and the coded constituency tests on the y-axis. Figures \ref{fig:chacobo_convergenceplot} and \ref{fig:ccupikconvergenceplot} display convergence plots for Chácobo and Central Alaskan Yupik respectively (\citealt{auderset2023constituency} for relevant terminology). A convergence between tests is where their left and right edges align on the x-axis. Convergent tests receive the name numerical label in the plots. For instance, in \figref{fig:chacobo_convergenceplot} Glottal insertion, consonant assimilation, and boundary prominence in Chácobo all three span positions 7--8 and are given the joint label \fbox{1}. We can see from these plots that while both languages display misalignments, Central Alaskan Yupik has a domain of structure from position 2 to 16 (the traditional orthographic word in this language), where a number of constituency tests align. In Chácobo, there is much less convergence overall.\footnote{Note that this figure does not present all of the tests from Chácobo, which is simplified somewhat for expositional purposes. The important point is to observe that the overall convergence pattern is different from that of Central Alaskan Yupik.}



Starting in 2017 at UT Austin, a number of researchers applied the planar-fractal method to a number of languages. The method travelled to the University of Ottawa and to the Laboratoire Dynamique du Langage (CNRS, Université de Lyon II), eventually diffusing to researchers at other institutions. The planar structure and application of the constituency tests is applied by researchers that are experts or expert native language speakers on the relevant languages. Researchers are asked to apply and critique constituency tests presented in the literature using the methodology and, where possible, reflect on how the results relate to published theoretical literature. A researcher might add a new constituency test not reported by other researchers. The other researchers in the project are then asked to apply the new test insofar as it is well formulated enough to apply without ambiguity. Researchers in the relevant project are encouraged to not just apply the methodology but critique and develop it as well. The variables for comparison are thus developed enriched through original empirical research. The idea is to pool perspectives and experiences from different researchers to enrich the variables, rather than applying them in a pre-defined top-down fashion or seeking to rally diagnostics here-and-there to ratify predefined formal categories such as ``word'' or ``phrase.''

This book presents the ongoing results of this collaborative project. The first goal was to use the methodology to help enrich descriptions of lesser described languages. Many of the chapters were written in the context of a PhD project on the documentation of the language in question. Secondly, the methodology is used to test claims about constituency and wordhood stated in the literature from a broader cross-linguistic perspective. The results suggest that there is much more cross-linguistic variation in constituency structure than would appear to be expected based on the current literature. Whether the methodology can be used to test competing hypotheses about constituency structure is partially contingent on whether those hypotheses are precise enough to be testable to begin with. In this respect, the methodology also provides a data structure for typological comparison that allows for the development of more testable hypotheses. I think the participants in this project have overall found that the methodology provides a powerful discovery procedure for the purposes of enriching linguistic description and documentation. The results have revealed that many claims about typological regularities and variation in wordhood and constituency are oversimplified and should be revised. 

% \begin{forest}
%     [S [V^0$/Word$
%     [Stem [\textsc{foot-} \textbf{tie} \textsc{-intr} \textsc{-intrc} \textsc{-going} \textsc{-again}, roof] ] 
%     [Inflection [\textsc{-decl:past} \textsc{-assert}, roof] ]
%     ] ]
% \end{forest}




% \ea \label{tree:chacobo}
% \begin{tikzpicture}
% This text uses a different font typeface
% \tikzset{frontier/.style={distance from root=250pt}}
% \tikzset{edge from parent/.append style={very thick}}
% \Tree [.{Minimal free form} [.Selection [.{Maximal reduplication} [.{Non-interruptability by NP} [.{Non-interruption by \textsc{neg}} [.{Deviations} [ foot ] [ tie ] [ \textsc{intr} ] ] [ together ] ] [ going ] ] [ again ] ]  [ \textsc{decl:past} ] ] [ assert ] ]
% \end{tikzpicture}
% \z 

% \ea \label{tree:chacobo}
% \begin{tikzpicture}
% This text uses a different font typeface
% \tikzset{frontier/.style={distance from root=250pt}}
% \tikzset{edge from parent/.append style={very thick}}
% \Tree [.{Minimal free form} [.Selection [.{Maximal reduplication} [.{Non-interruptability by NP} [.{Non-interruption by \textsc{neg}} [.{Deviations} foot tie \textsc{intr} ]  together  ]  going  ]  again  ] \textsc{decl:past}  ] assert ]
% \end{tikzpicture}
% \z 


% \ea \label{tree:chacobo}
% \begin{tikzpicture}
% \tikzset{frontier/.style={distance from root=210pt}}
% \tikzset{edge from parent/.append style={very thick}}
% \Tree [.{H tone reduction} [.{H boundary tone II} [.{H boundary tone I}  [.Minimality [.{ʔ-insertion} [ [.σ ta ] ] [ [.σ nɨ ] ] ] [ [.σ ʂɨ ] ] ]  [ [.σ βɨ̀ ] ] [ [.σ kí ] ] ] [ [.σ βò ] ] [ [.σ ná ] ] [ [.σ tɨ̀ ] ] [ [.σ kɨ́ ] ] [ [.σ kɨ ] ] ] [ [.σ ɾá ] ] ]
% \end{tikzpicture}
% \z 

% \ea \label{tree:chacobo}
% \begin{tikzpicture}
% \tikzset{frontier/.style={distance from root=210pt}}
% \tikzset{edge from parent/.append style={very thick}}
% \Tree [.S [ [ honi ] [ [ siri=́  ] ] ] [ [ ʃinó ] ] [ [ [ [ [ ta ] [ nɨʂ ] [ a ] ] [  βayá ] ] [ tɨkɨ ] ]  [ kɨ ] ] ]
% \end{tikzpicture}
% \z 

% \ea \label{tree:chacobo}
% \begin{tikzpicture}
% \tikzset{frontier/.style={distance from root=210pt}}
% \tikzset{edge from parent/.append style={very thick}}
% \Tree [.S [.XP [.$X^0$ honi ] [.XP [.$X^0$ siri=́  ] ] ] [.XP [.$X^0$ ʃinó ] ] [.XP [.XP [.$X^0$ [.$X^-1$ [ ta ] [ nɨʂ ] [ a ] ] [  βayá ] ] [ tɨkɨ ] ]  [ kɨ ] ] ]
% \end{tikzpicture}
% \z 

% \ea \label{tree:chacobo}
% \begin{tikzpicture}
% \tikzset{frontier/.style={distance from root=80pt}}
% \tikzset{edge from parent/.append style={very thick}}
% \Tree [.non-interruption [ {...by free form} ] [ {... by negation} ] [ {... by evidential} ] [ [ ... ] ] ]
% \end{tikzpicture}
% \z 

% \ea \label{tree:chacobo}
% \begin{tikzpicture}
% \tikzset{edge from parent/.append style={very thick}}
% \Tree [.TP T [.VP [.NP N ] [.VP [.NP N ] V  ] ] ] ]
% \end{tikzpicture}
% \z 

% \ea \label{tree:chacobo}
% \begin{tikzpicture}
% \tikzset{edge from parent/.append style={very thick}}
% \Tree [.ɩ [.ɸ F [.ɷ F F ] ]  [.ɸ [.ɷ F F ] [.ɷ F F ] ] ]
% \end{tikzpicture}
% \z 

\section{Basic linguistic theory}
\label{sec:blt}
\largerpage
Basic Linguistic Theory (BLT) seeks to provide a general framework and methodology for linguistic description and typological comparison \citep{dixon1997rise, dixon2010basic}. The framework has been the most influential in language description over the past 20 years.\footnote{I should point out that this is a very subjective impression. It is somewhat difficult to judge how influential BLT is in grammar writing because it probably tends to depend on the domain of grammar. Furthermore, analyses or assumptions can adopted in degrees rather than \textit{in toto}. It would be hard to say that BLT has had much influence on the writing of phonology chapters in grammars over the years where the trend is to include more and more detailed phonetic information. I do not think it is too controversial though to point out that in the domain of wordhood it has become a standard.}  Despite its near hegemony in descriptive linguistics, the framework is not without its critics \citep{mcgregor2021neo}. There is also some question as to whether all linguists interpret ``Basic Linguistic Theory'' in the same way \citep{haspelmath2008oxford}.

In what follows I will be concerned with the notion of BLT represented in R.M.W. Dixon's authoritative statement on the approach \citep{dixon2010basic, dixon2010basica}. I will focus specifically on the approach to grammatical and phonological wordhood within BLT as articulated in \citet{dixonaikhenvald02}, \citet{dixon2010basica} and \citet{aikhenvald2020essence}, and refer to other authors where relevant. I focus on this approach to grammatical and phonological wordhood for two reasons. First, it is my impression that it has the status of a virtual orthodoxy within linguistic description: descriptive linguists assume that the units ``phonological'' and ``grammatical'' word are present in the language under study and describe that language in those terms, rather than investigate let alone test the claim. Secondly, the methodology for this project partially developed as a critique of the BLT framework for describing and comparing grammatical and phonological words. Thirdly, many of the assumptions of BLT are commonplace across linguistics and approaches to the relationship between morphosyntax and phonology. In what follows I hope to highlight these assumptions, pointing out which of them I think are empirically unfounded.

The BLT approach recognizes that diagnostics for wordhood do not necessarily align with one another. BLT solves this by positing that grammatical words and phonological words should be distinguished. A basic statement of the how to study words in particular languages and cross-linguistically is summarized by \citet[10]{dixon2010basica}:

\ea \label{statements:bltprinciples}
    \ea Recognize ``phonological word'', determined on entirely phonological principles. \\
    \ex Recognize ``grammatical word'', determined on exclusively grammatical (that is morphological and syntactic) principles. \\
    \ex Compare the two units. In some languages, grammatical word and phonological word may coincide. In other languages, grammatical and phonological word will coincide in most cases, but with a number of instances where one grammatical word may consist of more than one phonological word, and/or vice versa.
    \z
\z

By phonological principles Dixon refers to phonological constraints (e.g. no coda consonants in a specific domain) and phonological processes (e.g. intervocalic voicing). It is not clear whether phonological principles also include so-called ``post-lexical'' processes or phonetic modifications related to phonological constituency generally (more on this below). Grammatical principles refer to properties holding of specific domains of structure (e.g. inability to permute elements or re-curse constituents). It is unclear how grammatical principles exclude phrase identifying processes. The identification of a distinction between grammatical and phonological words, of course, represents an important advance in linguistic description. By allowing grammatical and phonological words to misalign, it allows one to capture the generalizations that hold of these constituents while capturing some of the complexities of the relationship between phonology and morphosyntax. For example, recognizing a distinction between grammatical and phonological words allows one to capture the differences and similarities between affixes and clitics in South Bolivian Quechua (Gladys Camacho-Rios personal communication). The misalignment between g(rammatical)-words and p(honological)-words is represented with the labelled diagram below the example.

% \ea \label{ex:sbq1}
%    South Bolivian Quechua: \\
%      \gllll mana	rikhuri-n=puní=chu   \\
%      [mana]	[rikhuri -n] [=puní] [=chu] \\
%      (mana) (rikhuri -n =puní =chu) \\
%      \Neg{} appear -3 =certainly =\Neg{}  \\
%     \glt  `It certainly did not appear.'
% \z 


\ea \label{ex:sbq1}
   g-word \subset{ p-word}  \\
   South Bolivian Quechua: \\
     \gll mana	rikhuri-n=puní=chu   \\
     \Neg{} appear-3=certainly=\Neg{}  \\
    \glt  `It certainly did not appear.'
\z 

\ea 
    \ea 
        \begin{forest}
        [Sentence
        [g-word[mana]]
        [g-word[rikhuri][-n]]
        [g-word[-puni]]
        [g-word[-chu]]
        ]
    \end{forest}
    \ex 
        \begin{forest}
        [Utterance
        [p-word[mana]] [p-word[rikhuri-n-puni-chu]]
        ]
    \end{forest}
    \z
\z 

The g-words are elements or combinations of elements that can be displaced but with their internal parts in tact. The g-word \textit{rikhuri-n} is not interruptable by a free form or clitic element and the internal parts of this constituent display little variable ordering. The clitics \textit{=puni} and \textit{=chu} are not part of the grammatical word because they can occur right-adjacent to a noun phrase as well (without necessarily corresponding to a difference in meaning). 

However, the principles for identifying g-words (morphemes of combinations of morphemes that cannot be interrupted or split apart into pieces) do not line up consistently with phonological principles we can rally for identifying p-words. The clitics, while being independent g-words are incorporated into a pitch accent domain of the verb (projected from the verb root). The pitch accent domain is identified based on the distribution of Low-High* pitch accents on the penultimate syllable in of the relevant domain (the p-word in the domain above).\footnote{This means that the high part of the tone is realized on the ``stressed'' syllable and the low pitch is (typically) realized on the previous syllable.}

BLT is not particularly clear about what phonological and grammatical principles identify ``phrases.'' It is only stated that some sort of grammatical hierarchy exists \citep[33]{dixon2010basica}. In the Quechua case above in particular it is not clear whether the p-word should instead be regarded as a phonological phrase, for instance.

Another type of misalignment warranted by BLT is where the phonological words are smaller than morphosyntactic words. An example comes from Atkan Aleut. \citet{woodbury2011atkan} refers to pronominal elements that are obligatorily left-adjacent to the verb stem as ``unclitics''. (\citealt{zuniga2014anti} refers to these as ``anti-clitics''). They obey a principle of contiguity for g-words, but still have other properties that \citet{woodbury2011atkan} associates with p-words. A simplified depiction of the analysis of such forms presented in \citet[129]{woodbury2011atkan} is presented below.

\ea \label{ex:atkanaleut}
    p-word \subset{ g-word} \\ 
    Atkan Aleut: \\
    \gll Piitra-m      unana-x           ngiin    a-qa-ngis \\
    Peter-\Rel{}.\Sg{} cook-\Abs{}.\Sg{} for.3.\Pl{} be-\Pst{}1-3\Pl{}.NS/3.\Sg{}.S \\
    \glt `Peter was a cook for them.'
\z 

\ea 
    \ea 
        \begin{forest}
        [Sentence
        [g-word[Piitra][-m]] [g-word[unana][-x]] [g-word[ngiin] [a][-qa][-ngis]] 
        ]
        \end{forest}
    \ex \begin{forest}
        [Utterance
        [p-word[Piitra][-m]] [p-word[unana][-x]] [p-word[ngiin]] [p-word[a][-qa][-ngis]]]
        ]
        \end{forest}
    \z
\z

Woodbury argues that the element \textit{ngiin}, while being a separate p-word is part of the g-word of the rest of the verb. It is an unclitic, because it inverts the standard relationship definition of clitics as prosodically dependent, but grammatically independent. Woodbury does not explain why the g-word which takes in two inflected elements could not be considered a phrasal or subphrasal constituent. But, the point is that his description is broadly in line with the assumptions of BLT, despite the misalignment. 

These types of misalignments (g-word \subset{ p-word} and p-word \subset{ g-word}) exhaust what is statable in the BLT approach without modification. The researcher identifies grammatical and phonological principles, refers to the domains of structure where these principles hold as grammatical and phonological words respectively and describes how they align or do not.

\largerpage[-1]
There are at least two other types of misalignments that BLT does not have the vocabulary to express. These are cases where different candidate g-words (g-domains) or different candidate p-words (p-domains) misalign with each other. These were already discussed in \sectref{sec:introduction}, but they are worth mentioning again.

For an example of cases where candidate p-words misalign with each other consider the example in \REF{ex:chacobomisalign4}.

\ea \label{ex:chacobomisalign4}
	p-word$_1$ $\neq$  p-word$_2$ $\neq$ p-word$_3$ ...  \\
    Chácobo (Pano): \\
    \gll pi=má=βoná=kɨ \\
     eat=\Caus{}=going=\Decl{}:\Pst{} \\
    \glt `He made him eat on the go.'
\z 

\largerpage[2]
In Chácobo the constituent \textit{pi=ma} `causative to eat' could be regarded as a p-word on the grounds that it is a domain of obligatory minimality, without \textit{=ma} `causative', the verb root can lengthen (\textit{pii=βona...} `eat while going.') However, it would not be accurate to simply state that \textit{=βoná} `going' does not phonologically interact with the rest of the verb complex as the identification of \textit{pi=ma} `make someone eat' as the phonological word implies. The clitic \textit{=βoná} `going' blocks the insertion of a default high tone by having a lexical tone itself. In cases where the rest of the verb complex has no underlying high tone, the presence of a high tone on \textit{=βoná} blocks high tone insertion. For instance, without a high tone bearing suffix \textit{hana} `leave' is realized with a high tone on the first syllable, but otherwise this is blocked by morpheme like \textit{=βoná}. Therefore we could also say that \textit{pi=ma=βona} is the phonological word. This would ignore the fact that a different phonological principle identifies the whole string \textit{pi=ma=βoná=kɨ} as a phonological word, however. All of the aforementioned elements are in a domain of obligatory tone reduction whereby adjacent lexical high tones delete \citet{tallman2018grammar, tallman2021constituency}. The ambiguity of is depicted in \REF{tree:chacobo1}.

\ea \label{tree:chacobo1}
    \begin{forest}
        [{p-word$_1$}
        [{p-word$_2$}
        [{p-word$_3$} [pi, tier=word] [{=ma}, tier=word]
        ] [{=βoná}, tier=word]
        ] [{=kɨ}, tier=word]
        ]
    \end{forest}
\z 

% \ea \label{tree:chacobo1}
%     \begin{tikzpicture}
%         This text uses a different font typeface
%         \tikzset{frontier/.style={distance from root=90pt}}
%         \Tree [.{p-word$_1$} [.{p-word$_2$} [.{p-word$_3$} pi =ma ] =βoná ] =kɨ ]
%     \end{tikzpicture}
% \z 


\newpage
A number of issues arise in this case. One might claim that either p-word$_1$ or p-word$_2$ are phonological phrases (or ``composite groups''). the labelling issue (phonological word or phonological phrase) highlights a general problem with the BLT framework.\footnote{Many current prosodic phonology analyses also posit that prosodic domains can ``recurse.'' One might argue that \REF{tree:chacobo1} provides evidence that p-words are recursive in Chácobo. However, adopting recursion does not address the issue of ambiguity in label assignment, but rather exacerbates it, increasing the potential of arbitrariness of label assignment: in the case above, one could also claim that every single one of the candidate p-word domains are recursed phonological phrases, or perhaps any other layer of the prosodic hierarchy (see \sectref{sec:recursion}).} Phonological principles (e.g. phonological processes{\slash}rules) also apply at higher levels of structure. These data highlight the fact that an adequate typology of phonological and grammatical words cannot be decontextualized from issues of constituency in general.

%\ea \label{ex:tlvzapotec1}
%g-word_1 $\neg$ g-word_2 $\neg$ g-word_3 ...  \\
%Teotitlan del Valle Zapotec: \\
%\gll ked_5= tu_9= bi-_10- dʒi:by_12 =di_18 gu_10- nnā:_12 lǔ:y_24 \\
%\Neg{}= INDF.PRON= \Cmpl{}- be.afraid =\Neg{} \Compl{}- witness 2\Sg{}.INF  \\
%\glt `Nobody was afraid of you.' (Cite Gutierrez + Uchihara)
%\z 

Examples where grammatical principles misalign and thus provide competing notions of g-words are not hard to come by either.\footnote{Many morphosyntactic theories seem to be motivated by the fact that grammatical principles misalign, such as \citegen{baker_incorporation_1988} movement analysis and \citegen{sadock1991autolexical} autolexical approach to noun{--}incorporation. These authors do not appear to question the identification of ``words'', however. They seem to rely heavily on orthographic practices to parse up the boundaries between the modules that their theories presuppose.}  Consider the following example from Teotitlán del Valle Zapotec.

%\ea \label{ex:tlvzapotec2}
%g-word_1 $\neg$ g-word_2 $\neg$ g-word_3 ...  \\
%Teotitlan del Valle Zapotec: \\
%\gll gu_10- do:w_12 zhlyāʔ_16 bækw_23 \\
%\Compl{}- \Compl{}:eat in.vain dog \\
%\glt `(The/a) dog ate in vain.' (Cite Gutierrez + Uchihara)
%\z 


%\ea \label{ex:tlvzapotec2}
%g-word_1 $\neg$ g-word_2 $\neg$ g-word_3 ...  \\
%Teotitlan del Valle Zapotec: \\
%\gll d'= ʃ- gû\textsuperscript{ʔ} gwě:n -i\textsuperscript{ʔ}n tœ̰: =rú =an =kī b- %â̰ːny =īn \\
%\Pl{}= \Poss{} bull small -\Dim{} \Intsf =more 3\Sg{}.\Inf{} =\Dem{}.TEMP %\Cmpl{}- do =3\Sg{}.INAN \\
%\glt `Those smallest bulls of her/his did it.' (Cite Gutierrez + Uchihara)
%\z 

\ea \label{ex:tlvzapotec2}
g-word$_1$ $\neq$ g-word$_2$ $\neq$ g-word$_3$ ...  \\
Teotitlán del Valle Zapotec: \\
\gll r- œ- sut -nœ̄ -i\textsuperscript{ʔ}ny =zá =an lǎ̰:n \\
 \Hab{}- going- going:play -\Com{} -\Dim{} =also 3\Sg{}.\Inf{} 3\Sg{}.\Inf{} \\
\glt `S/he goes to play with him/her (how nice!).' \parencitetv{chapters/07-Zapotec}
\z 

The syntagm \textit{r-œ-sut} `going to play' is a g-word under principles of selection, minimal free occurrence and sharing under conjunction. The syntagm \textit{r-œ-sut-nœ̄-i\textsuperscript{ʔ}n} is a g-word under principles of non-permutability and non-interruption by a free form. The syntagm \textit{r-œ-sut-nœ̄-i\textsuperscript{ʔ}ny=za=an} is a g-word under principles of non-interruption by a noun phrase, repetition under conjunction and maximal free occurrence \parencite{chapters/07-Zapotec}. The full picture is hard to depict in a tree diagram because a rigorous application of constituency tests gives us bracketing paradoxes in TV Zapotec. A simplified depiction of the results is provided in \REF{tree:tvztree1}.

\ea \label{tree:tvztree1}
    \begin{forest}
       [sentence
       [{g-word$_1$}
       [{g-word$_2$}
       [{g-word$_3$} [{r-}, tier=word] [{œ-}, tier=word] [sut, tier=word]
       ] [{-nœ̄}, tier= word] [{-i\textsuperscript{ʔ}ny}, tier=word]
       ] [{=zá}, tier=word] [{=an}, tier=word]
       ] [{lǎ̰:n}, tier=word]
       ] 
    \end{forest}
\z 

% \ea \label{tree:tvztree1}
% \begin{tikzpicture}
% This text uses a different font typeface
% \tikzset{frontier/.style={distance from root=120pt}}
% \Tree [.sentence [.{g-word$_1$} [.{g-word$_2$} [.{g-word$_3$} r- œ- sut ] -nœ̄  -i\textsuperscript{ʔ}ny ] =zá =an ] [.{g-word} lǎ̰:n ] ]
% \end{tikzpicture}
% \z 

The same issues arise in this case. What is designated g-word$_1$ or g-word$_2$ could perhaps be reanalyzed as a ``phrase'', but such an analysis does not fall out of the principles described in \REF{statements:bltprinciples}.

Given the fact that p-word and g-word domains misalign, a naive linguist might wonder what the purpose is in identifying ``words'' at all in the description and comparison of individual languages. Entertaining such a possibility contradicts a central dogma underlying much contemporary descriptive and theoretical linguistics, however. I refer to this as the ``word bisection dogma.'' Dixon articulates the dogma succinctly.

\ea \label{dogma}
The word bisection dogma: \\
Units ‘phonological word’ and ‘grammatical word’ can without doubt, be recognized for all languages. \citep[7]{dixon2010basic}. 
\z

I use the expression ``bisection'', because the abstract notion of ``word'' only needs to be split into two versions in this formulation. I refer to the claim as a ``dogma'', because it is adopted uncritically in much language description and comparison. If a descriptive linguist claims that the principle does not apply or work for a given language, they are generally treated as ignorant or insane.

On one reading the claim in \REF{dogma} is simply a tautology, and, therefore, the expression ``without doubt'' is warranted. I refer to this as the ``fiat-based word bisection dogma.'' On another reading, Dixon is making an interesting empirical claim about the structure of all (or most?) languages. I refer to this as the ``empirical word bisection dogma.'' On this reading the ``without doubt'' expression is not warranted based on our current knowledge. The fiat-based and empirical interpretations of Dixon's claim should be kept distinct. However, many researchers seem to assume that the more substantive empirical claim follows from the fiat-based one, which is fallacious. Below, I explain the issue in more detail.

\hspace*{-1.9pt}The fiat-based word bisection dogma follows from the fact that (domain-bound) grammatical and phonological principles exist at all. Once the linguist has found some domain of structure where a grammatical principle holds (e.g. ``fixedness of order'') one  can recognize that domain as a g-word. If one finds another domain where a different grammatical principle holds (e.g. ``non-interruption by a free form"), there is no problem at all if this does not line up with the domain that was already christened as a ``word.'' When we have competing domains, the linguist simply arbitrarily designates one of the domains as a ``word'', discarding the other grammatical principles as irrelevant or unreliable. Another linguist (or even the same linguist) could refer to the second domain as a g-word, even if they do not line up. The same holds for phonological domains. If a stress domain and a vowel harmony domain misalign, just christen one as \textit{the} phonological word and be done with it. One need only insist that the other domain not-so-christened is not a reliable criterion in the language in question.\footnote{There could be a more empirically substantive notion of a test being poorly suited to a particular language. This could be defined as cases where a test is highly ambiguous providing a number of results.} Since there is no justificatory logic behind fiat-based designations apart from appeals to authority such an explanation will suffice.

On the tautological interpretation Dixon is simply referring to the linguist's ability to label certain domains ``p-word'' and/or ``g-word.'' No claim is made about g-words or p-words having a unique interpretation from language to language or from description to description and the fact that grammatical and phonological principles might not line up to give the same results is not a problem. The linguist is free to discard certain grammatical and phonological principles as irrelevant to their identification of g-words and p-words according to the alignment of the stars, the flip of a coin, or the flippant suggestions of a more senior linguist. The misalignments described for Chácobo and Zapotec above pose no problem for the tautological fiat-based interpretation because the linguist is free to choose any of the competing p-words or g-words as constituting the ``real'' instance of these categories according to how they feel, or perhaps according to precedence in their area of study (``Other Uto-Aztecanists/Zapotecanists/Arawakanists etc ... have defined it in this fashion and so I follow them".)

There is no problem, in principle, with the tautological word bisection dogma. It may even have expositional value in linguistic description and analysis. The expositional value of the fiat-based use of the notion of ``word'' is expressed most clearly by Chao in his \textit{Grammar of Spoken Chinese}.

\begin{quote}
    Not every language has a kind of unit which behaves in most (not to speak of all) respects as does the unit called ``word" when we talk or write \textit{in} English about the subunits \textit{of} English. It is therefore a matter of fiat and not a question of fact whether to apply the word ``word" to a type of subunit in the Chinese sentence which has so many points in common with, and so few points divergent from, the English word ``word" as to warrant the use of that term without danger of serious misunderstanding. As we shall see when we come to actual cases, we shall meet various types of word like units which can claim to be called the word, which overlap to a great extent, but which do not have quite the same scope. As usual, I shall prefer to use a familiar term, with a warning against making unwarranted inferences, in preference to using unfamiliar terms, which, though safe from being misunderstood, are often also safe from being understood. \citep[159]{chao2011grammar}
\end{quote}

Thus, one can assign the label of ``word'' to a particular constituent as a matter of convenience since it could bootstrap understanding of an unfamiliar concept.\footnote{As a matter of descriptive convenience it is just as likely that the notion of ``word'' obfuscates more than it clarifies and the purported understanding or agreement achieved is by and large an illusion. There is an important difference between a description \textit{feeling} intelligible and having a detailed understanding of the case at hand as there is an important difference between agreement and the illusion of agreement  (see \citealt{smaldino2017models, kahneman2021noise} on the illusion of agreement).}

But it follows as a matter of logic that one linguist's g-word and p-word will not necessarily be comparable to the next linguist's, even in the same language. There is also the danger that certain facts about the relevant language will remain poorly or imprecisely described. What would be the value in describing a potential diagnostic for g-words or p-words that does not line up with our preferred analysis \citep{haspelmathword:2011} especially if authorities in the field \textit{insist} that such constituents are manifested in all languages ``without doubt''?

On the empirical word bisection dogma, Dixon is making a substantive claim about regulative principles or constraints underlying the distribution of grammatical and phonological properties across the languages of the world. On this interpretation, Dixon is wrong to claim that grammatical and phonological words can be identified ``without doubt.'' For this position to hold, Dixon would have to articulate how the grammatical and phonological principles he considers relevant would be patterned were the word bisection dogma false. All substantive empirical claims depend on a description language that allows them to articulate what it would mean for them to be falsified in order to show that they are not tautologies \citep{mayo2018statistical}. This is what it means to have a substantive empirical claim. However, BLT has no vocabulary or descriptive language for even articulating the relevant counterfactual.

It is not always clear when a linguist is advocating a fiat-based or an empirically contentful conception of wordhood. \citet{haspelmath2022defining} is explicit in proposing a fiat based definition (not an empirically substantive theory) of ``word'' for all languages. Certain passages in \citet{dixonaikhenvald02}, \citet{dixon2010basica} and \citet{aikhenvald2020essence} suggest that they are pushing an empirically contentful claim about the existence of ``words" in languages. For example consider the following passage:

\begin{quote}
It is not impossible that there would be a language that lacks phonological words and/or grammatical words, but we are not at present aware of one. \citep[32]{dixonaikhenvald02}
\end{quote}

However, they do not articulate what such a hypothetical language would look like. It is hard to see from their discussion and their methodology how such a situation could arise, i.e. the claim appears to be tautological \citep{tallman2020beyond}. As such all claims that insinuate that grammatical and phonological words are present in all languages in BLT as it is currently formulated are unfalsifiable and, therefore, ascientific. Insisting that all languages have grammatical and/or phonological words in the absence of any clear articulation of what the falseness of such a claim would entail empirically can only reflect a metaphysical prejudice rather than a scientifically valid position.

In any case it is interesting to consider what an empirical version of the word bisection dogma could amount to.

A strong version of the empirical word bisection dogma would claim that all phonological principles converge on a single domain and all grammatical principles converge on a single domain. However, this is clearly false and is well recognized as such by everyone who has discussed the topic to my knowledge \citep{carnie2000definition, hildebrandt2007grammatical, bickel2009distribution, Bickel2017, haspelmathword:2011, tallman2023measuring}. Such a claim would be implausible on diachronic grounds alone as we would expect grammaticalizing elements to gradually integrate into word domains over time \citep{bybee1998prosody, schiering2006cliticization}. 

Another rendition of the empirical word bisection dogma is that it is probabilistic. This version of the claim seems to be presupposed in the following claim by \citet[274]{matthews:words}:

\begin{quote}
No [wordhood] criterion is either necessary or sufficient ... But they are relevant insofar as, in particular languages, they do tend to coincide.
\end{quote}

One interpretation of this claim is that the g-domains and p-domains tend to converge around unique results more than one would expect if they were distributed according to chance alone. In this perspective the g-word and p-word are seen as regulatory principles that predict statistical clusterings of grammatical and phonological properties. We do not predict perfect coincidence between grammatical principles, nor between phonological ones, but enough to support the idea that grammar can be divided into word and phrase structure in the morphosyntactic domain (morphology versus syntax) and phonological domain (lexical versus post-lexical phonology).

In \citet{bickel2009distribution} this issue is engaged with, if not directly tested, in the phonological domain. \citet{bickel2009distribution} argue that the p-domains do not cluster around one abstract p-word domain cross-linguistically. Thus, on the interpretation that criteria should tend to cluster, it is not clear that Matthews' conjecture is correct. At least in the phonological domain the assumption seems to be falsified. As far as I know, Matthews claim about the tendency of wordhood criteria to cluster has not been tested systematically in the morphosyntactic domain. In \cite{tallman2021constituency} I argue that it is not obviously true based on the application of wordhood tests in Chácobo. 

This does not mean some version of the word bisection dogma as a regulative principle cannot be established when we look at the relevant phenomena cross-linguistically. This question is partly what motivated the collaborative project which resulted in this volume: is there an empirically contentful, but perhaps statistically justifiable version of the word bisection dogma that can be defended? Addressing this question requires a typological project that codes and measures the degree to which the relevant criteria align.

Insisting on a definition of the concepts by fiat may have some value in another research context \citep{haspelmath2022defining}, but it is not the concern of this volume.\footnote{Note that \citet{haspelmath2022defining} provides a definition of a ``word", which is not based on any phonological criteria. Those wishing to maintain a distinction between g-words and p-words might choose another contrasting phonological criterion to define the p-word. For instance, one could claim that the phonological word is always a minimality domain or always the stress domain. There may be some research contexts where such a universal definition is useful or even necessary. But it remains unclear why such a designation would invalidate a research program that seeks to investigate how different notions of the word, or different domains, cluster with one another cross-linguistically.} We are concerned with describing and theorizing about patterns relevant to understanding identifiable empirical phenomena of the languages of the world, not with ratifying or rejecting some fetish in linguistics for traditional terminology.

\section{The prosodic hierarchy (hypothesis)}
\label{sec:theprosodichierarchyhypothesis}

The Prosodic Hierarchy Hypothesis (PHH) is perhaps the most prominent hypothesis that is concerned with the relationship between morphosyntactic and phonological domains. The more orthodox articulations of the theory state that all languages come with a fixed number of (post-lexical) phonological layers (prosodic word, phonological phrase, utterance phrase etc.), which are projected (or mapped) from morphosyntactic constituency in a constrained fashion \citep[111]{vogel2023is}. A corollary of this idea is that the relationship between morphosyntax and phonology is ``indirect'': Morphosyntactic objects are translated into phonological ones where they can be interpreted by a phonological and/or phonetic component of grammar. The mapping process eliminates details from the morphosyntax from phonology's vantage point. This information reduction constrains the types of relationships that phonology can bear with morphosyntax. That is the idea anyway. In practice, the diversity in projection and parsing rules and the flexibility with which morphosyntactic and phonological domains can be constructed by the analyst makes the PHH (and associated auxiliary hypotheses) hard (or impossible) to test.

This section provides a brief overview of the PHH and the typological studies which have sought to test it. The methodology employed in this volume was inspired by the latter studies but sought to advance from them and overcome some of their shortcomings.

To illustrate the basic idea of the PHH and indirect reference consider the following sentences from Chácobo in \REF{ex:chacobo4.1} and \REF{ex:chacobo5}. Note that in Chácobo the ergative tone is a floating high tone.

\ea \label{ex:chacobo4.1}
    \gll kamano=́  ina pi=kɨ \\
    jaguar=\Erg{} dog eat=\Decl{}:\Pst{} \\
    \glt `The jaguar ate the dog.'
\z 

\ea \label{ex:chacobo5}
    \gll ína píi kamano=́  =wa=kɨ \\
    dog eat jaguar=\Erg{} =\Tr{}=\Decl{}:\Pst{} \\
    \glt `The jaguar ate the dog.'
\z 

The sentences above serve to illustrate two facts about Chácobo. The displacement of the syntagm \textit{ina pi} `dog eat' from its position in \REF{ex:chacobo4.1} to its position in \REF{ex:chacobo5} suggests that the object and the verb root in Chácobo form a constituent excluding the clause-type and tense clitic \textit{=kɨ} `declarative past'. On the other hand comparison of the two examples shows that when \textit{=kɨ} `declarative past' is right-adjacent with the verb root as it is in \REF{ex:chacobo4.1} it behaves as a phonological constituent with the root, blocking the vowel lengthening manifest in \REF{ex:chacobo5}. Assuming that the blocking of the vowel lengthening signals that \textit{pi} and \textit{=kɨ} are a phonological constituent in \REF{ex:chacobo4.1}, we thereby arrive at an analysis where the an abstract syntactic structure motivated through constituency tests does not line up with phonological groupings based on minimality-induced processes, specifically blocking, permitting or obliging the insertion of phonological material to meet a bimoraicity requirement \citep{tallman_constituency_2021}.

We could posit the morphosyntactic structure for the Chácobo sentence in \REF{ex:chacobo4.1} with the translation rules in \REF{translationrules}, resulting in the prosodic tree in \REF{tree:chacobo5}. The structures below are simplified, only presenting constituency structures I discussed evidence for in the preceding paragraph (I assume that nouns and verbs are distinct and that Chácobo has noun and verb phrases, C/T stands for clause-type and/or tense, S stands for sentence).

\ea \label{tree:chacobo5}
     \begin{forest}
        [S [NP [N [jaguar, tier = word] ] ] [VP [NP [N [dog, tier=word] ] ] [V [eat, tier=word] ] ] [{C/T}  [{=\Decl{}:\Pst{}}, tier=word ] ] ]
     \end{forest}
\z 

% \ea \label{tree:chacobo5}
%     \begin{tikzpicture}
%     %\tikzset{frontier/.style={distance from root=140pt}}
%     %\tikzset{edge from parent/.append style={very thick}}
%         \Tree [.S [.NP [.N jaguar ] ] [.VP [.NP [.N dog ] ] [.V eat ] ] [.{C/T}  =\Decl{}:\Pst{} ] ]
%     \end{tikzpicture}
% \z 
\ea \label{translationrules}
    Morphosyntactic to phonological constituency translation \\
    \ea Lexical (X$^0$) elements project a phonological word.
    \ex A lexical (X$^0$) root parses nonlexical (clitic?) elements to its right into a phonological word (Pwd) if they are not already in a Pwd of their own (or clitic elements integrate into the prosodic word to their left).
    \ex Translate the highest projection into an intonational phrase (IP).
    \z
\z

\ea \label{tree:chacobo6}
    \begin{forest}
        [IP [Pwd [{kamanó}, roof] ] [Pwd [{ína}, roof] ] [Pwd [{píkɨ}, roof] ] ] 
    \end{forest}
\z 

% \ea \label{tree:chacobo6}
%     \begin{tikzpicture}
%     \tikzset{frontier/.style={distance from root=80pt}}
%     %\tikzset{edge from parent/.append style={very thick}}
%         \Tree [.UP [.Pwd \edge[roof]; {kamanó} ] [.Pwd \edge[roof]; {ína} ] [.Pwd \edge[roof]; {píkɨ} ] ]
%     \end{tikzpicture}
% \z 

We stipulate that if a Pwd is not minimally bimoraic, a root will undergo vowel lengthening. This captures the obligatory lengthening of \textit{pi} `eat' to \textit{pii} `eat' in the example in \REF{ex:chacobo5}.

The analysis sketched above illustrates non-isomorphy between morphosyntactic and phonological domains: in the morphosyntactic analysis \textit{pi=kɨ} is not a constituent, but in the phonological analysis it is. Or, put another way. Phonological rules of Chácobo rely on a (surface) constituent structure which is different from that which is motivated from morphosyntactic constituency tests. The analysis illustrates what is meant by indirect reference: minimality is built out of \textit{Pwd}, which is in turn parsed from abstract notions like lexical X$^0$.\footnote{The parsing rule provided more or less gives a ``relational rule"; an edge-based formulation might say that Pwd is parsed from the left edge of lexical X$^0$.} Note that the translation from morphosyntax to phonology does not make reference to part of speech categories like ``noun'' or morphosemantic content like \Pst{}. It only makes references to different layers of X and the distinction between lexical and functional categories. Typically lexical categories will project a phonological word but non-lexical categories will not \citep{selkirk1996prosodic, selkirk2011syntax, werle2009word}. The mapping rule also requires a morphosyntactic analysis with some type of division into levels for a correct formulation. If we gave Chácobo a different morphosyntactic structure by, for instance, assuming that \textit{ina pi} `dog eat' was under X$^0$ our parsing rules would no longer make the correct predictions. Thus, articulating one's morphosyntactic analysis is crucial for meaningful assessment of the predictions of any prosodic phonology analysis. If one does not present the evidence for X$^0$ or any of the presupposed constituency structures, the prosodic analysis will not make meaningful cross-linguistic predictions, nor be comparable to other prosodic analyses.

The Prosodic Hierarchy Hypothesis assumes that all languages manifest a universal prosodic hierarchy which is mapped from morphosyntactic constituency in a constrained fashion, depicted in \REF{prosodichierarchy}.

\ea \label{prosodichierarchy}
\begin{forest}
	[,phantom,s sep=0.5pt
	[CP
	[XP  [X$^0$] ] 
	]
	[$\Rightarrow$,no edge[$\Rightarrow$,no edge[$\Rightarrow$,no edge]]]
	[IP
	[PPh [Pwd ] { \draw (.east) node[right]{\text{(Phonological word)}}; } ] { \draw (.east) node[right]{\text{(Phonological phrase)}}; }
	] { \draw (.east) node[right]{\text{(Intonational phrase)}}; }
	]
\end{forest}
\z



% \ea \label{prosodichierarchy}
% \begin{table}[]
% \begin{tabular}{clcl}
% CP & \Rightarrow & IP  & (Utterance)           \\
% |  &             & |   &                       \\
% XP & \Rightarrow & PPh & (Phonological phrase) \\
% |  &             & |   &                       \\
% X⁰ & \Rightarrow & Pwd & (Phonological word)  
% \end{tabular}
% \end{table}
% \z
% \ea \label{prosodichierarchy}
%     \begin{forest}[phantom,s sep=1cm, GP1
%         [CP, name = CP [XP[X⁰]]] 
%         [{IP}, name=IP [{PPh} [{Pwd} ]]
%         ] 
%     ]
%     \end{forest}
% \z 

% \ea \label{prosodichierarchy}
%     \forestset{
%         xlist/.style={
%             phantom,
%             for children={no edge,replace by={[,append,
%             delay={content/.wrap pgfmath arg={\csname @alph\endcsname{##1}.}{n()+#1}}
%             ]}}
%         },
%         xlist/.default=0
%     }
%     \begin{forest}
%         [,xlist,
%             for tree={after packing node={s+=0.1pt}}
%         [CP
%              [XP  [X$^0$ ] { \draw (.east) node[right]{$\Rightarrow$}; }  ] { \draw (.east) node[right]{$\Rightarrow$}; } ] { \draw (.east) node[right]{$\Rightarrow$}; }
%         [IP
%              [PPh [Pwd ] { \draw (.east) node[right]{\text{(Phonological word)}}; } ] { \draw (.east) node[right]{\text{(Phonological phrase)}}; } ] { \draw (.east) node[right]{\text{(Intonational phrase)}}; }
%         \end{forest}
%     \forestset{
%         nice empty nodes/.style={
%             for tree={calign=fixed edge angles},
%             delay={where content={}{shape=coordinate,
%                                     for current and siblings={anchor=north}}{}}
%             },
%     }
% \z

Phonological processes make reference to phonological domains, not morphosyntax directly. A phonological rule that refers to morphosyntactic words or phrases is banned. This requirement will not make an empirical difference unless the mapping rules result in non-isomorphy. Phonological domains are constructed out of structures such as X$^0$ and XP. They do not make reference to noun phrases or verb phrases as such. X'-theory or one of its descendants, which presumes that there is phrase structure homogeneity across verbal, nominal and adjectival domains is presupposed. Indeed it is necessary for the translation process to occur. This prevents a phonological domain from being specific to a part of speech class or specific construction. 

It is important to highlight what this perspective shares and what it does not share with the BLT formulation of morphosyntactic and phonological wordhood. Both the PHH and BLT assume that there is a hierarchy of constituents. Discussions of such issues generally presuppose that the identification of distinct and comparable levels cross-linguistically is somehow obvious: not much attention is given to the possibility that there might be some ambiguity in distinguishing between ``word'' and ``phrase.'' The PHH also assumes the word bisection dogma: that a distinction between morphosyntactic and phonological words is sufficient for describing misalignments between candidate wordhood diagnostics. The PHH often comes coupled with a few other auxiliary positions, not explicitly articulated by BLT. For instance, BLT does not make explicit a distinction between lexical and post-lexical phonology, but this is assumed in much of the prosodic phonology research \citep{scheer2010guide}. Relatedly, in most formulations of prosodic phonology, mapping rules do not make direct reference to information like part of speech classes. But this assumption is not made explicit in BLT. One wonders, however, whether such assumptions are \textit{implicit} in the word bisection dogma. Does the notion of a phonological word really make sense if its content and/or relationship to morphosyntax varies from construction to construction, or part of speech category to part of speech category?

% In BLT literature the Prosodic Hierarchy Hypothesis is cited as complementary \citep{dixon2010basica}. The Prosodic Hierarchy Hypothesis makes little sense without assuming some aspects of generative syntax (i.e. some version of X' theory or one of its descendants). By positing that there are universal transconstructional constituents like `morphosyntactic word' and `phonological word', BLT adopts fundamentally similar assumptions to the Prosodic Hierarchy Hypothesis. The difference is that the Prosodic Hierarchy Hypothesis formalizes the relationship between these domains more explicitly. Another difference is that it is usually acknowledged that the Prosodic Hierarchy Hypothesis is relevant `post-lexically', or `above the word', whereas its assumptions do not necessarily hold for phonological processes which are word-internal (lexical phonology). In the word, phonological processes might make reference to a category such as `noun' or a specific root. Such a distinction between word-internal and sentence level phonology is not discussed in BLT, but note that it is likely relevant to make a notion such as `phonological word' meaningful. The phonological word stands in between lexical (word level) phonology and post-lexical (sentence level) phonology, and it is unclear how such a constituent could be identified consistently without such a distinction. 

The PHH shares with BLT the adoption the word bisection dogma and presents us with a set of labeling conventions for dealing with misalignments of the types p$_1$ \neq{ p$_2$} \neq { p$_n$} and g$_1$ \neq{ g$_2$} \neq{ g$_n$}. Misalignments in the morphosyntax can be handled by positing that the relevant g-domain is a phrasal, subphrasal or even a subword constituent. Despite the fact that misaligning domains can be dealt with by means of a more elaborate set of labels, there is still unresolved ambiguity with respect to which domain receives which label, a point I elaborate on below.

%Advocates of the prosodic hierarchy claim that it is a constrained theory that allows for assessment of clearly testable predictions (vogel, see scheer for a competing view). It is also claimed or implied that while not all the predictions of the prosodic hierarchy are born out in case after case the evidence seems to support more than refute the claim (bennett elfner). 

The PHH purports to make substantive predictions about the relationship between morphosyntactic and phonological domains. It is often implied that there is wide scale empirical support for the hypothesis and that it makes substantive predictions about language structure \citep{bennett2019syntax}, i.e. it is not just a set of arbitrary labeling conventions. Despite such triumphalist claims, it is not really accurate to discuss a single PHH. The empirical content of the hypothesis will vary drastically depending on what supporting auxiliary hypotheses are adopted and how one maps the metalanguage of the theory to language specific facts. Furthermore, the auxiliary hypotheses often weaken the predictions of the theory substantially. Below I take stock of these auxiliary hypotheses and assess their importance for the testability of (or some version of) the PHH and the general usefulness of the PHH for language comparison. 
The first three points are well known and widely discussed and debated in the prosodic phonology literature: (i) adding more layers (\sectref{sec:morelayers}); (ii) skipping layers (\sectref{sec:layerskipping}); (iii) recursion (\sectref{sec:recursion}). The last two points concern issues which are less discussed, but further weaken the claims of the PHH (\sectref{sec:empiricallycontentlesslayers} and \sectref{sec:whatmorphosyntax}). The final point concerns the most obvious empirical prediction of the PHH about domain clustering, which current research suggests is false \citep{bickel2009distribution}. More generally though, I argue that PHH is not testable and therefore the idea that the PHH has broad empirical support is fallacious. The best we can do is say that there are certain versions of the PHH that have been shown to be false. Furthermore, I argue that as a typological metalanguage for language comparison, the PHH is problematic due to the ambiguity in mapping its categories and structures to actual languages. Linguists should move with caution when using concepts from the PHH for language comparison, and by extension description, as the concepts are abstract and their mapping to language particulars indeterminate. I suggest that the planar-fractal method offers a better alternative for language comparison (for now).

\subsection{More layers} 
\label{sec:morelayers}

While the three layers displayed in \REF{prosodichierarchy} are assumed by most researchers, the literature attests to a wide variety of positions regarding which other layers might be relevant. In \citet{nespor2007prosodic} a domain called the ``clitic group" is posited to account for the behavior of combinations containing clitics between the prosodic word and the phonological phrase. The clitic group was abandoned when more sophisticated theories of clitic integration were developed in the 1990s \citep{booij1996cliticization, selkirk1996prosodic, peperkamp1996prosodic, peperkamp1997prosodic}. However, \citet{vogel2008morphology} argues that such a constituent is still necessary, renaming it the ``composite group". \citet{downing2020re} adopts the ``prosodic stem", a constituent lower than the prosodic word. \citet{hildebrandt2007grammatical} has shown that Limbu has too many domains to be able to be easily accounted for with the PHH.
The possibility of adding (or removing) domains ad-hoc weakens the predictions of the PHH. At no point (except in the case of Schiering, Hildebrandt and Bickel) was the necessity of adding new domains seen as evidence against the PHH, but the possibility immunizes the theory against a specific type of counter-evidence. Actual practice in the field suggests, therefore, that the PHH does not place any constraints on the number of phonological constituents a language might have. It is perhaps true that the PHH could make some claim concerning the number of phonological layers that languages \textit{tend} to have, but this has not been shown.

From the perspective of language comparison the possibility of adding new domains adds more ambiguity. Consider the case of adding the composite group or ``kappa" to our vocabulary \citep{miller2018phonology, vogel2019life}. Now for a given p-domain in a language where the kappa was not originally introduced, we are not just faced with potential ambiguity between p-word and p-phrase, but also between p-word, p-phrase and kappa. This problem could only in principle be resolved with attention to cross-linguistically \textit{operationalizable} morphosyntactic domains: kappa or whatever should relate to a kappa-specific morphosyntactic domain in a specific way. Otherwise the extra domain has no value for language comparison and introduces noise in language comparison. How are we to know that one linguists' kappa is not another linguist's phonological word or phonological phrase?

\subsection{Layer skipping}
\label{sec:layerskipping}

The original version of the PHH posited ``strict layering.'' An analysis that follows strict layering is one where in the parsing of elements into the prosodic hierarchy none of the layers can be skipped \citep{hayes1989prosodic, selkirk1996prosodic, nespor2007prosodic}. I quote Selkirk for a more precise definition.

\ea 
    \begin{quote}
    The strict layer hypothesis \\
    A constituent of category-level \textit{n} in the prosodic hierarchy immediately dominates only a (sequence of) constituents at category-level \textit{n}-1 in the hierarchy \citep[437]{selkirk1984phonology}.
    \end{quote}
\z 

A prosodic word can only be composed of feet. A phonological phrase can only be composed of prosodic words. It cannot contain prosodic words and syllables. This hypothesis constrains the structure of phonological constituency. There are two ways of violating the strict layer hypothesis. One is through layer-skipping and the other is through recursion. I start with layer skipping. A structure without layer skipping would be as in \REF{tree:strictlayering1} and one with layer skipping would be as in \REF{tree:layerskipping}. The right-most prosodic word in this tree ``skips'' the phonological phrase.

\ea 
    \ea \label{tree:strictlayering1}
   
     \begin{forest}
        [IP 
            [PPh    [Pwd ]  [Pwd   ] ]  [PPh   [Pwd    ]   [Pwd    ]    ]
        ]
        \end{forest}
    
    \ex \label{tree:layerskipping}
    
    \begin{forest}
        [IP 
            [PPh    [Pwd ]  [Pwd    ] ]  [PPh   [Pwd    ]   ] [Pwd ]
        ]
    \end{forest}
   
    \z 
\z

To illustrate the basic idea of layer skipping, consider the example from Chácobo below. There is a phonological domain in Chácobo where high tones are inserted if there is no underlying lexical L(ow)-H(igh) tone present.

\ea 
    $[$nǒjaki $\downarrow]$ \\
    \gll nǒya =kɨ \\
        fly =\Decl{}:\Pst{} \\
    \glt `S/he flew.'
\z 

When an underlying LH tone is present as in the example below, the high tone insertion is blocked. An H is not inserted on the first syllable as in the previous example.

\ea 
    $[$ nòjàjóki $\downarrow]$ \\
    \gll noya =yǒ =ki \\
        fly =\Compl{} =\Decl{}:\Pst{} \\ 
    \glt `They all flew.'
\z 

The domain of initial H tone insertion/blocking is larger than the minimality domain that I identified as the PWd above \citep{tallman2018grammar}. I thus assume it is the PPh, following the assumptions of the prosodic hierarchy.\footnote{But I could call it the ``composite group.''}

In the example in \REF{ex:chacobodifferentsubject1}, the clitic \textit{=kɨ̌} `prior event, different subject' (not to be confused with toneless \textit{=kɨ} `declarative, past') blocks the insertion of the H tone as expected on \textit{noya} `fly' as expected.

\ea \label{ex:chacobodifferentsubject1}
    $[$píno nojàkɨ́ tsí honi tsájakɨ$\downarrow]$ \\
    \gll pino noya =kɨ̌ tsi honi = ́  tsaya =kɨ \\
    humming.bird fly =\Prior{}:\Ds{} \Lnk{} man =\Erg{} see=\Decl{}:\Pst{} \\
    \glt `When the humming bird flew the man saw it.'
\z 

In different subject dependent clauses, verb phrases can front as in the example below, where \textit{noya} `fly' appears before the subject \textit{pino} `hummingbird.' Note that in this example, the H tone is inserted on \textit{noya} `fly.'

\ea 
    $[$nója píno kɨ̌ tsí ɨ tsájakɨ$\downarrow]$ \\
    \gll noya pino           =kɨ             tsi honi =́ tsaja =kɨ\\
           fly humming.bird =\Prior{}:\Ds{} \Lnk{} man =\Erg{} see =\Decl{}:\Pst{} \\
    \glt `What the humming bird did was fly when the man saw it.'
\z 

In the string \textit{noya pino kɨ̌} two possibilities are warranted under strict layering. Either, the \textit{=kɨ} must integrate into the Pwd projected from \textit{pino} or it must itself project its own Pwd. The two possibilities are depicted below (excluding an analysis whereby the clitic projects its own PPh, which would not solve the problem at hand in any case).

\ea \label{tree:chacobo8}
    \begin{forest}
    [IP [PPh [Pwd [noja] ] ] [PPh [Pwd [pino] ] [Pwd [kɨ] ] ] ]
    \end{forest}
\z 


% \ea \label{tree:chacobo8}
%     \begin{tikzpicture}
%         \tikzset{frontier/.style={distance from root=80pt}}
%     %\tikzset{edge from parent/.append style={very thick}}
%         \Tree [.IP [.PPh [.Pwd noja ] ] [.PPh [.Pwd pino ] [.Pwd kɨ ] ] ]
%     \end{tikzpicture}
% \z 

\ea \label{tree:chacobo9}
    \begin{forest}
    %\tikzset{edge from parent/.append style={very thick}}
        [IP [PPh [Pwd [noja] ] ] [PPh [Pwd [pino] [kɨ̌] ] ] ]
    \end{forest}
\z 

% \ea \label{tree:chacobo9}
%     \begin{tikzpicture}
%     \tikzset{frontier/.style={distance from root=80pt}}
%     %\tikzset{edge from parent/.append style={very thick}}
%         \Tree [.IP [.PPh [.Pwd noja ] ] [.PPh [.Pwd pino kɨ̌ ] ] ]
%     \end{tikzpicture}
% \z 

Neither analysis makes correct predictions. If we assume that \textit{=kɨ̌} `prior, different subject' projects its own Pwd, then it should lengthen to meet minimality requirements. Even if we allow it to integrate into an adjacent Pwd (for which there is no evidence based on vowel lengthening), its presence should block the insertion of an H tone on \textit{pino} `hummingbird', contrary to fact.

Our prosodic analysis can be saved from quick falsification, if we allow \textit{=kɨ̌} to integrate post-lexically with a higher prosodic domain, say IP, depicted in the tree below. This involves ``skipping'' both the Pwd and the PPh layer.

\ea \label{tree:chacobo10}
    \begin{forest}
        [IP
        [PPh [Pwd [noja] ] ] [PPh [Pwd [pino] ] ] [kɨ̌] ]
    \end{forest}
\z 



% \ea \label{tree:chacobo10}
%     \begin{tikzpicture}
%     \tikzset{frontier/.style={distance from root=100pt}}
%     %\tikzset{edge from parent/.append style={very thick}}
%     \Tree [.IP [.PPh [.Pwd noja ] ] [.PPh [.Pwd pino ] ] [ kɨ̌ ] ]
%     \end{tikzpicture}
% \z 

Violating strict layering makes the PHH weaker as it immunizes the theory further against potentially falsifying evidence, bringing it closer to the status of a tautology, i.e. a set of labels for annotating phonological domains and nothing else. As far as I have been able to discern the ability for clitics to integrate at various levels of the prosodic hierarchy does nothing except redescribe their phonological behavior in a stipulative fashion. Insofar as this interpretation is correct, layer skipping exonerates the PHH from making any predictions about clitic phenomena cross-linguistically. While it may be an elegant expositional device for representing language-internal and cross-linguistic differences in the behavior of clitics \citep{peperkamp1996prosodic}, it should be recognized as just that, not a theory that posits constraints on how much languages can vary. 


% For language comparison the important point about layer-skipping is that it shows that the term ``phonologically dependent" is highly ambiguous and cannot by itself be used as a point of comparison: ``phonologically dependent" means at most ``is realized with a form and does not project its own prosodic word". Apart from this the notion has no general meaning because the researcher needs to specific which prosodic domains a clitic integrates into and in what contexts it can undergo this integration. Clause-type clitics in Chácobo can integrate into Pwd, PPh or UP (granting the validity of the categories of the prosodic hierarchy for a moment) depending on their position in the clause.  

% A further issue for comparison is that which domain a given clitic integrates into is often ambiguous. But the formal architecture of the Prosodic Hierarchy Hypothesis forces us to make a decision, even in the absence of an empirical difference.

% In Chácobo there is a domain between the PPh and the UP, which predicts the presence of apocope on certain trisyllabic nouns. For instance, inside an IP the noun \textit{kamáno} reduces to \textit{kamá} `jaguar'. 

% \ea 
%     [kákɨ kamáno \downarrow] ]] \\   
%     \gll ka=kɨ kamáno \\
%     go=\Ant{} jaguar \\ 
%     \glt `The jaguar has gone'
% \z 

% \ea 
%     [kaa kàmá kɨ \downarrow]
%     \gll ka kamǎno kɨ \\
%     go jaguar \Decl{}:\Pst{} \\ 
%     \glt `The jaguar went.'
% \z 

% When \textit{kàmáno} `jaguar' occurs after the clause type marker the prosodic structure could be represented as in \ref{tree:chacobo11}. Notice that \textit{kamano} is outside of IP, which bans it from undergoing apocope. In Chácobo high tone insertion is does not apply to nouns and nominal structures that occur after the clause-type morpheme, thus we have to represent \textit{kàmáno} without a PPh. 

% \ea \label{tree:chacobo10}
% \begin{tikzpicture}
% \tikzset{frontier/.style={distance from root=120pt}}
% %\tikzset{edge from parent/.append style={very thick}}
% \Tree [.UP [.IP [.PPh [.Pwd ka kɨ ] ] ] [ [.Pwd kàmáno ] ] ]
% \end{tikzpicture}
% \z 

% When the noun occurs between the verbal root and the clause-type morpheme, it is not clear what the enclitic \textit{=kɨ} integrates into: two representations are possible.

% \ea \label{tree:chacobo11}
% \begin{tikzpicture}
% \tikzset{frontier/.style={distance from root=120pt}}
% %\tikzset{edge from parent/.append style={very thick}}
% \Tree [.UP [.IP [.PPh [.Pwd kaa ] ] [.PPh [.Pwd kàmá ] ] ] kɨ ]
% \end{tikzpicture}
% \z 

% \ea \label{tree:chacobo12}
% \begin{tikzpicture}
% \tikzset{frontier/.style={distance from root=120pt}}
% %\tikzset{edge from parent/.append style={very thick}}
% \Tree [.UP [.IP [.PPh [.Pwd kaa ] ] [.PPh [.Pwd kàmá ] ] kɨ ] ]
% \end{tikzpicture}
% \z 

\subsection{Recursion}
\label{sec:recursion}

As stated above, in the original PHH, strict-layering prevents individual prosodic domains from recursing. An example of a recursive structure in prosodic phonology would be as follows. In the structure below PPh' is a recursed PPh of the lower domain.

\ea \label{tree:prosodichierarchyrecurse1}
    \begin{forest}
        [IP [PPh [Pwd]  [Pwd] ] [PPh' [PPh [Pwd]  [Pwd] ] [Pwd] ] ]
    \end{forest}
\z 

% \ea \label{tree:prosodichierarchyrecurse}
%     \begin{tikzpicture}
%         \tikzset{frontier/.style={distance from root=100pt}}    
%         % \tikzset{edge from parent/.append style={very thick}}
%         \Tree [.IP [.PPh Pwd  Pwd ] [.PPh' [.PPh Pwd  Pwd ] Pwd ] ]
%     \end{tikzpicture}
% \z 

The issue of whether recursive structures exist in phonology is somewhat controversial \citep{fery2017intonation, tallman2021caroline, ishihara2023match, kugler2023phrase, boegel2021function, cheng2021recursion, ito2021recursive,miller2021is}. The reason seems to be related to the fact that different authors adopt different criteria for identifying recursion. Here I will limit the discussion to how the issue of recursive phonological domains is relevant for language comparison (see \cite{miller2021is} for an important discussion about how recursion might be constrained cross-linguistically).

An important first cut in understanding recursion in phonology would be to recognize a distinction between notational and empirical recursion. The distinction is inspired by the discussions in \citet{schiering2010prosodic} and \citet{miller2021is}.

\ea 
    \ea \textsc{Notational recursion}: A category is embedded under another category with the same label. The different instances of the label need not have the same empirical signal (i.e. they do not refer to identical empirical phenomena).
    \ex \textsc{Empirical recursion}: A category is embedded under another category. Each layer signals the same empirical phenomenon.
    \z
\z 

In notational recursion one label is just formally represented as embedded under another one. I can illustrate notational recursion with an example from Chácobo. In Chácobo, I associated minimality with Pwd, default H tone insertion with PPh and intonational phrasing with IP. There is an important prosodic phenomenon in Chácobo whose span of structure is in between that of the PPh and the IP. Trisyllabic nouns truncate their final syllable if they occur before the clause-type morpheme. Otherwise they occur in their ``long forms''. The long form of the morpheme \textit{kàmáno} `jaguar' is illustrated in \REF{ex:chacobo14} and the short form in \REF{ex:chacobo15}. Likewise the short and long forms of \textit{tsǎkaka~tsǎka} are provided in these examples.

\ea \label{ex:chacobo14}
    $[$ tsǎkà tsájakɨ kàmáno $\downarrow]$  \\   
    \gll tsǎkaka tsǎya =kɨ kamǎno \\
    agouti see =\Ant{} jaguar \\ 
    \glt `The jaguar has seen the agouti.'
\z 

\ea \label{ex:chacobo15}
    $[$ kàmá tsájakɨ tsákaka $\downarrow]$ \\
    \gll kamáno tsaya =kɨ tsákaka \\
    jaguar see =\Ant{} agouti \\ 
    \glt `The agouti has seen the jaguar.'
\z 

Rather than positing a new domain for noun and adjective apocope, I can assume that the PPh recurses. The lower PPh⁰ is relevant to H tone insertion and blocking and the higher PPh¹ is the domain where trisyllabic or larger nouns and adjectives truncate their final syllable.\footnote{I could even justify this decision based on a syntactic analysis whereby both PPh⁰ and PPh¹ are mapped from XPs as in Match Theory \citep{selkirk2011syntax}.} 

\ea \label{tree:prosodichierarchyrecurse2}
    \begin{forest}
        [IP [PPh¹ [PPh⁰ [Pwd [kamano] ] ] [PPh⁰ [Pwd [tsaya=kɨ] ] ] ] [Pwd [tsakaka] ] ] ]
    \end{forest}
\z 


% \ea \label{tree:prosodichierarchyrecurse}
%     \begin{tikzpicture}
%         \tikzset{frontier/.style={distance from root=120pt}}    
%         % \tikzset{edge from parent/.append style={very thick}}
%         \Tree [.IP [.PPh¹ [.PPh⁰ [.Pwd kamano ] ] [.PPh⁰ [.Pwd tsayakɨ ] ] ] [.Pwd tsakaka ] ] ]
%     \end{tikzpicture}
% \z 

Thus truncation only occurs in PPh¹. It should be obvious, however, that this is no different empirically from just positing an extra layer. The only difference is that using notational recursion introduces labeling ambiguity (a point made \textit{en passant} by \citealt[62]{fery2017intonation} and \citealt[97]{richards2016contiguity} without discussion of the resulting epistemic problems this ambiguity entails): once recursion is admitted there isn't a clear reason why we should not label PPh¹ as UP⁰, and the original UP as UP¹, shifting the burden of recursion to another domain. For the purposes of language comparison I, therefore, cannot see any advantage in using notational recursion.

On theoretical grounds, the adoption of notational recursion weakens the prosodic hierarchy for the same reason that adding new domains does. Without further constraints, the effect of adding recursion into the categories of the prosodic hierarchy seems to mean that this theory now puts no upper bound on the number of prosodic domains it allows \citep{tallman2021caroline}. It is not clear to me what the purpose is of advocating notational recursion over just adding extra domains.

There might be examples of real empirical recursion (see \cite{fery2017intonation} for a review). For instance, let's say that inside PPh¹, a super H tone with twice the distance in semitones from L tones was inserted on the first syllable of the domain. One could argue that the relevant phonetic effects have now been stacked in proportion to how embedded the domain is, but that the phonetic properties of the domain have remain unchanged. Something like this might be true for the prosodic behavior of some embedded clauses as they can display similar prosodic properties but with phonetic differences shrunk down \citep{vigario2010prosodic}.

\subsection{Empirically contentless layers}
\label{sec:empiricallycontentlesslayers}

\citet[11]{nespor2007prosodic} argue that if one does not find evidence for a given layer of the prosodic hierarchy one is not necessarily warranted in assuming that the layer is not present. While the layer may not be causally related to a specific phonological process or phonetic effect, stipulating its presence may help formulate rules for other prosodic domains. An example might be positing CVV syllables in Araona (Takana). While it is not strictly necessary to state the stress rule/pitch accent rule of the language (for this all you need are vowels and consonants), positing a syllabification rule makes the statement of the stress rule simpler \citep{tallmanacceptedprefix}. In this case perhaps one is warranted in positing the syllabification rule and syllables as a prosodic layer in the language. We might also find a pitch accent rule in a language which applies as PPh, which inserts a pitch accent on the leftmost prosodic word in the PPh. The prosodic word itself might not have any independent phonological processes, but assuming prosodic words are present helps in articulating the phonological phrase.

\citet[11-12]{nespor2007prosodic} seem to take the idea of empirically empty layers even further, however, suggesting a strong burden of proof for positing the absence of one of the domains of the prosodic hierarchy in a given language, thus letting the PHH off the hook again, this time in terms of making any predictions regarding the minimum number of phonological layers one needs to ratify the theory.

\begin{quote}
    If ... it turned out to be the case that all of the languages that appeared not to have phonological rules that refer to X$^i$ shared some other feature as well, this would be a more convincing type of evidence that X$^i$ may be absent in a particular category of languages characterized by this feature.
\end{quote}

The interesting empirical question raised by this point notwithstanding, it should be noted that the epistemic consequences of allowing categories of the prosodic hierarchy to be empirically invisible makes the PHH even weaker as a theory. For a given language, cases where no phonological rule or process can be found for a p-domain predicted to exist by the PHH cannot be regarded as counter-evidence. 

The suggestion that some languages may have little or no empirical phenomena which are causally related to their prosodic words has been taken up by \citet[270]{fery2017intonation}. Such languages are referred to as ``phrase languages'' (they include Hindi, Georgian, Turkish among others).

\begin{quote}
    ... tonal specifications are mostly assigned at the level of Φ - phrases and ι-phrases. But contrary to intonation languages, specifications at the level of the word are sparse, absent or only weakly implemented. Phrase languages do not automatically associate pitch accents with stressed syllables, most tones are nonlexical (or ‘post-lexical’). 
\end{quote}

This position begs the question as to when one is ever justified in questioning the universality of a specific domain according to prosodic phonologists, since the criterion of finding something in common in such languages is at least suggested by Féry. Note that the position seems to differ from \cite{nespor2007prosodic}. Féry finds evidence that the languages where no p-word is present have something in common, but assumes that the p-word is there anyways.

The analytic possibility of positing empirically contentless layers potentially adds more indeterminacy for language comparison. Instead of positing that a given Pwd has little or no empirical signal the question arises as to whether the PPh should be relabeled as the Pwd. This is a general problem when the number of phonological domains is smaller than the set predicted to exist from the prosodic hierarchy \citep{tallman2020beyond}. One linguist's Pwd might be another's PPh, for instance (see \cite[321-322]{michaud2017tone} for relevant commentary).

Domain labeling ambiguity arises as a consequence of a lower number of prosodic domains when we only consider the prosodic tree geometry without considering the structural relations between the prosodic tree and analogous morphosyntactic domains. A prosodic word is not (just) the domain between the foot and the phonological phrase, but also the domain which is structurally closest in some sense to the morphosyntactic word. 

\subsection{But what morphosyntactic structure?}
\label{sec:whatmorphosyntax}

The validity of using structural closeness to morphosyntactic domains to label prosodic ones, depends on those morphosyntactic domains also being consistently definable from language to language \citep{miller2018phonology}. That is, in case after case, the identification of and the distinction between X⁰, XP and other constituents has to be made consistently. However, in general, the prosodic phonology literature rarely discusses morphosyntactic criteria. For instance, in \citet{fery2017intonation} only a single criterion is provided for morphosyntactic wordhood (coordination), and as far as I could discern no literature is cited that helps the reader discern how to parse up morphosyntactic constituents in a way that makes predictions about the morphosyntax-phonology interface operationalizable cross-linguistically. 

Exacerbating the problem, the morphosyntactic literature is not obviously unified in its prescriptions for how one should go about identifying the relevant constituents or if the morphosyntactic constituents presupposed by the PHH are even valid at all. \citet{carnie2000definition}, for instance, argues that the there really is no discrete distinction between X⁰ and XP. The reasoning behind this is that the properties associated with (head moving) X⁰ constituents  and (A/A'-moving) XPs do not perfectly cluster. Similar problems have been discussed outside of the generative literature \citep{russell1999whats, haspelmathword:2011, Bickel2017, tallman2021constituency}. There are constituents that behave like X⁰s according to some criteria and like XPs according to others. 

We can add that part of controversy about direct versus indirect reference theories relates to what the correct morphosyntactic analysis is, as morphosyntax-phonology non-isomorphisms could be the result of an incorrect analysis of the morphosyntax \citep{seidl2001minimal}. The possibility that non-isomorphisms might be the result of unmotivated analyses in the morphosyntax was also highlighted in the usage-based literature \citep{bybee1999effect}. Nonchalance about the labeling of \textit{morphosyntactic} domains, not to mention how to motivate the correct constituency structure, is, therefore, not justified for linguists interested in testing and/or developing theories about the relationship between morphosyntax and phonology.

\subsection{Clustering hypothesis}

One prediction of the PHH is domain clustering or bundling \citep{bennett2019syntax}. This is the only claim of the prosodic hierarchy that has been tested in a typological study.

\citet{bickel2009distribution, schiering2012stress} developed a word-domain database. This database coded phonological processes in 70 typologically diverse languages. It taxonomized the phonological processes that define p-domains into a number of types (e.g. metrical based, harmony, segmental). Each domain could be coded as being mapped over a set of structural categories (e.g. prefix-root vs. prefix-root-suffix). The relative clustering of domains could then be assessed cross-linguistically. The structure of the database allowed the researchers to assess a number of statistical relationships between phonological domains: (i) which phonological processes tend to occur in ``higher" or ``lower" domains than others; (ii) which phonological processes tend to cluster together in terms of span of application; (iii) whether there is an overall tendency for domains to cluster or bundle together better than one might expect.

An answer to the last question is most relevant to the claims about the prosodic hierarchy. Using multidimensional scaling \citet{bickel2009distribution} argue that there is no tendency for the phonological domains of their study to cluster. They argue that this result refutes the claims of the Prosodic Hierarchy Hypothesis. The idea is that if the PHH were correct, we would expect prosodic domains to cluster around a single formal category, but they do not evince any tendency to do so. In another publication taking a close look at Thai and Limbu \citep{schiering2010prosodic}, two languages which present challenges to the PHH in that they do not have the right number of layers, the authors suggest that the reason for the observed non-clustering is that prosodic domains are ``emergent.'' There is no set of innate formal categories constraining the distribution of phonological domains, these emerge from language history.
The studies by Réné Schiering, Kristine Hildebrandt and Balthasar Bickel were the first to systematically investigate the issue of domain clustering. In certain aspects the methodology employed by these authors overcomes many of the epistemic difficulties associated with the prosodic hierarchy I discussed above. The methodology employed in the current study builds on Schiering and company's methodology in important respects. We try to overcome some of the shortcomings of their approach, and so these shortcomings are worth commenting on.

The first shortcoming is that the project focused only on ``word-domains'', rather than assessing the relationship of phonological domains from morph to utterance (or at least prosodic word to utterance phrase). This opens the research up to criticisms that \textit{perhaps} some of the domain misalignments could be related to the fact that some of these domains are ``phonological phrases'' (or higher domains). If there is no consistent way of distinguishing between prosodic words and phonological phrases based on phonological criteria, then it becomes unclear why some of these p-word domains are not actually indicating a higher level of structure.

As far as I understand, the identification of p-domains in \citet{schiering2012stress, bickel2009distribution} were limited to ``lexical'' phonological processes. This issue was not explicitly discussed in the published materials to my knowledge and thus my comments here should be taken with a grain of salt \parencitetv{chapters/18-CommentaryKH}. Lexical phonological processes are supposed to be different from post-lexical processes based on a number of properties: structure preservation, optionality, reference to morphosemantic information, categoriality, among other properties \citep[201]{zsiga2020phonology/phonetics}. Lexical phonological processes are also supposed to be word-internal. A phonological process is structure preserving if it involves changing one contrastive phonological unit to another. For instance, vowel tensing in English is structure preserving: the change of \textit{grain} /gren/ to /græn/ in the context of the form /grænular/ is structure preserving because /e/ and /æ/ contrast in English. Such a process would be considered ``lexical.'' Flapping in English, which only results in the introduction of a noncontrastive allomorphy [ɾ] is considered post-lexical. \citet{schiering2010prosodic} only focused on lexical phonology.

A problem arises when we consider the fact that the criteria for distinguishing between lexical and post-lexical processes do not cluster together. For instance, the morphophonetics literature has shown that there are many word-internal processes which are not structure preserving \citep{plag2014phonological}. Some research has also uncovered structure preserving processes that are ``post-lexical'' in the sense that they occur at phrase level domains \citep{hyman1993structure}. \citet[214]{bybee2001phonology} points out that the distinction between lexical and post-lexical is probably graded, rather than discrete. It is not clear, therefore, that a distinction between lexical and post-lexical phonology can serve to delimit a ``word domains project.'' We seem to be forced by the empirical phenomena to look at the whole picture without presupposing that phonological processes can be divided neatly into lexical and post-lexical categories.

On theoretical grounds, focusing only on the word domain means that the Prosodic Hierarchy Hypothesis cannot be systematically engaged with. In many current formulations of the PHH, it is \textit{only} concerned with post-lexical processes. Lexical phonological processes are handled by lexical phonology, where there is no expectation of domain convergence. Rather, layering and cyclicity is all that is expected in the word. Contrary to the assumptions that are made in \citet{bickel2009distribution}, clustering of phonological processes around a single domain is not predicted for domains defined by lexical phonological processes. 

Another criticism of the word domains project is that it did not explicitly engage with morphosyntactic information. This criticism is present in \citet{miller2021is}, for example. The PHH is not just a theory about the clustering of phonological domains. It also purports to be a theory which constrains the relationship between morphosyntax and phonology. Miller's criticisms suggest that one should not conduct a typological project of phonological word domains without also including morphosyntactic information. Insofar as Miller's criticisms are meant as a defense of PHH (rather than simply a critique of the word-domains project) they are somewhat weak, however, because prosodic phonology literature suffers from a general dearth of argumentation for its presupposed morphosyntactic analyses even where it posits abstract morphosyntactic structures.\footnote{It is my understanding that morphosyntactic information (g-domains) were included in the original AUTOTYP database. However, it is not obvious to me how the morphosyntactic domains related to the findings reported in published materials.}

Another critique of the word-domains project is that it did not present an alternative theory which meaningfully constrains the distribution of p-domains cross-linguistically.
The force of \citet{bickel2015distributional, schiering2012stress, schiering2010prosodic} is largely methodological. They argue that typological research should start from language specific processes rather than positing \textit{a priori} structures. Such an approach seems necessary if we are going to hope to test competing claims about prosodic phonology. \citet{schiering2010prosodic} also suggest that their results support an emergentist approach to phonological domains: ``This leads us to conclude that the prosodic word is a language-particular category which emerges through frequent reference of phonological patterns to a given morphological construction type." \citep[705]{schiering2010prosodic}. The argument seems to be largely based on the failure of formal theories to account for linguistic variation, rather than the development of a testable emergentist theory of prosodic domains (see \cite{mielke2008emergence} for discussion). Future research should be dedicated to fleshing out an empirically contentful emergentist alternative. If this is done we will be able to actually assess how much formal innate structure is really necessary, if any \citep{Schmidtke-Bode2019}.  

%subsection{Vacuous rule application and spurious convergences}
%\label{sec:vacuousapplication}

 %It is not correct to say that the Prosodic Hierarchy Hypothesis is a single claim about language structure. There are a large number of versions of the Prosodic Hierarchy Hypothesis depending on how one conceptualizes the projection of phonological domains from morphosyntactic information (edge-based vs. relational), how many domains are present (e.g. should a clitic group) and the type of auxiliary hypotheses warranted (which domains can recurse, are language-specific domains admitted, is direct reference admitted). And although it is rarely explicitly mentioned in the prosodic phonology literature, since the theory claims to be a theory about morphosyntax-phonology interfacing, linguists who adopt different morphosyntactic analyses are in a sense also adopting different versions of the prosodic hierarchy hierarchy insofar as we are concerned with testable predictions. The prosodic hierarchy theory is usually considered an `indirect reference' theory, because phonological domains are analyzed as non-isomorphic with morphosyntactic ones. 
 
 %In principle, the theory purports to make explicit claims about the limits of variation on the distribution of morphosyntactic constituents and phonological processes cross-linguistically. However, there are very few studies that are typological in nature. Most studies concern a single language and it is not clear whether the moving parts of the theory (the syntactic analysis, how domains are defined and identified) are held constant across each of the studies. For instance, the hypothesis typically makes claims about how specific phonological constituents will relate to X$^0$. However, since morphosyntactic evidence for constituency structure is rarely discussed it is not clear whether two linguists writing within the assumptions of the Prosodic Hierarchy Hypothesis are using the same methodology for identifying this constituent (or any other constituent). If they are not, their inferences about what aspects of the theory need to be modified or retained will not be the same. How to map all of the parts of the theory to specific languages remains `up in the air' to a large extent, which could have serious implications for inferences when faced with novel language data. This is another reason why referring to the prosodic hierarchy \textit{hypothesis} is perhaps a misnomer: it is not clear what specific predictions the hypothesis makes, and thus it is not clear if the ``hypothesis" is meaningfully testable. 
 
\section{Typological description languages, falsifiable theories and selection bias} 

\label{sec:descriptionlanguages}

\largerpage[-1]
The previous discussion has suggested that prosodic phonology suffers from two serious problems. First, insofar as it professes to be a theory about language structure it suffers from a lack of falsifiability. 

Second, insofar as it might serve a function for language comparison it is also problematic: the theory posits a repertoire of formal categories and structures, but the mapping between these and language specific facts is highly underdetermined, resulting in a lack of commensurability from description to description. 

The planar-fractal method seeks to be a typological description language in the spirit of \citet{schiering2010prosodic} and \citet{Good:2016} that addresses these issues. This means that it is a method for comparing structures from language to language. It does not seek to be a theory which constrains typological variation. But it can serve as a methodology for testing or developing such theories. It is developed in such a way that it can be used to create machine-readable databases. This will allow researchers to discover statistical trends in the relationship between morphosyntactic and phonological domains. 

Some researchers find this strange because they assume all formal frameworks for describing linguistic facts should necessarily be theories about typological variation or the nature of language, or language universals or whatever. However, developing a description language for stating facts independently of a theory is necessary to assess the relative merits of competing theories and to avoid lapsing into self-sealing tautologies in theory construction. Relatedly, some have criticized generative linguistics specifically for conflating ``theory" with ``notation" or ``metalanguage" \citep{dryer2006functionalism}. While it is true that the planar-fractal method makes certain assumptions about language structure and assumptions about what data are important via its notation, distinguishing between data structures and theoretical models is crucial in all the sciences. Data structures are useful because they allow us to state or even simulate explicitly what data patterns we would observe if our theories were false or true. Distinguishing data structures from our theories allows us to actually assess whether a theory is testable \citep{mayo2018statistical}.  

The planar-fractal method does not compete with the PHH or any other prosodic theory for status as a theory. However, as a description language for coding, testing and developing theories concerning the relationship between morphosyntax and phonology it is superior. It attempts to eliminate mapping ambiguity between language specific facts and language structures (e.g. is phonological domain \textit{x} a p-word or a p-phrase?) and code cross-linguistic data in a machine-readable database (See Auderset et al. This Volume for the database structure). It does not posit \textit{a priori} structures presupposed by certain theories. Rather it is designed in such a way that it could be used to test such theories and/or their auxiliary hypotheses. In this way it functions as a ``comparative concept'' \citep{haspelmath2010comparative, good2016linguistic} allowing constituency facts to be coded in a commensurate fashion from language to language.

One of the motivations for conducting a cross-linguistic study and developing a methodology such as the one used in this volume is to overcome certain methodological shortcomings of traditional linguistic analysis. One such methodological shortcoming is referred to as ``methodological opportunism'' or ``diagnostic fishing'' \citep{Croft2001, croft:tenunwarranted, haspelmathword:2011}. The idea behind this criticism is that, in certain cases, linguistic frameworks, theories or hypotheses are coupled with a methodology that allows (or perhaps impels) researchers to discard or ignore data that might contradict a preferred hypothesis or a preferred set of hypotheses. \citet{Croft2001} has argued that one of the reasons that there are so many competing syntactic theories is because researchers are simply using different data to construct their analyses throwing out or dismissing as irrelevant the data used by their competitors. \citet{haspelmathword:2011} applied a similar criticism to the literature that makes use of some notion of ``word.'' Because there is no jointly agreed upon set of wordhood criteria, criteria can be used to because they fit a preferred analysis or discarded if they do not.\footnote{While the criticism seems to be directed at generative linguistics, it is not clear why the same criticism does not apply to other theory-driven endeavors in linguistics. BLT, for instance, presupposes a distinction between phonological and morphosyntactic words: why does the methodological critique of generative linguistics not extend to this approach as well (see \sectref{sec:blt})?}

In general terms, biases of this kind are well-known outside of linguistics, especially in discussions about replicability and hypothesis testing \citep{risen2006informal, nosek:preregistration, mayo2018statistical}. More closely inspired by the latter literature, I refer to the problem as ``selection bias'' \citep{tallman2021analysis} as opposed to ``methodological opportunism" or ``diagnostic fishing". The solution to selection bias that I propose below is called ``full reporting.'' Rather than every linguist pulling criteria in an ``opportunistic'' fashion from the literature and interpreting the criteria \textit{just so} they fit with their preferred analysis, \textsc{full reporting} means applying constituency diagnostics according to a protocol, developed by a team of researchers working on different languages. The idea is that full reporting forces the linguist to be held accountable to constituency diagnostics they might not have used otherwise. With this methodology we hope to assess claims about domain clustering in a less biased fashion, because we are not as beholden to the implicit biases of individual linguists working in isolation.

%perhaps discuss methodological opportunism here

\section{Planar structures}
\label{sec:planartsructures}
\largerpage
A planar structure is a hypothesis space for coding the results of constituency tests or domains, phonological and morphosyntactic alike. It is a ``comparative concept'' in the sense that \citet{good2016linguistic} uses the term in his discussion of templates. A planar structure is a maximally flat structure that contains \textsc{positions} which are \textsc{fit out} by \textsc{elements}. The positions are ordered into a template. The planar structure is an extension of the coding methods developed by \citet{bickel2009distribution} and \citet{Bickel2017}. Unlike the structures of the latter sources, however, it is not delimited by orthographic word boundaries as it scopes over a whole sentence. Rather it contains syntagmatically distinct positions where elements (whether ``morphological" or ``syntactic") are positioned on the same ``plane'' with a caveat: languages have a planar structure for each part of speech distinction they contain. A verbal planar structure contains positions within a presupposed verbal word, ``free'' adverbials, and other syntactic elements and \textsc{noun phrases} (nominal planar structures) all in the same template. A nominal template will have the noun root, all affixes which can combine with a noun and any syntactic noun modifiers.

In this section, I describe the planar structure by comparing it to phrase structure analyses. First, I provide a conceptual introduction to planar structures by articulating them as ``flattened out'' phrase structure grammars in \sectref{sec:flattening}. Then I provide a more precise formal sketch of planar structure grammars in \sectref{sec:formal} describing them as a species of phrase structure grammar with more rigid conditions on what constitutes an admissible non-terminal node. \sectref{sec:tangling} discusses the \textsc{tangling} of different planar structures, referring to cases where modifiers of one domain (predication, reference) appear in another and how this is handled. Another constraint on planar structures is that they contain a \textsc{base} element which is fixed in place in the template, a condition not put on non-base elements (\sectref{sec:baseelements}). planar structures analyze elements into positions and elements are analyzed into minimal morphs where possible and larger structures where necessary. The minimal morph condition is discussed in \sectref{sec:minimalmorphs}.
Finally I briefly comment on a criticism of the methodology that has arisen through its presentation at various venues in \sectref{sec:competing}.

\newpage
\subsection{Flattening phrase structure grammar}
\label{sec:flattening}
In order to explain the planar structure I will compare it with a typical phrase structure grammar. To start off I point out that a planar structure could be viewed as a phrase structure grammar which is ``flattened out'' until issues of recursion would make the device unworkable as a constituency test coding device. This is not done because of a commitment to the idea that sentence structure is non-hierarchical. \textit{Rather} it is done in order to construct a template over which constituency test results can be coded in a commensurate fashion across languages. Furthermore, the formalism gives us the possibility of coding bracketing paradoxes in a given language, which are not straightforwardly supported in phrase structure grammars.\footnote{In order to represent or model them, one has to posit multiple phrase structure grammars \citep{sadock1991autolexical} or toss out certain test results.} I will emphasize throughout that the planar structure is not meant to compete with or replace any given phrase structure-based or prosodic theory as a tool for the development of testing of linguistic hypotheses. My view is that they should complement them. The planar structure is a \textit{cross-linguistic comparison tool} and \textit{constituency test or domain measuring device}, not a hypothetico-deductive model.

The idea of flattening out a constituency structure should be intuitive for linguists who are familiar with competing syntactic theories where more or less hierarchical analyses can be contrasted with more or less flatter analyses (e.g. \cite{culicover2005simpler, sobin2008do} for discussion). Consider the English sentence \textit{The student will have analyzed the sentence in class}. A fairly standard constituency analysis might posit the phrase structure rules in \REF{ex:englishhierarchical}, with the corresponding constituency analysis in \REF{ex:englishhierarchicaltree} (see \cite[207-261]{mccawley1988syntactic} \cite{ baker1995english} for rough equivalents in terms of the degree of hierarchical structure).

\ea \ea \label{ex:englishhierarchical}
    S \rightarrow {} NP VP \\
    VP \rightarrow {} VP PP \\
    VP \rightarrow {} will VP/V' \\
    VP \rightarrow {} have VP/V' \\
    V' \rightarrow {} V⁰ NP  \\
    V⁰ \rightarrow {} V Infl 
    \ex \label{ex:englishhierarchicaltree}
    \begin{forest}
        [S [NP [{The student}, roof]] 
        [VP
        [VP [will] 
        [VP [have]
        [V'[V⁰ [V [analyze]] [Infl [-ed]]]
        [NP [{the sentence}, roof] ]
        ]]] [PP [{in class}, roof] ] ] ]
    \end{forest}
    \z
\z 

A few arguments might be rallied in favor of the layered VP structure above. For example V'-deletion \citep[210]{mccawley1988syntactic} and affix-hopping combined with X'-theory \citep[95--99]{ouhalla1999introducing} can be used to motivate such an analysis. \textit{Do-so} proform replacement or perhaps considerations of scope might be rallied to support the idea that the prepositional phrase \textit{in class} requires an additional VP-layer \citep{sobin2008do}. 

Another analysis might flatten out the structure on the grounds that the evidence for the layered VP above is weak and/or problematic for a variety of reasons \citep{culicover2005simpler}. We might posit a flatter structure as in \REF{ex:englishflatter}.

\ea \ea \label{ex:englishflatter}
    S \rightarrow {} NP will have VP \\
    VP \rightarrow  V⁰ NP PP \\
    V⁰ \rightarrow {} V Infl \\
    \ex \label{ex:englishflattertree}
    \begin{forest}
    [S [NP [{The student}, roof]] [will] [have] [VP [V⁰ [V [analyze]] [Infl [-ed]]] [NP [{the sentence}, roof]] [PP [{in class}, roof]]  ]]
    \end{forest}
    \z
\z 

And this is as far as any linguist would go with English in terms of ``flatness'' (to my knowledge) if English was our primary consideration. For typological investigation though we want a representation that allows us to code constituency tests regardless of whether these support a specific constituency analysis. 

It is at this point that an important conceptual difference between phrase structure grammars and planar structures arises. We are interested in phrase structure grammars only insofar as they give as position classes over which we can state test results. We are not interested in an elegant account of English grammar but one which allows unbiased comparison of constituency tests with other languages unmediated by the chimerical and abstract constituents posited in phrase structure grammars. In fact, our goal is to represent all languages \textit{as if} they had the same degree of structural flatness so that we can assess how constituency tests might or might not support various hierarchical structures to different degrees across languages.

\largerpage
In order to do this we flatten the structure further as illustrated in \REF{ex:flattest} below.

\ea \label{ex:flattest}
    \ea 
    S/VP \rightarrow {} NP will have V Infl NP PP \\
    % S/VP \rightarrow {} 1 2 3 4 5 6 7 \\
    % % 1 \rightarrow {} NP \\
    % % 2 \rightarrow {} will \\
    % % 3 \rightarrow {} have \\
    % % 4 \rightarrow {} analyze \\
    % % 5 \rightarrow {} \textit{ed} \\
    % % 6 \rightarrow {} NP \\
    % % 7 \rightarrow {} PP
    \ex \begin{forest}
        [{S/VP} [NP [{The student}, roof]  ]  [will]  [have]  [V [analyz]]  [Infl [-ed]] [NP [{the sentence}, roof]] [PP [{in class}, roof] ] ] 
    \end{forest}
    \z
\z 

Constituency tests and constituency test fracturing are discussed in \sectref{sec:fracturing}, but the relationship between a constituency test and a planar structure needs to be introduced to understand the next step in explaining the motivation for our representational device.
Putting aside the noun phrase and prepositional phrase, the structure posited above represents nothing except the relative ordering of elements in the verbal word and/or the verb phrase with its functional projects or modifiers. To discuss constituency test results, we will refer to \textsc{spans} of structure identified by these tests and attempt to define them in a consistent way cross-linguistically.

Let us say we want to code the result of a do-so proform test in English. We could say that the test identifies a span of structure $[$V...NP$]$\footnote{As in \textit{The student will have $[$analyzed the sentence$]_i$ in class and his teacher will have $[$done so$]_i$ too in his office}.} and a span of structure $[$V...PP$]$\footnote{As in \textit{The student will have $[$analyzed the sentence in class$]_i$ and his teacher will have $[$done so$]_i$ too}.} over the template defined by the phrase structure rule in \REF{ex:flattest}. Such a notation will quickly get out of hand and become ambiguous with more complex structures, however.

We, therefore, take our flattened out representation and add consecutive numbers over the positions classes. As in the example in \REF{engplanarstructure1}, where \textsc{vps} stands for ``verbal planar structure'' and \textsc{nps} stands for ``nominal planar structure.''

\ea \label{engplanarstructure1}
    \begin{forest}
        [{\textsc{vps}} [1 [\textsc{nps} [{The student}, roof]]  ] [2 [will]] [3 [have]] [4 [analyz] ] [5 [-ed] ] [6 [\textsc{nps} [{the sentence}, roof]] ] [7 [PP [{in class}, roof] ] ] ] 
    \end{forest}
\z 

The relevant phrase structure rules would be as follows. The first rule giving the verbal planar structure and the other rule giving the structural positions and the elements that can fit them out.

\ea \label{engplanarstructurerules}
    \textsc{vps} \rightarrow {} 1 2 3 4 5 6 7 \\
    1 \rightarrow {} \textsc{nps} \\
    2 \rightarrow {} will \\
    3 \rightarrow {} have \\
    4 \rightarrow {} analyze \\
    5 \rightarrow {} ed \\
    6 \rightarrow {} \textsc{nps} \\
    7 \rightarrow {} $[$P \textsc{nps}$]$
\z

We could now say that the \textsc{do-so test} in English identifies a 4-6 and a 4-7 span. We use a flat template in order to state the constituency tests that motivate our constituency analysis. If we report only those tests that allow us to motivate the constituency analysis we consider valid, a phrase structure grammar and the planar structure with constituency tests would be notational variants of one another. But the planar structure allows us to approach the question with more agnosticism. We can state and code the results of tests which we are unsure about (i.e. unsure if they are constituent-identifying) and we can more easily state which groupings (spans) have more or less support.  

At this point the reader might wonder whether the planar-fractal method provides nothing except an awkward notational variant of constituency analyses which allow overlapping constituency structures \citep{Sadock1980, sadock1991autolexical}. This impression would be legitimate if we stopped short of developing the method for cross-linguistic comparison.

For typological comparison there is an important difference between providing a phrase structure grammar which manifests a particular constituency analysis that implicitly codes some set of constituency tests and a planar structure which allows for explicit coding of those constituency test results. The former is mediated by abstract constituent categories such as V⁰, VP, word, phrase etc., the latter is only mediated by a notion of verb/predicate, a notion of noun/referential expression, and (perhaps) a notion of adjective/modifier. Apart from this, the planar structure coupled with reported spans is only mediated by structural positions (which is also true of phrase structure grammars in any case).

The problem with abstract constituents for typological comparison is that they can stand in for groupings that are based on an open-ended set of constituency diagnostics and linguists can differ in terms of which of these constituency tests they think ought to be captured by the phrase structure representation. This can lead to obfuscation of empirical differences and similarities in constituents or domains across languages. A VP in one case might not mean the same thing as a VP in another. We can consider the English case and compare it with Chácobo. I stated that the VP containing an object NP and a V in Chácobo could be motivated by displacement in \sectref{sec:theprosodichierarchyhypothesis}. There are no verbal proform tests that provide evidence for a verb and object constituent which excludes the subject.\footnote{The translation equivalent \textit{toka ... a...} `do so' can replace a verb without an object noun phrase.} However, in English there are a host of tests that provide evidence for the verb phrase (see the sources cited in \citealt{osborne2018tests} for example). The tests that motivate a constituent in one case are different in kind and quantity than they are in the next. At this more granular perspective, debates about whether some language ``has'' or does not ``have'' an NP or VP \citep{austin1996non, louagie2021nouna} miss the point that languages might still vary in terms of the degree to which the latter structures are supported and what types of constituency tests support them.

That it might be theoretically legitimate to treat the Chácobo VP and the English VP as the same in some sense would be beside the point. If we are interested in comparing language constituent structures to the finest degree of detail, we need to start out by dissecting abstract constituents down to the tests that are used to justify them. The planar structure is designed to help us do just that.

To further develop the English planar structure we would continue adding positions until any and all predicative sentences of the language could be ``fit out'' with planar structure positions. Thus, we would add positions, for negative marking, adverbs, verbal particles, all of the auxiliaries, fronted constituents etc. This should be kept in mind in the following structure. A complete planar structure analysis of English would require a paper of its own.

Given that the structure is built specifically to represent linear ordering among elements, a question arises as to how variably ordered elements can be represented in the structure. As with typical phrase structure grammars, we can add structural positions that allow elements to base generate in alternative positions. For instance, to represent the variable ordering of \textit{quickly} with the verb phrase in English as in \REF{engquickly}.

\ea \label{engquickly}
    \ea \textit{The student analyzed the sentence \textbf{quickly}.} \\
    \ex \textit{The student \textbf{quickly} analyzed the sentence.}
    \z
\z

We add the requisite positions for \textit{quickly} in the planar structure in order to account for its ordering in relation to the elements we already have as in \REF{engplanarstructurerules2}.

\ea \label{engplanarstructurerules2}
    \ea S/VP \rightarrow {} 1 2 3 4 5 6 7 8 9 10 11 \\
    \ex 1 \rightarrow {} NP \\
    \ex 2 \rightarrow {} quickly \\
    \ex 3 \rightarrow {} will \\
    \ex 4 \rightarrow {} quickly \\
    \ex 5 \rightarrow {} have \\
    \ex 6 \rightarrow {} quickly \\
    \ex 7 \rightarrow {} analyze \\
    \ex 8 \rightarrow {} ed \\
    \ex 9 \rightarrow {} NP \\
    \ex 10 \rightarrow {} quickly \\
    \ex 11 \rightarrow {} $[$P NP$]$
    \z
\z

Another issue arises when we consider the fact that certain modifiers of the verb can combine with the verb complex iteratively \citep{vater1978possibility, forker2014canonical}. Prepositional phrases in English display this property. 

\ea \label{engPPs}
   \textit{The student analyzed the sentence} [\textit{at his desk}]$_{PP}$ [\textit{in class}]$_{PP}$ [\textit{without thinking}]$_{PP}$ ... \\
\z

To accommodate iterably combining modifiers we introduce a distinction in positions between slots and zones \citep{tallman2018grammar, tallman_constituency_2021}.

\ea 
    \ea \textsc{Slot}: can fit out a single element at a time;
    \ex \textsc{Zone}: can fit out multiple elements which can surface in any order.
    \z
\z 

The last planar structure rule only has to be modified by making position 11 a zone (11$_{zone}$ \rightarrow {} PP), which means that the category PP can repeat itself in that position.

Planar structures do not flatten out word and phrase structure without limits. We can only flatten out the templates insofar as we do not run into self-similar embedding or recursion. A relative clause in a nominal template will be represented as a single element, rather than flattening out a whole sentential template along with the nominal elaborators. A noun phrase (or more technically a nominal planar structure) in a verbal template will typically just be represented as a single element as well. Thus, we will have planar structures for each functional domain (predicate, referential expression) or part of speech. This is why in the example in \REF{engplanarstructurerules2} NP and P are represented as elements of the verbal plane. A noun will receive its own planar structure. The prepositional phrase will be coded as a nominal planar structure plus an element that codes the relationship between the verb and the noun, i.e. a case or P in rule 11.

% To get a basic idea of how to build a planar structure it is useful to view it as `flattening out' a hierarchical phrase structure grammar or representation \citep{pullum1982free} and translating this into an array of linear positions or `lumped' template \citep{good2016linguistic}. In this template \textbf{slots} refer to positions where all elements are mutually exclusive, and \textbf{zones} refer to positions where multiple elements can occur and can be variably ordered. The flattening out of hierarchically organized phrase structure rules is depicted in \ref{rules:flatten}. Assume that X$^0$ is a word domain, X' is a subphrasal constituent and XP is a phrasal domain. The rest of the elements do not project phrasal structure. Our flattening out puts all word-internal and phrase-internal structure on the same phrase structural level.

% \ea \label{rules:flatten}
% \begin{math}
%     \left.
%     \begin{array}{l}
%       XP \rightarrow A X'  \\
%       X' \rightarrow X^0 B C \\
%       X^0 \rightarrow X^{-1} A \\
%       C \rightarrow D E \\
%       C \rightarrow E D 
%     \end{array}
%   \right\}
% \end{math}
%     \textit{XP \rightarrow A X$^0$ B DE/ED X$^{-1}$ A} 
% \z 

% The flattened out phrase structure rule can then be translated into a planar structure as in \ref{rules:planarstructure}. As stated above a slot is a position where only one element can occur at a time. A zone is a position where more than one element can occur and they can occur in any order. 

% \ea \label{rules:planarstructure}
% \begin{table}[]
% \begin{tabular}{|l|l|l|}
% \hline
%   & Position & Elements \\ \hline
% 1 & slot     & A        \\ \hline
% 2 & slot     & X$^0$      \\ \hline
% 3 & slot     & B        \\ \hline
% 4 & zone     & D, E     \\ \hline
% 5 & slot     & X$^{-1}$   \\ \hline
% 6 & slot     & A        \\ \hline
% \end{tabular}
% \end{table}
% \z 

% Note that while templates are typically mechanism for capturing the linear order between elements \citep{good2016linguistic}, there are two additions to our structure that enable it to capture variable ordering. If elements variably order with one another locally, then we put them in a zone. This is true of elements D and E. If elements variably order non-locally, we simply put the element in two positions. The element A displays this behavior with respect to the other elements in the grammar. It is placed in positions 1 and 6 so that to account for its distribution.

% The structures are flattened out `as much as possible', which means that we stop flattening them when recursion (self-similar syntactic embedding arises) prevents us from flattening out to an end point. Thus if we added to our phrase structure grammar a recursive rule such as ``B \rightarrow XP", we would not flatten this out. XP would be an element in the structure.

% \ea \label{rules:flatten}
% \begin{math}
%     \left.
%     \begin{array}{l}
%       XP \rightarrow A X'  \\
%       X' \rightarrow X^0 B C \\
%       X^0 \rightarrow X^{-1} A \\
%       C \rightarrow D E \\
%       C \rightarrow E D \\
%       B \rightarrow XP
%     \end{array}
%   \right\}
% \end{math}
%     \textit{XP \rightarrow A X$^0$ XP DE/ED X$^{-1}$ A} 
% \z 

% To further illustrate the relationship between planar structures and typical constituency analyses I will give a few examples from English. Let's consider first the sentence \textit{I should have been rewriting the paper}. A constituency analysis is provided below (based partly on analyses in \cite{huddleston2002cambridge}).

% \ea \label{tree:english1}
% \begin{forest}
%       [S [NP [{I},roof]] [VP [Modal\\should ] [VP [Perf [Perf\\ha ] [Infl\\ve ] ] [VP [Prog [Prog\\be ] [Infl\\en ] ] [VP [V [V [prefix\\re- ] [root\\write ] ] [Infl\\-ing ] ] [NP [{the paper}, roof] ] ] ] ] ] ] 
% \end{forest}  
% \z 

% In a planar analysis we start by flattening out the whole structure. We do not flatten out the \textsc{nps}. \textsc{nps} will (eventually) be given their own planar structure. We know that in English the elements cannot be locally variably ordered. Thus we can give them their own positions (slots). 

% \ea \label{tree:english3}
% \begin{forest}
%       [{Verbal planar structure} [1_{slot} [NP [{I},roof]]]  [2_{slot} [Modal\\should] ] [3_{slot} [Perf\\ha ]] [4_{slot} [Infl\\ve ]]  [5_{slot} [Prog\\be ]] [6_{slot} [Infl\\en ]] [7_{slot} [re ] ] [8_{slot} [root\\write ]] [9_{slot} [Infl\\ing ]] [10_{slot} [NP [{the paper}, roof] ] ] ]  
% \end{forest}  
% \z 

% As we add more constructions and account for more sentences we add more positions. For instance, notice that negative marking and adverbs can occur in between the auxiliaries. This means that positions would have to be added between each of the auxiliaries.  Furthermore, more positions will have to be added to account for ditransitive constructions, phrasal verbs and  auxiliary inversion, pre- and post-sentential adverbs etc. The process is not any different from developing a template for any given descriptive grammar. The difference is that we avoid imposing constituency structure (words, phrases, subphrases). 
% An important point to emphasize is that we do not add positions that would reflect recursive or reiterated structures such as coordination or subordination. There are two reasons for this. First, it is impossible. The planar structure would go have an infinite number of positions. Secondly, recursive or iterating clausal or subclausal structures (coordination, subordination, serial verbs, compounding etc.) are going to be coded as constituency tests. These structures are referred to as `subspan repetition' in \cite{tallman2021constituency} and throughout the chapters of this volume.

% What the planar structure allows us to do is state constituency test results, morphosyntactic domains, or phonological domains without committing to calling these `wordhood tests' or even committing to the idea that the given domain is constituent-identifying at all. For instance, we can claim based on the preliminary analysis of English above that the 7-9 span is not interruptable by a free form and that the 7-10 is replaceable by \textit{do so}.

\subsection{A formal sketch of planar structure grammars}
\label{sec:formal}

A planar structure grammar is a coding device outfitted with the following elements:

\ea 
    \ea Planar structures (V, N, Adj, Adv ...); \\
    \ex Non-terminal elements / \textsc{positions}; \\ 
    \ex Terminal elements that occur inside positions; \\
    \ex Planar structure rules/templates; \\
    \ex Two types of rules for positions (\textsc{slots} versus \textsc{zones}) 
    \z 
\z 

Each terminal planar structure has a fixed number of non-terminal elements we call positions (see \cite{partee1990mathematical} for discussion of terminal versus nonterminal elements). Apart the initial symbol introducing the planar structure and positions of the planar structures, nonterminal elements are not allowed. All other elements associated with planar structures are terminal nodes. We call these terminal elements just ``elements" for short.

The positions are of two types: slots and zones defined below. The slash $/$ represents `or'. The curly brackets are used for an unordered set of elements which do not have a precedence relationship with each other.

\ea \label{slotsandzones}
        \ea P$_{slot}$ \rightarrow {} a$/$b$/$c .... \\  
        \ex P$_{zone}$ \rightarrow {} \{a, b, c ...\}
    \z 
\z 

Only one element can fit out a slot. The rule above for slots outputs the following.

\ea \label{slotoutput}
    \ea a \\
    \ex b \\
    \ex c \\
    \ex $\varnothing$ \\
\z
\z  

Inside a zone multiple elements can occur and these can occur in any order. Thus the rule P$_{zone}$ \rightarrow {} \{a, b, c ...\}, produces the following possibilities.\footnote{Note that the sequential lettering in the example above (a,b,c) has no formal significance. The lettering was inserted at the request of the series' editors.}

\ea \label{zoneoutput}
    \ea a b c \\
    \ex a c b  \\
    \ex b a c \\
    \ex b c a \\ 
    \ex c a b \\
    \ex c b a \\
    \ex a b \\
    \ex b a \\ 
    \ex a c \\ 
    \ex c a \\
    \ex b c \\
    \ex c b \\
    \ex a \\
    \ex b \\
    \ex c \\
    \ex $\varnothing$ \\
    \z
\z 
    
If a planar structure is embedded in a zone it is understood that this planar structure can iterate (like the prepositional phrase in the example above). Thus if we have a rule as in the following:

\ea \label{embedding1}
        P$_{zone}$ \rightarrow {} $\Pi$ \\
\z 

where $\Pi$ is  or contains a planar structure. The output is as follows:

\ea \label{embedding2}
        \ea $\Pi_1$ \\
        \ex $\Pi_1$ $\Pi_2$ \\
        \ex $\Pi_1$ $\Pi_2$ $\Pi_3$ \\
        \ex ...
        \z 
\z 

As stated above, planar structure rules consist only of non-terminal nodes called positions with precedence relations between them.

\ea \label{}
    \ea \textsc{vps} \rightarrow{} 1 2 3 4 5 6 .... \\
    \ex \textsc{nps} \rightarrow{} 1 2 3 4 5  .... \\
    \ex ... \\
    \z 
\z

Languages can vary in terms of the number of positions each planar structure has. Some languages might have a verbal planar structure with only around 20 positions (e.g. Araona) \parencitetv{chapters/13-Araona}, while others can have around 40 (e.g. Chorote) \parencitetv{chapters/15-Chorote}. Languages can further vary in terms of how many and which positions are slots or zones.

A language with more fixed orderings will typically be represented with more slots overall. A language without any fixed ordering at all would have a single zone. So-called ``free word-order'' languages are not represented with only zones, however. The reason is that they typically display some degree of fixed ordering inside their verbal or nominal ``words'', which are represented on the same plane.

\subsection{Tangling of planar structures}
\label{sec:tangling}
\largerpage[-1]
Planar structures can be ``tangled'' with one another. This aspect of planar structures has not been systematically discussed across the studies, because most studies have focused only on verbal planar structures. Nevertheless, it is an important aspect of some planar structures that needs to be described to adequately compare these with phrase structure grammars. Furthermore, if the study of constituency using planar structures advances beyond comparing verbal structures, tangling will need to be dealt with more systematically in future studies.

Normal phrase structure grammars allow different types of non-terminal elements. However, in a planar structure grammar, the only types of non-terminal nodes are \textsc{positions} and the initial symbols of the planar structures themselves. In this sense, planar structure grammars are more rigid than normal phrase structure grammars. Once again: this rigid flatness of planar structure grammar is imposed to for cross-linguistic commensurabilty so that planar structures can be constructed as constituency test coding and measurement devices, not because a linguist who uses a planar-fractal method believes that all linguistic structures are flat.

More is needed to describe structural relations in a sentence apart from the formal properties described above. The reason for this is the well-known fact that verbal and nominal categories and modifiers can intermingle syntagmatically. When developing a planar structure we allow ``tangling'' between nodes if necessary in order to capture such cases \citep[442]{partee1990mathematical}.\footnote{\citet[442]{partee1990mathematical} define the ``Nontangling Condition'' for a typical constituent structure grammar as follows: ``In any well-formed constituent structure tree, for any nodes \textit{x} and \textit{y}, if \textit{x} precedes \textit{y}, then all nodes dominated by \textit{x} precede all nodes dominated by \textit{y}." Trees for planar structure grammars can violate the non-tangling condition, whenever positions of distinct planar structures are intermingled.} An example from English comes from the quantifier \textit{all}, which displays a well-known property of ``stranding.''

\ea 
    \ea \textit{All the students will analyze the sentences.} \\
    \ex \textit{The students will all analyze the sentences.}
    \z 
\z 

The problem with such sentences is that there is a nominal modifier interspersed with a verbal modifiers, yet nominal and verbal modifiers should be on distinct planar structures according to the planar structure formalism. 

To accommodate cases of part-of-speech modifier intermingling, we add a position in the verbal planar structure for the quantifier \textit{all}. We only allow such intermingling if it is necessary, otherwise elements should be placed uniquely in their own planar structure. Preliminary verbal and nominal planar structures are provided in \REF{engverbalplanarstructure} and \REF{engnominalplanarstructure}. Once again, these are only partial planar structure grammars of English developed for expository purposes.

\ea \label{engverbalplanarstructure}
    \ea \textsc{vps} \rightarrow {} 1 2 3 4 5 6 7 8 9 10 11 12 \\
    \ex 1$_{slot}$ \rightarrow {} \textsc{nps} \\
    \ex 2$_{slot}$ \rightarrow {} quickly \\
    \ex 3$_{slot}$ \rightarrow {} will \\
    \ex 4$_{slot}$ \rightarrow {} quickly \\
    \ex 5$_{slot}$ \rightarrow {} have \\
    \ex 6$_{slot}$ \rightarrow {} quickly \\
    \ex 7$_{slot}$ \rightarrow{} all \\
    \ex 8$_{slot}$ \rightarrow {} \textsc{V-root} \\
    \ex 9$_{slot}$ \rightarrow {} ed \\
    \ex 10$_{slot}$ \rightarrow {} \textsc{nps} \\
    \ex 11$_{slot}$ \rightarrow {} quickly \\
    \ex 12$_{zone}$ \rightarrow {} $[$P nps$]$
    \z 
\z

Note that the element \textit{all} would be represented in the nominal planar structure as follows:

\ea \label{engnominalplanarstructure}
    \ea \textsc{nps} \rightarrow{} 1 2 3 4 5 6 7 8 9 10 \\
    \ex 1$_{slot}$ \rightarrow{} quantifier \\
    \ex 2$_{slot}$ \rightarrow{} of \\
    \ex 3$_{slot}$ \rightarrow{} the, a, all, \ex \textsc{nps}'s \\
    \ex 4$_{slot}$ \rightarrow{} one, two, three ... \\
    \ex 5$_{zone}$ \rightarrow{} \textsc{aps} \\
    \ex 6$_{zone}$ \rightarrow{} \textsc{n-root} \\
    \ex 7$_{zone}$ \rightarrow{} $[$ who/which... \ex \textsc{vps} $]$ \\
    \ex 8$_{slot}$ \rightarrow{} vsp$[$2--6$]$ \\
    \ex 9$_{slot}$ \rightarrow{} all
    \z
\z 

\ea \label{tangling}
     \begin{forest}where n children=0{tier=word}{}
    [\textsc{vps} 
    [1 [\textsc{nps} [3 [the]] [6 [students]] [8,name=N1 [{},no edge]] [9,name=N2 [{},no edge]] ] ] 
    [3 [will,name=V1]] 
    [7 [all,name=V2]] 
    [8 [analyze]] 
    [10 [\textsc{nps} [3 [the]] [6 [sentences]] ] 
    ]]
    \draw (N1.east) -- (V1.north);
    \draw (N2.east) -- (V2.north);
    \end{forest}
\z 

In a sense admitting tangled planar structures violates the constraint I placed earlier on flattening out planar structure, since in the representation above, \textit{all} is a modifier of the noun but also in the verbal planar structure. If we are allowed to tangle planar structures in this fashion, why not completely collapse them? The reason is because this would make planar structures infinitely long and thus impractical for database construction. In order to accommodate intermingled structures while also allowing planar structures to have some practical use, we adopt the following protocol in the development of planar structures.

\ea 
    \textsc{Tangle-only-if-necessary protocol}: Do not tangle planar structures unless it is necessary to account for the relative ordering of elements. Then, introduce the least amount of positions possible in order to capture the relevant precedence relations.
\z 

The protocol is followed by all descriptions in this volume. The restriction is imposed to guarantee commensurability across descriptions and to capture the relative ordering of elements, while enforcing finiteness on planar structures.\footnote{It is not yet clear though that all tangled elements have been appropriately represented in the nominal planar structures that are presented in this volume. Such \textsc{nps}s will perhaps require revision at a later stage.}

\subsection{Base elements and positions in planar structures}
\label{sec:baseelements}

Another restriction on planar structures relates to their base elements. Base elements can be regarded as the phrase structure equivalents of ``heads.'' But actually defining a base element as a comparative concept turns out to not be entire trivial. I will introduce these restrictions and then explain why they are adopted. The first restriction is stated below.

\ea 
    \textsc{Base position restriction}: All planar structures have a base element. The base element is the semantic head of the planar structure \citep{croft_radical_2001, croft2022cambridge}. The part of speech of the base element defines the type of planar structure. 
\z 

For instance, a verbal planar structure must contain a verb root, and a nominal planar structure must contain a noun root. Another restriction is imposed on how base elements are fit out in a given planar structure. Of course an immediate problem arises as to whether it is really obvious which element is the semantic head in any given case. I discuss this issue below. 

Before delving into this issue a second restriction has to be imposed on the distribution of base elements within planar structures.

\ea 
    \textsc{Only-one-base-position restriction}: There can be no more than one position for a base element or formative that is part of a base element per planar structure.
\z 

First, note that this restriction \textit{does not} mean that a base element cannot occupy more than one position at the same time. A base element can display multiple exponence allowing formatives split across more than one position of the planar structure if necessary. What it means is that we do not allow the same base element formative to be generated in different positions of a planar structure. Such a condition seems to be implicit in the construction of morphological templates, but in syntax it is common to think of a verb ``moving'' or ``dislocating'' to different positions of the clause, so the restriction requires more commentary. A similar interpretative warning is in order: we are not imposing this condition because we think ``verb root/stems never move'' or ``verb roots/stems never base generate in more than one position.'' Rather it is a restriction imposed to adequately code the results of constituency tests in a practical fashion.\footnote{Furthermore, it is perfectly possible that a methodology could exist where the \textsc{Only-one-base-position restriction} is rejected. It is adopted here because when it was not imposed the reporting of constituency tests became unwieldy as one would have to fracture tests according to the position of the base element. Relaxing this condition also very naturally results in competing planar structure analyses for the same language.}

I will illustrate what this means in practice with an example from Chácobo. In Chácobo a subject NP and the verb stem (verb plus affixes) can variably order. That is S-V and V-S orders are both permissible. \citet{tallman2018grammar} describes cases where the V occurs before the NP S/A argument as ``verb-fronting.'' An example of verb fronting is provided in \REF{ex:chacobowackernagel}. The first example displays S-V order and the second displays V-S order, where the verb and an associated motion clitic ``move'' to the front of the sentence.

\ea \label{ex:chacobowackernagel}
    \ea  \label{ex:chacobowackernagel1}
    \gll βakɨ́ tsi oʂa =kana =kɨ \\
        child \Lnk{} sleep =going.\Itr{} \Lnk{} =\Decl{}:\Pst{} \\
        `\glt `The child slept while going (e.g. in a truck).'
    \ex \label{ex:chacobowackernagel2}
    \gll oʂa =kana tsi βakɨ́ =kɨ \\
        sleep =going.\Itr{} \Lnk{} child =\Decl{}:\Pst{}   \\
        \glt  `The child slept while going (e.g. in a truck).'
    \z 
\z 

Using the planar fractal notation, two competing grammars emerge for the distributional facts above (at least). The first allows the verb to be generated in different positions in the planar structure depicted in \REF{rules:movingverb} where \textsc{v-base} represents the verb base and \textsc{nps} represents a nominal planar structure.

\ea \label{rules:movingverb}
    \ea \textsc{vps} \rightarrow{} 1 2 3 4 5 6 7 8 9
    \ex 1  \rightarrow{} \textsc{v-base} \\
    \ex 2 \rightarrow{} \textit{=kana} \\
    \ex 4 \rightarrow{} \textit{tsi} \\
    \ex 5 \rightarrow{} \textsc{nps} \\
    \ex 6 \rightarrow{} \textit{tsi} \\
    \ex 7 \rightarrow{} \textsc{v-base} \\ 
    \ex 8 \rightarrow{} \textit{=kana} \\
    \ex 9 \rightarrow{} \textit{=kɨ}
    \z 
\z 

This planar structure requires some extra restrictions to get the distributional facts right.\footnote{Certain positions would be open or closed depending on which position the verbal base fit out. Position 6 would be open if position 7 was filled by \textsc{v-base} and otherwise closed.. Position 4 would be open if position 1 was filled by \textsc{v-base} and otherwise closed.. Position 8 would be open if position 7 was filled by \textsc{v-base} and otherwise closed. Position 2 would be open if position 1 is filled with \textsc{v-base} and otherwise closed.}

Another grammar might let the \textsc{nps} move around in different positions and force the verb core to stay in place as in \REF{rules:movingnoun}.

\ea \label{rules:movingnoun}
    \ea \textsc{vps} \rightarrow{} 1 2 3 4 5 6 7 
    \ex 1  \rightarrow{} \textsc{nps} \\
    \ex 2 \rightarrow{} \textit{tsi} \\
    \ex 3 \rightarrow{} \textsc{v-base} \\
    \ex 4 \rightarrow{} \textit{=kana} \\
    \ex 5  \rightarrow{} \textit{tsi} \\
    \ex 6 \rightarrow{} \textsc{nps} \\
    \ex 7 \rightarrow{} \textit{kɨ}
    \z 
\z 

In the context of this project we would always choose the second grammar. The reason is that when we construct a verbal planar structure we do it with the goal of reporting constituency test results that include the verb. This restriction sometimes results in proliferation of positions around the verb in a way that many linguists might consider counter-intuitive. For instance, in South Bolivian Quechua there are a relatively large number of clitics which occur in a fixed order with respect to one another \citetv{chapters/14-Quechua}. Since they modify the predicate they are all in the verbal planar structure but they can occur before or after the verb with the same restrictions of linear order with respect to each other. As a consequence of \textsc{Only-one-base-position restriction} we have dedicated positions for the clitics before and after verb which recode their the linear constraints these elements have with one another.

There are two reasons for imposing the only-one-base-position restriction. The most important reason is practical and involves limiting the scope of constituency test application to make is manageable and also  more in line with how constituency tests are actually used. 

For each constituency test we assume that it must overlap with the base element of a planar structure. This reduces the number of constituency tests that have to be reported, but also makes the planar structure a more coherent tool for research. Defining constituency tests such that they must overlap with a specific position makes them easier to define and apply consistently. 

Allowing a base element to potentially occupy more than one position complicates constituency test reporting. We would have to report different constituency test for every position we allow the verb to occupy as the spans of structure would change accordingly.

The second reason this restriction is imposed is because it restricts the number of possible planar structures that are compatible with the data. This increases comparability between the descriptions, because it reduces the number of competing planar structure analyses that a researcher could construction. The ideal is actually to have the construction of the planar structure to be completely unambiguous insofar as the relevant facts are known (see \sectref{sec:competing} for discussion). This is achieved through imposing protocols and constraints on the construction of planar structures.

I now return to the notion of a semantic head which the original definition makes reference to. Simplifying Croft’s discussion somewhat, a semantic head combines the notions of \textsc{profile equivalent} with the highest paradigmatic contrast. In a combination X+Y the profile equivalent is X if X+Y is a type of X \citep[257]{croft_radical_2001}. In a combination X+Y, X is the element with the highest paradigmatic contrast if it is in paradigmatic contrast with more elements than Y \citep[270]{croft_radical_2001}. In the context of the planar structure, I assume that elements that can occur in the same position are in paradigmatic contrast with each other in that position. Croft conjectures that while both profile equivalence and relative paradigmatic contrast tend to align in defining headedness at the syntactic level, in morphology, these criteria tend to misalign such that the root displays the highest paradigmatic contrast while the affix is the profile equivalent.

As the planar-fracture method starts from the premise that we should homogenize morphological/word and syntactic/phrase structure representations as much as possible in order to investigate the actual empirical motivation for the division, Croft’s notion of \textsc{relative paradigmatic contrast} would appear to be more appropriate in defining the semantic head since it generalizes across syntax and morphology.

The main problem with systematically associating our verb base with
a profile equivalent is because it is frequently the case in many languages that there is more than one element that can be considered the profile equivalent. This would seem to be especially true of languages that are traditionally labelled as polysynthetic as they contain many ``lexically heavy'' elements that are neither roots in an obvious sense nor do they necessarily project their own planar structure.

To take one example, if we consider, for instance, \textit{do-bea-tsoa} $[$carry-come-go.up$]$ ’bring something up a hill’ from Araona it is not clear which of the morphemes (all classified as `roots’ by \cite{pitman:1980:araonasketch}) is the profile equivalent of the whole (the action is a type of carrying, a type of coming and a type of upwards motion). Nor is this issue particularly uncommon \parencitetv{chapters/02-Cupik}.

The paradox dissolves if we move away from identifying the verb base based on the properties of elements and define the notion based on the more abstract notion of \textsc{position}. If we associate relative paradigmatic complexity with positions, then we ask whether, when aggregating over the elements that can occur in each position, we find one position which simultaneously can function as a profile equivalent and displays a high degree of paradigmatic complexity. The verb base position is the position whose elements in the aggregate display the highest degree of paradigmatic complexity compared to other positions. The issue clearly requires more discussion, but based on the data I have observed thus far, it appears that conceptualizing the base in terms of a single position in the planar structure seems to resolve the issue of semantic head ambiguity. Another possibility would be, of course, to drop the condition that there can only be a single base, or that a base is necessary at all to define the planar structure. We have not adopted this strategy in this volume for practical reasons, but it does not mean that it is not an avenue that ought to be explored. 

Developing a coding device with different formal properties and constraints might highlight different aspects of constituency structure and allow different generalizations to come to light. The main point for typological comparison though is that whatever measurement instrument is developed and used that it be applied as consistently as possible across languages.

\subsection{Minimal morphs}
\label{sec:minimalmorphs}

I stated above that the planar structure breaks down elements into positions and those positions can be composed of morphs. However, the identification of morphs is known to lead ambiguities. In a recent review of the notion of ``morph'' in morphosyntactic analysis, \citet[124]{haspelmath2020morph} states ``whether a form is minimal or can be further divided into smaller forms with their own content is not always clear." (see \citealt{blevins2016word} for important discussion).

In the planar-fractal approach, we always divide forms into their smallest parts (``minimal morphs"). This means that many of the morphs will not necessarily have semantic content, rather they could just be ``recurrent partials'' in the sense of \citet[314]{crysmann2016variable}. The condition is stated below:

\ea 
    \textsc{Minimal-morph condition}: Analyze elements into morphs. Where ambiguity arises in terms of the number of morphs into which a form can be broken down, always chose the smallest element (or the analytic result that gives the most morphs).
\z 

There are two reasons for this condition. One is to impose consistency across the descriptions. The other relates to what the planar structure is for. It is a device for measuring (mis)alignments between constituency test results. Conflation of elements could result in conflation of positions, which could result in spurious convergences between constituency tests (i.e. a loss of precision and a loss of potentially important information). In contrast, it is hard to see how any sort of spurious misalignment between tests could arise because of overly splitting morphs. If it is truly correct that some purported combination of two or more morphs should really be regarded as one, there should be no reason to expect that a constituency test would break it into pieces. 

\largerpage
\subsection{Competing planar structures}
\label{sec:competing}

One of the reasons for not using constituency structure or phrase structure analyses to compare languages is that, for a given language, even for the same set of facts considered, there are competing constituency structure analyses. This point should be obvious enough to anyone who has read debates in the syntax literature (\citealt{croft_radical_2001, culicover2005simpler} among others). Constituency tests do not apparently point to one and only one analysis. Self-described descriptive linguists might imagine they are sheltered from this problem when they claim to be following Basic Linguistic Theory, but this is an illusion, for there can be competing analyses of what constitutes the grammatical and phonological word in this approach at the very least.

One criticism (or worry) that has arisen in the presentation of the methodology is the possibility that, even given the principles specified above, it might be possible that competing planar structure analyses are possible for a given language. That is, just as there are competing phrase structure analyses, there could be competing planar structure analyses. 

This criticism has some validity in principle. But there is an important difference between our critique of Basic Linguistic Theory, the Prosodic Hierarchy Hypothesis and traditional constituency analysis as tools for comparison and the latter criticism of the planar-fractal method. In the latter cases, the ways in which ambiguities arise are easy to state (e.g. different ``wordhood tests'' identify different domains of structure; different phonological domains could be mapped to different levels in the prosodic hierarchy; different constituency tests could be used or discarded in the development of a constituency analysis) and there are known empirical facts lead to such ambiguities. For the planar-fractal method, the criticism amounts to a speculation that if different researchers looking at the same set of facts from a given language \textit{somehow} develop distinct planar structures these same researchers might \textit{somehow} arrive at different results for the relative convergence and non-convergence of constituency tests.

But this criticism (or perhaps worry) could be applied to \textit{all} comparative concepts. Anytime a comparative concept is proposed we might upon closer empirical scrutiny find that the concept is more ambiguous than intended.\footnote{A sure-fire way of never having a comparative concept scrutinized is for it to never actually be used in any typological study.} In fact one of the goals of empirical research is to make sure that the comparative concept allows for consistent comparison. The solution to finding that our comparative concept is more ambiguous than intended is either to impose further restrictions on the concept or to split the concept into more variables. In the context of planar structures this would entail further tightening the protocol for building them or reporting competing analyses according to different principles. But if we simply start off with the premise that we need to develop a methodology that ensures no ambiguity could ever arise before engaging in any empirical studies, we will never engage in any empirical studies. 

At a minimum someone who has such a worry about planar structures should explain how the relevant ambiguity might arise and actually provide a case study demonstrating that it exists, in fact, and matters for the comparison of constit\-u\-en\-cy tests and domains. 

% \subsection{Planar structure addenda}

% \textit{Element non-co-occurrence constraint}

% \textit{Element co-occurrence constraint}

% \textit{Element blocking}

% \textit{Position closing}


\section{Fracturing constituency tests}
\label{sec:fracturing}

The constituency tests that one finds in the literature are ambiguous. For a given ``constituency test'' or ``wordhood test'' you will generally find (although not always) more than one interpretation when they are specified more precisely.

An obvious example of ambiguity in a constituency test comes from non-interruption or contiguity. The elements of words or constituents are non-inter\-rup\-table or contiguous. The problem with this claim is that it is contingent on identifying an appropriate \textsc{interrupting element}. Take a word like \textit{post-depen\-dence} in English. This prefix \textit{post-} can be interrupted from \textit{dependence} by the morph \textit{in-} as in \textit{post-independence}. We do not regard this as evidence that \textit{post} does not form a word with \textit{dependence} in the first example because of the status of \textit{in-} as a prefix. To make the criterion more precise we might say that this is because \textit{in-} is bound (cannot be a free form) and is highly selective of its particular base: \textit{in-} cannot be a full utterance by itself and selects noun roots. A combination of elements that can be interrupted by a non-selective free form would be regarded as more than one word. Importantly, the criterion cannot be used unless we have stated something about the interrupting element.

When researchers assume the existence of endoclitics, the criterion for non-interruptability is implicitly relaxed. For instance, in European Portuguese the form \textit{mostrar-emos} `we will show' can be interrupted by a bound pronoun \textit{-lho} as in \textit{mostrar-lho-emos} `we will show it to him' \citep{luis2004paradigm}. The question arises as to why such constructions are not simply seen as a violation non-interruption: why are \textit{mostrar} and \textit{-hemos} not distinct words? Here the interrupting element is bound and one could claim that on these grounds it does not constitute a genuine instance of interruption (\citealt{bauer2017compounds} for the contrary position). In certain types of incorporating or compounding structures the criterion of non-interruption is further weakened if not dropped altogether.

We can go even further though. In Chácobo, what the domain of non-inter\-rup\-tion is, will depend on whether our interrupting element is a free form or a combination of free forms (e.g. a noun phrase). If we use a combination of free forms (e.g. \textit{honi} `man' and \textit{siri} `old' in a noun phrase) as the interrupting element, then the causative is part of the verbal word. If we say the interrupting element ought to be fixed as a single free form, then the causative is not part of the verbal word. This is illustrated in \REF{ref:chacobointerruption} \citep{tallman2021constituency}.

\ea \label{ref:chacobointerruption}
    \gll tsaya =yáma =má honi siri=́  =wa =kɨ \\
    see =\Neg{} =\Caus{} man old=\Erg{} =\Tr{} =\Decl{}:\Pst{} \\
    \glt `The old man did not show it to him.'
\z 

Thus, the constituent identified by non-interruption will depend on what we choose as an interrupting element.

One way of dealing with this issue is to choose a ``correct" non-interruption test by fiat, as suggested in \citet{haspelmathword:2011, haspelmath2022defining}. The problem with this solution is that the result is bound to be arbitrary. Such a solution also pointlessly limits the amount of variation we are can cover in our typological study of constituency. We do not know which one of these versions of the test will be the most revealing a priori -- why should we engage in a research program that pretends that we do?\footnote{\citet{haspelmath2010comparative} notes that comparative concepts should be ``useful'' -- they are not true or false. However, in the case of his word ``retro--definition'', which amounts to a domain that cannot be interrupted by any free form, he does not show how it might be useful for any conceivable typological study. In order for Haspelmath's recent intervention of the question of wordhood to be of value for empirical studies, he needs to show why christening one the many domains coded in our study as \textit{the} ``word'', as opposed to any of the other domains, is revealing. The perspective taken in this volume is different. We assume that languages might be organized in such a way that a ``word'' might be definable based on a different set of diagnostics from case to case. The organization of constituency tests might show some sort of dichotomous patterning regardless of whether there is a single defining criterion across all languages. Note that this perspective is ostensibly empirical since it is not a foregone conclusion that we should find such a pattern. On the other hand, no empirical questions arise from Haspelmath's retro-definition.} Rather we \textsc{fracture} the test into its different interpretations and apply all of these, coding the relevant details in the database. We define domains for interruption by a free form, by a combination of free forms, or by some promiscuous element insofar as the fractures give distinct results.

% In the context of the study of this volume, Haspelmath's retro-definition is useless for two reasons. First, it is already covered by a fracture of the non-interruption test. Secondly, the retro-definition offers no methodological advance that will help us investigate questions concerning constituency and the morphology-syntax distinction, and only implies a gratuitous simplification of the issues at hand. It ignores questions related to the correlations between different types of domains cross-linguistically. It assumes that the distinction between morphology and syntax ought to be defined in exactly the same way from language to language ignoring other types of converges or patterns present in the language.

Similar considerations about ambiguity apply to phonological domains as well. The most obvious problem with identifying the span of application of a phonological process arises because of \textsc{vacuous application} of a phonological rule. Vacuous application occurs when the phonological conditions for a specific phonological rule are never met in a certain environment. If the relevant conditions are never met, one cannot tell whether the relevant phonological process and domain spans over such structural positions and their junctures or not. The solution, as with morphosyntactic domains, is to fracture. I will illustrate the issue with glottal stop insertion from Chácobo below.

In Chácobo there is one environment where glottal stop insertion is obligatory: this is between two vowels at the boundary between a prefix and a root. The process does not occur if the root begins with a consonant, however. The glottal stop insertion is shown at the prefix-root boundary in \REF{ex:chacobobodypartprefix1}. The non-application of the rule is found in \REF{ex:chacobobodypartprefix2}.


\ea \label{ex:chacobobodypartprefix1}
    $[$βáʔàtʃɨ́kɨ$]$ \\
    \gll βǎ- atʃ -ɨ̌ =kɨ \\
    arm- grab -\Itr{}{} =\Decl{}:\Pst{} \\
    \glt `S/he grabbed her/his own arm.'
\z 

\ea \label{ex:chacobobodypartprefix2}
    $[$βánɨ̀ʂɨ́kɨ$]$ \\
    \gll βǎ- nɨʂ -ɨ̌   =kɨ \\
    arm- tie -\Itr{} =\Decl{}:\Pst{} \\
    \glt `S/he tied his/her arm.'
\z 

We have evidence for the existence of the process of glottal stop insertion at the boundary between prefix and root. However, at the juncture between the root and suffixes or enclitics in Chácobo no evidence for or against the application of the glottal stop insertion rule ever arises. The reason is that vowel initial transitivity markers such as \textit{-ɨ} only ever combine with consonant final roots. Otherwise all suffixes and enclitics in Chácobo are consonant initial.

How are we to characterize the domain of application of glottal stop insertion? Does the glottal stop insertion domain span over suffixes or not? In principle there appear to be two options. One of these is to assume only positive evidence counts. This would define the prefix-root constituent as the domain for glottal stop insertion. The other is to assume that the rule applies vacuously in all cases where there is no evidence against the application of the rule, i.e. where there are adjacent vowels spanning morph boundaries, but where no glottal stop insertion applies. I refer to the smaller (positive evidence only domain) as the \textsc{minimal domain}. And the larger (negative evidence only domain) as the \textsc{maximal domain}.

The problem with leaving the issue open to interpretation is that it allows researchers to identify spurious convergences between domains. Since the maximal domain is substantially larger than the minimal domain in Chácobo, one could claim that it converges with any other domain of intermediate size between the minimal and maximal domains of glottal stop insertion. To be somewhat more formal, imagine the minimal domain spans 3-4 and the maximal domain 1-6 for glottal stop insertion. If we have a stress domain that spans 2-5, we can claim that the glottal stop and stress domains line up with one another if we leave the space between minimal and maximal domains open to interpretation rather than being more specific (see \cite{tallman2021constituency} for the actual details in Chácobo). Not providing a formalization of the degrees of freedom in domain interpretation will naturally result in theories of phonological parsing being confirmationally lax: if there is ambiguity chose the interpretation that makes your theory work.

Test fractures can be divided into different types. The first type, which reoccurs throughout the database, is the \textsc{minimal--maximal} fracture. I assume that a minimal--maximal fracture arises any time the minimal domain is by definition a subspan of the maximal. An example of this is provided with the glottal stop insertion above. This type of fracture reoccurs throughout the database and throughout the studies in the volume for a number of constituency domains.

Another type of fracture is a distinction between \textsc{strict} and \textsc{lax} interpretations of a criterion. The most obvious instance where this is relevant is in the context of tests of selection. The reason is that selection is a matter of degree. An element with high selectivity, might only combine with verbs. One with lower selectivity might only combine with nouns. An element might display an intermediate status in that it can appear in non-verbal predicates, but not strictly combine with nouns, however. For instance, the assertive morpheme \textit{rá} in Chácobo requires there to be a verbal predicate. The reportative only requires there to be a predicate, verbal or non-verbal. We can, thereby, define domains based on laxer and stricter definitions of selection.\footnote{Javier
    \textcitetv{chapters/15-Chorote} in particular is to be credited with highlighting this point, which was not initially obvious to me \citep{tallman2021constituency}}.

There are also fractures which relate to specific constructions of a language. The most obvious cases relate to recursion based diagnostics, or \textsc{subspan repetition}. These have to be fractured according to what appear to be very language specific subtypes (e.g. same vs. different subject clauses in Pano languages, ``word-internal" complementation structures in Inuit–Yupik–Unangan languages; compounding and/or serial verb constructions in Zapotec languages). Each of these constructions can be constituent identifying in different ways, but often they are distinguished according to highly specific structural criteria. This does not mean that the different instances of subspan repetition cannot be taxonomized into different subgroups eventually \citep{bickel2015distributional}. Future research might reveal that different construction types can be further broken down into codable properties for typological investigation \citep{bickel:capturing}.\footnote{A comment at this point is necessary to avoid confusion. It has been suggested to me that somehow fracturing involves abandoning ``comparative concepts.'' I do not think this is correct. Fracturing in the context of this research project simply means that each collaborator is responsible for developing and applying comparative concepts in the process of database development. Attention to concrete details not subsumed under a comparative concept does not entail abandonment of comparative concepts. For instance, we can code the domain which is not interruptable by a single free form in Chácobo and Hup, but note that the relevant interrupting elements are morphemes with different semantics.}

A final way that tests can be fractured is \textsc{by analysis}. This situation arises when interpretation of a test is contingent on whether some set of formatives is interpreted as being allomorphs of a single morpheme or diachronically related but distinct morphemes. The structure of syntagmatically defined distributional classes is contingent on such analytic decisions and tests that refer to linearization can, thereby, be affected as well. A clear example comes from the causative \textit{-chi} in South Bolivian Quechua. \citet{camachorios2022verbal} splits occurrences of the morph into cases where the suffix is ``lexicalized'' with a verb base and cases where it is not. \citet{muysken:1981}, among others, does  not adopt such an analysis, and, in fact, argues against it. These analytic differences matter for the interpretation of constituency tests since they change facts about the relative (non)permutability of elements in the Quechua verb complex. Fracturing according to analysis here implies reporting different tests depending on which of the analyses of the \textit{-chi} morphs is adopted. Fracturing by analysis provides us with important information about analytic ambiguity in the assessment of constituency tests.

% \section{Criticisms of the method}

% \subsection{Fracturing creates noncommensurability}

% -Allowing each author to fracture according to their language results in noncommeasurable descriptions

% - This is just wrong. Adding extra details to a variable, does not mean you cannot compare on a more abstract level

% \subsection{Competing planar structures}

% - Two or more authors could come up with competing planar structures for the same language. Or one author could come up with competing planar structures

% - Similar problems in typology in general - multiple phonemic analyses. Does this invalidate phonological typology?

% - Three strategies

% - Multiple analysts: What would this show?

% - Coding multiple planar structures? Why not?

% - Making the protocol for planar structure development more precise

% \subsection{Inconsistent fracturing}

% -Some domains might be more fractured than others

% -Doesn't lack of fracturing consistent domains underrepresent convergences?

% -some descriptions are works in progress, you might get inconsistent fracturing because there is just more known about one language rather than another

\section{Domains: Morphosyntactic, phonological and indeterminate}
\largerpage
\label{sec:domainsintroduction}

It is outside of the scope of this introduction to provide a full review of all the constituency tests and issues in their application. In this section I list the main test/domain types that we attempted to code across all the languages of this study. These can be classified into \textsc{morphosyntactic}, \textsc{phonological} and \textsc{indeterminate.}
The morphosyntactic tests/domains are listed in \REF{list:mstests}. The phonological tests are listed in \REF{list:phontests}. For details on how to apply the relevant tests and how they are fractured the reader should consult the chapters of this volume.


\ea Morphosyntactic tests/domain types \label{list:mstests}
    \ea  \textsc{Non-permutability}: A span wherein the elements do not display variable ordering with respect to one another.
        \ex \textsc{Non-interruptability}: A span that cannot be interrupted by an element of a certain type.
        \ex \textsc{Ciscategorial selection}: A span whose elements are ciscategorial selective with respect to a particular part of speech.
        \ex \textsc{Recursion-based/Subspan repetition -- maximal}: For a specific construction that involves repetition of positions in   the planar structure (e.g. conjunction, reduplication), the largest possible span where size is calculated as $\textit{R} – \textit{L}$, where R is the right edge and L is the left edge of positions filled out by elements in each of the conjoined spans of structure.
    \z
\z 

The phonological domains are divided into two overarching types. We also annotate these with the classifications provided in \citet{bickeletal:2007} as well as these are largely appropriate for our purposes.

\ea Phonological tests/domain types \label{list:phontests}

    \ea  \textsc{Segmental}: A span wherein a segmental phonological process applies.
    \ex  \textsc{Suprasegmental}: A span wherein a suprasegmental process applies.
    \z 
\z 

A number of coded domains do not fall straightforwardly into either the morphosyntactic or phonological categories. We refer to these as indeterminate domains they are listed in \REF{list:indeterminatedomains} below.

\ea Indeterminate domains \label{list:indeterminatedomains}
    \ea  \textsc{Free occurrence}: A span which is a single free form.
    \ex \textsc{Deviations from biuniqueness}: A span which displays deviations from biuniqueness.
    \ex \textsc{Recursion-based/Subspan repetition -- minimal}: For a specific construction that involves repetition of positions in the planar structure (e.g. conjunction, reduplication), this is the span wherein none of the elements can display wide scope over the conjoined spans of structure.
    \z
\z 

Free occurrence is sometimes described as a morphosyntactic test \citep{haspelmathword:2011} and sometimes as a phonological one \citep{zingler2020wordhood}. Deviations from biuniqueness (e.g. circumfixation, domains for the cells of inflectional classes etc.) mix phonological and morphosyntactic properties in such a way that straightforward classification as morphosyntactic or phonological is problematic. Finally, conjunction of spans of structure is used as a test for constituency, but accounts differ on whether wide-scope phenomena are a product of ellipsis or not. On an ellipsis based account the relevant domain could be phonological, which is why this domain is coded as indeterminate (see \cite{osborne2006shared} for background). This is only relevant for the minimal domain, however. The maximal domain would generally be treated as morphosyntactic.

It is worth stressing that coding a domain as indeterminate reflects agnosticism at the stage of coding data, rather than a theoretical commitment. 

Furthermore, I would like to emphasize that the constituency tests applied in this volume do not exhaust what one \textit{could} code as a constituency test in this approach. There are other aspects of constituency structure that have not yet been operationalized to a point where they can be coded in a cross-linguistic study. An example of this would be constraints related to islandhood which form an important part of the insights achieved in the syntactic literature. Hopefully future research will fill in the relevant gaps. The planar-fractal method is extensible in the sense that new tests can be added as we learn more about constituency and expand the scope of the project to new domains.

\section{Chapters of this volume}
\label{sec:chapters}

The chapters on this volume contribute to the description and analysis of wordhood and constituency phenomena in the languages of the Americas. We attempted to do this by applying a unified methodology, the planar-fractal method. Researchers are also encouraged to critique the method: this allows for the development a cross-linguistic database in the short term, but also for the development of ideas about how to improve or expand te coverage of the methodology in the long term.

In Chapter 2, Anthony C. Woodbury provides a description of constituency in Central Alaskan Yupik (Inuit–Yupik–Unangan, USA). Cup'ik displays a relatively high degree of convergence around the word domain, as it is understood in Inuit–Yupik–Unangan studies. Out of the studies of this volume, the evidence for wordhood based on convergence is perhaps the most impressive in this language. However, Woodbury identifies a number of word ``slivers'' inside the traditional word that could also be identified as ``words'' if other criteria were rallied. Woodbury provides a number of incisive comments on the definition of wordhood in Cup'ik. He points out that ``conventionalized coherence and meaning'', while specified as a wordhood diagnostic in \cite{dixonaikhenvald02}, identifies lexemic verb bases in Cup'ik. Woodbury also critiques Tallman's \citeyear{tallman2021constituency} notion of planar structure base or core, used as a type of non-moveable anchor in the construction of a planar structure. \citet{tallman2021constituency} tried to use Croft's notion of semantic head to define this construct, but Woodbury points out that the criteria for semantic headedness give competing results in Cup'ik. This raises the question as to whether planar structures presuppose an assumption about language structure (one semantic head per part of speech domain) that does not apply in all cases.

In Chapter 3, Hiroto Uchihara provides a description of Oklahoma Cherokee (Iroquian, USA). He shows a high number of convergences around the traditional Iroquian word in this language. He provides a detailed discussion of how the domains identified in Cherokee relate to categories of the prosodic hierarchy. While previous research has reanalyzed the Iroquian ``word'' as a phrase, Uchihara points out that this depends on what criterion or set of criteria are rallied to support domain labeling. Based on a the relatively high number of convergences found in Cherokee, he points out that apparent cases of domain misalignment could arise from looking at an arbitrarily low number of criteria (e.g. \citealt{Bickel2017}). While certain languages may show a relatively high amount of domain misalignments, ``emergentist'' explanations still need to explain high convergences where they occur.

In Chapter 4, Miller applies the planar-fractal method to Kiowa (Tanoan, USA). She argues that the methodology provides further support (in addition to \cite{miller2021is}) for Tri-P mapping, a phase-based theory of the syntax-phonology interface. In this approach phonological domains are the output of morphosyntactic phases, defined in terms of derivations in syntax. Empirically the results suggest that for every phonological domain there is at least one converging morphosyntactic one. Miller's chapter shows that the planar-fractal method might be helpful in testing competing theories of the syntax-phonology interface since it ``strips away theoretical assumptions'' that can lead to noncommeasurability between linguistic analyses.

Nakamoto provides a detailed analysis of constituency in Ayautla Mazatec (Popolocan, Oto-Manguean, Mexico) in Chapter 5. Nakamoto shows a relatively low amount of convergence in phonological domains. He shows that interesting analytic issues arise with domain (mis)alignment assessment because of the presence of concatenative floating tones. This suggests more potential problems in assessing domain (mis)alignment cross-linguistically.

In Chapter 6, Sandra Auderset, Carmen Hernandez Martinez and Albert Venta\-yol-Boada provide a description of constituency tests applied to Duraznos Mixtec (Baja Mixteca, Oto-Manguean, Mexico). Duraznos Mixtec displays the most striking misalignments out of any of the languages in the volume. The authors show that the high degree of ambiguity in identifying the word is reflected in the literature by authors representing Mixtec languages with different degrees of synthesis orthographically. In general, the results could be regarded as evidence for Pike's contention that the morphology-syntax and word-phrase distinctions are weak or unmotivated in Mixtec languages, yet we should refrain from claiming that all Mixtec languages are the same in this regard.

In Chapter 7, Ambrocio Gutiérrez Lorenzo and Hiroto Uchihara apply the planar-fractal to  the analysis of nominal and verbal domains in Teotitlán del Valle Zapotec (Zapotecan, Oto-Manguean, Mexico). They argue that there is some support for morphosyntactic words independent of phonological words based on the clustering assumption (i.e. words are domains of high clustering). Based on the clustering assumption, TDZ Zapotec would appear to be closer to  isolating than is has been described in previous literature, at least morphosyntactically. Assessment of the clustering of phonological domains is less clear, however. The highest domain appears to be the one with the strongest convergences. The results suggest that a clustering assumption cannot be used to divide words from phrases: higher utterance/sentence level domains might be just as likely to show high convergences. 

Eric Campbell provides a description of constituency in Zenzontepec Chatino (Chatino, Oto-Manguean, Mexico) in Chapter 8. He shows a high degree of convergence in Zenzontepec Chatino on (morpho)phonological grounds around a small span of structure, which he described as the word in previous work. The situation is reminiscent of Central Alaskan Yupik in terms of convergences, but for a smaller (isolating?) word domain. However, in Zenzontepec Chatino identifying a morphosyntactic word is more problematic. Nevertheless, a question arises in such cases as to how an emergentist approach would explain high convergences in phonological processes found in Chatino. 

In Chapter 9, Minella Duzerol provides a description of the French-based creole Martinican (Martinique). According to Duzerol there are not many phonological criteria that can be used to motivate a notion of phonological word in the language, thus most of the criteria that one can rally to analyze Martinican structure are morphosyntactic. Duzerol discusses the results in light of orthographic conventions and practices in Martinican. While the results do not line up with official orthographic conventions for delineating words, Duzerol suggests they might line up more with actual writing practice.

In Chapter 10, Patience Epps provides a description of Hup (Nadahup) using the planar-fractal method. By focusing on the difference between Hup and its sister language Daw, she argues that one could characterize the Hup and/or Daw structures as isolating or synthetic depending on which criteria are prioritized. Either both languages are isolating, Hup is polysynthetic and Daw is isolating or both languages are polysynthetic depending on which criteria are considered. Epps suggests that the key difference between Daw and Hup, the phonological integration of elements in a fixed order into a larger phonological unit in the latter but not the former, arose due to contact with Tukanoan languages. Epps discussion also reveals that non-interruption as a test is not obviously informative. There are many different non-interruptable domains depending on which element is chosen. Epps suggests a diachronic explanation for this situation.

Magdalena Lemus-Serrano provides a description of constituency in Yukuna (Arawak, Colombia) in Chapter 11. Lemus-Serrano reports extremely low levels of convergence in Yukuna overall (somewhat surprising given that Yukuna's template also requires a relatively lower number of positions compared to that of other languages). This raises questions about the applicability or relevance of categories such as morphosyntactic and phonological word for the language. The synthetic status of Yukuna is likewise unclear because it depends on which criteria are prioritized. On the other hand Lemus-Serrano argues that the results support current diachronic scenarios about the evolution of person prefixes/proclitics in Arawak.

Andrés Salanova provides a description of Mẽbêngôkre (Ge, Brazil) in Chapter 12. Salanova argues that the planar-fractal analysis provides further support for the notion of word that was adopted in his previous analysis. That the relevant constituent is a word is also supported by the fact that a number of structure preserving morphophonological processes occur within the same span. Interestingly, Salanova suggests that the language has few obvious post-lexical processes. Apart from this Salanova shows that Mẽbêngôkre displays a number of striking bracketing paradoxes that are mostly related to the possibility of incorporating postpositions into a span of structure left-adjacent to the word. 

In Chapter 13, Adam Tallman describes the application of constituency tests to Araona (Takanan, Bolivia). I argue that whether we find convergences within the phonological or morphosyntactic domains depends on how certain ``indeterminate'' domains are classified. It is unclear whether deviations from biuniqueness, minimal subspan repetition and free occurrence domains should be classified as morphosyntactic or phonological. How to relate the results to claims about morphosyntactic and phonological structure is contingent on how we treat these indeterminate domains. Overall there is a way of interpreting the results with respect to common assumptions about wordhood in Takanan languages, but the planar-fractal method shows that such analyses are partially arbitrary. Whether Araona is isolating or (poly)synthetic depends on which of the diagnostics we assume are word identifying versus phrase identifying.

In Chapter 14, Gladys Camacho-Rios and Adam Tallman provide an analysis of Uma Piwra South Bolivian Quechua (SBQ) (Quechua, Bolivia).  We find some support from wordhood diagnostics for the orthographic word in SBQ. SBQ is interesting because of the number of complex morphemes that replace spans of structure internal to the word, but without covering the root (semantic head). In the phonological domain, there are no convergences in SBQ. We contextualize the results in relation to debates about the morphology-syntax distinction in Quechua.

In Chapter 15, Javier Carol provides a description of constituency in Chorote (Matacoan, Argentina). Carol discusses his results in terms of the high degree of ``transcategoriality'' of elements in Chorote. Transcategoriality is relevant for the way we have formulated selection in this project. A selection domain is one which contains elements which can only combine with a single part of speech class. Carol argues that this domain is, in fact, ambiguous because it depends on whether we are concerned with ``selection of a predicate'' versus ``selection of a verb'' in its assessment. He breaks down the criteria further to capture this difference. Chorote displays cases where the nominal structure must be partially interspersed (tangled) with the verbal one because the distribution of noun phrases in Chorote depends on whether these occur with a demonstrative or not: nominal demonstratives also incorporate into the Chorote verbal structure. Overall the results for Chorote suggest a highly ambiguous situation without obvious support for the word bisection thesis.

\hspace*{-2.3pt}In Chapter 16, Cristian R. Juárez provides a description of constituency tests in Mocovi (Guaycuruan, Argentina). Juarez shows that the constituency test results in Mocovi support a graded notion of word. Minimal fractures of domains overall suggest a much smaller word constituent than has been described for Guaycuruan languages, whereas maximal domains come closer to supporting a larger word constituent.

Chapter 17 provides an overview of the results of the volume. We focus on the structure of the database and the workflow for its development. We target three assumptions in linguistics that we think need to be revised in light of the results of this volume. This chapter calls for reassessment of the notion of synthesis, wordhood test, and claims about the relative reliability of tests in the linguistic literature.

Chapter 18 provides a critical and retrospective commentary on the project of comparing wordhood and constituency cross-linguistically by Kristine Hildebrandt. Hildebrant compares the methodology of the Word Domains project to the Constituency-Convergence project, commenting on areas that still require future research.

In Chapter 19, Taylor Miller further assesses the planar-fractal method in relation to a one of the current theories of syntax-phonology interaction: Tri-P mapping with Cophonologies by Phase. Taking some select examples from this volume, she argues that the model makes successful predictions concerning the patterns found in Araona and Ayautla Mazatec. She shows that a description of the data in terms of the planar-fractal method permits a relatively stream-lined assessment of how well data fit syntax-phonology interface theories, thus opening the door to more rigorous intertheoretic comparison. 

% \ea
% \gll ~\\
% \Assimil \Ciscat \Ccompl \Coal \Cons \Ds \Exp \Extend \Max \Min \Nointerrupt \Nopermut \Occurr \Rec \Rep \Sel \Ss \Vclust\\
% \z

\printglossary



{\sloppy\printbibliography[heading=subbibliography,notkeyword=this]}
\end{document}








