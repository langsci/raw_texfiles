\chapter{Translation technology}\label{ch:translation_technology}

\begin{sloppypar}
This chapter analyses translation technology, computer-assisted translation (CAT) tools in particular, and related research from a usability engineering perspective (discussed in Chapter \ref{ch:usability_engineering}). The analysis will serve as a means of comparison for the review of interpreting technology, computer-assisted interpreting tools in particular, and related research in the following chapter (Chapter \ref{ch:interpreting_technology}). After a brief definition of \textit{translation}, the chapter unravels the history of translation technology and the development of computer-assisted translation tools. It then provides a succinct review of CAT tool research, with a focus on studies dedicated to informing the design of CAT tools through the analysis of users’ needs and requirements as well as through empirical testing. The chapter concludes with a discussion of the extent to which a usability engineering approach is reflected in the development of CAT tools.
\end{sloppypar}

\section{Developments and current landscape}

Translation may be defined as ``the result of a linguistic-textual operation in which a text in one language is re-produced in another language'' \citep[1]{house2014translation}. Theories of what translation is and how to translate began to emerge as early as in the writings of Cicero and Quintillian, whose debate on translation practice pertained mostly to \textit{how} a text should be translated – either word-for-word or sense-for-sense. Despite these ancient origins, the actual birth of \textit{Translation Studies} (TS), as the discipline that studies the theoretical and practical aspects of translation, goes back to \citegen{holmes1975name} seminal work ``the name and nature of translation studies''. Through time, theorising on translation has been informed by other disciplines and different worldviews, often referred to as turns in TS (e.g. \cite{snell2006turns}). Different perspectives have led to a substantial redefinition of the concept of translation \citep{cheung2011reconceptualizing} and through time TS has differentiated into a plethora of approaches and lines of research \citep{baker2019}. For society at large, translation is a technology – a means to communicate across language differences:

\begin{quote}
    The infinite extension of the written symbol through time requires the good offices of the translator. Similarly, when the written symbol is considered in terms of spatial range, the default multilingualism of the planet means that there can be no extension in space without the work of the translator. The text needs translation to travel. So the afterlife of the text, dependent on elements of the third system, the artefacts of “ink” and “paper”, relies also on the tool of language, and, by extension, translation, for its ability to reach “readers” in a different time and space. \citep[22]{cronin2012translation}
\end{quote}
At the same time, translation is, by its own nature, dependent on writing technology, be it stone inscriptions, ink quills on parchment, typewriters, or the personal computer. Because of this dependency on writing technology, the activity of written translation came after that of oral interpreting (see   \chapref{ch:smarterp}).

\begin{sloppypar}
When translation scholars discuss the relationship between translation and technology, they commonly refer to the introduction of digital technology into the profession (cf. \cite{chan2015}). Digital technologies changed ``how translations are commissioned, produced, distributed and consumed or used'' \citep[2]{jimenez2020technological}. The impact of digital technologies has been profound and affected the translational \textit{micro}- and \textit{macro-systems} \citep{o2013impact}. ICTs created new forms of translating, such as crowdsourced translation and localization. Digital tools came to play a central role in all phases of the translator’s work, so much so that by the beginning of the 21st century no translator could expect to work without digital tools any longer \citep{bowker2002computer}. ICTs have become so deeply entrenched into translation that all of translation may be seen as a form of \textit{human-computer interaction} \citep{o2012translation}. The deep influence that technologies had on translation made scholars refer to it as a technological turn (e.g. \cite{chan2007taking,cronin2010translation,o2013impact}). This turn not only led to significant shifts in the way in which translation is carried out in the contemporary world, but also led to a systematic re-examination of the ``conventional understandings of what constitutes translation and the position of the translator'' \citep[1]{cronin2010translation}. Hence, the technological turn, like previous turns, has led to a re-definition of the very concept of translation. From a disciplinary perspective, technology permeates translation studies across its different subdisciplines, both in their theoretical apparatus and/or in their research methodologies (cf. \cite{jimenez2020technological}).
\end{sloppypar}

The digital technologies that have so shaped the translator’s work are varied and may be summarised as five broad categories: the translator’s computer equipment, communication and documentation tools, text edition and desktop publishing, language tools and resources, and translation tools \citep{alcina2008translation}. Translation tools, which are the main focus of scholarly debates on technology and translation, may be further divided into two categories: technologies aimed at \textit{replacing human translators} and those aimed at \textit{supporting human translators} \citep{alcina2008translation}.

Technologies aimed at replacing human translators have the ambition to generate fully automatic translation. Efforts to develop such technologies began to emerge in the 1950s and they are referred to as \textit{machine translation} (MT) \citep{hutchins2015machine}. The initial enthusiasm for machine translation, which started from the second half of the 1940s, led to the realisation around the first half of the 1960s that machine translation needed to be revised by humans, leading to twice the costs of human translation and a raw output that was unable to meet expectations; therefore, fully automatic machine translation was not going to be realized for a long time \citep[3--4]{chan2015}. Today, MT produces large volumes of translation and is commonly used for people to get access to content: ``Google translation services are used by more than 500 million people every month, producing more than 1 billion translations a day. Every day, Google translates more text than all human translators translate together in a whole year'' \citep[377]{carl2017translation}. Despite the uncertainty about whether MT will ever attain sufficient quality to make it a stand-alone solution, the spread of MT has had a psychological impact on translators:
\begin{quote}
    Over the last decade, speaking to audiences in different parts of the world, the same questions keeps returning: Is there a future for translators? In the age of Google Translate, is the human translator condemned to large-scale extinction, or to the quaint peripherality of the Sunday hobbyist? The demand for translation keeps growing apace in the contemporary world, but will humans continue to be asked to service this need, or will it be our machines that will do the bidding? \citep[1]{cronin2012translation}
\end{quote}
This initial disappointment with MT in the 1960s led to interest in developing technology to support human translators, increasing its efficiency and productivity and reducing its costs \citep[4]{chan2015}. The use of technology to support the translator’s work is known as computer-assisted, or -aided, translation (CAT), \citet[4]{chan2015} reports the United States’ Automatic Language Processing Advisory Committee’s (ALPAC) 1966 report as a turning point in the evolution of translation technology. After establishing the failure of MT, the report suggested that MT should shift to machine-aided translation, which would be ``aimed at improved human translation, with an appropriate use of machine aids'' \citep[iii]{ALPAC1966}, and that ``machine-aided translation may be an important avenue toward better, quicker, and cheaper translation'' \citep[32]{ALPAC1966}. Specialised CAT tools began to be developed for this purpose in the second half of the 1960s \citep{chan2015}.

\citeauthor{hutchins1998origins}' (\citeyear{hutchins1998origins}) seminal paper attributes the origin of CAT tools (specifically, of the \textit{translation memory} concept, discussed later) to \citet{arthern1978machine}, Head of English Translation Division at the European Commission (at the time, Council of the European Communities). In his paper, Arthern observed that translators working at the European Commission were wasting valuable time by retranslating (parts of) texts that had already been translated. Hence, he proposed to develop a digital storage of source and target texts for translators to re-use in current translations, speeding up the process. This solution may be referred to this as ``translation by text-retrieval'' \citep[94]{arthern1978machine}.

Already the year before, in 1978, Melby of the Translation Research Group of Brigham Young University conducted research on machine translation and developed an interactive translation system, ALPS (Automated Language Processing Systems) based on “Repetitions Processing”, which aimed at finding matched strings (\citealt{Melby1978} cited in \cite[4]{chan2015}).

Another milestone was laid by Kay in his paper titled ``The proper place of men and machines in language translation'' \citep{kay1980}. He argued that MT and translators should work together and proposed the development of a software split in two windows: the upper window for the source text to be translated and the bottom window as a workspace where the translator could edit the translation with aids for word selection and dictionary consultation. Chan points out that ``In view of the level of word-processing capacities at that time, his [Kay’s] proposal was inspiring to the development of computer-aided translation and exerted a huge impact on its research later on'' \citep[5]{chan2015}.


\section{Computer-assisted translation (CAT) tools}

Computer-assisted translation tools may be defined as ``a specialized set of tools that are designed specifically with translation in mind'' \citep[504]{o2013impact}. Since MT is now commonly used as a support to human translation, although it was not necessarily designed with the human translator in mind, another possible definition of CAT tools is: ``tools that are (relatively) specific to the translation process'' \citep[121]{kruger2016contextualising}. There are several “specialised instruments” aimed for specific aspects of the translator’s work. The label “CAT tool” may be used to denote both the specialised instruments in isolation and their integration into a comprehensive solution – which may also be referred to as a ``translation environment'' \citep[1]{coppers2018intellingo}.

CAT tools can support different phases of translators’ and organisations’ work, for instance as described in the \textit{Cologne model} \citep{kruger2016contextualising,kruger2016fachubersetzen}. Paraphrasing and summarising the main phases of the model (cf. \cite{kruger2016contextualising,kruger2016fachubersetzen} for a detailed discussion), CAT tools can facilitate the phases of client acquisition, work preparation and coordination among translators through project management functions -- i.e. the \textit{project initiation} and (\textit{general} and \textit{translator}) \textit{preparation phases}. CAT tools assist translators in the \textit{actual translation phase}, where the text is translated from the source to the target language. After the translation is completed, CAT tools support the \textit{quality control phase}, in which the translation is revised, the \textit{final administrative work} and the \textit{follow-up work}. In the present discussion, I will focus on the CAT tool components that are aimed to support the actual translation phase. The use of CAT tools during the translation process has been of particular interest for scholars, who maintain that it may have a profound impact on the translator’s cognition. In the words of Pym, CAT tools (or their components) used in the translation phase ``far from being merely added tools, are altering the very nature of the translator’s cognitive activity'' \citep[1]{pym2011technology}. Furthermore, these may be seen as the equivalent of in-booth CAI tool use, which is the focus of this work.

CAT tools (components) for the translation process were initially developed based on the assumption that translators' work would become more efficient if it could be provided with automated translation aids. This idea originated \textit{translation memory} (TM) systems: ``a translation memory stores sentences and their human translation from a specific domain. Given a source segment, the translation memory provides the user sentences that have the same or a similar vocabulary and/or grammar \citep[1]{coppers2018intellingo}. Another more basic type of translation aid is provided by CAT tools through the \textit{term base}, which stores terms and their metadata. Finally, MT itself is integrated into CAT tools as a form of translation aid. The MT engine pre-translates the source-text which is then edited by the translator -- an activity commonly referred to as ``post-editing'' (e.g. \cite{flanagan2014testing}). In some cases, the machine translation engine can adapt its output during translation based on the translator’s corrections \citep[1]{coppers2018intellingo}. In professional settings, MT engines are typically trained using in-house TM databases and term bases -- a system also referred to as ``MT-assisted TM'' \citep{christensen2017mapping}. Since the translator edits the MT output which feeds back into the TM databases and term bases, Mt-assisted TM blurs the traditional distinction between MT, post-editing and TM-assisted translation \citep[9]{christensen2017mapping}.






\section{CAT tool design, development and reception}

While the quest for adequate solutions that could make the machine-translator symbiosis possible started in the 1980s at the ideational level, commercially viable CAT tools first became widely available in the early 1990s. The need to increase the efficiency of human translation was stimulated by the ``globalisation turn'' \citep{snell2006turns} and improved ICTs:
\begin{quote}
    CAT systems were developed from the early 1990s to respond to the increasing need of corporations and institutions to target products and services toward other languages and markets (localization). Sheer volume and tight deadlines (simultaneous shipment) required teams of translators to work concurrently on the same source material. In this context, the ability to reuse vetted translations and to consistently apply the same terminology became vital. \citep[63]{garcia2015computer}
\end{quote}
The first commercial CAT tools were developed by the German-based Trados and the Swiss-based STAR AG. Since then, the growth in number has been exponential:
\begin{quote}
    Before 1993, there were only three systems available on the market, including Translator’s Workbench II of Trados, IBM Translation Manager / 2, and STAR Transit 1.0. During this ten-year period between 1993 and 2003, about twenty systems were developed for sale, including the following better-known systems such as Déjà Vu, Eurolang Optimizer (Brace 1994), Wordfisher, SDLX, ForeignDesk, Trans Suite 2000, Yaxin CAT, Wordfast, Across, OmegaT, MultiTrans, Huajian, Heartsome, and Transwhiz. This means that there was a sixfold increase in commercial computer-aided translation systems during this period. \citep[8]{chan2015}
\end{quote}
CAT tools were first equipped with basic components, such as translation memory, terminology management, and translation editor. With the growing sophistication if ICTs, more functions were developed into CAT tools and more components were gradually integrated into these systems \citep[12]{chan2015}.

TRADOS\footnote{\url{https://www.trados.com}} (Translation \& Documentation Software) was developed by the German engineers Jochen Hummel and Iko Knyphausen. It soon became the industry standard, partly thanks to successful tender bids to the European Commission in 1996 and 1997 \citep[70]{garcia2015computer}. From the late 1990s, TRADOS’ technology was integrated into other CAT tools too and its products became the most popular in the industry \citep[13]{chan2015}. The acquisition by SDL further supported its commercial success. SDL Trados, the new name of Trados, was the first company to integrate a translation memory into a CAT tool. In 2009, the release of SDL Trados Studios 2009 marked the shift towards an integrated CAT tool with all translation aid components integrated in a single interface. A survey conducted by Proz.com, the largest networking website for professional translators, in 2013\footnote{\url{https://go.proz.com/blog/cat-tool-use-by-translators-what-are-they-using}} suggests that Trados remains the market leader among CAT tools. It is estimated that TRADOS today holds over 70\% of shares in the global language translation software market \citep{Cheng2021}.

The UIs of CAT tools present a series of features aimed at enabling translators to incorporate translation aids into their translation. The system front-end that translators use to create the translation is called \textit{editor}. In the editor, translators open the source file for translation, query the TM systems and databases for relevant data and/or post-edit the MT output \citep[71]{garcia2015computer}. A CAT system editor segments the source file into translation units to enable the translator to work on individual segments separately and the program to search for matches in the memory \citep[72]{garcia2015computer}. Inside the editor window, the translator sees the active source segment displayed together with a workspace for the target text, where matches are shown for the translator to review, edit or translate from scratch \citep[72]{garcia2015computer}. The workspace can appear below (\textit{vertical presentation}, as in Trados and Wordfast) or beside (\textit{horizontal} or \textit{tabular presentation}, as in one visualisation option in Déjà Vu) the currently active source-text segment. \textit{Segmentation} and \textit{orientation} (vertical or horizontal) are two of the most commonly debated UI parameters of CAT tools. The similarity between text segments that must be translated and previously translated segments in the TM is expressed as a \textit{matching score} which can be of three main types \citep[61]{bowker2010computer}: \textit{exact match} (100\% correspondence), \textit{fuzzy match} (about 60--70\% correspondence), \textit{sub-segment match} (if a portion of the segment is recognised by the TM), \textit{term match} (if a term in the source segment is present in the term base), \textit{no match} (if the TM fails to detect previously translated material).

\begin{sloppypar}
Today, CAT tools are commonly used in professional translation. However, scholars and professionals have expressed mixed views concerning their impact on human translation. Positive views contend that CAT tools increase the efficiency of time-consuming and error-prone tasks, such as translating repeated text portions in a consistent fashion \citep{o2012translation}. Because of this, CAT ``has contributed to increasing speed, improving consistency, reducing costs'' \citep{ehrensberger2014translatorbs}. At the cognitive level, CAT tools ``have extended translators’ memory by externalizing it, thus decreasing the load on working and long-term memory'' \citep{pym2011technology}.
\end{sloppypar}


Negative views claim that CAT tools may change the process and the very nature of translating. \citet{pym2011technology} contends that CAT tools impose the paradigmatic constraints on the syntagmatic nature of the practice as they cause translation to lose its linearity and drift further away from the perception of translating as an act of translator-mediated communication between people. The constant use of translation aids transforms the translator into a ``de-facto post-editor'' \citep{christensen2017mapping}. Some hypothesised disadvantages are of psychological nature: they emerge from translators’ perception of and relationship with technology, with several factors potentially contributing to a (perceived or actual) downgrading of the professional status of the translator and subsequent feelings of ``dehumanisation'' and ``devaluation'' \citep{o2012translation}. These challenges are ascribed to the view of the translator as a fixer of MT errors, as well as translators’ lack of knowledge of MT which is seen as a black box, ``something they do not quite understand and which removes them further from the task of translation'' \citep[109]{o2012translation}. This feeling of disconnection and distrust manifests on social media, where professional translators express doubts about the usefulness of technologies like MT \citep{laubli2017google}. Research carried out at the European Commission’s Directorate-General for Translation suggests translators felt uncomfortable with MT technology despite having used it for many years \citep{cadwell2016human}. From a cognitive perspective, the complexity of many of the newer CAT interfaces may increase the cognitive demands on their users \citep{hansen2012nutzbarkeit}.

A major point of controversy, denounced by scholars and professionals alike is that translators were not sufficiently involved in the development of CAT tools. Moorkens and O’Brien, for instance, concluded that users’ needs where insufficiently accounted for in the design of CAT tools: ``prior to the current research there has not been a focus on what functionality users would like to see in a tool for post-editing as the MT research community has had a tendency to ``focus on system development and evaluation'' rather than considering end users \citep[4]{doherty2019translation}'' \citep{moorkens2017assessing}. Observing the lack of a user-centred design, scholars plea for iterative design processes in which users’ feedback and data is constantly used to validate and refine the solution \citep{laubli2019translation} -- i.e. they call for a usability engineering approach (see \chapref{ch:usability_engineering}) to the design and development of CAT.

\cite[381]{laubli2019translation} report of the development of Intellingo \citep{coppers2018intellingo} as an out-of-the-ordinary example of a user-centred development approach to the development of a CAT tool. Intellingo is an intelligible CAT tool showing contextual information to the translator, such as metadata about where the translation aids originated from (term base, translation memory, the machine translation engine, or a combination of these resources). The rationale for the development of such a system is that increasing the intelligibility of translation groups could increase users’ trust in the tool: ``CAT tools offer some form of intelligibility, by showing matching scores, for example. However, the inner logic of the algorithms is rarely shown, and there is plenty of potential to enhance their intelligibility'' \citep[3]{coppers2018intellingo}. The authors report in the paper that the whole software was developed in successive iterations and started from surveys and contextual enquiries to develop the tool based on translators’ requirements. They then tested two UIs of the tool to check whether the intelligibility function served the translator and to what extent it was used. The development team started by surveying 180 translators, and then iterated over mock-ups and functional prototypes, involving translators from the outset. Also the project by \citet{teixeira2019creating} present an iterative development process of a web-based translation editing interface that permits multimodal input via touch-enabled screens and speech recognition in addition to keyboard and mouse. Two usability studies were conducted between iterations and reported in the paper. These latter virtuous examples, however, arose within research projects with a limited impact on the CAT tool market. An example of a translator-centred CAT system with a commercial application is Predictive Translation Memory (PTM) developed by \citet{green2014predictive}. PTM is a type of interactive translation memory (ITM) system. It aims to facilitate the interaction between translators and CAT tools as well as the integration of TM suggestions into the translator’s work through a UI reducing gaze shift. In their paper, Green and colleagues explain that translators’ discontent with existing systems led to the development of the PTM and detail the lare-scale evaluation study. PTM was later integrated into Lilt’s CAT tool editor. Lilt\footnote{\url{https://lilt.com/}} is a translation and technology business founded by John DeNero and Spence Green. It provides translation and localisation services to clients worldwide, supporting their pool of freelance translators with a dedicated CAT tool, based on ongoing research\footnote{\url{https://lilt.com/research}} such as the aforementioned paper and others.





\section{CAT tool research}

CAT tool research may be positioned within the TS subdiscipline of translation technology research. Given the pervasiveness of technology in the translation profession, ``the study of translation in one-way or another requires acknowledgement of [the] interrelationship [between translators and technologies]'' \citep[2]{jimenez2020technological} and technology may be seen as a ``connecting thread across sub-disciplines of TS and diverse research areas'' \citep[3]{jimenez2020technological}. I will define translation technology research as research that is specifically focused on translation technology, technology-dependent phenomena as well as the impact of technology on the translator and translating -- as opposed to TS research using technology as a necessary medium of translation (e.g. a word processor) without focusing on the impact of the medium on the translation process/product. CAT tool research, in turn, may be defined as a line of research concerned with ``the design and adaptation of strategies, tools and technological resources that make the translator’s job easier as well as facilitating the research and teaching of such activities'' \citep[90]{alcina2008translation}.

In TS, translation technologies in general, and CAT tools, in particular, have been studied from a variety of perspectives, drawing explanatory concepts and frameworks from other disciplines (cf. \citealt{olohan2019technology}). Although they may not have an explicit design focus, studies of predominantly cognitive or descriptive nature may yield implications for CAT tool development (e.g. \cite{mellinger2016match}). Research with an explicit focus on the extent to which CAT tools are adequate to translators’ needs and what UI features can support or inhibit the work of translators are most commonly aligned to either an \textit{ergonomics approach} (cf. \cite{ehrensberger2019ergonomics}) or a \textit{human-computer interaction} (HCI) \textit{approach} (cf. \cite{laubli2019translation}).

The ergonomics approach to the study of translation technology encompasses cognitive, physical, and organizational ergonomics to investigate the impact of various factors on the situated activity of translation, including the use of CAT tools \citep[63]{ehrensberger2014a}. This approach was informed, on the one hand, by the cognitive paradigm in TS (cf. \cite[Chapter 2]{walker2021cognitive}), which called for explorations of issues such as cognitive load and mental processes inherent to translators’ use of CAT tools as well as for methods of the translation-process research (TPR) tradition such as key-logging, screen recording, and eye-tracking (cf. \cite{jakobsen2017translation}). On the other hand, research on the ergonomics of CAT tool was informed by the theory of situated translation (cf. \cite{risku2002situatedness,risku2004interkulturelle}), grounded in situated cognition theory (e.g. \cite{brown1989situated}), which called for naturalistic workplace studies aimed at exploring the role of technology in the translator’s cognitive ecosystem (cf. \cite{ehrensberger2019ergonomics,ehrensberger2015ergonomics}).

Scholars aligned with the ergonomics approach typically draw on the International Ergonomics’ Association’s (IEA) definition of \textit{ergonomics} as ``the scientific discipline concerned with the understanding of interactions among humans and other elements of a system, and the profession that applies theory, principles, data and methods to design in order to optimize human well-being and overall system performance'' (IEA, cited in \cite{ehrensberger2019ergonomics}). They also distinguish, with the IEA, between physical, organisational, and cognitive ergonomics. \textit{Physical ergonomics} is defined by the IEA as ``human anatomical, anthropometric, physiological and biomechanical characteristics as they relate to physical activity''. In the context of translation, this essentially means exploring the impact of the characteristics of the translators’ workplace, such as the tables, chairs, computers, noise level etc. \citep[38]{ehrensberger2019ergonomics}. \textit{Organisational ergonomics} ``is concerned with the optimization of sociotechnical systems, including their organizational structures, policies and processes.'' In the context of translation technology research, this has meant a concern with the extent to which the increasing technologization of the profession has impacted the translator’s professional status and agency \citep[39]{ehrensberger2019ergonomics}. \textit{Cognitive ergonomics} refers to the ``mental processes, such as perception, memory, reasoning, and motor response, as they affect interactions among humans and other elements of a system''. O’Brien and colleagues explain the primary concern of CAT tools’ cognitive ergonomics research as ``understanding of cognitive friction arising from translators’ interactions with non-optimal CAT tool features'' \citep[147]{o2017irritating}. Cooper’s concept of \textit{cognitive friction} \citep{cooper2004high} has been used as a primary explanatory concept in the study of CAT tools’ cognitive ergonomics. It is defined as ``the resistance encountered by a human intellect when it engages with a complex system of rules that change as the problem changes'' \citep[19]{cooper2004high}. The concept was first introduced to the study of CAT tools by \cite[110]{o2012translation}, who paraphrased it as ``the tension between translators and computers.'' It was then further explored by \citep[102]{ehrensberger2015ergonomics} who defined it as a disturbance to the translation \textit{flow}. Flow is understood as a psychological state of being fully immersed in a task such that this immersion is energising (\citealt{NakamuraCsikszentmihalyi2002}, cited in \cite{ehrensberger2015ergonomics}). The interruption of the state of flow by sub-optimal CAT tool features is thought to manifest as the translator’s \textit{irritation} with those tools and to increase the cognitive load in the translation task \citep[146]{o2017irritating}. The assumption is hence that ``since being irritated can affect negatively performance, improvements in the cognitive ergonomics of translator tools could contribute to better decision-making, creativity, and efficiency'' \citep[43]{ehrensberger2019ergonomics}. Therefore, CAT tools ``should be designed in such a way that they aid cognition and do not become a potential source of cognitive friction'' \citep[81]{teixeira2017investigating}.

The ergonomics approach to translation technology research, particularly the cognitive ergonomics approach, has contributed to increasing the field’s awareness of the importance of CAT tool usability, shedding light on translators’ needs and the features of CAT tools that might decrease their usability. However, as noted by Kruger, ``the issue of CAT tool usability is not addressed specifically in cognitive ergonomics research, and the investigation of translation technology remains at a rather coarse-grained level, being mostly concerned with shortcomings of user interfaces and the possibility to customise tool settings according to individual preferences'' \citep[128]{kruger2016contextualising}.

More fine-grained usability research has been conducted within what \citet{laubli2019translation} refer to as the human-computer interaction (HCI) approach to the study of translation technology. While the ergonomics approach has been mostly influenced by translation theory and led by TS scholars, the HCI approach draws explicitly on concepts and research methods from the field of HCI and usability. The major contribution of studies within the HCI approach is the development of requirements for CAT tool interface and design recommendations through rigorously designed empirical studies (e.g. \citealt{laubli2020machine, laubli2021impact}). Such data may provide compelling arguments for the adaptation of CAT tools to interpreters’ needs:
\begin{quote}
    However, the impact of poor usability on translator performance has rarely been tested empirically, and since the motivation for using CAT tools is primarily economic – saving time by leveraging translation suggestions rather than translating from scratch – the design of these tools is unlikely to change until measurements show that alternative designs speed translators up or cause them to make fewer mistakes. \citep[1]{laubli2020machine}
\end{quote}
Within this approach, we also find examples of translator-centred, iterative development of CAT solutions \citep{coppers2018intellingo,green2014predictive,teixeira2019creating}, although these were developed within research projects without a direct influence on market realities.

The review below addresses previous research on CAT tools that has explicit implications for their design. The focus will be on the most common methods used to develop recommendations for the design and their further improvement. I will first consider research providing input on users’ needs and general CAT tool requirements. Then, I will examine research focused on the empirical evaluation of CAT tools via tool performance, users’ performance, and users’ perception.

\subsection{Need analysis and tool requirements}

The analysis of translators’ needs in the use of CAT tools has been the focus of a wealth of studies, the majority of which were conducted by TS scholars. Through the years, several explorations elicited information about the extent to which CAT tools are employed, which tools are most used and users’ perceptions of their usability. Several methods were used, with surveys and interviews followed by contextual enquiry being the most common methods. Other studies used user research methods, mixed-method designs and literature review/theoretical modelling to develop requirements for CAT tool design.

Survey was one of the first methods to be used to explore translators’ needs and the usability of CAT tools and today remains a popular method to develop requirements for CAT tool design (e.g. \cite{schneider2018translation}). Surveys concerned specifically with the usability of CAT tools began to emerge in the noughties, about a decade after CAT tools began to appear on the market. Today, surveys remain The survey by \citet{lagoudaki2006translation} is considered one of the first surveys dedicated to the usability of TMs. One of the conclusions of the survey, which collected the responses of 874 professionals, was that respondents felt that their needs and usability issues had not adequately been accounted for in the design and development of TMs. The author hence recommended that ``user engagement be pursued in all stages of software development'' (\citealt[205]{Lagoudaki2008}, cited in \cite{vargas2019usability}). Among the most renowned studies that employed survey methods, \citet{moorkens2013user} asked posteditors to describe the features of their ideal TM UI. The usability of CAT tool UI was further studied in an international survey within the \textit{ErgoTrans} project \citep{o2017irritating}, which aimed to identify the specific features of CAT tools that translators found ``irritating'' or that they felt were missing. Among the most common irritating features, the complexity of the UI and text segmentation were mentioned as disturbing elements. Users reported that they felt overloaded by the crowded UI. The authors also reported that much of such irritation could potentially be reduced by customising the interface through basic tool settings but less than half (44\%) of CAT users in the study used customisation options.

Interviews are another method that has been largely employed to investigate translators’ needs and define CAT tool requirements. For instance, following up on survey results, \citet{moorkens2017assessing} conducted an in-depth exploration aimed at identifying user requirements for post-editing tools and possible UI features capable of fulfilling those requirements. To accomplish this aim, they interviewed experienced post-editors. They found that a major source of frustration was the non-responsiveness of MT output, which forced users to make the same changes, again and again. Another key point that emerged was posteditors’ need to know the provenance of TM and MT data, which justified the development of intelligible systems (e.g. Intellingo in \cite{coppers2018intellingo}).

Other scholars proposed creative alternatives to the use of surveys and interviews drawing on user research methods. \citet{koskinen2017love} asked their study participants ($N=102$ professional translators) to write either a break-up or a love letter addressed to a tool of their choice to gain insight into tool usability but also the broader perception and needs of users. 70\% of the collected letters addressed translation technology, mostly search tools and databases rather than TM or MT. The authors mapped translators’ comments onto the usability dimensions of learnability, efficiency, memorability, errors and satisfaction. \citet{laubli2017google} analysed translators’ comments related to translation technology and, in particular, MT on Twitter to gain insight into their attitude and the relationship between practitioners’ perception and scientific knowledge.

Ethnographic research has been another approach of choice for the development of CAT tool requirements. For example, \citegen{asare2011ethnographic} PhD thesis examined the workflow translators working at an agency as a case study for how CAT tools were perceived by users, which features were being used and which ones were not being used. The study concluded that ``a number of features in the translation tools were not being used because their purposes were not understood by the tool users'' \citep[138]{asare2011ethnographic}, pointing out a discrepancy between the CAT tool designer’s intention and actual use. Another renowned ethnographic case study was conducted in Canada by \citet{leblanc2013translators} in three medium-sized translation agencies. The methods used were (1) semi-directed interviews with translators (as well as informal conversations, accounts and testimonials) and management, (2) participant observation of translators at work at their workstations (shadowing), and (3) contextual information on the texts, the clients, the service or the firm \citep[3]{leblanc2013translators}. The aim was to explore the perceived advantages and disadvantages of using TMs at the workplace. One of the conclusions was that part of translators’ dissatisfaction with TMs ``revolves around the tool’s conception or design'' \citep[10]{leblanc2013translators}.

More elaborate mixed-method designs were also used to gain a deeper understanding of translators’ needs, particularly within the framework of PhD theses work. For example, \citet{bundgaard2016translator} collected data concerning the revision of MT-assisted TM translation with a group of in-house translators at TextMinded Danmark. \textit{Micro-level translation processes} were investigated through an experiment with eight in-house translators using SDL Trados Studio 2011 integrated with a client-specific MT engine. (using screen capture, keystroke logging, observation, retrospective interviews, and a post-experimental questionnaire) and \textit{macro-level translation processes} were studied primarily through ethnographic methods, namely participant observation, semi-structured interviews and document collection \citep[111]{bundgaard2016translator}. Another example is the doctoral dissertation of \citet{zaretskaya2017translators}, which investigated translators’ needs by means of a user survey, the evaluation of existing CAT systems, and the analysis of the process of post-editing of machine translation.

Differently from these studies, \citet{kruger2016contextualising,kruger2019model} developed a model of CAT tool usability starting from usability concepts rather than from data. Krüger defined CAT tool usability based on \citegen{iso2016} usability definition and added elements from \citet{iso2011} and the \textit{Quality in Use Model} developed by this standard, to define CAT tool usability criteria. He considers CAT tool usability to be dependent on the context of use (and the context coverage of the tool) and defined by the \textit{effectiveness} and \textit{efficiency} of use as well as translators’ satisfaction when using the tool to complete translation tasks. He also defines CAT usability by users’ perceived learnability. Finally, also the tool’s \textit{data security} is included as a usability dimension because of the pressing issue of data security in the translation industry, which, in Krüger’s view, restricts the context coverage \citep[113]{kruger2019model}. To my knowledge, however, this model has not yet been used as an analysis instrument in empirical explorations.



\subsection{Evaluation research}


CAT tools have been evaluated empirically from different perspectives. In his review, \citet{doherty2019translation} distinguishes between \textit{product-oriented}, or \textit{linguistic}, evaluation and \textit{process-oriented}, or \textit{performance-based}, evaluation. Studies in the first category are concerned with the evaluation of the output of translation technology, for instance, the output of MT or TM. Studies in the second category focus on the translation product and process using a variety of methods and metrics. \citegen{laubli2019translation} review focuses on evaluation methods testing tools on human translators and distinguishes between the evaluation of \textit{translation speed}, \textit{translation quality}, and \textit{user experience}. In the review below, I will divide studies into the categories (1) evaluation of tool performance, (2) evaluation of users’ performance, and (3) evaluation of users’ perception.


\subsubsection{Tool performance}

The evaluation of CAT tool performance has been mostly concerned with some quality aspects of the translation aids using several methods and metrics. Other possible evaluation focuses include cost-effectiveness, ease of implementation and maintenance, and considerations of training \citep{whyman1999evaluation}. The evaluation of translation aids has typically been based on the measures of accuracy, precision and recall \citep{whyman1999evaluation}.

The evaluation of TMs attempted to evaluate the ``usability'' of translation aids without the involvement of human translators. \citet{whyman1999evaluation}, for instance, report searching for a  parameter capable of being used as an optimisation criterion. In their study, they evaluated the accuracy, precision and recall of TM matching and proposed a weighting factor in terms of keystrokes needed to change the proposed target segment into the desired text. Another example is provided by \citet{colominas2008towards}, who evaluated the accuracy and recall of TM segmentation at the sub-sentential level.

The evaluation of the accuracy of MT output has been a major concern in the industry. Through time, it has shifted from human annotation to automatic evaluation, which was intended to be more objective, consistent, faster and cheaper than human evaluation \citep{doherty2019translation}. Human evaluation was typically conducted by asking human raters to express a judgment on Likert-scale items \citep[340]{doherty2019translation}. Machine-based evaluation measures are called \textit{automatic evaluation metrics} (AEMs). Their purpose was to ``measure the similarity or difference between the output of an MT system and a reference translation or gold standard, typically a human translation, on a set of predefined linguistic criteria'' \citep[344]{doherty2019translation}. \citet[344--345]{doherty2019translation} explains that AEMs originated from speech recognition research and the metric of word error rate (WER) which was adapted into translation error rate (TER) and human-targeted TER. Other AEMs, such as BLUE \citep{papineni2002bleu}, gained substantial popularity. More complex AEMs later emerged to outperform BLUE in their correlations with human evaluation as well as the complexity of linguistic features they can cover \citep[345]{doherty2019translation}.

\subsubsection{User's performance}

Data concerning users’ performance has also been used to evaluate several usability aspects of CAT tools. The evaluation has been directed both to the translation product and the translation process. One aspect of translators’ performance that has been evaluated to gain insight into the effectiveness/efficiency of CAT tools is the \textit{translation speed}, typically measured as words per hour, seconds per word, seconds per segment \citep{laubli2019translation}. This is considered a critical measure due to its direct economic impact \citep[375]{laubli2019translation}. Time spent on a translation unit may also be interpreted as a sign of mental effort and measured, for instance, as the number of keystrokes and mouse clicks used to produce a target text or segment and \textit{keystroke ratio}, i.e. ratio of keystrokes to the number of characters in the final text or segment (cf. \cite{koponen2012post}). Läubli and Green explain how these measures may be used to evaluate the clarity or efficiency of the UI or interactive TM (ITM): ``In the context of IMT, typing effort is an interesting metric to gauge how often translators make use of suggested translations, e.g., by accepting the completion of a word instead of typing it out'' \citep[375]{laubli2019translation}. A higher-than-expected keystroke ratio may hence be interpreted as a sign for a lack of visibility of the translation aids, which hinders their identification and incorporation into the translation by the user, leading the translator to type the target text rather than simply accept the aid.

Another important aspect in the evaluation of users’ performance is the \textit{quality} of translators’ output. This aspect is essential to consider because ``it can offset gains in speed and usability. Even when a sentence completion feature allows for a 30\% increase in translation speed, if the feature leads users to produce worse translations, then the finding is less (or not at all) meaningful'' \citep[375]{laubli2019translation}. \citep[341--342]{laubli2019translation} explains that the evaluation has typically revolved around the measures of accuracy and fluency to then expand to the dimensions of readability, comprehensibility, and acceptability. Paraphrasing \citet[341--342]{laubli2019translation}, \textit{accuracy} (also called adequacy or fidelity) pertains to the extent to which the translation unit carries the meaning of the source into the target. \textit{Fluency} (also called intelligibility) focuses on the extent to which the translation complies with the rules and norms of the target language. \textit{Readability} relates to the extent to which a defined segment of text can be read by a specified reader. \textit{Comprehensibility} (Closely related to the theoretical construct and measurement of readability) measures to what extent a reader has understood and retained the information contained in a text. \textit{Acceptability} refers to the extent to which a system and its output meet users’ expectations, essentially as expressed in usability research (e.g. \cite{nielsen2010}). Hence through time, the evaluation of translators’ performance has extended from the linguistic level to a broader perspective of the user of translators as a means to evaluate the usability of CAT tools. I call this perspective communicative because it considers translation as an activity of communication with the recipient of translation.

While the evaluation methods above pertain to the translation products, other methods have been used to tap into the translation process and identify problems in translators’ interaction with CAT tools (cf. \cite{o2005methodologies}). Examples include the use of TPR instruments such as TransLog, eye trackers, think-aloud protocols (TAP) and cued retrospective interviews.

The evaluation of translators’ performance when using CAT tools essentially depends on two key variables: the CAT tool and the text to be translated. These may be considered as the two core test materials that may require manipulation to varying extents based on the study aims. Generally, exploratory studies aimed at a holistic evaluation of CAT tool use in real practice call for naturalistic study materials. On the contrary, studies aimed at a more fine-grained evaluation of the UI to develop design recommendations require some degree of manipulation of the study materials to control for influencing variables and ensure that the conditions for meaningful observations are in place. One control measure is the design of the text to be translated during the test. For example, for their study on SDL TRADOS’ AutoSuggest function, \citet{o2010keeping} designed a semi-technical German text of 424 words in 25 segments from the domain of business to be translated into English by subjects. In their study of the optimal format of text presentation for translation and revision, \citet{laubli2020machine} inserted errors into human translations that are unambiguously wrong to measure whether and how quickly study participants could correct these errors within the different UIs. The UI design is another study material that may need to be manipulated to control for influencing variables and zoom in on precise UI design features. For instance, \citet{laubli2020machine} aimed to gain insight into the impact of text segmentation and alignment on users’ performance in translation and revision tasks. To achieve this aim, they presented test participants with different UIs and measured their performance in terms of speed and accuracy.



\subsubsection{User's perception}


Users’ perception of CAT tools is a further source of data commonly used to evaluate the usability of CAT tools. Most commonly, this has been gathered through post-task questionnaires. Authors have used both self-designed questionnaires and previously-existing usability questionnaires, such as the Systems Usability Scale \citep{coppers2018intellingo} and the Software Usability Measurement Inventory \citep{vargas2019usability}. In the development and evaluation of Lilt, \citet{green2014predictive} asked translators to rank the usefulness of translation aids from the most to the least helpful with the aim to identify the preferred features.

\section{Discussion: Usability engineering in CAT}


This chapter contextualised the development of CAT tools within translation technology and discussed the research informing the development of such tools. As emerges from this review, the development of CAT tools was driven by market needs for greater translation volumes at reduced turnaround times and costs rather than translators’ needs. The basic features of CAT tools were mostly defined by ICT experts and implemented in the first commercially available CAT tools without preliminary research on translators’ needs to define requirements and UI design principles. Since then, these first tools have become the industry standard, and the core UI features have remained relatively stable. Although new tools keep emerging on the market, most often is the agency or the client to decide which CAT tool is to be used, which implies that translators are often forced to choose a tool that they find too expensive and less attractive than another one out of the sheer practical need of accessing jobs (cf. \cite{garcia2015computer}). Despite the concern that ``if tool settings and features do not align with translators’ ways of working, then their flow can be interrupted, their cognitive load increased, and their efficacy compromised'' \citep[2]{kappus2020ergonomics}, the design of CAT tools has been rather ``non-user centric'' \citep{moorkens2017assessing}. Indeed, translators’ needs began to be systematically examined only about a decade after the commercial release of CAT tools and focussed empirical investigations of the impact of fundamental UI features on the translator’s work are still scarce (cf. \cite{laubli2020machine}).

Although established market realities are difficult to change, virtuous examples of translator-centred CAT tool development do exist and usability-oriented CAT research can draw on a plethora of methods and a wealth of interdisciplinary experience. Given the commercial interest in leveraging technology to increase the efficiency and quality of translation, CAT tools have been the object of a multitude of studies conducted not just by TS scholars but also by HCI experts.

As discussed in the review, the usability of CAT tools has been explored by means of tool performance, users’ performance, and users’ perception. The studies explicitly aimed at informing CAT tool design are usually characterised by some degree of experimental control, especially in the manipulation of test materials -- primarily, the text to be translated, the task (e.g. translating, revising etc.) and the UI that users have to work with during the test. Studies within this line have produced the most fine-grained analyses of the impact of specific UI features on translators’ performance (e.g. \cite{laubli2020machine}). This line of research has the potential not just to advance scientific understanding of translator-CAI tool interaction and the variables inherent to the UI that influence such interaction. While studies approaching CAT tools with this level of detail remain scarce, they are contributing to developing generalisable principles for CAT tools’ UI design that can ensure that CAT tools are more adequate to translators’ needs. In doing so, they have the potential to pay great service to the profession. As pointed out by \citet[1]{laubli2020machine} ``since the motivation for using CAT tools is primarily economic – saving time by leveraging translation suggestions rather than translating from scratch – the design of these tools is unlikely to change until measurements show that alternative designs speed translators up or cause them to make fewer mistakes''. This reveals the instrumental function of usability research in the development of translation technology -- to increase the inclusion of translators’ views in the development of technology.

Since already mature systems are difficult to change for economic reasons, experts recommend involving translators early on in the design of CAT solutions, advancing the development through iterations of prototyping, testing and revision and incorporating data into the whole development process (cf. \cite{laubli2019translation}), as prescribed by the usability engineering approach (see Chapter \ref{ch:usability_engineering}). Even in the case of already mature systems, research can provide compelling arguments for change. As pointed out by \citet[1]{laubli2020machine} ``since the motivation for using CAT tools is primarily economic – saving time by leveraging translation suggestions rather than translating from scratch – the design of these tools is unlikely to change until measurements show that alternative designs speed translators up or cause them to make fewer mistakes''. This reflection exemplifies the role of research not just to advance scientific understanding but also to drive change. By establishing the heuristic principles of CAT tool design that make UI interfaces maximally efficient and effective, usability-oriented CAT research can contribute to the development of instruments that are adequate to translators’ needs.
