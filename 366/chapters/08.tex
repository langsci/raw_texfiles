\chapter{Second iteration: Main study}\label{ch:second_iteration}

The main study, conducted with 10 practicing conference interpreters, represents the second iteration of prototyping, testing and refinement of SmarTerp at a more mature stage of its development following the implementation of the design recommendations derived from the first test. After the pilot study, the order of appearance of items was changed into the scrolling list order with new items always appearing on top of the list. The prototype was also corrected to achieve ceiling performance (i.e. not to present the errors and omissions that characterised the first study). Only one omission involuntarily occurred in the task NIU. This chapter presents the results of the analysis of performance and perception data.



\section{Users' performance}

\subsection{Task success rates}

Table \ref{tab:22} provides the measures of central tendency in the dataset for the success rates for each task in the interpreting test. As expected, participants achieved a higher success rate on tasks of lowest complexity (AC, NE, NR, TL). NU represents an unexpected exception. The success rates are lower in tasks of higher complexity.

\begin{table}
\begin{tabular}{ll rrr}
\lsptoprule
              &                                       & \multicolumn{3}{c}{\%}\\\cmidrule(lr){3-5}
Code          & Task                                  & {Mean} & {Median} & {Mode} \\ \midrule
AC            & Isolated acronym                      & 100         & 100           & 100         \\
NE            & Isolated named entity                 & 90          & 98            & 98          \\
NU            & Isolated numeral                      & 40          & 0             & 0           \\
NR            & Numeral and complex referent                  & 90          & 95            & 95          \\
NIU           & Numerical  information unit           & 79          & 92            & 92          \\
NCR           & Redundant number cluster              & 73          & 67            & 67          \\
NCN           & Non-redundant number cluster          & 55          & 64            & 67          \\
TS            & Terms in a semantically complex sentence & 45          & 30            & 30          \\
TL            & List of three unknown terms           & 99          & 100           & 100         \\
TE            & Isolated term                         & 90          & 100           & 100         \\
SO            & Complex speech opening                & 60          & 64            & 49          \\
CP            & Conference programme                  & 80          & 79            & 92          \\\lspbottomrule
\end{tabular}
\caption{Success rates: central tendency measures (main study)}
\label{tab:22}
\end{table}




\subsection{Error patterns}

\subsubsection{Acronyms}


Among the tasks of lowest complexity, AC (\textit{isolated acronym}) is the one for which the highest success rate was registered. No specific error pattern was noticed in the rendition of this item, but the use of the visual aid varied across participants: five interpreted the extended version of the acronym only, four interpreted both the short and the extended version and one used the short version only. In the interview, participants explained that they found the support for acronyms advantageous because of the complexity of transcoding the sequence of digits from one language to the other. They also mentioned being provided with both the short and the extended version of the acronym as advantageous because this allows the interpreter to select the most appropriate version based on the audience’s background knowledge and their décalage. Only one participant was observed leaning forward and squinting at the screen to read the acronym more clearly.
\begin{quote}
    \textit{Source}: The signing of the AfCFTA by the African Member States significantly strengthens the movement towards this goal.\\
\textit{Delivery example} (Laila): The signing of the [leans forward to read] AfCFTA, the African Continental Free Trade Area, is aimed at this goal.
\end{quote}

\subsubsection{Named entities}


While participants succeeded in reproducing \textit{named entities}, both in isolation (task NE) and in combination with other problem triggers (tasks SO and CP), recurring errors were noticed, namely pronunciation errors and gender errors. Their frequency and context of occurrence are reported in \tabref{tab:23}.

\begin{table}
\begin{tabular}{ll cc}
\lsptoprule
     &              & \multicolumn{2}{c}{Errors (/10)}\\\cmidrule(lr){3-4}
Code & Named entity &  Pronunciation  &  Gender  \\ \midrule
SO-1    & Paul Kagame                          & 2   & 0  \\
SO-2-1  & Soraya Hakuziyaremye                 & 9   & 2  \\
SO-3-1  & Giovanie Biha                        & 2   & 4  \\
NE-1    & Felix-Antoine   Tshisekedi Tshilombo & 8   & 0  \\
CP-1-2  & Tschisekedi Tschilombo               & 7   & 0  \\
CP-2-2  & Kwesi Quartey                        & 2   & 0  \\
CP-3-1  & Victor Harison                       & 0   & 0  \\
\lspbottomrule
\end{tabular}
\caption{Pronunciation errors\label{tab:23}}
\end{table}

The dataset contains 70 interpretations of named entities in total (7 per participant). Of these, 30 (43\%) were mispronounced. The percentage of mispronunciations climbs to 70--90\% for rare names. The frequency of pronunciation errors was high also for the rare element ``praseodymium'' (TL-1), mispronounced by 3 of 10 participants. Since the occurrence of mispronunciations does not depend on the complexity of the source speech unit, the phenomenon may be ascribed to participants’ difficulty in reading the item. Several participants were observed pausing, leaning forward, and squinting at the screen to read the named entity. In the interview, albeit acknowledging the usefulness of the transcription of named entities, participants reported difficulty in reading complex and long names, and two participants suggested that the mode of display should be adjusted to ease reading during SI. The reading difficulty may have diminished the overall effectiveness of the interpreter-CAI tool interaction and had a broader impact on the delivery than the mere rendition of the item. The delivery sample below exemplifies a recurring error pattern in the dataset, where the delay generated by having to pause and lean forward to read the named entity caused the interpreter to omit or misinterpret some following items.
\begin{quote}
\begin{sloppypar}
    \textit{Source}: Honourable Soraya Hakuziyaremye, Rwanda's MINICOM Minister.\\
\textit{Delivery example} (Jam): Soraya [leans forward to read] ``Hazuziariame'' [Minicom appears] Rwanda’s ∅ Minister [male gender marker, gender error].
\end{sloppypar}
\end{quote}
Coming to \textit{gender errors}, these were moderate to high in two cases. Their occurrence may have several explanations. In some cases, it may be difficult to ascertain the gender by the name and because of the absence of gender markers in languages like English, whereas the target language requires the interpreter to make a choice. At the same time, errors of this kind were observed also when the gender was explicitly stated by the speaker, as in ``Ms Giovanie Biha'' (SO-3-1) interpreted as ``Mr'' by 4/10 participants.



\subsubsection{Isolated numeral}

Another task of low complexity that registered a low success contrary to expectations is NU (isolated numeral). The mean success rate achieved by participants on the task NU was 40\%, with 0\% (in this case signifying a plausibility error) being the most frequent score. A delivery sample is provided below.
\begin{quote}
    \textit{Source}: The continent currently has a gross domestic product of 3.42 trillion USD.\\
\textit{Delivery example} (Molly): The continent has a GDP of 3.42 billion dollars.
\end{quote}

As explained in the discussion of the pilot study results, the order of magnitude trillion ($10^{12}$) was displayed as \textit{bilione} in Italian, which is the correct translation but rarely used -- common alternatives are: \textit{trilione} ($10^{18}$), an incorrect translation but used with increasing frequency as a loanword from English, and \textit{mille miliardi}, a correct and more native alternative but difficult to process during SI and to implement in the CAI tool. Six of 10 participants translated \textit{bilione} (trillion) as \textit{miliardo} and described the tool’s suggestion as a mistake: ``I don’t understand how the tool got that wrong'' (Molly). Seeing \textit{bilione} on the screen, they probably associated it with the English order of magnitude \textit{billion} and translated it into \textit{miliardo} (the Italian order of magnitude for billion). Two of these participants used the tool’s suggestion first and then wrongly corrected it into \textit{miliardo}. Of the remaining four study participants, two opted for the Italian order of magnitude \textit{trilioni} and only two accepted the tool’s suggestion \textit{bilioni}. Hence, albeit correct, the tool’s suggestion seems to have been confusing and disruptive to interpreters, probably due to its low frequency of use. It must be noted that the statement ``Africa’s GDP is 3.42 billion dollars'' corresponds to a plausibility error. Given that we can expect professional conference interpreters to be able to gauge, in normal conditions, the implausibility of this statement, the most likely explanation is that correcting the tool required too much of their attention for them to also check the plausibility of their delivery.

\subsubsection{Lists}

The success rates on tasks of slightly higher complexity -- when a series of terms are presented as a list (TL) or when a numeral is presented together with a complex referent (NR) -- were high, with mean values between 90\% and 100\%. However, some recurring problems occurred in the neighbouring text, as in the example below, where while the information displayed by the tool was rendered accurately, the parenthetical information was misinterpreted. The parenthetical information was rendered completely and accurately by only 1 participant, whereas 7 participants omitted it and the 2 remaining participants misinterpreted it.
\begin{quote}
    \textit{Source}: This year, the market cap of AngloGold Ashanti -- the largest mining company headquartered in Africa -- was 12.13 billion USD.\\
\textit{Delivery example} (Lotta): This year, the market cap of AngloGold Ashanti -- which represents the main headquarter -- eh (.) nearly reached [numeral appears] 12.13 billion US dollars.
\end{quote}




\subsubsection{Terms in semantically complex sentence}

Problems were identified in the delivery when items displayed by the tool were connected by complex logical links. This is the case of the task TS, which presents three terms like TL but, differently from TL, the terms are not presented in the form of a bullet-point list but rather they are embedded in a more complex conceptual structure. The mean success rate dropped from 99\% for TL to 45\% for TS, with median and mode values dropping from 100\% to 30\%. Deliveries of TL break down into 2 correct renditions (100\% success rate), 2 partial renditions (66\% success rate), 4 generalisation strategies (30\% success rate) and 2 semantic errors (0\% success rate), where the interpreter’s delivery was completely different in meaning from the source speech or nonsensical, as in the example below:
\begin{quote}
    \textit{Source}: Furthermore, the porous high-rank coal matrix, with larger hy\-dro\-car\-bon\nobreakdash-stor\-age capacity, makes coal-bed methane reservoirs advantageous for commercial operations.\\
\textit{Delivery example} (Lotta): Furthermore, we must also consider an interesting coal matrix, hence, with a capacity of storage of hydrocarbon and coal-bed methane.
\end{quote}


\subsubsection{Highly complex tasks}


The occurrence of errors in the interpretation of the speech seems to have been more frequent in the most complex tasks, i.e. those characterised by high information density and the co-occurrence of several problem triggers in the speech unit. Mean accuracy rates lay between 60\% and 80\% for tasks presenting by the named entity-acronym-charge sequence (especially SO and partly CP) and 79\% and 55\% for numerical tasks (NIU, NCR, NCN).

The main recurrent pattern that was noticed in these tasks is participants’ tendency to interpret the tool’s suggestions and omit or misinterpret other components of the message not provided by the tool. These components were not provided because of the tool’s functions: they do not classify as problem triggers and hence would not be extracted by the AI.

\begin{sloppypar}
This error pattern had a significant impact on the rendition of the named entity-acronym-charge sequence in the task SO (complex speech opening), where the speaker greeted conference participants. Study participants tended to omit the person’s charge, which was not displayed by the tool, as in the example reported below. With some variations, this is a pattern that was identified in the delivery of every participant, as testified by the fact that none of them scored close to 90--100\% on this task. Two main explanations of this phenomenon were provided by study participants in the interview. The first is that they expected that charges would appear. The second is the difficulty in sharing attention between the acoustic and the visual input due to the excessive latency, mentioned by two participants: ``the latency was too high and so I didn’t hear Rwanda at all'' (Stella).
\end{sloppypar}
\begin{quote}
\begin{sloppypar}
    \textit{Source}: His Excellency Paul Kagame; Honourable Soraya Hakuziyaremye, Rwanda MINICOM Minister, Ms Giovanie Biha UNECA Deputy Executive Secretary.\\
\textit{Delivery example} (Stella): His Excellency Paul Kagame; Soraya ``Hakuziaramie'' from the Ministry of Trade and Industry; Giovanie Biha from the Economic Commission for Africa.
\end{sloppypar}
\end{quote}
This error pattern was identified also in number-dense tasks. In NCN (non-re\-dun\-dant number cluster), the referent ‘diamond production’ was not displayed by the tool. 6/10 participants misinterpreted the referent and, consequently, the whole task. As in the example below, the error pattern consists of an omission of the referent resulting in either a sentence fragment or a misattribution of the arithmetical value to the previous referent.
\begin{quote}
    \textit{Source}: Madagascar alone produced approximately 58,000 metric tons of nickel in 2021. Namibia's diamond production amounted to 2.52 million carats in 2018.\\
\textit{Delivery example} (Mermaid): Madagascar alone has produced 58,000 tons of nickel Namibia 2.52 million of nickel.
\end{quote}
During the interview, one participant (Oscar) explained that he found the suggestions confusing because the item ‘nickel’ remained highlighted. It could be that the persistence of irrelevant stimuli on the screen, combined with participants’ difficulty in sharing attention between the acoustic and the visual input, could be a design-related factor increasing the likelihood of error hence requiring optimisation.



\subsubsection{CAI tool omission}

The test speech presented only one case of CAI tool omission. The omitted numeral was omitted by 6/10 participants and misinterpreted by 1 participant, as in the example below.
\begin{quote}
    \textit{Source}: Analysts forecast that African production of LNG will increase by 150\% from 28 mtpy in 2018 to reach 84 mtpy by 2025.\\
\textit{Delivery example} (Jam): According to forecasts, African production of LNG will increase by 150\% to reach 28 million tonnes per year (.) next year and 84 million tonnes in 2025.
\end{quote}




\section{Users' perception}

\subsection{Post-task questionnaire}

Table \ref{tab:25} reports the measures of central tendency for the post-test questionnaire answers.

\begin{table}
\begin{tabular}{lrrr}
\lsptoprule
                                 & \multicolumn{1}{c}{Mean} & \multicolumn{1}{c}{Median} & \multicolumn{1}{c}{Mode} \\ \midrule
Satisfaction                     & 1.8           & 2\phantom{.5}   & 3             \\
Ease of use                      & 2.2           & 3\phantom{.5}   & 3             \\
Effectiveness                    & 1.9           & 2\phantom{.5}   & 3             \\
Ease of learning                 & 0.8           & 1\phantom{.5}   & 3             \\
Timeliness                       & 0.7           & 0.5             & 0             \\
Dependability                    & 1.4           & 1.5             & 3             \\ \midrule
Likelihood to use   CAI (before) & 1.4           & 1.5             & 2             \\
Likelihood to use   CAI (after)  & 2.4           & 3\phantom{.5}   & 3             \\ \lspbottomrule
\end{tabular}
\caption{Questionnaire results: central tendency measures (main study)\label{tab:25}}
\end{table}

The questionnaire results provide a measurement of participants’ self-reported satisfaction with the tool and their evaluation of usability attributes. These values are shown in \figref{fig:9}, which represents the standard interpretation of scale means based on the UEQ.

\begin{figure}\small
 %   \includegraphics[width=\textwidth]{figures/Picture9.png}
    \begin{tikzpicture}
		\begin{axis}[
			xbar,
			y dir=reverse,
			axis lines* = left,
			width=.9\textwidth,
			ytick={0,1,...,6},
			yticklabels = {Overall sta.,Ease of use,Effectiveness,Ease of leaning,Timeliness,Dependability},
			nodes near coords,
			legend pos = north west,
			legend cell align=left,
			xmin=0,
			reverse legend
			]
			\addplot+[lsDarkBlue]
			coordinates{
				(1.8,0)
				(2.2,1)
				(1.9,2)
				(0.8,3)
				(0.7,4)
				(1.4,5)
			};
			\addplot+[lsMidOrange]
			coordinates{
				(2,0)
				(3,1)
				(2,2)
				(1,3)
				(0.5,4)
				(1.5,5)
			};
			\addplot+[lsLightBlue]
			coordinates{
				(3,0)
				(3,1)
				(3,2)
				(3,3)
				(0,4)
				(3,5)
			};
			\legend{Mean, Median, Mode}
		\end{axis}
	\end{tikzpicture}
    \caption{Questionnaire results: central tendency measures (main study)\label{fig:9}}
\end{figure}

The usability qualities that were attributed the highest value are ease of use and effectiveness. Ease of learning, timeliness and dependability obtained significantly lower scores. The questionnaire results also show participants’ stated likelihood that they would use ASR-based CAI tools in the booth in the near future. The self-reported likelihood after the test is compared with the judgment expressed by participants in the enrolment questionnaire, before testing the tool. It stands out that the self-reported likelihood of using an ASR-based CAI tool increased in 6 cases after testing SmarTerp and the mean value increased from 1.4 to 2.4.




\subsection{Interviews}

\subsubsection{SmarTerp’s UI and technical specifications}

\begin{sloppypar}
In the interviews, several issues were raised by participants concerning SmarTerp’s UI and technical specifications. Participants explained that locating items on the screen was a major difficulty in using the tool. One participant (Jam) reflected on the fact that this process should become automatic for the interpreter for the interaction to be as efficient as possible. Two UI design elements that were seen as facilitating this process were the chronological order of appearance of items (i.e. the scrolling list with new items placed on top, mentioned by 2 participants as a facilitating feature) as well as the highlight of new items or repeated items (mentioned by 2 participants). Other design features were seen as obstructive for the identification of relevant items on the screen. The most frequently reported issue (by 6 participants) is the need for repeated items to be placed at the top of the list. Participants explained that whenever they heard a problem trigger, they immediately looked at the top of the list; if they did not find the information there, ``the eye had to wander'' (Lotta), which in their view decreased the efficiency of the tool. This was the case when a repeated term was simply re-highlighted in its current position (e.g. third item from the top) rather than displayed on top of the list again. One participant reported that she felt disoriented by the fact that acronyms appeared in the terms module, in some cases, and in the named entities column, in other cases, based on whether the acronym abbreviated a term or a name. This forced her to ``look for'' the given item on the screen, which made her lose time and concentration. The fact that items that are not relevant anymore remain highlighted is another factor of complexity mentioned by some participants.
\end{sloppypar}

As far as the tool’s technical specifications are concerned, most participants (8/10) regarded the latency as too high. 3 participants expressed the need to know where the terms come from, which influenced the perceived dependability of the tool. 2 participants suggested that adjusting the display of named entities and providing supporting information, in particular the charges accompanying named entities and the referents accompanying numerals, should help prevent some of the recurring problems identified in the deliveries and increase the effectiveness of the interaction. As far as the transcription of named entities is concerned, one participant suggested adopting a ``syllabified coarse phonetic transcription'' (Oscar)  --  syllabified to aid the identification of phonetic units and ``coarse'' because, differently from a scientific phonetic transcription, this should be easily readable for every interpreter. Another participant suggested adopting a ``sound-like transcription based on the source language'' (Laila), like the one used in publicly available ASRs systems (e.g. Google Cloud, Otter.ai etc.).

Participants’ opinions diverged on some aspects of the interface, which may require more in-depth exploration or customisation. While 5 participants mentioned the division into columns as a strength of the tool, one participant saw this characteristic as an unnecessary complexity; she also predicted that this feature may become overloading in the context of speeches accompanied by PowerPoint presentations. Another controversial aspect was the usefulness of the source and target version of terms and acronyms, essential for one participant and unnecessarily complex for another.

\subsubsection{Perception of usability attributes}


In the interviews, users were asked to justify their evaluation of the usability qualities of SmarTerp. Starting from the usability aspects that received the highest values in the post-test questionnaire, participants’ evaluation of the tool’s effectiveness and ease of use were highest. Based on the interviews, the potential of the tool to improve performance on problem triggers was regarded as the main factor making its use effective (mentioned by 6 participants):
\begin{quote}
    The tool can hugely increase accuracy: where in the past you would have used emergency strategies [e.g., approximation] because of our human limits (in my case, after 20 years in the booth I should interpret numbers with eyes closed, but that’s absolutely not the case) the tool can help you achieve greater accuracy; if you combine your human ingenuity with the technical support, you can reach new heights. I believe that these tools will be compulsory in a few months. (Laila)
\end{quote}
The automatic extraction and display of suggestions and the ``intuitive'' interface were mentioned as the main factors determining the tool’s ease of use. However, some negative aspects were mentioned too as impairments to the tool’s effectiveness and the ease of use. Amongst them, the most common are a sort of ``distraction'' caused by the tool and the need to ``get used to it''. Users’ perception of these issues and their impact on the SI process is reflected in the following quote:
\begin{quote}
    The tool is very useful but also very complex to use: seeing a screen with moving items is not very natural. You must identify items on the screen and even a split second of delay can disrupt the interpretation, especially in highly dense passages. There is also a difficulty in dividing attention between the speech and the tool. Moreover, if you see the suggestions on the screen you feel compelled to say them but if you haven’t understood the overall message, you can’t do much with the suggestions. (Jam)
\end{quote}
Similar positive and negative considerations were made by users on the ease of learning of SmarTerp. This is the usability attribute for which participants’ opinions seem to diverge the most. Most users gave a +3 score to this usability attribute and explained that, in their view, one can start successfully using the tool immediately, without the support of a trainer, since it is ``very self-evident: you get suggestions and what do you have to do? Absolutely nothing. It is foolproof'' (Laila). Other participants referred again to the aforementioned drawbacks (getting used to the tool, the feeling of being ``distracted'' etc.) and added that the ``intelligent'' use (Jam) of the tool may require specific training.

The tool’s timeliness was the attribute that scored lowest on all measures of central tendency, meaning that it was the attribute that received both the lowest mean value and the most negative evaluations. In fact, only two participants found the latency acceptable. The reason is summarised in the quote below:
\begin{quote}
    Too much time went by before the item appeared on the screen: waiting to see it, I lost concentration on what came next and something went lost [in the messages or the rest of the information]. You must remember that the usual speaking pace we are confronted with is very high. Even milliseconds can make a difference. (Stella)
\end{quote}
Finally, participants were asked to evaluate the tool’s dependability and explain what made them perceive the tool as reliable or unreliable. Participants who subscribed to the tool’s reliability explained that they ``expected'' or ``presumed'' it to be accurate. Other users saw possible inaccuracies and omissions as major threats to the tool’s reliability. The main factors that, according to users, should be evaluated are the adequacy of terminological suggestions (mentioned by 4 participants) and ASR performance (4) in the face of real-life challenges, such as different accents, non-native pronunciation, bad sound quality and a slow internet connection, in the case of on-site use of SmarTerp. It must be stressed that the tool’s dependability seems to be a priority for users because, in the speed and complexity of SI, it might be too demanding to check the plausibility of the tool’s suggestion:
\begin{quote}
    In some cases, I realised that the terminological suggestion provided by the tool might not have been the most adequate, but I did not have time to add my own version. Consider what happens when you use a CAI tool during SI: (1) you see the prompt, (2) you read it out, (3) while you read it, you assess its plausibility, (4) you don’t have time to add an alternative solution because you have already committed to the CAI. (Molly)


    It was great to see all those long names and unknown terms on the screen. But I did not have time to examine them while interpreting. Since I had the suggestion, I wanted to use it, but I don’t know if I would in a real-life assignment without knowing whether they are correct. What if they were wrong? (Laila)
\end{quote}
Finally, 4 participants said that they expected items to appear which did not appear (as they were not meant to) and this negatively influenced their perception of the tool’s dependability.

\subsection{Drivers of users’ satisfaction}


The interview questions concerning participants’ self-reported likelihood to use the tool as well as those concerning the major perceived advantages and disadvantages in the use of SmarTerp yield insights into interpreters’ needs in the use of a CAI tool and make it possible to identify some possible factors that may drive their acceptance of such tools in the booth.

A first-time positive experience with the tool (which is commonly referred to as \textit{user activation}) seems to be strongly influenced by the perception of substantial advantages in using the CAI tool. In other words, interpreters whose self-reported likelihood to use an ASR-based CAI tool increased after testing SmarTerp (6/10 study participants) declared to have changed their evaluation because the test made them realise that the tool has the potential to improve their performance beyond expectations, as reflected in the quotes below:
\begin{quote}
    My interest definitely increased: I had a chance to see what the tool can actually give you. (Mermaid)\\
When I saw the opportunity to test the tool, I was sceptical at first. But after testing it, I am very impressed at what it can give you. (Oscar)\\
When I filled out the enrolment questionnaire, I had just tried another technological tool that was meant to enhance consec [the smartpen] but that was a big disappointment and so I was a bit discouraged. But then I saw SmarTerp and it was love at first sight: it is evident that behind the tool there are people who know what the interpreting profession is about. (Lilla)
\end{quote}
Other factors that contributed to users’ activation and overall satisfaction are:
\begin{enumerate}
    \item Improved \textit{accuracy}, mentioned by 5/10 participants who claimed that the tool helped them reduce the number of errors and omissions.
    \item Feeling of greater \textit{security/self-confidence}, mentioned by 5/10 participants who defined the tool as ``a lifeline'' (Mermaid, Jam), ``a parachute'' (Lotta), ``an umbrella when you’re walking under the rain'' (Oscar), and ``a good boothmate'' (Jam), who ``is always there for you, when you’re in need'' (Stella). One participant explained: ``I dread numbers, but this time I was 100 times more relaxed because I knew that I’d land on my feet'' (Laila).
    \item Reduced \textit{effort}, mentioned by 3/10 participants who claimed that they felt less tired because they did not need to retain in memory or write down problem triggers during SI.
\end{enumerate}
However, study participants (particularly but not only those whose self-reported likelihood to use an ASR-based CAI tool did not increase after testing SmarTerp) declared that they would need to assess several aspects of SmarTerp before they could decide to introduce it into their professional practice. Based on the interview data, we may expect that interpreters’ continued use of a CAI tool (a factor known as \textit{user retention}) may be conditional to the following needs:
\begin{enumerate}
    \item Ascertaining the tool’s absolute \textit{dependability}, mentioned by 4/10 participants, who explained that the tool’s dependability is the very prerequisite for using it: ``you must trust that it is 100\% reliable'' (Lotta); ``I wouldn’t want a software telling me wrong things'' (Stella). As explained earlier, dependability is a prerequisite both because of users’ expectations and because it may be too demanding for the interpreter to check the plausibility of the CAI tool, as well as the source speech and the plausibility of their interpretation.
    \item \textit{Testing} the tool in the interpreter’s \textit{work domain}, a need mentioned by 3/10 participants, who suggested that the use of this tool may be more useful in specific interpreting settings or speech types rather than others; for instance, one participant explained: ``in my field, a whole phrase made up of non-technical terms may represent a technical expression which must be rendered precisely into the target language; I doubt that the tool could help me in these cases'' (Jam).
    \item \textit{Comparing} SmarTerp with other ASR-based solutions, mentioned by 3/10 participants.
    \item Hearing other \textit{users’ opinions}, mentioned by 1 participant: ``It looks like a promising development. However, before purchasing such a tool I’d need to consider a few factors (such as its cost) and wait for other interpreters’ reviews and opinions of colleagues'' (Toni).
    \item Evaluating the \textit{costs} of the tool, mentioned by 1 participant.
\end{enumerate}


\subsubsection{Usefulness}

Participants’ reflections on the usefulness of SmarTerp to interpret problem triggers provide insights into users’ expectations on a CAI tool. Users generally believe that the main advantages in using a CAI tool are increasing the accuracy and completeness of the rendition of problem triggers and reducing the mental effort in processing these difficult items:
\begin{quote}
    [Problem triggers] are the elements that most often slip away when we interpret, we do not understand or do not know how to translate. They are also the elements that take up the most space in your brain. (Lilla)
\end{quote}
Through the support of a CAI tool, users expect to reduce errors and omissions in the interpretation of these items. In the case of acronyms, two participants added that being provided with the extended version of the acronym can increase the quality of the interpretation because the interpreter can provide additional information to the audience. At the same time, they expect that the CAI tool will alleviate some of the mental effort by offloading their memory or performing some processing steps for them. For instance, 4/10 participants declared in the interview that they commonly write down numerals when interpreting simultaneously but did not do so during the test because they expected that the tool would do so for them and reported that this way they felt more ``relaxed'' and ``rested''. Finally, some participants reflected on the fact that the tool can be helpful as a confirmation or ``a litmus test'' (Jam), i.e., in all those cases when they are not sure to have understood an item correctly.

These comments also offer insight into the problem situations in which a CAI tool is most likely to be perceived as useful by interpreters:
\begin{itemize}
    \item [a.] Interpreting items not found in preparation: although assignment preparation is a crucial aspect of interpreters’ work, as one participant explained, ``a specialised term you don’t know can always come up'' (Stella).
\item [b.] Dealing with highly technical assignments, which require a high degree of terminological precision by the interpreter.
\item [c.] Interpreting speech passages particularly dense in problem triggers because they are associated with mental effort and a high error rate; in this regard, three study participants mentioned in the interview that a human boothmate may provide wrong suggestions or fail to understand numbers and named entities and, hence, found the virtual boothmate more reliable for these items.
\end{itemize}
In general, we can expect that the CAI tool will be most useful in challenging situations. As one participant explained:
\begin{quote}
    The usefulness of the tool depends on the problem: a CAI tool is very useful for streams of numbers or numbers combined with a complex term. If the sentence to be interpreted is ``population amounts to 150.000'' you can make it by yourself. (Molly)\end{quote}

In the same way, participants reflected on the usefulness of the tool for particularly complex named entities, such as long names, unknown names, foreign names with a difficult pronunciation or names mispronounced by a foreigner.

In another section of the interview, study participants were invited to reflect on the differences between the virtual and the human boothmate. In general, they see consistency of performance accuracy (mentioned by 5 participants), readability (3) and availability (2) as a strength of the virtual boothmate compared to the human one. As explained by study participants, ``human boothmates come and go, your CAI is always the same'' (Toni); the virtual boothmate ``gives you everything you need without complaining'' (Oscar), ``it is always there: it doesn’t go on coffee break, it doesn’t go to the toilet'' (Lilla), ``it doesn’t get tired'' (Jam), ``it doesn’t get distracted'' (Laila). 4 participants stressed the objective user-tool relationship as an advantage: while interpersonal factors influence the relationship with the human boothmate, the use of the virtual boothmate is solely dependent on the interpreter’s individual needs:
\begin{quote}
    It sometimes annoys me when colleagues are too helpful, but what can you do? It would be impolite to ask them to stop it or look away. The tool doesn’t take offence if I ignore it. (Molly)
\end{quote}
However, the tool is perceived as less reliable when it comes to terminology (2 particiapnts): the human boothmate is seen as a more reliable help because s/he can select the right term in context by virtue of his/her professional experience in the field. At the same time, the tool is seen as limited when it comes to providing help on the colleagues’ overall understanding of the speech (2 participants).

When asked which context of use they would prefer for the tool (online, on-site or both), all participants replied ``both''. The general tendency is that of preferring online use because of the possible technical barriers to on-site use (unstable or unavailable interpret connection, cables required to connect the tool etc.). They also declared that in the context of combined use of human and virtual boothmate, they would prefer to use mostly the virtual boothmate and have the human boothmate serve as a ``back up'' helping in case of the tool’s failure, checking the accuracy of the tool, monitoring the plausibility of the interpretation, and helping the interpreter when the overall meaning of the utterance is not clear to them.



\subsubsection{Difficulty in using the tool}


During the test, study participants also perceived possible disadvantages in the use of a CAI tool, which negatively affected their overall satisfaction. The ones reported most often are:
\begin{itemize}
    \item [a.] \textit{Failure to attend to the acoustic input}: participants explained that when they were looking at or waiting for the visual input, they lost their focus on the source speech. Because of this excessive attention on the visual input, participants explained that they failed to acoustically perceive elements in the immediate linguistic context, such as the charge associated with a person’s name or the referent of a number, as shown earlier in the analysis of participants’ performance.
\item [b.] \textit{Loss of concentration on the overall meaning of the message}: one participant mentioned the fact that interpreters should always be able to ``retell the story'', i.e., to grasp the general meaning of the utterance rather than just transcode words; he then explained that a high degree of accuracy for specific items at the expense of holistic understanding may be a threat in the use of in-booth CAI support.
\item [c.] \textit{Indiscriminate consultation}: a further risk may lie in making indiscriminate, non-strategic use of the tool, i.e., consulting it and relying on its input also when an alternative strategy may have been more effective. For example, Mermaid mentioned that she usually repeats the sound of unknown named entities; during the test, instead, she only looked at the tool and, in doing so, did not attend to the sound; since she found it difficult to correctly read out the long foreign names, she suggested that listening to and trying to reproduce the sound might have been a better strategy.
\item [d.] \textit{Reliance-agency balance}: some participants mentioned that they expected the tool to help them, as for the participants who usually write down numerals but did not this time. This exposes them to problems if the tool is inaccurate or it presents limitations. For instance, one participant explained ``sometimes I expected items to appear but they did not'' (Oscar) and another commented, ``if the tool helps you twice, you expect that it will help you a third time'' (BCM). As discussed earlier in the report, this is reflected in the omissions of the item omitted by the CAI tool as well as the failure to interpret items not displayed by the tool because of its functions.
\end{itemize}












\section{Usage problems and design recommendations}

In this study, several usage problems were identified leading to recommendations for the improvement of the CAI tool SmarTerp. Below, they are divided into issues related to the CAI tool’s general UI design features, the particular characteristics of how problem triggers are displayed, and the tool’s technical specifications.




\subsection{UI design}

In the pilot study, it was noticed that the sequential order of appearance of items (ABCD, E $\longrightarrow$ A, F $\longrightarrow$ B, etc.) was confusing to users, who reported difficulty in locating relevant information on the screen. The SmarTerp developers hence changed the order of appearance to chronological (scrolling list with new items appearing on top). Repeated items were not repeated but only highlighted in their current position in the list. In the main study, two participants spontaneously mentioned the chronological order of appearance as ``ideal''. However, six users still found that the highlight of repeated items in their current position (e.g. third place from the top of the list) without moving them back to top represented an impediment to the detection of relevant input. In their view, relevant items should be always placed on top because that’s the spot on the screen where they spontaneously directed their gaze when they heard or anticipated a problem trigger. The preparatory direction of the gaze onto the spot where items are supposed to appear might be one of the processes in CAI tool use that become automatic with repeated usage and make the interpreter-CAI tool interaction more efficient and effective. We, hence, recommend placing new items on top of the list to increase the tool’s consistency favouring the development of automatic behaviour. However, the items should not be repeated to avoid unnecessary clutter. Two solutions are possible to avoid repetitions: (a) the repeated item moves from its current position to the top of the list and all the other items descend to fill the gap (which one study participant referred to as ``Tetris mode''); (b) the repeated item swaps place with the item at the top of the list. The first option implies more movement on the screen, which may be either a distractor or a feature facilitating tool consultation thanks to the evident sign that a new item is being provided. While, at the current state of research, we cannot judge whether the scrolling of items would be advantageous or not, the first option allows us to keep the chronological order in the items on the screen: as the repeated item moves to the top, the second most recent item moves to the second position in the list. Since this mode of display is more consistent with the chronological order of appearance of new items, we recommend adopting this mode of display.

In order to facilitate the detection of items on the screen, it also seems recommendable to remove and/or de-highlight items when they are not relevant anymore. We currently do not know what the optimal length of permanence of items on the screen is. A solution could be to give users the option to decide whether they want items to disappear and customise the length of permanence (e.g. items disappear 30 seconds/1 minute/2 minutes etc. after they were pronounced). A safer option to implement may be to de-highlight items after a certain time length (which may be customised too). In users’ performance, some misattributions (i.e. interpretations in which a numeral is linked to the wrong referent) were interpreted as usage problems triggered by the fact that no longer relevant items remained highlighted. We noted that the referent constituting the previous numerical information unit persisted on the screen as a highlighted item, while the current referent had not been displayed. We hence hypothesised that the permanence of irrelevant highlights might be a factor confusing users.

By the same rationale, it seems recommendable to enable users to switch on and off the tool as well as individual modules to reduce clutter and satisfy interpreters’ need for personalised help. Allowing users to customise the order of the modules within the CAI tool interface may also fulfil this purpose: users may benefit from the opportunity to place modules in the order that they find more logical or fields in the position that is most salient for them.





\subsection{Display of problem triggers}

The test confirmed some of the design team’s hypotheses about the optimal display of individual problem triggers and confuted other ones, pointing to some optimisation potential. Our data suggest that not all interpreters may find the display of both source and target language of acronyms and specialised terms equally important -- an idiosyncrasy which we observed both in the pilot and in the main study. Some interpreters feel that the source language adds reliability to the term. Others find the input excessive and superfluous since, as some argued, interpreters do not have enough time to compare source and target during SI. Hence, it seems recommendable to enable users to decide whether both source and target language or only one of both should be displayed. At the same time, users expressed the need to know the provenance of the terms displayed by the tool to gauge whether these are reliable or not. The UI may signal (through a colour code or an icon) whether the term/acronym comes from the interpreter’s glossary or has been retrieved from other terminological sources, which was seen as a major factor affecting the tool’s dependability.

When it comes to named entities, in the light of the high frequency of pronunciation errors, using an alternative graphic representation, such as a sound-like phonetic transcription (possibly syllabified) as suggested by study participants, should be explored in the future. The occurrence of gender errors also points to the fact that users may benefit from having access to additional information about the person, organisation etc. that is being mentioned. A possible option is introducing a pop-up window that opens upon mouse hovering displaying a picture and some fundamental information about people that are mentioned, and possibly other named entities (such as places, names of organisations etc.) too.

Finally, coming to numbers, our observations concern the mode of display of numerals as well as the number of components of the numerical information unit which are provided. In designing the tool, we decided to display digits as Arabic numerals (with target-language punctuation) and provide the order of magnitude, if above ‘thousand’, as a target-language word. This choice was aimed at supporting interpreters in the last phase of numeral processing, which is recoding from Arabic graphic code into target-language phonological code. Compared to previous studies, which displayed the whole numeral in the Arabic code (e.g. \cite{canali2019technologie}) or a combination of Arabic digits and source-language orders of magnitude (e.g. \cite{pisani2021measuring}), in our study, no syntactic errors were identified for orders of magnitude ‘million’ and ‘billion’, which supports the effectiveness of our design strategy. However, a major problem was identified in participants’ recoding of the order of magnitude ‘trillion’ (task NU, isolated numeral). Participants had difficulty gauging the reliability of the suggestion and either corrected it wrongly or chose an alternative translation. Note that simply replacing the order of magnitude with another terminological alternative would not represent a definite solution to the problem. The problem that may occur in all languages in the translation of rare orders of magnitude, especially where the target language does not present a univocal translation and one of the solutions may cause ambiguity under the influence of source-language interference. While it is difficult to propose a definite, one-size-fits-all solution, several options should be tested, and perhaps the alternative that is gauged as correct and unambiguous by most interpreters should be chosen. Furthermore, it seems necessary to explain to interpreters how orders of magnitude were translated. Coming to the amount of information displayed, the number was displayed together with the following element in the same item box, which typically is the referent or the unit of measurement. The initial hypothesis was that it might be ideal to display both referent and unit of measurement together with the numeral to provide the interpreters with the core of the numerical information unit. However, this is currently not possible because the syntactic position of NIU components may vary, and these are not always problem triggers recognised by the AI engine. After having observed that recurrent and severe errors occurred when interpreters were not provided with the referent, the research team wondered whether an alternative mode of display (e.g. a running transcript) might be better for numbers. Another option to avoid overloading the interface could be having a pop-up window with the transcription of the sentence containing the numeral open at the click of the mouse or through mouse hovering, so that interpreters may be able to selectively look at the broader context in which the item occurred.



\subsection{SmarTerp's technical specifications}


Coming to SmarTerp’s technical specifications, a first reflection pertains to the decision of whether to favour precision over recall, as recommended by \citet{fantinuoli2017speech}. Fantinuoli hypothesised that ``if a priority has to be set, precision has priority over recall, in order to avoid producing results that are not useful and may distract the interpreter''. The fact that study participants expressed the need for the tool to be 100\% reliable (dependability was defined as a prerequisite for the adoption of the CAI tool) may be considered as empirical evidence for this principle.

The excessive latency was pointed out by study participants as a major shortcoming of the CAI tool. In their view, error patterns such as the failure to perceive other components of the message were, at least partly, caused by the excessive latency. It could be that latency places a burden on interpreters’ working memory (cf. \cite{cowan2010magical}). If the interpreter waits to see the item appear on the screen to produce the target speech, his/her working memory may become overloaded by retaining understood but not-yet-interpreted items. This may either cause inaccuracy in the interpretation of the already-processed speech segment or make it impossible to listen and understand the subsequent speech segment. In the test, all items appeared at constant two-second latency, which, at the time of writing, is the lowest possible latency achieved by CAI tools. Even if technological advancement makes it possible to further reduce latency in the future, it may not be expected that this will consistently be lower than 2 seconds. Rather, it seems recommendable to train interpreters on how to effectively adjust their décalage to use the CAI tool as productively as possible.

In observing study participants interact with the CAI tool, I noticed two distinct approaches to adjusting décalage to the CAI tool latency (see example below). By the first approach, the interpreter interpreted the already-understood source speech segment without waiting for the item to appear. When the item did appear, s/he integrated it into her delivery. By doing this, décalage was close to the source speech rather than dictated by the tool’s latency. By the second approach, the interpreter followed the CAI tool and waited for items to be displayed to start producing the source speech segment. décalage was hence dictated by the tool’s latency. Interpreters who successfully implemented the first approach (\textit{following the speaker, not the tool}), were the best performers in complex and dense speech passages (e.g. SO, NCR, NCN). Interpreters who adopted the second approach (\textit{following the tool, not the speaker}) were generally less successful at coping with complex speech passages. Their delivery was often characterised by errors in the second or third sentence, possibly because of memory overload. If this hypothesis gets confirmed by future evidence, it could mean that interpreters’ décalage strategy may offset a possible disadvantage derived by CAI tool latency.

\begin{quote}
    \textit{Source}: In 2019, Africa produced nearly 8.41 mbd [million barrels per day] of oil. Madagascar alone produced approximately 58,000 metric tons of nickel in 2021. Namibia's diamond production amounted to 2.52 million carats in 2018.

\textit{Delivery example 1} (interpreter following the speaker): In 2019 Africa [2019 appears] produced about 8.41 million barrels per day of oil. Madagascar alone produced 58.000 tons of nickel in 2021. Diamond production in Namibia amounted to 2.52 million carats in 2018.

\textit{Delivery example 2} (interpreter follows the tool): Africa produced, as far as oil is concerned, [Madagascar appears] 8.41 million barrels per day, as far as Madagascar is concerned also 58,000 tons [Namibia appears] in Madagascar. Instead, as far as Namibia is concerned, we talked about 2.56 million increase of nickel production.
\end{quote}
