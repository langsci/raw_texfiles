
\chapter{Sonority: Background}\label{sec:background}

\emph{Sonority} is a fundamental notion in phonetics and phonology, playing a crucial role in accounts of the syllable in linguistic theory (as a good indication in support of this claim, \citealt{parker2018abib} cites 2413 titles involving sonority).
The topic of sonority can be roughly divided into two related theoretical constructs:
(i) \emph{sonority hierarchies} (or \emph{scales}) and;
(ii) \emph{sonority principles} (or \emph{generalizations}).
Sonority hierarchies locate all speech sounds on a single scale, while sonority principles are universal generalizations about the well-formedness of syllables. Sonority principles require a sonority hierarchy to model the well-formedness of syllables given their underlying sequence of consonants and vowels.
Thus, a model of sonority is capable of predicting distributional patterns of consonants and vowels in all human language systems in terms of \emph{phonotactics} -- preferences and restrictions with regards to possible combinations of segmental sequences.

Sonority hierarchies and principles are designed to model speech in discrete terms. Thus, sonority models standardly express sonority in terms of integers that are associated to classes of consonants and vowels along an ordinal sonority hierarchy. Syllabic well-formedness is computed from the concatenation of these values in symbolic time (i.e.~from linearly ordered non-overlapping symbols). This type of modeling lacks robust cognitive motivations as it assumes -- explicitly or implicitly -- that linguistic processing is analogous to the workings of a computer despite strong evidence to the contrary (see \chapref{sec:lingMod} and especially \sectref{sec:risenfall}).

Although widely used and accepted, the notion of sonority at the same time remains vague and highly contested for various reasons. To date, no real consensus exists with respect to the phonetic basis of sonority in terms of a consistent articulatory or perceptual phenomenon
which sonority distinctions could be derived from.
This results in a
multitude of different sonority hierarchies. Furthermore, the lack of a phonetically useful metric for sonority plagued most sonority models with inherent circularity, as sonority hierarchies are often both determined and confirmed by attested segmental combinations, without recourse to any independently motivated phenomenon \citep{ohala1992alternatives}.
Moreover, sonority principles such as the widely used \emph{Sonority Sequencing Principle} (SSP) have been taken as axioms with formal definitions that lack an explicit functional motivation relating to speech articulation or perception.
This choice of architecture for the SSP resulted in some of the persistent failures of SSP-based models, such as the unpredicted prevalence of \emph{/s/-stop} clusters on the one hand, and the unpredicted rarity of sonorant plateaus on the other (see \sectref{sec:problems}).

\section{Hierarchies and principles}\label{sec:hierandprince}

\subsection{Sonority hierarchies}\label{sec:hierarchies}

A sonority hierarchy is a single scale on which all consonant and vowel types can be ranked relative to each other.\footnote{Note that a related notion of \emph{strength hierarchies} makes similar distinctions, yet in the opposite direction (stronger = less sonorant). Strength hierarchies are mostly evoked in relation to lenition processes rather than phonotactic phenomena.}
Such hierarchies can be traced back centuries, and concepts akin to sonority hierarchies can be found already in the pioneering works of early Sanskrit grammarians.
\citet{Donegan1978onthenatural} notes that Pāṇini and the Sanskrit grammarians used the term \emph{svara} to imply some kind of harmonic musical quality which applies mainly to vowels.
%Parker (2002, p. 58) 
\citet[58]{parker2002quantifying} notes further that the Sanskrit grammarians observed natural classes for speech sounds that are \enquote{grouped according to their degree of \enquote{opening} (\emph{vivāra})}.
Early versions of current sonority hierarchies are often dated to \citet{sievers1893grundzugesk, jespersen1899fonetiksk}, and \citet{whitney1865relation}, while \citet{ohala1992alternatives} even goes as far back as \citet{debrosses1765traite}.

While the phonetic basis of sonority hierarchies remains controversial, phonological sonority hierarchies have been primarily based on repeated observations that revealed systematic behaviors of segmental distribution and syllabic organization within and across languages. The general consensus regarding the phonological sonority hierarchy thus stems from attested cross-linguistic phonotactic behaviors of different segmental classes, such as, for instance, the preference for \emph{stop-liquid} sequences in onset positions (e.g.~/kl/ in the English word \emph{\textbf{cl}ean}) and for the mirror-image \emph{liquid-stop} sequences in coda positions (e.g.~/lk/ in the English word \emph{mi\textbf{lk}}), but not the other way around.
See examples in \citet{zwicky1972notesk, selkirk1984majorsk, parker2002quantifying, jany2007universal}, and recall
%Ohala's \citeyear{ohala1992alternatives} 
\citegen{ohala1992alternatives}
related criticism regarding the circularity that results from determining sonority hierarchies according to attested behavior without another independent (phonetic) variable (see also \citealt{yin2023frequent}).

Most common phonological sonority hierarchies group segment types into classes that primarily reflect the standard \emph{manners of articulation} in traditional phonology. The distinct categories commonly used include \emph{stops}, \emph{fricatives}, \emph{nasals}, \emph{liquids}, \emph{glides}, and \emph{vowels}, often with additional distinctions such as voicing and vowel height.\footnote{The group of \emph{liquids} is the most loosely defined, as it includes both \emph{lateral approximants} (namely /l/) and various types of rhotics such as \emph{trills} (/r, ʀ, ʁ/), \emph{taps} (namely /ɾ/), and alveolar and retroflex \emph{approximants} (/ɹ, ɻ/).} Although there are many different proposals for sonority hierarchies (\citealt{parker2002quantifying} found more than 100 distinct sonority hierarchies in the literature), a very basic hierarchy that seems to reach a considerable consensus, and is often cited in relation to 
%Clements's \citeyear{clements1990role}
\citegen{clements1990role} 
seminal paper is given in (\ref{ex:scale}).

\begin{exe} 
\ex Obstruents $<$ Nasals $<$ Liquids $<$ Glides $<$ Vowels  \label{ex:scale} 
\end{exe}

The ordering of different speech sounds along the sonority hierarchy is assumed to be universal,
in line with the common assumption that sonority has a phonetic basis in perception and/or articulation, yet the patterning of segmental classes as distinct groups along the scale is considered to be language-specific, i.e. based on phonological categorization.
For example, voiceless stops may be considered universally lower than voiced fricatives on the sonority hierarchy, yet for some languages and analyses they may constitute a single level of \emph{obstruents}. Classes along the sonority hierarchy are most commonly modeled as a series of integers (often referred to as sonority indices) reflecting the ordinal nature of phonological interpretations of the sonority hierarchy.

The main differences that result from variation of the basic hierarchy in (\ref{ex:scale}) concern the class of obstruents, which may contain voiced and voiceless variants of stops and fricatives (to mention just the most prominent distinctions).
It is therefore not uncommon to expand the class of obstruents, whereby stops are lower than fricatives and voiceless consonants are lower than voiced ones.
Note that vowels are often also commonly divided into subgroups along the sonority hierarchy (see \citealt{gordon2012sonority}), but these distinctions will be irrelevant in the context of this work.

The two variants of sonority index values given in \tabref{tab:hierarchy} thus reflect two ends of a common sonority hierarchies spectrum. These range from hierarchies that collapse all obstruents together into a single class (resulting in the same sonority index value for all obstruents), to hierarchies that expand the class of obstruents by employing voicing distinctions as well as manner distinctions between stops and fricatives (resulting in multiple sonority index values within the class of obstruents). In what follows I will refer to these two versions of the sonority hierarchy as \emph{H}\textsubscript{col} for the \emph{collapsed} sonority hierarchy, and \emph{H}\textsubscript{exp} for the \emph{expanded} sonority hierarchy.




\begin{table}
\caption{\label{tab:hierarchy}Traditional phonological sonority hierarchies. 
%\textit{Note:} 
Index values reflect the ordinal ranking of categories in sonority hierarchies. The obstruents in \emph{H}\textsubscript{col} are collapsed into one category (bottom four rows = 1), while in \emph{H}\textsubscript{exp} they are expanded into four distinct levels.}
\begin{tabular}{ccll}
\lsptoprule
\multicolumn{2}{c}{{Sonority index}} & &\\\cmidrule(lr){1-2}
\multicolumn{1}{c}{\emph{H}\textsubscript{col}} & \multicolumn{1}{c}{\emph{H}\textsubscript{exp}} & Segmental class & Phonemic examples\\
\midrule
5 & 8 & Vowels & \multicolumn{1}{l}{/u, i, o, e, a/}\\
4 & 7 & Glides & \multicolumn{1}{l}{/w, j/}\\
3 & 6 & Liquids & \multicolumn{1}{l}{/l, r/}\\
2 & 5 & Nasals & \multicolumn{1}{l}{/m, n/}\\
\textbf{1} & \textbf{4} & Voiced Fricatives & \multicolumn{1}{l}{/v, z/}\\
\textbf{1}& \textbf{3} & Voiced Stops & \multicolumn{1}{l}{/b, d, g/}\\
\textbf{1}& \textbf{2} & Voiceless Fricatives & \multicolumn{1}{l}{/f, s/}\\
\textbf{1}&\textbf{1} & Voiceless Stops & \multicolumn{1}{l}{/p, t, k/}\\
\lspbottomrule
\end{tabular}
\end{table}

\subsection{Traditional sequencing principles}\label{sec:principles}

Sequencing principles can be understood as a mapping scheme between the ranks of a sonority hierarchy and the linear order of symbolic speech segments.
Modern formulations of such principles, which use the ordinal sonority hierarchy to generalize over the phonotactics of consonantal sequences in terms of \emph{sonority slopes} were developed mainly throughout the 1970s and 1980s in seminal works such as \citet{zwicky1972notesk, hankamer1974sonority, hooper1976introduction, kiparsky1979metrical, lowenstamm1981maximal, steriade1982greek, cairns1982markedness, selkirk1984majorsk, harris1983syllablesk, mohanan1986theory} and \citet{clements1990role}.

Sonority index values, indicating a rank on the sonority hierarchy, can be readily plugged into models that are able to predict distributional patterns of segments vis-à-vis syllabic organization in terms of sonority slopes. Consonants and vowels in a given string are interpreted as a sequence of discrete points in symbolic linear time. The corresponding sonority index values that are associated with these segments are then interpreted in terms of slopes that result from interpolation over the sequence of points. Thus, for instance, going from a low ranking segment to a high one is considered to yield a rising slope, while two adjacent segments that share the same sonority index yield a plateau. Importantly, the notion of the \emph{syllable} is required to define the ranges and types of preferred slopes, which rise from the onset of the syllable to its nucleus and fall from the nucleus of the syllable to its coda. Syllabic well-formedness is therefore defined in terms of universal generalizations over the preferred and dispreferred types of sonority slopes that result from the concatenation of different consonants and vowels, and their grouping into syllables.

The most basic and widely used sonority-based principle that derives phonotactic predictions in terms of syllabic well-formedness is the \emph{Sonority Sequencing Principle} (SSP). The SSP is a simple yet powerful generalization about phonotactics that has been evidently useful in countless theoretical accounts. It identifies three distinct types of slopes -- \emph{rises}, \emph{falls}, and \emph{plateaus} -- such that sequences of segments should rise in sonority from the consonant(s) in the syllabic onset to the syllable's nucleus (most often a vowel) and fall from the nucleus to the consonant(s) in the syllabic coda. In this project, I focus on syllable-initial onset consonant clusters that precede a vowel, whereby a rising sonority slope (e.g.~\emph{plV}) is considered well-formed and a falling sonority slope (e.g.~\emph{lpV}) is considered ill-formed (see \figref{fig:slopes-pl-lp}). Sonority plateaus (e.g.~\emph{pkV}) fare in between, giving way to various interpretations depending on the language and analysis. As such, plateaus may be considered as ill-formed or well-formed (e.g.~\citealt{blevins1995syllable, asherov2019syllablesk, bat1996selectingsk}), although they are generally interpreted as denoting a third, mid-level of well-formedness.


\begin{figure}
\includegraphics[width=.8\textwidth]{figures/graphics-slopes-pl-lp-1} 
\caption{Schematic depiction of the sonority slopes of two onset clusters, \emph{plV} and \emph{lpV}. The red line denotes the sonority slope of the onset cluster (i.e.~the two onset consonants), while the grey line denotes the slope between the second consonant and the vowel at the nucleus position (always a rise in these cases). The angle of the red lines reflects the well-formed rising sonority slope of the onset cluster in \emph{plV} and the ill-formed falling sonority slope of the onset cluster in \emph{lpv}.}\label{fig:slopes-pl-lp}
\end{figure}

The concept of \emph{Minimum Sonority Distance} (MSD; \citealt{steriade1982greek, selkirk1984majorsk}) is a well-known elaboration on the preferred angle of sonority slopes compared to basic applications of the SSP, given that the SSP makes no distinction between different angles of rising or falling slopes. The MSD was designed to prefer onset rises with steep slopes over onset rises with shallow slopes, under the assumption that consonantal sequences in the onset are preferred with a larger sonority distance between them. For instance, \emph{plV} has a steeper rise compared to \emph{bnV} and it is therefore better-formed according to the MSD (see \figref{fig:slopes-pl-bn}).

The \emph{Sonority Dispersion Principle} (SDP; \citealt{clements1990role, clements1992sonority}) is a slightly different yet related principle that prefers onset rises with a large distance and an equal dispersion of sonority index values across the consonantal sequence and the following vowel. The results of the SDP are highly contingent on the given sonority hierarchy and it is not very clear how to apply the SDP formula with onset sonority falls (among other problems listed in \cite[22--24]{parker2002quantifying}). The SDP is therefore not comparable as a model that can generate the full set of well-formedness predictions for onset clusters. Indeed, the SDP is mostly invoked in relation to other generalizations that it makes about the status of the onset versus the coda (not directly related to consonantal clusters), by assuming that onsets prefer to maximize sonority distance from the following nucleus while codas prefer to minimize it.



\begin{figure}
\includegraphics[width=.8\linewidth]{figures/graphics-slopes-pl-bn-1}
\caption{Schematic depiction of the sonority slopes of two onset clusters, \emph{plV} and \emph{bnV} (the red solid line denotes the sonority slope of the onset clusters). The angle of the red lines reflects a steeper rise for \emph{plV} (left) compared with \emph{bnV} (right), due to the larger sonority distance between the consonants in \emph{plV}.}\label{fig:slopes-pl-bn}
\end{figure}

\section{Problems with standard sonority theory}\label{sec:problems}

\subsection{Slippery sonority slopes}\label{sec:slippery}

The widely accepted use of sonority slopes in order to explain and predict phonotactic behaviors has been adopted by many researchers with only few changes such as the above-mentioned elaborations on the angle of sonority slopes (e.g.~the MSD). This is a strong testament to the simplicity and power of the concept of sonority slopes. However, given that the role of slopes is essentially formal, with no explicit functional motivation from articulation, perception or cognition, they remain open for interpretation.
In other words, since sonority slopes are not tied to functional aspects such as degree of jaw opening, or the degree of perceived loudness, they pose no inherent limit on what type of phonotactic behavior they can be used to explain and predict.
Indeed, sonority slopes have been used in attempts to explain practically all types of phonotactic phenomena, regardless of their different potential sources.
This over-application of sonority slopes has resulted in various contradictions in the sonority literature (such as the case of \emph{/s/-stop} clusters, see \sectref{sec:failures}), which were highlighted in some prominent objections to a notion of sonority that is not phonetically motivated and appears to act like a cover term for various functionally-different processes (e.g.~\citealt{ohala1984prosodic, henke2012isthessp, laks1995connectionistsk, ohala1992alternatives, steriade1999alternativessk, wright2004review}).

Traditional sonority accounts formalize sonority principles in terms of slopes that are obtained from the sonority index values of members of a consonantal cluster, where only the difference, or distance, between segments in a sequence is taken into account. This suffices to characterize the rough angle of the sonority slope, but not its underlying power, which could potentially differentiate between a low sonority sequence and a high sonority sequence that have the exact same type of sonority slope (see Figures~\ref{fig:slopes-ml-ps} and \ref{fig:slopes-nm-sf}).
To cover this aspect of the sequence, it suffices to obtain the sonority index value of the most marginal member of a sequence alongside the information about the slope of that sequence.
For onset sequences, the most marginal member is the first segment that reflects the sonority \emph{intercept} of the onset sequence.
In the context of the current study, which focuses on complex onset clusters consisting of biconsonantal sequences, the slope is the difference between members of a sequence and the intercept is the sonority index value of the first consonant.

Intercepts play no role in the characterization of traditional sonority profiles although they are informative with respect to the amount of underlying sonority that a certain slope carries. This is a curious fact given that sonority-based accounts stem from the assumption that sonority quantities have an effect on the observed phenomena. \citegen{clements1990role} SDP was actually designed to prefer less sonorant onsets, which could account for this aspect of sonority profiles, but, as mentioned above in Section~\ref{sec:principles}, the SDP has a host of problems that prevent it from becoming a full model (e.g.~it is not designed to account for falling consonantal slopes in onsets).
Crucially, the SSP and MSD do not account for this aspect at all, as they only look at sonority slopes.
Presumably, it is the propensity for simple and elegant rather than functional generalizations in many theoretical linguistic traditions (see \citealt{chomsky2021simplicity}) that cemented the formal architecture of sonority principles with a maximally reduced conception of sonority slopes.

Taken together, the over-application of traditional sonority principles that employ a highly reduced conception of slopes leads to consistent cases of misinterpretation of sonority principles, wherein superficially similar qualities are treated as similar regardless of their underlying differences in quantity. For example, the rising slopes in \emph{mlV} and \emph{psV} (see \figref{fig:slopes-ml-ps}), are treated similarly in hierarchies such as \emph{H}\textsubscript{exp} regardless of their underlying differences in quantity, which are reflected by their different intercepts:
the cluster /ml/ has a higher underlying sonority level than the comparable sonority rise in the cluster /ps/.
A similar generalization holds for the two plateaus in \figref{fig:slopes-nm-sf} below, in Section~\ref{sec:failures}.



\begin{figure}
\includegraphics[width=.8\linewidth]{figures/graphics-slopes-ml-ps-1}
\caption{Schematic depiction of the sonority slopes of two sonority onset rises, \emph{mlV} and \emph{psV}, with comparable angles but different intercepts. The red solid line which denotes the sonority slope of the onset clusters is higher for \emph{mlV} (left) than for \emph{psV} (right) due to the higher intercept of /m/ compared to /p/.}\label{fig:slopes-ml-ps}
\end{figure}

\subsection{Inherent failures of traditional sonority principles}\label{sec:failures}

\subsubsection{/s/-stop clusters are well-formed}\label{s-stop-clusters-are-well-formed}

One rather well-known and well-studied consistent flaw in the empirical coverage of all traditional sonority principles concerns sequences that are often termed \emph{/s/-stop clusters}, referring to cases where a sibilant fricative -- most often /s/ -- precedes a stop consonant, like in the English words \emph{\textbf{st}op}, \emph{\textbf{sk}y} and \emph{\textbf{sp}ort} (see, e.g., \citealt{fudge1969syllables, goad2011representation, kenstowicz1994phonology, olender2013acousticsk, vaux2009append, wright2004review, yavacs2008sonority}). The sonority slope of \emph{/s/-stop} clusters is either an onset fall or an onset plateau, depending on the given sonority hierarchy (see \figref{fig:slopes-sp-sp}). Thus, although \emph{/s/-stop} clusters are relatively common in languages that tolerate sequences and should therefore be considered as relatively well-formed (\citealt{morelli2003relative, steriade1999alternativessk}), such clusters are predicted to be rare, or even extremely rare, due to their ill-formed sonority slopes.

As can be seen in the sketches of the syllable \emph{spV}, illustrated here in \figref{fig:slopes-sp-sp} with two different sonority hierarchies, the sonority slopes of the consonantal sequence (red solid line) is either a fall or a plateau depending on the given sonority hierarchy (\emph{H}\textsubscript{col} vs.~\emph{H}\textsubscript{exp} in \tabref{tab:hierarchy}). The very low intercept of the clusters may serve as an indication that the effect of these ill-formed slopes may be somewhat diminished due to the low amount of underlying sonority. This would make it a case of misinterpretation (i.e.~\emph{/s/-stop} clusters do not violate sonority principles) due to over-application of sonority slopes, implying that sonority has a limited explanatory contribution to the phonotactics of \emph{/s/-stop} clusters.



\begin{figure}
\includegraphics[width=.8\linewidth]{figures/graphics-slopes-sp-sp-1}
\caption{Schematic depiction of the two potential sonority slopes of the \emph{/s/-stop} cluster \emph{spV}. The red solid line that denotes the sonority slope of the consonantal clusters is falling when 
%applied with 
the expanded sonority hierarchy \emph{H}\textsubscript{exp} is adopted (left), and it is a plateau when 
%applied with 
the collapsed sonority hierarchy \emph{H}\textsubscript{col} is adopted (right).}\label{fig:slopes-sp-sp}
\end{figure}

Rather than redefining sonority principles to be able to account for the phenomenon of \emph{/s/-stop} clusters, more successful attempts to solve this problem in the phonological literature redefined deviant marginal sibilants as exceptional, keeping the traditional sonority principles unaffected by their consistent failure to predict the attested relative well-formedness of \emph{/s/-stop} clusters.
The main type of exception that is used to explain sibilant-initial clusters is based on tweaking symbolic representations by removing the symbol of the marginal sibilant segment outside of the syllable that contains the following consonant such that -- in theory -- there is no tautosyllabic complex cluster to trigger sonority restrictions in the first place (see, e.g., \citealt{steriade1982greek, kaye1992you, rialland1994phonologysk, vaux2009append}).
A slightly different theoretical solution with similar results is to assert that \emph{/s/-stop} clusters are, in fact, a single complex segment (see, e.g., \citealt{fudge1969syllables, weijer1996segmental}) such that, again, there simply is no cluster to account for (for an overview, see \citealt{goad2016sonority}).

Those theoretical tweaks are not without merit as they follow a strong intuition that marginal sibilants are somehow \enquote{outside} the scope of syllabic processes. This intuition is supported by evidence of some unique behaviors of marginal sibilants, such as the kinematic data presented in \citet{hermes2013phonologysk}, which finds unique coordination patterns in the articulation of sibilant-initial consonantal gestures in Italian. That said, it is important to remember that the problem with \emph{/s/-stop} clusters is not that they are common, and, at the same time, unique. The problem with \emph{/s/-stop} clusters is that traditional sonority principles fail to account for them in consistent manners, without resorting to exceptions.

I return to this point in \sectref{sec:division} in proposing a more holistic account of \emph{/s/-stop} clusters that illustrates the division of labor between sonority and other phonotactic principles.

\subsubsection{Not all plateaus are equal}\label{not-all-plateaus-are-equal}

A second problem that has received far less attention in the literature (but see \citealt{baroni2014language}) is the general failure of traditional sonority principles to correctly account for sonority plateaus.
This case is perhaps less prominent as it is the \emph{absence} of some plateau types that serves as the main evidence.
Sonority plateaus can result from any combination of consonants of the same class, regardless of which class. Thus, a voiceless fricative plateau such as \emph{sfV}, like in the English word \emph{\textbf{sph}ere}, should be exactly as ill- or well-formed as a nasal plateau, such as \emph{nmV} (see \figref{fig:slopes-nm-sf}), which is, in fact, a much less common (more \emph{marked}) cluster among the languages of the world (\citealt{greenberg1978some, kreitman2008phoneticssk, lindblom1983production}). This problem can be, again, attributed to the lack of 
%an 
the notion of 
intercept in traditional sonority models.

Different sonority plateaus have the same flat line in terms of sonority slopes, yet they differ in their apparent distribution. This difference seems to be linked to the different intercepts of the plateaus.
A plateau with a low-sonority intercept like \emph{sfV} is better-formed, given that it is cross-linguistically more common, than a plateau with a higher sonority intercept like \emph{nmV}.



\begin{figure}
\includegraphics[width=.8\linewidth]{figures/graphics-slopes-nm-sf-1} 

\caption{Schematic depiction of the sonority slopes of two sonority plateaus, \emph{nmV} and \emph{sfV}. The red solid line which denotes the sonority slope of the onset clusters is higher for \emph{nmV} (left) than for \emph{sfV} (right) due to the higher intercept of /n/ compared to /s/. This difference is not accounted for by traditional sequencing principles.}\label{fig:slopes-nm-sf}
\end{figure}

Note that the critique regarding the lack of intercepts in traditional sonority principles is given from within a discrete symbolic framework, where non-overlapping segments and their associated sonority values are interpolated into slopes in symbolic time. This is only the first step towards a more radically different treatment of sonority with continuous entities and dynamic procedures, which I will propose in \chapref{sec:sonPitch}.

\subsection{\texorpdfstring{Sonority \enquote{correlusions}}{Sonority ``correlusions''}}\label{sec:correlusions}

Although no strong consensus has ever been reached with respect to the phonetic basis of sonority, acoustic \emph{intensity} is perhaps the most widely assumed correlate of linguistic sonority. This is evident from the many influential studies on sonority that consider acoustic intensity as its phonetic correlate (e.g. \citealt{sievers1893grundzugesk, blevins1995syllable, clements1990role, heffner1969generalsk, ladefoged1975acourse, parker2008sound}, and \citealt{gordon2012sonority}, to name just a few prominent examples).\footnote{In his overview of existing literature, \citet{parker2002quantifying} found close to 100 different proposals for correlates of sonority, and he tested five leading proposals in laboratory conditions: \emph{intensity}, \emph{intraoral air pressure}, \emph{F\textsubscript{1} frequency}, \emph{total air flow}, and \emph{duration}. In his study, the tightest correlations with sonority classes were obtained for acoustic intensity measurements, a conclusion that was repeated and %elaborated upon 
further developed 
in \citet{parker2008sound}.}

The main problem with intensity-based accounts is related to the distinction between \emph{causation} and \emph{correlation}. It is possible to find acoustic markers that correlate with some linguistic phenomenon. A discovery of this kind is valuable, but to advance our knowledge further we would also need to know if the correlation between the linguistic phenomenon and our acoustic marker of choice can be characterized in terms of causation. Establishing causation from acoustic signals necessitates a theory that can reliably map acoustic markers to consistent operations or processes in sensorimotor speech articulation and/or auditory speech perception. The problem with accounts that are based on acoustic intensity is that the general acoustic intensity of the signal does not consistently map to any aspect of human auditory perception, not even perceived loudness.

\subsubsection{Acoustic intensity ≠ perceived loudness}\label{sec:intensity}

The acoustic signal has certain physical qualities contributing to its overall power, but they have different effects on the perceptual system of the human hearer. This discrepancy between acoustic intensity and perceived loudness is a well-known problem, playing a role at different dimensions of the mapping between acoustics and perception.
The prominent points of departure between acoustic intensity and perceived loudness include
the following:
(i) loudness perception differs for sine waves with the same intensity level at different frequencies (e.g.~\citealt{fletcher1933loudness, plack1995loudness, suzuki2004equal});
(ii) loudness perception differs for comparable sounds at different durations (e.g.~\cites{turk1996processing}[143]{moore2013anintro}{olsen2010loudness}{seshadri2009perceived});
and (iii) loudness perception differs for otherwise comparable periodic (harmonic) vs.~aperiodic (noise) sounds, and noise, like sine waves, is not uniformly loud across the frequency spectrum (e.g.~\cites{hellman1972asymmetry}{bao2010psychoacousticsk}[140]{moore2013anintro}).
Acoustic intensity is therefore a physical description of sound waves in space which does not consistently relate to how loud we perceive these sounds, or to any other perceptual phenomenon for that matter.

\subsubsection{Loudness is not a good candidate for sonority}\label{sec:loudness}

Note also that the relevance of perceived loudness to syllabic organization requires some sort of functional explanation, which seems to be lacking.
The systematic differences in intensity of adjacent speech sounds imply that these differences are neutralized in perception, as it should make sense to assume that the different sounds that compose coherent speech are perceived as having comparable loudness.
The literature on perceived loudness supports this assumption given that speech portions with relatively low acoustic intensity, like voiceless fricatives, appear in speech next to portions with relatively high acoustic intensity, like vowels.
Our auditory system perceives the aperiodic high-mid frequencies of many obstruents as exceptionally loud compared to the periodic low-mid frequency ranges of vowel sounds, thus compensating in perception for physical differences in acoustic intensity.

Given the above, we should anticipate that perceived loudness will not be a good candidate for the acoustic correlate of sonority hierarchies, as a measure of perceived loudness would bring all speech sounds closer together by diminishing the distinctions provided by acoustic intensity. Indeed, although good approximations of perceived loudness from acoustic signals are available (e.g.~\citealt{seshadri2009perceived, itu2015algorithmssk, lund2014loudnesssk, skovenborg2012loudnesssk}), I am not aware of any attempts to employ such measures for sonority.

Instead of attempts to map acoustic intensity to perception in terms of perceived loudness, most successful endeavors that use intensity-based measures as correlates of sonority do so by essentially enhancing the intensity--loudness discrepancy. Certain frequency bands are targeted to -- roughly speaking -- discriminate against energy at the higher frequencies (which are more characteristic of obstruents) in favor of energy at low-mid ranges of the spectrum (which are more characteristic of sonorants and particularly vowels).\footnote{For example, \citet{Pfitzinger1996syllablesk, port1996dynamic, fant2000source, galves2002sonoritysk, wang2007robust, tilsen2013speech, patha2016syllablesk, nakajima2017english}, and \citet{rasanen2018pre}.}
The relative success of such metrics is not commonly based on perceptual grounds. However, they are often tightly linked to the perceptual quality that is identified with sonority in this work -- the capacity to perceive pitch.
