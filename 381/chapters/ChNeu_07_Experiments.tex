\chapter{Experimental study}\label{sec:experiments}

In order to assess NAP-based predictions in situations where both bottom-up and top-down inferences contribute to speech processing, an experimental procedure was designed to collect behavioral responses using a perception task.
In what follows I present three experiments:
Experiment 1 is a short exploratory pilot study with 12 German-speaking subjects;
Experiment 2 is a confirmatory study with 51 German-speaking subjects;
and Experiment 3 is a confirmatory study with 33 Hebrew-speaking subjects.
This chapter starts by describing the rationale of the experimental design (\sectref{sec:rationale}) before presenting the linguistic and acoustic materials used in the experiments (\sectref{sec:materials}) and the perception task procedures (\sectref{sec:percproc}).
The predictions of the different models are then summarized in \sectref{sec:predictions}, followed by descriptions of the experimental design (Section~\ref{sec:designs}), participants (Section~\ref{sec:participants}) and our data analysis strategies (\sectref{sec:datanlysis}). The results and related discussions follow in \sectref{sec:results}.

%Important notes:
Important notes with respect to the following chapter:

\begin{itemize}
\item
  The design of the model implementations and the ensuing experiments were co-authored with Bruno Nicenboim (University of Potsdam and Tilburg University), who also contributed greatly to the statistical analyses of the results. Major parts of this chapter were also published in \citet{albert2022modeling}.
%\item
%  Major parts of this chapter were also published in \citet{albert2022modeling}.
\item
  The original code and all the materials and data can be found online in an Open Science Framework repository at \url{https://osf.io/y477r/}.
\item
  The experiments were complied with the June 1964 Declaration of Helsinki (carried out by the World Medical Association and entitled \enquote{Ethical Principles for Medical Research Involving Human Subjects}), as last revised in accordance with German Research Foundation (DFG) guidelines for experiments with unimpaired adult populations. The ethics approval was obtained by the Principal Investigator (Prof.~Dr.~Martine Grice). Informed consent from the participants was obtained before each experimental session.
\end{itemize}

\section{Rationale}\label{sec:rationale}

The goal of the experimental procedure is to tap into the cognitive cost of syllabification processes. To that end, we devised a forced-choice task that allowed us to systematically compare response times of forced categorical decisions. Response times are linked with cognitive cost, which, in the context of this task, is understood as the result of nucleus competition. The working assumption is that more competition within a structure makes it cognitively harder for this structure to be parsed as a single syllable, which is reflected in slower processing times altogether.

This design uses nonce words to test specific consonantal combinations in structures that either feature two vowels and no consonantal sequences (typically considered to be disyllabic forms) or one vowel with a word-initial consonantal sequence (more likely to be considered as monosyllabic forms).
This experimental design is reminiscent of many experiments on sonority effects that Iris Berent and her colleagues have published, starting with the seminal paper \citet{berent2007we}.\footnote{Examples of further publications by Berent et al.~with various experimental settings that test sonority effects in perception with behavioral data include: \citet{berent2008language, berent2010phonological, berent2011syllable, berent2012language, berent2013phnological, tamasi2014sensitivity, zhao2015universalsk, lennertz2015onthesonority}. The following examples also include neurological data: \citet{berent2014languagesk, gomez2014language, berent2015role}.} The premise of many of the tasks that Berent et al.~test in the context of traditional sonority principles has a slightly different rationale than the one used for NAP, although with very similar predictions. For Berent et al., an ill-formed sonority onset fall, as in the monosyllable \emph{lbV}, is more likely to be confused with disyllabic \emph{lə.bV} when compared with well-formed monosyllable \emph{blV} and its disyllabic counterpart, \emph{bə.lV} (the schwa /ə/ in these examples denotes a generic epenthetic weak vowel). This misperception and confusion between alternatives is expected to be systematically greater with worse-formed sonority clusters, which leads to a drop in categorical accuracy (e.g.~\enquote{correct} identification of syllable number, or correct detection of similarity in a same/different task) accompanied by a scalar increase in response time (I return to Berent's work in the general discussion in \sectref{sec:projection}).

Comparable experimental assumptions regarding misperception of consonantal clusters can be found in related works on perception of non-native clusters such as \citet{dupoux1999epentheticsk} and \citet{davidson2012sources}, including also tasks that utilized the production of such clusters (e.g. \citealt{davidson2010phoneticsk} and \citealt{wilson2014effects}).

To test the different predictions of the six sonority models
(SSP\textsubscript{col}, SSP\textsubscript{exp}, MSD\textsubscript{col}, MSD\textsubscript{exp}, NAP\textsubscript{td} and NAP\textsubscript{bu}),
we designed a perception task that prompts meta-linguistic syllable count judgement with 29 experimental target items.
Participants were presented with a collection of speech items that were systematically produced with one or two vowels for each combination of consonants in our set.
Only the single-vowel productions were considered as targets, and an accurate response to our targets is always the monosyllabic option (note that the term \enquote{accuracy} is used here to describe participants' responses with respect to predictions).
By focusing on the response time of \enquote{correct} responses to the target words we essentially measure the time it took participants to decide that a given single-vowel stimulus is monosyllabic.
We can therefore interpret the reaction times of monosyllabic responses to single-vowel targets as reflective of the processing cost of assigning one nucleus to a given target stimulus with one vowel.

We assume with NAP-based models that this processing cost is tightly related to the nucleus competition between different portions of a syllable, such that response times will reflect the degree of nucleus competition within syllables (more competition = slower responses = worse-formed sequence). Traditional sonority models interpret the processing cost as related to well-formedness in terms of sonority slopes, such that worse-formed clusters are more likely to be misperceived and take longer to process (e.g.~\citealt{berent2007we, berent2012language, berent2008language, berent2009listeners, lennertz2010people, maionchi2015sonoritysk, sung2016perceptionsk, young2017markednesssk}).

The SSP derives a ternary ordinal hierarchy of complex onset well-formedness scores: onset rise \(>\) onset plateau \(>\) onset fall. This essentially predicts that response times will pattern into three groups, in line with the sonority slope of the onset clusters. MSD models derive a slightly more elaborate ordinal hierarchy, where onset rises with a small sonority distance pattern below onset rises with a larger sonority distance. The latter are predicted to evoke the fastest responses in MSD models.

Note that since the bottom-up predictions of NAP are derived via measurements of acoustic signals of particular productions rather than from fixed symbolic predictions, the assumption that all things other than the controlled variable are equal in the experimental stimuli should hold also for a large degree of variation that occurs in natural speech. Thus, if a certain segment in one item is slightly longer, shorter, louder or softer than in other comparable tokens, bottom-up NAP is designed to directly account for this variation, while the other symbol-based ordinal models essentially assume that such variation is mostly negligible. This allows us to opt for a slightly more ecologically valid experimental paradigm, by using natural speech recordings that were designed and selected to sound as similar as possible, rather than using synthesized speech, which would have allowed a higher degree of similarity between tokens.

\section{Materials}\label{sec:materials}

The experimental design is focused on onset consonantal clusters with two members. These CC combinations are composed from a set of consonants with one of two major \emph{place of articulation} types: \emph{coronal} and \emph{labial}. This allows us to avoid articulatory effects that may arise from \emph{homorganic} sequences (i.e.~adjacent consonants that share the same place of articulation, and may coalesce to some extent as a result) while exploiting both directions of each combination -- coronal-labial (back-to-front) and labial-coronal (front-to-back). From an articulatory point of view, there is also an advantage in the fact that the two places of articulation use different main articulators -- the tongue tip reaches the palate in coronals, while the lower lip reaches the upper lip or teeth in labials. This relative articulatory independence helps to reduce co-articulation effects of adjacent gestures in consonantal clusters.

The consonantal classes in this study include \emph{stops}, \emph{fricatives}, \emph{nasals}, and \emph{liquids} to reflect the main \emph{manner of articulation} classes in traditional sonority hierarchies (excluding \emph{glides}).
The list of considerations and criteria that were used in constructing the experimental stimulus set is presented in Section~\ref{sec:stimChoice}.

\begin{table}
\caption{\label{tab:targetlist}Experimental stimulus set: CC types. Legend: {S−} = voiceless stops; {F−} = voiceless fricatives; {F+} = voiced fricatives; {N} = nasals; {L} = liquids; cor = coronal; lab = labial; * = voicing disagreement between obstruents; ** = no labial liquid; *** = dorsal stop /k/ (see list in Section~\ref{sec:stimChoice}).}
\fittable{\begin{tabular}{lcccccccc}%{cclcclcclcclcclcclcclcclccl}
\lsptoprule
& \multicolumn{8}{c}{{C\textsubscript{1}}}\\\cmidrule(lr){2-9}
& \multicolumn{2}{c}{{{F−}}} & \multicolumn{2}{c}{{{F+}}} & \multicolumn{2}{c}{{{{N}}}} & \multicolumn{2}{c}{{{{L}}}}\\\cmidrule(lr){2-3}\cmidrule(lr){4-5}\cmidrule(lr){6-7}\cmidrule(lr){8-9}
{C\textsubscript{2}} & {cor-lab} & {lab-cor} & {cor-lab} & {lab-cor} & {cor-lab} & {lab-cor} & {cor-lab} & {lab-cor}\\
\midrule
{S−} & sp, ʃp & ft & * & * & np & mt & lp & lk***\\
{F−} & sf, ʃf & fs & * & * & nf & ms & lf & **\\
{F+} & * & * & zv & vz & nv & mz & lv & **\\
{N} & sm, ʃm & fn & zm & vn & nm & mn & lm & **\\
{L} & ** & fl & ** & vl & ** & ml & ** & **\\
\lspbottomrule
\end{tabular}}
\end{table}

\tabref{tab:targetlist} presents the 29 CC types in the experimental set, reflecting 16 different combinations of \emph{manner} classes (16 unique cells in \tabref{tab:targetlist}, irrespective of differences in place of articulation). Of the 16 cluster types, 7--8 are considered onset falls, 3--4 are considered onset plateaus (11 total), and 5 are considered onset rises.\footnote{Depending on whether fricatives are considered higher or similar in sonority to stops, clusters of the type \emph{fricative-stop} may be considered as either an onset fall or an onset plateau.} 

%new from paper:
Of the 29 different clusters, only three clusters regularly occur in German words (/ʃp, ʃm, fl/), while six clusters are attested to some degree in German loanwords (/sp, sf, sm, vl, zv, ml/; see \citealt{van2012sonority}),
and one cluster (/ʃf/) may be considered as similar to German licit clusters with a voiced obstruent following a voiceless one (i.e.~/ʃv/ and /cv/).\footnote{Recall that the symbol /c/ is used here as an alternative sign to the voiceless affricate /t͡s/ in the standard IPA system, see Section~\ref{conventions}.}
Thus, the experimental set contains 19 clusters that are unattested in German words. These unattested clusters appear in 13 of the 16 unique cluster types. 
The other three are rising sonority clusters with a liquid in C\textsubscript{2}, /fl, vl, ml/, that are attested in German complex onsets to some degree, yet only marginally so in the case of /vl/ and /ml/.

More clusters out of the 29 different cluster types in \tabref{tab:targetlist} occur regularly in Modern Hebrew (see \citealt{asherov2019syllablesk}). These include all of the eight sibilant-initial clusters, /sp, ʃp, sf, ʃf, sm, ʃm, zm, zv/, and two liquid-second clusters, /fl, vl/. The voiceless cluster /ft/ and the /m/-initial clusters /ml, mn/ are marginally attested in Modern Hebrew \citep[75, 86]{asherov2019syllablesk}.
Thus, the experimental set contains 16 cluster types that are unattested in Hebrew words.
These unattested CC types appear in 12 of the 16 unique combinations in \tabref{tab:targetlist}, excluding the three rising sonority clusters with a liquid in C\textsubscript{2} (e.g.~/fl, vl, ml/), and the \emph{fricative-stop} clusters (including /ft/), although note that /ft/ and /ml/ are only marginally attested in Hebrew complex onsets.

%previously...
%Since the following experiments collect responses from native German-speaking subjects, it is important to note that of the 29 different clusters, only 3 clusters regularly occur in German words (/ʃp, ʃm, fl/) and 6 clusters are attested to some degree in German loanwords (/sp, sf, sm, vl, zv, ml/; see \citealt{van2012sonority}),
%and one cluster (/ʃf/) may be considered as similar to German licit clusters with a voiced obstruent following a voiceless one (i.e.~/ʃv/ and /cv/).
%Thus, the experimental set contains 19 clusters that are unattested in German words. These unattested clusters appear in 13 of the 16 unique cluster types.
%The other three are rising sonority clusters with a liquid in C\textsubscript{2}, /fl, vl, ml/, that are attested in German complex onsets to some degree, yet only marginally so in the case of /vl/ and /ml/.

The different CC sequences were embedded within a /CCal/ word-like frame, with a recurring \emph{-al} rime. These /CCal/ tokens were produced with a single vowel, intended to yield monosyllabic items that resemble typical content words (i.e.~prosodically heavier than a single light syllable; see, e.g., \citealt{demuth1996prosodic}). Two disyllabic counterparts were prepared for each CC type -- one with an epenthetic vowel, /CəCal/, and another with a prothetic vowel, /əCCal/ (a more accurate annotation should be /(ʔ)əCCal/, given that the presence of an initial glottal stop was not controlled for).
Note that the schwa in the stimulus set recorded by speaker AA was produced as a weak (unstressed) /e/ vowel from the 5-vowel inventory of Modern Hebrew, while in the stimulus set recorded by speaker HN it was produced as a typical German schwa.
The entire word set eventually included 29 single-vowel target types and 58 associated bi-vocalic filler types, adding up to 87 different word-like stimuli.

\subsection{Segmental considerations}\label{sec:stimChoice}

The following list summarizes concerns that were taken into consideration when constructing the stimulus set (see full set in \tabref{tab:targetlist}):

\begin{itemize}
\item
  Glides were excluded from the experimental set due to their complex status, which is dependent on both structure and theory. A glide (sometimes referred to as a \emph{semi-vowel}) is considered a vowel when it is in the nucleus position. A glide immediately adjacent to a nuclear vowel may be analyzed as a vowel in the nucleus, or as a consonant in the onset or coda positions, depending on language and analysis (namely, this depends on whether the language is considered to feature \emph{diphthongs} or not, in itself not always a simple determination). Furthermore, clusters with glides in C\textsubscript{1} are predicted to be ill-formed in all the models we consider, while clusters with glides in C\textsubscript{2} are predicted to be well-formed in all of them. We therefore also do not expect glides to be very informative in the context of this study.
\item
  For the class of liquids, only the lateral /l/ is used, disregarding the sub-class of \emph{rhotics} that are phonetically very varied and highly inconsistent between different languages in terms of phonetic detail (see, e.g., \citealt{lindau1980storysk, ladefoged1996rhotics, wiese2001phonology}). In that context, it is important to note that the set of stimuli used in this study was created with the intention of being used on speakers of many different languages in which the relevant segments can map to native segments to a comparable degree. There are therefore no liquid plateaus in the experimental set.
\item
  The alveolar /s/ is used for the class of voiceless sibilants (voiceless coronal fricatives). In C\textsubscript{1} positions, the post-alveolar /ʃ/ is also used to control for potential language-specific effects that may appear due to specific restrictions on /s/. For example, in German /ʃC/ onset clusters can be licit, while /sC/ onset clusters occur only marginally in loanwords.
\item
  Stops are used only in C\textsubscript{2} position, and only voiceless stops are used in order to keep the size of the stimulus set reasonably small. Stops in C\textsubscript{1} position are avoided since it is also the phrase-initial position of the stimuli, which is practically devoid of acoustic cues for the closure phase of the stop. Within the stream of speech, the movement of articulators towards the target of a stop's closure phase leaves auditory traces from the preceding segment and into the closure of the stop, containing important information about the identity of the stop (e.g.~\citealt{barry1984place}). In that sense, a stop in C\textsubscript{1} position at the beginning of a phrase contains only a transient release burst.
  Furthermore, note that all the stop-initial clusters (with the exclusion of \emph{stop-stop} plateaus) are generally well-formed according to all sonority models tested here, such that their added value in this comparison would have been smaller than their cost (in terms of the size of the stimulus set).
\item
  The set includes one instance of the dorsal consonant /k/ instead of the coronal /t/ as an alternative to a labial-coronal cluster, which would have required a labial liquid. Instead, the coronal-dorsal cluster /lk/ is used to retain the same direction of a labial-coronal cluster -- both are front-to-back in terms of places of articulation. There are no other dorsals in the set (i.e.~no fricative, nasal or liquid dorsal), as these tend to be relatively more marked and less consistent between languages.
\item
  Lastly, sequences of obstruents that differ in voicing are avoided due to the cross-linguistic tendency of obstruent clusters to agree in voicing (see, e.g., \citealt{cho1990typologysk}), although note that German allows /ʃv/ and /cv/ clusters while banning /ʃf/.
\end{itemize}

\subsection{Audio recordings}\label{sec:audio}

Audio stimuli for the experiment were recorded by a phonetically trained native Hebrew speaker, AA (the author), and a phonetically trained native German speaker, HN, in a sound-attenuated booth at the phonetics laboratory of the University of Cologne. Speech was recorded via a head-mounted headset condenser microphone (AKG C420), capturing mono digital audio files at a resolution of 44.1k\,Hz sample-rate and 24 bit depth with a Metric Halo MIO 2882 audio interface. Selected audio takes were treated in the original high resolution for DC offset correction and compression of ultra low frequencies under 52\,Hz (to compensate for some room reverberation effects). Audio was then downgraded from 24 to 16 bit depth with Goodhertz Good Dither dithering to be used in the perception task running on OpenSesame 3.1.9 \citep{mathot2012opensesame}. The audio that was submitted to analyses by the APP Detector (see Section~\ref{sec:obtaining}) was also downgraded in sample-rate to 16k Hz. Finally, all audio takes, at all resolutions, were normalized to the same RMS target of $-20$\,dBFS (dB full scale).

To record the stimuli, the combined 87 word-like stimuli (29 targets and 58 fillers) were embedded within carrier sentences in non-final position and produced with default declarative intonation, in order to maintain consistent prosody. Carrier sentences were also designed to minimize potential effects of resyllabification as well as co-articulation by controlling the segmental makeup immediately preceding and following target words (see examples in (\ref{ex:sentence1}--\ref{ex:sentence2})).

\begin{exe}
\ex \textbf{/ze maʁ.gíʃ \emph{CCal} ka.ʁé.ga/} (Hebrew: `it feels (like) \emph{CCal} at the momentʼ) \label{ex:sentence1}
\ex \textbf{er muss \emph{CCal} kaufen} (German: `he must buy \emph{CCal}ʼ) \label{ex:sentence2}
\end{exe}

The original sentence elicitation lists are available at the OSF repository in mixed Hebrew, German and phonemic transcripts in the form of the PowerPoint presentations that were used in this self-paced task (see link in the opening notes of \chapref{sec:experiments}).

\subsection{Obtaining periodic energy data}\label{sec:obtaining}\largerpage

Continuous measurements of periodic energy from acoustic signals were extracted for the experiments using the \emph{Aperiodicity, Periodicity and Pitch Detector} (APP Detector), a computer code that was introduced in \citet{deshmukh2003detectionsk} and developed in subsequent publications (\citealt{deshmukh2005use, vishnubhotla2007detection}).
The APP Detector has the ability to measure the spectral distribution of periodic energy from digital audio files with a 16k Hz sample-rate, effectively measuring periodic energy up to 8k Hz (more than sufficient for speech, see Section~\ref{sec:periodicenergy}).
The periodic energy data was exported from the APP Detector's Matlab analysis tables into R \citep{R-base} for further data manipulation, visualization, modelling, and statistical analysis.

To obtain the periodic energy curve, it is necessary to first sum over the different frequencies that the APP Detector measures at each time point (every 10\,ms) to create a time series of \emph{periodic power}.
Next, a smoothed curve is fitted to the periodic power time series with \emph{Tukey's (running median) smoothing} (\enquote{3RS3R}), to eliminate small-scale fluctuations in the periodic power curve.
Finally, the periodic power time series is log-transformed to yield \emph{periodic energy}, see Equation \eqref{eq:perLog}.

Within the log-transform function we can plug a value that reflects the threshold of effective voicing periodicity to set a meaningful zero for the periodic energy floor -- the \emph{periodic floor} in Equation \eqref{eq:perLog}.
This is similar to the standard \emph{dB SPL} measurement (SPL stands for \emph{sound pressure level}), which plugs a generic value that represents the threshold of human hearing in terms of sound pressure into the denominator of the log-transform function. In this way, SPL suggests a shared reference for different dB measurements that use the zero value to denote the low end of human hearing.
In the case of the current periodic energy measurement the threshold of the floor is not a universal determination but a calibration that allows us to take the audio quality and the inner-workings of the APP Detector into account.
The effective periodicity threshold for the log-transform of the periodic energy time series was determined by extracting the maximal periodic power value obtained for voiceless portions in the given set. To be sure that there was no marginal voicing in these samples, only voiceless C\textsubscript{1} consonants that precede another voiceless consonant in C\textsubscript{2} were measured. In this way, the value 0 in our periodic energy curve is optimally calibrated to reflect the low end of pitch-related periodic components in the signal.

\begin{equation}
  \text{periodic energy} = 10 \log_{10}\!\left(\frac{\text{periodic power}}{\text{periodic floor}}\right) \label{eq:perLog}
\end{equation}

Note that the periodic energy curve is smoothed further with Local Polynomial Regression Fitting (\emph{loess}) in the figures shown in this chapter. This is only used for additional visual clarity. All the acoustic analyses are based on the periodic energy curve before this final aesthetic smoothing (and after the other processes mentioned above).
The codes of all the above processes are available at the OSF repository (see link in the opening notes of \chapref{sec:experiments}).

\section{Perception task procedures}\label{sec:percproc}\largerpage

Recall that the experiments were designed as a forced-choice 2-alternative perception task, where accuracy and response time information were collected.
To normalize response times, the countdown in each trial started in the middle of the transition from C\textsubscript{2} to /a/,
illustrated with the location of the dash in \emph{(ə)C\textsubscript{1}(ə)\textbf{C\textsubscript{2}--a}l}. This zero time point was determined individually for each one of the 87 stimuli, capitalizing on the fact that all stimuli share the rime \emph{-al}, which is fully predictable in the context of the experiment, in contrast to the unpredictability of preceding material (the predictability of the \emph{-al} rime was assumed to become evident already in the training phase, before any data were collected for analysis). Manual segmentations conducted by the author were used to determine this point for each target. Eventually, response times shorter than 100\,ms (i.e.~100\,ms after the zero point between C\textsubscript{2} and /a/) were considered as too fast to be valid and were therefore excluded. This threshold led to only one observation being excluded from Experiment 2.

Participants were seated in a quiet room in front of a laptop computer (a MacBook Air 13-inch, Early 2014) running the experiment on OpenSesame 3.1.9 \citep{mathot2012opensesame}, where they listened to the stimuli through a set of closed headphones (Sennheiser HD 201), fed directly from the laptop's internal audio interface. After verifying that participants shared a standard understanding of the notion of the syllable with a few examples of words in their language (German or Hebrew) with one and two syllables (e.g. German \emph{See}, \emph{Spaß}, \emph{Quark}, \emph{Angst} vs.~\emph{Schu-le}, \emph{Kin-der}, \emph{Bre-zel}, \emph{Pflau-men}), they were instructed to listen to nonce words in an \enquote{unknown} foreign language.
Nonce words were used and a foreign language was mentioned in order to increase reliance on bottom-up processing in the task as much as possible.
The meta-linguistic task may otherwise strongly have favoured top-down inferences.
To that end, it was important to use recordings of a speaker with a foreign native language compared to the participants' L1.
The German-speaking listeners in Experiments 1--2 heard speech recording of a native Hebrew speaker and the Hebrew-speaking listeners in Experiment 3 heard speech recording of a native German speaker.

Participants were instructed to respond quickly and accurately whether they heard one or two syllables by using their left and right index fingers to choose 1 or 2 at the location of the \enquote{F} (for 1) and \enquote{J} (for 2) keys on a QWERTY keyboard layout (relevant keys were covered with salient red-on-white \enquote{1} and \enquote{2} stickers).

A training session of ten trials preceded the experimental blocks, allowing the participants to familiarize themselves with the task, and allowing the experimenter to adjust listening volume and monitor potential problems and misunderstandings regarding the task.

\section{Summary of predictions}\label{sec:predictions}

The full set of predictions for the 29 experimental targets is presented for all the symbol-based ordinal models
(SSP\textsubscript{col}, SSP\textsubscript{exp}, MSD\textsubscript{col}, MSD\textsubscript{exp} and NAP\textsubscript{td})
in \tabref{tab:OrdinalTargetPreds}, and for the signal-based continuous model (NAP\textsubscript{bu}) in Figures~\ref{fig:com-monosyl}--\ref{fig:com-monosylHeb}. Note that the scores of NAP\textsubscript{bu} are presented on a continuous ratio scale, with specific predictions for each token and consequential intervals between scores. The scores in NAP\textsubscript{bu} are not a generalization (nor are they based on averages). Rather, they were extracted from the specific set of recordings, and they are expected to vary to some extent when measuring different tokens. NAP\textsubscript{bu} scores are presented for the two sets of stimuli used in the experiments: a set spoken by a native Hebrew speaker (\figref{fig:com-monosyl}) and a set spoken by a native German speaker (\figref{fig:com-monosylHeb}).

\begin{table}[p]
\caption{\label{tab:OrdinalTargetPreds}Well-formedness scores for the 29 experimental items using the five ordinal models that are based on symbolic phonemes.
%: SSP\textsubscript{col/exp}, MSD\textsubscript{col/exp}, and NAP\textsubscript{td}. 
Positive values indicate a rise (rs), negative values a fall (fll), and 0 a plateau (plt). Note that higher values predict better-formed onset clusters in an ordinal scale (i.e.~magnitude of differences between values cannot be inferred from these models). }
\begin{tabular}{l *4{S[table-format=-1.0]@{~}l} S[table-format=-1.0]}
\lsptoprule
{Onset cluster types} & \multicolumn{2}{c}{{SSP\textsubscript{col}}} & \multicolumn{2}{c}{{SSP\textsubscript{exp}}} & \multicolumn{2}{c}{{MSD\textsubscript{col}}} & \multicolumn{2}{c}{{MSD\textsubscript{exp}}} & \multicolumn{1}{c}{{NAP\textsubscript{td}}}\\
\midrule
fl & 1 & (rs) & 1 & (rs) & 2 & (rs) & 4 & (rs) & 5\\
sm, ʃm, fn & 1 & (rs) & 1 & (rs) & 1 & (rs) & 3 & (rs) & 5\\
vl & 1 & (rs) & 1 & (rs) & 2 & (rs) & 2 & (rs) & 3\\
zm, vn & 1 & (rs) & 1 & (rs) & 1 & (rs) & 1 & (rs) & 3\\
ml & 1 & (rs) & 1 & (rs) & 1 & (rs) & 1 & (rs) & 1\\
sf, ʃf, fs & 0 & (plt) & 0 & (plt) & 0 & (plt) & 0 & (plt) & 3\\
zv, vz & 0 & (plt) & 0 & (plt) & 0 & (plt) & 0 & (plt) & 2\\
nm, mn & 0 & (plt) & 0 & (plt) & 0 & (plt) & 0 & (plt) & 1\\
sp, ʃp, ft & 0 & (plt) & -1 & (fll) & 0 & (plt) & -1 & (fll) & 3\\
lm & -1 & (fll) & -1 & (fll) & -1 & (fll) & -1 & (fll) & 1\\
mz, nv, lv & -1 & (fll) & -1 & (fll) & -1 & (fll) & -1 & (fll) & 0\\
ms, nf, np, mt, lf, lp, lk & -1 & (fll) & -1 & (fll) & -1 & (fll) & -1 & (fll) & -1\\
\lspbottomrule
\end{tabular}
\end{table}
\clearpage

\begin{figure}[p]
\includegraphics[width=\textwidth]{figures/graphics-com-monosyl-1}
\caption{AA set (Hebrew speaker). Well-formedness scores in the continuous NAP\textsubscript{bu} model shown in terms of the distance between the center of mass of the entire syllable, {CoM\textsubscript{syllable}} (red vertical lines), and the center of mass of the left portion, {CoM\textsubscript{onset}} (blue vertical lines). See Section~\ref{sec:napbu} for details. Periodic energy is represented by the black curve. Grey dotted vertical lines and annotated text denote segmental intervals by manual segmentation (for exposition purposes only). Items are ordered by score (from worse- to better-formed), going from left-to-right and from top-to-bottom.}\label{fig:com-monosyl}
\end{figure}

\begin{figure}[p]
\includegraphics[width=\textwidth]{figures/graphics-com-monosylHeb-1}
\caption{HN set (German speaker). See previous figure (\figref{fig:com-monosyl}) for plot details.}\label{fig:com-monosylHeb}
\end{figure}

\clearpage
\section{Designs}\label{sec:designs}

The details in the following analyses address three separate experiments:
\emph{Experiment 1}, an exploratory pilot experiment with 12 German-speaking subjects listening to stimulus set AA (Hebrew speaker); \emph{Experiment 2}, a confirmatory experiment with 51 German-speaking subjects listening to stimulus set AA; and \emph{Experiment 3}, a confirmatory experiment with 33 Hebrew-speaking subjects listening to stimulus set HN (German speaker).

Given the various novelties in this proposal, the methodologies for data collection, data extraction, and model implementation were first tested on a small body of real data that we collected before finalizing our methodologies (namely, the model implementations in \chapref{sec:modelimp} and the various procedural details in \sectref{sec:materials}).
We used this exploratory study to test our methodologies and to explore the possibilities for properly estimating nucleus competition in each of the NAP models.

We also used the exploratory pilot study to verify that the number of participants is large enough with respect to the size of the expected effects. With 12 participants, we could already observe clear effects (see \sectref{sec:results}). To be confident that we have enough power to compare the models, we aimed at 50 participants in the confirmatory studies (note that this goal was only partially reached in Experiment 3 due to the COVID-19 pandemic).

The exploratory pilot study was conducted in two versions, each with half of the fillers and all of the targets in one block, yielding a total of 58 data points per subject (29 fillers + 29 targets, no repetitions).
The two different versions were evenly split between participants (each version was presented to six participants).

Experiments 2 and 3 are the main confirmatory studies conducted after finalizing our hypotheses and methodologies with the data from Experiment 1. 
The difference between Experiments 2 and 3 concerns the native language of the subjects, and, as a consequence, the stimulus set in use. 
Experiment 2 tested German-speaking subjects on stimulus set AA, featuring a Hebrew speaker, while Experiment 3 tested Hebrew-speaking subjects on stimulus set HN, featuring a German speaker (see explanation in \sectref{sec:rationale}). 
Each experimental block in Experiments 2–3 consisted of two repetitions of the target words (2 \(\times\) 29 \(=\) 58) and one trial of each filler word (1 \(\times\) 58). The experiment consisted of two blocks with randomized trials, generating altogether four repetitions of the target words (4 \(\times\) 29 \(=\) 116) and two repetitions of the filler words (2 \(\times\) 58 \(=\) 116), yielding a total of 232 data points per subject.

%The difference between Experiments 2 and 3 concerns the native language of the subjects, and, as a consequence, the stimulus set in use. To promote bottom-up inferences (see Section~\ref{sec:rationale}), Experiment 2 tested German-speaking subjects on stimulus set AA, featuring a Hebrew speaker, while Experiment 3 tested Hebrew-speaking subjects on stimulus set HN, featuring a German speaker.
%In theory, we assume that speakers of any language will exhibit the general trends that are predicted by sonority-based models. We therefore assume that small differences between the groups should be reflective mostly of their language-specific experience, which is related to their overall top-down phonotactic knowledge (not necessarily to sonority per se).

\section{Participants}\label{sec:participants}

\subsection{Experiment 1}\label{experiment-1}

The exploratory pilot study consisted of 12 subjects (two males and ten females), all native German-speaking students from the Technische Hochschule Köln, who volunteered to participate in the study. The experiment was administered in a quiet room at one the institute's buildings in Cologne. The mean age of participants in the pilot study was 25 (21--30 range).

\subsection{Experiment 2}\label{experiment-2}



\begin{figure}
\includegraphics[width=0.32\linewidth]{figures/graphics-participantsGer-1_cropped} \includegraphics[width=0.32\linewidth]{figures/graphics-participantsGer-2_cropped} \includegraphics[width=0.32\linewidth]{figures/graphics-participantsGer-3_cropped} \caption{Participants in Experiment 2 ($n = 51$). Education categories refer to academic achievements (\enquote{school} = academic degree not yet acquired).}\label{fig:participantsGer}
\end{figure}

Fifty-one native German speakers (who did not participate in the exploratory pilot study) participated in Experiment 2, of which 48 were monolingual (the 3 bilingual speakers had Polish, Low German, and Hebrew as their heritage language). 49 participants were right-handed. See more details on age, gender and education of participants in \figref{fig:participantsGer}.

Of the 51 participants, 34 were students at the University of Cologne who took part in the experiment at the sound-attenuated booth of the phonetics laboratory. The other 17 participants took part in the experiment at three different locations -- all small quiet rooms within private apartments. All subjects were paid five Euros for their participation.

We excluded the responses from one participant who failed in our participant inclusion criterion requiring accuracy of at least 75\% with bi-vocalic fillers. The bi-vocalic fillers of the forms /CəCal/ and /əCCal/ link correct responses to the disyllabic choice (2), and we expect relatively few monosyllabic choices (1) in response to stimuli with two separate vowels.
Indeed, the overall average accuracy of all 51 participants, when responding to bi-vocalic filler stimuli, was 96\%. The excluded participant achieved a much lower accuracy score for bi-vocalic fillers, almost approaching chance-level with 65\%.

\subsection{Experiment 3}\label{sec:participants3}



\begin{figure}
\includegraphics[width=0.32\linewidth]{figures/graphics-participantsHeb-1_cropped} \includegraphics[width=0.32\linewidth]{figures/graphics-participantsHeb-2_cropped} \includegraphics[width=0.32\linewidth]{figures/graphics-participantsHeb-3_cropped} \caption{Participants in Experiment 3 ($n = 33$). Education categories refer to academic achievements (\enquote{school} = academic degree not yet acquired).}\label{fig:participantsHeb}
\end{figure}

Thirty-three native Hebrew speakers participated in Experiment 3, of which 28 were monolingual (the five bilinguals were also native speakers of English, Russian and Spanish). 28 participants were right-handed. See more details on age, gender and education of participants in \figref{fig:participantsHeb}.

The data collection in Experiment 3 was more diverse, and, perhaps therefore also more \enquote{noisy} than in Experiment 2.
The first round of data collection took place in 2019 with student volunteers from Tel Aviv University and The Hebrew University of Jerusalem. The second round of data collection took place during the early phases of the global COVID-19 pandemic, which resulted in fewer overall participants and the use of different ad-hoc and suboptimal locations to administer the experiment.

\section{Data analysis}\label{sec:datanlysis}

We used a Bayesian data analysis approach implemented in the probabilistic programming language \emph{Stan} \citep{Stan2018} using the model wrapper package \emph{brms} (\citealt{R-brms_a, R-brms_b}) in \emph{R} \citep{R-base}.\footnote{The complete list of \emph{R} packages and versions that we used is: R (Version 3.6.3; \citealt{R-base}) and the R-packages \emph{brms} (Version 2.16.3; \citealt{R-brms_a, R-brms_b}), \emph{Cairo} (Version 1.5.12; \citealt{R-Cairo}), \emph{dplyr} (Version 0.8.5; \citealt{R-dplyr}), \emph{ggplot2} (Version 3.3.0; \citealt{R-ggplot2}), \emph{ggrepel} (Version 0.8.2; \citealt{R-ggrepel}), \emph{hexbin} (Version 1.28.1; \citealt{R-hexbin}), \emph{loo} (Version 2.4.1; \citealt{R-loo_b}), \emph{purrr} (Version 0.3.4; \citealt{R-purrr}), \emph{R.matlab} (Version 3.6.2; \citealt{R-R.matlab}), \emph{Rcpp} (Version 1.0.4.6; \citealt{R-Rcpp_a, R-Rcpp_b}), \emph{readr} (Version 1.3.1; \citealt{R-readr}), \emph{rstan} (Version 2.19.3; \citealt{R-rstan}), \emph{StanHeaders} (Version 2.21.0.1; \citealt{R-StanHeaders}), \emph{stringr} (Version 1.4.0; \citealt{R-stringr}), and \emph{tidyr} (Version 1.0.2; \citealt{R-tidyr}).} An important motivation for using the Bayesian approach is that it facilitates fitting fully hierarchical models with the so-called \enquote{maximal random effect structure}, which provide the most conservative estimates of uncertainty \citep{SchielzethForstmeier2009}. In all our models, we used regularizing priors (detailed below). These priors are minimally informative and have the objective of yielding stable inferences (\citealt{chung2013weakly, gelman2008weakly, GelmanEtAl2017}). \citet{NicenboimVasishth2016} and \citet{VasishthEtAl2017EDAPS} discuss the Bayesian approach in detail in the context of psycholinguistics and phonetics. We fitted the models with four chains and 4000 iterations each, of which 1000 iterations were the warm-up phase. In order to assess convergence, we verified that there were no divergent transitions, that all the \(\hat{R}\) (the between- to within-chain variances) were close to one, that the number of effective sample size was at least 10\% of the number of post-warmup samples, and visually inspected the chains.

For the statistical models, we took into account that the traditional sonority models and the top-down version of NAP (i.e.~SSP\textsubscript{col}, SSP\textsubscript{exp}, MSD\textsubscript{col}, MSD\textsubscript{exp} and NAP\textsubscript{td}) are ordinal models, while the bottom-up version of NAP (NAP\textsubscript{bu}) is a continuous model. The ordinal models predict that certain groups of onset clusters will be better or worse-formed than other group depending on an ordinal score, but they do not assume that the score will be equidistant with respect to its effect on the response variable, log-transformed response times. For this reason, the discrete scores of these models are assumed to have a monotonic effect on the log-response time in our task, that is, having a monotonically increasing or decreasing relationship with the log-response time, while the distance between groups is estimated from the data \citep{burknerModelingMonotonicEffects2018}.

In contrast, NAP\textsubscript{bu} provides scores on a ratio scale, in which the distance between scores is also taken to be informative (as opposed to the ordinal scales of the other models), which is modeled with a continuous predictor that is assumed to have a linear relationship with the log-response times. Finally, as a baseline, we fitted a \textit{null} model which assumes no relationship between the stimuli and the response times.

All the models included a random intercept and slope by subjects (except for the null model that included only a random intercept) and the following weakly regularizing priors: \(\text{Normal}(6, 2)\) for the intercept, \(\text{Normal}(0, 1)\) for the slope, \(\text{Normal}_+(0,1)\) for the variance components, and \(lkj(2)\) for the correlation between by-participant adjustments. The ordinal models also have a Dirichlet prior for the simplex vector that represents the distance between the categories set to one for each of its parameters.

We evaluated the models in three different ways: (i) estimation, (ii) descriptive adequacy, and (iii) model comparison.\\

\begin{description}
\item[Estimation:] We report mean estimates and 95\% quantile-based Bayesian credible intervals. A 95\% Bayesian credible interval is interpreted such that it contains the true value with 95\% probability given the data and the model (see, for example, \citealt{Jaynes1976, MoreyEtAl2015}).

\item[Descriptive adequacy:] We used posterior predictive checks to examine the descriptive adequacy or \enquote{fit} of the models \citep{shiffrinSurveyModelEvaluation2008}. The observed data should look plausible under the posterior predictive distribution of the models. The posterior predictive distribution of each model is composed of simulated datasets generated based on the posterior distributions of its parameters. Given the posteriors of the parameters of the model, the posterior predictive distribution shows how similar data may look. Achieving descriptive adequacy means that the current data could have been predicted with the model. It is important to note that a good fit, that is, passing a test of descriptive adequacy, is not strong evidence in favor of a model. In contrast, a major failure in descriptive adequacy can be interpreted as strong evidence against a model \citep{shiffrinSurveyModelEvaluation2008}. Thus, we use posterior predictive checks to assess whether the model behavior is reasonable and in which situations it is not (see \citealt{gelmanBayesianDataAnalysis2013} for further discussion).

\item[Model comparison:] For model comparison, we examine the out-of-sample predictive accuracy of the different models using $k$-fold ($k=15$) cross-validation stratified by subjects.\footnote{Pareto smoothed importance sampling approximation to leave-one-out cross-validation (implemented in the package \texttt{loo}, \citealt{vehtariParetoSmoothedImportance2015, vehtariPracticalBayesianModel2017}) failed to yield stable estimates.} Cross-validation evaluates the different models with respect to their predictive accuracy, that is, how well the models generalize to new data.
\end{description}

\section{Results}\label{sec:results}

\subsection{Estimations}\label{estimations}

For all the models, the well-formedness score shows a clear effect on response times, with lower scores yielding longer log-transformed response times (see Table~\ref{tab:estimationsTable}).


\begin{table}
  \caption{\label{tab:estimationsTable}Estimations} 
  \begin{tabular}{lS[table-format=-1.5, group-digits=false] 
         >{{[}} S[table-format=-1.5, 
    		  table-space-text-pre={[}, 
    		  table-space-text-post={,},
    		  table-align-text-after=false] <{{,}}
 		    @{\!} S[table-format=-1.5, table-space-text-post={]}] <{{]}}}
	     \lsptoprule
	    & $ \hat\beta $ & \multicolumn{2}{c}{95\% CrI} \\\midrule
	    \multicolumn{4}{l}{Experiment 1}\\
	    SSP\textsubscript{col} & -0.18  & -0.27 & -0.087     \\
	    SSP\textsubscript{exp} & -0.1   & -0.19 & -0.011     \\
	    MSD\textsubscript{col} & -0.13  & -0.2  & -0.056      \\
	    MSD\textsubscript{exp} & -0.052 & -0.11 & 0.0016     \\
	    NAP\textsubscript{td}  & -0.079 & -0.13 & -0.03      \\
	    NAP\textsubscript{bu}  & -0.003 & -0.0054 & -0.00068\\\midrule
	    \multicolumn{4}{l}{Experiment 2}\\
	    SSP\textsubscript{col} & -0.14   & -0.17 & -0.11    \\
	    SSP\textsubscript{exp} & -0.066  & -0.084 & -0.048  \\
	    MSD\textsubscript{col} & -0.099  & -0.12 & -0.078   \\
	    MSD\textsubscript{exp} & -0.039  & -0.049 & -0.03   \\
	    NAP\textsubscript{td}  & -0.071  & -0.085 & -0.058  \\
	    NAP\textsubscript{bu}  & -0.0027 & -0.0032 & -0.0021\\\midrule
	    \multicolumn{4}{l}{Experiment 3}\\
	    SSP\textsubscript{col} &  -0.066   & -0.096 & -0.036   \\
	    SSP\textsubscript{exp} &  -0.043   & -0.065 & -0.02    \\
	    MSD\textsubscript{col} &  -0.045   & -0.066 & -0.024   \\
	    MSD\textsubscript{exp} &  -0.02    & -0.032 & -0.009   \\
	    NAP\textsubscript{td}  &  -0.032   & -0.048 & -0.017   \\
	    NAP\textsubscript{bu}  &  -0.00097 & -0.0015 & -0.00049\\
	    \lspbottomrule
	\end{tabular}
\end{table}


% {Experiment 1}

% \begin{itemize}
% % \tightlist
% \item
%   For SSP\textsubscript{col}: \(\hat\beta = -0.18\text{, }95\% \text{ CrI } = [-0.27,-0.087]\).
% \item
%   For SSP\textsubscript{exp}: \(\hat\beta = -0.1\text{, }95\% \text{ CrI } = [-0.19,-0.011]\).
% \item
%   For MSD\textsubscript{col}: \(\hat\beta = -0.13\text{, }95\% \text{ CrI } = [-0.2,-0.056]\).
% \item
%   For MSD\textsubscript{exp}: \(\hat\beta = -0.052\text{, }95\% \text{ CrI } = [-0.11,0.0016]\).
% \item
%   For NAP\textsubscript{td}: \(\hat\beta = -0.079\text{, }95\% \text{ CrI } = [-0.13,-0.03]\).
% \item
%   For NAP\textsubscript{bu}: \(\hat\beta = -0.003\text{, }95\% \text{ CrI } = [-0.0054,-0.00068]\).
% \end{itemize}

% \textbf{Experiment 2}

% \begin{itemize}
% % \tightlist
% \item
%   For SSP\textsubscript{col}: \(\hat\beta = -0.14\text{, }95\% \text{ CrI } = [-0.17,-0.11]\).
% \item
%   For SSP\textsubscript{exp}: \(\hat\beta = -0.066\text{, }95\% \text{ CrI } = [-0.084,-0.048]\).
% \item
%   For MSD\textsubscript{col}: \(\hat\beta = -0.099\text{, }95\% \text{ CrI } = [-0.12,-0.078]\).
% \item
%   For MSD\textsubscript{exp}: \(\hat\beta = -0.039\text{, }95\% \text{ CrI } = [-0.049,-0.03]\).
% \item
%   For NAP\textsubscript{td}: \(\hat\beta = -0.071\text{, }95\% \text{ CrI } = [-0.085,-0.058]\).
% \item
%   For NAP\textsubscript{bu}: \(\hat\beta = -0.0027\text{, }95\% \text{ CrI } = [-0.0032,-0.0021]\).
% \end{itemize}

% \textbf{Experiment 3}

% \begin{itemize}
% % \tightlist
% \item
%   For SSP\textsubscript{col}: \(\hat\beta = -0.066\text{, }95\% \text{ CrI } = [-0.096,-0.036]\).
% \item
%   For SSP\textsubscript{exp}: \(\hat\beta = -0.043\text{, }95\% \text{ CrI } = [-0.065,-0.02]\).
% \item
%   For MSD\textsubscript{col}: \(\hat\beta = -0.045\text{, }95\% \text{ CrI } = [-0.066,-0.024]\).
% \item
%   For MSD\textsubscript{exp}: \(\hat\beta = -0.02\text{, }95\% \text{ CrI } = [-0.032,-0.009]\).
% \item
%   For NAP\textsubscript{td}: \(\hat\beta = -0.032\text{, }95\% \text{ CrI } = [-0.048,-0.017]\).
% \item
%   For NAP\textsubscript{bu}: \(\hat\beta = -0.00097\text{, }95\% \text{ CrI } = [-0.0015,-0.00049]\).
% \end{itemize}

Note that the posterior of the effect of well-formedness, \(\hat\beta\), is not comparable across models. For the ordinal models, it represents the average increase (or decrease) in the dependent variable associated with two neighboring factor levels, or in other words, \(\hat\beta\) multiplied by the number of categories minus one represents the increase in log-scale between the first and the last category. This means that
it
is highly affected by the number of categories. For the continuous bottom-up model, \(\NAP_{\text{bu}}\),
\(\beta\)
represents the increase in log-scale for one unit in the well-formedness scale. To give some concrete examples from set AA, there are 24 units between /lpal/ and /lkal/ (since their NAP scores are $-129$ and $-153$, respectively); and there are 81 units between /lkal/ and /spal/ ($-48$ and $-129$, respectively). However, for all the models, \(\hat\beta\) is negative, indicating that well-formedness is associated with faster responses. See Appendix~\ref{appendix:a} for the complete output of the models.

The results shown here reflect the final state of the models in the exploratory stage, which is the same as the state of the models in the confirmatory stage. Importantly, the results of the confirmatory studies, Experiments~2–3, which are statistically much more robust, remain consistent with those of Experiment 1, which had a relatively small number of observations. As such, Experiment 1 was not designed to distinguish between the models and it will not be considered in the further presentation of results.

\subsection{Descriptive adequacy}\label{descriptive-adequacy}

The model fits of the different models are shown in Figures~\ref{fig:NullFit}--\ref{fig:NAPbuFit}. The plots in these figures present the dispersion of the average response time results, depicted as red points for related CC clusters, vis-à-vis each model's predictions in the form of distributions, depicted with blue violins. The order of the stimuli, from left to right, follows from the models' scores such that predictions for better-formed clusters appear further to the right. Recall that scores in the NAP\textsubscript{bu} model yield slightly different predictions for each stimulus set (AA vs.~HN).

\subsubsection{Null models}\label{null-models}

The null models are shown in \figref{fig:NullFit} as baselines in the respective experiments (the order of stimuli along the x-axis follows the NAP\textsubscript{bu} scores, but in a forced ordinal scale, with equidistant intervals). The slight differences in predictions for different clusters are due to individual differences in the accuracy. Recall that we subset the response times conditional on the monosyllabic response (when pressing '1') to the forced-choice task. This means that when participants give more monosyllabic answers for a specific cluster, their adjusted intercept will have a greater influence on the predictions of the model for that cluster. In addition, clusters with fewer monosyllabic responses show more variability in their predictions (e.g.~/lf/ vs.~/fl/ in the AA set, on the left side of \figref{fig:NullFit}).



\begin{figure}
\includegraphics[width=0.49\linewidth]{figures/graphics-NullFit-1} \includegraphics[width=0.49\linewidth]{figures/graphics-NullFit-2} \caption{Null model fit. Observed mean log-transformed response times are depicted with red points, distribution of simulated means based on the null model are depicted with blue violins.}\label{fig:NullFit}
\end{figure}

\subsubsection{SSP and MSD models}\label{sec:traditionalModelfit}

We consider a good fit in the case of the ordinal models to be roughly characterized by the following three criteria:
(i) the data are contained within the predictions, i.e. the red points appear within the respective violins;
(ii) the data are consistent within each predicted level, i.e. the vertical dispersion of red points pattern together around the same area within each level (preferably in the middle of the distribution); and
(iii) the model predictors are not redundant, i.e. the violins of the different model levels show little overlap between them.



\begin{figure}[p]
\includegraphics[width=0.49\linewidth]{figures/graphics-SSPcolFit-1} \includegraphics[width=0.49\linewidth]{figures/graphics-SSPcolFit-2} \caption{SSP\textsubscript{col} model fit. Stimuli ordered from left to right according to their score in the model in ascending well-formedness (other details are the same as above).}\label{fig:SSPcolFit}
\end{figure}

\begin{figure}[p]
\includegraphics[width=0.49\linewidth]{figures/graphics-SSPexpFit-1} \includegraphics[width=0.49\linewidth]{figures/graphics-SSPexpFit-2} \caption{SSP\textsubscript{exp} model fit (plot details are the same as above).}\label{fig:SSPexpFit}
\end{figure}

\begin{figure}[p]
\includegraphics[width=0.49\linewidth]{figures/graphics-MSDcolFit-1} \includegraphics[width=0.49\linewidth]{figures/graphics-MSDcolFit-2} \caption{MSD\textsubscript{col} model fit (plot details are the same as above).}\label{fig:MSDcolFit}
\end{figure}

\begin{figure}[p]
\includegraphics[width=0.49\linewidth]{figures/graphics-MSDexpFit-1} \includegraphics[width=0.49\linewidth]{figures/graphics-MSDexpFit-2} \caption{MSD\textsubscript{exp} model fit (plot details are the same as above).}\label{fig:MSDexpFit}
\end{figure}

A quick glance at the four plots for Experiment 2, in the left panels of Figures~\ref{fig:SSPcolFit}--\ref{fig:MSDexpFit}, reveals a common failure of all the traditional sonority models
to contain the nasal plateaus (/mn/ and /nm/) within their predicted distribution alongside all the other plateaus (0 model score in all figures). Furthermore, the data within the 0 plateau levels appears to be broadly dispersed for the German-speaking subjects in Experiment 2 (plots on the left side) but quite well centered for the Hebrew-speaking subjects in Experiment 3 (right plots).

A comparison of the left-most violins in Figures~\ref{fig:SSPcolFit}--\ref{fig:MSDexpFit} highlights some differences between the two sonority hierarchies \emph{H}\textsubscript{col} (SSP\slash MSD\textsubscript{col}) and \emph{H}\textsubscript{exp} (SSP\slash MSD\textsubscript{exp}).
The left-most violins reflect the onset fall levels of the SSP and MSD models.
For the Hebrew-speaking subjects in Experiment 3 (right panels), there was no clear difference between the two sonority hierarchies and a similar, broad distribution appears in all fits of sonority falls. In contrast, the reponse times of German-speaking subjects in Experiment 2 exhibit a bimodal distribution in the falling onsets of sonority models that use the \emph{H}\textsubscript{exp} hierarchy (SSP/MSD\textsubscript{exp}), whereby \emph{fricative-stop} clusters /ʃp, sp, ft/ are considered to be highly ill-formed onset falls.

This suggests that the \emph{H}\textsubscript{col} hierarchy (where all obstruents are grouped into one class on the sonority hierarchy such that \emph{fricative-stop} clusters are considered plateaus) is better than the \emph{H}\textsubscript{exp} hierarchy in treating \emph{fricative-stop} clusters.
This can be deduced from
the better model fits for onset sonority falls and plateaus when the \emph{H}\textsubscript{col} hierarchy is applied (SSP/MSD\textsubscript{col} vs.~SSP/MSD\textsubscript{exp}). However, the difference between the two sonority hierarchies also plays a role in the grouping of onset rises when the MSD-based models are taken into account.

The violins in the right panel of each plot, reflecting well-formed onset rises with positive model scores, present three types of grouping across the four models. The two SSP models (SSP\textsubscript{col/exp}) make identical predictions with respect to onset rises, lumping all rises into one category (1 in Figures~\ref{fig:SSPcolFit}--\ref{fig:SSPexpFit}).
This, again, results in a broader distribution for the German-speaking subjects in Experiment 2 (left panels) compared to the Hebrew-speaking subjects in Experiment 3 (right panels).

The MSD models present multiple levels of well-formedness for onset rises. MSD\textsubscript{col} exhibits two levels of rises (1--2 in \figref{fig:MSDcolFit}) while MSD\textsubscript{exp} exhibits four levels of rises (1--4 in \figref{fig:MSDexpFit}).
This elaboration seems to be beneficial in fitting the scores of the German-speaking subjects to the 4 rise levels of MSD\textsubscript{exp}, but less so for MSD\textsubscript{col}. Furthermore, the additional levels of the MSD are redundant, and even slightly reversed for the fits of the scores of the Hebrew-speaking subjects in Experiment 3 (right plots).

To conclude, an observation of the model fits of the four traditional sonority models in the two confirmatory studies reveals a mixed picture. The \emph{H}\textsubscript{col} hierarchy (in models SSP/MSD\textsubscript{col}) appears to result in a better fit with onset falls and plateaus, especially for the German-speaking subjects.
The competing \emph{H}\textsubscript{exp} hierarchy appears to be advantageous when fitting the scores of rising onset slopes, but mostly with MSD\textsubscript{exp} and only for the German-speaking subjects in Experiment 2, where sonority falls can exhibit an undesirable bimodal distribution.

\subsubsection{NAP models}\label{sec:NAPtdModelfit}\largerpage

Although NAP\textsubscript{td} is an ordinal model like all the traditional sonority models, it follows a different rationale (see Section~\ref{sec:naptdmodel}), whereby the scores of the model estimate nucleus competition to reflect well-formedness.

\begin{sloppypar}
\figref{fig:NAPtdFit} shows that NAP\textsubscript{td} succeeds in containing all the data (points) within the respective predictions (blue violins) in both experiments, making NAP\textsubscript{td} the only model to achieve such coverage.
NAP\textsubscript{td} appears to exhibit some redundancy, as suggested by the relatively large degrees of overlap between some of the predictive distributions of the model. This is apparent from the overlap between violins in the left side (worse-formed) of the model fit with Experiment 2 (left panel), and between violins in the right side (better-formed) of the model fit with Experiment 3 (right panel) in \figref{fig:NAPtdFit}.
\end{sloppypar}

NAP\textsubscript{bu} is different from all the other models in that it presents scores that are specific to each token in a continuous ratio scale, rather than an ordinal scale (i.e.~the distances between scores in the model are also predicted). 
Importantly, the expected correlation between response time and ill-formedness appears to hold for the model fits of NAP\textsubscript{bu} in \figref{fig:NAPbuFit}.

\begin{figure}
\includegraphics[width=0.49\linewidth]{figures/graphics-NAPtdFit-1} \includegraphics[width=0.49\linewidth]{figures/graphics-NAPtdFit-2} \caption{NAP\textsubscript{td} model fit (plot details are the same as above).}\label{fig:NAPtdFit}
\end{figure}

\begin{figure}
\includegraphics[width=0.49\linewidth]{figures/graphics-NAPbuFit-1} \includegraphics[width=0.49\linewidth]{figures/graphics-NAPbuFit-2} \caption{NAP\textsubscript{bu} model fit (plot details are the same as above).}\label{fig:NAPbuFit}
\end{figure}

%See \figref{fig:NAPbuFit} where the expected positive correlation between response time and ill-formedness appears to generally hold for both the predictions and the data of the model fit of NAP\textsubscript{bu}.

Our criteria for goodness of fit based on the plot analyses (see Subsection
\ref{sec:traditionalModelfit}) are not all valid when evaluating NAP\textsubscript{bu} since we have no classes and no vertical dispersion of data (points) within levels, and the horizontal overlap of predictions (violins) between levels requires a different interpretation. However, the criterion for inclusion of data points within the violins of the models' predictions naturally also holds for the NAP\textsubscript{bu} fit, which fails to include the data for the nasal plateaus /nm/ and /mn/ within the respective predictive distribution in Experiment 2 (a failure that is shared by all the traditional models in Experiment 2; see Section~\ref{sec:traditionalModelfit}). Furthermore, in Experiment 2 NAP\textsubscript{bu} also fails to include the /z/-initial clusters -- /zm/ and /zv/ -- within their respective predictive distribution.

The failures in the fit of the NAP\textsubscript{bu} model with German-speaking subjects in Experiment 2 can be split into two types:
(i) nasal-initial clusters -- \emph{nval}, \emph{nmal}, and \emph{mnal} -- which received results on a par with the slowest responses in the data, reflecting an overestimation of well-formedness by the model, and;
(ii) syllables beginning with a voiced sibilant -- \emph{zval} and \emph{zmal} -- which received results that pattern with faster responses, reflecting
an underestimation of well-formedness by the model.

These results may be taken to suggest language-specific top-down effects of German. In German, sibilants are regularly unvoiced/devoiced at edges of clusters, while nasals, on the other hand, can be syllabic. In that sense, German-speaking listeners may be more prone to considering marginal sibilance as a voiceless nucleus repeller and nasality as a potential nucleus attractor.
Compare this with Hebrew (the native language of the subjects in Experiment 3), in which nasals cannot be syllabic and voiced sibilants are common in marginal cluster edges.

\subsection{Model comparison}\label{sec:modComp}

While the model fits give us an insight into the behavior of each model with respect to the data, they are not well-suited for a comparison of different models against a consistent criterion. To do this, we ran out-of-sample predictions using cross-validation, thereby testing the ability of each model to predict unseen items.

\subsubsection{Experiment 2}\label{experiment-2-1}

A bird's eye view of all the six model fits in Experiment 2 is available in \figref{fig:SonFitAll}. The results of the model comparison from Experiment 2 are available in \tabref{tab:resultsmodels}. They reveal a clear advantage of NAP\textsubscript{td} over all other models.
The main metric in the table is the $\smash{\widehat{\text{elpd}}}$ score, henceforth elpd, which stands for \emph{expected log-predictive density} (higher score indicating better predictive accuracy). The raw values are transformed to more informative values that measure the distance from the best score in terms of \emph{difference in elpd}. The size of this difference can be compared to the size of a standard error of difference, \emph{difference SE}.

The difference of NAP\textsubscript{td} from the next three models -- SSP\textsubscript{col}, MSD\textsubscript{col} and NAP\textsubscript{bu} -- is about 6 standard errors (considering that the difference is around 90 elpd and the corresponding standard error is around 15), reflecting a very robust lead for NAP\textsubscript{td}.
The small differences between the next three models (SSP\textsubscript{col}, MSD\textsubscript{col} and NAP\textsubscript{bu}) make them all indistinguishable in the second place.
The two traditional models that are based on the \emph{H}\textsubscript{exp} hierarchy -- SSP/MSD\textsubscript{exp} -- are similar to each other in last place and only marginally better than the null model.

The right-most column in \tabref{tab:resultsmodels}, \emph{weight}, shows model averaging via stacking of predictive distributions. Stacking maximizes the potential elpd score by pulling the predictions of all the different models together. The values under the \emph{weight} column represent the relative contribution of each model to this combined optimal model.
NAP\textsubscript{td} alone contributes the lion's share with 65\% and NAP\textsubscript{bu} comes second with 14\%. This is notable as both NAP models are essentially based on the same principle, 
lending support to the idea that the two models are essentially complementary.
%lending support to the idea top-down and bottom-up lead to two complementary models.
The other traditional models contribute 8\% (SSP\textsubscript{col}) and 3\% (MSD\textsubscript{col}) to this picture, less than the 9\% that the null model manages to contribute.

\subsubsection{Experiment 3}\label{experiment-3}

A bird's eye view of all the six model fits in Experiment 3 is available in \figref{fig:SonFitAllHeb}.
The results of the model comparison from Experiment 3 (see \tabref{tab:resultsmodelsHeb}) reveal a borderline advantage of NAP\textsubscript{td} over other models.
The difference in elpd scores from the next two models -- MSD\textsubscript{col} and NAP\textsubscript{bu} -- is only about 2 standard errors (considering the difference at around 10 elpd and the corresponding standard error at around 5 elpd). %$\widehat{elpd}$).

SSP\textsubscript{col} is more clearly distinguishable from NAP\textsubscript{td}, with a difference that is almost 3 standard errors (about 20:7). MSD\textsubscript{col} and NAP\textsubscript{bu} are barely distinguishable from SSP\textsubscript{col} and NAP\textsubscript{td}. The two traditional models that are based on the \emph{H}\textsubscript{exp} hierarchy -- SSP/MSD\textsubscript{exp} -- are, again, very clearly the worst in the comparison.

The \emph{weight} values of Experiment 3 in \tabref{tab:resultsmodelsHeb} show that, again, NAP\textsubscript{td} alone provides the biggest relative contribution to a combined optimal model, with 61\%. MSD\textsubscript{col} covers almost the entire remaining space with 37\%, leaving NAP\textsubscript{bu} and all the other traditional models with practically zero additional contribution.

\begin{table}
\caption{\label{tab:resultsmodels}\label{tab:7:modelstackingA} All models comparison: Experiment 2. %\textit{Note.} 
The table is ordered by the expected log-predictive density (elpd) score of the models, with a higher score indicating better predictive accuracy. The highest scored model is used as a baseline for the difference in elpd and the difference standard error (SE). The column weight represents the weights of the individual models that maximize the total elpd score of all the models.}

\begin{tabular}{l S[table-format=-5.0] S[table-format=-3.2] S[table-format=2.2] S[table-format=1.2]}
\lsptoprule
model & \multicolumn{1}{c}{$\widehat{\text{elpd}}$} & \multicolumn{1}{c}{Difference in $\widehat{\text{elpd}}$} & \multicolumn{1}{c}{Difference SE} & \multicolumn{1}{c}{weight}\\
\midrule
NAP\textsubscript{td}  & -28595 &   0.00 & 0.00 & 0.65\\
SSP\textsubscript{col} & -28685 & -89.56 & 14.30 & 0.08\\
NAP\textsubscript{bu}  & -28686 & -90.91 & 15.45 & 0.14\\
MSD\textsubscript{col} & -28689 & -93.85 & 14.07 & 0.03\\
MSD\textsubscript{exp} & -28796 & -200.32 & 20.14 & {$\approx$ 0}\\
SSP\textsubscript{exp} & -28806 & -211.12 & 20.20 & {$\approx$ 0}\\
Null        & -28850 & -255.00 & 23.69 & 0.09\\
\lspbottomrule
\end{tabular}
\end{table}



\begin{figure}
\includegraphics[width=0.49\linewidth]{figures/graphics-SonFitAll-1} \includegraphics[width=0.49\linewidth]{figures/graphics-SonFitAll-2} \includegraphics[width=0.49\linewidth]{figures/graphics-SonFitAll-3} \includegraphics[width=0.49\linewidth]{figures/graphics-SonFitAll-4} \includegraphics[width=0.49\linewidth]{figures/graphics-SonFitAll-5} \includegraphics[width=0.49\linewidth]{figures/graphics-SonFitAll-6} \caption{Experiment 2: all sonority model fits (unspecified cluster types, see detailed versions above). Observed mean log-transformed response times are depicted with red points; distribution of simulated means based on the model are depicted with blue violins. Stimuli are ordered from left to right according to their score in a given model in ascending well-formedness.}\label{fig:SonFitAll}
\end{figure}

\begin{table}

\caption{\label{tab:resultsmodelsHeb}\label{tab:modelstackingB}All models comparison: Experiment 3 (details are the same as above)}

\begin{tabular}{l S[table-format=-5.0] S[table-format=-3.2] S[table-format=2.2] S[table-format=1.2]}
\lsptoprule
model & \multicolumn{1}{c}{$\widehat{\text{elpd}}$} & \multicolumn{1}{c}{Difference in $\widehat{\text{elpd}}$} & \multicolumn{1}{c}{Difference SE} & \multicolumn{1}{c}{weight}\\
\midrule
NAP\textsubscript{td} & -22981 & 0.00 & 0.00 & 0.61\\
NAP\textsubscript{bu} & -22990 & -9.58 & 4.82 & {$\approx$ 0}\\
MSD\textsubscript{col} & -22991 & -10.01 & 6.89 & 0.37\\
SSP\textsubscript{col} & -23000 & -19.77 & 6.99 & {$\approx$ 0}\\
SSP\textsubscript{exp} & -23027 & -46.22 & 10.25 & {$\approx$ 0}\\
MSD\textsubscript{exp} & -23031 & -50.44 & 10.10 & {$\approx$ 0}\\
Null & -23053 & -72.62 & 12.52 & 0.01\\
\lspbottomrule
\end{tabular}
\end{table}

\begin{figure}
\includegraphics[width=0.49\linewidth]{figures/graphics-SonFitAllHeb-1} \includegraphics[width=0.49\linewidth]{figures/graphics-SonFitAllHeb-2} \includegraphics[width=0.49\linewidth]{figures/graphics-SonFitAllHeb-3} \includegraphics[width=0.49\linewidth]{figures/graphics-SonFitAllHeb-4} \includegraphics[width=0.49\linewidth]{figures/graphics-SonFitAllHeb-5} \includegraphics[width=0.49\linewidth]{figures/graphics-SonFitAllHeb-6} \caption{Experiment 3: all sonority model fits (plot details are the same as above).}\label{fig:SonFitAllHeb}
\end{figure}

\subsection{Summary of results}\label{sec:discussionResults}

The results of the confirmatory studies, Experiments 2–3, can be summarized as follows:
(i) all of the sonority models we tested are capable of explaining the response time data for different consonant clusters to a reasonable extent;
(ii) the symbolic top-down NAP model, NAP\textsubscript{td}, outperforms all the the other models;
(iii) some interesting differences between the \emph{H}\textsubscript{col} and \emph{H}\textsubscript{exp} sonority hierarchies were observed and the advantages of the minimal \emph{H}\textsubscript{col} sonority hierarchy proved to be more effective.

Experiment 3 exhibits most of the general trends found in Experiment 2, albeit in a less compelling way. 
The Hebrew speakers in Experiment 3 tended to respond relatively fast to ill-formed structures.
One path of explanation for these discrepancies can be found in the differences between the ambient languages. We expect language-specific differences to account for some of the differences between the experiments, as was mentioned in \sectref{sec:designs}. Specifically, the difference between nasals, as well as the difference between voiced sibilants in Hebrew and German, were suggested as explanations in Section~\ref{sec:NAPtdModelfit}.

Moreover, we suspect that differences between the experiments were also due to the various sources of noise that were introduced in the process. These include the smaller group of participants and the diverse physical locations in which Experiment 3 was administered (see Section~\ref{sec:participants3}).
The results may be taken to support this with a larger standard deviation for the by-subject adjustments to the intercept for the models of Experiment 3 in comparison with Experiment 2 (e.g.~\(\hat\sigma_\alpha = 0.32~[0.25, 0.41]\) in Experiment 3 vs.~\(\hat\sigma_\alpha = 0.21~[0.17, 0.26]\) in Experiment~2, when comparing the null models, see the full models in Appendix~\ref{appendix:a}).

%Furthermore, it was the impression of the experimenter (the author) that Hebrew speakers in this study tended to have a less uniform understanding of the notion of the syllable such that their performance may exhibit higher degrees of misunderstanding of the meta-linguistic syllable count task. This impression seems consistent with the overall smaller range of response times in Experiment 3, whereby Hebrew speakers tended to respond relatively fast to ill-formed structures.

The success of our NAP models relative to the traditional models in predicting the data can be mainly attributed to the following traits of NAP:
(i) all the voiceless-initial onset clusters, including onset falls and plateaus (e.g.~/sp/ and /sf/), are relatively well-formed in NAP, correctly predicting the patterning together of such data with faster response times (at the low-right parts of the plots);
(ii) onset rises (like /ml/), nasal plateaus (/nm/ and /mn/), and onset falls (like /lm/) pattern together as similar and relatively ill-formed in NAP, correctly predicting the data, as sonorant-initial plateaus and rises do not tend to pattern with (better-formed) obstruent-initial plateaus and rises.

A superficial formal generalization that can illustrate these results in symbolic terms may be that the sonority \emph{intercept} of onset clusters appears to be (at least) as impactful as the sonority \emph{slope} in determining syllabic well-formed\-ness (i.e.~the starting level of the onset cluster is at least as predictive of well-formedness as the angle of the cluster's slope).
