\chapter{Epilogue}
\label{ch:epilog}




\section{Introduction}

You have been introduced to a variety of language technologies  that are now nearly as pervasive and socially transformative as language itself.  Along the way, we hope you have learned which tasks are easier or harder for a computer and why, what input is required for what output, and at least a rough idea of what goes on in between.  If you come from a computing background, we hope that you've learned to appreciate  the structural and social richness of language as a domain to build tools for.  If you come from a linguistics background,  we hope that you've gained technical expertise and confidence to use your knowledge of language in new ways.  Either way, we hope that students from all backgrounds  feel empowered to further explore language technology.

In this final chapter of the book, we step back to consider the consequences of language technology for economics, education, and society.  We frame the chapter in part as a debate between an imaginary pessimist and optimist, and we invite you to particularly consider the perspectives that you are less inclined to agree with.  We also raise questions to discuss with your classmates.  Whether professionally or just as a member of society, you will encounter these questions again and again.  

\section{Economic consequences}

We have encountered many tools that automate tasks which were previously done by humans -- the work of  proof-readers, editors, language teachers, office assistants,  translators, and customer service workers is now partially replaced or transformed by writers' aids, computer-assisted language learning, text classification, machine translation, and dialog systems, with far-reaching  consequences.


As we've noted throughout the book, a pessimist would worry that human jobs are being automated out of existence.  In the most alarmist scenario, most people could become economically redundant, while only those in charge of the automation rule as oligarchs.  More realistically, millions of people might find that they have trained for a job that no longer exists, and thus  have to \keyword{re-skill} -- learn new skills to get a different job.  Of course, it can be challenging to restart one's career later in life, so some people may end up underemployed and demoralized.
Some jobs could be \keyword{de-skilled} (meaning that the human contribution  is diminished as a result of automation), as when a barista stops making bespoke coffee drinks  to   watch a machine do so.
 A machine can learn to  emulate the repetitive elements of even such training-intensive, high-paying tasks as flying airplanes, identifying cancerous X-rays, picking successful stocks, and finding legal evidence within a trove of documents.  So a pessimist would warn that no job is safe from de-skilling.  
 
 In contrast, an optimist would say that automation can take over the parts of a job that are mentally tedious or physically dangerous.  We saw that human translators find it faster and more enjoyable to revise the output of machine translation (post-editing).  In the ideal scenario, the human and the computer each use their \keyword{comparative advantage} (their unique skills) to complement one another, creating a human-computer team that is more productive than either one alone.  Working in tandem with a computer, the human's work may require more skill, such as the ability to use technology or the critical thinking needed to resolve the issues that the computer can't handle.  When the task is \keyword{up-skilled} in this way, the human feels more fulfilled and can make more money, which also  adds to the wealth of the entire society.

When a job is up-skilled to leverage a more efficient human-computer team, perhaps fewer human workers will be needed -- which, in turn, could be perceived as good or bad.  A pessimist would warn that humans might suffer from unemployment,  poverty, and a loss of purpose.  An optimist might suggest that if society redistributes the wealth generated by the efficient upskilled workforce (expanding on the popular idea of a \keyword{universal basic income}), all people could live comfortably without having to work much.  In Jane Austen's novels from early nineteenth-century England, the main characters live on money from interest and renters, employ servants and buy goods produced by less-privileged laborers, and otherwise occupy themselves with their family lives combined with parties, hunting, travel, piano, and romance.  With a highly efficient automated workforce and redistributive policies, perhaps more people could enjoy the lifestyle of the English landed gentry.  

On the other hand, it is more likely that in light of automation, human labor will transform in quality without decreasing in quantity.  In her 1983 book \textit{More work for Mother: The ironies of household technology from the open hearth to the microwave}, the historian Ruth Schwartz \citet{Cowan:1983} explores why American homemakers spent just as much (unpaid) time on housework in the 1980s, with grocery stores and home appliances,  as they did in the 1700s with home gardens and a kitchen fire.  One might have thought that labor-saving technology would let homemakers  work less, but instead they just re-allocated their labor, for example reading books to their children (perhaps hoping to train them for success in the knowledge economy!) rather than scrubbing laundry by hand. As it became possible over time to maintain the same standard of homemaking with less work, the standards went up -- cooking, cleanliness, and childcare all became more elaborate and work-intensive.  Household appliances to some extent took on work previously done by domestic servants, and the number of servants declined as other occupations grew.  Overall, the nature of work changed, arguably becoming more efficient and pleasant, but the amount of work did not diminish.


In the realm of paid work, the economist John Maynard \citet{Keynes:1931} predicted in the 1930s that his (nonexistent) grandchildren would work only fifteen hours a week as automation made it possible to do the same amount of work in less time.  Keynes was probably correct that a modern person could  maintain a 1930s standard of living on fifteen hours of work per week, but he was incorrect to believe that they would want to.  Depending on how you count, the average number of working hours has declined slightly over time, but remains well above thirty hours a week.  People work because they want to maintain their  standard of living relative to other people rather than an absolute standard.  Moreover, as partial automation makes human labor  more efficient,  the \keyword{opportunity cost} of not working rises with a worker's hourly wage, particularly when people also find  purpose and pleasure in their work.


We have seen that automation has largely not displaced human labor historically, but do you think the future will be different?  What jobs do you think are easier or harder to automate, and why?  To what extent does it relate to the job's level of training, pay, or status?   What do you see as the comparative  advantages of humans versus computers?  
On a philosophical level, what does it mean for our self-concept as humans if our capacity for language, rather than making us unique, can be to some extent emulated by automated tools?

To kick off a discussion, you might review your grandparents' jobs,  your parents' jobs, and your own career plans, to explore how the economic history of technology has played out in your own family.  




\section{Educational consequences}

Language technology also has wide-ranging consequences for  the methods and goals of education.  In terms of methods,  language technologies -- writers'  aids, search, automatic video captioning, CALL, and dialog-capable tutors --  have transformed classrooms, in the best case making education more effective and accessible.  

As for the overall goals, the lightning speed of technological progress means that students must prepare to succeed in a world unfamiliar to their parents and teachers.  Taking the perspective of a strategist (rather than a pessimist or an optimist), what content and skills do you think are most important for students to learn now in order to succeed in an uncertain future? 

Some skills become obsolete quickly, such as secretarial shorthand,  the now-unfashionable programming language FORTRAN, and perhaps spelling.  Other skills might be needed in the future, but can't be taught because they do not exist yet.  But some skills are arguably timeless, such as critical thinking, quantitative reasoning, creativity, communication, and empathy.  As educators, we would argue that the greatest tool of all is learning how to learn -- how to break down an intimidating new topic into bite-sized pieces that you can pursue with confidence and tenacity, which is as much an attitude as a skill.

Do you agree with the list of skills that we have presented as timeless?  How, through what types of courses or assignments, can these skills be taught?  To what extent do you feel that your education is preparing you for success in a fast-changing future?



\section{Socio-political consequences}

%Language technology begins and ends with people.

In any language processing task, the input most likely consists of text or other data produced by people, and the output is used in some manner by people. Like any domain involving people, language technology intertwines issues of power, privacy, and politics. 

Focusing first on the input, a tool usually works best on data  most similar to what it was built for.  As a result, many language technologies work best on the standardized, written varieties of high-resource languages (English, Spanish), while performing much worse on minoritized varieties (African American English) or low-resource languages (Hawaiian), reproducing historical inequalities.  Moreover, all types of machine learning can end up generalizing social biases from their input, as when a machine translation system assigns gendered grammatical information to professions based on stereotypes baked into its training data, or when Tay the chatbot parroted hate speech from users.

An optimist would hope that these problems can be minimized by encouraging people of diverse social and linguistic backgrounds to work in language processing;  gathering more, better, and less-biased data;  penalizing algorithms that reproduce social bias; and  continually trying to improve.  Concretely, one suggestion is to revise the structure of conferences so that abstracts are reviewed not just for quality and originality, but also for potential ethical concerns. It is increasingly common for authors to be asked  how they ensured a fair rate of pay for the gig workers (on platforms such as Mechanical Turk) who produce annotation data. Another suggestion is for wealthy language-processing laboratories to purchase carbon offsets to counterbalance the energy cost of training  language models on huge amounts of data.  When language tools are built using taxpayer money (in the form of government grants), there is a growing movement to make them freely available through open-source software and open-access publications.

A pessimist would counter that such problems cannot be solved just by hacking or talking about them, and worry that it is very difficult for lower-resourced scientists to compete with the massive, expensive, potentially biased data underlying modern language models.


Turning to  output and usage, a pessimist might warn that language technology can be used in dystopian ways.  From your internet usage (writings, searches, purchases, and clicks), technology companies own a huge  amount of information about you, which you may see as a threat to your privacy.  This information can be used to target advertisements for stuff you don't need,  send you down a rabbit hole of ideas far removed from the mainstream, or suggest as much to government authorities.  To the extent that public discourse plays out on such platforms, they also have the power to use language technology to suppress dissent, manufacture consensus, or amplify vitriol.

An optimist would reply that language technology tools have made our lives more efficient, accessible, and interesting in uncountable ways: Imagine life without spell-check, auto-complete, education technology,  filters for spam and hate speech, search engines, recommendation systems, and machine translation.  These tools have problems, of course, but they are arguably still a net positive. 

More generally, do you think that technological progress can or should be stopped?  Alternatively, (how) can it be channeled in beneficent directions?





\begin{tblsfilledsymbol}{Checklist}{test}

% optimistic, pessimistic take on each of these issues.
% explain to a computer scientist why they should learn linguistics, explain to a linguist why they should learn computer science, articulate one key idea for each one.
% sketch different possibilities for the future of work -- 
% define upskilling, deskilling, reskilling, and the pros and cons of each one
% 

\begin{itemize}
\item Explain to a computer scientist why they might benefit from studying some linguistics.
\item Explain to a linguist why they might benefit from studying some computer science.
\item Outline different predictions about the future of work in a world of increasing automation.
\item Give examples of re-skilling, de-skilling, and up-skilling.
\item Articulate what you see as the most important and lasting takeaways of a university education.
\item Give examples of how people who work in language processing are trying to improve the ethical dimension of their work.
\item Sketch pessimistic and optimistic views of the economic, educational, and sociopolitical consequences of rapidly-improving language technology.

% 

\end{itemize}
\end{tblsfilledsymbol}

% no exercises here.


