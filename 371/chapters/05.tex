\chapter{\label{ch:5}Quantitative und qualitative Analyse der Ergebnisse}


\section{\label{sec:5.0}Einleitung}

In diesem Kapitel werden die Ergebnisse quantitativ dargestellt und anhand von Beispielen aus dem Datensatz qualitativ erläutert. Das Kapitel besteht aus vier Unterkapiteln: Im ersten Unterkapitel werden die Ergebnisse einer allgemeinen Analyse des Datensatzes sowie der Teilnehmerprofildaten und \nobreakdash-feedbacks zur Evaluation präsentiert. Die drei weiteren Unterkapitel liefern die Ergebnisse auf den vier Analyseebenen: der Sprachenpaarebene (unter \sectref{sec:5.2}), der Regelebene sowie der Regel- und MÜ-Systemebene (unter \sectref{sec:5.3}) und der MÜ-Systemebene (\sectref{sec:5.4}).

\section{\label{sec:5.1}Allgemeine Analyse}

In diesem Unterkapitel werden die Ergebnisse einer allgemeinen Analyse dargestellt. Diese Analyse umfasst einen Überblick über den untersuchten Datensatz, die Methode der Festlegung der Teilnehmeranzahl bei der Humanevaluation, eine Darstellung der Interrater- und Intrarater-Agreements sowie eine genaue Betrachtung der Teilnehmerprofildaten, der Teilnehmer-Feedbacks zur Evaluation und ihrer Implikationen.

\subsection{Überblick über den Datensatz}
\label{sec:5.1.0}
Zunächst liefert \tabref{tab:05:11} einen Überblick über den Datensatz, der im Rahmen der ersten Analyse (Fehlerannotation) und der zweiten Analyse (Humanevaluation) untersucht wurde. Insgesamt wurden 2.160 Sätze annotiert. Daraus wurden 1.100 von den teilnehmenden Übersetzern bewertet. Darüber hinaus gab es insgesamt 545 MÜ-Sätze, die bei mehreren MÜ-Systemen identisch waren (d.~h. die Ausgangssätze wurden von verschiedenen Systemen identisch übersetzt). Für jeden Ausgangssatz wurde nur eine Instanz der identischen MÜ-Sätze in der Humanevaluation bewertet, somit waren 95 der 545 Instanzen in den 1.100 humanevaluierten MÜ-Sätzen enthalten. Alle weiteren identischen wiederholten Instanzen (450 von 545) erhielten denselben Score der bewerteten Instanzen. Basis der präsentierten statistischen Ergebnisse ist die Summe der humanevaluierten (1.100) und der wiederholten (450) MÜ-Sätze (d.~h. insgesamt 1.550 MÜ-Sätze). Die restlichen 610 Sätze vom Gesamtdatensatz wurden ausgeschlossen. Die Ausschlusskriterien sind unter \sectref{sec:4.4.3.1} [8] und [9] dargestellt.


\begin{table}
\begin{tabularx}{\textwidth}{Xrr}
\lsptoprule
Anzahl der annotierten MÜ (Gesamtdatensatz): & 2.160 & (100~\%)\\
Anzahl der humanevaluierten MÜ: & 1.100 & (51~\%)\\
Anzahl der wiederholten MÜ: & 450 & (21~\%)\\
Anzahl der ausgeschlossenen MÜ: & 610 & (28~\%)\\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:11} Überblick über den Datensatz   }
\end{table}

\subsection{Entwicklung des Mittelwerts der Qualität mit der Zunahme der Teilnehmeranzahl}
\label{sec:5.1.1}
Zur Festlegung der Anzahl der teilnehmenden Bewerter bei der Humanevaluation wurde zunächst mit fünf Teilnehmern getestet und die Anzahl der Teilnehmer sukzessive erhöht bis die akkumulierten Mittelwerte der Stil- und Inhaltsqualität sich stabilisierten (Genaueres zur Teilnehmeranzahl sowie Qualitätsdefinition unter \sectref{sec:4.4.5.3} bzw. \sectref{sec:4.4.5.1}). Wie \figref{fig:05:10} zeigt, begannen sich ab dem 6. Teilnehmer und bis zu dem 8. Teilnehmer die akkumulierten Mittelwerte der Stil- und Inhaltsqualität zu stabilisieren und veränderten sich kaum. Entsprechend wurde die Teilnehmeranzahl nicht weiter erhöht.


\begin{figure}
%\begin{tabularx}{\textwidth}{XX}
%\lsptoprule
%\multicolumn{2}{p{6cm}}{
%\includegraphics[height=.3\textheight]{figures/d3-img007.png}
%} \\
%&
\includegraphics[width=\textwidth]{figures/d3-img008.png}
%\\
%\lspbottomrule
%\end{tabularx}
\caption{\label{fig:05:10} Entwicklung des Mittelwerts der Qualität mit der Zunahme der Teilnehmeranzahl}
\end{figure}

\subsection{Interrater-Agreement}
\label{sec:5.1.2}
Zur Messung des Interrater-Agreements (Interrater-Reliabilität) in der Humanevaluation wurde eine Reliabilitätsanalyse durchgeführt, in der die „Intra-Klassen-Korrelation“ (ICC) berechnet wurde. Die ICC wird zur Berechnung des Agreements zwischen mehr als zwei Beobachtern und bei metrischen Variablen (hier eine 1-5-Likertskala) verwendet (vgl. \citealt{LandisKoch1977}).


\begin{table}
\begin{tabularx}{.4\textwidth}{lr}
\lsptoprule
\textbf{Qualität mit 8 TN} & \textbf{ICC}\\
\midrule
SQ vor KS & 0,816\\
SQ nach KS & 0,763\\
CQ vor KS & 0,891\\
CQ nach KS & 0,890\\
%\multicolumn{5}{p{6cm}}{0 = poor \newline 0,4 – 0,6 moderate} \\
%\multicolumn{5}{p{6cm}}{0 – 0,2 slight  \newline 0,6 – 0,8 substantial} \\
%\multicolumn{5}{p{6cm}}{0,2 – 0.4 fair \newline 0,8 – 1 (almost) perfect}\\
%\multicolumn{5}{p{6cm}}{Interpretation der Koeffizienten als Grad der Übereinstimmung nach \citet{LandisKoch1977}}\\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:12} Interrater-Agreement}
\bspnote{
\begin{tabbing}
0 = poor\hspace{5em} \= 0 -- 0,2 slight\hspace{5em} \= 0,2 -- 0.4 fair\\
0,4 -- 0,6 moderate \> 0,6 -- 0,8 substantial \> 0,8 -- 1 (almost) perfect
\end{tabbing}
Interpretation der Koeffizienten als Grad der Übereinstimmung nach \citet{LandisKoch1977}}
\end{table}

Wie \tabref{tab:05:12} zeigt, ist das Interrater-Agreement bei allen Qualitätsmessungen (Stilqualität „SQ“ und Inhaltsqualität „CQ“ vor und nach der Anwendung der KS) größer als 0,8, mit Ausnahme der Stilqualität nach KS, die knapp unter 0,8 lag. Nach \citet{LandisKoch1977} deutet dieses Ergebnis auf eine „substantial“ bis „(almost) perfect“ Übereinstimmung der Bewertungen der acht Teilnehmer hin (\tabref{tab:05:12}).

\subsection{Intrarater-Agreement}
\label{sec:5.1.3}
Der Datensatz beinhaltete 130 Übersetzungen (von den 2.160 Übersetzungen), die vor und nach der Anwendung der jeweiligen KS-Regel identisch waren (\tabref{tabex:05:10}).

\begin{table}
\begin{tabularx}{\textwidth}{lX}
\lsptoprule
\textbf{Vor-KS} & \bful{Schicken} Sie das Gerät zusammen mit dem Original-Kaufbeleg an nachstehende Adresse \bful{zu}.\\
\textbf{Nach-KS} & \bful{Schicken} Sie das Gerät zusammen mit dem Original-Kaufbeleg an nachstehende Adresse.\\
\textbf{Identische MÜ} & \bful{Send} the device together with the original receipt to the following address.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:10} Beispiel einer identischen MÜ vor und nach KS aus der Regel „Überflüssige Präfixe vermeiden“  }
\end{table}

Von den 130 Übersetzungen wurden 102 (78,4~\%) in der Humanevaluation bewertet (siehe \tabref{tab:05:13}). Dies bot eine wertvolle Gelegenheit dafür, das Intrara\-ter-Agreement (Intrarater-Reliabilität) zu messen. \tabref{tab:05:13} fasst die Anzahl der identischen Übersetzungen sowie der daraus in der Humanevaluation getesteten Übersetzungen bei jeder KS-Regel zusammen:


\begin{table}
%\begin{tabularx}{\textwidth}{XXXXXXXXXXX}

%\lsptoprule
%& \textbf{per} & \textbf{pak} & \textbf{nsp} & \textbf{kos} & \textbf{wte} & \textbf{pas} & \textbf{FVG} & \textbf{Prä} & \textbf{anz} & \textbf{Summe}\\
%\textbf{Identische MÜ}  & 2 & 4 & 3 & 39 & 6 & 0 & 14 & 61 & 1 & \textbf{130}\\
%\textbf{Getestete identische MÜ}  & 2 & 4 & 3 & 31 & 5 & 0 & 10 & 46 & 1 & \textbf{102}\\
%\textbf{\%} & { 2/2} \newline  100~\% & { 4/4} \newline  100~\% & 3/3 100~\% & { 31/39} \newline  79~\% & { 5/6} \newline  83~\% & 0 & { 10/14} \newline  71~\% & { 46/61} \newline  75~\% & { 1/1} \newline  100~\% & { \textbf{102/130}} \newline  \textbf{78~\%}\\
%\lspbottomrule
%\end{tabularx}

% transpose table
\begin{tabularx}{\textwidth}{Xrrr}
\lsptoprule
& {\bfseries Identische MÜ}	& {\bfseries Getestete identische MÜ}	& {\bfseries \%}\\
\midrule
{\bfseries per} &	2	& 2 &	2/2, 100~\%\\
{\bfseries pak}	& 4 & 4 &	4/4, 100~\%\\
{\bfseries nsp} &	3 &	3 &	3/3, 100~\%\\
{\bfseries kos}	& 39 &	31 &	31/39, 79~\%\\
{\bfseries wte}	& 6 &	5 &	5/6, 83~\%\\
{\bfseries pas}	& 0 &	0 &	0\\
{\bfseries FVG}	& 14	& 10	& 10/14, 71~\%\\
{\bfseries Prä} &	61 &	46 &	46/61, 75~\%\\
{\bfseries anz} & 1	& 1	& 1/1, 100~\%\\
\midrule
{\bfseries Summe} & 130 &	102 &	102/130, 78~\%\\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:13} Anzahl der identischen MÜ und der davon in der Humanevaluation getesteten MÜ bei jeder Regel}
\end{table}


Zur Messung des Intrarater-Agreements (Intrarater-Reliabilität) in der Humanevaluation wurde eine Reliabilitätsanalyse durchgeführt, in der die „Intra-Klas\-sen-Korrelation“ (ICC) berechnet wurde. Die ICC wird zur Berechnung des Agreements zwischen mehr als zwei Beobachtern und bei metrischen Variablen (hier eine 1-5-Likertskala) verwendet (vgl. \citealt{LandisKoch1977}).


\begin{table}
%\begin{tabularx}{\textwidth}{XXXXXXXXXXX}

%\lsptoprule

%\multicolumn{2}{p{6cm}}{} & { \textbf{Jam}} & \multicolumn{2}{p{6cm}}{ \textbf{Ryn}} & { \textbf{Ros}} & { \textbf{Ven}} & { \textbf{Tan}} & { \textbf{Cro}} & { \textbf{Stl}} & \textbf{Len}\footnote{Die Namen der Teilnehmer wurden aus Datenschutzgründen abgekürzt.}\\
%\multicolumn{2}{p{6cm}}{\textbf{ICC - SQ}} & { 0,744} & \multicolumn{2}{p{6cm}}{ 0,381} & { 0,599} & { 0,877} & { 0,806} & { 0,790} & { 0,565} & 0,716\\
%\multicolumn{2}{p{6cm}}{\textbf{ICC - CQ}} & { 0,923} & \multicolumn{2}{p{6cm}}{ 0,800} & { 0,739} & { 0,899} & { 0,849} & { 0,835} & { 0,706} & 0,611\\
%{} &  & \multicolumn{7}{p{6cm}}{}\\
%\multicolumn{11}{p{\textwidth}}{0 = poor \newline 0,4 – 0,6 moderate}\\
%\multicolumn{11}{p{\textwidth}}{0 – 0,2 slight \newline 0,6 – 0,8 substantial}\\
%\multicolumn{11}{p{\textwidth}}{0,2 – 0.4 fair \newline 0,8 – 1 (almost) perfect}\\
%\multicolumn{11}{p{\textwidth}}{Interpretation der Koeffizienten als Grad der Übereinstimmung nach Landis und \citet{LandisKoch1977}}\\
%\lspbottomrule
%\end{tabularx}

% transpose table

\begin{tabularx}{.4\textwidth}{lrr}
\lsptoprule
& {\bfseries ICC - SQ}	& {\bfseries ICC - CQ}\\
\midrule
{\bfseries Jam}	& 0,744 &	0,923\\
{\bfseries Ryn}	& 0,381 &	0,800\\
{\bfseries Ros}	& 0,599	& 0,739\\
{\bfseries Ven}	& 0,877 &	0,899\\
{\bfseries Tan}	& 0,806	& 0,849\\
{\bfseries Cro}	& 0,790	& 0,835\\
{\bfseries Stl}	& 0,565	& 0,706\\
{\bfseries Len}\footnotemark&	0,716 &	0,611\\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:14}   Intrarater-Agreement}
\bspnote{\begin{tabbing}
0 = poor\hspace{5em} \= 0 -- 0,2 slight\hspace{5em} \= 0,2 -- 0.4 fair\\
0,4 -- 0,6 moderate \> 0,6 -- 0,8 substantial \> 0,8 -- 1 (almost) perfect
\end{tabbing}
Interpretation der Koeffizienten als Grad der Übereinstimmung nach \citet{LandisKoch1977}}
\end{table}
\footnotetext{Die Namen der Teilnehmer wurden aus Datenschutzgründen abgekürzt.}

Nach den Ergebnissen (\tabref{tab:05:14}) lag das Intrarater-Agreement bei der Inhaltsqualität bei fünf der acht Teilnehmer bei mindestens 0,8 („(almost) perfect“ Übereinstimmung nach \citet{LandisKoch1977}) und bei drei Teilnehmern zwischen 0,6 und 0,8 („substantial“ Übereinstimmung, ebd.). Auf der anderen Seite lag bei der Stilqualität das Intrarater-Agreement nur bei zwei der acht Teilnehmer über 0,8 („(almost) perfect“ Übereinstimmung, ebd.), bei drei Teilnehmern zwischen 0,7 und 0,8 („substantial“ Übereinstimmung, ebd.), bei zwei Teilnehmern bei ca. 0,5 („moderate“ Übereinstimmung, ebd.) und beim letzten Teilnehmer bei ca. 0,3 („fair“ Übereinstimmung, ebd.) (\tabref{tab:05:14}). Eine mögliche Interpretation der Übereinstimmungsunterschiede zwischen der Inhalts- und Stilqualität ist, dass die Bewertung der Inhaltsqualität hinsichtlich der Genauigkeit und der Verständlichkeit in der Regel eine unumstritten eindeutigere Aufgabe im Vergleich zu der Bewertung der Stilqualität ist. Vor diesem Hintergrund werden in einigen Post-Editing-Leitlinien inhaltliche Fehler behoben und stilistische Probleme ignoriert (\citealt{O’BrienEtAl2009}; \citealt{O’Brien2010}), da in der Regel mehrere stilistisch akzeptable Formulierungen denkbar sind.

\subsection{Analyse der Teilnehmerprofildaten und -feedbacks zur Evaluation}
\label{sec:5.1.4}
Im Rahmen der Humanevaluation wurden die Profildaten anhand des Pretests und Posttests (siehe Anhang \ref{app:2}) erhoben. Im \textit{Pretest} wurden die Grunddaten zum Geschlecht, Herkunftsland, Deutschkenntnisse und Übersetzungserfahrung erfragt.


\begin{table}
\begin{tabularx}{\textwidth}{p{.25\textwidth}Q}
\lsptoprule
\textbf{Pretest} & \textbf{Profildaten der Teilnehmer}\\
\midrule
\textbf{Geschlecht}  & Vier Studentinnen und vier Studenten\\
\tablevspace
\textbf{Herkunftsland} & Zwei Teilnehmer aus Großbritannien; sechs aus den USA\\
\tablevspace
  \textbf{Deutschkenntnisse} & Zwei Teilnehmer sind zweisprachig (Englisch/Deutsch) aufgewachsen, wobei sie Englisch als ihre dominante Sprache einschätzen.\newline
    Drei Teilnehmer erwarben Kenntnisse der deutschen Sprache durch den Besuch einer deutschen Schule im Herkunftsland.\newline
    Drei Teilnehmer erlernten die deutsche Sprache im Rahmen von Deutschsprachkursen sowie durch einen vierjährigen Aufenthalt in Deutschland.\\
    \tablevspace
\textbf{Dauer der Übersetzungserfahrung} & Fünf Teilnehmer haben ein Jahr Übersetzungserfahrung.\newline
                                            Zwei Teilnehmer haben zwei Jahre Übersetzungserfahrung.\newline
                                            Ein Teilnehmer hat vier Jahre Teilzeit Übersetzungserfahrung.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:15} Profildaten der Teilnehmer}
\end{table}

Wie \tabref{tab:05:15} (Pretest) zeigt, waren die Teilnehmerprofile bezüglich des Geschlechts ausgewogen. Sie stammen aus zwei englischsprachigen Ländern, beherrschen die deutsche Sprache und verfügen über Übersetzungserfahrung. Ferner wurde die Homogenität der Teilnehmer bereits bei den Teilnahmekriterien (Besitz eines Bachelor-Abschlusses in Translation und das Studium im letzten Semester des Master-Abschlusses Translation) sichergestellt.

Der \textit{Posttest} bestand aus zwei Teilen: Teil 1 \textit{Fachliche Fragen} und Teil 2 \textit{Feedback zur Evaluation bzw. zur Testphase}. Die \textit{Fachlichen Fragen} (Teil 1) wurden erst nach der Evaluation gestellt, damit die Teilnehmer im Vorfeld keinen Hinweis bekommen, worum es sich bei der Bewertung handelt. Dieser Teil bestand aus zwei Fragen:

\begin{description}[font = \normalfont\bfseries]
\item[1. Einstellung zur MÜ:] Die Einstellung zur MÜ wurde durch die Verwendung von MÜ-Systemen erfragt. Die Frage \textit{Wie gehst Du in der Regel vor, wenn Du einen technischen Text übersetzen möchtest? bzw. wie würdest Du vorgehen?} zeigte Folgendes:

Vier der acht Teilnehmer verwenden ein Übersetzungsprogram mit einem Zugriff auf ein MÜ-System zum Übersetzen und anschließend posteditieren sie ihre maschinellen Übersetzungen; zwei Teilnehmer konsultieren ein MÜ-System nur bei Bedarf; zwei Teilnehmer verwenden gar keine MÜ-Systeme, da sie sich mit der Übersetzung literarischer Texte beschäftigen. Auf Basis dieses Ergebnisses wird in der Studie von einer überwiegend positiven Einstellung zur MÜ ausgegangen.

\newpage
\largerpage[3]
\item[2. Kenntnisse bzw. Erfahrung mit der Kontrollierten Sprache] wurden wie folgt erfragt: \textit{Hast Du Erfahrung mit der Kontrollierten Sprache (Controlled Language)?}

Die Antworten der Teilnehmer zeigten, dass sechs Teilnehmern das Thema KS durch das Studium bekannt ist; zwei Teilnehmer haben zudem Übersetzungserfahrung mit der KS; zwei Teilnehmer hatten bislang gar keinen Kontakt mit dem Thema. Die Auswahlmöglichkeiten „Ich beachte im Allgemeinen bei meiner technischen Übersetzung die Regeln der Kontrollierten Sprache“ und „Obwohl die Regeln der Kontrollierten Sprache mir bekannt sind, bevorzuge ich danach nicht zu übersetzen“ wurden von keinem Teilnehmer angekreuzt. Da die Mehrheit der Teilnehmer keine berufliche Erfahrung mit der KS hatte, war ihre Einstellung zur KS noch nicht gefestigt (weder positiv noch negativ). Auf Basis dieses Ergebnisses wird von einer neutralen Einstellung zur KS ausgegangen.
\end{description}\clearpage

Im \textit{Feedback zur Evaluation bzw. zur Testphase} (Teil 2) wurden sechs Fragen über den Umfang, Aufbau und Inhalt der Evaluation gestellt und ihre Implikationen bei der Auswertung berücksichtigt. Dieses Feedback kann außerdem als Erkenntnis bei zukünftigen Untersuchungen dienen. %In \tabref{tab:05:16}
Im Folgenden wurden die Antworten der Teilnehmer zusammengefasst und analysiert:

%\textbf{Feedback zur Evaluation bzw. zur Testphase}


% \begin{table}
% \begin{tabularx}{\textwidth}{X}
% \lsptoprule
% \caption{\label{bkm:Ref36844629}\label{tab:05:} Feedback der Teilnehmer zur Evaluation bzw. zur Testphase}


%\textbf{Feedback der Teilnehmer}\\
\begin{description}[font = \normalfont]
\item [1.] Fandst du die Evaluation lang / umfangreich?\\
Sechs der Teilnehmer fanden den Umfang der Evaluation eher groß, dennoch aufgrund der Zeit- und Ortsflexibilität machbar. Kommentare in diesem Zusammenhang waren: „Es war ziemlich viel, aber ich würde nicht sagen, dass es zu viel war, weil ich genug Zeit hatte. Wenn ich das alles in 2 Wochen hätte schaffen müssen, wäre das zu viel gewesen“ und „die Tests an sich waren meiner Meinung nach nicht unbedingt zu lang oder zu viel, ich hatte meinen Laptop dabei und es war möglich jeden Tag eine Stunde zu finden, in der ich in Ruhe arbeiten konnte.“ Die zwei weiteren Teilnehmer fanden den Umfang der Evaluation groß und gaben an, dass sie wenig Zeit hatten, vor allem weil sie während der Testphase ihre Masterarbeit schrieben.

\textbf{Bedeutung bzw. Implikation}: Auf Basis dieses Feedbacks können der Evaluationsumfang und die dafür vorgesehene Zeitspanne in Kombination mit der Ortsflexibilität als akzeptabel beurteilt werden. Die Gewährung einer zeitlichen und örtlichen Freiheit und Flexibilität ist förderlich und sehr empfehlenswert.

\item[2.] Fandst du die Evaluation interessant / langweilig? Falls langweilig, wann hat die Langweile eingesetzt, nach dem 10., 20., \ldots Test?\\
Die meisten Teilnehmer (6 von 8) gaben an, dass die Evaluation am Anfang interessant war, jedoch etwa ab dem 20. Test begann, langweilig zu werden. Als Hauptgrund hierfür wurde die Wiederholung der MÜ-Sätze genannt. Des Weiteren fanden sie die Evaluation \textit{„ziemlich langweilig, aber durch die Arbeit ohne Zeitdruck ziemlich angenehm“}. Der achte Teilnehmer beschrieb die Evaluation als \textit{„interessant“}.

\textbf{Bedeutung bzw. Implikation}: Bei manchen Ausgangssätzen waren die MÜ-Outputs ähnlich. Die Evaluation der feinen Unterschiede in den MÜ-Sätzen war für das Ziel der Studie unerlässlich. Die MÜ-Sätze wurden auf 44 Tests aufgeteilt und jeder Übersetzer hatte die Möglichkeit min. 1 und max. 3 Tests pro Tag zu bewerten. Bei ähnlichen Untersuchungen könnte es ratsam sein, die Zeitspanne der Evaluation zu verlängern oder die Anzahl der ähnlichen MÜ-Sätze auf mehrere Teilnehmer aufzuteilen, d.~h. eine Erhöhung der Anzahl der Teilnehmer mit einer gleichzeitigen Reduzierung der ähnlichen MÜ-Sätze pro Teilnehmer. Jedoch war es der Forscherin ein Anliegen, alle Testsätze komplett von jedem Teilnehmer bewerten zu lassen, um einem potenziellen negativen Einfluss auf das Agreement vorzubeugen.

\item[3.] Fandst du den Aufbau der Evaluation verständlich / zu schwer?\\
Vier Teilnehmer beschrieben den Aufbau der Evaluation als „verständlich“. Die anderen vier Teilnehmer gaben an, dass es am Anfang schwierig gewesen sei, die Fehler den Qualitätskriterien zuzuordnen.

\textbf{Bedeutung bzw. Implikation}: Einige Teilnehmer wendeten sich mit Rückfragen an den Tester. Damit alle Teilnehmer mit derselben Ausgangssituation bzw. unter denselben Voraussetzungen die Evaluation durchführen konnten, bat der Tester sie, die Testanweisungen genauer zu lesen und wies sie auf die darin enthaltenen Beispiele hin. Eine Intervention durch den Tester wurde vermieden, damit jeder Teilnehmer im Rahmen der vorgeschriebenen Anweisungen sein eigenes Evaluationsschema festlegt und danach bewertet.

\item [4.] Hast Du durch die Bewertung etwas Neues gelernt?\\
Drei Teilnehmer betrachteten die Evaluation als eine Korrekturaufgabe und fanden die genaue Analyse bzw. Differenzierung der Fehler lehrreich bzw. informativ. Ein Teilnehmerkommentar lautete „es wäre spannender, wenn die Übersetzungen unterschiedlich wären“. Ein anderer Teilnehmer fand die Verwendung von MS-Excel für diesen Zweck „hilfreich“. Die weiteren vier Teilnehmer ließen diese Frage unbeantwortet.

\textbf{Bedeutung bzw. Implikation}: Ziel dieser Frage war indirekt Näheres über das Interesse bzw. die Motivation der Teilnehmer zu erfahren. Ebenfalls hier wäre es überlegungswert, die Anzahl der ähnlichen MÜ-Sätze auf mehrere Teilnehmer aufzuteilen (d. h. eine Erhöhung der Anzahl der Teilnehmer mit einer gleichzeitigen Reduzierung der ähnlichen MÜ-Sätze pro Teilnehmer). Jede Entscheidung hat ihre Vor- und Nachteile, die abgewogen werden müssen, wie unter 2 angegeben.

\newpage
\item[5.] War in den DE- oder EN-Sätzen irgendetwas auffällig?\\
Zwei Teilnehmer gaben an, dass sie aufgrund der Übersetzungen davon ausgehen, dass es sich um eine MÜ-Analyse handle. Vier Teilnehmer fanden, dass sich die Fehler oft wiederholten. Zwei Teilnehmer beantworteten die Frage mit „nein“.

\textbf{Bedeutung bzw. Implikation}: Ziel dieser Frage war indirekt zu erfahren, ob die Teilnehmer die KS-Regeln entdecken konnten, was den Antworten der Teilnehmer nach nicht der Fall war und durch die Antworten auf Frage 6 bestätigt wurde.

\item[6.] Kannst Du im Nachhinein erraten, worum es geht?\\
Drei Teilnehmer antworteten, dass es sich um einen Vergleich von MÜ-Systemen handle. Die weiteren Antworten lauteten „Korrekturlesen und Fehleridentifikation“ und „Verständlichkeitsforschung“. Auch diese Frage wurde nicht von allen Teilnehmern beantwortet.

\textbf{Bedeutung bzw. Implikation}: Um auszuschließen, dass die Teilnehmer das Ziel der Studie durch die Sätze erraten konnten und es entsprechend bei der Evaluation gezielt berücksichtigt zu haben, wurde diese Frage direkt gestellt. Den Antworten der Teilnehmer zufolge konnte keiner das Thema der Studie richtig erraten, was insbesondere bei der Bewertung der Stilqualität vorteilhaft ist. Dies kann auf die große Anzahl der bewerteten Sätze sowie die hohe Randomisierung der Sätze der verschiedenen Regeln zurückgeführt werden.
\end{description}
% \lspbottomrule
% \end{tabularx}
% \end{table}


Zu den obengenannten Implikationen kann anhand des Teilnehmerfeedbacks ein mit der Humanevaluation verbundenes Risiko nahezu ausgeschlossen werden: \citet{White2003} thematisiert die Gefahr, dass die Bewerter “react differently to a translated expression if they (think they) know how it got that way. [\ldots] in MT, judges will be more forgiving of particular errors if they think their cause is a trivial bug (e.g., missing lexical item) rather than a serious problem (e.g., scope of modification)”. Weder das erhaltene Feedback im Posttest noch die Kommentare der Teilnehmer bei der Evaluation geben einen Hinweis darauf, dass die Bewertung der Teilnehmer durch den potenziellen technischen Grund der Fehler beeinflusst wurde. Die Teilnehmer, die MÜ-Systeme verwendeten, sind in dem Fall Nutzer mit Übersetzungskompetenz, jedoch besitzen sie kein technisches Wissen über die genaue Systemfunktionsweise bzw. keinen technischen Hintergrund, wie ein Fehler entstehen kann.

\section{\label{sec:5.2} Analyse auf Sprachenpaarebene (regel- und systemübergreifend)}

Fokus der Studie ist zwar der Vergleich des MÜ-Outputs vor vs. nach der Anwendung der \textit{einzelnen} KS-Regel, für einen Gesamtüberblick bietet aber der folgende Abschnitt zunächst ein allgemeines einführendes Bild für diesen Vergleich regel- und systemübergreifend. Die hierfür angewendeten Analysefaktoren sind unter \sectref{sec:5.2.0} genau dargestellt, gefolgt von den Ergebnissen dieser Faktoren. Bezüge auf vorherige Studien werden nicht in diesem Unterkapitel, sondern im Rahmen der Diskussion in \sectref{ch:6} vorgenommen.

\subsection{Analysefaktoren}
\label{sec:5.2.0}
Der Vergleich des MÜ-Outputs vor vs. nach der Anwendung aller analysierten KS-Regeln regel- und systemübergreifend erfolgte nach den folgenden neun Analysefaktoren:

\subsubsection{Erster Analysefaktor: Vergleich der Fehleranzahl vor vs. nach der Anwendung der KS-Regeln}

\begin{itemize}
\item Fragestellung: Gibt es einen Unterschied in der Fehleranzahl nach der Anwendung der KS-Regeln im Vergleich zu vor der Anwendung?
\item Variablen: Summe der Fehler und Mittelwert der Fehleranzahl (von allen Fehlertypen) innerhalb der KS-Stelle; Variablentyp: ordinal
\item Statistische Auswertung: Deskriptive Statistiken auf Basis der Fehlerannotation; Abbildungen: Balken und Fehlerbalken
\item Hypothesen:
  \begin{itemize}[align=left]
  \item[H0 --] Es gibt keinen Unterschied in der Fehleranzahl vor vs. nach der Anwendung der KS-Regeln.

  \item[H1 --] Es gibt einen Unterschied in der Fehleranzahl vor vs. nach der Anwendung der KS-Regeln.
  \end{itemize}
\item Signifikanztest: Wilcoxon; Begründung der Testauswahl: Die Variablen sind ordinal.
\end{itemize}

\subsubsection{Zweiter Analysefaktor: Vergleich der Fehleranzahl vor vs. nach der Anwendung der KS-Regeln außerhalb der KS-Stelle bei der Gruppe RR}

\begin{itemize}
\item Fragestellung: Wie häufig wurde die KS-Stelle vor und nach der Anwendung der KS-Regeln korrekt übersetzt und stieg \textit{gleichzeitig} die Fehleranzahl \textit{außerhalb} der KS-Stelle nach der Anwendung der KS-Regeln?
\item Variablen: Differenzen in der Fehleranzahl bei der Annotationsgruppe RR (RR: MÜ innerhalb der KS-Stelle ist vor und nach der Anwendung der KS-Regeln fehlerfrei); Variablentyp: ordinal.
\item Statistische Auswertung: Häufigkeitstabelle auf Basis der Fehlerannotation

\end{itemize}

\subsubsection{Dritter Analysefaktor: Aufteilung der Annotationsgruppen}

\begin{itemize}
\item In der Studie werden die Ergebnisse der Fehlerannotation in vier Annotationsgruppen unterteilt:

(1) RR: MÜ ist vor und nach der Anwendung der KS-Regel fehlerfrei; (2) FF: MÜ beinhaltet vor und nach der Anwendung der KS-Regel Fehler; (3) RF: MÜ ist nur vor der Anwendung der KS-Regel fehlerfrei; (4) FR: MÜ ist nur nach der Anwendung der KS-Regel fehlerfrei.

\item Fragestellung: Wie hoch ist der Prozentsatz jeder Annotationsgruppe?
\item Statistische Auswertung: Häufigkeiten mit Bootstrapping\footnote{\textrm{Bootstrapping ist ein statistisches Verfahren zur Schätzung der Stichprobenverteilung eines Schätzers durch erneute Stichprobenerstellung mit Ersatz aus der ursprünglichen Stichprobe. Es wird als ein nützliches Verfahren zum Testen der Modellstabilität betrachtet.~(\citealt{IBMnodate})}} auf Basis der Fehlerannotation; Abbildungen: Kreisdiagramm
\end{itemize}

\subsubsection{Vierter Analysefaktor: Vergleich der Fehlertypen vor vs. nach der Anwendung der KS-Regeln}

\begin{itemize}
\item Es werden die 13 analysierten Fehlertypen vor vs. nach der Anwendung der KS-Regeln verglichen.
\item Fragestellung: Kommen bestimmte Fehlertypen vor bzw. nach der Anwendung der KS-Regeln vor?

Davon wird abgeleitet, (1) ob bestimmte Fehlertypen, die vor der Anwendung der KS-Regeln existierten, nach der Anwendung der KS-Regeln eliminiert bzw. reduziert wurden; (2) ob bestimmte Fehlertypen erst nach der Anwendung der KS-Regeln auftraten bzw. deutlich stiegen (im Vergleich zu vor der Anwendung der KS-Regeln).

\item Variablen: Fehler existiert ja/nein; Fehlertyp: dichotom. Summe der Fehler sowie Mittelwert der Fehleranzahl innerhalb der KS-Stelle; Variablentyp: ordinal
\item Statistische Auswertung: Kreuztabellen auf Basis der Fehlerannotation; Abbildungen: Balken
\item Hypothesen:

  \begin{itemize}[align=left]
  \item [H0 --] Es gibt keinen Unterschied in der Häufigkeit der einzelnen Fehlertypen vor vs. nach der Anwendung der KS-Regeln.

  \item [H1 --] Es gibt einen Unterschied in der Häufigkeit der einzelnen Fehlertypen vor vs. nach der Anwendung der KS-Regeln.
  \end{itemize}

\item Signifikanztest: McNemar; Begründung der Testauswahl: Mithilfe des\linebreak McNe\-mar-Tests können zwei verbundene dichotome Parameter verglichen werden, somit kann eine mögliche signifikante Veränderung bei einem Fehlertyp vor vs. nach der Anwendung der KS-Regeln identifiziert werden.
\end{itemize}

\subsubsection{Fünfter Analysefaktor: Vergleich der Qualität vor vs. nach der Anwendung der KS-Regeln}

\begin{itemize}
\item Fragestellung: Gibt es einen Unterschied in der Stil- und Inhaltsqualität der MÜ der KS-Stelle nach der Anwendung der KS-Regeln im Vergleich zu vor der Anwendung?
\item Variablen: Mittelwert der Qualitätspunktzahlen der acht Teilnehmer auf der Likert-Skala; Variablentyp: metrisch
\item Statistische Auswertung: Deskriptive Statistiken auf Basis der Humanevaluation; Abbildungen: Fehlerbalken
\item Hypothesen:

  \begin{itemize}[align=left]
  \item [H0 --] Es gibt keinen Qualitätsunterschied vor vs. nach der Anwendung der KS-Regeln.

  \item [H1 --] Es gibt einen Qualitätsunterschied vor vs. nach der Anwendung der KS-Regeln.
  \end{itemize}

\item Signifikanztest: Wilcoxon; Begründung der Testauswahl: Nicht alle Qualitätswerte sind normalverteilt. Wilcoxon kann bei normalverteilten sowie nicht-normalverteilten Variablen verwendet werden.
\end{itemize}

\subsubsection{Sechster Analysefaktor: Vergleich der Qualität vor vs. nach der Anwendung der KS-Regeln auf Annotationsgruppenebene}

\begin{itemize}
\item Fragestellung: Gibt es einen Unterschied in der Stil- und Inhaltsqualität bei den einzelnen Annotationsgruppen nach der Anwendung der KS-Regeln im Vergleich zu vor der Anwendung?

Davon wird abgeleitet, (1) ob bei der Gruppe RR die Stil- bzw. Inhaltsqualität vor bzw. nach der Anwendung der KS-Regeln höher ist, obwohl die MÜ in beiden Fällen fehlerfrei ausfällt; (2) ob bei der Gruppe FF die Stil- bzw. Inhaltsqualität vor bzw. nach der Anwendung der KS-Regeln höher ist, obwohl die MÜ in beiden Fällen Fehler beinhaltet; (3) ob bei der Gruppe RF die Stil- bzw. Inhaltsqualität nach der Anwendung der KS-Regeln stieg, obwohl die MÜ nach der Anwendung der KS-Regeln Fehler beinhaltet und davor fehlerfrei war; (4) ob bei der Gruppe FR die Stil- bzw. Inhaltsqualität nach der Anwendung der KS-Regeln sank, obwohl die MÜ nach der Anwendung der KS-Regeln fehlerfrei war und davor Fehler beinhaltete.

\item Variablen: Mittelwert der Qualitätspunktzahlen der acht Teilnehmer auf der Likert-Skala in jeder Annotationsgruppe; Variablentyp: metrisch
\item Statistische Auswertung: Deskriptive Statistiken auf Basis der Humanevaluation unter Aufteilung der Daten nach den Annotationsgruppen; Abbildungen: Fehlerbalken
\item Hypothesen:

  \begin{itemize}[align=left]
  \item [H0 --] Bei den Annotationsgruppen gibt es keinen Qualitätsunterschied vor vs. nach der Anwendung der KS-Regeln.

  \item [H1 --] Bei den Annotationsgruppen gibt es einen Qualitätsunterschied vor vs. nach der Anwendung der KS-Regeln.
  \end{itemize}

\item Signifikanztest: Wilcoxon; Begründung der Testauswahl: Nicht alle Qualitätswerte sind normalverteilt. Wilcoxon kann bei normalverteilten sowie nicht-normalverteilten Variablen verwendet werden.
\end{itemize}

\subsubsection{Siebter Analysefaktor: Korrelation zwischen den Fehlertypen und der Qualität}

\begin{itemize}
\item Fragestellung: Besteht ein Zusammenhang zwischen der Differenz der Fehleranzahl eines bestimmten Fehlertyps (Fehleranzahl nach KS \textit{minus} Fehleranzahl vor KS) und der Differenz der Stil- bzw. Inhaltsqualität (Qualität nach KS \textit{minus} Qualität vor KS)?
\item Variablen: Differenz der Mittelwerte der Qualitätspunktzahlen der acht Teilnehmer auf der Likert-Skala; Variablentyp: metrisch. Differenz der Fehleranzahl der einzelnen Fehlertypen; Variablentyp: ordinal.
\item Statistische Auswertung: Spearman-Korrelationstest
\item Hypothesen:

  \begin{itemize}[align=left]
  \item [H0 --] Es besteht kein Zusammenhang zwischen der Differenz der Fehleranzahl eines bestimmten Fehlertyps und der Differenz der Stil- bzw. Inhaltsqualität.

  \item [H1 --] Es besteht ein Zusammenhang zwischen der Differenz der Fehleranzahl eines bestimmten Fehlertyps und der Differenz der Stil- bzw. Inhaltsqualität.
  \end{itemize}

\item Signifikanztest: Spearman-Korrelationstest; Begründung der Testauswahl: Eine der Variablen ist ordinal. Zudem setzt Spearman keine Anforderung an die Verteilung und die Linearität voraus.
\end{itemize}

\subsubsection{Achter Analysefaktor: Vergleich der AEM-Scores vor vs. nach der Anwendung der KS-Regeln}

\begin{itemize}
\item Fragestellung: Gibt es einen Unterschied in den AEM-Scores von TERbase bzw. hLEPOR nach der Anwendung der KS-Regeln im Vergleich zu vor der Anwendung?
\item Variablen: Mittelwert der AEM-Scores\footnote{{{{Bei jeder MÜ wurde der Mittelwert der AEM-Scores auf Basis von zwei Referenzübersetzungen ermittelt; für eine genaue Beschreibung des Verfahrens siehe \sectref{sec:4.4.6.4}.}}}} sowie Differenzen der AEM-Scores (AEM-Score nach KS \textit{minus} AEM-Score vor KS); Variablentyp: metrisch
\item Statistische Auswertung: Deskriptive Statistiken auf Basis der automatischen Evaluation; Abbildungen: Fehlerbalken für die Differenzen der AEM-Scores\footnote{{{{Bei der Auswertung werden nur die Differenzen der AEM-Scores (und nicht die Mittelwerte der AEM-Scores) verwendet. Der Grund dafür ist, dass die Bewerter die komplette MÜ editiert haben. Ihre Edits können daher Stellen außerhalb der KS-Stelle umfassen. Da aber die MÜ vor und nach KS außerhalb der KS-Stelle vereinheitlicht wurden, wird hier davon ausgegangen, dass wir durch die Verwendung der Differenz (AEM-Score nach KS $-$ AEM-Score vor KS) nur die Edits innerhalb der KS-Stelle betrachten; für eine detaillierte Erläuterung siehe \sectref{sec:4.4.6.4}.}}}}
\item Hypothesen:

  \begin{itemize}[align=left]
  \item [H0 --] Es gibt keinen Unterschied in den AEM-Scores vor vs. nach der Anwendung der KS-Regeln.

  \item [H1 --] Es gibt einen Unterschied in den AEM-Scores vor vs. nach der Anwendung der KS-Regeln.
  \end{itemize}

\item Signifikanztest: Wilcoxon; Begründung der Testauswahl: Nicht alle Qualitätswerte sind normalverteilt. Wilcoxon kann bei normalverteilten sowie nicht-normalverteilten Variablen verwendet werden.
\end{itemize}

\subsubsection{Neunter Analysefaktor: Korrelation zwischen den AEM-Scores-Differenzen und der Qualitätsdifferenz}

\begin{itemize}
\item Fragestellung: Besteht ein Zusammenhang zwischen der Differenz der AEM-Scores in TERbase bzw. hLEPOR (Mittelwert der AEM-Scores nach KS \textit{minus} Mittelwert der AEM-Scores vor KS) und der Differenz der allgemeinen Qualität\footnote{{{{Die allgemeine Qualität ist der Mittelwert der Stilqualität und der Inhaltsqualität, da bei der Untersuchung dieser Korrelation keine Unterscheidung zwischen der Stil- und Inhaltsqualität notwendig ist.}}}} (Qualität nach KS \textit{minus} Qualität vor KS)?
\item Variablen: Differenz der Mittelwerte der AEM-Scores sowie Differenz der Mittelwerte der Qualitätspunktzahlen der acht Teilnehmer auf der Likert-Skala; Variablentyp: metrisch
\item Statistische Auswertung: Spearman-Korrelationstest
\item Hypothesen:
  \begin{itemize}[align=left]
  \item [H0 --] Es besteht kein Zusammenhang zwischen der Differenz der AEM-Scores und der Differenz der allgemeinen Qualität.

  \item [H1 --] Es besteht ein Zusammenhang zwischen der Differenz der AEM-Scores und  der Differenz der allgemeinen Qualität.
  \end{itemize}

\item Signifikanztest: Spearman-Korrelationstest; Begründung der Testauswahl: Nicht alle Variablen sind normalverteilt. Spearman setzt keine Anforderung an die Verteilung und die Linearität voraus.
\end{itemize}

\subsection{Vergleich der Fehleranzahl vor vs. nach der Anwendung aller KS-Regeln}
\label{sec:5.2.1}
Die Fehleranzahl sank system- und regel-übergreifend signifikant um knapp 23,5~\% (\figref{fig:05:11}) von 738 Fehlern vor der Anwendung der KS-Regeln (M = ,68 / SD = ,898 / N = 1080) auf 562 Fehler nach der Anwendung der KS-Regeln (M = ,52 / SD = ,825 / N = 1080) (\figref{fig:05:12}).\footnote{\figref{fig:05:12} ist wie folgt zu lesen: Die Punkte zeigen, wie hoch die durchschnittliche Fehleranzahl ausfällt (z.~B. ,68 vor KS). Die Fehlerbalken zeigen das realisierte 95 \%-Konfidenzintervall (CI) für die durchschnittliche Fehleranzahl (in dem Fall beläuft sich das CI vor KS auf ,63; ,74). Demnach würde die Fehleranzahl bei der Durchführung einer weiteren vergleichbaren Untersuchung mit einer Wahrscheinlichkeit von 95~\% zwischen ,63 und ,74 liegen (vgl. \citealt{Eckstein2008}: 81).}


%\begin{table}
%\begin{tabularx}{\textwidth}{XX}
%\lsptoprule
%\multicolumn{2}{p{6cm}}
%{\includegraphics[height=.3\textheight]{figures/d3-img009.png}\newline \textbf{\textit{$-$ 23,5\%}}\newline \textbf{\textit{Signifikante Diff.}}}\\

\begin{figure}
\begin{tikzpicture}
  \begin{axis}[
     ybar,
     ymin = 0,
     ymax = 800,
     axis lines* = left,
     xtick = {0,1},
     xticklabels = {{vor KS},{nach KS}},
%      xtick=data,
     nodes near coords,
     ylabel = {Summe},
     bar shift = 0pt,
     width = .5\textwidth,
     extra description/.code={
     \node at (axis cs:.3, 700)[anchor=west]{\bfitul{$-$ 23,5\%}};
     }
  ]
  \addplot+[tmnlpone] coordinates { (0, 738) };
  \addplot+[tmnlpthree] coordinates {(1, 562)};
  \end{axis}
\end{tikzpicture}
	\caption{\label{fig:05:11} Summe der Fehleranzahl vor vs. nach KS auf Sprachenpaarebene}
  \bspnote{\bfitul{Signifikante Diff.}}
\end{figure}

%\lspbottomrule
%\end{tabularx}
%
%\end{table}



  Der Mittelwert der Differenz (nach KS minus vor KS) in der Fehleranzahl pro Satz lag bei $-$~,16 (SD =~,961) mit einem 95\%-Konfidenzintervall\footnote{\textrm{Konfidenzintervalle bezeichnen „Intervalle mit einer Ober- und einer Untergrenze. Sie geben die Sicherheit der Schätzung einer gesuchten Kenngröße, z. B. des Mittelwerts, an“ \citep{Keller2015}.}} zwischen einem Minimum von $-$~,22 (SD = ,901) und einem Maximum von $- 0,10$ (SD = 1,026) (Bootstrapping mit 1000 Stichproben).\footnote{\textrm{Bootstrapping ist eine Resampling-Methode, bei der aus der Stichprobe viele Stichproben (in der vorliegenden Studie 1000 Stichproben) entnommen werden. Die Datenanalyse wird dann jeweils auf Grundlage der vielen Stichproben durchgeführt und die Ergebnisse werden zu einem Endergebnis zusammengefasst und mit dem Konfidenzintervall (CI) (in dieser Studie mit CI 95~\%) angegeben. Ziel ist es, ein verlässliches Endergebnis zu erhalten, auch wenn die Daten nicht normalverteilt sind oder Ausreißer beinhalten \citep{Keller2019}. Mehr zu Bootstrapping in \citet{Chernick2008}.}} Die Differenz (nach KS $–$ vor KS) in der Fehleranzahl erwies sich als hochsignifikant ($z (N = 1080) = - 5,589, p < 0,001$).


\begin{figure}
{\itshape}
\includegraphics[width=.7\textwidth]{figures/Abb12-num.png}
\caption{\label{fig:05:12}Mittelwert der Fehleranzahl pro Satz vor vs. nach KS auf Sprachenpaarebene}
\end{figure}

\subsection{Vergleich der Fehleranzahl vor vs. nach KS außerhalb der KS-Stelle bei der Gruppe RR}
\label{sec:5.2.2}
Ein Szenario, das nicht außer Acht gelassen durfte, war die Untersuchung, ob die KS-Stelle vor und nach der Anwendung der KS-Regeln korrekt übersetzt wurde \textit{und gleichzeitig} die Fehleranzahl \textit{außerhalb} der KS-Stelle nach der Anwendung der KS-Regeln stieg. In der folgenden Häufigkeitstabelle (\tabref{tab:05:17}) werden die Ergebnisse präsentiert (N = 490).


\begin{table}
\begin{tabularx}{\textwidth}{Xrrrr}
\lsptoprule
\textbf{Differenz der Fehleranzahl}
\textbf{nach KS \textit{minus}} \textbf{vor KS außerhalb KS} & Häufigkeit & Prozent & \makecell[rt]{Gültige\\Prozente} & \makecell[rt]{Kumulierte\\Prozente}\\
\midrule
 \textbf{+~3} & 3 & ,6 & ,6 & ,6\\
 \textbf{+~2} & 2 & ,4 & ,4 & 1,0\\
 \textbf{+~1} & 27 & 5,5 & 5,5 & 6,5\\
 \textbf{0} & 413 & 84,3 & 84,3 & 90,8\\
 \textbf{$-$ 1} & 30 & 6,1 & 6,1 & 96,9\\
 \textbf{$-$ 2} & 10 & 2,0 & 2,0 & 99,0\\
 \textbf{$-$ 3} & 4 & ,8 & ,8 & 99,8\\
 \textbf{$-$ 5} & 1 & ,2 & ,2 & 100,0\\
 \midrule
 \textbf{Gesamt} & 490 & 100,0 & 100,0 & \\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:17}   Häufigkeit der Differenz der Fehleranzahl außerhalb der KS-Stelle bei einer korrekten Übersetzung der KS-Stelle auf Sprachenpaarebene}
\end{table}

\tabref{tab:05:17} listet die Differenzen in der Fehleranzahl aller Übersetzungen auf, die innerhalb der KS-Stelle vor und nach der Anwendung der KS-Regeln fehlerfrei waren, aber eine Veränderung in der Fehleranzahl außerhalb der KS-Stelle hatten. Nach den demonstrierten Häufigkeiten der Differenzen gab es keinen auffälligen Anstieg oder Abstieg bei der Fehleranzahl.

Ferner wurden die Daten getrennt auf Regelebene und auf Systemebene untersucht, um herauszufinden, ob ein auffälliger Anstieg bei einer bestimmten Regel bzw. einem bestimmten System vorkam. Auf Regelebene gab es keine hohen Häufigkeiten. Auf Systemebene stieg nur bei Google Translate und Bing die Fehleranzahl um +~1 Fehler: bei Google Translate 10 Mal innerhalb von 183 Fällen und bei Bing 12 Mal innerhalb von 81 Fällen. Es handelt sich hierbei um vereinzelte Anstiege, die bei verschiedenen KS-Regeln vorkamen (mehr dazu unter \sectref{sec:5.4.2}).

\subsection{Aufteilung der Annotationsgruppen}
\label{sec:5.2.3}
Aus der Untersuchung der Aufteilung der Annotationsgruppen ergab sich Folgendes (\figref{fig:05:13}):


%\begin{figure}
%\includegraphics[height=.3\textheight]{figures/d3-img011.png}
%\includegraphics[height=.3\textheight]{figures/d3-img012.png}
%\caption{\label{bkm:Ref51544564}\label{fig:05:} Aufteilung der Annotationsgruppen auf Sprachenpaarebene}
%\end{figure}

\begin{figure}
%	\begin{tikzpicture}
%		\begin{axis}[marzoukBar, symbolic x coords = {FF, RF, FR, RR}, width=.9\textwidth,
%			legend style={at={(0.5,1.4)}, anchor=north,legend columns=1},]
%			\addplot coordinates {(FF, 481) (RF, 106) (FR, 214) (RR, 481)};
%			\addlegendentry{}
%			\addplot coordinates {(FF, 50) (FR, 37) (RR, 31) (RF, 2)};
%			\addlegendentry{KS-Regel: Anführungszeichen verwenden}
%		\end{axis}
%	\end{tikzpicture}

  \torte{279}{214}{106}{481}
	\caption{\label{fig:05:13} Aufteilung der Annotationsgruppen auf Sprachenpaarebene}
\end{figure}

Knapp 45~\% der Übersetzungen waren sowohl vor als auch nach der Anwendung der KS-Regeln korrekt (Gruppe RR). Außerdem waren fast 26~\% der Übersetzungen vor und nach der Anwendung der KS-Regeln (Gruppe FF) falsch. Im nächsten Abschnitt werden die persistenten Fehlertypen ins Visier genommen. Wesentlich im Ergebnis ist, dass ungefähr 20~\% der vor KS falschen Übersetzungen nach KS korrigiert wurden (Gruppe FR). Gleichzeitig gab es Fälle (ca. 10~\%), die nur nach KS falsch übersetzt wurden (Gruppe RF) (\figref{fig:05:13}).

Die Ermittlung der Konfidenzintervalle (CI 95\%) der Aufteilung der Annotationsgruppen mithilfe eines Bootstrapping mit 1000 Stichproben ergab die folgenden Unter- und Oberwerte (N = 1080):


\begin{table}
\begin{tabularx}{\textwidth}{XXXXXX}
\lsptoprule
\multirow[b]{3}{=}{\textbf{Annotations-gruppe}} &  &  & \multicolumn{3}{c}{ \textbf{Bootstrapping}}\\
\cmidrule(lr){4-6}
&  &  &  & \multicolumn{2}{c}{ \textbf{95\%-Konfidenzintervall}}\\
%\hhline%%replace by cmidrule{~~~---}
\cmidrule(lr){5-6}
 & \textbf{Häufigkeit} & \textbf{Prozente} &  \textbf{Verzerrung} & \textbf{Unterer Wert} & \textbf{Oberer Wert}\\
 \midrule
 \textbf{FF} & 279 & 25,8 & ,0 & 23,1 & 28,5\\
 \textbf{FR} & 214 & 19,8 & ,0 & 17,4 & 22,3\\
 \textbf{RF} & 106 & 9,8 & ,0 & 8,1 & 11,6\\
 \textbf{RR} & 481 & 44,5 & ,0 & 41,5 & 47,5\\
 \midrule
 \textbf{Gesamt} & 1080 & 100,0 & ,0 & 100,0 & 100,0\\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:18}   Konfidenzintervalle (CI 95\%) der Aufteilung der Annotationsgruppen auf Sprachenpaarebene}
\end{table}

Durch das 95\%-Konfidenzintervall wird belegt, dass bei der Durchführung einer weiteren vergleichbaren Untersuchung die Aufteilung der Annotationsgruppen mit einer Wahrscheinlichkeit von 95~\% zwischen den aufgeführten Unter- und Oberwerten liegen würde.

\subsection{Vergleich der Fehlertypen vor vs. nach der Anwendung aller KS-Regeln}
\label{sec:5.2.4}
Die Veränderungen in der Fehleranzahl bei den verschiedenen Fehlertypen nach der Anwendung der KS-Regeln variieren zwischen gestiegen, gesunken und fast gleichgeblieben (\figref{fig:05:14}). Eine positive Wirkung hatten die KS-Regeln am stärksten auf den semantischen Fehlertyp SM.13 „Kollokation“ ($-$~68~\%) gefolgt von dem lexikalischen Fehlertyp LX.3 „Wort ausgelassen“ ($-$ 61~\%). Als nächstes sank der grammatische Fehler GR.8 „Falsches Verb“ ($-$~56~\%) gefolgt vom orthografischen OR.2 „Großschreibfehler“ ($-$~52~\%). Weitere Rückgänge der Fehleranzahl waren bei dem GR.10 „Wortstellungsfehler“ ($-$ 38~\%) und dem GR.9 „Kongruenzfehler“ ($-$~21~\%) zu beobachten. Zudem nahmen, wie die \figref{fig:05:14} zeigt, einige Fehlertypen nach der Anwendung der KS-Regeln zu. Dies ist insbesondere beim LX.6 „Konsistenzfehler“ (+~700~\%) und dem orthografischen OR.1 „Zeichensetzungsfehler“ (+~186~\%) der Fall.


%\begin{table}
%\begin{tabularx}{\textwidth}{llXX}
%\lsptoprule
%\multicolumn{3}{p{6cm}}{
%\includegraphics[height=.3\textheight]{figures/d3-img013.png}\newline
%        \textbf{\textit{$-$ 38~\%}}\newline
%        \textbf{\textit{$-$ 21~\%}}\newline
%        \textbf{\textit{$-$ 61~\%}}\newline
%        \textbf{\textit{+~186~\%}}\newline
%        \textbf{\textit{$-$ 68~\%}}\newline
%        \textbf{\textit{$-$ 56~\%}}\newline
%        \textbf{\textit{$-$ 52~\%}}\newline
%        \textbf{\textit{+~700~\%}}
%}
%    & OR.1: Orthografie – Zeichensetzung\\
%\hhline%%replace by cmidrule{~~~-}
%&  &  & OR.2: Orthografie – Großschreibung\\
%\hhline%%replace by cmidrule{~~~-}
%&  &  & LX.3: Lexik – Wort ausgelassen\\
%\hhline%%replace by cmidrule{~~~-}
%&  &  & LX.4: Lexik – Wort zusätzlich falsch eingefügt\\
%\hhline%%replace by cmidrule{~~~-}
%&  &  & LX.5: Lexik – Wort unübersetzt geblieben (auf DE wiedergegeben)\\
%\hhline%%replace by cmidrule{~~~-}
%&  &  & LX.6: Lexik – Konsistenzfehler\\
%\hhline%%replace by cmidrule{~~~-}
%&  &  & GR.7: Grammatik – Falsche Wortart / Wortklasse\\
%\hhline%%replace by cmidrule{~~~-}
%&  &  & GR.8: Grammatik – Falsches Verb (Zeitform, Komposition, Person)\\
%\hhline%%replace by cmidrule{~~~-}
%&  &  & GR.9: Grammatik – Kongruenzfehler (Agreement)\\
%\hhline%%replace by cmidrule{~~~-}
%&  &  & GR.10: Grammatik – Falsche Wortstellung\\
%\hhline%%replace by cmidrule{~~~-}
%&  &  & SM.11: Semantik – Verwechslung des Sinns\\
%\hhline%%replace by cmidrule{~~~-}

 %& \textbf{\textit{Signifikante Diff.}}

%\includegraphics[height=.3\textheight]{figures/d3-img013.png}

%\includegraphics[height=.3\textheight]{figures/d3-img013.png} & vor KS\newline nach KS & SM.12: Semantik – Falsche Wahl\\
%&  &  & SM.13: Semantik – Kollokationsfehler\\
%\hhline%%replace by cmidrule{~~~-}
%\lspbottomrule
%\end{tabularx}
%\caption{\label{bkm:Ref36826894}\label{fig:05:} Summe der Fehleranzahl der einzelnen Fehlertypen vor vs. nach KS auf Sprachenpaarebene}
%\todo[inline]{check captioning}
%\end{table}
\begin{figure}
% 14
\pgfplotstableread{
1 22
2 63
3 86
4 41
5 89
6 35
7 42
8 44
9 2
10 5
11 1
12 8
13 15
14 8
15 54
16 24
17 43
18 34
19 143
20 89
21 149
22 150
23 39
24 44
25 53
26 17
}\datatable
\smbars[extra description/.code={
\node at (axis cs:.15, 80)[anchor=west]{\bfitul{$+$ 186\%}};
\node at (axis cs:2, 100)[anchor=west]{\bfitul{$-$ 52\%}};
\node at (axis cs:4, 110)[anchor=west]{\bfitul{$-$ 61\%}};
\node at (axis cs:10, 20)[anchor=west]{\bfitul{$+$ 700\%}};
\node at (axis cs:14, 65)[anchor=west]{\bfitul{$-$ 56\%}};
\node at (axis cs:16, 75)[anchor=west]{\bfitul{$-$ 21\%}};
\node at (axis cs:22, 140)[anchor=west]{\bfitul{$-$ 38\%}};
\node at (axis cs:24.5, 65)[anchor=west]{\bfitul{$-$ 68\%}};
}]{}
\caption{Summe der Fehleranzahl der einzelnen Fehlertypen vor vs. nach KS auf Sprachenpaarebene}
\label{fig:05:14}
\bspnote{\bful{\textit{Signifikante Diff.}}\\
  OR.1: Orthografie -- Zeichensetzung\\
  OR.2: Orthografie -- Großschreibung\\
  LX.3: Lexik -- Wort ausgelassen\\
  LX.4: Lexik -- Wort zusätzlich falsch eingefügt\\
  LX.5: Lexik -- Wort unübersetzt geblieben (auf DE wiedergegeben)\\
  LX.6: Lexik -- Konsistenzfehler\\
  GR.7: Grammatik -- Falsche Wortart / Wortklasse\\
  GR.8: Grammatik -- Falsches Verb (Zeitform, Komposition, Person)\\
  GR.9: Grammatik -- Kongruenzfehler (Agreement)\\
  GR.10: Grammatik -- Falsche Wortstellung\\
  SM.11: Semantik -- Verwechslung des Sinns\\
  SM.12: Semantik -- Falsche Wahl\\
  SM.13: Semantik -- Kollokationsfehler
  }
\end{figure}

Nur bei den folgenden Fehlertypen erwies sich die Differenz in der Fehleranzahl als signifikant (\tabref{tab:05:19}).

\begin{table}
%\small
\begin{tabularx}{\textwidth}{QlYYY}
\lsptoprule
 & \textbf{N} & \textbf{Mittelwert} & \textbf{Standard-abweichung} & { \textbf{Signifikanz}}\newline  \textbf{(McNemar-Test)}\\
\midrule
\textbf{OR.1: Orthografie -- Zeichensetzung} & 1080 & { vor KS = ,02}\newline  nach KS = ,06 & { vor KS = ,165}\newline  nach KS = ,278 & p < ,001\\
\textbf{OR.2: Orthografie -- Großschreibung} & 1080 & { vor KS = ,08}\newline nach KS = ,04 & { vor KS = ,271}\newline nach KS = ,191 & p < ,001\\
\textbf{LX.3: Lexik -- Wort ausgelassen} & 1080 & { vor KS = ,08}\newline nach KS = ,03 & { vor KS = ,282}\newline nach KS = ,187 & p < ,001\\
\textbf{LX.6: Lexik -- Konsistenzfehler} & 1080 & { vor KS = ,00}\newline nach KS = ,01 & { vor KS = ,030}\newline nach KS = ,086 & p = ,039\\
\textbf{GR.8: Grammatik -- Falsches Verb (Zeitform, Komposition, Person)} & 1080 & { vor KS = ,05}\newline nach KS = ,02 & { vor KS = ,218}\newline nach KS = ,147 & p < ,001\\
\textbf{GR.9: Grammatik -- Kongruenzfehler} & 1080 & { vor KS = ,04}\newline nach KS = ,03 & { vor KS = ,196}\newline nach KS = ,213 & p = ,002\\
\textbf{GR.10: Grammatik -- Falsche Wortstellung} & 1080 & { vor KS = ,13}\newline nach KS = ,08 & { vor KS = ,365}\newline nach KS = ,282 & p < ,001\\
\textbf{SM.13: Semantik -- Kollokationsfehler} & 1080 & { vor KS = ,05}\newline nach KS = ,02 & { vor KS = ,225}\newline nach KS = ,125 & p < ,001\\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:19} Fehlertypen mit signifikanter Veränderung nach der KS-Anwendung auf Sprachenpaarebene}
\bspnote{\textit{Kursiv} = gestiegene Fehlertypen nach KS}
\end{table}

Die acht signifikant veränderten Fehlertypen entstammen allen linguistischen Bereichen (Orthografie, Lexik, Grammatik sowie Semantik). Mit Ausnahme von Fehlertyp LX.6 „Lexik -- Konsistenzfehler“ waren die Differenzen bei allen Fehlertypen hochsignifikant. Wie die Analyse auf Regelebene zeigt, kam die signifikante Veränderung bei Fehlertyp LX.6 fast nur bei Regel „Eindeutige pronominale Bezüge verwenden“ vor (siehe \sectref{sec:5.3.4.3}).\footnote{{{{Außerdem kam Fehlertyp LX.6 bei einer einzigen Übersetzung bei der Regel „Für zitierte Oberflächentexte gerade Anführungszeichen verwenden“ vor.}}} } Dies begründet die kleine Fehleranzahl und entsprechend das niedrigere Signifikanzniveau. Innerhalb der acht signifikant veränderten Fehlertypen stieg die Fehleranzahl nur bei zwei Fehlertypen (OR.1 „Zeichensetzung“ bei der Regel „Partizipialkonstruktionen vermeiden“ (siehe \sectref{sec:5.3.5.3}) und LX.6 „Konsistenz“ bei der Regel „Eindeutige pronominale Bezüge verwenden“ (siehe \sectref{sec:5.3.4.3}) und sank bei den übrigen sechs Fehlertypen. Mögliche Interpretationen hierfür sind regelspezifisch und daher auf Regelebene präsentiert.

\subsection{Vergleich der MÜ-Qualität vor vs. nach der Anwendung aller KS-Regeln}
\label{sec:5.2.5}
Ein Vergleich der Qualität vor vs. nach der Anwendung der KS-Regeln zeigt, dass sowohl die Stil- als auch die Inhaltsqualität stiegen (\figref{fig:05:15}):


\begin{figure}
\includegraphics[width=.84\textwidth]{figures/Abb14-cut.png}
\includegraphics[width=.15\textwidth]{figures/Abb15-legend.png}
\caption{\label{fig:05:15} Mittelwerte der Qualität vor vs. nach KS auf Sprachenpaarebene}
\end{figure}

Die Stilqualität stieg um 1,7~\% (Mv = 4,056 / SDv = ,620 / Mn = 4,125 / SDn = ,539 / N = 775). Die Inhaltsqualität stieg um 2,9~\% (Mv = 4,314 / SDv = ,769 / Mn = 4,440 / SDn = ,710 / N = 775). Der Mittelwert der Differenz (nach KS minus vor KS) in den vergebenen Qualitätspunkten pro Satz lag für die Stilqualität bei ,069 (SD = ,637) mit einem 95\%-Konfidenzintervall zwischen einem Minimum von ,024 und einem Maximum von ,114 und für die Inhaltsqualität bei ,126 (SD = ,830) mit einem 95\%-Konfidenzintervall zwischen einem Minimum von ,068 und einem Maximum von ,185 (Bootstrapping mit 1000 Stichproben) (\figref{fig:05:16}). Das 95\%-Konfidenzintervall besagt, dass bei der Durchführung einer weiteren vergleichbaren Untersuchung der Mittelwert der Differenz mit einer Wahrscheinlichkeit von 95~\% zwischen den aufgeführten Unter- und Oberwerten liegen würde (vgl. \citealt{Eckstein2008}: 81).


\begin{figure}
\includegraphics[width=.84\textwidth]{figures/Abb16-cut.png}
\includegraphics[width=.15\textwidth]{figures/Abb16-legend.png}
\caption{\label{fig:05:16} Mittelwert der Qualitätsdifferenzen auf Sprachenpaarebene}
\end{figure}

Die Differenzen (nach KS \textit{minus} vor KS) in der Stil- und Inhaltsqualität erwiesen sich als signifikant (z (N = 775) = $-$ 2,062 / p = ,039) bzw. (z (N = 775) = $-$ 4,566 / p < ,001). Dieser allgemeine positive Einfluss der KS auf den MÜ-Output wurde in anderen empirischen und theoretischen Studien bestätigt (vgl. \citealt{NybergMitamura1996}; \citealt{Bernth1999}; \citealt{BernthGdaniec2001}: 208; \citealt{Drugan2013}: 98; \citealt{DrewerZiegler2014}: 196; \citealt{Wittkowsky2017}: 92). Dennoch ist es beachtenswert, dass sich die Inhaltsqualität im Vergleich zu der Stilqualität nach KS wesentlich verbesserte. Das wirft die Frage auf, in genau welchen Fällen die Inhaltsqualität mehr als die Stilqualität stieg. Dies lässt sich auf Regelebene beantworten (\figref{fig:06:151}): Bei den fünf Regeln „Konditionalsätze als ‚Wenn‘-Sätze formulieren“, „Eindeutige pronominale Bezüge verwenden“, „Partizipialkonstruktionen vermeiden“, „Überflüssige Präfixe vermeiden“ und „Keine Wortteile weglassen“ stieg die Inhaltsqualität nach der Anwendung der KS mehr als die Stilqualität, während bei den drei Regeln „Für zitierte Oberflächentexte gerade Anführungszeichen verwenden“, „Funktionsverbgefüge vermeiden“, „Konstruktionen mit ‚sein +~zu +~Infinitiv‘ vermeiden“ der Anstieg der Stilqualität höher war (detailliert erläutert auf Regelebene, siehe \sectref{sec:5.3}). Bei der neunten Regel „Passiv vermeiden“ waren die Differenzen bei der Stil- und Inhaltsqualität vergleichbar.

\subsection{Vergleich der MÜ-Qualität vor vs. nach der Anwendung aller KS-Regeln auf Annotationsgruppenebene}
\label{sec:5.2.6}
Eine genaue Betrachtung der Annotationsgruppen zeigt Folgendes (\figref{fig:05:17}): Erwartungsgemäß sanken die Stil- und Inhaltsqualität bei der Gruppe RF (Übersetzung vor KS richtig und nachher falsch) signifikant (N = 83 / p < ,001) und stiegen bei der Gruppe FR (Übersetzung vor KS falsch und nachher richtig) signifikant (N = 159 / p < ,001).


\begin{figure}
\includegraphics[width=\textwidth]{figures/d3-img018.png}

%\includegraphics[height=.3\textheight]{figures/d3-img015.png}

\caption{\label{fig:05:17}Mittelwerte der Qualität vor vs. nach KS bei den einzelnen Annotationsgruppen auf Sprachenpaarebene}
\end{figure}

Bei der Gruppe FF (falsch vor und nach KS) gab es eine minimale Steigerung, die sich nicht als signifikant erweisen konnte. Hingegen liefert die Gruppe RR (richtig vor und nach KS) ein wesentliches Ergebnis: Die Stilqualität nach KS fällt signifikant geringer als vor KS (N = 341 / p = ,022) aus. Auf der anderen Seite blieb die Inhaltsqualität fast unverändert. In anderen Worten vergleicht man zwei fehlerfreie MÜ vor und nach der Anwendung der KS, wäre die Stilqualität vor KS besser als nach KS, während die Inhaltsqualität vergleichbar bliebe. Aus stilistischer Sicht -- wie die Ergebnisse auf Regelebene (siehe \sectref{sec:6.2}) zeigen -- fanden die Bewerter die Verwendung einiger Regeln unnatürlich bzw. unidiomatisch.


\begin{figure}
\includegraphics[width=\textwidth]{figures/Abb18-num.png}
%\includegraphics[width=.2\textwidth]{figures/Abb16-legend.png}
\caption{\label{fig:05:18} Qualitätsdifferenzen vor- vs. nach KS auf Annotationsgruppenebene  }
\end{figure}

Zudem wurde nur ein extrem niedriges Konfidenzintervall (\figref{fig:05:18}) bei der Gruppe RR registriert. Dies deutet darauf hin, dass bei der Durchführung einer weiteren Untersuchung vom gleichen Umfang und aus der gleichen Grundgesamtheit die Qualitätswerte mit einer Wahrscheinlichkeit von 95~\% sehr ähnlich ausfallen würden.

\subsection{Korrelation zwischen der Differenz der Fehlertypen und den Qualitätsdifferenzen}
\label{sec:5.2.7}
Die Spearman-Korrelation erwies einen signifikanten negativen mittleren Zusammenhang zwischen der Differenz im LX.3 „Lexik -- Wort ausgelassen“ und der Differenz in der Inhaltsqualität sowie zwischen der Differenz im GR.10 „Grammatik -- Falsche Wortstellung“ und der Differenz in der Stil- und Inhaltsqualität. Erwartungsgemäß profitierten beide Qualitätsattribute von der 38~\%-igen Minderung der Wortstellungsfehler (GR.10), siehe \figref{fig:05:14}. Ebenfalls beeinflusste das Auslassen von Wörtern (LX.3) vor der Anwendung der KS-Regeln die Inhaltsqualität negativ. Nach der Anwendung der KS-Regeln wurde dieser Fehlertyp in 61~\% der Fälle korrigiert (siehe \figref{fig:05:14}), was mit einem Anstieg der Inhaltsqualität verbunden war (\tabref{tab:05:20}).


\begin{sidewaystable}
%\small
\begin{tabularx}{\textwidth}{Xrrrrrrr}
\lsptoprule
& \textbf{N} & \multicolumn{3}{c}{ \textbf{Signifikanz}
 \textbf{(p)}} & \multicolumn{3}{c}{ \textbf{Korrelationskoeffizient (ρ)}}\\
 \cmidrule(lr){3-5}\cmidrule(lr){6-8}
%\hhline%%replace by cmidrule{~~------}
&  & \textbf{SQ} & \textbf{CQ} & \textbf{Q} & \textbf{SQ} & \textbf{CQ} & \textbf{Q}\\
\midrule
Differenz der Anzahl der \textbf{OR.1} & 775 & < ,001 & ,019 & < ,001 & $-$ ,212 & $-$ ,084 & $-$ ,170\\
Differenz der Anzahl der \textbf{OR.2} & 775 & < ,001 & ,026 & < ,001 & $-$ ,170 & $-$,080 & $-$ ,130\\
Differenz der Anzahl der \textbf{LX.3} & 775 & < ,001 & < ,001 & < ,001 & $-$ ,204 & \txgreen{$-$ ,366} & \txgreen{$-$ ,321}\\
Differenz der Anzahl der \textbf{LX.4} & 775 & < ,001 & < ,001 & < ,001 & $-$ ,235 & $-$ ,224 & $-$ ,240\\
Differenz der Anzahl der \textbf{LX.5} & 775 & \txgray{,059} & ,003 & ,007 & $-$ ,068 & $-$ ,107 & $-$ ,097\\
Differenz der Anzahl der \textbf{LX.6} & 775 & ,029 & ,011 & ,012 & $-$ ,078 & $-$ ,091 & $-$ ,090\\
Differenz der Anzahl der \textbf{GR.7} & 775 & \txgray{,513} & ,004 & \txgray{,083} & $-$ ,024 & $-$ ,102 & $-$ ,062\\
Differenz der Anzahl der \textbf{GR.8} & 775 & < ,001 & < ,001 & < ,001 & $-$ ,269 & $-$ ,239 & $-$ ,264\\
Differenz der Anzahl der \textbf{GR.9} & 775 & \txgray{,070} & ,007 & ,016 & $-$ ,065 & $-$ ,097 & $-$ ,087\\
Differenz der Anzahl der \textbf{GR.10} & 775 & < ,001 & < ,001 & < ,001 & \txgreen{$-$ ,319} & \txgreen{$-$ ,307} & \txgreen{$-$ ,337}\\
Differenz der Anzahl der \textbf{SM.11} & 775 & < ,001 & < ,001 & < ,001 & $-$ ,206 & $-$ ,230 & $-$ ,246\\
Differenz der Anzahl der \textbf{SM.12} & 775 & ,006 & < ,001 & < ,001 & $-$ ,099 & $-$ ,226 & $-$ ,203\\
Differenz der Anzahl der \textbf{SM.13} & 775 & ,002 & \txgray{,239} & ,022 & $-$ ,113 & $-$ ,042 & $-$ ,082\\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:20} Korrelationen zwischen den Fehlertypen und der Qualität auf Sprachenpaarebene  }
\bspnote{schwache Korrelation (ρ >= 0,1)\hspace{1em} \txgreen{mittlere Korrelation (ρ >= 0,3)}\hspace{1em} \boxblue{starke Korrelation (ρ >= 0,5)}\hspace{1em} \txgray{nicht signifikant (p > 0,05)}
}
\end{sidewaystable}

Weitere mittlere oder starke Korrelationen zwischen anderen einzelnen Fehlertypen und der Qualität konnten nicht belegt werden (\tabref{tab:05:20}).

\subsection{Vergleich der AEM-Scores vor vs. nach der Anwendung aller KS-Regeln}
\label{sec:5.2.8}
Durchschnittlich verbesserten sich sowohl der TERbase-Score als auch der hLE\-POR-Score\footnote{{{{Näheres zu den AEMs TERbase und hLEPOR unter \sectref{sec:4.4.6.3} „Auswahl der automatischen Evaluationsmetriken“.}}}} minimal nach der Anwendung der KS-Regeln im Vergleich zu vorher:\footnote{{{{Eine genaue Erklärung für die Berechnung des Mittelwerts der Differenz des TERbase-Scores und hLEPOR-Scores sowie seine Bedeutung ist unter \sectref{sec:4.4.6.4} „Basis des Vergleichs vor-KS vs. nach-KS zur Ermittlung des KS-Einflusses“ aufgeführt.}}}} Die Differenz (nach KS \textit{minus} vor KS) lag beim TERbase-Score bei ,0011 und beim hLEPOR-Score bei ,0087 (\figref{fig:05:19}).


\begin{figure}
\includegraphics[width=.7\textwidth]{figures/d3-img021.jpg}

\includegraphics[width=.3\textheight]{figures/Abb19-legend.png}


\caption{\label{fig:05:19}Mittelwert der Differenz des TERbase-Scores und hLEPOR-Scores auf Sprachenpaarebene}
\bspnote{Differenz = AEM-Score nach KS \textit{minus} AEM-Score vor KS}
\end{figure}

\subsection{Korrelation zwischen den Differenzen der AEM-Scores und den Qualitätsdifferenzen}
\label{sec:5.2.9}
Die Spearman-Korrelation erwies einen hochsignifikanten positiven starken Zusammenhang zwischen den Differenzen der TERbase-Scores und hLEPOR-Scores und der Differenz der Qualität im Allgemeinen (\tabref{tab:05:21}).\footnote{\textrm{Mittelwert der Stilqualität und der Inhaltsqualität, da bei der Ermittlung dieser Korrelation keine Unterscheidung zwischen den beiden Qualitätsattributen notwendig ist.}} Dies besagt: Verbessert sich der AEM-Score, verbessert sich ebenfalls die Qualität.

\begin{table}
%\begin{sidewaystable}
\begin{tabularx}{\textwidth}{Xrrrr}
\lsptoprule
& \textbf{N} & {\bfseries\makecell[tr]{Signifikanz\\(p)}} & {\bfseries\makecell[tr]{Korrelations-\\koeffizient\\(ρ)}} & {\bfseries\makecell[tr]{Stärke\\der\\Korrelation}}\\
\midrule
Korrelation zw. Differenz der allg. Qualität und Differenz des TERbase-Scores (nach KS $-$ vor KS) & { 775} & { < ,001} & ,520 & \makecell[tr]{starker\\Zusammen-\\hang}\\
\tablevspace
Korrelation zw. Differenz der allg. Qualität und Differenz des hLEPOR-Scores (nach KS $-$ vor KS) & { 775} & { < ,001} & ,519 & \makecell[tr]{starker\\Zusammen-\\hang}\\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:21}   Korrelation zwischen den Differenzen der AEM-Scores und den Qualitätsdifferenzen}
\bspnote{
schwache Korrelation (ρ >=0,1)\hspace{.5em} mittlere Korrelation (ρ >= 0,3)\hspace{.5em} starke Korrelation (ρ >= 0,5)\hspace{.5em}
}
%\end{sidewaystable}
\end{table}

Somit bestätigen sich die Ergebnisse der Humanevaluation und die der automatischen Evaluation gegenseitig, denn eine starke positive Korrelation besagt, dass ein positiver Effekt der KS-Anwendung sich sowohl durch einen erhöhten Score in der Humanevaluation als auch einen verbesserten AEM-Score in der automatischen Evaluation zeigte. Umgekehrt gingen auch bei einem negativen Effekt der KS-Anwendung die Scores beider Evaluationen zurück.

\subsection{Analyse auf Sprachenpaarebene -- Validierung der Hypothesen}
\label{sec:5.2.10}
Um die in diesem Unterkapitel dargestellten Ergebnisse auf die Forschungsfragen der Studie zurückzuführen, listet dieser Abschnitt die zugrunde liegenden Hypothesen der Forschungsfragen zusammen mit einer Zusammenfassung der obigen Ergebnisse in tabellarischer Form auf. Für einen schnelleren Überblick steht ($+$) für eine Verbesserung bzw. einen Anstieg z.~B. im Sinne eines Qualitätsanstiegs, verbesserter AEM-Scores oder eines Anstiegs der Fehleranzahl; ($-$) steht für einen Rückgang; die \txgreen{grüne} Farbe symbolisiert eine signifikante Veränderung; \textit{neg} steht für eine negative Korrelation und \textit{pos} für eine positive Korrelation; <{}<{}>{}> steht für eine starke Korrelation und <> für eine mittlere Korrelation.\footnote{\textrm{Schwache Korrelationen werden in dieser Übersicht nicht angezeigt.}}

\paragraph*{Vergleich der Fehleranzahl vor vs. nach der Anwendung der KS-Regeln}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Gibt es einen Unterschied in der Fehleranzahl nach der Anwendung der KS-Regeln im Vergleich zu vor der Anwendung?
\item [H0] -- Es gibt keinen Unterschied in der Fehleranzahl vor vs. nach der Anwendung der KS-Regeln.
\item [H1] -- Es gibt einen Unterschied in der Fehleranzahl vor vs. nach der Anwendung der KS-Regeln.
\item[Resultat] \sethlcolor{smGreen}\hl{Die Fehleranzahl sank nach der Anwendung der KS-Regeln signifikant. Somit wurde H0 abgelehnt und H1 bestätigt.\strut}
\end{description}
\hrule
\paragraph*{Vergleich der Fehlertypen vor vs. nach der Anwendung der KS-Regeln}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Kommen bestimmte Fehlertypen vor bzw. nach der Anwendung der KS-Regeln vor?
\item [H0] -- Es gibt keinen Unterschied in der Häufigkeit der einzelnen Fehlertypen vor vs. nach der Anwendung der KS-Regeln.
\item [H1] -- Es gibt einen Unterschied in der Häufigkeit der einzelnen Fehlertypen vor vs. nach der Anwendung der KS-Regeln.
\item[Resultat] H0 wurde abgelehnt und somit H1 bestätigt, und zwar nur für die hier aufgeführten Fehlertypen:
\sethlcolor{smGreen}\hl{+~OR.1, $-$ OR.2, $-$ LX.3, +~LX.6, $-$ GR.8, $-$ GR.9, $-$ GR.10, $-$ SM.13\strut}
\end{description}
\hrule
\paragraph*{Vergleich der Qualität vor vs. nach der Anwendung der KS-Regeln}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Gibt es einen Unterschied in der Stil- und Inhaltsqualität der MÜ der KS-Stelle nach der Anwendung der KS-Regeln im Vergleich zu vor der Anwendung?
\item[H0] -- Es gibt keinen Qualitätsunterschied vor vs. nach der Anwendung der KS-Regeln.
\item[H1] -- Es gibt einen Qualitätsunterschied vor vs. nach der Anwendung der KS-Regeln.
\item [Resultat] \sethlcolor{smGreen}\hl{Die Stil- und Inhaltsqualität stiegen nach der Anwendung der KS-Regeln signifikant. Somit wurde H0 abgelehnt und H1 bestätigt.\strut}
\end{description}
\hrule
\paragraph*{Vergleich der Qualität vor vs. nach der Anwendung der KS-Regeln auf Annotationsgruppenebene}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Gibt es einen Unterschied in der Stil- und Inhaltsqualität bei den einzelnen Annotationsgruppen nach der Anwendung der KS-Regeln im Vergleich zu vor der Anwendung?
\item[H0] -- Bei den Annotationsgruppen gibt es keinen Qualitätsunterschied vor vs. nach der Anwendung der KS-Regeln.
\item[H1] -- Bei den Annotationsgruppen gibt es einen Qualitätsunterschied vor vs. nach der Anwendung der KS-Regeln.
\item [Resultat] In den folgenden Fällen wurde H0 abgelehnt und somit H1 bestätigt: bei dem Qualitätsrückgang in der Gruppe RF, bei der Qualitätssteigerung in FR und bei der Abnahme der Stilqualität in RR.
\begin{table}[H]
\begin{tabularx}{\textwidth}{XXXXXXXX}
\lsptoprule
\multicolumn{2}{c}{\textbf{FF}} & \multicolumn{2}{c}{\textbf{RF}} & \multicolumn{2}{c}{\textbf{FR}} & \multicolumn{2}{c}{\textbf{RR}}\\
\cmidrule(lr){1-2}\cmidrule(lr){3-4}\cmidrule(lr){5-6}\cmidrule(lr){7-8}
\textbf{SQ} & \textbf{CQ} & \textbf{SQ}  & \textbf{CQ} & \textbf{SQ} & \textbf{CQ} & \textbf{SQ} & \textbf{CQ}\\
\midrule
$+$ & $+$ & \cellcolor{smGreen}$(-)$ & \cellcolor{smGreen}$(-)$ & \cellcolor{smGreen}$+$ & \cellcolor{smGreen}$+$ & \cellcolor{smGreen}$(-)$ & $+$\\
\lspbottomrule
\end{tabularx}
\end{table}
\end{description}
\hrule
\paragraph*{Korrelation zwischen den Fehlertypen und der Qualität}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Besteht ein Zusammenhang zwischen der Differenz der Fehleranzahl eines bestimmten Fehlertyps (Fehleranzahl nach KS \textit{minus} Fehleranzahl vor KS) und der Differenz der Stil- bzw. Inhaltsqualität (Qualität nach KS \textit{minus} Qualität vor KS)?
\item[H0] -- Es besteht kein Zusammenhang zwischen der Differenz der Fehleranzahl eines bestimmten Fehlertyps und der Differenz der Stil- bzw. Inhaltsqualität.
\item[H1] -- Es besteht ein Zusammenhang zwischen der Differenz der Fehleranzahl eines bestimmten Fehlertyps und der Differenz der Stil- bzw. Inhaltsqualität.
\item [Resultat] H0 wurde abgelehnt und H1 bestätigt, und zwar für den Zusammenhang zwischen den Qualitätswerten und zwei Fehlertypen wie folgt:\\\sethlcolor{smGreen}\hl{\textit{neg} GR.10 <> SQ, \textit{neg} LX.3 <> CQ,  \textit{neg} GR.10 <> CQ\strut}
\end{description}
\hrule
\paragraph*{Vergleich der AEM-Scores vor vs. nach der Anwendung der KS-Regeln}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Gibt es einen Unterschied in den AEM-Scores von TERbase bzw. hLEPOR nach der Anwendung der KS-Regeln im Vergleich zu vor der Anwendung?
\item[H0] -- Es gibt keinen Unterschied in den AEM-Scores vor vs. nach der Anwendung der KS-Regeln.
\item[H1] -- Es gibt einen Unterschied in den AEM-Scores vor vs. nach der Anwendung der KS-Regeln.
\item [Resultat] Die AEM-Scores von TERbase bzw. hLEPOR verbesserten sich nur minimal. Somit wurde H0 nicht abgelehnt und H1 konnte nicht bestätigt werden.
\end{description}
\hrule
\paragraph*{Korrelation zwischen den AEM-Scores-Differenzen und der Qualitätsdifferenz}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Besteht ein Zusammenhang zwischen der Differenz der AEM-Scores in TERbase bzw. hLEPOR (Mittelwert der AEM-Scores nach KS \textit{minus} Mittelwert der AEM-Scores vor KS) und der Differenz der allgemeinen Qualität (Qualität nach KS \textit{minus} Qualität vor KS)?
\item[H0] -- Es besteht kein Zusammenhang zwischen der Differenz der AEM-Scores und der Differenz der allgemeinen Qualität.
\item[H1] -- Es besteht ein Zusammenhang zwischen der Differenz der AEM-Scores und der Differenz der allgemeinen Qualität.
\item [Resultat] H0 wurde abgelehnt und H1 bestätigt, und zwar für den Zusammenhang zwischen der allgemeinen Qualität und den AEM-Scores wie folgt: \sethlcolor{smGreen}\hl{\textit{pos} TERbase <{}<{}>{}> Q, \textit{pos} hLEPOR <{}<{}>{}> Q\strut}
\end{description}






\subsection{Übersicht der Ergebnisse auf Sprachenpaarebene}
\label{sec:5.2.11}
\tabref{tab:05:22} bietet eine Übersicht über die Ergebnisse auf Sprachenpaarebene, d.\,h. für den kompletten Datensatz.


\begin{sidewaystable}
\begin{tabularx}{\textwidth}{llllllllll}
\lsptoprule
\makecell[tl]{Fehler-\\anzahl} & Fehlertypen & \multicolumn{2}{c}{Qualität} & \multicolumn{2}{c}{Fehlertypen <> Qualität} & \multicolumn{2}{c}{AEM-Scores} & \multicolumn{2}{c}{\makecell[tl]{AEM-Scores <> allg.\\Qualität}}\\
\cmidrule(lr){5-6}\cmidrule(lr){7-8}\cmidrule(lr){9-10}
&  &  &  & Stilqualität & \makecell[tl]{Inhalts-\\qualität} & TERbase & hLEPOR & TERbase & hLEPOR\\
\midrule
\cellcolor{smGreen}& \cellcolor{smGreen}$+$ OR.1 &\cellcolor{smGreen}  &\cellcolor{smGreen}  &\cellcolor{smGreen}  &\cellcolor{smGreen}  &  &  &\cellcolor{smGreen}  &\cellcolor{smGreen} \\
\cellcolor{smGreen}& \cellcolor{smGreen}$-$ OR.2 &\cellcolor{smGreen}  &\cellcolor{smGreen}  &\cellcolor{smGreen}  &\cellcolor{smGreen}  &  &  &\cellcolor{smGreen}  &\cellcolor{smGreen}  \\
\cellcolor{smGreen}& \cellcolor{smGreen}$-$ LX.3 &\cellcolor{smGreen}  &\cellcolor{smGreen}  &\cellcolor{smGreen}  &\cellcolor{smGreen}  &  &  &\cellcolor{smGreen}  &\cellcolor{smGreen}\\
\cellcolor{smGreen}& \cellcolor{smGreen}$+$ LX.6 &\cellcolor{smGreen}  &\cellcolor{smGreen}  &\cellcolor{smGreen}  &\cellcolor{smGreen}  &  &  &\cellcolor{smGreen}  &\cellcolor{smGreen} \\
\cellcolor{smGreen}& \cellcolor{smGreen}$-$ GR.8 &\cellcolor{smGreen}  &\cellcolor{smGreen}  &\cellcolor{smGreen}  &\cellcolor{smGreen}  &  &  &\cellcolor{smGreen}  &\cellcolor{smGreen} \\
\cellcolor{smGreen}& \cellcolor{smGreen}$-$ GR.9 &\cellcolor{smGreen}  &\cellcolor{smGreen}  &\cellcolor{smGreen}  &\cellcolor{smGreen}  &  &  &\cellcolor{smGreen}  &\cellcolor{smGreen} \\
\cellcolor{smGreen}& \cellcolor{smGreen}$-$ GR.10 &\cellcolor{smGreen}  &\cellcolor{smGreen}  &\cellcolor{smGreen}  &\cellcolor{smGreen}  &  &  &\cellcolor{smGreen}  &\cellcolor{smGreen} \\
\cellcolor{smGreen}\multirow{-8}{*}{($-$)} & \cellcolor{smGreen}$-$ SM.13 & \cellcolor{smGreen}\multirow{-8}{*}{$+$ SQ} & \cellcolor{smGreen}\multirow{-8}{*}{$+$ CQ} &\cellcolor{smGreen}\multirow{-8}{*}{\makecell[cl]{\textit{neg} GR.10\\<> SQ}} & \cellcolor{smGreen}\multirow{-8}{*}{\makecell[cl]{\textit{neg} LX.3\\<> CQ\\\textit{neg} GR.10\\<> CQ}} & \multirow{-8}{*}{$+$} & \multirow{-8}{*}{$+$} & \cellcolor{smGreen}\multirow{-8}{*}{\makecell[cl]{\textit{pos}\\TERbase\\ <{}<{}>{}> Q}} &\cellcolor{smGreen}\multirow{-8}{*}{\makecell[cl]{\textit{pos}\\hLEPOR\\<{}<{}>{}> Q}}\\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:22} Übersicht der Ergebnisse auf Sprachenpaarebene}
\bspnote{
SQ: Stilqualität\hspace{1em} CQ: Inhaltsqualität\hspace{1em} Q: allg. Qualität\hspace{1em} \colorbox{smGreen}{Signifikant (p < 0,5)}\hspace{1em} Blank: nicht signifikant\\
<> mittlere Korrelation (ρ >= 0,3)\hspace{1em} <{}<{}>{}> starke Korrelation (ρ >= 0,5)\hspace{1em} \textit{neg}: negative Korrelation\hspace{1em} \textit{pos}: positive Korrelation
}
\end{sidewaystable}

Regel- und systemübergreifend zeigt die Anwendung der neun KS-Regeln einen positiven Einfluss auf den MÜ-Output. Die Fehleranzahl sank und die Stil- und Inhaltsqualität stiegen signifikant. Die AEM-Scores verbesserten sich leicht. Die signifikant starke positive Spearman-Korrelation zwischen beiden AEMs und der allgemeinen Qualität lässt beide Analysen (Humanevaluation und automatische Evaluation) den positiven Effekt der KS-Regeln bestätigen. Die Fehleranzahl mehrerer Fehlertypen sank signifikant nach der KS-Anwendung. Diese sind: OR.2 „Großschreibung“, LX.3 „Wort ausgelassen“, GR.8 „Falsches Verb (Zeitform, Komposition, Person)“, GR.9 „Kongruenzfehler“, GR.10 „Falsche Wortstellung“ und SM.13 „Kollokationsfehler“. Gleichzeitig stieg die Fehleranzahl zweier Fehlertypen OR.1 „Zeichensetzung“ (überwiegend durch die Regel „Partizipialkonstruktionen vermeiden“, siehe \sectref{sec:5.3.5.3}) und LX.6 „Konsistenzfehler“ (überwiegend durch die Regel „Eindeutige pronominale Bezüge verwenden“, siehe \sectref{sec:5.3.4.3}). Den Ergebnissen des Spearman-Tests zufolge besteht eine signifikante mittlere negative Korrelation zwischen Fehlertyp GR.10 „Falsche Wortstellung“ und der SQ und CQ sowie zwischen LX.3 „Wort ausgelassen“ und der CQ. Somit war der Rückgang dieser Fehlertypen mit einem Anstieg der genannten Qualitätswerte verbunden.


\section{\label{sec:5.3}Analyse auf Regelebene sowie auf Regel- und MÜ-Systemebene}

In diesem Kapitel werden die Ergebnisse auf Regelebene sowie auf Regel- und MÜ-Systemebene dargestellt. Auf Regelebene wird jede Regel einzeln anhand einer Reihe von Faktoren analysiert, die den Vergleich der Szenarien „vor der Anwendung der KS-Regel“ vs. „nach der Anwendung der KS-Regel“ ermöglichen. Anschließend werden unter jeder Regel die fünf MÜ-Systeme verglichen (Regel- und MÜ-Systemebene). Für den Vergleich werden folgende Analysefaktoren herangezogen: Fehleranzahl, Aufteilung der Annotationsgruppen, Fehlertypen, Stil- und Inhaltsqualität, Korrelation zwischen den Fehlertypen und der Stil- und Inhaltsqualität, Stil- und Inhaltsqualität auf Annotationsgruppenebene, AEM-Scores und Korrelation zwischen den Differenzen der AEM-Scores und der Qualitätsdifferenz.\footnote{{{{Zur Berechnung aller Differenzen in der Studie wird durchgehend das Szenario „nach KS“ minus „vor KS“ subtrahiert, somit ist die Qualitätsdifferenz = Qualität nach KS $-$ Qualität vor KS; AEM-Score-Differenz = AEM-Score nach KS $-$ AEM-Score vor KS usw.}}}} Bevor die Ergebnisse demonstriert werden, gibt uns der erste Abschnitt eine Übersicht über die Analysefaktoren, die zugrundeliegenden Fragestellungen und Hypothesen sowie die statistische Auswertung. Danach folgt die quantitative und qualitative Analyse der einzelnen Regeln dargestellt in alphabetischer Reihenfolge. Bezüge auf vorherige Studien werden nicht in diesem Unterkapitel, sondern im Rahmen der Diskussion in \sectref{ch:6} vorgenommen.

\subsection{Analysefaktoren}
\label{sec:5.3.0}
Für den Vergleich der Übersetzungen vor vs. nach der Anwendung jeder KS-Regel wurden die Übersetzungen \textit{außerhalb} der KS-Stelle vereinheitlicht, somit war nur die KS-Stelle in den beiden Szenarien unterschiedlich (für die genaue Vorgehensweise siehe \sectref{sec:4.4.3.1}). Auf dieser Basis wird in der folgenden Analyse die KS-Stelle unter die Lupe genommen. Ziel hierbei ist, herauszufinden, ob die Anwendung der jeweiligen KS-Regel mit Vorteilen verbunden war. Der Aufbau der Analyse ist wie folgt strukturiert:

\subsubsection{Erster Analysefaktor: Vergleich der Fehleranzahl vor vs. nach der Anwendung der KS-Regel}

\begin{itemize}
\item Fragestellung: Gibt es einen Unterschied in der Fehleranzahl nach der Anwendung der KS-Regel im Vergleich zu vor der Anwendung?

Gibt es \textit{bei einem bestimmten MÜ-System} einen Unterschied in der Fehleranzahl nach der Anwendung der KS-Regel im Vergleich zu vor der Anwendung?

\item Variablen: Summe der Fehler und Mittelwert der Fehleranzahl (von allen Fehlertypen) innerhalb der KS-Stelle; Variablentyp: ordinal
\item Statistische Auswertung: Deskriptive Statistiken auf Basis der Fehlerannotation; Abbildungen: Balken
\item Hypothesen:

  \begin{itemize}[align = left]

  \item[H0 --] Es gibt keinen Unterschied in der Fehleranzahl vor vs. nach der Anwendung der KS-Regel.

  \item[H1 --] Es gibt einen Unterschied in der Fehleranzahl vor vs. nach der Anwendung der KS-Regel.

\end{itemize}

\item Signifikanztest: Wilcoxon; Begründung der Testauswahl: Die Variablen sind ordinal.
\end{itemize}

\subsubsection{Zweiter Analysefaktor: Aufteilung der Annotationsgruppen}

\begin{itemize}
\item In der Studie werden die Ergebnisse der Fehlerannotation in vier Annotationsgruppen unterteilt:

(1) RR: MÜ ist vor und nach der Anwendung der KS-Regel fehlerfrei;
(2) FF: MÜ beinhaltet vor und nach der Anwendung der KS-Regel Fehler;
(3) RF: MÜ ist nur vor der Anwendung der KS-Regel fehlerfrei;
(4) FR: MÜ ist nur nach der Anwendung der KS-Regel fehlerfrei.

\item Fragestellung: Wie hoch ist der Prozentsatz jeder Annotationsgruppe bei jeder Regel?

Wie hoch ist der Prozentsatz jeder Annotationsgruppe \textit{bei den einzelnen MÜ-Systemen} innerhalb der analysierten Regel?

\item Statistische Auswertung: Häufigkeiten mit Bootstrapping\footnote{{{{Bootstrapping ist ein statistisches Verfahren zur Schätzung der Stichprobenverteilung eines Schätzers durch erneute Stichprobenerstellung mit Ersatz aus der ursprünglichen Stichprobe. Es wird als ein nützliches Verfahren zum Testen der Modellstabilität erachtet.~(\citealt{IBMnodate})}}}} auf Basis der Fehlerannotation; Abbildungen: Kreisdiagramme
\end{itemize}

\subsubsection{Dritter Analysefaktor: Vergleich der Fehlertypen vor vs. nach der Anwendung der KS-Regel}

\begin{itemize}
\item Es werden die 13 analysierten Fehlertypen vor vs. nach der Anwendung der KS-Regel verglichen.
\item Fragestellung: Beinhaltet die MÜ bestimmte Fehlertypen vor bzw. nach der Anwendung der KS-Regel?

Kommen bestimmte Fehlertypen \textit{bei einem bestimmten MÜ-System} vor bzw. nach der Anwendung der KS-Regel vor?

Davon wird abgeleitet, (1) ob bestimmte Fehlertypen, die vor der Anwendung der KS-Regel existierten, nach der Anwendung der KS-Regel eliminiert bzw. reduziert wurden; (2) ob bestimmte Fehlertypen erst nach der Anwendung der KS-Regel auftraten bzw. ihre Anzahl deutlich stieg (im Vergleich zu vor der Anwendung der KS-Regel).

\item Variablen: Fehler existiert ja/nein; Fehlertyp: dichotom. Summe der Fehler sowie Mittelwert der Fehleranzahl innerhalb der KS-Stelle; Variablentyp: ordinal
\item Statistische Auswertung: Kreuztabellen auf Basis der Fehlerannotation; Abbildungen: Balken
\item Hypothesen:

  \begin{itemize}[align=left]

  \item[H0 --] Es gibt keinen Unterschied in der Häufigkeit der einzelnen Fehlertypen vor vs. nach der Anwendung der KS-Regel.

  \item[H1 --] Es gibt einen Unterschied in der Häufigkeit der einzelnen Fehlertypen vor vs. nach der Anwendung der KS-Regel.

  \end{itemize}

\item Signifikanztest: McNemar; Begründung der Testauswahl: Mithilfe des\linebreak McNemar-Tests können zwei verbundene dichotome Parameter verglichen werden, somit kann eine mögliche signifikante Veränderung bei einem Fehlertyp vor vs. nach der Anwendung der KS-Regeln identifiziert werden.
\end{itemize}

\subsubsection{Vierter Analysefaktor: Vergleich der Qualität vor vs. nach der Anwendung der KS-Regel}

\begin{itemize}
\item Fragestellung: Gibt es einen Unterschied in der Stil- und Inhaltsqualität der MÜ der KS-Stelle nach der Anwendung der KS-Regel im Vergleich zu vor der Anwendung?

Gibt es \textit{bei einem bestimmten MÜ-System} einen Unterschied in der Stil- und Inhaltsqualität der MÜ der KS-Stelle nach der Anwendung der KS-Regel im Vergleich zu vor der Anwendung?

\item Variablen: Mittelwert der Qualitätspunktzahlen der acht Teilnehmer auf der Likert-Skala; Variablentyp: metrisch
\item Statistische Auswertung: Deskriptive Statistiken auf Basis der Humanevaluation; Abbildungen: Fehlerbalken
\item Hypothesen:
  \begin{itemize}[align=left]

  \item[H0 --] Es gibt keinen Qualitätsunterschied vor vs. nach der Anwendung der KS-Regel.

  \item[H1 --] Es gibt einen Qualitätsunterschied vor vs. nach der Anwendung der KS-Regel.

  \end{itemize}
\item Signifikanztest: Wilcoxon; Begründung der Testauswahl: Nicht alle Qualitätswerte sind normalverteilt. Wilcoxon kann bei normalverteilten sowie nicht-normalverteilten Variablen verwendet werden.
\end{itemize}

\subsubsection{Fünfter Analysefaktor: Korrelation zwischen den Fehlertypen und der Qualität}

\begin{itemize}
\item Fragestellung: Besteht bei der analysierten Regel ein Zusammenhang zwischen der Differenz der Fehleranzahl eines bestimmten Fehlertyps (Fehleranzahl nach KS \textit{minus} Fehleranzahl vor KS) und der Differenz der Stil- bzw. Inhaltsqualität (Qualität nach KS \textit{minus} Qualität vor KS)?

Besteht \textit{bei einem bestimmten MÜ-System} innerhalb der analysierten Regel ein Zusammenhang zwischen der Differenz der Fehleranzahl eines bestimmten Fehlertyps (Fehleranzahl nach KS \textit{minus} Fehleranzahl vor KS) und der Differenz der Stil- bzw. Inhaltsqualität (Qualität nach KS \textit{minus} Qualität vor KS)?

\item Variablen: Differenz der Mittelwerte der Qualitätspunktzahlen der acht Teilnehmer auf der Likert-Skala; Variablentyp: metrisch. Differenz der Fehleranzahl der einzelnen Fehlertypen; Variablentyp: ordinal.
\item Statistische Auswertung: Spearman-Korrelationstest
\item Hypothesen:
  \begin{itemize}[align=left]

  \item[H0 --] Es besteht kein Zusammenhang zwischen der Differenz der Fehleranzahl eines bestimmten Fehlertyps und der Differenz der Stil- bzw. Inhaltsqualität.

  \item[H1 --] Es besteht ein Zusammenhang zwischen der Differenz der Fehleranzahl eines bestimmten Fehlertyps und der Differenz der Stil- bzw. Inhaltsqualität.

  \end{itemize}
\item Signifikanztest: Spearman-Korrelationstest; Begründung der Testauswahl: Eine der Variablen ist ordinal. Zudem setzt Spearman keine Anforderung an die Verteilung und die Linearität voraus.
\end{itemize}

\subsubsection{Sechster Analysefaktor: Vergleich der Qualität vor vs. nach der Anwendung der KS-Regel auf Annotationsgruppenebene}

\begin{itemize}
\item Fragestellung: Gibt es einen Unterschied in der Stil- und Inhaltsqualität bei den einzelnen Annotationsgruppen nach der Anwendung der KS-Regel im Vergleich zu vor der Anwendung?

Davon wird abgeleitet, (1) ob bei der Gruppe RR die Stil- bzw. Inhaltsqualität vor bzw. nach der Anwendung der KS-Regel höher ist, obwohl die MÜ in beiden Fällen fehlerfrei ausfällt; (2) ob bei der Gruppe FF die Stil- bzw. Inhaltsqualität vor bzw. nach der Anwendung der KS-Regel höher ist, obwohl die MÜ in beiden Fällen Fehler beinhaltet; (3) ob bei der Gruppe RF die Stil- bzw. Inhaltsqualität nach der Anwendung der KS-Regel stieg, obwohl die MÜ nach der Anwendung der KS-Regel Fehler beinhaltet und davor fehlerfrei war; (4) ob bei der Gruppe FR die Stil- bzw. Inhaltsqualität nach der Anwendung der KS-Regel sank, obwohl die MÜ nach der Anwendung der KS-Regel fehlerfrei ist und davor Fehler beinhaltete.

\item Variablen: Mittelwert der Qualitätspunktzahlen der acht Teilnehmer auf der Likert-Skala in jeder Annotationsgruppe; Variablentyp: metrisch
\item Statistische Auswertung: Deskriptive Statistiken auf Basis der Humanevaluation unter Aufteilung der Daten nach den Annotationsgruppen; Abbildungen: Fehlerbalken
\item Hypothesen:
  \begin{itemize}[align = left]

  \item[H0 --] Bei den Annotationsgruppen gibt es keinen Qualitätsunterschied vor vs. nach der Anwendung der KS-Regel.

  \item[H1 --] Bei den Annotationsgruppen gibt es einen Qualitätsunterschied vor vs. nach der Anwendung der KS-Regel.

  \end{itemize}
\item Signifikanztest: Wilcoxon; Begründung der Testauswahl: Nicht alle Qualitätswerte sind normalverteilt. Wilcoxon kann bei normalverteilten sowie nicht-normalverteilten Variablen verwendet werden.
\end{itemize}

\subsubsection{Siebter Analysefaktor: Vergleich der AEM-Scores vor vs. nach der Anwendung der KS-Regel}

\begin{itemize}
\item Fragestellung: Gibt es einen Unterschied in den AEM-Scores von TERbase bzw. hLEPOR nach der Anwendung der KS-Regel im Vergleich zu vor der Anwendung?
\item Variablen: Mittelwert der AEM-Scores\footnote{{{{Bei jeder MÜ wurde der Mittelwert der AEM-Scores auf Basis von zwei Referenzübersetzungen ermittelt; für eine genaue Beschreibung des Verfahrens siehe \sectref{sec:4.4.6.4}.}}}} sowie Differenzen der AEM-Scores (AEM-Score nach KS \textit{minus} AEM-Score vor KS); Variablentyp: metrisch
\item Statistische Auswertung: Deskriptive Statistiken auf Basis der automatischen Evaluation; Abbildungen: Fehlerbalken für die Differenzen der AEM-Scores\footnote{{{{Bei der Auswertung wurden nur die Differenzen der AEM-Scores (und nicht die Mittelwerte der AEM-Scores) verwendet. Der Grund ist, dass die Bewerter die komplette MÜ editiert haben. Ihre Edits können daher Stellen außerhalb der KS-Stelle umfassen. Da aber die MÜ vor und nach KS außerhalb der KS-Stelle vereinheitlicht wurden, wird hier davon ausgegangen, dass wir durch die Verwendung der Differenz (AEM-Score nach KS minus AEM-Score vor KS) nur die Edits innerhalb der KS-Stelle betrachten; für eine detaillierte Erläuterung siehe \sectref{sec:4.4.6.4}.}}}}
\item Hypothesen:
  \begin{itemize}[align = left]

  \item[H0 --] Es gibt keinen Unterschied in den AEM-Scores vor vs. nach der Anwendung der KS-Regel.

  \item[H1 --] Es gibt einen Unterschied in den AEM-Scores vor vs. nach der Anwendung der KS-Regel.

  \end{itemize}
\item Signifikanztest: Wilcoxon; Begründung der Testauswahl: Nicht alle Qualitätswerte sind normalverteilt. Wilcoxon kann bei normalverteilten sowie nicht-normalverteilten Variablen verwendet werden.
\end{itemize}

\subsubsection{Achter Analysefaktor: Korrelation zwischen den AEM-Scores-Differenzen und der Qualitätsdifferenz}

\begin{itemize}
\item Fragestellung: Besteht ein Zusammenhang zwischen der Differenz der AEM-Scores in TERbase bzw. hLEPOR (Mittelwert der AEM-Scores nach KS \textit{minus} Mittelwert der AEM-Scores vor KS) und der Differenz der allgemeinen Qualität\footnote{{{{Die allgemeine Qualität ist der Mittelwert der Stilqualität und der Inhaltsqualität, da bei der Untersuchung dieser Korrelation keine Unterscheidung zwischen der Stil- und Inhaltsqualität notwendig ist.}}}} (Qualität nach KS \textit{minus} Qualität vor KS)?
\item Variablen: Differenz der Mittelwerte der AEM-Scores sowie Differenz der Mittelwerte der Qualitätspunktzahlen der acht Teilnehmer auf der Likert-Skala; Variablentyp: metrisch
\item Statistische Auswertung: Spearman-Korrelationstest
\item Hypothesen:
  \begin{itemize}[align = left]

  \item[H0 --] Es besteht kein Zusammenhang zwischen der Differenz der AEM-Scores und der Differenz der allgemeinen Qualität.

  \item[H1 --] Es besteht ein Zusammenhang zwischen der Differenz der AEM-Scores und der Differenz der allgemeinen Qualität.

  \end{itemize}
\item Signifikanztest: Spearman-Korrelationstest; Begründung der Testauswahl: Nicht alle Variablen sind normalverteilt. Spearman setzt keine Anforderungen an die Verteilung und die Linearität voraus.
\end{itemize}

\subsection{ERSTE REGEL: Für zitierte Oberflächentexte gerade Anführungszeichen $"$…$"$ verwenden}
\label{sec:5.3.1}

\subsubsection{\label{sec:5.3.1.0}Überblick}

%In \tabref{tab:05:23}
Im Folgenden wird die KS-Regel „Für zitierte Oberflächentexte gerade Anführungszeichen verwenden“ kurz beschrieben.\footnote{{{{Die für diese Regel relevanten Kontraste im Sprachenpaar DE-EN sind unter \sectref{sec:4.4.2.3} erörtert.} }}} Zudem wird zusammenfassend und anhand eines Beispiels demonstriert, wie die Regel bei der Analyse angewendet wurde. Anschließend wird die Aufteilung der Testsätze im Datensatz dargestellt:

\begin{description}[font=\normalfont\bfseries]
\item [Beschreibung der KS-Regel:] \textbf{Für zitierte Oberflächentexte gerade Anführungszeichen verwenden} (tekom-Regel-Nr. Z 103b)

Nach dieser Regel sollen Oberflächentexte, z.~B. Texte in Software-Oberflä\-chen oder Displaytexte von Geräten, in geraden Anführungszeichen stehen (\citealt{tekom2013}: 117).

Begründung: Die Anführungszeichen erhöhen die Lesbarkeit. Im Vergleich zu der Verwendung von verschiedenen Schriftarten oder Schriftgraden sind gerade Anführungszeichen optisch nicht störend. Zudem unterstützen die Anführungszeichen eine korrekte Übersetzung. (ebd.: 118)

\item[Umsetzungsmuster:]
~\\
\textbf{Vor KS:} Oberflächentext ohne Anführungszeichen\\
\textbf{Nach KS:} Oberflächentext angegeben in geraden Anführungszeichen

\item[KS-Stelle]
~\\
\textbf{Vor KS:} Oberflächentext ohne Anführungszeichen\\
\textbf{Nach KS:} Oberflächentext mit geraden Anführungszeichen

\item[Beispiele]
~\\
\textit{Wählen Sie danach die Option \txgray{Software automatisch installieren.}}\\
\textit{Wählen Sie danach die Option \txgray{$"$Software automatisch installieren$"$}}.

\item[Aufteilung der Testsätze:]
Die Länge der zitierten Oberflächentexte gemessen an der Anzahl der Wörter kann unterschiedlich sein. Da dieser Unterschied einen Einfluss auf das Ergebnis haben kann, wurde bei der Auswahl der Testsätze darauf geachtet, dass sie verschiedene Längen abdecken. Somit bestehen die 24 analysierten Sätze aus: 9 Sätzen mit nur einem Wort als Oberflächentext, 8 Sätzen mit zwei Wörtern und 7 Sätzen mit mehr als zwei Wörtern.

\end{description}


%\caption{\label{bkm:Ref36844888}\label{tab:05:23}   Eckdaten der ersten Regel „Für zitierte Oberflächentexte gerade Anführungszeichen verwenden“}
%\end{table}
Im Folgenden werden die Ergebnisse der einzelnen Analysefaktoren präsentiert.

\subsubsection{\label{sec:5.3.1.1}Vergleich der Fehleranzahl vor vs. nach der Verwendung von Anführungszeichen}

Die Fehleranzahl sank deutlich um knapp 46~\% von 137 Fehlern vor der Verwendung von Anführungszeichen (M = 1,14 / SD = ,964 / N = 120) auf 74 Fehler nach der Verwendung der Anführungszeichen (M = ,62 / SD = ,842 / N = 120), \figref{fig:05:20} und \figref{fig:05:21}.\footnote{\figref{fig:05:21} ist wie folgt zu lesen: Die Punkte zeigen, wie hoch die durchschnittliche Fehleranzahl ausfällt (z.~B. 1,142 vor KS). Die Fehlerbalken zeigen das realisierte 95 \%-Konfidenzintervall (CI) für die durchschnittliche Fehleranzahl (in dem Fall beläuft sich das CI vor KS auf ,98; 1,32). Demnach würde die Fehleranzahl bei der Durchführung einer weiteren vergleichbaren Untersuchung mit einer Wahrscheinlichkeit von 95~\% zwischen ,98 und 1,32 liegen (vgl. \citealt{Eckstein2008}: 81).} Der Mittelwert der Differenz (nach KS $-$ vor KS) der Fehleranzahl pro Satz lag somit bei $-$~,53 (SD = ,767) mit einem 95\%\nobreakdash-Konfidenzintervall zwischen einem Minimum von $-$ ,67 (SD = ,653) und einem Maximum von $-$ ,39 (SD = ,867) (Bootstrapping mit 1000 Stichproben). Die Differenz (nach KS $-$ vor KS) der Fehleranzahl erwies sich als hochsignifikant (z (N = 120) = $-$~6,161 / p < ,001).


\begin{figure}
\captionsetup{width=.45\textwidth}
\begin{floatrow}
%\includegraphics[height=.3\textheight]{figures/d3-img023.png}

%\includegraphics[height=.3\textheight]{figures/d3-img023.png}

%\includegraphics[height=.3\textheight]{figures/d3-img024.png}\newline
%                                    \textbf{,47,77}\newline
%                                    \textbf{,981,32}\newline
%                                    \includegraphics[height=.3\textheight]{figures/d3-img024.png}\\
\ffigbox[.5\textwidth]{\caption{„Anführungsz. verw.“ - Fehlersumme vor vs. nach KS}
\label{fig:05:20}}{
\begin{tikzpicture}
	\begin{axis}[
	ybar,
	ymin = 0,
	ymax = 150,
	axis lines* = left,
	nodes near coords,
%         nodes near coords align = vertical,
  legend style={at={(0.5,-0.2)},anchor=north,cells={align=left}},
  xtick=\empty,
  width = .45\textwidth,
  enlarge x limits = .5
	]
	\addplot+[tmnlpone]
	coordinates{
	(1,137)
	};
	\addplot+[tmnlpthree]
	coordinates{
	(2,74)
	};
	\legend{Anzahl der  fehler\\innerh. KS vor KS,Anzahl der Fehler\\innerh. KS nach KS}
	\end{axis}
\end{tikzpicture}
%\end{figure}
}
%
%
\ffigbox[.45\textwidth]{\caption{Anführungsz. verw.“ - Mittelwert der Fehleranzahl pro Satz vor vs. nach KS}\label{fig:05:21}}{
%\begin{figure}
\includegraphics[width=.25\textwidth]{figures/Abb21-main.png}
\includegraphics[width=.4\textwidth]{figures/Abb21-legend.png}
}
\end{floatrow}
\end{figure}


Durch die Kennzeichnung der Oberflächentexte mithilfe der Anführungszeichen konnten die MÜ-Systeme sie als spezifische Begriffe bzw. Mehrwortentitäten parsen und entsprechend richtig übersetzen: Die Testsätze beinhalteten 9 Sätze (von 24 Ausgangssätzen) mit einem Verb innerhalb des Oberflächentexts (z.~B. ‚Upload vom Gerät‘, ‚Software automatisch installieren‘). Bei 36~\% (16 von 25) der Übersetzungen dieser Sätze wurden die Fehler behoben. Dieser Prozentsatz war höher im Vergleich zu den restlichen 15 Sätzen, in denen kein Verb im Oberflächentext vorkommt. In der letzteren Gruppe wurden in 28~\% (21 von 75) der Übersetzungen die Fehler behoben. Sätze, die innerhalb des Oberflächentexts ein Verb enthalten, beinhalten zudem das Hauptverb des Satzes. Dies erschwert die syntaktische Analyse (Parsing) und begünstigt das Auftreten von Fehlern. In \tabref{tabex:05:11} wurden die Fehler (Großschreibung und Wortstellung) in der Optionsbezeichnung nach der Verwendung der Anführungszeichen behoben (Genaueres zu den Fehlertypen unter \sectref{sec:5.3.1.3}).


\begin{table}
\begin{tabularx}{\textwidth}{lX}
\lsptoprule
\textbf{Vor-KS}     & Wählen Sie danach die Option \textbf{Software automatisch installieren}.\\
\tablevspace
RBMÜ Lucy           & Then select the option \txblue{software automatically} \txred{install}.\\
\midrule
\textbf{Nach-KS}    & Wählen Sie danach die Option \textbf{$"$Software automatisch installieren$"$}.\\
\tablevspace
RBMÜ Lucy           & Then select the option \txblue{$"$Install software automatically$"$}.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:11}Beispiel 11 }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}


\subsubsubsection{Vergleich der Fehleranzahl auf Regel- und MÜ-Systemebene}

Durch die Kennzeichnung der Oberflächentexte mithilfe der Anführungszeichen konnten die MÜ-Systeme diese Texte als spezifische Begriffe bzw. Mehrwortentitäten parsen und entsprechend richtig übersetzen. Die Fehleranzahl nach der Umsetzung der KS-Regel sank entsprechend bei allen MÜ-Systemen.


\begin{figure}
%\textbf{\textit{$-$ 81,8~\%}}

%\textbf{$-$ 80,0~\%}

%\textbf{$-$ 2,4~\%}

%\textbf{\textit{$-$ 63,0~\%}}

%\textbf{\textit{$-$ 46,7~\%}}

%\includegraphics[height=.3\textheight]{figures/d3-img025.png}


%\includegraphics[height=.3\textheight]{figures/d3-img023.png}\\
\begin{tikzpicture}
	\begin{axis}[
	ybar,
	ymin = 0,
	ymax = 50,
	axis lines* = left,
	nodes near coords,
  legend style={at={(0.5,-0.2)},anchor=north},
  xticklabels = {Bing,Google,Lucy,SDL,Systran},
  xtick=data,
  ylabel = {Summe},
  extra description/.code={
            \node at (axis cs:-.5, 40)[anchor=west] {\bfitul{$-$ 81,8\%}};
						\node at (axis cs:.5, 10)[anchor=west] {$-$ 80,0\%};
						\node at (axis cs:1.5, 38)[anchor=west] {\bfitul{$-$ 63,0 \%}};
						\node at (axis cs:2.5, 35)[anchor=west] {\bfitul{$-$ 46,7 \%}};
						\node at (axis cs:3.5, 53)[anchor=west] {$-$ 2,4 \%};
						}
	]
	\addplot+[tmnlpone]
	coordinates{
	(0,33)
	(1,5)
	(2,30)
	(3,27)
	(4,42)
	};
	\addplot+[tmnlpthree]
	coordinates{
	(0,6)
	(1,1)
	(2,16)
	(3,10)
	(4,41)
	};
	\legend{Anzahl der  fehler innerh. KS vor KS,Anzahl der Fehler innerh. KS nach KS}
	\end{axis}
\end{tikzpicture}
\caption{\label{fig:05:22}„Anführungsz. verw.“ -- Summe der Fehleranzahl vor vs. nach KS bei den einzelnen MÜ-Systemen}
\bspnote{\bfitul{Signifikante Differenz vor vs. nach KS}}
\end{figure}

Bei dem NMÜ-System Google Translate war die Fehleranzahl sowohl vor als auch nach der Umsetzung der KS-Regel gering (Mdiff~=~$-$~,167), während bei dem HMÜ-System Systran die Fehleranzahl sowohl vor als auch nach der Umsetzung der KS-Regel sehr hoch und mit einer minimalen Differenz (nach KS $-$ vor KS) verbunden war (Mdiff = $-$~,042). Ein Vergleich der MÜ beider Systeme (Google Translate vs. Systran) in \tabref{tabex:05:12} zeigt Folgendes:


\begin{table}
\begin{tabularx}{\textwidth}{lX}
\lsptoprule
\textbf{Vor-KS} & Im Reiter \textbf{Kommunikation BACnet} können die notwendigen Einstellungen eingegeben werden.\\
\tablevspace
HMÜ Systran & In the tab \txred{communication} \txblue{BACnet}, the necessary settings can be entered.\\
GNMÜ & The necessary settings can be entered in the \txblue{Communication} tab \txred{BACnet}.\\
\midrule
\textbf{Nach-KS} & Im Reiter \textbf{$"$Kommunikation BACnet$"$} können die notwendigen Einstellungen eingegeben werden.\\
\tablevspace
HMÜ Systran & In the tab \txblue{“}\txred{communication} \txblue{BACnet”}, the necessary settings can be entered.\\
GNMÜ & The necessary settings can be entered in the \txblue{$"$Communication BACnet$"$} tab.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:12}Beispiel 12   }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

Bei dem HMÜ-System Systran wurde der Oberflächentext sowohl mit als auch ohne Verwendung der Anführungszeichen kleingeschrieben, jedoch gab es keinen Wortstellungsfehler. Das NMÜ-System konnte ohne Anführungszeichen den Oberflächentext nur zum Teil (in ‚Communication‘) als Bezeichnung erkennen und großschreiben. Problematisch für Google Translate war die unbekannte Bezeichnung ‚BACnet‘. Dies war möglicherweise die Ursache für den Wortstellungsfehler. Die Schwäche der NMÜ bei der Übersetzung von seltenen Wörtern und Eigennamen wurde in vorherigen Studien (vgl. \citealt{LeSchuster2016}; \citealt{Köhn2017}) thematisiert. Die Verwendung der Anführungszeichen war hierbei für Google Translate nützlich, denn durch die Markierung der Oberflächenbezeichnung konnte der Wortstellungsfehler behoben werden. Insgesamt traten bei Google Translate fünf Fehler bei der Übersetzung von vier Sätzen (inkl. \tabref{tabex:05:12}) vor der Regelanwendung auf (\figref{fig:05:22}). In einer Wiederholung der Übersetzung Anfang 2020 ohne Verwendung der Anführungszeichen mit Google Translate trat nur ein Fehler (Kleinschreibung einer Bezeichnung) auf. Dies deutet auf einen Fortschritt im Bereich der Übersetzung von seltenen Wörtern bzw. Eigennamen hin.

Einen signifikanten Unterschied gab es bei den drei weiteren Systemen: dem \textit{HMÜ-System Bing}\textbf{ }(Mdiff = $-$ 1,125; z (N = 24) = $-$ 4,093 / p < ,001); dem \textit{SMÜ-System SDL} (Mdiff = $-$ ,708; z (N = 24) = $-$ 3,117 / p = ,002); dem \textit{RBMÜ-System Lucy} (Mdiff = $-$ ,583; z (N = 24) = $-$ 2,889 / p = ,004). Mehr Details zu den genauen Fehlertypen bei jedem System sind unter \sectref{sec:5.3.1.3} zu finden.

\subsubsection{\label{sec:5.3.1.2}Aufteilung der Annotationsgruppen}

Wie \figref{fig:05:23} zeigt, enthielten knapp 42~\% der Übersetzungen sowohl vor als auch nach der Verwendung der Anführungszeichen Fehler (Gruppe FF). Außerdem waren fast 26~\% der Übersetzungen sowohl vor als auch nach der Verwendung der Anführungszeichen fehlerfrei (Gruppe RR). Gleichzeitig wurden ungefähr 31~\% falsche Übersetzungen (vor KS) nach der Verwendung der Anführungszeichen korrigiert (Gruppe FR).


\begin{figure}
%\includegraphics[height=.3\textheight]{figures/d3-img012.png}

%\includegraphics[height=.3\textheight]{figures/d3-img012.png}
% 23
\torte[pin]{50}{37}{2}{31}

\caption{\label{fig:05:23} „Anführungsz. verw.“ -- Aufteilung der Annotationsgruppen}
\end{figure}

Auf der anderen Seite kam es sehr selten vor (nur bei 2 Übersetzungen), dass nach der Verwendung der Anführungszeichen eine vor der Verwendung der Anführungszeichen korrekte Übersetzung falsch übersetzt wurde (Gruppe RF). Im nächsten Abschnitt (\sectref{sec:5.3.1.3}) werden die Fehlertypen ins Visier genommen.

\subsubsubsection{Vergleich der Aufteilung der Annotationsgruppen auf Regel- und MÜ-Systemebene}

Eine genauere Analyse der einzelnen MÜ-Systeme bei der Regel „Für zitierte Oberflächentexte gerade Anführungszeichen verwenden“ zeigt Folgendes (\figref{fig:05:24}):


\begin{figure}
%\includegraphics[height=.3\textheight]{figures/d3-img026.png}\newline  \textbf{21\%}   \textbf{4\%}  \textbf{58\%}  \textbf{29\% 96\%}            \textbf{67\% 13\%}  \textbf{29\% 46\%}                                                 \textbf{8\%}                       \textbf{13\% 83\% 13\%}  \textbf{17\%}  \textbf{4\%}\newline  \includegraphics[height=.3\textheight]{figures/d3-img026.png}\\
\begin{tikzpicture}
\tikzset{every node/.style={font=\scriptsize}};
	\begin{axis}[
	ybar,
	width = \textwidth,
	axis lines* = left,
	ylabel = {Anzahl},
	xtick = {3,9,15,21},
	xticklabels = {FF,FR,RF,RR},
  x tick label style ={yshift=-5pt},
	xtick=data,
  xlabel={Annotationsgruppe},
	ymin=0,
	ymax = 25,
%	bar shift = 0pt,
  bar width=9,
	nodes near coords,
%	legend pos= north east,
	legend style={at={(0.5,-0.15)},anchor=north},
	legend columns = {-1},
	extra description/.code={
  \node at (axis cs:.9,7)[anchor = west]{4,2\%};
	\node at (axis cs:.7,-.5)[anchor = west]{21\%};
	\node at (axis cs:1.5,3)[anchor = west]{0,8\%};
	\node at (axis cs:1.5,-.5)[anchor = west]{4\%};
	\node at (axis cs:2.2,16)[anchor = west]{11,7\%};
	\node at (axis cs:2.2,-.5)[anchor = west]{58\%};
	\node at (axis cs:3.1,9)[anchor = west]{5,8\%};
	\node at (axis cs:3.1,-.5)[anchor = west]{29\%};
	\node at (axis cs:4,25)[anchor = west]{19,2\%};
	\node at (axis cs:4,-.5)[anchor = west]{96\%};
	\node at (axis cs:6.5,18)[anchor = west]{13,3\%};
	\node at (axis cs:6.4,-.5)[anchor = west]{67\%};
	\node at (axis cs:7.5,5)[anchor = west]{2,5\%};
	\node at (axis cs:7.5,-.5)[anchor = west]{13\%};
	\node at (axis cs:8.3,9)[anchor = west]{5,8\%};
	\node at (axis cs:8.3,-.5)[anchor = west]{29\%};
	\node at (axis cs:9.3,13)[anchor = west]{9,2\%};
	\node at (axis cs:9.3,-.5)[anchor = west]{46\%};
	\node at (axis cs:15,4)[anchor = west]{1,7\%};
	\node at (axis cs:15.2,-.5)[anchor = west]{8\%};
	\node at (axis cs:18.4,5)[anchor = west]{2,5\%};
	\node at (axis cs:18.4,-.5)[anchor = west]{13\%};
	\node at (axis cs:19.3,22)[anchor = west]{16,7\%};
	\node at (axis cs:19.4,-.5)[anchor = west]{83\%};
	\node at (axis cs:20.3,5)[anchor = west]{2,5\%};
	\node at (axis cs:20.3,-.5)[anchor = west]{13\%};
	\node at (axis cs:21.2,6)[anchor = west]{3,3\%};
	\node at (axis cs:21.2,-.5)[anchor = west]{17\%};
	\node at (axis cs:22.1,3)[anchor = west]{0,8\%};
	\node at (axis cs:22.2,-.5)[anchor = west]{4\%};
	}
	]
	\addplot+[lsNightBlue]
	coordinates {
	(3,5)
	(9,16)
	(15,0)
	(21,3)
	};
	\addplot+[tmnlpone]
	coordinates {
	(3,1)
	(9,3)
	(15,0)
	(21,20)
	};
	\addplot+[tmnlptwo]
	coordinates {
	(3,14)
	(9,7)
	(15,0)
	(21,3)
	};
	\addplot+[tmnlpthree]
	coordinates {
	(3,7)
	(9,11)
	(15,2)
	(21,4)
	};
	\addplot+[tmnlpfour]
	coordinates {
	(3,23)
	(9,0)
	(15,0)
	(21,1)
	};
	\legend{Bing,Google,Lucy,SDL,Systran}
	\end{axis}
\end{tikzpicture}
\bspnote{Die oben angezeigten Prozentzahlen sind für alle Systeme, d. h. systemübergreifend, (N = 120) berechnet.\\
Die untenstehenden Prozentzahlen sind auf Systemebene (N = 24) berechnet.}
 \caption{\label{fig:05:24}   „Anführungsz. verw.“ -- Aufteilung der Annotationsgruppen bei den einzelnen MÜ-Systemen}
\end{figure}

Wie \figref{fig:05:24} zeigt, waren 96~\% der 24 Sätze des HMÜ-Systems Systran sowohl vor der Verwendung der Anführungszeichen als auch danach falsch (Gruppe FF). Der Grund hierfür ist, dass Systran die Oberflächentexte immer in Kleinschreibung übersetzt hat (vgl. \tabref{tabex:05:12}). Ebenfalls blieben 11 von 24 Oberflächentexte bei dem RBMÜ-System Lucy trotz der Verwendung der Anführungszeichen kleingeschrieben (Gruppe FF). Insbesondere bei regelbasierten Systemen ist davon auszugehen, dass sie auf Basis der hinterlegten Systemregeln die Oberflächentexte mithilfe der Anführungszeichen erkennen und in Großschreibung übersetzen. In anderen Worten würde bei dem RBMÜ-System in Verbindung mit dieser KS-Regel eine Besserung des MÜ-Outputs erwartet.

In der Gruppe RR war das NMÜ-System Google mit 83~\% seiner 24 analysierten Sätze an erster Stelle vertreten. Zudem wurden 13~\% seiner Sätze (3 von 24 Sätzen) erst nach der Verwendung der Anführungszeichen korrekt übersetzt (Gruppe FR) (vgl. \tabref{tabex:05:12}), siehe \figref{fig:05:24}.

Im Gegenteil zu dem HMÜ-System Systran konnte das andere HMÜ-System (Bing) von der Anwendung der Regel deutlich profitieren, sodass 67~\% der falschen Übersetzungen nach der Verwendung der Anführungszeichen fehlerfrei übersetzt wurden (Gruppe FR), siehe \figref{fig:05:24}. Auch bei dem SMÜ-System SDL konnten viele Kleinschreibungen mithilfe der Anführungszeichen (nach KS) korrigiert werden. Die Gruppe RF kam selten (genau in zwei Fällen) nur bei SDL vor.

\subsubsection{\label{sec:5.3.1.3}Vergleich der Fehlertypen vor vs. nach der Verwendung von Anführungszeichen}

Nach der Verwendung von Anführungszeichen sank die Fehleranzahl von zwei Fehlertypen deutlich: Fehlertyp OR.2 „Orthografie -- Großschreibung“ von 80 auf 39 (51,2~\% / Mv = ,67 / SDv = ,473 / Mn = ,33 / SDn = ,470 / N = 120) sowie Fehlertyp GR.10 „Grammatik -- Falsche Wortstellung“ von 32 auf 14 (56,2~\% / Mv = ,27 / SDv = ,463 / Mn = ,12 / SDn = ,322 / N = 120), siehe \figref{fig:05:25}. Der Unterschied bei den beiden Fehlertypen OR.2 und GR.10 erwies sich als hochsignifikant (p < ,001 / N = 120).


\begin{figure}
% \begin{tabularx}{\textwidth}{XXXX}
% \lsptoprule
% \multicolumn{3}{p{6cm}}{{
%\includegraphics[height=.3\textwidth]{figures/d3-img027.png}%
% }\newline
%\textbf{
% \textit{$-$ 56,2~\%}
% }\newline
% \textbf{\textit{$-$ 51,2~\%}}
% \newline
%\includegraphics[height=.3\textwidth]{figures/d3-img027.png}
% } &



%\includegraphics[height=.3\textwidth]{figures/d3-img013.png}%
%\includegraphics[height=.3\textwidth]{figures/d3-img013.png}


% 25
\pgfplotstableread{
1 1
2 2
3 80
4 39
5 1
6 1
7 3
8 0
9 0
10 0
11 1
12 0
13 0
14 1
15 0
16 0
17 0
18 0
19 32
20 14
21 16
22 15
23 3
24 2
25 0
26 0
}\datatable
\smbars[extra description/.code={
\node at (axis cs:3.2, 70)[anchor=west]{\bfitul{$-$ 51,2\%}};
\node at (axis cs:18, 40)[anchor=west]{\bfitul{$-$ 56,2\%}};
}]{}

\caption{\label{fig:05:25} „Anführungsz. verw.“ -- Summe der Fehleranzahl der einzelnen Fehlertypen vor vs. nach KS}
\bspnote{
*Die X-Achse ist folgendermaßen zu lesen: Jeder Fehlertyp wird anhand von zwei Balken abgebildet. Der erste Balken repräsentiert die Summe der Fehler vor KS und der zweite die Summe der Fehler nach KS, somit steht z. B. „OR\_1.v“ für „OR\_1: Orthografischer Fehler Nr. 1“ und „v: Vor KS“; „OR\_1.n“ wäre entsprechend das Pendant zu „OR\_1.v“ für das nach-KS-Szenario („n“). \\
**\bfitul{Signifikante Differenz vor vs. nach KS}\\
OR.1: Orthografie -- Zeichensetzung\\
OR.2: Orthografie -- Großschreibung\\
LX.3: Lexik -- Wort ausgelassen\\
LX.4: Lexik -- Zusätzliches Wort eingefügt\\
LX.5: Lexik -- Wort unübersetzt geblieben (auf DE wiedergegeben)\\
LX.6: Lexik -- Konsistenzfehler\\
GR.7: Grammatik -- Falsche Wortart / Wortklasse\\
GR.8: Grammatik -- Falsches Verb (Zeitform, Komposition, Person)\\
GR.9: Grammatik -- Kongruenzfehler (Agreement)\\
GR.10: Grammatik -- Falsche Wortstellung\\
SM.11: Semantik -- Verwechslung des Sinns\\
SM.12: Semantik -- Falsche Wahl\\
SM.13: Semantik -- Kollokationsfehler
}
\end{figure}


Die Markierung der Oberflächentexte, insbesondere derjenigen, die als Mehrwortentitäten auftreten, mithilfe von Anführungszeichen vereinfacht die syntaktische Analyse (Parsing). Entsprechend wird der Oberflächentext als solcher erkannt und großgeschrieben übersetzt. Ferner fördert die Erkennung des Oberflächentexts eine korrekte Wortstellung. Insbesondere Oberflächentexte, die ein Verb umfassen, sind für die MÜ-Systeme problematisch, da dieses Verb, wie in \tabref{tabex:05:13}, oft mit dem eigentlichen Verb des Satzes kollidiert:


\begin{table}
\begin{tabularx}{\textwidth}{lQ}
\lsptoprule
\textbf{Vor-KS} & \textbf{Hierzu kann die Funktion} \txred{Upload vom Gerät} \textbf{gewählt werden.}\\
\tablevspace
HMÜ Bing & To do this, the function can \txred{upload XXX the} \txblue{device} be selected.\\
\midrule
\textbf{Nach-KS} & \textbf{Hierzu kann die Funktion} \txred{$"$Upload vom Gerät$"$} \textbf{gewählt werden.}\\
\tablevspace
HMÜ Bing & To do this, the function \txblue{$"$Upload from the unit$"$} can be selected.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:13}Beispiel 13   }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens; \txred{XXX} für ein fehlendes Wort oder Komma.}
\end{table}

Der Fehlertyp SM.11 „Semantik -- Verwechslung des Sinns“ blieb fast unverändert (16 vor der Umsetzung bzw. 15 nach der Umsetzung der KS-Regel), siehe \figref{fig:05:25}. Wenn der Oberflächentext semantisch nicht eindeutig ist, stellt dies eine Schwierigkeit für die MÜ-Systeme dar, die durch die Verwendung von Anführungszeichen nicht gemindert werden kann. Beispiele hierfür sind die Oberflächentexte ‚Netzwerk \textit{absuchen}‘ (wurde als ‚\textit{Search} network‘ anstatt ‚Scan network‘ übersetzt) und ‚\textit{Geräte}parameter ändern‘ (wurde als ‚Change \textit{equipment} parameters‘ anstatt ‚Change device parameters‘ übersetzt). Alle anderen Fehlertypen kamen mit sehr wenigen Instanzen (max. drei Mal in den 240 analysierten maschinellen Übersetzungen) vor und nach der Anwendung der Regel vor.

\subsubsubsection{Vergleich der Fehlertypen auf Regel- und MÜ-Systemebene}

Eine genauere Untersuchung der Fehlertypen bei den verschiedenen MÜ-Systemen zeigt, dass die obengenannten signifikanten Unterschiede in der Fehleranzahl des Fehlertyps OR.2 „Orthografie -- Großschreibung“ und des Fehlertyps GR.10 „Grammatik -- Falsche Wortstellung“ wie folgt zu beobachten sind: Die Veränderung im orthografischen Fehlertyp OR.2 „Großschreibung“ war bei den Systemen Bing, Lucy und SDL signifikant, während die Veränderung im grammatischen Fehlertyp GR.10 „Wortstellung“ nur bei Bing signifikant ausfiel.


\begin{figure}
%\includegraphics[height=.3\textheight]{figures/d3-img028.png}\newline  \includegraphics[height=.3\textheight]{figures/d3-img026.png}\\
\begin{tikzpicture}
	\begin{axis}[
	ybar,
	width = \textwidth,
	axis lines* = left,
	ylabel = {Summe},
	xtick = {1,2,3,4,5,6},
	xticklabels = {IN\_OR\_2.v,IN\_OR\_2.n,IN\_GR\_10.v,IN\_GR\_10.n,IN\_SM\_11.v,IN\_SM\_11.n},
	x tick label style={font=\footnotesize},
	enlarge x limits={.09},
	ymin=0,
	ymax = 26,
  	bar width=7,
	nodes near coords,
	legend style={at={(0.5,-0.1)},anchor=north},
	legend columns = {-1},
	]
	\addplot+[lsNightBlue]
	coordinates {
	(1,20)
	(2,1)
	(3,9)
	(4,3)
	(5,1)
	(6,2)
	};
	\addplot+[tmnlpone]
	coordinates {
	(1,2)
	(2,1)
	(3,3)
	(4,0)
	(5,0)
	(6,0)
	};
	\addplot+[tmnlptwo]
	coordinates {
	(1,18)
	(2,11)
	(3,7)
	(4,0)
	(5,3)
	(6,3)
	};
	\addplot+[tmnlpthree]
	coordinates {
	(1,17)
	(2,3)
	(3,6)
	(4,4)
	(5,2)
	(6,0)
	};
	\addplot+[tmnlpfour]
	coordinates {
	(1,23)
	(2,23)
	(3,7)
	(4,7)
	(5,10)
	(6,10)
	};
	\legend{Bing,Google,Lucy,SDL,Systran}
	\end{axis}
\end{tikzpicture}

% \lspbottomrule
% \end{tabularx}
\caption{\label{fig:05:26}  „Anführungsz. verw.“ -- Summe der Fehleranzahl der Fehlertypen vor vs. nach KS bei den einzelnen MÜ-Systemen}
\bspnote{*Die Balken zeigen die Summe der Fehleranzahl bei jedem Fehlertyp, wobei „v“ für die Summe „vor der Anwendung der KS-Regel“ und „n“ für die Summe „nach der Anwendung der KS-Regel“ steht. Jeder Fehlertyp wird erst für alle Systeme für das Szenario „vor KS“ abgebildet, danach folgt derselbe Fehlertyp wieder für alle Systeme für das Szenario „nach KS“.

**Um die Übersichtlichkeit und Lesbarkeit der Grafik zu erhöhen, wurden in der Grafik die Fehlertypen ausgeblendet, die 0 oder nur einmal bei \textit{allen} MÜ-Systemen auftraten: In dieser Grafik kamen die Fehlertypen 5, 8, 9 und 13 bei gar keinem MÜ-System vor. Zudem wurden die Fehlertypen 1, 3, 4, 6, 7 und 12 nur einmal jeweils bei 1--3 MÜ-Systemen in vereinzelten Fällen registriert.}
\end{figure}

Wie \figref{fig:05:26} zeigt, sank der Fehlertyp OR.2 bei Bing von 20 auf 1 ($-$~95~\%), bei Lucy von 18 auf 11 ($-$~38,9~\%) und bei SDL von 17 auf 3 ($-$ 82,4~\%). Der Fehlertyp GR.10 sank bei Bing von 9 auf 3 ($-$~66,7~\%). \tabref{tabex:05:14} zeigt, wie die beiden Fehlertypen (der Großschreibungsfehler und der Wortstellungsfehler im Oberflächentext ‚Install software from a specific list‘) nach der Verwendung der Anführungszeichen behoben wurden:

\begin{table}
\begin{tabularx}{\textwidth}{lQ}
\lsptoprule
\textbf{Vor-KS} & \textbf{Wählen Sie die Option} \txred{Software von einer bestimmten Liste installieren}.\\
\tablevspace
HMÜ Bing & Select the \txred{install} \ul{option} \txred{software} \txblue{from a specific list}.\\
\midrule
\textbf{Nach-KS} & \textbf{Wählen Sie die Option} \txred{$"$Software von einer bestimmten Liste installieren$"$}.\\
\tablevspace
HMÜ Bing & Select the option \txblue{$"$Install software from a specific list$"$}.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:14}Beispiel 14   }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

Wie \figref{fig:05:22} zeigt, fanden die markanten Veränderungen der Fehleranzahl nur bei den Systemen Bing, Lucy und SDL statt. Bei Google war die Fehleranzahl vor und nach der Anwendung der KS-Regel klein und bei Systran war die Fehleranzahl in beiden Szenarien groß mit einer minimalen Veränderung nach der Regelanwendung. Entsprechend erwies sich der Unterschied in der Fehleranzahl der beiden Fehlertypen OR.2 und GR.10 wie folgt als signifikant (\tabref{tab:05:24}).


\begin{table}
\begin{tabularx}{.81\textwidth}{lllll}
\lsptoprule
& \textbf{N} & \textbf{Mittelwert} & \textbf{Standard-} & \textbf{Signifikanz}\\
& &  & \textbf{abweichung} & \textbf{(McNemar-Test)}\\
\midrule
\multicolumn{5}{l}{\textbf{OR.2 „Großschreibung“}}\\
 Bing & 24 & vor KS = ,83 & vor KS = ,381 & p < ,001\\
 & & nach KS = ,04 & nach KS = ,204 &\\
 Lucy & 24 & vor KS = ,75 & vor KS = ,442 & p = ,016\\
 & & nach KS = ,46 & nach KS = ,509 &\\
 SDL & 24 & vor KS = ,71 & vor KS = ,464 & p < ,001\\
 & & nach KS = ,13 & nach KS = ,338 &\\
\midrule
\multicolumn{5}{l}{\textbf{GR.10 „Falsche Wortstellung“}}\\
 Bing & 24 & vor KS = ,17 & vor KS = ,482 & p = ,031\\
 & & nach KS = ,13 & nach KS = ,338 &\\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:24} „Anführungsz. verw.“ -- Fehlertypen mit signifikanter Veränderung nach KS  }
\end{table}

Erwartungsgemäß blieb Fehlertyp SM.11 „Semantik -- Verwechslung des Sinns“ fast unverändert. Wenn der Oberflächentext semantisch nicht eindeutig ist, stellt dies eine Schwierigkeit für die MÜ-Systeme dar, die durch die Verwendung von Anführungszeichen nicht beeinflusst werden können. Beispiel hierfür ist die Menübezeichnung ‚Raumdruck‘, die von Systran als ‚Space printing‘ und von Bing als ‚Pressure of space‘ anstelle von ‚Room pressure‘ übersetzt wurde.

\subsubsection{Vergleich der MÜ-Qualität vor vs. nach der Verwendung von Anführungszeichen sowie die Korrelation zwischen den Fehlertypen und der Qualität}\label{sec:5.3.1.4}

Sowohl die Stil- als auch die Inhaltsqualität\footnote{\textrm{Definitionen der Qualität unter \sectref{sec:4.4.5.1}.}} stiegen nach der Verwendung der Anführungszeichen stark: Die Stilqualität verbesserte sich um 13,6~\% (Mv = 3,61 / SDv = ,654 / Mn = 4,10 / SDn = ,461 / N = 74). Die Inhaltsqualität erhöhte sich um 9,6~\% (Mv = 4,17 / SDv = ,857 / Mn = 4,57 / SDn = ,527 / N = 74) (\figref{fig:05:27}). Der Mittelwert der Differenz (nach KS $-$ vor KS) der vergebenen Qualitätspunkte pro Satz lag für die Stilqualität bei ,490 (SD = ,525) mit einem 95\%\nobreakdash-Konfidenzintervall zwischen einem Minimum von ,368 und einem Maximum von ,611 und für die Inhaltsqualität bei ,394 (SD = ,763) mit einem 95\%\nobreakdash-Konfidenzintervall zwischen einem Minimum von ,217 und einem Maximum von ,571 (Bootstrapping mit 1000 Stichproben) (\figref{fig:05:28}). Die Differenzen (nach KS $-$ vor KS) in der Stil- und Inhaltsqualität erwiesen sich als hochsignifikant (z (N = 74) = $-$ 6,235 / p < ,001) bzw. (z (N = 74) = $-$~4,740 / p < ,001).

\begin{figure}
\captionsetup{width=.45\textwidth}
\begin{floatrow}
%\hhline%%replace by cmidrule{-~-}
%\includegraphics[height=.3\textheight]{figures/d3-img029.png}\newline
%                                            \textbf{3,463,76}\newline
%                                            \textbf{4,454,69}\newline
%                                            \textbf{3,984,37}\newline
%                                            \textbf{3,994,20}\newline
%\includegraphics[height=.3\textheight]{figures/d3-img030.png} &  &
%                                                                    \includegraphics[height=.3\textheight]{figures/d3-img017.png}\newline
%                                                                    \includegraphics[height=.3\textheight]{figures/d3-img017.png} \\
\ffigbox[.5\textwidth]{\caption{„Anführungsz. verw.“ -- Mittelwerte der Qualität vor und nach KS}\label{fig:05:27}}{
\includegraphics[width=.25\textwidth]{figures/Abb27.png}
\includegraphics[width=.2\textwidth]{figures/Abb15-legend.png}
}
\ffigbox[.45\textwidth]{\caption{„Anführungsz. verw.“ -- Mittelwert der Qualitätsdifferenzen}\label{fig:05:28}}{
\includegraphics[width=.25\textwidth]{figures/Abb16-legend.png}
\includegraphics[width=.3\textwidth]{figures/Abb28.png}
}
\end{floatrow}
%\end{minipage}
\end{figure}

Die Humanevaluation deckt genauer auf, wie der Qualitätsanstieg zustande kam. Eine Analyse der Qualitätskriterien (\figref{fig:05:29}) zeigt, dass das erste und zweite Stilqualitätskriterium (SQ1 und SQ2) sowie das zweite Inhaltsqualitätskriterium (CQ2) die wesentliche Rolle bei der Qualitätsveränderung spielten.


\begin{figure}


%\includegraphics[height=.3\textheight]{figures/d3-img031.png}\newline
%                                            \textbf{$-$ 21~\%}\newline
%                                            \textbf{$-$ 9~\%}\newline
%                                            \textbf{$-$ 47~\%}\newline
%                                            \textbf{$-$ 51~\%}\newline
%                                            \textbf{$-$ 42~\%}\newline
%                                            }\\
\pgfplotstableread{
1 361
2 210
3 106
4 56
5 293
6 266
7 135
8 107
9 170
10 83
}\datatable

\begin{tikzpicture}
    \begin{axis}[ybar,
                enlarge x limits={.05},
                width  = \textwidth,
                height = .45\textheight,
                axis lines*=left,
                axis on top,
                bar width=8.5,
                bar shift=0pt,
                ymin = 0,
                ymax=400,
                xtick = {1,2,...,10},
                xticklabels={SQ1\_v,
                SQ1\_n,
                SQ2\_v,
                SQ2\_n,
                SQ3\_v,
                SQ3\_n,
                CQ1\_v,
                CQ1\_n,
                CQ2\_v,
                CQ2\_n},
            x tick label style={font=\small},
            nodes near coords,
 	 extra description/.code={
	 \node at (axis cs:1.1,300)[anchor = west]{$-$ 42\%};
	 \node at (axis cs:3,150)[anchor = west]{$-$ 47\%};
	  \node at (axis cs:5.2,350)[anchor = west]{$-$ 9\%};
	   \node at (axis cs:7,180)[anchor = west]{$-$ 21\%};
	    \node at (axis cs:9,200)[anchor = west]{$-$ 51\%};
	  }
            ]
        \addplot +[shift={(.5,0)},lsDarkBlue,x filter/.code={\ifodd\coordindex\def\pgfmathresult{}\fi}] table {\datatable};
        \addplot +[shift={(-.5,0)},lsMidBlue,  x filter/.code={\ifodd\coordindex\relax\else\def\pgfmathresult{}\fi}] table {\datatable};
    \end{axis}
\end{tikzpicture}

\caption{\label{fig:05:29} „Anführungsz. verw.“ -- Vergleich der \textup{Qualitätskriterien}}
\bspnote{\textbf{SQ1:} Ü ist \textbf{nicht} korrekt bzw. \textbf{nicht} klar dargestellt, d. h. nicht orthografisch\\
 \textbf{SQ2:} Ü ist \textbf{nicht} ideal für die Absicht des Satzes, d. h. motiviert den Nutzer \textbf{nicht} zum Handeln, zieht \textbf{nicht} seine Aufmerksamkeit an usw.\\
 \textbf{SQ3:} Ü klingt \textbf{nicht} natürlich bzw. \textbf{nicht} idiomatisch.\\
\textbf{CQ1:} Ü gibt die Informationen im Ausgangstext \textbf{nicht} exakt wieder.\\
\textbf{CQ2:} Ü ist \textbf{nicht} leicht zu verstehen, d. h. \textbf{nicht} gut formuliert bzw. dargestellt.}
\end{figure}

In \tabref{tabex:05:15} unterstützten die Anführungszeichen das MÜ-System (SDL) dabei, die Modulbezeichnung ‚ASV15‘ zu erkennen. Dies bewirkte eine Behebung des Wortstellungsfehlers.


\begin{table}
\begin{tabularx}{\textwidth}{lQ}
\lsptoprule
\textbf{Vor-KS} & Das Modul \textbf{ASV15} darf nur für seinen spezifizierten Einsatzzweck verwendet werden. \\
\tablevspace
SMÜ SDL & The \txblue{ASV} module should only \txred{15} be used for its specified operational purpose.\\
\midrule
\textbf{Nach-KS} & Das Modul \textbf{$"$ASV15$"$} darf nur für seinen spezifizierten Einsatzzweck verwendet werden. \\
\tablevspace
SMÜ SDL & The \txblue{$"$ASV15$"$} module should only be used for its specified operational purpose.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:15}Beispiel 15   }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

Dieses Beispiel veranschaulicht, wie die Verwendung von Anführungszeichen bei Oberflächentexten zu einer korrekten Darstellung der MÜ (SQ1) führt. Dies wiederum trägt dazu bei, die Satzabsicht besser zu vermitteln (SQ2) und die Verständlichkeit zu erhöhen (CQ2).

\subsubsubsection{Korrelation zwischen den Fehlertypen und der Qualität}

Auf Basis der Fehlerannotation zeigte der Vergleich der Fehlertypen vor vs. nach der Verwendung der Anführungszeichen (siehe \sectref{sec:5.3.1.3}), dass ein Zusammenhang zwischen Fehlertyp OR.2 (Orthografie -- Großschreibung) und Fehlertyp GR.10 (Grammatik -- Falsche Wortstellung) und der Verwendung von Anführungszeichen besteht. Anhand der Spearman-Korrelationsanalyse erwies sich ein signifikanter starker negativer Zusammenhang zwischen der Differenz im Fehlertyp GR.10 (Fehleranzahl nach KS \textit{minus} Fehleranzahl vor KS) und der Qualitätsdifferenz (Qualität nach KS $–$ Qualität vor KS), siehe \tabref{tab:05:25}. Weitere Korrelationen zwischen anderen einzelnen Fehlertypen und der Qualität konnten nicht nachgewiesen werden. Durch die Korrektur der Wortstellung nach der Verwendung der Anführungszeichen stieg die Qualität deutlich. In \tabref{tabex:05:15} wurde Fehlertyp GR.10 eliminiert, daraufhin stiegen die Stilqualität um 1,00 Punkte und die Inhaltsqualität um 2,38 Punkte auf der Likert-Skala an.


\begin{table}
\begin{tabularx}{\textwidth}{Xrrr}
\lsptoprule
& \textbf{N} & \textbf{p} & \textbf{ρ}\\
\midrule
\textbf{Differenz SQ (nach KS $-$ vor KS)} &  &  & \\
Diff. der Anzahl der \textbf{GR.10 „f. Wortstellung“} & 74 & < ,001 & \boxblue{$-$~,532}\\
\tablevspace
\textbf{Differenz CQ (nach KS $-$ vor KS)} &  &  & \\
Diff. der Anzahl der \textbf{GR.10 „f. Wortstellung“} &  74 &  < ,001 & \boxblue{$-$~,582}\\
\tablevspace
\textbf{Differenz allg. Q (nach KS $-$ vor KS)} &  &  & \\
Diff. der Anzahl der \textbf{GR.10 „f. Wortstellung“} &  74 &  < ,001 & \boxblue{$-$~,593}\\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:25}„Anführungsz. verw.“ -- Korrelation zwischen den Fehlertypen und der Qualität}
\bspnote{*In der Tabelle werden nur die Fehlertypen dargestellt, die mindestens mit einer Qualitätsvariable signifikant korrelieren.\\
\begin{tabbing}
p: Signifikanz\hspace{2.5cm} \= ρ: Korrelationskoeffizient\hspace{1cm} \= \hspace{4cm}\\
schwache Korrelation (ρ >=0,1) \> \txgreen{mittlere Korrelation (ρ >= 0,3)} \> \boxblue{starke Korrelation (ρ >= 0,5)}\\
\end{tabbing}
}
\end{table}

\subsubsubsection{Vergleich der Qualität auf Regel- und MÜ-Systemebene}

Wie \figref{fig:05:30} zeigt, stiegen sowohl die Stilqualität als auch die Inhaltsqualität bei allen MÜ-Systemen nach der Verwendung der Anführungszeichen.


\begin{figure}
\includegraphics[width=\textwidth]{figures/d3-img032.png}
%\includegraphics[width=.15\textwidth]{figures/Abb15-legend.png}
\caption{\label{fig:05:30}„Anführungsz. verw.“ -- Mittelwerte der Qualität vor vs. nach KS bei den einzelnen MÜ-Systemen   }
\end{figure}

Am höchsten stieg die Stilqualität des HMÜ-Systems Bing, nämlich um 21,2~\%, und am wenigsten die des HMÜ-Systems Systran, und zwar um 9,7~\%. Gleichzeitig stieg die Inhaltsqualität ebenfalls am stärksten bei Bing um 18,4~\% und am schwächsten beim NMÜ-System Google Translate um knapp 3~\%. Da im Falle von Google Translate 83~\% der Sätze sowohl vor als auch nach der Verwendung der Anführungszeichen korrekt übersetzt wurden, zeigte sich bei der Inhaltsqualität kaum eine Veränderung. Dennoch verbesserte die Anwendung der Regel die Stilqualität signifikant um 9,4~\%. Alle Differenzen bei den anderen MÜ-Systemen erwiesen sich in der Stil- und Inhaltsqualität als signifikant (\tabref{tab:05:26}).


\begin{table}
\begin{tabularx}{\textwidth}{Xrrrrrrrrr}
\lsptoprule
& \multicolumn{3}{c}{\textbf{Differenz SQ}} & \multicolumn{3}{c}{\textbf{Differenz CQ}} & \multicolumn{3}{c}{\textbf{Differenz allg. Q}}\\
&  \multicolumn{3}{c}{\textbf{(nach KS $-$ vor KS)}} &  \multicolumn{3}{c}{\textbf{(nach KS $-$ vor KS)}} & \multicolumn{3}{c}{\textbf{(nach KS $-$ vor KS)}}\\
\cmidrule(lr){3-4}\cmidrule(lr){5-7}\cmidrule(lr){8-10}
& \textbf{N} & \textbf{p} & \textbf{z} & \textbf{N} & \textbf{p} & \textbf{z} & \textbf{N} & \textbf{p} & \textbf{z}\\
\midrule
 \textbf{Bing} & 14 & ,003 & $-$ 2,944 & 14 & ,043 & $-$ 2,028 & 14 & ,016 & $-$ 2,418\\
 \textbf{Google} & 19 & < ,001 & $-$ 3,520 & 19 & \txgray{,093} & $-$~1,680 & 19 & ,001 & $-$ 3,250\\
 \textbf{Lucy} & 13 & ,005 & $-$ 2,812 & 13 & ,036 & $-$ 2,092 & 13 & ,004 & $-$ 2,908\\
 \textbf{SDL} & 15 & ,023 & $-$ 2,277 & 15 & ,018 & $-$ 2,374 & 15 & ,012 & $-$ 2,503\\
 \textbf{Systran} & 13 & ,031 & $-$ 2,163 & 13 & ,012 & $-$ 2,512 & 13 & ,011 & $-$ 2,554\\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:26}„Anführungsz. verw.“ -- Signifikanz der Qualitätsveränderung bei den einzelnen MÜ-Systemen}
\bspnote{p: Signifikanz\hspace{2.5cm} z: Teststatistik\hspace{2.5cm} \txgray{nicht signifikant (p ${\geq}$ 0,05)}}
\end{table}

\subsubsubsection{Korrelation zwischen den Fehlertypen und der Qualität auf Regel- und MÜ-Systemebene}

Auf Basis der Fehlerannotation zeigte der Vergleich der Fehlertypen vor vs. nach der Verwendung der Anführungszeichen (siehe \sectref{sec:5.3.1.3}), dass ein Zusammenhang zwischen Fehlertyp OR.2 (Orthografie -- Großschreibung) und Fehlertyp GR.10 (Grammatik -- Falsche Wortstellung) und der Verwendung von Anführungszeichen besteht. Anhand der Spearman-Korrelationsanalyse erwies sich bei dem HMÜ-System Bing und dem RBMÜ-System Lucy jeweils ein signifikanter starker negativer Zusammenhang zwischen der Differenz in den Fehlertypen OR.2 sowie GR.10 und den Qualitätsdifferenzen. Durch die Korrektur der Großschreibung und der Wortstellung nach der Verwendung der Anführungszeichen stieg die Qualität. Weitere Korrelationen zwischen den Fehlertypen und der Qualität konnten bei den anderen MÜ-Systemen nicht nachgewiesen werden (\tabref{tab:05:27}).


\begin{table}
\begin{tabularx}{\textwidth}{Xrrrrrr}
\lsptoprule
& \multicolumn{3}{c}{ \textbf{Bing}}  & \multicolumn{3}{c}{ \textbf{Lucy}} \\
\cmidrule(lr){2-4}\cmidrule(lr){5-7}
& \textbf{N} & \textbf{p} & \textbf{ρ} &  \textbf{N} & \textbf{p} & \textbf{ρ}\\
\midrule
\multicolumn{7}{l}{\textbf{Differenz SQ} \textbf{(nach KS $-$ vor KS)}}\\
Diff. der Anzahl \textbf{OR.2 „Großs.“} &    & &  & 13 & ,021 &  \boxblue{$-$~,631}  \\
Diff. der Anzahl \textbf{GR.10 „Wortst.“} & 14 & ,007 &  \boxblue{$-$~,686} &   13 &  ,005 &  \boxblue{$-$~,722} \\
\midrule
\multicolumn{7}{l}{\textbf{Differenz CQ} \textbf{(nach KS $-$ vor KS)} }\\
 Diff. der Anzahl \textbf{OR.2 „Großs.“} & &  &  &    13 &\txgray{,142} & { $-$~,430}\\
 Diff. der Anzahl \textbf{GR.10 „Wortst.“} & 14 & ,016 &  \boxblue{$-$~,629} &    13 &  ,001 &  \boxblue{$-$~,815}  \\
 \midrule
\multicolumn{7}{l}{\textbf{Differenz Q} \textbf{(nach KS $-$ vor KS)}} \\
 Diff. der Anzahl \textbf{OR.2 „Großs.“} & &  &  & 13 &  \txgray{,126} & { $-$~,447}  \\
 Diff. der Anzahl \textbf{GR.10 „Wortst.“} &  14 & ,005 & \boxblue{$-$~,704} &  13 &  ,001 &  \boxblue{$-$~,804}\\
 \lspbottomrule
\end{tabularx}
\caption{\label{tab:05:27} „Anführungsz. verw.“ -- Korrelationen zwischen den Fehlertypen und der Qualität bei den einzelnen MÜ-Systemen}
\bspnote{*In der Tabelle werden nur die Fehlertypen dargestellt, die bei mind. einer Qualitätsvariable eine signifikante Korrelation aufweisen.\\
\begin{tabbing}
p: Signifikanz\hspace{2.5cm} \= \txgray{nicht signifikant (p ${\geq}$ 0,05)}\hspace{.5cm} \= ρ: Korrelationskoeffizient\\
schwache Korrelation (ρ >= 0,1) \> \txgreen{mittlere Korrelation (ρ >= 0,3)} \> \boxblue{starke Korrelation (ρ >= 0,5)}
\end{tabbing}
}
\end{table}

Der Zusammenhang lässt sich mithilfe von Beispielsätzen veranschaulichen: In \tabref{tabex:05:14} wurden die Fehlertypen OR.2 und GR.10 eliminiert, daraufhin stiegen die Stilqualität (+~1,50 Punkte) und die Inhaltsqualität (+~2,0 Punkte auf der Likert-Skala) deutlich.

In \tabref{tabex:05:16} wurde der Fehlertyp GR.10 eliminiert, daraufhin erfolgte ein starker Anstieg der Inhaltsqualität um 2,38 Punkte und der Stilqualität um 0,88 Punkte auf der Likert-Skala.


\begin{table}
\begin{tabularx}{\textwidth}{lX}
\lsptoprule
\textbf{Vor-KS} & Mit der Funktion \textbf{Anwendung neu konfigurieren}, kann dem Gerät eine neue Anwendung zugewiesen werden.\\
\tablevspace
RBMÜ Lucy & \textcolor{lsRed}{Configure} the function \txblue{application again} enables you to assign a new application to the device.\\
\midrule
\textbf{Nach-KS} & Mit der Funktion \textbf{$"$Anwendung neu konfigurieren$"$}, kann dem Gerät eine neue Anwendung zugewiesen werden.\\
\tablevspace
RBMÜ Lucy & The function \txblue{$"$Configure application again$"$} enables you to assign a new application to the device.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:16}Beispiel 16   }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

Bei beiden Beispielen reflektieren die Kommentare der Bewerter in der Humanevaluation die Notwendigkeit der Großschreibung und der Hervorhebung der Funktionsbezeichnungen mithilfe von Anführungszeichen oder Fettformatierung. Ferner kommentierten sie aufgrund des Wortstellungsfehlers: „The sentence does not reflect the meaning of the source text at all”; „The translation fails in its informative function; the user has no idea what to do.”\footnote{\textrm{Außerdem haben die Bewerter im letzteren Beispiel eine Formulierung mit „Reconfigure” anstatt „Configure again” als idiomatische Übersetzung empfohlen. Da „Configure again” an sich keine semantisch falsche Übersetzung ist, wurde sie nicht als Fehler annotiert.}}

\subsubsection{\label{sec:5.3.1.5}Vergleich der MÜ-Qualität vor vs. nach der Verwendung von Anführungszeichen auf Annotationsgruppenebene}

Die MÜ-Qualität\footnote{\textrm{Definitionen der Qualität unter \sectref{sec:4.4.5.1}.}} stieg in allen Annotationsgruppen mit Ausnahme der Gruppe RF (\figref{fig:05:31}):


\begin{figure}
\includegraphics[width=\textwidth]{figures/d3-img034.png}
\caption{\label{fig:05:31} „Anführungsz. verw.“ -- Mittelwerte der Qualität vor vs. nach KS auf Annotationsgruppenebene  }
\end{figure}

In der Gruppe FF (Übersetzung vor und nach der Verwendung der Anführungszeichen falsch) stieg die Qualität signifikant: bei der Stilqualität (z (N = 30) = $-$~3,711 / p <~,001) bzw. (z (N = 30) = $-$~2,998 / p~=~,003) bei der Inhaltsqualität (\tabref{tab:05:28}).

\begin{table}
\begin{tabularx}{\textwidth}{Xrrr}

\lsptoprule
& \textbf{N} & \textbf{p} & \textbf{Z} \\
& & \textbf{(Signifikanz)} & \textbf{(Teststatistik)}\\
\midrule
{\textbf{Annotationsgruppe FF}} & {} & {} & \\
\textbf{Differenz SQ} (nach KS $-$ vor KS) & 30 & < ,001 & $-$ 3,711\\
\textbf{Differenz CQ} (nach KS $-$ vor KS) & 30 & ,003 & $-$ 2,998\\
\textbf{Differenz allg. Q} (nach KS $-$ vor KS) & 30 & < ,001 & $-$ 3,659\\
\midrule
{\textbf{Annotationsgruppe FR}} & {} & {} & \\
\textbf{Differenz SQ} (nach KS $-$ vor KS) & 24 & < ,001 & $-$ 3,950\\
  \textbf{Differenz CQ} (nach KS $-$ vor KS) & 24 & ,001 & $-$ 3,402\\
\textbf{Differenz allg. Q} (nach KS $-$ vor KS) & 24 & < ,001 & $-$ 3,787\\
\midrule
{\textbf{Annotationsgruppe RF}} & {} & {} & \\
\textbf{Differenz SQ} (nach KS $-$ vor KS) & 1 & -- & --\\
  \textbf{Differenz CQ} (nach KS $-$ vor KS) & 1 & -- & --\\
\textbf{Differenz allg. Q} (nach KS $-$ vor KS) & 1 & -- & --\\
\midrule
{\textbf{Annotationsgruppe RR}} & {} & {} & \\
\textbf{Differenz SQ} (nach KS $-$ vor KS) & 19 & ,001 & $-$ 3,282\\
  \textbf{Differenz CQ} (nach KS $-$ vor KS) & 19 & \txgray{,273} & $-$~1,096\\
   \textbf{Differenz allg. Q} (nach KS $-$ vor KS) & 19 & ,005 & $-$ 2,825\\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:28} „Anführungsz. verw.“ -- Signifikanz der Qualitätsveränderung auf Annotationsgruppenebene}
\end{table}

Dieses Ergebnis ist auf zwei Gründe zurückzuführen: Erstens wurden die Fehler, die vor der Verwendung der Anführungszeichen auftraten, nach der Verwendung der Anführungszeichen zum Teil eliminiert. In \tabref{tabex:05:17} beinhaltet die Übersetzung einen orthografischen Fehler OR.2 „Großschreibung“ und einen Wortstellungsfehler (GR.10) in der Optionsbezeichnung sowie einen semantischen Fehler SM.11 „Verwechslung des Sinns“ (in der Übersetzung der Präposition ‚von‘) \textit{vor} der Verwendung der Anführungszeichen und \textit{nur} den semantischen Fehler \textit{nach} der Verwendung der Anführungszeichen. Dies führte zur Steigerung der Stil- und Inhaltsqualität. Außerdem unterstützte die orthografische Darstellung mithilfe der Anführungszeichen eine schnelle Verständlichkeit, somit stieg die Stil- und Inhaltsqualität in \tabref{tabex:05:17} um 1,63 bzw. 1,50 Punkte auf der Likert-Skala.


\begin{table}
\begin{tabularx}{\textwidth}{lQ}
\lsptoprule
\textbf{Vor-KS} & Wählen Sie die Option \textbf{Software von einer bestimmten Liste installieren}.\\
\tablevspace
RBMÜ Lucy & Select the option \txred{software of} \txblue{a certain list} \txred{install}.\\
\midrule
\textbf{Nach-KS} & Wählen Sie die Option \textbf{$"$Software von einer bestimmten Liste installieren$"$}.\\
\tablevspace
RBMÜ Lucy & Choose the option \txblue{$"$Install software} \txred{of} \txblue{a certain list$"$}.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:17}Beispiel 17   }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

Zweitens gab es Fälle, in denen die Fehler sich vor sowie nach der Verwendung der Anführungszeichen wiederholten, dennoch stiegen die Stil- und Inhaltsqualität. In \tabref{tabex:05:18} sind die Fehlertypen OR.2 (Großschreibung), SM.11 (Verwechslung des Sinnes) und GR.10 (Falsche Wortstellung) in den beiden Szenarien vorhanden. Eine Darstellung des Oberflächentexts in Anführungszeichen verbesserte jedoch die Stil- und Inhaltsqualität um 1,13 bzw. 0,88 Punkte auf der Likert-Skala.


\begin{table}
\begin{tabularx}{\textwidth}{lQ}
\lsptoprule
\textbf{Vor-KS} & Wählen Sie die Option \textbf{Software von einer bestimmten Liste installieren}.\\
\tablevspace
HMÜ Systran & Select the option \txred{software of} \txblue{a certain list} \txred{install}.\\
\midrule
\textbf{Nach-KS} & Wählen Sie die Option \textbf{$"$Software von einer bestimmten Liste installieren$"$}.\\
\tablevspace
HMÜ Systran & Select the option \txblue{$“$}\txred{software of} \txblue{a certain list} \txred{install}\txblue{$”$}.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:18}Beispiel 18   }
\bspnote{ Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

Erwartungsgemäß stieg die Qualität in der Gruppe FR (Übersetzung vor der Verwendung der Anführungszeichen falsch und nachher richtig) hochsignifikant bei der Stilqualität (z (N = 24) = $-$~3,950 / p <~,001) und bei der Inhaltsqualität (z (N = 24) = $-$~3,402 / p = ,001), siehe \tabref{tab:05:28}. Die Verwendung der Anführungszeichen unterstützte die MÜ-Systeme bei der syntaktischen Analyse (Parsing), entsprechend wurden schwerwiegende Fehler wie die falsche Wortstellung eliminiert.

Die Gruppe RF (Übersetzung vor der Verwendung der Anführungszeichen richtig und nachher falsch) war, wie die Aufteilung der Annotationsgruppen (siehe \sectref{sec:5.3.1.2}) zeigte, sehr selten vertreten. Sie bestand aus nur zwei Übersetzungen. In dieser Gruppe blieb die Inhaltsqualität unverändert, während die Stilqualität sank. Aufgrund der kleinen Anzahl der Übersetzungen können sie allerdings als Ausnahmefälle betrachtet werden.

In der Gruppe RR (Übersetzung vor und nach der Verwendung der Anführungszeichen richtig) war der Unterschied in der Stilqualität signifikant (z (N = 19) = $-$ 3,282 / p = ,001), wobei die Inhaltsqualität einen kleinen insignifikanten Anstieg zeigte. Dieses Ergebnis ist nachvollziehbar, denn die Übersetzung bei dieser Gruppe bleibt inhaltlich identisch, dennoch wird sie durch die Verwendung der Anführungszeichen klarer dargestellt. In \tabref{tabex:05:19} gab es keine Differenz bei der Inhaltsqualität, wobei die Stilqualität um 0,63 Punkte auf der Likert-Skala stieg.


\begin{table}
\begin{tabularx}{\textwidth}{lQ}
\lsptoprule
\textbf{Vor-KS} & Mit der Funktion \textbf{Geräteparameter ändern} können Sie die Parameter eines Gerätes ändern.\\
\tablevspace
GNMÜ & The function \txblue{Change device parameters} enables you to change the parameters of a device.\\
\midrule
\textbf{Nach-KS} & Mit der Funktion \textbf{$"$Geräteparameter ändern$"$} können Sie die Parameter eines Gerätes ändern.\\
\tablevspace
GNMÜ & The function \txblue{$"$Change device parameters$"$} enables you to change the parameters of a device.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:19}Beispiel 19   }
\bspnote{ Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet.}
\end{table}

\subsubsection{Vergleich der AEM-Scores vor vs. nach der Verwendung von Anführungszeichen sowie die Korrelation zwischen den AEM-Scores und der Qualität}
\label{sec:5.3.1.6}

Der Vergleich der AEM-Scores vor und nach der Verwendung von Anführungszeichen zeigte sowohl mit TERbase als auch mit hLEPOR eine Verbesserung der AEM-Scores.

\begin{figure}
\includegraphics[width=.4\textwidth]{figures/Abb32.png}
\includegraphics[width=.35\textwidth]{figures/Abb19-legend.png}

\caption{\label{fig:05:32}  „Anführungsz. verw.“ -- Mittelwert der Differenz der AEM-Scores}
\bspnote{Differenz = AEM-Score nach KS \textit{minus} AEM-Score vor KS }
\end{figure}

Der Mittelwert der Differenz (nach KS $-$ vor KS) im AEM-Score pro Satz lag für TERbase bei ,069 (SD = ,158) und für die hLEPOR bei ,041 (SD = ,119) mit einem 95\%\nobreakdash-Konfidenzintervall (Bootstrapping mit 1000 Stichproben), siehe \figref{fig:05:32}. Die Differenzen (nach KS $-$ vor KS) in TERbase und hLEPOR erwiesen sich als signifikant (z (N = 74) = $-$~3,853 / p <~,001) bzw. (z (N = 74) = $-$~3,266 / p = ,001). Dieses Ergebnis deutet darauf hin, dass nach der Verwendung der Anführungszeichen weniger Edits erforderlich waren.

\subsubsubsection{Korrelation zwischen den Differenzen in den AEM-Scores und der Qualität}

Mithilfe des Spearman-Korrelationstests erwies sich ein signifikanter mittlerer positiver Zusammenhang zwischen den Differenzen der AEM-Scores von TERbase und hLEPOR und der Differenz der allgemeinen Qualität\footnote{\textrm{Die allgemeine Qualität ist Mittelwert der Stilqualität und der Inhaltsqualität, da bei der Untersuchung dieser Korrelation keine Unterscheidung zwischen der Stil- und Inhaltsqualität notwendig ist.}}. \tabref{tab:05:29} demonstriert die Korrelationswerte:


\begin{table}
\begin{tabularx}{\textwidth}{Xrrrr}
\lsptoprule
& \textbf{N} &  \textbf{Signifikanz} & \textbf{Korrelations-} & \textbf{Stärke}\\
& & \textbf{(p)} & \textbf{koeffizient} & \textbf{der}\\
& & & \textbf{(ρ)} & \textbf{Korrelation}\\
\midrule
Korrelation zw. Differenz in der allg. Qualität und Differenz des TERbase-Scores (nach KS $-$ vor KS) & 74 & < ,001 & ,431 & \makecell[tr]{mittlerer\\Zusammen-\\hang}\\
\tablevspace
Korrelation zw. Differenz in der allg. Qualität und Differenz des hLEPOR-Scores (nach KS $-$ vor KS) & { 74} & ,006 & ,319 & \makecell[tr]{mittlerer\\Zusammen-\\hang}\\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:29} „Anführungsz. verw.“ -- Korrelation zwischen den Differenzen der AEM-Scores und den Qualitätsdifferenzen}
\bspnote{
schwache Korrelation (ρ >= 0,1)\hspace{.5em} mittlere Korrelation (ρ >= 0,3)\hspace{.5em} starke Korrelation (ρ >= 0,5)
}
\end{table}

Dieses Ergebnis weist darauf hin, dass -- nach der Verwendung der Anführungszeichen -- die Scores der beiden AEMs sich verbesserten und die Qualität stieg.

\subsubsection{\label{sec:5.3.1.7}Analyse der ersten Regel -- Validierung der Hypothesen}

Um die vorgestellten Ergebnisse auf die Forschungsfragen der Studie zurückzuführen, listet dieser Abschnitt die zugrunde liegenden Hypothesen der Forschungsfragen zusammen mit einer Zusammenfassung der Ergebnisse der ersten analysierten Regel in tabellarischer Form auf. Für einen schnelleren Überblick steht (+) für eine Verbesserung bzw. einen Anstieg z.~B. im Sinne eines Qualitätsanstiegs, verbesserter AEM-Scores oder eines Anstiegs der Fehleranzahl; ($-$) steht für einen Rückgang; die \txgreen{grüne} Farbe symbolisiert eine signifikante Veränderung; \textit{neg} steht für eine negative Korrelation und \textit{pos} für eine positive Korrelation; <{}<{}>{}> steht für eine starke Korrelation und <> für eine mittlere Korrelation.\footnote{\textrm{Schwache Korrelationen werden in dieser Übersicht nicht angezeigt.}}

\subsubsubsection*{\textbf{Regel 1: Für zitierte Oberflächentexte gerade Anführungszeichen $"$\ldots$"$ verwenden}}

\paragraph*{Erster Analysefaktor: Vergleich der Fehleranzahl vor vs. nach der Verwendung von Anführungszeichen}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Gibt es einen Unterschied in der Fehleranzahl nach der Anwendung der KS-Regel im Vergleich zu vor der Anwendung?
\item [H0 --] Es gibt keinen Unterschied in der Fehleranzahl vor vs. nach der Anwendung der KS-Regel.
\item [H1 --] Es gibt einen Unterschied in der Fehleranzahl vor vs. nach der Anwendung der KS-Regel.
\item[Resultat] {}
\end{description}
\parbox[t]{.8\textwidth}{\textbf{Auf Regelebene:}}\\
\noindent
\parbox[t]{.8\textwidth}{
H0 wurde abgelehnt und somit H1 bestätigt.
Die Fehleranzahl sank nach der Verwendung der Anführungszeichen signifikant.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.15\textwidth}{
\textbf{Anz.F.} \textbf{($-$)}\\
}}

\noindent
\parbox[t]{.8\textwidth}{\textbf{Auf Regel- und MÜ-Systemebene:}\\
Bei Lucy, SDL und Systran sank die Fehleranzahl nach der Verwendung der Anführungszeichen signifikant.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.15\textwidth}{
\textbf{Lu ($-$)}\\\textbf{SD ($-$)}\\\textbf{Sy ($-$)}
}}

\medskip
\noindent
\parbox[t]{.8\textwidth}{
Bei Bing und Google sank ebenfalls nach KS die Fehleranzahl, dennoch war der Rückgang nicht signifikant.
}
\parbox[t]{.04\textwidth}{}
\parbox[t]{.15\textwidth}{
\textbf{Bi ($-$)}\\\textbf{Go ($-$)}
}

\hrule
\paragraph*{Zweiter Analysefaktor}\hfill
\begin{figure}[H]
\torte[pin]{50}{37}{2}{31}
\caption{Aufteilung der Annotationsgruppen auf Regelebene}
\end{figure}

\begin{figure}[H]
\begin{tikzpicture}
\tikzset{every node/.style={font=\scriptsize}};
	\begin{axis}[
	ybar,
	width = \textwidth,
  height = .5\textheight,
	axis lines* = left,
	ylabel = {\%},
	xtick = {3,9,15,21},
	xticklabels = {FF,FR,RF,RR},
%  x tick label style ={yshift=-5pt},
	xtick=data,
%  xlabel={Annotationsgruppe},
	ymin=0,
	ymax = 20,
  y filter/.code={\pgfmathparse{#1/120*100}\pgfmathresult},
  bar width=9,
%	nodes near coords,
	legend style={at={(0.5,-0.1)},anchor=north},
	legend columns = {-1},
	]
	\addplot+[lsNightBlue]
	coordinates {
	(3,5)
	(9,16)
	(15,0)
	(21,3)
	};
	\addplot+[tmnlpone]
	coordinates {
	(3,1)
	(9,3)
	(15,0)
	(21,20)
	};
	\addplot+[tmnlptwo]
	coordinates {
	(3,14)
	(9,7)
	(15,0)
	(21,3)
	};
	\addplot+[tmnlpthree]
	coordinates {
	(3,7)
	(9,11)
	(15,2)
	(21,4)
	};
	\addplot+[tmnlpfour]
	coordinates {
	(3,23)
	(9,0)
	(15,0)
	(21,1)
	};
	\legend{Bing,Google,Lucy,SDL,Systran}
	\end{axis}
\end{tikzpicture}
\caption{Aufteilung der Annotationsgruppen auf Regel- und MÜ-Systemebene}
\end{figure}
\hrule
\paragraph*{Dritter Analysefaktor: Vergleich der Fehlertypen vor vs. nach der Verwendung von Anführungszeichen}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Beinhaltet die MÜ bestimmte Fehlertypen vor bzw. nach der Anwendung der KS-Regel?
\item [H0 --] Es gibt keinen Unterschied in der Häufigkeit der einzelnen Fehlertypen vor vs. nach der Anwendung der KS-Regel.
\item [H1 --] Es gibt einen Unterschied in der Häufigkeit der einzelnen Fehlertypen vor vs. nach der Anwendung der KS-Regel.
\item [Resultat] {}
\end{description}
\parbox[t]{.8\textwidth}{\textbf{Auf Regelebene:}}\\
\noindent
\parbox[t]{.8\textwidth}{
H1 wurde nur für zwei Fehlertypen bestätigt.\\
Die Fehleranzahl von OR.2 „Großschreibung“ und GR.10 „Falsche Wortstellung“ sanken nach der Verwendung der Anführungszeichen signifikant.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.15\textwidth}{
\textbf{OR.2 ($-$)}\\
\textbf{GR.10 ($-$)}
\vspace{24pt}
}}

\noindent
\parbox[t]{.8\textwidth}{\textbf{Auf Regel- und MÜ-Systemebene:}}\\
\noindent
\parbox[t]{.8\textwidth}{
Bei Bing, Lucy und SDL sank die Fehleranzahl von OR.2 „Großschreibung“ nach der Verwendung der Anführungszeichen signifikant.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.15\textwidth}{
\textbf{OR.2 ($-$):}\\
\textbf{Bi Lu SD}\\
}}

\medskip
\noindent
\parbox[t]{.8\textwidth}{
Bei Bing sank die Fehleranzahl von GR.10 „Falsche Wortstellung“ nach der Verwendung der Anführungszeichen signifikant.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.15\textwidth}{
\textbf{GR.10 ($-$):}\\
\textbf{Bi}
}}

\medskip
\noindent
\parbox[t]{.8\textwidth}{
Alle weiteren Veränderungen waren nicht signifikant.
}

\hrule
\paragraph*{Vierter Analysefaktor: Vergleich der MÜ-Qualität vor vs. nach der Verwendung von Anführungszeichen}
\begin{description}[font=\normalfont\bfseries]
\item[Fragestellung:] Gibt es einen Unterschied in der Stil- und Inhaltsqualität der MÜ der KS-Stelle nach der Anwendung der KS-Regel im Vergleich zu vor der Anwendung?
\item [H0 --] Es gibt keinen Qualitätsunterschied vor vs. nach der Anwendung der KS-Regel.
\item [H1 --] Es gibt einen Qualitätsunterschied vor vs. nach der Anwendung der KS-Regel.
\newpage
\item [Resultat]
\end{description}
\noindent
\parbox[t]{.75\textwidth}{
\textbf{Auf Regelebene:}}\\
\noindent
\parbox[t]{.75\textwidth}{
H0 wurde abgelehnt und somit H1 bestätigt.\\
Sowohl die Stil- als auch die Inhaltsqualität stiegen signifikant.\\
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.2\textwidth}{
\textbf{SQ (+)}\\
\textbf{CQ (+)}\\
}}

\noindent
\parbox[t]{.75\textwidth}{
\textbf{Auf Regel- und MÜ-Systemebene:}\\
Die Stil- und Inhaltsqualität stiegen bei Bing, Lucy, SDL und Systran signifikant.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.1\textwidth}{
\textbf{SQ (+)}\\
\textbf{Bi} \textbf{Lu}\\
\textbf{SD} \textbf{Sy}
}}
\colorbox{smGreen}{\parbox[t]{.1\textwidth}{
\textbf{CQ (+)}\\
\textbf{Bi} \textbf{Lu}\\
\textbf{SD} \textbf{Sy}
}}

\medskip
\noindent
\parbox[t]{.75\textwidth}{
Bei Google stieg die Stilqualität signifikant und die Inhaltsqualität nicht signifikant.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.1\textwidth}{
\textbf{SQ (+)}\\
\textbf{Go}
}}
\parbox[t]{.1\textwidth}{
\textbf{CQ (+)}\\
\textbf{Go}
}

\hrule
\paragraph*{Fünfter Analysefaktor: Korrelation zwischen den Fehlertypen und der Qualität}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Besteht ein Zusammenhang zwischen der Differenz der Fehleranzahl eines bestimmten Fehlertyps (Fehleranzahl nach KS $-$ vor KS) und der Differenz der Stil- bzw. Inhaltsqualität (Qualität nach KS $-$ vor KS)?
\item [H0 --] Es besteht kein Zusammenhang zwischen der Differenz der Fehleranzahl eines bestimmten Fehlertyps und der Differenz der Stil- bzw. Inhaltsqualität.
\item [H1 --] Es besteht ein Zusammenhang zwischen der Differenz der Fehleranzahl eines bestimmten Fehlertyps und der Differenz der Stil- bzw. Inhaltsqualität.
\item [Resultat]
\end{description}
\noindent
\parbox[t]{.7\textwidth}{
\textbf{Auf Regelebene:}}\\
\noindent
\parbox[t]{.7\textwidth}{
H1 wurde nur für einen Fehlertyp bestätigt.\\
Es bestand ein signifikanter starker negativer Zusammenhang zwischen der Differenz der Fehleranzahl des GR.10 „Falsche Wortstellung“ und der Differenz der Stil- und Inhaltsqualität.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.25\textwidth}{
\textbf{\textit{neg}} \textbf{GR.10 <{}<{}>{}> SQ}\\
\textbf{\textit{neg}} \textbf{GR.10 <{}<{}>{}> CQ}\\
\\
\\
}}

\noindent
\parbox[t]{.7\textwidth}{
\textbf{Auf Regel- und MÜ-Systemebene:}}\\
\noindent
\parbox[t]{.7\textwidth}{
Bei Bing bestand ein signifikanter starker negativer Zusammenhang zwischen der Differenz der Fehleranzahl des GR.10 „Falsche Wortstellung“ und der Differenz der Stil- und Inhaltsqualität.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.25\textwidth}{
\textbf{Bi}\\
\textbf{\textit{neg}} \textbf{GR.10 <{}<{}>{}> SQ}\\
\textbf{\textit{neg}} \textbf{GR.10 <{}<{}>{}> CQ}\\
}}

\medskip
\noindent
\parbox[t]{.7\textwidth}{
Bei Lucy bestand ein signifikanter starker negativer Zusammenhang zwischen der Differenz der Fehleranzahl des GR.10 „Falsche Wortstellung“ und der Differenz der Stil- und Inhaltsqualität sowie ein signifikanter starker negativer Zusammenhang zwischen der Differenz der Fehleranzahl des OR.2 „Großschreibung“ und der Differenz der Stilqualität.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.25\textwidth}{
\textbf{Lu}\\
\textbf{\textit{neg}} \textbf{GR.10 <{}<{}>{}> SQ}\\
\textbf{\textit{neg}} \textbf{GR.10 <{}<{}>{}> CQ}\\
\textbf{\textit{neg}} \textbf{OR.2 <{}<{}>{}> SQ}\\
\\
\\
}}

\medskip
\noindent
\parbox[t]{.7\textwidth}{
Alle weiteren Korrelationen waren nicht signifikant.}

\hrule
\paragraph*{Sechster Analysefaktor: Vergleich der MÜ-Qualität vor vs. nach der Verwendung von Anführungszeichen auf Annotationsgruppenebene}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Gibt es einen Unterschied in der Stil- und Inhaltsqualität bei den einzelnen Annotationsgruppen nach der Anwendung der KS-Regel im Vergleich zu vor der Anwendung?
\item [H0 --] Bei den Annotationsgruppen gibt es keinen Qualitätsunterschied vor vs. nach der Anwendung der KS-Regel.
\item [H1 --] Bei den Annotationsgruppen gibt es einen Qualitätsunterschied vor vs. nach der Anwendung der KS-Regel.
\item [Resultat]
\end{description}
\noindent
\parbox[t]{.8\textwidth}{
H1 wurde nur zum Teil bestätigt:\\
Bei den Annotationsgruppen FF und FR stiegen die Stil- und Inhaltsqualität nach der Verwendung der Anführungszeichen signifikant.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.15\textwidth}{
\textbf{SQ (+)}\\
\textbf{CQ (+)}\\
\\
}}

\medskip
\noindent
\parbox[t]{.8\textwidth}{
Bei der Annotationsgruppe RR stieg die Stilqualität signifikant
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.15\textwidth}{
\textbf{SQ (+)}
}}\\
\noindent
\parbox[t]{.8\textwidth}{
und die Inhaltsqualität nicht signifikant.
}
\parbox[t]{.04\textwidth}{}
\parbox[t]{.15\textwidth}{
\textbf{CQ (+)}
}

\medskip
\noindent
\parbox[t]{.8\textwidth}{
Bei der Annotationsgruppe RF sank die Stilqualität nicht signifikant und blieb die Inhaltsqualität unverändert.
}
\parbox[t]{.04\textwidth}{}
\parbox[t]{.15\textwidth}{
\textbf{SQ ($-$)}\\
\textbf{CQ (=)}
}

\hrule
\paragraph*{Siebter Analysefaktor: Vergleich der AEM-Scores vor vs. nach der Verwendung von Anführungszeichen}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Gibt es einen Unterschied in den AEM-Scores von TERbase bzw. hLEPOR nach der Anwendung der KS-Regel im Vergleich zu vor der Anwendung?
\item [H0 --] Es gibt keinen Unterschied in den AEM-Scores vor vs. nach der Anwendung der KS-Regel.
\item [H1 --] Es gibt einen Unterschied in den AEM-Scores vor vs. nach der Anwendung der KS-Regel.
\item [Resultat]
\end{description}
\noindent
\parbox[t]{.75\textwidth}{
H0 wurde abgelehnt und somit H1 bestätigt.\\
AEM-Scores sowohl von TERbase als auch von hLEPOR verbesserten sich nach der Verwendung von Anführungszeichen signifikant.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.2\textwidth}{
\textbf{TERbase (+)}\\
\textbf{hLEPOR (+)}\\
\\
}}

\hrule
\paragraph*{Achter Analysefaktor: Korrelation zwischen den Differenzen der AEM-Scores und der Qualität}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Besteht ein Zusammenhang zwischen der Differenz der AEM-Scores von TERbase bzw. hLEPOR (Mittelwert der AEM-Scores nach KS $-$ vor KS) und der Differenz der allgemeinen Qualität (Qualität nach KS $-$ vor KS)
\item [H0 --] Es besteht kein Zusammenhang zwischen der Differenz der AEM-Scores und der Differenz der allgemeinen Qualität.
\item [H1 --] Es besteht ein Zusammenhang zwischen der Differenz der AEM-Scores und der Differenz der allgemeinen Qualität.
\item [Resultat]
\end{description}
\parbox[t]{.7\textwidth}{H0 wurde abgelehnt und somit H1 bestätigt.

Es bestand ein signifikanter mittlerer positiver Zusammenhang zwischen der Differenz der AEM-Scores von TERbase und hLEPOR und der Differenz der allgemeinen Qualität.}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.25\textwidth}{\textbf{\textit{pos}} \textbf{TERbase <> Q}\\
\textbf{\textit{pos}} \textbf{hLEPOR <> Q}\\
\\
\\
}}




\subsection{ZWEITE REGEL: Funktionsverbgefüge vermeiden}
\label{sec:5.3.2}

\subsubsection{\label{sec:5.3.2.0}Überblick}

%In \tabref{tab:05:30}
Im Folgenden wird die KS-Regel „Funktionsverbgefüge vermeiden“ kurz beschrieben.\footnote{\textrm{Die für diese Regel relevanten Kontraste im Sprachenpaar DE-EN sind unter \sectref{sec:4.4.2.3} erörtert.} } Zudem wird zusammenfassend und anhand eines Beispiels demonstriert, wie die Regel bei der Analyse angewendet wurde. Anschließend wird die Aufteilung der Testsätze im Datensatz dargestellt:


\begin{description}[font=\normalfont\bfseries]
\item [Beschreibung der KS-Regel:] \textbf{Funktionsverbgefüge vermeiden} (tekom-Regel-Nr. L 103)

Nach dieser Regel soll das bedeutungstragende Verb anstatt des Funktionsverbgefüges verwendet werden (\citealt{tekom2013}: 107).

Begründung: Die Verwendung des bedeutungstragenden Verbs lässt den Satz konkreter und direkter ausfallen (ebd.).

\item[Umsetzungsmuster:]
~\\
\textbf{Vor KS:} mit Funktionsverbgefüge\\
\textbf{Nach KS:} Das Funktionsverbgefüge wird durch das bedeutungstragende Verb ersetzt.

\item[KS-Stelle]
~\\
\textbf{Vor KS:} das Funktionsverbgefüge (FVG)\\
\textbf{Nach KS:} das bedeutungstragende Verb

\item[Beispiele]
~\\
\textit{Im oberen Abschnitt können Sie \txgray{Einstellungen} für die angezeigten Module \txgray{vornehmen}.}\\
\textit{Im oberen Abschnitt können Sie die angezeigten Module \txgray{einstellen}}.

\item[Aufteilung der Testsätze:]
Der Datensatz besteht aus 24 verschiedenen Funktionsverbgefügen, die an unterschiedlichen Stellen in den Sätzen erscheinen und die zwei Formen eines Funktionsverbgefüges umfassen, nämlich:

12 Funktionsverbgefüge aus Funktionsverb + Präpositionalphrase (z. B. zur Anwendung kommen) und

12 Funktionsverbgefüge aus Funktionsverb + Nominalphrase (z.~B. Auswahl treffen).

\end{description}
%\caption{\label{tab:05:30}  Eckdaten der zweiten Regel „Funktionsverbgefüge vermeiden“}
%\end{table}

Im Folgenden werden die Ergebnisse der einzelnen Analysefaktoren präsentiert.


\subsubsection{Vergleich der Fehleranzahl mit vs. ohne Funktionsverbgefüge}
\label{sec:5.3.2.1}

Die Fehleranzahl sank deutlich um 56,7~\% von 90 Fehlern im Falle der Verwendung von Funktionsverbgefügen (M = ,75 / SD = ,928 / N = 120) auf 39 Fehler ohne Funktionsverbgefüge (M = ,33 / SD = ,552 / N = 120), \figref{fig:05:33} und \figref{fig:05:34}. Der Mittelwert der Differenz (nach KS $-$ vor KS) der Fehleranzahl pro Satz lag somit bei $-$~,43 (SD =,984) mit einem 95\%\nobreakdash-Konfidenzintervall zwischen einem Minimum von $-$~,61 (SD = ,805) und einem Maximum von $-$~,26 (SD = 1,145) (Bootstrapping mit 1000 Stichproben). Die Differenz (nach KS $-$ vor KS) der Fehleranzahl erwies sich als hochsignifikant (z (N = 120) = $-$ 4,401 / p < ,001).

\begin{figure}\captionsetup{width=.45\textwidth}
\begin{floatrow}
\ffigbox[.5\textwidth]{\caption{„FVG verm.“ -- Fehlersumme vor vs. nach KS}\label{fig:05:33}}{
\begin{tikzpicture}
	\begin{axis}[
	ybar,
	ymin = 0,
	ymax = 150,
	axis lines* = left,
	nodes near coords,
%         nodes near coords align = vertical,
         legend style={at={(0.5,-0.2)},anchor=north,cells={align=left}},
         xtick=\empty,
         width = .45\textwidth,
         enlarge x limits = .5
	]
	\addplot+[tmnlpone]
	coordinates{
	(1,90)
	};
	\addplot+[tmnlpthree]
	coordinates{
	(2,39)
	};
	\legend{Anzahl der  fehler\\innerh. KS vor KS,Anzahl der Fehler\\innerh. KS nach KS}
	\end{axis}
\end{tikzpicture}
}
\ffigbox[.45\textwidth]{\caption{„FVG verm.“ -- Mittelwert der Fehleranzahl pro Satz vor vs. nach KS}\label{fig:05:34}}{
\includegraphics[width=.4\textwidth]{figures/Abb34.png}
\includegraphics[width=.4\textwidth]{figures/Abb21-legend.png}
}
\end{floatrow}
%\includegraphics[height=.3\textheight]{figures/d3-img023.png}
%\includegraphics[height=.3\textheight]{figures/d3-img023.png}
%\includegraphics[height=.3\textheight]{figures/d3-img023.png}
%&  &
%    \includegraphics[height=.3\textheight]{figures/d3-img024.png}
%    \textbf{,58,93}
%    \includegraphics[height=.3\textheight]{figures/d3-img024.png}
%    \textbf{,23,43}
%    \includegraphics[height=.3\textheight]{figures/d3-img024.png}\\

\end{figure}

Der Datensatz deckte gleichermaßen die zwei Formen eines Funktionsverbgefüges (12 aus Funktionsverb + Präpositionalphrase bestehende Funktionsverbgefüge (z. B. ‚zur Anwendung kommen‘) und 12 aus Funktionsverb + Nominalphrase bestehende Funktionsverbgefüge (z.~B. ‚Auswahl treffen‘)) ab. Im Rahmen der Fehlerannotation wurde untersucht, ob eine der beiden Formen mit mehr Fehlern (vor der KS-Anwendung) verbunden war bzw. ob die KS-Anwendung bei einer der beiden Formen zur stärkeren Reduzierung der Fehleranzahl beitrug.


\begin{table}
\begin{tabularx}{\textwidth}{Xrr}

\lsptoprule
& { \textbf{FVG}} & \textbf{FVG}\\
& \textbf{aus Funktionsverb +} & \textbf{aus Funktionsverb +}\\
& \textbf{Präpositionalphrase} & \textbf{Nominalphrase}\\
 \midrule
\textbf{Anzahl der Fälle} & 12 x 5 MÜ & 12 x 5 MÜ\\
\tablevspace
\textbf{Durchschnittliche Diff. der Fehleranzahl (nach KS – vor KS)} & { $-$ 3,75} & $-$~1,33\\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:31}   Daten der untersuchten FVG-Formen}
\end{table}

Wie \tabref{tab:05:31} zeigt, war der Rückgang der Fehleranzahl ($-$ 3,75) im Falle der aus Funktionsverb + Präpositionalphrase bestehenden Funktionsverbgefüge im Vergleich zu den aus Funktionsverb + Nominalphrase bestehenden Funktionsverbgefügen ($-$ 1,33) größer. Eine genauere Untersuchung des Datensatzes zeigte außerdem, dass die Anwendung der KS-Regel sich in zwei Fällen als besonders sinnvoll erwies:

Erstens -- ein Funktionsverbgefüge besteht aus einem Substantiv und einem Funktionsverb. Wenn das Substantiv ein Teil eines Kompositums ist (z.~B. Flecken\-\textit{behandlung durchführen}, Küchen\textit{montage durchführen}), stellt das Zerlegen dieses Kompositums (d.~h. die Tokenisierung) und anschließend das Parsen des Substantives zusammen mit dem Funktionsverb als zusammengehörender Struktur für die älteren MÜ-Ansätze (SMÜ, RBMÜ und HMÜ Systeme) eine komplexe Aufgabe dar. In \tabref{tabex:05:20} wurde das Kompositum ‚Küchenmöbelmontagen‘ bei der Verwendung des Funktionsverbgefüges vom HMÜ-System Bing gar nicht übersetzt bzw. vom RBMÜ-System Lucy falsch übersetzt. Nach der Verwendung des bedeutungstragenden Verbs (nach KS) lieferten beide Systeme korrekte Übersetzungen.


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & Küchenmöbel\textbf{montagen} dürfen nur von geschulten Fachleuten \textbf{durchgeführt} werden.\\
\tablevspace
HMÜ Bing & \textcolor{lsRed}{Küchenmöbel\textbf{montagen}} may only be \txred{carried out} by trained specialists.\\
RBMÜ Lucy & Kitchen \txred{piece of furniture} \txblue{assemblies} may only be \txred{carried out} by trained specialists.\\
\midrule
\textbf{Nach-KS} & Küchenmöbel dürfen nur von geschulten Fachleuten \textbf{montiert} werden.\\
\tablevspace
HMÜ Bing & Kitchen furniture may only be \txblue{installed} by trained specialists.\\
RBMÜ Lucy & Kitchen furniture may only be \txblue{mounted} by trained specialists.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:20} Beispiel 20  }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

Zweitens -- wenn das Funktionsverbgefüge kein Pendant bzw. keine direkte Übersetzung im Englischen hat (z.~B. Einstellungen vornehmen, Schaden nehmen, Reinigung vornehmen), erwies sich die Verwendung des bedeutungstragenden Verbs ebenfalls als sinnvoll. In \tabref{tabex:05:21} wurde der Kollokationsfehler in ‚make the cleaning‘ nach der Verwendung des bedeutungstragenden Verbs ‚reinigen‘ (nach KS) behoben.


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & Die \textbf{Reinigung} der Küchenmöbel sollten Sie mit einem leicht feuchten Tuch \textbf{vornehmen}. \\
\tablevspace
HMÜ Bing & You should \txred{make} the \txblue{cleaning} of the kitchen furniture with a slightly damp cloth.\\
\midrule
\textbf{Nach-KS} & Sie sollten die Küchenmöbel mit einem leicht feuchten Tuch \textbf{reinigen}. \\
\tablevspace
HMÜ Bing & You should \txblue{clean} the kitchen furniture with a slightly damp cloth.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:21}Beispiel 21   }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

Es gab insgesamt 19 falsche Übersetzungen, die eine dieser Eigenschaften aufweisen. Durch das Vermeiden des Funktionsverbgefüges wurden 13 von den 19 falschen Übersetzungen (68,4~\%) korrigiert.

All diese problematischen Fälle des Funktionsverbgefüges (präpositionale FVG-Konstruktion, FVG in Verbindung mit Kompositum und FVG ohne englisches Pendant) gingen mit Transfer- und Parsing-Problemen einher. Somit wurde das Funktionsverbgefüge wörtlich übersetzt, was zu lexikalischen und semantischen Fehlern führte (wie in der Analyse der Fehlertypen und ihrer Korrelationen mit den Qualitätsveränderungen unter \sectref{sec:5.3.2.3} und \sectref{sec:5.3.2.4} detailliert dargestellt).

\subsubsubsection{Vergleich der Fehleranzahl auf Regel- und MÜ-Systemebene}

Durch die Verwendung des bedeutungstragenden Verbs (nach KS) wurden viele Kollokationsfehler vermieden, die bei der Verwendung des Funktionsverbgefüges (vor KS) auftraten. Die Fehleranzahl nach der Umsetzung der KS-Regel sank bei allen Systemen:


\begin{figure}


%\textbf{\textit{$-$ 63,6~\%}}

%textbf{\textit{$-$ 64,0~\%}}

%\textbf{\textit{$-$ 52,2~\%}}

%\textbf{$-$ 41,2~\%}



%\includegraphics[height=.3\textheight]{figures/d3-img038.png}\\


%\textbf{$-$ 66,7~\%}


%\includegraphics[height=.3\textheight]{figures/d3-img023.png}\\
\begin{tikzpicture}
	\begin{axis}[
	ybar,
	ymin = 0,
	ymax = 25,
  width = \textwidth,
	axis lines* = left,
	nodes near coords,
%         nodes near coords align = vertical,
         legend style={at={(0.5,-0.1)},anchor=north},
         xticklabels = {Bing,Google,Lucy,SDL,Systran},
         xtick=data,
         ylabel = {Summe},
         extra description/.code={
                					\node at (axis cs:-.3, 20)[anchor=west] {$-$ 41,2\%};
						\node at (axis cs:.7, 6)[anchor=west] {$-$ 66,7\%};
						\node at (axis cs:1.7, 25)[anchor=west] {\bfitul{$-$ 63,6 \%}};
						\node at (axis cs:3,21 )[anchor=west] {\bfitul{$-$ 64,0 \%}};
						\node at (axis cs:3.7, 26)[anchor=west] {\bfitul{$-$ 52,2 \%}};
						}
	]
	\addplot+[tmnlpone]
	coordinates{
	(0,17)
	(1,3)
	(2,22)
	(3,25)
	(4,23)
	};
	\addplot+[tmnlpthree]
	coordinates{
	(0,10)
	(1,1)
	(2,8)
	(3,9)
	(4,11)
	};
	\legend{Anzahl der  fehler innerh. KS vor KS,Anzahl der Fehler innerh. KS nach KS}
	\end{axis}
\end{tikzpicture}

\caption{\label{fig:05:35} „FVG verm.“ -- Summe der Fehleranzahl vor vs. nach KS bei den einzelnen MÜ-Systemen  }
\bspnote{ \bfitul{Signifikante Differenz vor vs. nach KS}}
\end{figure}

Signifikant war der Rückgang bei dem RBMÜ-System Lucy (Mdiff = $-$~,583; z (N = 24) = $-$ 2,501 / p = ,012); dem SMÜ-System SDL (Mdiff = $-$~,667; z (N = 24) = $-$ 2,358 / p = ,018); dem HMÜ-System Systran (Mdiff = $-$~,500; z (N = 24) = $-$ 2,144 / p = ,032). Bei dem NMÜ-System Google war die Fehleranzahl sowohl vor als auch nach der Umsetzung der KS-Regel gering (Mdiff = $-$~,083). Bei dem HMÜ-System Bing war die Differenz (nach KS $-$ vor KS) sehr niedrig (Mdiff = $-$~,292).

Das NMÜ-System Google Translate war in der Lage, die Sätze mit und ohne Funktionsverbgefüge korrekt -- und in mehreren Fällen sogar identisch -- zu übersetzen, während die Übersetzungen der anderen MÜ-Systeme Fehler beinhalteten. In \tabref{tabex:05:21} konnte das HMÜ-System Bing erst nach der Verwendung des bedeutungstragenden Verbs (nach KS) den Satz korrekt übersetzen. Das SMÜ-System SDL konnte denselben Satz weder mit Funktionsverbgefüge noch mit dem bedeutungstragenden Verb korrekt übersetzen (die Fehlertypen werden unter \sectref{sec:5.3.2.3} diskutiert), während die Übersetzung vom NMÜ-System Google Translate in beiden Fällen trotz der veränderten Struktur des Ausgangssatzes korrekt und identisch war (\tabref{tabex:05:22}).


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule
\textbf{Vor-KS} & Die \textbf{Reinigung} der Küchenmöbel sollten Sie mit einem leicht feuchten Tuch \textbf{vornehmen}. \\
\tablevspace
SMÜ SDL & The \txblue{cleaning} of the kitchen furniture you should \txred{start} with a slightly damp cloth.   \\
GNMÜ & You should \txblue{clean} the kitchen furniture with a slightly damp cloth.\\
\midrule
\textbf{Nach-KS} & Sie sollten die Küchenmöbel mit einem leicht feuchten Tuch \textbf{reinigen}. \\
\tablevspace
SMÜ SDL & You should \txred{set} the kitchen furniture with a slightly damp cloth.\\
GNMÜ & You should \txblue{clean} the kitchen furniture with a slightly damp cloth.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:22} Beispiel 22  }
\bspnote{ Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

Sogar ein gängiges Funktionsverbgefüge wie ‚zur Verfügung stehen‘ war für alle MÜ-Systeme problematisch zu übersetzen, während das NMÜ-System es problemlos übersetzen konnte und erneut sowohl mit dem Funktionsverbgefüge als auch mit dem bedeutungstragenden Verb eine identische Übersetzung lieferte. \tabref{tabex:05:23} veranschaulicht, wie die Übersetzung des RBMÜ-Systems Lucy vor und nach der Anwendung der KS-Regel Fehler beinhaltete, während die Übersetzung des NMÜ-Systems Google Translate in den beiden Szenarien fehlerfrei war.


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & Auf der Startseite \textbf{stehen} die folgenden Funktionen zur Auswahl \textbf{zur Verfügung}.\\
\tablevspace
RBMÜ Lucy & On the Start page, the following functions \txblue{are} to choose from \txred{availably}.\\
GNMÜ & The following functions \txblue{are available} for selection on the start page.\\
\midrule
\textbf{Nach-KS} & Auf der Startseite \textbf{sind} die folgenden Funktionen zur Auswahl \textbf{vorhanden}.\\
\tablevspace
RBMÜ Lucy & On the Start page, the following functions to choose from \txred{are available}.\\
GNMÜ & The following functions \txblue{are available} for selection on the start page.\\

\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:23} Beispiel 23  }
\bspnote{ Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}


\subsubsection{\label{sec:5.3.2.2}Aufteilung der Annotationsgruppen}

Knapp 42~\% der Übersetzungen waren sowohl mit Funktionsverbgefüge als auch mit dem bedeutungstragenden Verb richtig (Gruppe RR). Außerdem waren fast 21~\% der Übersetzungen in beiden Szenarien falsch (Gruppe FF). Gleichzeitig wurden ungefähr 30~\% falsche Übersetzungen von Sätzen mit Funktionsverbgefügen nach der Verwendung des bedeutungstragenden Verbs korrigiert (Gruppe FR) (siehe \figref{fig:05:36}). Auf der anderen Seite gab es 10 Fälle (8,3~\%), die nur nach der Verwendung des bedeutungstragenden Verbs (nach KS) falsch übersetzt wurden (Gruppe RF) (siehe \figref{fig:05:36}).


\begin{figure}



%\includegraphics[height=.3\textheight]{figures/d3-img012.png}


%\includegraphics[height=.3\textheight]{figures/d3-img039.png}

% 36
\torte{25}{35}{10}{50}

\caption{\label{fig:05:36} „FVG verm.“ -- Aufteilung der Annotationsgruppen  }
\end{figure}


Hierbei handelte es sich zum Teil um semantische Fehler und in einzelnen Fällen um grammatische Fehler. Aufgrund der kleinen Anzahl der Fälle dieser Gruppe konnte jedoch kein bestimmtes Fehlermuster erkannt werden.  Im nächsten Abschnitt werden die Fehlertypen genauer besprochen.

\subsubsubsection{Vergleich der Aufteilung der Annotationsgruppen auf Regel- und MÜ-Systemebene}

Eine genauere Analyse der einzelnen MÜ-Systeme bei der Regel „Funktionsverbgefüge vermeiden“ zeigt Folgendes:


\begin{figure}


%      \textbf{25\% 4\%}  \textbf{21\%25\%29\%}        \textbf{25\% 8\%}  \textbf{42\%29\%42\%}          \textbf{1\%}         \textbf{13\%13\%13\%}         \textbf{46\%88\%25\%33\%17\%}



%\includegraphics[height=.3\textheight]{figures/d3-img040.png}



%\includegraphics[height=.3\textheight]{figures/d3-img026.png}\\
\begin{tikzpicture}
\tikzset{every node/.style={font=\scriptsize}};
	\begin{axis}[
	ybar,
	width = \textwidth,
	axis lines* = left,
	ylabel = {Anzahl},
	xtick = {3,9,15,21},
	xticklabels = {FF,FR,RF,RR},
	x tick label style ={yshift=-5pt},
% 	xtick=data,
%	x=12pt,
	enlarge x limits={.15},
	ymin=0,
	ymax = 25,
%	bar shift = 0pt,
%  	bar width=9,
	nodes near coords,
%	legend pos= north east,
	legend style={at={(0.5,-0.1)},anchor=north},
	legend columns = {-1},
	extra description/.code={
	\node at (axis cs:.5,8)[anchor = west]{5,0\%};
  \node at (axis cs:.5,-.5)[anchor = west]{25\%};
	\node at (axis cs:1.3,3)[anchor = west]{0,8\%};
  \node at (axis cs:1.5,-.5)[anchor = west]{4\%};
	\node at (axis cs:2.1,7)[anchor = west]{4,2\%};
  \node at (axis cs:2.1,-.5)[anchor = west]{21\%};
	\node at (axis cs:3.1,8)[anchor = west]{5,0\%};
  \node at (axis cs:3.1,-.5)[anchor = west]{25\%};
	\node at (axis cs:4,9)[anchor = west]{5,8\%};
  \node at (axis cs:4,-.5)[anchor = west]{29\%};
	\node at (axis cs:6.5,8)[anchor = west]{5,0\%};
  \node at (axis cs:6.5,-.5)[anchor = west]{25\%};
	\node at (axis cs:7.3,4)[anchor = west]{1,7\%};
  \node at (axis cs:7.4,-.5)[anchor = west]{8\%};
	\node at (axis cs:8.3,12)[anchor = west]{8,3\%};
  \node at (axis cs:8.2,-.5)[anchor = west]{42\%};
	\node at (axis cs:9,9)[anchor = west]{5,8\%};
  \node at (axis cs:9.1,-.5)[anchor = west]{29\%};
  \node at (axis cs:10,12)[anchor = west]{8,3\%};
  \node at (axis cs:10.1,-.5)[anchor = west]{42\%};
  \node at (axis cs:12.5,3)[anchor = west]{0,8\%};
  \node at (axis cs:12.5,-.5)[anchor = west]{1\%};
  \node at (axis cs:14,5)[anchor = west]{2,5\%};
  \node at (axis cs:14,-.5)[anchor = west]{13\%};
	\node at (axis cs:15,5)[anchor = west]{2,5\%};
  \node at (axis cs:15,-.5)[anchor = west]{13\%};
  \node at (axis cs:16,5)[anchor = west]{2,5\%};
  \node at (axis cs:16,-.5)[anchor = west]{13\%};
	\node at (axis cs:18.2,13)[anchor = west]{9,2\%};
  \node at (axis cs:18.2,-.5)[anchor = west]{46\%};
	\node at (axis cs:19.3,23)[anchor = west]{17,5\%};
  \node at (axis cs:19.3,-.5)[anchor = west]{88\%};
	\node at (axis cs:20.3,8)[anchor = west]{5,0\%};
  \node at (axis cs:20.3,-.5)[anchor = west]{25\%};
	\node at (axis cs:21.2,10)[anchor = west]{6,7\%};
  \node at (axis cs:21.2,-.5)[anchor = west]{33\%};
	\node at (axis cs:22.2,6)[anchor = west]{3,3\%};
  \node at (axis cs:22.2,-.5)[anchor = west]{17\%};
	}
	]
	\addplot+[lsNightBlue]
	coordinates {
	(3,6)
	(9,6)
	(15,1)
	(21,11)
	};
	\addplot+[tmnlpone]
	coordinates {
	(3,1)
	(9,2)
	(15,0)
	(21,21)
	};
	\addplot+[tmnlptwo]
	coordinates {
	(3,5)
	(9,10)
	(15,3)
	(21,6)
	};
	\addplot+[tmnlpthree]
	coordinates {
	(3,6)
	(9,7)
	(15,3)
	(21,8)
	};
	\addplot+[tmnlpfour]
	coordinates {
	(3,7)
	(9,10)
	(15,3)
	(21,4)
	};
	\legend{Bing,Google,Lucy,SDL,Systran}
	\end{axis}
\end{tikzpicture}

\caption{\label{fig:05:37}„FVG verm.“ -- Aufteilung der Annotationsgruppen bei den einzelnen MÜ-Systemen   }
\bspnote{Die oben angezeigten Prozentzahlen sind für alle Systeme, d. h. systemübergreifend, (N = 120) berechnet.

Die untenstehenden Prozentzahlen sind auf Systemebene (N = 24) berechnet.}
\end{figure}

Die größten Prozentsätze von drei Systemen wurden bei der Gruppe RR verzeichnet. Diese sind das NMÜ-System Google mit 88~\%, das HMÜ-System Bing mit 46~\% sowie das SMÜ-System SDL mit 33~\% (\figref{fig:05:37}). Die zwei weiteren Systeme, das RBMÜ-System Lucy und das HMÜ-System Systran, waren stärker repräsentiert bei der Gruppe FR (im Vergleich zur Gruppe RR), jeweils mit 42~\% (\figref{fig:05:37}). Durch das Vermeiden von den Funktionsverbgefügen konnten sämtliche Kollokationsfehler behoben werden. Dennoch blieb die Gruppe FF bei allen Systemen mit Ausnahme von Google relativ groß (mehr als 20~\%) (\figref{fig:05:37}). Im folgenden Abschnitt werden die aufgetreten Fehlertypen ins Visier genommen.

\subsubsection{\label{sec:5.3.2.3}Vergleich der Fehlertypen mit vs. ohne Funktionsverbgefüge}

Nach der Formulierung des Satzes ohne Funktionsverbgefüge sank die Fehleranzahl bei dem Fehlertyp SM.13 „Semantik -- Kollokationsfehler“ deutlich, und zwar von 38 auf 2 ($-$~94,7~\% / Mv = ,32 / SDv = ,502 / Mn = ,02 / SDn = ,129 / N = 120) (\figref{fig:05:38}). Der Unterschied in der Fehleranzahl erwies sich als hochsignifikant (p < ,001 / N = 120).


\begin{figure}

%\includegraphics[height=.3\textheight]{figures/d3-img041.png}

%\textbf{$-$ 71,4~\%}

%\textbf{$-$ 18,2~\%}

%\textbf{\textit{$-$ 94,7~\%}}

%\includegraphics[height=.3\textheight]{figures/d3-img027.png}}

%\includegraphics[height=.3\textheight]{figures/d3-img013.png}

%\includegraphics[height=.3\textheight]{figures/d3-img013.png}
% 38

\pgfplotstableread{
1 0
2 0
3 0
4 0
5 4
6 3
7 7
8 2
9 1
10 0
11 0
12 0
13 3
14 0
15 5
16 6
17 1
18 0
19 13
20 10
21 11
22 9
23 7
24 7
25 38
26 2
}\datatable
\smbars[extra description/.code={\node at (axis cs:6, 10)[anchor=west] {$-$ 71,4\%};
\node at (axis cs:20, 15)[anchor=west] {$-$ 18,2\%};
\node at (axis cs:24, 42)[anchor=west] {\bfitul{$-$ 94,7\%}};}
]{}

\caption{\label{fig:05:38} „FVG verm.“ -- Summe der Fehleranzahl der einzelnen Fehlertypen vor vs. nach KS}
\bspnote{*Die X-Achse ist folgendermaßen zu lesen: Jeder Fehlertyp wird anhand von zwei Balken abgebildet. Der erste Balken repräsentiert die Summe der Fehler \textit{vor KS} und der zweite die Summe der Fehler \textit{nach KS}, somit steht z.~B. „OR\_1.v“ für „OR\_1: orthografischer Fehler Nr. 1“ und „v: vor KS“; „OR\_1.n“ wäre entsprechend das Pendant zu „OR\_1.v“ für das nach-KS-Szenario („n“).\\
**\bfitul{Signifikante Differenz vor vs. nach KS}\\
OR.1: Orthografie -- Zeichensetzung\\
OR.2: Orthografie -- Großschreibung\\
LX.3: Lexik -- Wort ausgelassen\\
LX.4: Lexik -- Zusätzliches Wort eingefügt\\
LX.5: Lexik -- Wort unübersetzt geblieben (auf DE wiedergegeben)\\
LX.6: Lexik -- Konsistenzfehler\\
GR.7: Grammatik -- Falsche Wortart / Wortklasse\\
GR.8: Grammatik -- Falsches Verb (Zeitform, Komposition, Person)\\
GR.9: Grammatik -- Kongruenzfehler (Agreement)\\
GR.10: Grammatik -- Falsche Wortstellung\\
SM.11: Semantik -- Verwechslung des Sinns\\
SM.12: Semantik -- Falsche Wahl\\
SM.13: Semantik -- Kollokationsfehler}
\end{figure}

Erwartungsgemäß ging die Anzahl der Kollokationsfehler nach der Anwendung der KS-Regel zurück, denn nicht alle deutschen Funktionsverbgefüge haben ein Pendant im Englischen. Ein Beispiel hierfür ist das Funktionsverbgefüge ‚in Betrieb nehmen‘ (siehe \tabref{tabex:05:24}). Hier konnte das MÜ-System nur das bedeutungstragende Verb (nach KS) richtig übersetzen.


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule
\textbf{Vor-KS} & Der Bediener darf erst die Maschine \textbf{in Betrieb nehmen}, wenn er die Betriebsanleitung gelesen hat.\\
\tablevspace
HMÜ Systran & The operator may only \txred{take} the machine \txred{in enterprise} after reading the operating instructions.\\
\midrule
\textbf{Nach-KS} & Der Bediener darf erst die Maschine \textbf{starten}, wenn er die Betriebsanleitung gelesen hat.\\
\tablevspace
HMÜ Systran & The operator may only \txblue{start} the machine after reading the operating instructions.\\
\lspbottomrule
\end{tabularx}\caption{\label{tabex:05:24}Beispiel 24   }
\bspnote{ Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

Bei allen anderen Fehlertypen hat sich die Fehleranzahl vor im Vergleich zu nach der Anwendung der Regel nicht (signifikant) verändert, z.~B. sank der semantische Fehlertyp SM.11 „Verwechslung des Sinns“ von 11 auf 9 ($-$~18,2~\%) Fehler und der lexikalische Fehlertyp LX.4 „Zusätzliches Wort eingefügt“ sank von 7 auf 2 Fehler ($-$~71,4~\%; ein aufgrund der kleinen Fehleranzahl nicht signifikanter Rückgang), während der semantische Fehlertyp SM.12 „Falsche Wahl“ unverändert blieb (7 Fehler vor und nach KS).

\subsubsubsection{Vergleich der Fehlertypen auf Regel- und MÜ-Systemebene}

Eine genauere Untersuchung der Fehlertypen bei den verschiedenen MÜ-Sys\-te\-men zeigt (\figref{fig:05:39}), dass Fehlertyp SM.13 „Semantik -- Kollokationsfehler“ bei zwei Systemen sank (RBMÜ-System Lucy und HMÜ-System Systran) und bei drei Systemen vollständig behoben wurde (HMÜ- System Bing, NMÜ-System Google und SMÜ-System SDL).


\begin{figure}

%\includegraphics[height=.3\textheight]{figures/d3-img042.png}



%\includegraphics[height=.3\textheight]{figures/d3-img026.png}\\
\begin{tikzpicture}
\tikzset{every node/.style={font=\scriptsize}};
	\begin{axis}[
	xbar,
	width = \textwidth,
	height = .83\textheight,
	axis lines* = left,
	xlabel = {Summe},
	ytick = {1,2,3,...,14},
	yticklabels = {IN\_LX\_3.v,
	IN\_LX\_3.n,
	IN\_LX\_4.v,
	IN\_LX\_4.n,
	IN\_GR\_8.v,
	IN\_GR\_8.n,
	IN\_GR\_10.v,
	IN\_GR\_10.n,
	IN\_SM\_11.v,
	IN\_SM\_11.n,
	IN\_SM\_12.v,
	IN\_SM\_12.n,
	IN\_SM\_13.v,
	IN\_SM\_13.n
	},
%	x tick label style={rotate=60,anchor=east,font=\scriptsize},
	enlarge y limits={.032},
	xmin=0,
	xmax = 20,
%	bar shift = 1pt,
  	bar width=3,
	nodes near coords,
	legend pos = south east,
	reverse legend,
%	legend style={at={(0.5,-0.1)},anchor=north},
%	legend columns = {-1},
	]
	\addplot+[tmnlpone]
	coordinates {
	(3,1)
	(2,2)
	(0,3)
	(2,4)
	(0,5)
	(3,6)
	(4,7)
	(3,8)
	(2,9)
	(0,10)
	(1,11)
	(0,12)
	(5,13)
	(0,14)
	};
	\addplot+[lsLightOrange]
	coordinates {
	(0,1)
	(0,2)
	(0,3)
	(0,4)
	(1,5)
	(1,6)
	(0,7)
	(0,8)
	(0,9)
	(0,10)
	(0,11)
	(0,12)
	(2,13)
	(0,14)
	};
	\addplot+[smGreen]
	coordinates {
	(0,1)
	(0,2)
	(1,3)
	(0,4)
	(2,5)
	(1,6)
	(2,7)
	(1,8)
	(3,9)
	(3,10)
	(3,11)
	(2,12)
	(10,13)
	(1,14)
	};
	\addplot+[tmnlpthree]
	coordinates {
	(1,1)
	(1,2)
	(6,3)
	(0,4)
	(2,5)
	(1,6)
	(5,7)
	(3,8)
	(1,9)
	(2,10)
	(3,11)
	(3,12)
	(5,13)
	(0,14)
	};
	\addplot+[lsRed]
	coordinates {
	(0,1)
	(0,2)
	(0,3)
	(0,4)
	(0,5)
	(0,6)
	(2,7)
	(3,8)
	(5,9)
	(4,10)
	(0,11)
	(2,12)
	(16,13)
	(1,14)
	};
	\legend{Bing,Google,Lucy,SDL,Systran}
	\end{axis}
\end{tikzpicture}

\caption{\label{fig:05:39}„FVG verm.“ -- Summe der Fehleranzahl der Fehlertypen vor vs. nach KS bei den einzelnen MÜ-Systemen   }
\bspnote{*Die Balken zeigen die Summe der Fehleranzahl bei jedem Fehlertyp, wobei „v“ für die Summe „vor der Anwendung der KS-Regel“ und „n“ für die Summe „nach der Anwendung der KS-Regel“ steht. Jeder Fehlertyp wird erst für alle Systeme für das Szenario „vor KS“ abgebildet, danach folgt derselbe Fehlertyp wieder für alle Systeme für das Szenario „nach KS“.

**Um die Übersichtlichkeit und Lesbarkeit der Grafik zu erhöhen, wurden in der Grafik die Fehlertypen ausgeblendet, die 0 oder nur einmal bei \textit{allen} MÜ-Systemen vorkamen: In dieser Grafik kamen die Fehlertypen 1, 2 und 6 bei gar keinem MÜ-System vor. Zudem kamen die Fehlertypen 5, 7 und 9 nur einmal jeweils bei 1 bis 3 MÜ-Systemen in vereinzelten Fällen vor.}
\end{figure}

Nur bei dem RBMÜ-System Lucy (ein Rückgang von 10 auf 1 Fehler ($-$~90~\%)) und dem HMÜ-System Systran (ein Rückgang von 16 auf 1 Fehler ($-$~93,8~\%)) erwies sich die Differenz bei dem SM.13 Kollokationsfehler als signifikant.


\begin{table}
\begin{tabularx}{.87\textwidth}{lrlll}
\lsptoprule
& \textbf{N} & \textbf{Mittelwert} & \textbf{Standard-} & { \textbf{Signifikanz}}\\
& & & \textbf{abweichung} & \textbf{(McNemar-Test)}\\
\midrule
\multicolumn{5}{l}{\textbf{SM.13 „Kollokationsfehler“}}\\
 \textbf{Lucy} & 24 & vor KS = ,42 & vor KS = ,504 & p = ,004\\
& & nach KS = ,04 & nach KS = ,204 &\\
 \textbf{Systran} & 24 & vor KS = ,67 & vor KS = ,637 & p < ,001\\
& & nach KS = ,04 & nach KS = ,204 &\\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:32} „FVG verm.“ -- Fehlertypen mit signifikanter Veränderung nach KS  }
\end{table}

\tabref{tabex:05:25} zeigt den bei dem RBMÜ-System Lucy aufgetretenen Kollokationsfehler im Falle der Verwendung des Funktionsverbgefüges und wie er nach der Verwendung des bedeutungstragenden Verbs vermieden wurde.


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule
\textbf{Vor-KS} & Wird diese Regel nicht beachtet, kann der Motor \textbf{Schaden nehmen}. \\
\tablevspace
RBMÜ Lucy & If this rule is not observed, the motor can \txred{take damage}.\\
\midrule
\textbf{Nach-KS} & Wird diese Regel nicht beachtet, kann der Motor \textbf{beschädigt werden}.\\
\tablevspace
RBMÜ Lucy & If this rule is not observed, the motor can \txblue{be damaged}.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:25}  Beispiel 25 }
\bspnote{ Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

Wie \figref{fig:05:39} zeigt, gab es bei dem zweiten HMÜ-System (Bing) sowie bei dem SMÜ-System SDL bei mehreren Fehlertypen eine kleine Fehleranzahl. Schließlich war bei dem NMÜ-System Google Translate die Fehleranzahl im Allgemeinen sehr gering (insgesamt 3 Fehler vor KS und 1 Fehler nach KS), wie die Analyse der Fehleranzahl (\figref{fig:05:35}) zeigt.



\subsubsection{\label{sec:5.3.2.4}Vergleich der MÜ-Qualität mit vs. ohne Funktionsverbgefüge sowie die Korrelation zwischen den Fehlertypen und der Qualität}

Sowohl die Stil- als auch die Inhaltsqualität\footnote{\textrm{Definitionen der Qualität unter \sectref{sec:4.4.5.1}.}} stiegen nach der Vermeidung von Funktionsverbgefügen. Auf den ersten Blick erkennt man in \figref{fig:05:41}, dass der Einfluss auf die Stilqualität größer als der auf die Inhaltsqualität war. Die Übersetzung des Funktionsverbgefüges war in vielen Fällen mit dem semantischen Fehlertyp SM.13 „Kollokationsfehler“ verbunden (siehe \sectref{sec:5.3.2.3}). Nachdem das Funktionsverbgefüge vermieden wurde (nach KS), sank die Anzahl der Kollokationsfehler stark. Dies trug zu einer besseren Verständlichkeit (höhere Inhaltsqualität) und gleichzeitig zu einer deutlich natürlicheren Formulierung (höhere Stilqualität) bei.

Die Stilqualität verbesserte sich um 8,2~\% (Mv = 4,03 / SDv = ,583 / Mn = 4,36 / SDn = ,449 / N = 84). Die Inhaltsqualität erhöhte sich um 5,2~\% (Mv = 4,25 / SDv = ,792 / Mn = 4,47 / SDn = ,681 / N = 84), siehe \figref{fig:05:40}. Der Mittelwert der Differenz (nach KS $-$ vor KS) der vergebenen Qualitätspunkte pro Satz lag für die Stilqualität bei ,330 (SD = ,615) mit einem 95\%\nobreakdash-Konfidenzintervall zwischen einem Minimum von ,197 und einem Maximum von ,464 und für die Inhaltsqualität bei ,219 (SD = ,948) mit einem 95\%\nobreakdash-Konfidenzintervall zwischen einem Minimum von ,013 und einem Maximum von ,425 (Bootstrapping mit 1000 Stichproben), siehe \figref{fig:05:41}. Die Differenzen (nach KS $-$ vor KS) in der Stil- und Inhaltsqualität erwiesen sich als signifikant (z (N = 84) = $-$ 4,036 / p < ,001) bzw. (z (N = 84) = $-$ 2,180 / p = ,029).




%\includegraphics[height=.3\textheight]{figures/d3-img029.png}



%\includegraphics[height=.3\textheight]{figures/d3-img029.png}

%\textbf{4,324,62}

%\textbf{4,084,42}

%\textbf{3,904,15}

%\textbf{4,264,46}



%\includegraphics[height=.3\textheight]{figures/d3-img030.png} &  &
%\includegraphics[height=.3\textheight]{figures/d3-img017.png}




%\includegraphics[height=.3\textheight]{figures/d3-img017.png}




%\includegraphics[height=.3\textheight]{figures/d3-img017.png}\\

\begin{figure}
\captionsetup{width=.45\textwidth}
\begin{floatrow}
\ffigbox[.5\textwidth]{\caption{„FVG verm.“ -- Mittelwerte der Qualität vor und nach KS}\label{fig:05:40}}{
\includegraphics[width=.25\textwidth]{figures/Abb40.png}
\includegraphics[width=.2\textwidth]{figures/Abb15-legend.png}
}
\ffigbox[.5\textwidth]{\caption{„FVG verm.“ -- Mittelwert der Qualitätsdifferenzen}\label{fig:05:41}}{
\includegraphics[width=.25\textwidth]{figures/Abb16-legend.png}
\includegraphics[width=.45\textwidth]{figures/Abb41.png}
}
\end{floatrow}
\end{figure}


Wie unter \sectref{sec:5.3.2.1} dargestellt, waren die Funktionsverbgefüge der Gruppe Funktionsverb + Präpositionalphrase mit einem größeren Rückgang der Fehleranzahl (im Vergleich zu der Gruppe Funktionsverb + Nominalphrase) verbunden. Ebenfalls zeigte die Humanevaluation, dass das Vermeiden der Funktionsverbgefüge im Falle der Gruppe Funktionsverb + Präpositionalphrase zu einer stärkeren Qualitätsverbesserung beitrug (+~0,34 im Vergleich zu +~0,23 Qualitätsanstieg bei der Gruppe Funktionsverb + Nominalphrase) (\tabref{tab:05:33}).\footnote{\textrm{Die Qualitätsverbesserung bezieht sich hier auf die allgemeine Qualität, d. h. der Mittelwert der Stilqualität und der Inhaltsqualität.}}


\begin{table}
\begin{tabularx}{\textwidth}{Xrr}

\lsptoprule
& { \textbf{FVG}} & \textbf{FVG}\\
& \textbf{aus Funktionsverb +} & \textbf{aus Funktionsverb +}\\
&  \textbf{Präpositionalphrase} & \textbf{Nominalphrase}\\
\midrule
\textbf{Anzahl der Fälle} & 43 MÜ & 36 MÜ\\
\tablevspace
\textbf{Durchschnittliche Diff. der Allg. Q (nach KS $-$ vor KS)} & { +~0,34} & +~0,23\\
\lspbottomrule
\end{tabularx}\caption{\label{tab:05:33} Qualitätsdifferenz bei den untersuchten FVG-Formen  }
\end{table}


Durch die Humanevaluation wird ferner ersichtlich (\figref{fig:05:42}), dass alle Qualitätskriterien sich nach KS verbesserten (insbesondere die Verständlichkeit (CQ2) sowie alle Stilqualitätskriterien).


\begin{figure}


%\includegraphics[height=.3\textheight]{figures/d3-img043.png}

%\textbf{$-$ 44~\%}

%\textbf{$-$ 19~\%}

%\textbf{$-$ 23~\%}

%\textbf{$-$ 31~\%}

%\textbf{+~29~\%}

\pgfplotstableread{
1 14
2 18
3 105
4 72
5 379
6 291
7 194
8 158
9 142
10 79
}\datatable
\begin{tikzpicture}
%    \tikzset{every node/.style={font=\scriptsize}};
    \begin{axis}[ybar,
  %              ylabel = {Summe},
  %              ylabel style={yshift=-.2cm},
                enlarge x limits={.05},
                width  = \textwidth,
                height = .45\textheight,
                axis lines*=left,
                axis on top,
                bar width=8.5,
                bar shift=0pt,
                ymin = 0,
                ymax=400,
                xtick = {1,2,...,10},
                xticklabels={SQ1\_v,
                SQ1\_n,
                SQ2\_v,
                SQ2\_n,
                SQ3\_v,
                SQ3\_n,
                CQ1\_v,
                CQ1\_n,
                CQ2\_v,
                CQ2\_n},
            x tick label style={font=\small},
            nodes near coords,
 %           legend style={at={(0.5,-0.25)},anchor=north},
 %           legend columns={-1},
 	 extra description/.code={
	 \node at (axis cs:1.1,50)[anchor = west]{$+$ 29\%};
	 \node at (axis cs:3,150)[anchor = west]{$-$ 31\%};
	  \node at (axis cs:5.2,350)[anchor = west]{$-$ 23\%};
	   \node at (axis cs:7,240)[anchor = west]{$-$ 19\%};
	    \node at (axis cs:9.2,140)[anchor = west]{$-$ 44\%};
	  }
            ]
        \addplot +[shift={(.5,0)},tmnlpone,x filter/.code={\ifodd\coordindex\def\pgfmathresult{}\fi}] table {\datatable};
        \addplot +[shift={(-.5,0)},tmnlpthree,  x filter/.code={\ifodd\coordindex\relax\else\def\pgfmathresult{}\fi}] table {\datatable};
 %       \legend{vor KS,nach KS}
    \end{axis}
\end{tikzpicture}
\caption{\label{fig:05:42} „FVG verm.“ -- Vergleich der Qualitätskriterien  }
\bspnote{\textbf{SQ1:} Ü ist \textbf{\textit{nicht}} korrekt bzw. \textbf{\textit{nicht}} klar dargestellt, d. h. nicht orthografisch.\\
\textbf{SQ2:} Ü ist \textbf{\textit{nicht}} ideal für die Absicht des Satzes, d. h. motiviert den Nutzer \textbf{\textit{nicht}} zum Handeln, zieht \textbf{\textit{nicht} }seine Aufmerksamkeit an usw.\\
\textbf{SQ3:} Ü klingt \textbf{\textit{nicht} }natürlich bzw. \textbf{\textit{nicht} }idiomatisch.\\
\textbf{CQ1:} Ü gibt die Informationen im Ausgangstext \textbf{\textit{nicht}} exakt wieder.\\
\textbf{CQ2:} Ü ist \textbf{\textit{nicht}} leicht zu verstehen, d. h. \textbf{\textit{nicht}} gut formuliert bzw. dargestellt.}
\end{figure}

In \tabref{tabex:05:26} wurde der Kollokationsfehler in ‚does $\ldots$ be in the use‘ behoben, nachdem das Funktionsverbgefüge vermieden wurde (nach KS):


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule
\textbf{Vor-KS} & \textbf{Steht} die Maschine nicht \textbf{im Einsatz}, den Hauptschalter auf $"$0$"$ setzen.\\
\tablevspace
RBMÜ Lucy & If the machine \txred{does} not \txred{be~in the~use}, set the main switch to $"$0$"$.\\
\midrule
\textbf{Nach-KS} & \textbf{Wird} die Maschine nicht \textbf{verwendet}, den Hauptschalter auf $"$0$"$ setzen.\\
\tablevspace
RBMÜ Lucy & If the machine \txblue{is} not \txblue{used}, set the main switch to $"$0$"$.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:26} Beispiel 26  }
\bspnote{ Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

Daraufhin stiegen sowohl die Inhaltsqualität als auch die Stilqualität, wobei der Anstieg bei der Stilqualität höher war (SQdiff +~1,50 und CQdiff +~0,13 auf der Likert-Skala).


\subsubsubsection{Korrelation zwischen den Fehlertypen und der Qualität}

Auf Basis der Fehlerannotation zusammen mit der Humanevaluation gibt uns eine Spearman-Korrelationsanalyse Aufschluss, wie die Veränderung bei der Fehleranzahl bei jedem Fehlertyp (Anz. nach KS $-$ Anz. vor KS) mit den Qualitätsunterschieden (Q. nach KS $-$ Q. vor KS) zusammenhängt. Mithilfe des Spearman-Tests konnten mehrere signifikante Korrelationen nachgewiesen werden:

Bei der Stilqualität gab es einen signifikanten negativen mittleren Zusammenhang zwischen der Differenz in dem lexikalischen Fehlertyp LX.4 „Zusätzliches Wort eingefügt“ sowie dem semantischen Fehlertyp SM.11 „Verwechslung des Sinns“ und der Differenz in der Stilqualität; sowie einen signifikanten negativen schwachen Zusammenhang zwischen der Differenz im semantischen Fehlertyp SM.13 „Kollokationsfehler“ und der Differenz in der Stilqualität (\tabref{tab:05:34}).

Bei der Inhaltsqualität gab es einen signifikanten negativen mittleren Zusammenhang zwischen der Differenz im semantischen Fehlertyp SM.12 „Falsche Wahl“ und der Differenz in der Inhaltsqualität; sowie einen signifikanten negativen schwachen Zusammenhang zwischen der Differenz in den Fehlertypen LX.3 (Lexik -- Wort ausgelassen), LX.4 (Lexik -- Zusätzliches Wort eingefügt) sowie SM.13 (Semantik -- Kollokationsfehler) und der Differenz in der Inhaltsqualität (nächste \tabref{tab:05:34}).

Weitere Korrelationen zwischen anderen einzelnen Fehlertypen und der Qualität konnten nicht erwiesen werden.


\begin{table}
\begin{tabularx}{\textwidth}{Xrrr}

\lsptoprule
& \textbf{N} & \textbf{p}& \textbf{ρ}\\
\midrule
\textbf{Differenz SQ (nach KS $-$ vor KS)} &  &  &\\
Differenz der Anzahl der \textbf{LX.3 „W. fehlt“} & 84 & \txgray{ ,544} & { ,067}\\
Differenz der Anzahl der \textbf{LX.4 „W. extra“} & 84 & { ,005} & \txgreen{ $-$,306}\\
Differenz der Anzahl der \textbf{SM.11 „Sinn“} & 84 & { ,003} & \txgreen{ $-$,317}\\
Differenz der Anzahl der \textbf{SM.12 „f. Wahl“} & 84 & \txgray{ ,184} & { $-$,146}\\
Differenz der Anzahl der \textbf{SM.13 „Kollok.“} & 84 & { ,014} & { $-$,267}\\
\midrule
\textbf{Differenz CQ (nach KS $-$ vor KS)} &  &  & \\
Differenz der Anzahl der \textbf{LX.3 „W. fehlt“} & 84 & { ,008} & { $-$,286}\\
Differenz der Anzahl der \textbf{LX.4 „W. extra“} & 84 & { ,023} & { $-$,248}\\
Differenz der Anzahl der \textbf{SM.11 „Sinn“} & 84 & \txgray{ ,111} & { $-$,175}\\
Differenz der Anzahl der \textbf{SM.12 „f. Wahl“} & 84 & { < ,001} & \txgreen{ $-$,375}\\
Differenz der Anzahl der \textbf{SM.13 „Kollok.“} & 84 & { ,048} & { $-$,216}\\
\midrule
\textbf{Differenz allg. Q (nach KS $-$ vor KS)} &  &  & \\
Differenz der Anzahl der \textbf{LX.3 „W. fehlt“} & 84 & { ,023} & { $-$,248}\\
Differenz der Anzahl der \textbf{LX.4 „W. extra“} & 84 & { ,004} & \txgreen{ $-$,307}\\
Differenz der Anzahl der \textbf{SM.11 „Sinn“} & 84 & { ,016} & { $-$,262}\\
Differenz der Anzahl der \textbf{SM.12 „f. Wahl“} & 84 & { < ,001} & \txgreen{ $-$,385}\\
Differenz der Anzahl der \textbf{SM.13 „Kollok.“} & 84 & { ,027} & { $-$,242}\\

\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:34} „FVG verm.“ -- Korrelation zwischen den Fehlertypen und der Qualität  }
\bspnote{*In der Tabelle werden nur die Fehlertypen dargestellt, die mindestens mit einer Qualitätsvariable signifikant korrelieren.\\
\begin{tabbing}
p: Signifikanz\hspace{2.5cm} \= \txgray{nicht signifikant (p ${\geq}$ 0,05)}\hspace{.5cm} \= ρ: Korrelationskoeffizient\\
schwache Korrelation (ρ >=0,1)\> \txgreen{mittlere Korrelation (ρ >= 0,3)}\> \boxblue{starke Korrelation (ρ >= 0,5)}
\end{tabbing}}
\end{table}

Diese signifikanten negativen Korrelationen deuten darauf hin, dass sobald die Fehleranzahl der genannten Fehlertypen sank, die Qualität stieg. Ein Beispiel hierfür ist der folgende Satz (\tabref{tabex:05:27}).


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule
\textbf{Vor-KS} & Nach Ihrer Registrierung im Programm können Sie aus den Leistungen eine \textbf{Auswahl treffen}.\\
\tablevspace
SMÜ SDL & After your registration in the program, you can \txblue{select} from the services \txred{to make a selection}.\\
\midrule
\textbf{Nach-KS} & Nach Ihrer Registrierung im Programm können Sie aus den Leistungen \textbf{wählen}.\\
\tablevspace
SMÜ SDL & After your registration in the program, you can \txblue{select} from the services.\\
\lspbottomrule
\end{tabularx}\caption{\label{tabex:05:27}Beispiel 27   }
\bspnote{ Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

In diesem Beispiel kam bei der Verwendung des Funktionsverbgefüges der lexikalische Fehlertyp LX.4 „Zusätzliches Wort eingefügt“ in ‚to make a selection‘ vor. Bei einer Formulierung des Satzes mit dem bedeutungstragenden Verb wurde der Fehler behoben. Daraufhin stiegen die Stil- und Inhaltsqualität jeweils um 1,00 Punkte auf der Likert-Skala.

\subsubsubsection{Vergleich der Qualität auf Regel- und MÜ-Systemebene}

Auf MÜ-Systemebene stieg nach der Anwendung der KS-Regel nur die Stilqualität bei zwei Systemen signifikant (\tabref{tab:05:35}): bei dem RBMÜ-System Lucy (+~15,4~\%) und dem HMÜ-System Systran (+~13,8~\%). Alle weiteren Veränderungen in der Stil- und Inhaltsqualität waren bei allen Systemen niedrig.


\begin{figure}


\includegraphics[width=\textwidth]{figures/d3-img044.png}
%\includegraphics[height=.3\textheight]{figures/d3-img033.png}\\

\caption{\label{fig:05:43} „FVG verm.“ -- Mittelwerte der Qualität vor vs. nach KS bei den einzelnen MÜ-Systemen  }
\end{figure}


Wie die Aufteilung der Annotationsgruppen zeigte, waren 88~\% der Übersetzungen des NMÜ-Systems Google Translate sowohl vor als auch nach der Anwendung der KS-Regel richtig (Annotationsgruppe RR). Entsprechend ist zu erwarten, dass das Qualitätsniveau sich nicht verändert. Ebenfalls waren die Ergebnisse bei dem HMÜ-System Bing sowie dem SMÜ-System SDL vor und nach der Anwendung der KS-Regel hinsichtlich der Annotationsgruppen gemischt, daher konnte keine signifikante Veränderung in der Qualität festgestellt werden (\tabref{tab:05:35}).


\begin{table}
\begin{tabularx}{\textwidth}{Xrrrrrrrrr}

\lsptoprule
& \multicolumn{3}{c}{\textbf{Differenz SQ}} & \multicolumn{3}{c}{\textbf{Differenz CQ}} & \multicolumn{3}{c}{\textbf{Differenz allg. Q}}\\
&  \multicolumn{3}{c}{\textbf{(nach KS $-$ vor KS)}} &  \multicolumn{3}{c}{\textbf{(nach KS $-$ vor KS)}} & \multicolumn{3}{c}{\textbf{(nach KS $-$ vor KS)}}\\
\cmidrule(lr){2-4}\cmidrule(lr){5-7}\cmidrule(lr){8-10}
& \textbf{N} & \textbf{p} & \textbf{z} & \textbf{N} & \textbf{p} & \textbf{z} & \textbf{N} & \textbf{p} & \textbf{z}\\
\midrule
 \textbf{Bing} & 14 & \txgray{,431} & $-$ ,787 & 14 & \txgray{,362} & $-$,912 & 14 & \txgray{,248} & { $-$1,155}\\
 \textbf{Google} & 22 & \txgray{,392} & $-$,857 & 22 & \txgray{,946} & $-$,067 & 22 & \txgray{,536} & { $-$,618}\\
 \textbf{Lucy} & 18 & ,002 & $-$ 3,030 & 18 & \txgray{,143} & $-$1,463 & 18 & ,011 & { $-$ 2,534}\\
 \textbf{SDL} & 15 & \txgray{,055} & $-$1,920 & 15 & \txgray{,850} & $-$,189 & 15 & \txgray{,450} & { $-$,755}\\
 \textbf{Systran} & 15 & ,035 & $-$ 2,108 & 15 & \txgray{,064} & $-$1,855 & 15 & ,036 & { $-$ 2,102}\\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:35} „FVG verm.“ -- Signifikanz der Qualitätsveränderung bei den einzelnen MÜ-Systemen  }
\bspnote{p: Signifikanz\hspace{2.5cm} z: Teststatistik\hspace{2.5cm} \txgray{nicht signifikant (p ${\geq}$ 0,05)}}
\end{table}


\subsubsubsection{Korrelation zwischen den Fehlertypen und der Qualität auf Regel- und MÜ-Systemebene}

Anhand der Spearman-Korrelationsanalyse erwies sich bei dem HMÜ-System Bing nur ein signifikanter starker negativer Zusammenhang zwischen dem lexikalischen Fehlertyp LX.3 „Wort ausgelassen“ und der Inhaltsqualität (\tabref{tab:05:36}).

Bei dem RBMÜ-System Lucy erwies sich ein signifikanter starker negativer Zusammenhang zwischen dem semantischen Fehlertyp SM.11 „Verwechslung des Sinns“ und der Stilqualität; sowie ein signifikanter starker negativer Zusammenhang zwischen dem semantischen Fehlertyp SM.12 „Falsche Wahl“ und der Inhaltsqualität (\tabref{tab:05:36}).

Bei dem SMÜ-System SDL konnten mehrere signifikante Korrelationen nachgewiesen werden: Bei der Stilqualität gab es einen signifikanten negativen starken Zusammenhang zwischen der Differenz in den Fehlertypen LX.4 „Lexik -- Zusätzliches Wort eingefügt“ (vgl. \tabref{tabex:05:27}) und GR.10 „Grammatik -- Falsche Wortstellung“ einzeln und der Differenz in der Stilqualität (\tabref{tab:05:36}), während es bei der Inhaltsqualität einen signifikanten negativen starken Zusammenhang zwischen der Differenz in den Fehlertypen LX.4 „Lexik -- Zusätzliches Wort eingefügt“ und SM.12 „Semantik -- Falsche Wahl“ einzeln und der Differenz in der Inhaltsqualität gab (\tabref{tab:05:36}).

Bei dem HMÜ-System Systran erwies sich nur ein signifikanter starker negativer Zusammenhang zwischen dem grammatischen Fehlertyp GR.7 „Falsche Wortart / Wortklasse“ und der Inhaltsqualität (\tabref{tab:05:36}).


\begin{sidewaystable}
\scriptsize
\captionsetup{width=\textwidth}
\begin{tabularx}{\textwidth}{Xrrrrrrrrrrrr}

\lsptoprule
 & \multicolumn{3}{c}{\textbf{Bing}} &  \multicolumn{3}{c}{\textbf{Lucy}} & \multicolumn{3}{c}{\textbf{SDL}} & \multicolumn{3}{c}{\textbf{Systran}}\\
 \cmidrule(lr){2-4} \cmidrule(lr){5-7} \cmidrule(lr){8-10} \cmidrule(lr){11-13}
 & {\textbf{N}} & {\textbf{p}} & {\textbf{ρ}} & {\textbf{N}} & \textbf{p} & \textbf{ρ} & \textbf{N} & \textbf{p} & \textbf{ρ} & \textbf{N} & \textbf{p} & \textbf{ρ}\\
 \midrule
\multicolumn{13}{l}{\textbf{Differenz der Anzahl SQ} \textbf{(nach KS $-$ vor KS)}} \\
\textbf{LX.3 „W. fehlt“} & {14} & \cellcolor{lsLightGray}{,516} & {,190} &   &  &  &  &  &  &  &  &\\
\textbf{LX.4 „W. extra“} &  &  & &  &  &  & 15 & ,020 & \cellcolor{smBlue}  {$-$,594} &  &  & \\
\textbf{GR.7 „F. W.Art“} &  & &  &   &  &  &  &  &  & 21 & \cellcolor{lsLightGray} {,060} & $-$~,417\\
\textbf{GR.10 „Wortst.“} &  &  &  &   &  &  & 15 & ,010 & \cellcolor{smBlue} {$-$,641} &  &  & \\
\textbf{SM.11 „Sinn“} &  &  &  &  18 & ,027 & \cellcolor{smBlue} {$-$,521} &  &  &  &  &  & \\
\textbf{SM.12 „F. Wahl“} & &  &  &  18 & \cellcolor{lsLightGray} {,501} & $-$,169 & 15 & \cellcolor{lsLightGray} {,078} & $-$,468 &  &  & \\
\midrule
\multicolumn{13}{l}{\textbf{Differenz der Anzahl CQ} \textbf{(nach KS $-$ vor KS)}}\\
\textbf{LX.3 „W. fehlt“} & {14} & {,035} & \cellcolor{smBlue} {$-$,566} &   &  &  &  &  &  &  &  & \\
\textbf{LX.4 „W. extra“} &  &  &  &   &  &  & 15 & ,009 & \cellcolor{smBlue} {$-$,646} &  &  & \\
\textbf{GR.7 „F. W.Art“} &  &  &   &  &  &  &  &  &  & 21 & ,018 & \cellcolor{smBlue} {$-$,511}\\
\textbf{GR.10 „Wortst.“} &  & &  &   &  &  & 15 & \cellcolor{lsLightGray} {,295} & ,290 &  &  & \\
\textbf{SM.11 „Sinn“} &  &  &  &  18 & \cellcolor{lsLightGray} {,289} & $-$,264 &  &  &  &  &  & \\
\textbf{SM.12 „F. Wahl“} &  &  &  &  18 & ,021 & \cellcolor{smBlue} {$-$,537} & 15 & ,020 & \cellcolor{smBlue} {$-$,593} &  &  & \\
\midrule
\multicolumn{13}{l}{\textbf{Differenz der Anzahl Q} \textbf{(nach KS $-$ vor KS)}}\\
\textbf{LX.3 „W. fehlt“} & { 14} & \cellcolor{lsLightGray} {,110} & {$-$~,446} &   &  &  &  &  &  &  &  & \\
\textbf{LX.4 „W. extra“} &  &  &  &  &  &  & 15 & ,007 & \cellcolor{smBlue} {$-$,664} &  &  & \\
\textbf{GR.7 „F. W.Art“} &  &  &  &   &  &  &  &  &  & 21 & ,018 & \cellcolor{smBlue} {$-$,509}\\
\textbf{GR.10 „Wortst.“} &  &  &  &  &  &  & 15 & \cellcolor{lsLightGray} {,081} & $-$,465 &  &  & \\
\textbf{SM.11 „Sinn“} &  &  &  &  18 & \cellcolor{lsLightGray} {,053} & $-$,463 &  &  &  &  &  & \\
\textbf{SM.12 „F. Wahl“} & & &  &  18 & ,014 & \cellcolor{smBlue} {$-$,567} & 15 & ,020 & \cellcolor{lsLightGray} {$-$,594} &  &  & \\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:36}„FVG verm.“ -- Korrelationen zwischen den Fehlertypen und der Qualität bei den einzelnen MÜ-Systemen}
\bspnote{*In der Tabelle werden nur die Fehlertypen dargestellt, die mindestens mit einer Qualitätsvariable signifikant korrelieren.
\vspace{-8pt}
\begin{tabbing}
p: Signifikanz\hspace{2.5cm} \= \txgray{nicht signifikant (p ${\geq}$ 0,05)}\hspace{1cm} \= ρ: Korrelationskoeffizient\\
schwache Korrelation (ρ >=0,1)\> \txgreen{mittlere Korrelation (ρ >= 0,3)}\> \boxblue{starke Korrelation (ρ >= 0,5)}
\end{tabbing}}
\end{sidewaystable}

Die Korrelation zwischen der Qualitätsdifferenz und der Fehleranzahldifferenz lässt sich anhand \tabref{tabex:05:28} beleuchten: Der semantische Fehlertyp SM.12 in ‚suits in‘ wurde eliminiert, nachdem das bedeutungstragende Verb anstelle des Funktionsverbgefüges verwendet wurde. Daraufhin stiegen deutlich die Stilqualität um 1,38 Punkte und die Inhaltsqualität um 1,88 Punkte auf der Likert-Skala.


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & Es \textbf{liegt in der Verantwortung} des Planers, aufeinander abgestimmte Produkte einzusetzen. \\
\tablevspace
RBMÜ Lucy & It \txred{suits in} \txblue{the responsibility} of the planner to use compatible products.\\
\midrule
\textbf{Nach-KS} & Der Planer \textbf{ist dafür verantwortlich}, aufeinander abgestimmte Produkte einzusetzen. \\
\tablevspace
RBMÜ Lucy & The planner \txblue{is responsible for} using compatible products.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:28} Beispiel 28   }
\bspnote{ Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

Die Bewerter fanden den semantischen Fehler (in ‚suits in‘) irreführend. Einer der Kommentare lautete: „The reader will have no idea what ‘suits in the responsibility of the planner’ means. The text therefore fails in its informative function. Using ‘suits’ can be confusing. I would therefore write: ‘It is the responsibility of the planner \dots’“

\subsubsection{\label{sec:5.3.2.5}Vergleich der MÜ-Qualität mit vs. ohne Funktionsverbgefüge auf Annotationsgruppenebene}

Mit Ausnahme der Gruppe FR fiel die Differenz in der Stil- und Inhaltsqualität\footnote{\textrm{Definitionen der Qualität unter \sectref{sec:4.4.5.1}.}} (nach KS $-$ vor KS) bei allen anderen Annotationsgruppen gering aus.


\begin{figure}
\includegraphics[width=\textwidth]{figures/d3-img045.png}
%\includegraphics[height=.3\textheight]{figures/d3-img035.png}\\
\caption{\label{fig:05:44} „FVG verm.“ -- Mittelwerte der Qualität vor vs. nach KS auf Annotationsgruppenebene  }
\end{figure}

In der Gruppe FF (Übersetzung vor und nach KS falsch) wurden die vor KS vorgekommenen Fehler -- vor allem die semantischen Fehler -- in vereinzelten Fällen nach der Anwendung der KS-Regel \textit{zum Teil} eliminiert. Daher stieg die Qualität durchschnittlich nur leicht, demzufolge war die Differenz in der Qualität insignifikant (\tabref{tab:05:37}).


\begin{table}
\begin{tabularx}{\textwidth}{Xrrr}

\lsptoprule
& \textbf{N} & { \textbf{p}} & { \textbf{Z} }\\
& & \textbf{(Signifikanz)} & \textbf{(Teststatistik)}\\
\midrule
{\textbf{Annotationsgruppe FF}} & {} & {} & \\
\textbf{Differenz SQ (nach KS $-$ vor KS)} & 17 & \txgray{,420} & $-$,807\\
\textbf{Differenz CQ (nach KS $-$ vor KS)} & 17 & \txgray{,636} & $-$,474\\
\textbf{Differenz allg. Q (nach KS $-$ vor KS)} & 17 & \txgray{,421} & $-$,805\\
\midrule
{\textbf{Annotationsgruppe FR}} & {} & {} & \\
\textbf{Differenz SQ (nach KS $-$ vor KS)} & 25 & < ,001 & $-$ 4,205\\
  \textbf{Differenz CQ (nach KS $-$ vor KS)} & 25 & < ,001 & $-$ 3,884\\
\textbf{Differenz allg. Q (nach KS $-$ vor KS)} & 25 & < ,001 & $-$ 4,043\\
\midrule
{\textbf{Annotationsgruppe RF}} & {} & {} & \\
\textbf{Differenz SQ (nach KS $-$ vor KS)} & 7 & \txgray{,416} & ,813\\
  \textbf{Differenz CQ (nach KS $-$ vor KS)} & 7 & \txgray{,107} & $-$1,612\\
\textbf{Differenz allg. Q (nach KS $-$ vor KS)} & 7 & \txgray{,058} & $-$1,892\\
\midrule
{\textbf{Annotationsgruppe RR}} & {} & {} & \\
\textbf{Differenz SQ (nach KS $-$ vor KS)} & 35 & \txgray{,140} & $-$1,477\\
  \textbf{Differenz CQ (nach KS $-$ vor KS)} & 35 & \txgray{,926} & $-$,093\\
   \textbf{Differenz allg. Q (nach KS $-$ vor KS)} & 35 & \txgray{,190} & $-$1,312\\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:37} „FVG verm.“ -- Signifikanz der Qualitätsveränderung auf Annotationsgruppenebene  }
\end{table}

In der Gruppe FR stiegen die Stil- und Inhaltsqualität erwartungsgemäß hochsignifikant (\tabref{tab:05:37}): bei der Stilqualität (z (N = 25) = $-$ 4,205 / p < ,001) bzw. bei der Inhaltsqualität (z (N = 25) = $-$ 3,884/ p < ,001). Durch die Aufhebung der semantischen Fehler (meist SM.13 Kollokationsfehler), die mit der Verwendung des Funktionsverbgefüges verbunden sind, stiegen die Verständlichkeit und Genauigkeit sowie die Idiomatik und stilistische Adäquatheit\footnote{\textrm{Stilistische Adäquatheit im Sinne von \citet[163]{HutchinsSomers1992} „the extent to which the translation uses the language appropriate to its content and intention”. Mehr zu den Definitionen der Qualität unter \sectref{sec:4.4.5.1}.}} der MÜ deutlich. In \tabref{tabex:05:29} war der Anstieg relativ markant und betrug bei der Stilqualität 1,38 Punkte bzw. bei der Inhaltsqualität 2,88 Punkte auf der Likert-Skala.


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule
\textbf{Vor-KS} & Der Bediener darf erst die Maschine \textbf{in Betrieb nehmen}, wenn er die Betriebsanleitung gelesen hat.\\
\tablevspace
HMÜ Systran & The operator may only \txred{take} the machine \txred{in enterprise} after reading the operating instructions.\\
\midrule
\textbf{Nach-KS} & Der Bediener darf erst die Maschine \textbf{starten}, wenn er die Betriebsanleitung gelesen hat.\\
\tablevspace
HMÜ Systran & The operator may only \txblue{start} the machine after reading the operating instructions.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:29} Beispiel 29  }
\bspnote{ Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

In einem weiteren Satz (\tabref{tabex:05:30}) konnte das MÜ-System (vor KS) das Kompositum ‚Fleckenbehandlung‘, aus dem das Funktionsverbgefüge zum Teil besteht, richtig übersetzen. Allerdings beinhaltete die Übersetzung einen Kollokationsfehler (in ‚treatment \ldots accomplished‘), der nach der Verwendung des bedeutungstragenden Verbs ‚behandeln‘ (nach KS) behoben werden konnte.


\begin{table}
\begin{tabularx}{\textwidth}{lX}
\lsptoprule
\textbf{Vor-KS} & Die Fleck\textbf{behandlung} muss so schnell wie möglich \textbf{durchgeführt} werden.\\
\tablevspace
HMÜ Systran & The stain \txblue{treatment} should be \txred{accomplished} as soon as possible.\\
\midrule
\textbf{Nach-KS} & Die Fleck\textbf{en} müssen so schnell wie möglich \textbf{behandelt} werden.\\
\tablevspace
HMÜ Systran & The stains should be \txblue{treated} as soon as possible.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:30} Beispiel 30   }
\bspnote{ Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

In der Gruppe RF war die Anzahl der vorgekommenen Fälle relativ klein (8~\%). In dieser Gruppe wurde das Funktionsverbgefüge (vor KS) richtig übersetzt, während das bedeutungstragende Verb aus unterschiedlichen Gründen falsch übersetzt wurde. Folgender Satz ist ein Beispiel für solche Fälle, bei denen die Stilqualität um 0,25 Punkte bzw. die Inhaltsqualität um 0,63 Punkte auf der Likert-Skala zurückgingen (\tabref{tabex:05:31}).


\begin{table}
\begin{tabularx}{\textwidth}{lX}
\lsptoprule
\textbf{Vor-KS} & \textbf{Die \txred{Abwicklung} von Garantieleistungen \txred{erfolgt} über die lokale Service-Hotline.}\\
\tablevspace
SMÜ SDL & \textcolor{tmnlpthree}{Handling} of warranty services \txblue{is effected} by the local service hotline.\\
\midrule
\textbf{Nach-KS} & \textbf{Die Garantieleistungen \txred{werden} über die lokale Service-Hotline \txred{abgewickelt}.}\\
\tablevspace
SMÜ SDL & The warranty services \txblue{are} \txred{XXX} by the local service hotline.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:31} Beispiel 31   }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens; \txred{XXX} für ein fehlendes Wort oder Komma.}
\end{table}

In der Gruppe RR (Übersetzung vor und nach KS richtig) war die Inhaltsqualität vor und nach der Anwendung der KS-Regel vergleichbar. Auf der anderen Seite stieg die Stilqualität in manchen Fällen, da die Übersetzung des bedeutungstragenden Verbs von den Bewertern als prägnanter wahrgenommen wurde. In \tabref{tabex:05:32} blieb die Inhaltsqualität unverändert, während die Stilqualität um 1,13 Punkte auf der Likert-Skala stieg.


\begin{table}
\begin{tabularx}{\textwidth}{lX}
\lsptoprule
\textbf{Vor-KS} & Die Höhen\textbf{verstellung} der Fronten können Sie mittels eines Schraubendrehers \textbf{vornehmen}.\\
\tablevspace
HMÜ Systran & You can \txblue{make} the height \txblue{adjustment} of the fronts using a screwdriver.\\
\midrule
\textbf{Nach-KS} & Die \textbf{Höhe} der Fronten können Sie mittels eines Schraubendrehers \textbf{verstellen}.\\
\tablevspace
HMÜ Systran & You can \txblue{adjust} the height of the fronts using a screwdriver.\\
\lspbottomrule
\end{tabularx}\caption{\label{tabex:05:32}Beispiel 32   }
\bspnote{ Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

\subsubsection{\label{sec:5.3.2.6}Vergleich der AEM-Scores mit vs. ohne Funktionsverbgefüge sowie die Korrelation zwischen den AEM-Scores und der Qualität}

Der Vergleich der AEM-Scores mit und ohne Funktionsverbgefüge zeigte sowohl mit TERbase als auch mit hLEPOR eine Verbesserung der AEM-Scores.


\begin{figure}
%\includegraphics[height=.3\textheight]{figures/d3-img022.png}

%\includegraphics[height=.3\textheight]{figures/d3-img022.png}

%\includegraphics[height=.3\textheight]{figures/d3-img022.png}\\
\includegraphics[width=.4\textwidth]{figures/Abb45.png}
\includegraphics[width=.35\textwidth]{figures/Abb19-legend.png}
\caption{\label{fig:05:45}   „FVG verm.“ -- Mittelwert der Differenz der AEM-Scores}
\bspnote{Differenz = AEM-Score nach KS \textit{minus} AEM-Score vor KS}
\end{figure}

Der Mittelwert der Differenz (nach KS $-$ vor KS) im AEM-Score pro Satz lag für TERbase bei ,126 (SD = ,244) und für die hLEPOR bei ,048 (SD = ,151) mit einem 95\%\nobreakdash-Konfidenzintervall (Bootstrapping mit 1000 Stichproben). Die Differenzen (nach KS $-$ vor KS) in TERbase und hLEPOR erwiesen sich als signifikant (z (N = 85) = $-$ 4,353 / p < ,001) bzw. (z (N = 85) = $-$ 2,975 / p = ,003). Dieses Ergebnis weist darauf hin, dass -- nachdem das Funktionsverbgefüge vermieden wurde (nach KS) –weniger Edits erforderlich waren.

\subsubsubsection{Korrelation zwischen den Differenzen in den AEM-Scores und der Qualität}

Mithilfe des Spearman-Korrelationstests erwies sich ein signifikanter starker positiver Zusammenhang zwischen den Differenzen der AEM-Scores von TERbase und hLEPOR und der Differenz der allgemeinen Qualität. \tabref{tab:05:38} präsentiert die Korrelationswerte:


\begin{table}
\begin{tabularx}{\textwidth}{Xrrrr}
\lsptoprule
& \textbf{N} & { \textbf{Signifikanz} } &\textbf{Korrelations-} & \textbf{Stärke}\\
& & \textbf{(p)} & \textbf{koeffizient} & \textbf{der}\\
&&& \textbf{(ρ)} &   \textbf{Korrelation}\\
\midrule
Korrelation zw. Differenz in der allg. Qualität und Differenz des TERbase-Scores (nach KS $-$ vor KS) & { 84} & < ,001 & ,503 & \makecell[tr]{starker\\Zusammen-\\hang}\\
\tablevspace
Korrelation zw. Differenz in der allg. Qualität und Differenz des hLEPOR-Scores (nach KS $-$ vor KS) & { 84} & < ,001 & ,510 & \makecell[tr]{starker\\Zusammen-\\hang}\\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:38}„FVG verm.“ -- Korrelation zwischen den Differenzen der AEM-Scores und den Qualitätsdifferenzen}
\bspnote{schwache Korrelation (ρ >=0,1)\hspace{1em} mittlere Korrelation (ρ >= 0,3)\hspace{1em} starke Korrelation (ρ >= 0,5)}
\end{table}

Dieses Ergebnis deutet darauf hin, dass -- nachdem das bedeutungstragende Verb anstelle des Funktionsverbgefüges verwendet wurde -- die Scores der beiden AEMs sich verbesserten und die Qualität stieg.

\subsubsection{\label{sec:5.3.2.7}Analyse der zweiten Regel -- Validierung der Hypothesen}

Um die vorgestellten Ergebnisse auf die Forschungsfragen der Studie zurückzuführen, listet dieser Abschnitt die zugrunde liegenden Hypothesen der Forschungsfragen zusammen mit einer Zusammenfassung der Ergebnisse der zweiten analysierten Regel in tabellarischer Form auf. Für einen schnelleren Überblick steht (+) für eine Verbesserung bzw. einen Anstieg z.~B. im Sinne eines Qualitätsanstiegs, verbesserter AEM-Scores oder eines Anstiegs der Fehleranzahl; ($-$) steht für einen Rückgang; die \txgreen{grüne} Farbe symbolisiert eine signifikante Veränderung; \textit{neg} steht für eine negative Korrelation und \textit{pos} für eine positive Korrelation; <{}<{}>{}> steht für eine starke Korrelation und <> für eine mittlere Korrelation.\footnote{\textrm{Schwache Korrelationen werden in dieser Übersicht nicht angezeigt.}}

\subsubsubsection*{\textbf{Regel 2: Funktionsverbgefüge vermeiden}}

\paragraph*{Erster Analysefaktor: Vergleich der Fehleranzahl mit vs. ohne Funktionsverbgefüge}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Gibt es einen Unterschied in der Fehleranzahl nach der Anwendung der KS-Regel im Vergleich zu vor der Anwendung?
\item [H0 --] Es gibt keinen Unterschied in der Fehleranzahl vor vs. nach der Anwendung der KS-Regel.
\item [H1 --] Es gibt einen Unterschied in der Fehleranzahl vor vs. nach der Anwendung der KS-Regel.
\item [Resultat]
\end{description}
\noindent
\parbox[t]{.8\textwidth}{\textbf{Auf Regelebene:}}\\
\noindent
\parbox[t]{.8\textwidth}{
H0 wurde abgelehnt und somit H1 bestätigt.

Die Fehleranzahl sank signifikant, nachdem das Funktionsverbgefüge vermieden wurde.}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.15\textwidth}{\textbf{Anz.F.} \textbf{($-$)}\\
\\
}}

\noindent
\parbox[t]{.8\textwidth}{\textbf{Auf Regel- und MÜ-Systemebene:}

Bei Lucy, SDL und Systran sank die Fehleranzahl signifikant, nachdem das Funktionsverbgefüge vermieden wurde.}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.15\textwidth}{\textbf{Lu ($-$)}

\textbf{SD ($-$)}

 \textbf{Sy ($-$)}}}

\medskip
 \noindent
 \parbox[t]{.8\textwidth}{Bei Bing und Google sank ebenfalls die Fehleranzahl, jedoch war der Rückgang nicht signifikant.}
 \parbox[t]{.04\textwidth}{}
 \parbox[t]{.15\textwidth}{\textbf{Bi ($-$)}

 \textbf{Go ($-$)}\vspace{11pt}}
\hrule
\paragraph*{Zweiter Analysefaktor}\hfill\\
\begin{figure}[H]
% 36
\torte{25}{35}{10}{50}

\caption{Aufteilung der Annotationsgruppen auf Regelebene }
\end{figure}

\begin{figure}[H]

\begin{tikzpicture}
\tikzset{every node/.style={font=\scriptsize}};
	\begin{axis}[
	ybar,
	width = \textwidth,
  height = .5\textheight,
	axis lines* = left,
	ylabel = {\%},
	xtick = {3,9,15,21},
	xticklabels = {FF,FR,RF,RR},
	x tick label style ={yshift=-5pt},
% 	xtick=data,
%	x=12pt,
	enlarge x limits={.15},
	ymin=0,
	ymax = 20,
  y filter/.code={\pgfmathparse{#1/120*100}\pgfmathresult},
%	bar shift = 0pt,
%  	bar width=9,
%	nodes near coords,
%	legend pos= north east,
	legend style={at={(0.5,-0.1)},anchor=north},
	legend columns = {-1},
	]
	\addplot+[lsNightBlue]
	coordinates {
	(3,6)
	(9,6)
	(15,1)
	(21,11)
	};
	\addplot+[tmnlpone]
	coordinates {
	(3,1)
	(9,2)
	(15,0)
	(21,21)
	};
	\addplot+[tmnlptwo]
	coordinates {
	(3,5)
	(9,10)
	(15,3)
	(21,6)
	};
	\addplot+[tmnlpthree]
	coordinates {
	(3,6)
	(9,7)
	(15,3)
	(21,8)
	};
	\addplot+[tmnlpfour]
	coordinates {
	(3,7)
	(9,10)
	(15,3)
	(21,4)
	};
	\legend{Bing,Google,Lucy,SDL,Systran}
	\end{axis}
\end{tikzpicture}

\caption{Aufteilung der Annotationsgruppen auf Regel- und MÜ-Systemebene   }
\end{figure}
\hrule
\newpage
\paragraph*{Dritter Analysefaktor: Vergleich der Fehlertypen mit vs. ohne Funktionsverbgefüge}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Beinhaltet die MÜ bestimmte Fehlertypen vor bzw. nach der Anwendung der KS-Regel?
\item [H0 --] Es gibt keinen Unterschied in der Häufigkeit der einzelnen Fehlertypen vor vs. nach der Anwendung der KS-Regel.
\item [H1 --] Es gibt einen Unterschied in der Häufigkeit der einzelnen Fehlertypen vor vs. nach der Anwendung der KS-Regel.
\item [Resultat]
\end{description}
\noindent
\parbox[t]{.8\textwidth}{\textbf{Auf Regelebene:}}\\
\noindent
\parbox[t]{.8\textwidth}{
H1 wurde nur für einen Fehlertyp bestätigt.

Die Fehleranzahl von SM.13 „Kollokationsfehler“ sank signifikant, nachdem das Funktionsverbgefüge vermieden wurde.}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.15\textwidth}{\textbf{SM.13 ($-$)}\\
\\
}}

\noindent
\parbox[t]{.8\textwidth}{\textbf{Auf Regel- und MÜ-Systemebene:}}\\
\noindent
\parbox[t]{.8\textwidth}{
Bei Lucy und Systran sank die Fehleranzahl von SM.13 „Kollokationsfehler“ signifikant, nachdem das Funktionsverbgefüge vermieden wurde.}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.15\textwidth}{\textbf{SM.13 ($-$):}

{ \textbf{Lu}}

{ \textbf{Sy}}}}

\medskip
\noindent
\parbox[t]{.8\textwidth}{Alle weiteren Veränderungen waren nicht signifikant.}
\hrule
\paragraph*{Vierter Analysefaktor: Vergleich der MÜ-Qualität mit vs. ohne Funktionsverbgefüge}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Gibt es einen Unterschied in der Stil- und Inhaltsqualität der MÜ der KS-Stelle nach der Anwendung der KS-Regel im Vergleich zu vor der Anwendung?
\item [H0 --] Es gibt keinen Qualitätsunterschied vor vs. nach der Anwendung der KS-Regel.
\item [H1 --] Es gibt einen Qualitätsunterschied vor vs. nach der Anwendung der KS-Regel.
\item [Resultat]
\end{description}
\noindent
\parbox[t]{.8\textwidth}{\textbf{Auf Regelebene:}}\\
\noindent
\parbox[t]{.8\textwidth}{
H0 wurde abgelehnt und somit H1 bestätigt.

Sowohl die Stil- als auch die Inhaltsqualität stiegen nach KS signifikant.}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.15\textwidth}{\textbf{SQ (+)}

 \textbf{CQ (+)}\\
 }}

\noindent
\parbox[t]{.8\textwidth}{\textbf{Auf Regel- und MÜ-Systemebene:}

 Nur die Stilqualität stieg bei Lucy und Systran signifikant.}
 \parbox[t]{.04\textwidth}{}
 \colorbox{smGreen}{\parbox[t]{.15\textwidth}{\textbf{SQ (+)}

 { \textbf{Lu}} { \textbf{Sy}}}}

\medskip
 \noindent
 \parbox[t]{.8\textwidth}{Die Stilqualität stieg bei allen anderen Systemen, allerdings nicht signifikant.

Die Inhaltsqualität stieg bei allen Systemen -- mit Ausnahme von Google Translate -- nicht signifikant. Bei Google Translate sank sie leicht.}
\medskip
\hrule
\paragraph*{Fünfter Analysefaktor: Korrelation zwischen den Fehlertypen und der Qualität}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Besteht ein Zusammenhang zwischen der Differenz der Fehleranzahl eines bestimmten Fehlertyps (Fehleranzahl nach KS $-$ vor KS) und der Differenz der Stil- bzw. Inhaltsqualität (Qualität nach KS $-$ vor KS)?
\item [H0 --] Es besteht kein Zusammenhang zwischen der Differenz der Fehleranzahl eines bestimmten Fehlertyps und der Differenz der Stil- bzw. Inhaltsqualität.
\item [H1 --] Es besteht ein Zusammenhang zwischen der Differenz der Fehleranzahl eines bestimmten Fehlertyps und der Differenz der Stil- bzw. Inhaltsqualität.
\item [Resultat]
\end{description}
\noindent
\parbox[t]{.7\textwidth}{\textbf{Auf Regelebene:}}\\
\noindent
\parbox[t]{.7\textwidth}{
H1 wurde nur für drei Fehlertypen wie folgt bestätigt:

Es bestand ein signifikanter mittlerer negativer Zusammenhang zwischen der Differenz der Fehleranzahl des LX.4 „Zusätzliches Wort eingefügt“ und des SM.11 „Verwechslung des Sinns“ einzeln und der Differenz der Stilqualität sowie ein signifikanter mittlerer negativer Zusammenhang zwischen der Differenz der Fehleranzahl des SM.12 „Falsche Wahl“ und der Differenz der Inhaltsqualität.}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.25\textwidth}{\textbf{\textit{neg}} \textbf{LX.4 <> SQ}

\textbf{\textit{neg}} \textbf{SM.11 <> SQ}

\textbf{\textit{neg}} \textbf{SM.12 <> CQ}\vspace{79pt}}}

\noindent
\parbox[t]{.7\textwidth}{\textbf{Auf Regel- und MÜ-Systemebene:}}\\
\noindent
\parbox[t]{.7\textwidth}{
Bei Bing bestand ein signifikanter starker negativer Zusammenhang zwischen der Differenz der Fehleranzahl des LX.3 „Wort ausgelassen“ und der Differenz der Inhaltsqualität.}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.25\textwidth}{\textbf{Bi}

 \textbf{\textit{neg}} \textbf{LX.3 <{}<{}>{}> CQ}\vspace{29pt}}}

\medskip
 \noindent
 \parbox[t]{.7\textwidth}{Bei Lucy bestand ein signifikanter starker negativer Zusammenhang zwischen der Differenz der Fehleranzahl des SM.11 „Verwechslung des Sinns“ und der Differenz der Stilqualität
sowie ein signifikanter starker negativer Zusammenhang zwischen der Differenz der Fehleranzahl des Fehlertyps 12 „SM -- Falsche Wahl“ und der Differenz der Inhaltsqualität.}
 \parbox[t]{.04\textwidth}{}
 \colorbox{smGreen}{\parbox[t]{.25\textwidth}{\textbf{Lu}

 { \textbf{\textit{neg}} \textbf{SM.11 <{}<{}>{}> SQ}}

  \textbf{\textit{neg}} \textbf{SM.12 <{}<{}>{}> CQ}\vspace{52pt}}}

  \medskip
   \noindent
   \parbox[t]{.7\textwidth}{Bei SDL bestand ein signifikanter starker negativer Zusammenhang zwischen der Differenz der Fehleranzahl des LX.4 „Zusätzliches Wort eingefügt“ und des GR.10 „Falsche Wortstellung“ einzeln und der Differenz der Stilqualität sowie ein signifikanter starker negativer Zusammenhang zwischen der Differenz der Fehleranzahl des LX.4 „Zusätzliches Wort eingefügt“ und des SM.12 „Falsche Wahl“ einzeln und der Differenz der Inhaltsqualität.}
   \parbox[t]{.04\textwidth}{}
   \colorbox{smGreen}{\parbox[t]{.25\textwidth}{\textbf{SD}

   { \textbf{\textit{neg}} \textbf{LX.4 <{}<{}>{}> SQ}}

   { \textbf{\textit{neg}} \textbf{GR.10 <{}<{}>{}> SQ}}

   { \textbf{\textit{neg}} \textbf{LX.4 <{}<{}>{}> CQ}}

    \textbf{\textit{neg}} \textbf{SM.12 <{}<{}>{}> CQ}\vspace{42pt}}}

    \medskip
     \noindent
     \parbox[t]{.7\textwidth}{Bei Systran bestand ein signifikanter starker negativer Zusammenhang zwischen der Differenz der Fehleranzahl des GR.7 „Falsche Wortart / Wortklasse“ und der Differenz der Inhaltsqualität.}
     \parbox[t]{.04\textwidth}{}
     \colorbox{smGreen}{\parbox[t]{.25\textwidth}{\textbf{Sy}

      \textbf{\textit{neg}} \textbf{GR.7 <{}<{}>{}> CQ}\vspace{25pt}}}

  \medskip
  \noindent
  \parbox[t]{.7\textwidth}{Alle weiteren Korrelationen waren nicht signifikant.}
\hrule
\paragraph*{Sechster Analysefaktor: Vergleich der MÜ-Qualität mit vs. ohne Funktionsverbgefüge auf Annotationsgruppenebene}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Gibt es einen Unterschied in der Stil- und Inhaltsqualität bei den einzelnen Annotationsgruppen nach der Anwendung der KS-Regel im Vergleich zu vor der Anwendung?
\item [H0 --] Bei den Annotationsgruppen gibt es keinen Qualitätsunterschied vor vs. nach der Anwendung der KS-Regel.
\item [H1 --] Bei den Annotationsgruppen gibt es einen Qualitätsunterschied vor vs. nach der Anwendung der KS-Regel.
\item [Resultat]
\end{description}
\noindent
\parbox[t]{.8\textwidth}{H1 wurde nur für die Gruppe FR bestätigt:

Bei der Annotationsgruppe FR stiegen die Stil- und Inhaltsqualität signifikant, nachdem das Funktionsverbgefüge vermieden wurde.}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.15\textwidth}{\textbf{SQ (+)}

 \textbf{CQ (+)}\vspace{25pt}}}

\medskip
\noindent
\parbox[t]{.8\textwidth}{Bei den Annotationsgruppen FF und RR stiegen die Stil- und Inhaltsqualität leicht.}
\parbox[t]{.04\textwidth}{}
\parbox[t]{.15\textwidth}{\textbf{SQ (+)}

 \textbf{CQ (+)}}

\medskip
\noindent
\parbox[t]{.8\textwidth}{Bei der Annotationsgruppe RF sanken die Stil- und Inhaltsqualität leicht.}
\parbox[t]{.04\textwidth}{}
\parbox[t]{.15\textwidth}{\textbf{SQ ($-$)}

 \textbf{CQ ($-$)}}
\hrule
\paragraph*{Siebter Analysefaktor: Vergleich der AEM-Scores mit vs. ohne Funktionsverbgefüge}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Gibt es einen Unterschied in den AEM-Scores von TERbase bzw. hLEPOR nach der Anwendung der KS-Regel im Vergleich zu vor der Anwendung?
\item [H0 --] Es gibt keinen Unterschied in den AEM-Scores vor vs. nach der Anwendung der KS-Regel.
\item [H1 --] Es gibt einen Unterschied in den AEM-Scores vor vs. nach der Anwendung der KS-Regel.
\item [Resultat]
\end{description}
\noindent
\parbox[t]{.75\textwidth}{H0 wurde abgelehnt und somit H1 bestätigt.

AEM-Scores sowohl von TERbase als auch von hLEPOR verbesserten sich signifikant, nachdem das Funktionsverbgefüge vermieden wurde.}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.2\textwidth}{\textbf{TERbase (+)\\hLEPOR (+)}\vspace{22pt}}}
\hrule
\paragraph*{Achter Analysefaktor: Korrelation zwischen den Differenzen der AEM-Scores und der Qualität}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Besteht ein Zusammenhang zwischen der Differenz der AEM-Scores von TERbase bzw. hLEPOR (Mittelwert der AEM-Scores nach KS $-$ vor KS) und der Differenz der allgemeinen Qualität (Qualität nach KS $-$ vor KS)?
\item [H0 --] Es besteht kein Zusammenhang zwischen der Differenz der AEM-Scores und der Differenz der allgemeinen Qualität.
\item [H1 --] Es besteht ein Zusammenhang zwischen der Differenz der AEM-Scores und der Differenz der allgemeinen Qualität.
\newpage
\item [Resultat]
\end{description}
\noindent
\parbox[t]{.7\textwidth}{H0 wurde abgelehnt und somit H1 bestätigt.

Es bestand ein signifikanter starker positiver Zusammenhang zwischen den Differenzen der Scores der beiden AEMs (TERbase und hLEPOR) und der Differenz der allgemeinen Qualität.}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.25\textwidth}{\textbf{\textit{pos}} \textbf{TERbase <{}<{}>{}> Q}

 \textbf{\textit{pos}} \textbf{hLEPOR <{}<{}>{}> Q}\vspace{40pt}}}


\subsection{DRITTE REGEL: Konditionalsätze mit ‚Wenn‘ einleiten}
\label{sec:5.3.3}

 \subsubsection{\label{sec:5.3.3.0}Überblick}

%In \tabref{tab:05:39}
Im Folgenden wird die KS-Regel „Konditionalsätze mit ‚Wenn‘ einleiten“ (auch bekannt als „Bedingungen als ‚Wenn‘-Sätze formulieren“) kurz beschrieben.\footnote{\textrm{Die für diese Regel relevanten Kontraste im Sprachenpaar DE-EN sind unter \sectref{sec:4.4.2.3} erörtert.} } Zudem wird zusammenfassend und anhand von Beispielen demonstriert, wie die Regel bei der Analyse angewendet wurde. Anschließend wird die Aufteilung der Testsätze im Datensatz dargestellt:

\begin{description}[font=\normalfont\bfseries]
\item [Beschreibung der KS-Regel:] \textbf{Konditionalsätze mit ‚Wenn‘ einleiten} (tekom-Regel-Nr. S 201 „Bedingungen als ‚Wenn‘-Sätze formulieren“)

Nach dieser Regel (\citealt{tekom2013}: 66) sollen Bedingungssätze mit der Konjunktion „Wenn“ oder „Falls“ eingeleitet werden.

Begründung: Durch die Satzstruktur „Wenn-Nebensatz-Hauptsatz“ wird das „Bedingung-Folge-Verhältnis“ ersichtlich und somit die Textverständlichkeit erhöht (ebd.: 67).

\item[Umsetzungsmuster:]
~\\
\textbf{Vor KS:} Der Satz beginnt mit dem Verb.\\
\textbf{Nach KS:} Der Satz ist mit ‚Wenn‘ am Satzanfang formuliert.\\
Wenn der Nebensatz vor KS mit ‚so‘ formuliert ist, wurde ‚so‘ aus stilistischen Gründen nach KS entfernt (siehe Beispiel unten).

\item[KS-Stelle]
~\\
\textbf{Vor KS:} das Verb\\
\textbf{Nach KS:} ‚Wenn‘ +~das Verb

\item[Beispiele]
~\\
\textit{\txgray{Ist} die Seriennummer des Gerätes bekannt, kann im Feld \ldots}

\textit{\txgray{Wenn} die Seriennummer des Gerätes bekannt \txgray{ist}, kann im Feld \ldots}
~\\
\textit{\txgray{Werden} die vordefinierten Werte \txgray{verändert}, so erfolgt die Umrechnung automatisch.}

\textit{\txgray{Wenn} die vordefinierten Werte \txgray{verändert werden}, erfolgt die Umrechnung automatisch.}

\item[Aufteilung der Testsätze:]
Da die Konditionalsätze im Deutschen mit unterschiedlichen Verben beginnen können und dies wiederum unterschiedliche Schwierigkeitsgrade für die MÜ-Systeme bedeutet, bestehen die Testsätze aus:

7 Konditionalsätzen, die mit dem Verb ‚Werden‘ beginnen,

8 Konditionalsätzen mit dem Verb ‚Sind‘ und

9 Konditionalsätzen mit weiteren unterschiedlichen Verben.

\end{description}



Im Folgenden werden die Ergebnisse der einzelnen Analysefaktoren präsentiert.

\subsubsection{\label{sec:5.3.3.1}Vergleich der Fehleranzahl bei Konditionalsätzen mit vs. ohne ‚Wenn‘}

Die Fehleranzahl sank deutlich um 56,5~\% von 92 Fehlern im Falle der Formulierung der Bedingungen mit Verben (M = ,77 / SD = 1,059 / N = 120) auf 40 Fehler bei der Formulierung mit ‚Wenn‘ (M = ,33 / SD = ,626 / N = 120), siehe \figref{fig:05:46} und \figref{fig:05:47}. Der Mittelwert der Differenz (nach KS $-$ vor KS) der Fehleranzahl pro Satz lag somit bei $-$~,43 (SD = 1,019) mit einem 95\%\nobreakdash-Konfidenzintervall zwischen einem Minimum von $-$ ,62 (SD =,814) und einem Maximum von $-$~,25 (SD = 1,197) (Bootstrapping mit 1000 Stichproben). Die Differenz (nach KS $-$ vor KS) der Fehleranzahl erwies sich als hochsignifikant (z (N = 120) = $-$ 4,282 / p < ,001).



%\includegraphics[height=.3\textheight]{figures/d3-img023.png}
%\includegraphics[height=.3\textheight]{figures/d3-img023.png}
%\includegraphics[height=.3\textheight]{figures/d3-img023.png} &  &
%    \includegraphics[height=.3\textheight]{figures/d3-img024.png}
%    \includegraphics[height=.3\textheight]{figures/d3-img024.png}
%    \textbf{,58,96}

%    \textbf{,23,45}
%    \includegraphics[height=.3\textheight]{figures/d3-img024.png}\\
\begin{figure}
\captionsetup{width=.45\textwidth}
\begin{floatrow}
\ffigbox[.5\textwidth]{\caption{„Kondi. m. Wenn“ -- Fehlersumme vor vs. nach KS}\label{fig:05:46}}{
\begin{tikzpicture}
	\begin{axis}[
	ybar,
	ymin = 0,
	ymax = 150,
	axis lines* = left,
	nodes near coords,
%         nodes near coords align = vertical,
  legend style={at={(0.5,-0.2)},anchor=north,cells={align=left}},
  xtick=\empty,
  width = .45\textwidth,
  enlarge x limits = .5
	]
	\addplot+[tmnlpone]
	coordinates{
	(1,92)
	};
	\addplot+[tmnlpthree]
	coordinates{
	(2,40)
	};
	\legend{Anzahl der  fehler\\innerh. KS vor KS,Anzahl der Fehler\\innerh. KS nach KS}
	\end{axis}
\end{tikzpicture}
}
\ffigbox[.45\textwidth]{\caption{„Kondi. m. Wenn“ -- Mittelwert der Fehleranzahl pro Satz vor vs. nach KS}\label{fig:05:47}}{
\includegraphics[width=.25\textwidth]{figures/Abb47.png}
\includegraphics[width=.4\textwidth]{figures/Abb21-legend.png}
}
\end{floatrow}
%\end{minipage}
\end{figure}



Im Datensatz ist ersichtlich, dass das Einleiten eines Konditionalsatzes mit einem Verb den MÜ-Systemen Probleme bereitet. Knapp 80~\% (19 von 24) der analysierten Sätze wurden von mindestens einem MÜ-System falsch übersetzt und mithilfe der KS-Regel korrigiert. Daher war die Anwendung der KS-Regel im Hinblick auf die Fehleranzahl sinnvoll. Wie in der Überblickstabelle erwähnt, bestehen die Testsätze aus sieben Konditionalsätzen, die mit dem Verb ‚Werden‘ beginnen, acht Konditionalsätzen mit dem Verb ‚Sind‘ und neun Konditionalsätzen mit weiteren unterschiedlichen Verben am Satzanfang. Die Ergebnisse bei den drei Gruppen waren auf Regelebene im Allgemeinen relativ ähnlich (\tabref{tab:05:40}). Nur bei der Kategorie \textit{Fehler vollständig korrigiert} sind mehr korrigierte Fälle bei den Konditionalsätzen mit ‚Sind‘ im Vergleich zu den anderen Verben zu beobachten:


\begin{table}
\begin{tabularx}{\textwidth}{Xrrr}

\lsptoprule
\multirow[t]{3}{=}{Veränderung in der Fehleranzahl nach Anwendung der Regel} & Konditional-  & Konditional-  & Konditional- \\
& sätze mit & sätze mit & sätze mit \\
& ‚Sind‘ & untersch. Verben & ‚Werden‘\\
\midrule
\rowcolor{lsLightGray}
Fehler vollständig korrigiert & 16 MÜ & 12 MÜ & 10 MÜ\\
Fehleranzahl gleich geblieben & 20 MÜ & 29 MÜ & 22 MÜ\\
Fehleranzahl stieg & 4 MÜ & 4 MÜ & 3 MÜ\\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:40}Fehleranzahlveränderung bei den verschiedenen Konditionalsätzen   }
\bspnote{N = 120}
\end{table}
 Die verschiedenen Annotationsgruppen werden unter \sectref{sec:5.3.3.2} näher betrachtet.


\subsubsubsection{Vergleich der Fehleranzahl auf Regel- und MÜ-Systemebene}

Die Fehleranzahl nach der Umsetzung der KS-Regel sank bei allen Systemen mit Ausnahme des\textbf{ }NMÜ-Systems: Google Translate war in der Lage 22 der 24 analysierten Sätze sowohl vor als auch nach der Umsetzung der KS-Regel korrekt zu übersetzen. Bei den zwei falschen Übersetzungen (\figref{fig:05:48}) handelt es sich um einen semantischen Fehler (‚Wenn‘ wurde als ‚When‘ anstatt ‚If‘ übersetzt) (\tabref{tabex:05:33}):


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule
\textbf{Vor-KS} & \textbf{Ist} diese Zeit \textbf{erreicht}, muss das Gerät für 2 Minuten abkühlen.\\
\tablevspace
GNMÜ & \textcolor{lsRed}{When} this time is reached, the unit must cool down for 2 minutes.\\
\midrule
\textbf{Nach-KS} & \textbf{Wenn} diese Zeit \textbf{erreicht ist}, muss das Gerät für 2 Minuten abkühlen.\\
\tablevspace
GNMÜ & \textcolor{lsRed}{When} this time is reached, the unit must cool down for 2 minutes.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:33} Beispiel 33 }
\bspnote{ Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

Die beiden falsch übersetzten Sätze waren sehr kontextabhängig, da das Konditionalverb ohne Kontext sowohl als ‚If‘ als auch ‚When‘ übersetzt werden kann. Mehr zu den Fehlertypen ist unter \sectref{sec:5.3.3.3} aufgeführt.

Weitere nicht signifikante Differenzen in der Fehleranzahl waren bei dem RBMÜ-System Lucy (Mdiff = $-$~,125) und dem hybriden System Systran (Mdiff = $-$~,042) zu finden (\figref{fig:05:48}).


\begin{figure}
%\textbf{\textit{$-$ 66,7~\%}}

%\textbf{\textit{$-$ 69,0~\%}}{}



%\includegraphics[height=.3\textheight]{figures/d3-img048.png}

%\textbf{$-$ 9,1~\%}

%\textbf{$-$ 37,5~\%}

%\textbf{100~\%}


%\includegraphics[height=.3\textheight]{figures/d3-img023.png}\\
\begin{tikzpicture}
	\begin{axis}[
	ybar,
	ymin = 0,
	ymax = 50,
	axis lines* = left,
	nodes near coords,
%         nodes near coords align = vertical,
         legend style={at={(0.5,-0.2)},anchor=north},
         xticklabels = {Bing,Google,Lucy,SDL,Systran},
         xtick=data,
         ylabel = {Summe},
%         width = \textwidth,
         extra description/.code={
         \node at (axis cs:-.3, 50)[anchor=west] {\bfitul{$-$ 69,0\%}};
         \node at (axis cs:.5, 10)[anchor=west] {100\%};
         \node at (axis cs:1.5, 15)[anchor=west] {$-$ 37,5 \%};
         \node at (axis cs:2.3, 37)[anchor=west] {\bfitul{$-$ 66,7 \%}};
         \node at (axis cs:3.5, 17)[anchor=west] {$-$ 9,1 \%};
						}
	]
	\addplot+[tmnlpone]
	coordinates{
	(0,42)
	(1,1)
	(2,8)
	(3,30)
	(4,11)
	};
	\addplot+[tmnlpthree]
	coordinates{
	(0,13)
	(1,2)
	(2,5)
	(3,10)
	(4,10)
	};
	\legend{Anzahl der  fehler innerh. KS vor KS,Anzahl der Fehler innerh. KS nach KS}
	\end{axis}
\end{tikzpicture}
\caption{\label{fig:05:48} „Kondi. m. Wenn“ -- Summe der Fehleranzahl vor vs. nach KS bei den einzelnen MÜ-Systemen}
\bspnote{\bfitul{Signifikante Differenz vor vs. nach KS}}
\end{figure}

Hingegen war die Differenz bei dem HMÜ-System Bing (Mdiff = $-$~1,208; z (N = 24) = $-$ 3,859 / p < ,001) und dem SMÜ-System SDL (Mdiff = $-$~,833; z (N = 24) = $-$ 2,357 / p = ,018) signifikant (\figref{fig:05:48}). Bei diesen beiden Systemen war die Anwendung der KS-Regel sehr nützlich. Die korrigierten Fehlertypen werden im \sectref{sec:5.3.3.3} detaillierter dargestellt.

\subsubsection{\label{sec:5.3.3.2}Aufteilung der Annotationsgruppen}

Genau die Hälfte der übersetzten Sätze war sowohl bei der Formulierung des Konditionalsatzes mit Verben (vor KS) als auch mit ‚Wenn‘ (nach KS) fehlerfrei (Gruppe RR) (\figref{fig:05:51}). Knapp ein Viertel der Sätze beinhaltete vor der Anwendung der KS-Regel Fehler, die nach der Anwendung der Regel vollständig korrigiert wurden (Gruppe FR) (\figref{fig:05:52}). Die drittgrößte Gruppe war die Gruppe FF. Diese Gruppe repräsentiert fast 21~\% der analysierten Sätze (\figref{fig:05:53}). Hier beinhaltete die Übersetzung Fehler sowohl vor der Anwendung der KS-Regel als auch danach.


\begin{figure}

%{
%\includegraphics[height=.3\textheight]{figures/d3-img049.png}
%}


%\includegraphics[height=.3\textheight]{figures/d3-img012.png}
% 49
\torte{25}{29}{6}{60}
\caption{\label{fig:05:49}   „Kondi. m. Wenn“ -- Aufteilung der Annotationsgruppen}

\end{figure}

Schließlich wurden nur 5~\% der Sätze bei der Formulierung des Konditionalsatzes mit Verb fehlerfrei übersetzt und erst nach der Formulierung mit ‚Wenn‘ falsch übersetzt (\figref{fig:05:49}). Im \sectref{sec:5.3.3.3} werden die Fehlertypen näher betrachtet.

\subsubsubsection{Vergleich der Aufteilung der Annotationsgruppen auf Regel- und MÜ-Systemebene}

Bei der dominanten Annotationsgruppe RR verzeichnete das NMÜ-System Google Translate den höchsten Prozentsatz mit 92~\%, gefolgt von dem RBMÜ-System Lucy mit 71~\% und schließlich von dem HMÜ-System Systran mit 58~\% (\figref{fig:05:50}).


\begin{figure}

% \textbf{38\% 4\%}  \textbf{21\%17\%25\%}         \textbf{58\%}         \textbf{8\% 46\% 8\%}                    \textbf{4\%}         \textbf{13\%}  \textbf{8\%}           \textbf{4\%}  \textbf{92\%71\%25\%58\%}


%\includegraphics[height=.3\textheight]{figures/d3-img050.png}


%\includegraphics[height=.3\textheight]{figures/d3-img026.png}\\
\begin{tikzpicture}
\tikzset{every node/.style={font=\scriptsize}};
	\begin{axis}[
	ybar,
	width = \textwidth,
	axis lines* = left,
	ylabel = {Anzahl},
	xtick = {3,9,15,21},
	xticklabels = {FF,FR,RF,RR},
	x tick label style ={yshift=-5pt},
% 	xtick=data,
%	x=12pt,
	enlarge x limits={.15},
	ymin=0,
	ymax = 25,
%	bar shift = 0pt,
%  	bar width=9,
	nodes near coords,
%	legend pos= north east,
	legend style={at={(0.5,-0.1)},anchor=north},
	legend columns = {-1},
	extra description/.code={
	\node at (axis cs:.5,11)[anchor = west]{7,5\%};
	\node at (axis cs:.5,-.5)[anchor = west]{38\%};
	\node at (axis cs:1.3,3)[anchor = west]{0,8\%};
	\node at (axis cs:1.5,-.5)[anchor = west]{4\%};
	\node at (axis cs:2.2,7)[anchor = west]{4,2\%};
	\node at (axis cs:2.2,-.5)[anchor = west]{21\%};
	\node at (axis cs:3.1,6)[anchor = west]{3,3\%};
	\node at (axis cs:3.1,-.5)[anchor = west]{17\%};
	\node at (axis cs:4,8)[anchor = west]{5,0\%};
	\node at (axis cs:4,-.5)[anchor = west]{25\%};
	\node at (axis cs:6.5,16)[anchor = west]{11,7\%};
	\node at (axis cs:6.4,-.5)[anchor = west]{58\%};
	\node at (axis cs:8.3,4)[anchor = west]{1,7\%};
	\node at (axis cs:8.3,-.5)[anchor = west]{8\%};
	\node at (axis cs:9.2,13)[anchor = west]{9,2\%};
	\node at (axis cs:9.2,-.5)[anchor = west]{46\%};
  \node at (axis cs:10.3,4)[anchor= west]{1,7\%};
  \node at (axis cs:10.3,-.5)[anchor= west]{8\%};
  \node at (axis cs:13.3,3)[anchor= west]{0,8\%};
  \node at (axis cs:13.3,-.5)[anchor= west]{4\%};
  \node at (axis cs:15.2,5)[anchor= west]{2,5\%};
  \node at (axis cs:15.2,-.5)[anchor= west]{13\%};
	\node at (axis cs:16.2,4)[anchor = west]{1,7\%};
	\node at (axis cs:16.2,-.5)[anchor = west]{8\%};
	\node at (axis cs:18.2,3)[anchor = west]{0,8\%};
	\node at (axis cs:18.3,-.5)[anchor = west]{4\%};
	\node at (axis cs:19.3,24)[anchor = west]{18,3\%};
	\node at (axis cs:19.3,-.5)[anchor = west]{92\%};
	\node at (axis cs:20.3,19)[anchor = west]{14,2\%};
	\node at (axis cs:20.3,-.5)[anchor = west]{71\%};
	\node at (axis cs:21.2,8)[anchor = west]{5,0\%};
	\node at (axis cs:21.2,-.5)[anchor = west]{25\%};
	\node at (axis cs:22.2,16)[anchor = west]{11,7\%};
	\node at (axis cs:22.2,-.5)[anchor = west]{58\%};
	}
	]
	\addplot+[lsNightBlue]
	coordinates {
	(3,9)
	(9,14)
	(15,0)
	(21,1)
	};
	\addplot+[tmnlpone]
	coordinates {
	(3,1)
	(9,0)
	(15,1)
	(21,22)
	};
	\addplot+[tmnlptwo]
	coordinates {
	(3,5)
	(9,2)
	(15,0)
	(21,17)
	};
	\addplot+[tmnlpthree]
	coordinates {
	(3,4)
	(9,11)
	(15,3)
	(21,6)
	};
	\addplot+[tmnlpfour]
	coordinates {
	(3,6)
	(9,2)
	(15,2)
	(21,14)
	};
	\legend{Bing,Google,Lucy,SDL,Systran}
	\end{axis}
\end{tikzpicture}
\caption{\label{fig:05:50}   „Kondi. m. Wenn“ -- Aufteilung der Annotationsgruppen bei den einzelnen MÜ-Systemen}
\bspnote{Die oben angezeigten Prozentzahlen sind für alle Systeme, d. h. systemübergreifend, (N = 120) berechnet.

Die untenstehenden Prozentzahlen sind auf Systemebene (N = 24) berechnet.}

\end{figure}

Erneut erzielten die HMÜ-Systeme unterschiedliche Ergebnisse. Anders als Systran waren 58~\% der Übersetzungen bei dem HMÜ-System Bing vor der Anwendung der KS-Regel falsch und danach richtig (Annotationsgruppe FR) (\figref{fig:05:50}).  Eine Formulierung der Bedingungen mit ‚Wenn‘ hat das System entsprechend unterstützt. Auch das SMÜ-System SDL erzielte ein ähnliches Ergebnis mit 46~\% aus der Annotationsgruppe FR (\figref{fig:05:50}).



\subsubsection{\label{sec:5.3.3.3}Vergleich der Fehlertypen bei Konditionalsätzen mit vs. ohne ‚Wenn‘}

Das Einleiten eines Konditionalsatzes mit einem Verb (vor KS) wurde in vielen Fällen von den MÜ-Systemen fehlerhaft übersetzt. Die Systeme übersetzen dieses Verb in den meisten Fällen falsch bzw. doppelt. Somit entstehen zwei lexikalische Fehlertypen: Fehlertyp LX.3 durch das Auslassen der Konjunktion ‚Wenn‘ und Fehlertyp LX.4 durch das Hinzufügen eines überflüssigen Verbs (‚is‘ in \tabref{tabex:05:34}):


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule
\textbf{Vor-KS} & \textbf{Ist} die Seriennummer des Gerätes bekannt, kann im Feld Seriennummer diese Nummer eingegeben werden.\\
\tablevspace
SMÜ SDL & \textcolor{lsRed}{XXX Is} the serial number of the device is known, this number can be entered in the $"$Serial Number$"$ field.\\
\midrule
\textbf{Nach-KS} & \textbf{Wenn} die Seriennummer des Gerätes bekannt \textbf{ist}, kann im Feld Seriennummer diese Nummer eingegeben werden.\\
\tablevspace
SMÜ SDL & \textcolor{tmnlpthree}{If} the serial number of the device \txblue{is} known, this number can be entered in the $"$Serial Number$"$ field.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:34}Beispiel 34   }
\bspnote{ Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens; \txred{XXX} für ein fehlendes Wort oder Komma.}
\end{table}

Die Fehleranzahl beider lexikalischen Fehlertypen LX.3 „Wort ausgelassen“ und LX.4 „Zusätzliches Wort eingefügt“ sank nach der Formulierung der Konditionalsätze mit ‚Wenn‘: Bei dem Fehlertyp LX.3 sank die Fehleranzahl massiv von 45 auf 2 ($-$~95,6~\% / Mv = ,38 / SDv = ,486 / Mn = ,02 / SDn = ,129 / N = 120) und bei dem Fehlertyp LX.4 wurden alle 7 vorgekommenen Fehler vor KS nach KS vollständig behoben ($-$~100~\% / Mv = ,06 / SDv = ,235 / Mn = -- / SDn = -- / N = 120) (\figref{fig:05:51}). Entsprechend erwies sich der Unterschied bei den beiden Fehlertypen als hochsignifikant (p < ,001 bzw. p = ,023 / N = 120).


\begin{figure}


%\includegraphics[height=.3\textheight]{figures/d3-img051.png}

%\textbf{\textit{$-$ 95,6~\%}}

%\textbf{\textit{$-$ 100~\%}}



%\includegraphics[height=.3\textheight]{figures/d3-img027.png}

%\includegraphics[height=.3\textheight]{figures/d3-img013.png}



%\includegraphics[height=.3\textheight]{figures/d3-img013.png}

%51
\pgfplotstableread{
1 0
2 0
3 0
4 0
5 45
6 2
7 7
8 0
9 0
10 0
11 0
12 0
13 0
14 0
15 7
16 5
17 1
18 2
19 19
20 14
21 11
22 15
23 0
24 0
25 2
26 2
}\datatable
\smbars[extra description/.code={
\node at (axis cs:4.5,49)[anchor = west]{\bfitul{$-$ 95,6\%}};
\node at (axis cs:6.5,12)[anchor = west]{\bfitul{$-$ 100\%}};
}]{}

\caption{\label{fig:05:51}„Kondi. m. Wenn“ -- Summe der Fehleranzahl der einzelnen Fehlertypen vor vs. nach KS   }
\bspnote{
*Die X-Achse ist folgendermaßen zu lesen: Jeder Fehlertyp wird anhand von zwei Balken abgebildet. Der erste Balken repräsentiert die Summe der Fehler vor KS und der zweite die Summe der Fehler nach KS, somit steht z. B. „OR\_1.v“ für „OR\_1: orthografischer Fehler Nr. 1“ und „v: vor KS“; „OR\_1.n“ wäre entsprechend das Pendant zu „OR\_1.v“ für das nach-KS-Szenario („n“).\\
**\bfitul{Signifikante Differenz vor vs. nach KS}\\
OR.1: Orthografie -- Zeichensetzung\\
OR.2: Orthografie -- Großschreibung\\
LX.3: Lexik -- Wort ausgelassen\\
LX.4: Lexik -- Zusätzliches Wort eingefügt\\
LX.5: Lexik -- Wort unübersetzt geblieben (auf DE wiedergegeben)\\
LX.6: Lexik -- Konsistenzfehler\\
GR.7: Grammatik -- Falsche Wortart / Wortklasse\\
GR.8: Grammatik -- Falsches Verb (Zeitform, Komposition, Person)\\
GR.9: Grammatik -- Kongruenzfehler (Agreement)\\
GR.10: Grammatik -- Falsche Wortstellung\\
SM.11: Semantik -- Verwechslung des Sinns\\
SM.12: Semantik -- Falsche Wahl\\
SM.13: Semantik -- Kollokationsfehler\\}
\end{figure}

Außerdem stellt die Übersetzung der Konditionalkonjunktion als Verb (‚Is‘ in \tabref{tabex:05:34}) am Satzbeginn einen semantischen Fehler dar, nämlich Fehlertyp SM.11 „Verwechslung des Sinns“. Dieser Fehlertyp stieg systemübergreifend minimal (11 vor der Umsetzung bzw. 15 nach der Umsetzung der KS-Regel) und entsprechend war die Veränderung insignifikant. Der Grund für den Anstieg der Fehleranzahl liegt darin, dass ‚Wenn‘ in einigen Fällen als ‚When‘ anstatt ‚If‘ übersetzt wurde. Im kommenden Abschnitt wird dieser Punkt systembezogen anhand eines Beispiels näher erläutert.

\subsubsection{Vergleich der Fehlertypen auf Regel- und MÜ-Systemebene}

Während auf Regelebene die Fehleranzahl des Fehlertyps LX.3 „Lexik -- Wort ausgelassen“  und LX.4 „Lexik -- Zusätzliches Wort eingefügt“ sich signifikant veränderte, zeigt eine nähere Analyse der Fehlertypen bei den verschiedenen MÜ-Systemen Folgendes (\figref{fig:05:52}): Die Fehlertypen LX.3 „Lexik -- Wort ausgelassen“ und GR.10 „Grammatik -- Falsche Wortstellung“ wiesen einzeln bei dem HMÜ-System Bing signifikante Veränderungen auf. Bei dem SMÜ-System SDL veränderte sich nur Fehlertyp LX.3 „Lexik -- Wort ausgelassen“ signifikant. Fehlertyp LX.4 „Lexik -- Zusätzliches Wort eingefügt“ zeigte bei keinem bestimmten System eine signifikante Veränderung.


\begin{figure}

%\includegraphics[height=.3\textheight]{figures/d3-img052.png}



%\includegraphics[height=.3\textheight]{figures/d3-img026.png}\\
\begin{tikzpicture}
\tikzset{every node/.style={font=\scriptsize}};
	\begin{axis}[
	xbar,
	width = \textwidth,
	height = .83\textheight,
	axis lines* = left,
	xlabel = {Summe},
	ytick = {1,2,3,...,14},
	yticklabels = {IN\_LX\_3.v,
	IN\_LX\_3.n,
	IN\_LX\_4.v,
	IN\_LX\_4.n,
	IN\_GR\_8.v,
	IN\_GR\_8.n,
  IN\_GR\_9.v,
  IN\_GR\_9.n,
	IN\_GR\_10.v,
	IN\_GR\_10.n,
	IN\_SM\_11.v,
	IN\_SM\_11.n,
	IN\_SM\_13.v,
	IN\_SM\_13.n
	},
%	x tick label style={rotate=60,anchor=east,font=\scriptsize},
	enlarge y limits={.032},
	xmin=0,
	xmax = 24,
%	bar shift = 1pt,
  	bar width=3,
	nodes near coords,
	legend pos = south east,
	reverse legend,
%	legend style={at={(0.5,-0.1)},anchor=north},
%	legend columns = {-1},
	]
	\addplot+[lsDarkBlue]
	coordinates {
	(23,1)
	(2,2)
	(2,3)
	(0,4)
	(4,5)
	(1,6)
	(1,7)
	(0,8)
	(10,9)
	(3,10)
	(2,11)
	(7,12)
	(0,13)
	(0,14)
	};
	\addplot+[lsLightOrange]
	coordinates {
	(0,1)
	(0,2)
	(0,3)
	(0,4)
	(0,5)
	(0,6)
	(0,7)
	(0,8)
	(0,9)
	(0,10)
	(1,11)
	(2,12)
	(0,13)
	(0,14)
	};
	\addplot+[smGreen]
	coordinates {
	(4,1)
	(0,2)
	(0,3)
	(0,4)
	(0,5)
	(0,6)
	(0,7)
	(0,8)
	(2,9)
	(2,10)
	(2,11)
	(3,12)
	(0,13)
	(0,14)
	};
	\addplot+[lsLightBlue]
	coordinates {
	(15,1)
	(0,2)
	(5,3)
	(0,4)
	(2,5)
	(3,6)
	(0,7)
	(0,8)
	(3,9)
	(5,10)
	(5,11)
	(2,12)
	(0,13)
	(0,14)
	};
	\addplot+[lsRed]
	coordinates {
	(3,1)
	(0,2)
	(0,3)
	(0,4)
	(1,5)
	(1,6)
	(0,7)
	(2,8)
	(4,9)
	(4,10)
	(1,11)
	(1,12)
	(2,13)
	(2,14)
	};
	\legend{Bing,Google,Lucy,SDL,Systran}
	\end{axis}
\end{tikzpicture}
\caption{\label{fig:05:52} „Kondi. m. Wenn“ -- Summe der Fehleranzahl der Fehlertypen vor vs. nach KS bei den einzelnen MÜ-Systemen  }
\bspnote{*Die Balken zeigen die Summe der Fehleranzahl bei jedem Fehlertyp, wobei „v“ für die Summe „vor der Anwendung der KS-Regel“ und „n“ für die Summe „nach der Anwendung der KS-Regel“ steht. Jeder Fehlertyp wird erst für alle Systeme für das Szenario „vor KS“ abgebildet, danach folgt derselbe Fehlertyp wieder für alle Systeme für das Szenario „nach KS“.

**Um die Übersichtlichkeit und Lesbarkeit der Grafik zu erhöhen, wurden in der Grafik die Fehlertypen ausgeblendet, die 0 oder nur einmal bei \textit{allen} MÜ-Systemen vorkamen: In dieser Grafik kamen die Fehlertypen 1, 2, 5, 6, 7 und 12 bei gar keinem MÜ-System vor.}
\end{figure}

Fehlertyp LX.3 sank bei Bing von 23 auf 2 Fehler ($-$ 91,3~\%) und bei SDL von 15 auf 5 Fehler ($-$ 66,7~\%) (\figref{fig:05:52}). Fehlertyp GR.10 sank bei Bing von 10 auf 3 Fehler ($-$ 70~\%) (\figref{fig:05:52}). Entsprechend erwies sich der Unterschied in der Fehleranzahl der beiden Fehlertypen LX.3 und GR.10 wie folgt als signifikant (\tabref{tab:05:41}).


\begin{table}
\begin{tabularx}{.87\textwidth}{lrlll}

\lsptoprule

{} & { \textbf{N}} & { \textbf{Mittelwert}} & { \textbf{Standard-}} & { \textbf{Signifikanz}}\\
&&&\textbf{abweichung} & \textbf{(McNemar-Test)}\\
\midrule
\multicolumn{5}{l}{\textbf{LX.3 „Wort ausgelassen“}}\\
{ \textbf{Bing}} & { 24 x 2} & vor KS = ,96 & vor KS = ,204 & p < ,001\\
&&nach KS = ,08 & nach KS = ,282 &\\
{ \textbf{SDL}} & { 24 x 2} & vor KS = ,63 & vor KS = ,495 & p < ,001\\
&&nach KS = -- & nach KS = --&\\
\midrule
\multicolumn{5}{l}{\textbf{GR.10 „Falsche Wortstellung“}}\\
{ \textbf{Bing}} & { 24 x 2} & vor KS = ,42 & vor KS = ,504 & p = ,016\\
&&nach KS = ,13 & nach KS = ,338 &\\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:41}„Kondi. m. Wenn“ -- Fehlertypen mit signifikanter Veränderung nach KS   }
\end{table}

Diese signifikante Veränderung ist in \tabref{tabex:05:35} zu beobachten.


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & \textbf{Steht} die Maschine nicht im Einsatz, den Hauptschalter auf $"$0$"$ setzen.\\
\tablevspace
HMÜ Bing & \textcolor{lsRed}{XXX Is~}the~machine~not~in~use,~set the main switch to $"$0$"$.\\
\midrule
\textbf{Nach-KS} & \textbf{Wenn} die Maschine nicht im Einsatz \textbf{steht}, den Hauptschalter auf $"$0$"$ setzen.\\
\tablevspace
HMÜ Bing & \textcolor{tmnlpthree}{If} the machine \txblue{is} not in use, \textbf{\textit{set}} the main switch to $"$0$"$.\\
\lspbottomrule
\end{tabularx}\caption{\label{tabex:05:35} Beispiel 35  }
\bspnote{ Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens; \txred{XXX} für ein fehlendes Wort oder Komma.}
\end{table}

Hierbei wurden der lexikalische Fehlertyp LX.3 (in dem Auslassen von ‚If‘) und der grammatische Fehlertyp GR.10 (in der falschen Wortstellung des Verbs ‚Is‘) nach der Anwendung der KS-Regel behoben.

Der insignifikante Anstieg in der Fehleranzahl bei Fehlertyp SM.11 „Semantik -- Verwechslung des Sinns“ bei dem HMÜ-System Bing und dem NMÜ-System Google kann durch \tabref{tabex:05:36} verdeutlicht werden.


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & \textbf{Schließt} der Kontaktschalter, so wird der Raumdruck-Sollwert aktiv.\\
\tablevspace
GNMÜ & \textcolor{tmnlpthree}{If} the contact switch \txblue{closes}, the room pressure setpoint becomes active.\\
\midrule
\textbf{Nach-KS} & \textbf{Wenn} der Kontaktschalter \textbf{schließt}, wird der Raumdruck-Sollwert aktiv.\\
\tablevspace
GNMÜ & \textcolor{lsRed}{When}~the~contact switch~\txblue{closes},~the room pressure setpoint becomes active.\\
\lspbottomrule
\end{tabularx}\caption{\label{tabex:05:36} Beispiel 36   }
\bspnote{ Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

Solche semantischen Fehler der Verwechslung des Sinns wurden auch in den Ergebnissen der Humanevaluation beobachtet. Hierbei kommentierten die Teilnehmer, dass sie Kontextinformationen benötigen, um den korrekten Sinn erkennen zu können.

\subsubsection{\label{sec:5.3.3.4}Vergleich der MÜ-Qualität bei Konditionalsätzen mit vs. ohne ‚Wenn‘ sowie die Korrelation zwischen den Fehlertypen und der Qualität}

Sowohl die Stil- als auch die Inhaltsqualität\footnote{\textrm{Definitionen der Qualität unter \sectref{sec:4.4.5.1}.}} stiegen nach der Formulierung der Konditionalsätze mit ‚Wenn‘ (nach KS). Auf den ersten Blick erkennt man in \figref{fig:05:54}, dass der Einfluss auf die Inhaltsqualität im Vergleich zur Stilqualität größer war. Angesichts des deutlichen Rückgangs der lexikalischen Fehlertypen LX.3 „Wort ausgelassen“ und LX.4 „Zusätzliches Wort eingefügt“ nach der Verwendung der Konjunktion ‚Wenn‘ (nach KS) (siehe \sectref{sec:5.3.3.3}), ist es nachvollziehbar, dass die Inhaltsqualität durch die erhöhte Verständlichkeit und Genauigkeit primär beeinflusst wird:

Die Stilqualität stieg um 3,8~\% (Mv = 4,22 / SDv = ,533 / Mn = 4,38 / SDn = ,483 / N = 84). Die Inhaltsqualität stieg um 9,3~\% (Mv = 4,21 / SDv = ,748 / Mn = 4,60 / SDn = ,599 / N = 84) (\figref{fig:05:53}). Der Mittelwert der Differenz (nach KS $-$ vor KS) der vergebenen Qualitätspunkte pro Satz lag für die Stilqualität bei ,168 (SD = ,562) mit einem 95\%\nobreakdash-Konfidenzintervall zwischen einem Minimum von ,046 und einem Maximum von ,290 und für die Inhaltsqualität bei ,384 (SD = ,800) mit einem 95\%\nobreakdash-Konfidenzintervall zwischen einem Minimum von ,210 und einem Maximum von ,558 (Bootstrapping mit 1000 Stichproben) (\figref{fig:05:54}). Die Differenzen (nach KS $-$ vor KS) in der Stil- und Inhaltsqualität erwiesen sich als signifikant (z (N = 84) = $-$ 2,585 / p = ,010) bzw. (z (N = 84) = $-$ 3,983 / p < ,001).


\begin{figure}

%\textbf{4,474,73}



%\includegraphics[height=.3\textheight]{figures/d3-img029.png}

%\textbf{4,104,33}

%\textbf{4,054,38}

%\textbf{4,284,49}



%\includegraphics[height=.3\textheight]{figures/d3-img029.png}



%\includegraphics[height=.3\textheight]{figures/d3-img030.png} &  &
%\includegraphics[height=.3\textheight]{figures/d3-img017.png}




%\includegraphics[height=.3\textheight]{figures/d3-img017.png}



%\includegraphics[height=.3\textheight]{figures/d3-img017.png}\\
%\hhline%%replace by cmidrule{-~-}

\captionsetup{width=.45\textwidth}
\begin{floatrow}
\ffigbox[.5\textwidth]{\caption{„Kondi. m. Wenn“ -- Mittelwerte der Qualität vor und nach KS}\label{fig:05:53}}{
\includegraphics[width=.25\textwidth]{figures/Abb53.png}
\includegraphics[width=.2\textwidth]{figures/Abb15-legend.png}
}
\ffigbox[.45\textwidth]{\caption{„Kondi. m. Wenn“ -- Mittelwert der Qualitätsdifferenzen}\label{fig:05:54}}{
\includegraphics[width=.25\textwidth]{figures/Abb16-legend.png}
\includegraphics[width=.3\textwidth]{figures/Abb54.png}
}
\end{floatrow}

\end{figure}


Durch die Humanevaluation wird ersichtlich, dass der Anstieg der allgemeinen Qualität durch den Anstieg der Inhaltsqualität begründet ist. \figref{fig:05:55} „Vergleich der Qualitätskriterien“ zeigt, dass sich beide Inhaltsqualitätskriterien (CQ1 und CQ2) nach der Verwendung der Konjunktion ‚Wenn‘ anstelle von Verben am Satzbeginn deutlich verbesserten.


\begin{figure}

%\includegraphics[height=.3\textheight]{figures/d3-img053.png}

%\textbf{$-$ 23~\%}

%\textbf{$-$ 37~\%}

%\textbf{$-$ 50~\%}

%\textbf{$-$ 17~\%}

%\textbf{+~4~\%}
\pgfplotstableread{
1 50
2 52
3 81
4 62
5 295
6 245
7 216
8 108
9 155
10 98
}\datatable
\begin{tikzpicture}
%    \tikzset{every node/.style={font=\scriptsize}};
    \begin{axis}[ybar,
  %              ylabel = {Summe},
  %              ylabel style={yshift=-.2cm},
                enlarge x limits={.05},
                width  = \textwidth,
                height = .45\textheight,
                axis lines*=left,
                axis on top,
                bar width=8.5,
                bar shift=0pt,
                ymin = 0,
                ymax=350,
                xtick = {1,2,...,10},
                xticklabels={SQ1\_v,
                SQ1\_n,
                SQ2\_v,
                SQ2\_n,
                SQ3\_v,
                SQ3\_n,
                CQ1\_v,
                CQ1\_n,
                CQ2\_v,
                CQ2\_n},
            x tick label style={font=\small},
            nodes near coords,
 %           legend style={at={(0.5,-0.25)},anchor=north},
 %           legend columns={-1},
 	 extra description/.code={
	 \node at (axis cs:1.1,100)[anchor = west]{$+$ 4\%};
	 \node at (axis cs:3,125)[anchor = west]{$-$ 23\%};
	  \node at (axis cs:5,325)[anchor = west]{$-$ 17\%};
	   \node at (axis cs:7.2,180)[anchor = west]{$-$ 50\%};
	    \node at (axis cs:9,200)[anchor = west]{$-$ 37\%};
	  }
            ]
        \addplot +[shift={(.5,0)},lsDarkBlue,x filter/.code={\ifodd\coordindex\def\pgfmathresult{}\fi}] table {\datatable};
        \addplot +[shift={(-.5,0)},lsMidBlue,  x filter/.code={\ifodd\coordindex\relax\else\def\pgfmathresult{}\fi}] table {\datatable};
 %       \legend{vor KS,nach KS}
    \end{axis}
\end{tikzpicture}

\caption{\label{fig:05:55}„Kondi. m. Wenn“ -- Vergleich der Qualitätskriterien   }
\bspnote{\textbf{SQ1:} Ü ist \textbf{\textit{nicht}} korrekt bzw. \textbf{\textit{nicht}} klar dargestellt, d. h. nicht orthografisch.\\
\textbf{SQ2:} Ü ist \textbf{\textit{nicht}} ideal für die Absicht des Satzes, d. h. motiviert den Nutzer \textbf{\textit{nicht} }zum Handeln, zieht \textbf{\textit{nicht} }seine Aufmerksamkeit an usw.\\
\textbf{SQ3:} Ü klingt \textbf{\textit{nicht} }natürlich bzw. \textbf{\textit{nicht} }idiomatisch.\\
\textbf{CQ1:} Ü gibt die Informationen im Ausgangstext \textbf{\textit{nicht}} exakt wieder.\\
\textbf{CQ2:} Ü ist \textbf{\textit{nicht}} leicht zu verstehen, d. h. \textbf{\textit{nicht}} gut formuliert bzw. dargestellt.}
\end{figure}


Wie \tabref{tabex:05:37} zeigt, ist die MÜ vor KS unverständlich (CQ2) und gibt den Inhalt des Ausgangstexts nicht wieder (CQ1).


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & \textbf{Ist} nur ein Gerät \textbf{angeschlossen}, so ist die Funktion PP zu wählen.\\
\tablevspace
HMÜ Systran & Only \txred{if} one device \txblue{is attached}, the $"$PP$"$ function must be selected.\\
\midrule
\textbf{Nach-KS} & \textbf{Wenn} nur ein Gerät \textbf{angeschlossen ist}, ist die Funktion PP zu wählen.\\
\tablevspace
HMÜ Systran & \textcolor{tmnlpthree}{If} only one device \txblue{is attached}, the $"$PP$"$ function must be selected.\\

\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:37}Beispiel 37   }
\bspnote{ Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

Durch den Wortstellungsfehler in ‚If‘ (vor KS) wird falscher Inhalt vermittelt. Dieser Einfluss ist in den Kommentaren der Bewerter wiederzufinden „only ‚if‘ is wrong and actually provides false information, I suggest ‚if only‘“ (Kommentar eines Bewerters).

\subsubsubsection{Korrelation zwischen den Fehlertypen und der Qualität}

Auf Basis der Fehlerannotation in Kombination mit der Humanevaluation gibt uns die Spearman-Korrelationsanalyse Aufschluss, wie die Veränderung bei der Fehleranzahl bei jedem Fehlertyp (Anz. nach KS $–$ Anz. vor KS) mit den Qualitätsunterschieden (Q. nach KS $–$ Q. vor KS) zusammenhängt. Mithilfe des Spearman-Tests erwies sich (\tabref{tab:05:42}) ein signifikanter starker negativer Zusammenhang zwischen der Differenz in Fehlertyp LX.3 „Wort ausgelassen“ und der Differenz in der Stilqualität. Außerdem erwies sich ein signifikanter mittlerer negativer Zusammenhang zwischen der Differenz in Fehlertyp GR.10 „Falsche Wortstellung“ und der Differenz in der Stilqualität; sowie ein signifikanter schwacher negativer Zusammenhang zwischen der Differenz in Fehlertyp LX.4 „Zusätzliches Wort eingefügt“ und der Differenz in der Stilqualität.

Bezüglich der Inhaltsqualität erwies sich (\tabref{tab:05:42}) ein signifikanter starker negativer Zusammenhang zwischen der Differenz in Fehlertyp LX.3 und der Differenz in der Inhaltsqualität; sowie ein signifikanter schwacher negativer Zusammenhang zwischen der Differenz in den Fehlertypen LX.4 und GR.10 einzeln und der Differenz in der Inhaltsqualität. Weitere Korrelationen zwischen anderen einzelnen Fehlertypen und der Qualität konnten nicht nachgewiesen werden.


\begin{table}
\begin{tabularx}{\textwidth}{Xrrr}

\lsptoprule
& \textbf{N} & { \textbf{p}} & { \textbf{ρ}}\\
\midrule
\textbf{Differenz SQ (nach KS $-$ vor KS)} &  &  & \\
 Differenz der Anzahl der \textbf{LX.3} & 84 & { < ,001} & \boxblue{ $-$~,630}\\
 Differenz der Anzahl der \textbf{LX.4} & 84 & { ,010} & { $-$~,281}\\
 Differenz der Anzahl der \textbf{GR.10} & 84 & { < ,001} & \txgreen{ $-$~,375}\\
 \midrule
\textbf{Differenz CQ (nach KS $-$ vor KS)} &  &  & \\
 Differenz der Anzahl der \textbf{LX.3} & 84 & { < ,001} & \boxblue{ $-$~,804}\\
 Differenz der Anzahl der \textbf{LX.4} & 84 & { ,046} & { $-$~,218}\\
 Differenz der Anzahl der \textbf{GR.10} & 84 & { ,016} & { $-$~,263}\\
 \midrule
\textbf{Differenz allg. Q (nach KS $-$ vor KS)} &  &  & \\
 Differenz der Anzahl der \textbf{LX.3} & 84 & { < ,001} & \boxblue{ $-$~,774}\\
 Differenz der Anzahl der \textbf{LX.4} & 84 & { ,014} & { $-$~,268}\\
 Differenz der Anzahl der \textbf{GR.10} & 84 & { ,004} & \txgreen{ $-$~,308}\\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:42}„Kondi. m. Wenn“ -- Korrelation zwischen den Fehlertypen und der Qualität   }
\bspnote{*In der Tabelle werden nur die Fehlertypen dargestellt, die mindestens mit einer Qualitätsvariable signifikant korrelieren.\\
\begin{tabbing}
p: Signifikanz\hspace{2.5cm} \= ρ: Korrelationskoeffizient\hspace{1cm} \= \hspace{4cm}\\
schwache Korrelation (ρ >=0,1) \> \txgreen{mittlere Korrelation (ρ >= 0,3)} \> \boxblue{starke Korrelation (ρ >= 0,5)}
\end{tabbing}}
\end{table}


Diese signifikanten negativen Korrelationen deuten darauf hin, dass sobald die Fehleranzahl der genannten Fehlertypen sank, die Qualität stieg. In \tabref{tabex:05:37} wurde der grammatische Fehlertyp GR.10 „Falsche Wortstellung“ in ‚If‘ korrigiert, daraufhin stieg die Stil- und Inhaltsqualität jeweils um 0,75 Punkte auf der Likert-Skala.

In einem weiteren Beispiel wurde nur der lexikalische Fehler (LX.3) für die fehlende Übersetzung des Verbs ‚Ist‘ korrigiert, nachdem der Konditionalsatz mit ‚Wenn‘ formuliert wurde (\tabref{tabex:05:38}).


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & \textbf{Ist} die Seriennummer des Gerätes bekannt, kann im Feld Seriennummer diese Nummer eingegeben werden.\\
\tablevspace
HMÜ Bing & \textcolor{lsRed}{XXX} The~serial number~of the~device\txblue{~is~}known,~this number can be entered in the $"$Serial Number$"$ field.\\
\midrule
\textbf{Nach-KS} & \textbf{Wenn} die Seriennummer des Gerätes bekannt \textbf{ist}, kann im Feld Seriennummer diese Nummer eingegeben werden.\\
\tablevspace
HMÜ Bing & \textcolor{tmnlpthree}{If} the serial number of the device \txblue{is} known, this number can be entered in the $"$Serial Number$"$ field.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:38}Beispiel 38   }
\bspnote{ Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens; \txred{XXX} für ein fehlendes Wort oder Komma.}
\end{table}
Daraufhin stieg die Stilqualität um 0,38 Punkte und die Inhaltsqualität um 1,63 Punkte auf der Likert-Skala.

\subsubsubsection{Vergleich der Qualität auf Regel- und MÜ-Systemebene}

Wie \figref{fig:05:56} zeigt, stiegen die Stil- und Inhaltsqualität nach der Anwendung der KS-Regel nur bei dem HMÜ-System Bing (+~15,6~\% (SQ) bzw. +~33,5~\% (CQ)). Zudem stieg nur die Inhaltsqualität bei dem SMÜ-System SDL (+~16,5~\%). Diese Zunahmen erwiesen sich als signifikant. Bei den anderen Systemen war die Veränderung, wenn überhaupt, minimal.


\begin{figure}

\includegraphics[width=\textwidth]{figures/d3-img054.png}

%\includegraphics[height=.3\textheight]{figures/d3-img033.png}\\
\caption{\label{fig:05:56}  „Kondi. m. Wenn“ -- Mittelwerte der Qualität vor vs. nach KS bei den einzelnen MÜ-Systemen  }
\end{figure}

Wie die Aufteilung der Annotationsgruppen zeigte, waren 92~\% der Übersetzungen vom NMÜ-System Google Translate sowohl vor als auch nach der Anwendung der KS-Regel richtig (Annotationsgruppe RR). Entsprechend ist zu erwarten, dass das Qualitätsniveau sich nicht verändert. Ebenfalls waren bei dem RBMÜ-System Lucy 71~\% der MÜ in der Annotationsgruppe RR und 21~\% in der Annotationsgruppe FF enthalten. Bei zwei fehlerfreien MÜ (Gruppe RR) bzw. zwei fehlerhaften MÜ (Gruppe FF) waren die Qualitätswerte vor und nach der Regelanwendung vergleichbar, daher ist die minimale Qualitätsveränderung bei Lucy begründet. Bei dem HMÜ-System Systran waren die Fehleranzahl vor und nach der Anwendung der KS-Regel vergleichbar hoch und die Fehlertypen sehr gemischt, daher konnte keine signifikante Veränderung in der Qualität verzeichnet werden.


\begin{table}
\begin{tabularx}{\textwidth}{lrrrrrrrrr}
\lsptoprule
& \multicolumn{3}{c}{\textbf{Differenz SQ}} & \multicolumn{3}{c}{\textbf{Differenz CQ}} & \multicolumn{3}{c}{\textbf{Differenz allg. Q}}\\
&  \multicolumn{3}{c}{\textbf{(nach KS $-$ vor KS)}} &  \multicolumn{3}{c}{\textbf{(nach KS $-$ vor KS)}} & \multicolumn{3}{c}{\textbf{(nach KS $-$ vor KS)}}\\
\cmidrule(lr){2-4}\cmidrule(lr){5-7}\cmidrule(lr){8-10}
& \textbf{N} & \textbf{p} & \textbf{z} & \textbf{N} & \textbf{p} & \textbf{z} & \textbf{N} & \textbf{p} & \textbf{z}\\
\midrule
 \textbf{Bing} & 18 & ,002 & $-$ 3,108 & 18 & < ,001 & $-$ 3,489 & 18 & ,001 & $-$ 3,422\\
 \textbf{Google} & 21 & \txgray{,982} & $-$~,022 & 21 & \txgray{,353} & $-$~,929 & 21 & \txgray{,516} & $-$~,649\\
 \textbf{Lucy} & 13 & \txgray{,328} & $-$~,978 & 13 & \txgray{,168} & $-$~1,378 & 13 & ,027 & $-$ 2,209\\
 \textbf{SDL} & 19 & \txgray{,080} & $-$~1,754 & 19 & ,011 & $-$ 2,528 & 19 & ,008 & $-$ 2,637\\
 \textbf{Systran} & 13 & \txgray{,348} & $-$~,938 & 13 & \txgray{,797} & $-$~,257 & 13 & \txgray{,366} & $-$~,904\\
\lspbottomrule
\end{tabularx}\caption{\label{tab:05:43}„Kondi. m. Wenn“ -- Signifikanz der Qualitätsveränderung bei den einzelnen MÜ-Systemen   }
\bspnote{p: Signifikanz\hspace{2.5cm} z: Teststatistik\hspace{2.5cm} \txgray{nicht signifikant (p ${\geq}$ 0,05)}}
\end{table}


\subsubsubsection{Korrelation zwischen den Fehlertypen und der Qualität auf Regel- und MÜ-Systemebene}

Anhand der Spearman-Korrelationsanalyse erwiesen sich bei zwei MÜ-Systemen signifikante starke negative Korrelationen (\tabref{tab:05:44}): Bei dem HMÜ-System Bing konnte eine signifikante starke negative Korrelation zwischen der Differenz in Fehlertyp LX.3 „Wort ausgelassen“ und der Differenz der Stil- und Inhaltsqualität nachgewiesen werden, wie in \tabref{tabex:05:38}. Bei dem SMÜ-System SDL erwies sich eine signifikante starke negative Korrelation zwischen den Fehlertypen LX.3 „Wort ausgelassen“ und GR.10 „Falsche Wortstellung“ einzeln und der Stilqualität; sowie eine signifikante starke negative Korrelation zwischen LX.3 und der Inhaltsqualität.


\begin{table}
\begin{tabularx}{\textwidth}{Xrrrrrr}
\lsptoprule
& \multicolumn{3}{c}{ \textbf{Bing}}  & \multicolumn{3}{c}{ \textbf{SDL}} \\
\cmidrule(lr){2-4}\cmidrule(lr){5-7}
& \textbf{N} & \textbf{p} & \textbf{ρ} &  \textbf{N} & \textbf{p} & \textbf{ρ}\\
\midrule
\multicolumn{7}{l}{\textbf{Differenz SQ} \textbf{(nach KS $-$ vor KS)}}\\
 Diff. der Anzahl \textbf{LX.3 „W. fehlt“} & 18 & ,029 & \boxblue{$-$~,513} & 19 & ,005 & \boxblue{$-$~,611} \\
 Diff. der Anzahl \textbf{GR.10 „Wortst.“} &  &  &  & 19 & ,008 & \boxblue{$-$~,588}\\
 \midrule
\multicolumn{7}{l}{\textbf{Differenz CQ} \textbf{(nach KS $-$ vor KS)}} \\
 Diff. der Anzahl \textbf{LX.3 „W. fehlt“} & 18 & ,019 & \boxblue{$-$~,548} &  19 & < ,001 & \boxblue{$-$~,757} \\
 Diff. der Anzahl \textbf{GR.10 „Wortst.“} &  &  &  &  19 & \txgray{,306} & $-$~,248 \\
 \midrule
\multicolumn{7}{l}{\textbf{Differenz Q} \textbf{(nach KS $-$ vor KS)}}\\
 Diff. der Anzahl \textbf{LX.3 „W. fehlt“} & 18 & ,019 & \boxblue{$-$~,547}  & 19 & < ,001 & \boxblue{$-$~,766} \\
 Diff. der Anzahl \textbf{GR.10 „Wortst.“} &  &  &  &  19 & \txgray{,058 }& $-$~,443  \\

\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:44} „Kondi. m. Wenn“ -- Korrelationen zwischen den Fehlertypen und der Qualität bei den einzelnen MÜ-Systemen  }
\bspnote{*In der Tabelle werden nur die Fehlertypen dargestellt, die bei mind. einer Qualitätsvariable eine signifikante Korrelation aufweisen.\\
\begin{tabbing}
p: Signifikanz\hspace{2.5cm} \= \txgray{nicht signifikant (ρ ${\geq}$ 0,05)}\hspace{.5cm} \= ρ: Korrelationskoeffizient\\
schwache Korrelation (ρ >=0,1) \> \txgreen{mittlere Korrelation (ρ >= 0,3)} \> \boxblue{starke Korrelation (ρ >= 0,5)}
\end{tabbing}
}
\end{table}

In \tabref{tabex:05:39} wurden die Fehlertypen LX.3 „Wort ausgelassen“ (in ‚if‘) und GR.10 „Falsche Wortstellung“ (in ‚is‘) eliminiert.


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & \textbf{Steht} ein normierter Faktor zur Verfügung, kann dieser Faktor direkt in der Eingabemaske eingegeben werden.\\
\tablevspace
SMÜ SDL & \textcolor{lsRed}{XXX Is} a standardized factor available, this factor can be entered directly in the input mask.\\
\midrule
\textbf{Nach-KS} & \textbf{Wenn} ein normierter Faktor zur Verfügung \textbf{steht}, kann dieser Faktor direkt in der Eingabemaske eingegeben werden.\\
\tablevspace
SMÜ SDL & \textcolor{tmnlpthree}{If} a standardized factor \txblue{is} available, this factor can be entered directly in the input mask.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:39}Beispiel 39   }
\bspnote{ Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens; \txred{XXX} für ein fehlendes Wort oder Komma.}
\end{table}

Daraufhin stieg die Stilqualität um 1,25 Punkte und die Inhaltsqualität um 0,75 Punkte auf der Likert-Skala.



\subsubsection{Vergleich der MÜ-Qualität bei Konditionalsätzen mit vs. ohne ‚Wenn‘ auf Annotationsgruppenebene}
\label{sec:5.3.3.5}

Mit Ausnahme der Gruppe FR fiel die Differenz in der Stil- und Inhaltsqualität\footnote{\textrm{Definitionen der Qualität unter \sectref{sec:4.4.5.1}.}} bei allen anderen Annotationsgruppen sehr gering aus (\figref{fig:05:57}).


\begin{figure}

\includegraphics[width=\textwidth]{figures/d3-img055.png}

%\includegraphics[height=.3\textheight]{figures/d3-img035.png}\\

\caption{\label{fig:05:57}„Kondi. m. Wenn“ -- Mittelwerte der Qualität vor vs. nach KS auf Annotationsgruppenebene   }
\end{figure}

In der Gruppe FF (Übersetzung vor und nach KS falsch) blieb die Inhaltsqualität fast unverändert und die Stilqualität sank minimal (\figref{fig:05:57}). Es gab in dieser Gruppe keinen bestimmten Fehler, der vor oder nach der Anwendung der KS auftrat bzw. eliminiert wurde.


\begin{table}
\begin{tabularx}{\textwidth}{Xrrr}

\lsptoprule
& \textbf{N} & { \textbf{p}} & { \textbf{Z} }\\
&& \textbf{(Signifikanz)} & \textbf{(Teststatistik)}\\
 \midrule
{\textbf{Annotationsgruppe FF}} & {} & {} & \\
\textbf{Differenz SQ (nach KS $-$ vor KS)} & 14 & \txgray{,090} & $-$~1,694\\
\textbf{Differenz CQ (nach KS $-$ vor KS)} & 14 & \txgray{,278} & $-$~1,084\\
\textbf{Differenz allg. Q (nach KS $-$ vor KS)} & 14 & \txgray{,157} & $-$~1,414\\
\midrule
{\textbf{Annotationsgruppe FR}} & {} & {} & \\
\textbf{Differenz SQ (nach KS $-$ vor KS)} & 23 & < ,001 & $-$ 4,143\\
  \textbf{Differenz CQ (nach KS $-$ vor KS)} & 23 & < ,001 & $-$ 4,209\\
\textbf{Differenz allg. Q (nach KS $-$ vor KS)} & 23 & < ,001 & $-$ 4,201\\
\midrule
{\textbf{Annotationsgruppe RF}} & {} & {} & \\
\textbf{Differenz SQ (nach KS $-$ vor KS)} & 3 & \txgray{,285} & $-$~1,069\\
  \textbf{Differenz CQ (nach KS $-$ vor KS)} & 3 & \txgray{,285} & $-$~1,069\\
\textbf{Differenz allg. Q (nach KS $-$ vor KS)} & 3 & \txgray{,285} & $-$~1,069\\
\midrule
{\textbf{Annotationsgruppe RR}} & {} & {} & \\
\textbf{Differenz SQ (nach KS $-$ vor KS)} & 44 & \txgray{,620} & $-$~,222\\
  \textbf{Differenz CQ (nach KS $-$ vor KS)} & 44 & \txgray{,795} & $-$~,260\\
   \textbf{Differenz allg. Q (nach KS $-$ vor KS)} & 44 & \txgray{,229} & $-$~1,204\\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:45} „Kondi. m. Wenn“ -- Signifikanz der Qualitätsveränderung auf Annotationsgruppenebene  }
\end{table}


In der Gruppe FR stiegen erwartungsgemäß die Stil- und Inhaltsqualität signifikant (\figref{fig:05:57}): Ein Anstieg von 18,6~\% bei der Stilqualität (z (N = 23) = $-$~4,143 / p <~,001) bzw. ein doppelt so hoher Anstieg von 36,3~\% bei der Inhaltsqualität (z (N = 23) = $-$~4,209 / p <~,001) (\tabref{tab:05:45}). Die Eliminierung des Fehlertyps LX.3 (das Auslassen von ‚If‘) führte eindeutig zu einer hohen Verständlichkeit und Genauigkeit der MÜ (hohe Inhaltsqualität) und steigerte die stilistische Adäquatheit\footnote{\textrm{Stilistische Adäquatheit im Sinne von \citet[163]{HutchinsSomers1992} ist „the extent to which the translation uses the language appropriate to its content and intention”. Mehr zu den Definitionen der Qualität unter \sectref{sec:4.4.5.1}.}} für eine Formulierung als Bedingung. Dieses Ergebnis wird in \tabref{tabex:05:40} verdeutlicht, in dem die Stilqualität um 0,88 und die Inhaltsqualität um 1,63 Punkte auf der Likert-Skala stiegen.


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & \textbf{Ist} ein mehrstufiges Modul \textbf{parametriert}, so sind die externen Kontakte zu verriegeln.\\
\tablevspace
HMÜ Bing & \textcolor{lsRed}{XXX} A multi-level module \txblue{is programmed}, the external contacts must be locked.\\
\midrule
\textbf{Nach-KS} & \textbf{Wenn} ein mehrstufiges Modul \textbf{parametriert ist}, sind die externen Kontakte zu verriegeln.\\
\tablevspace
HMÜ Bing & \textcolor{tmnlpthree}{If} a multi-level module \txblue{is programmed}, the external contacts must be locked.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:40}Beispiel 40   }
\bspnote{ Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens; \txred{XXX} für ein fehlendes Wort oder Komma.}
\end{table}

Die Gruppe RF war, wie die Aufteilung der Annotationsgruppen (\sectref{sec:5.3.3.2}) zeigte, sehr selten vertreten (nur 5~\% der Fälle) (\figref{fig:05:49}). Übersetzungen dieser Gruppe kamen in grenzwertigen Fällen vor, in denen z. B. die Konditionalkonjunktion ‚Wenn‘ mangels Kontextinformationen als ‚When‘ anstatt ‚If‘ übersetzt wurde (siehe \tabref{tabex:05:36}). In der Gruppe RR (Übersetzung vor und nach KS richtig) waren die Übersetzungen vor und nach der Anwendung der KS-Regel identisch, so dass es keinen Raum für eine Veränderung im Qualitätsniveau gibt.



\subsubsection{\label{sec:5.3.3.6}Vergleich der AEM-Scores bei Konditionalsätzen mit vs. ohne ‚Wenn‘ sowie die Korrelation zwischen den AEM-Scores und der Qualität}

Der Vergleich der AEM-Scores vor und nach der Formulierung der Konditionalsätze mit ‚Wenn‘ zeigte sowohl mit TERbase als auch mit hLEPOR nur eine geringe nicht signifikante Verbesserung der AEM-Scores (\figref{fig:05:58}).


\begin{figure}
%\includegraphics[height=.3\textheight]{figures/d3-img022.png}

%\includegraphics[height=.3\textheight]{figures/d3-img022.png}

%\includegraphics[height=.3\textheight]{figures/d3-img022.png}
\includegraphics[width=.4\textwidth]{figures/Abb58.png}
\includegraphics[width=.35\textwidth]{figures/Abb19-legend.png}

\caption{\label{fig:05:58} „Kondi. m. Wenn“ -- Mittelwert der Differenz der AEM-Scores  }
\bspnote{Differenz = AEM-Score nach KS \textit{minus} AEM-Score vor KS}
\end{figure}

Der Mittelwert der Differenz (nach KS $-$ vor KS) im AEM-Score pro Satz lag für TERbase bei ,018 (SD = ,188) und für die hLEPOR bei ,019 (SD = ,124) mit einem 95\%-Konfidenzintervall (Bootstrapping mit 1000 Stichproben) (\figref{fig:05:58}). Durch diese minimalen Unterschiede waren die Differenzen (nach KS $-$ vor KS) in TERbase und hLEPOR nicht signifikant (z (N = 84) = $-$~1,223 / p = ,221) bzw. (z (N = 84) = $-$~1,774 / p = ,076). Wie der Vergleich der Fehlertypen (siehe \sectref{sec:5.3.3.3}) zeigt, war der dominante Fehlertyp (LX.3) das Fehlen der Konjunktion ‚If‘ vor der Anwendung der Regel. In \tabref{tabex:05:41} wird der Fehler LX.3 (vor KS) durch das Einfügen von ‚If‘ (nach KS) korrigiert.


\begin{table}
\begin{tabularx}{\textwidth}{lX}
\lsptoprule
\textbf{Vor-KS} & \textbf{Liegt} die Regelabweichung innerhalb der x-Zone, so bleibt das erste Modul stehen.\\
\tablevspace
HMÜ Bing & \textcolor{lsRed}{XXX} The control deviation \txblue{is} within the x-zone, the first module remains stationary.\\
\midrule
\textbf{Nach-KS} & \textbf{Wenn} die Regelabweichung innerhalb der x-Zone \textbf{liegt}, bleibt das erste Modul stehen.\\
\tablevspace
HMÜ Bing & \textcolor{tmnlpthree}{If} the control deviation \txblue{is} within the x-zone, the first module remains stationary.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:41} Beispiel 41   }
\bspnote{ Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens; \txred{XXX} für ein fehlendes Wort oder Komma.}
\end{table}

Außer diesem Fehler (Fehlen der Konjunktion ‚If‘) waren viele MÜ-Sätze -- vergleichbar mit dem \tabref{fig:05:41} -- in beiden Szenarien identisch. Das kann der Grund für die kleine (insignifikante) Differenz in den AEM-Scores (nach KS $-$ vor KS) gewesen sein.

\subsubsubsection{Korrelation zwischen den Differenzen in den AEM-Scores und der Qualität}

Mithilfe des Spearman-Korrelationstests erwies sich ein signifikanter starker positiver Zusammenhang zwischen den Differenzen der AEM-Scores von TERbase und hLEPOR und der Differenz in der allgemeinen Qualität. \tabref{tab:05:46} demonstriert die Korrelationswerte.


\begin{table}
\begin{tabularx}{\textwidth}{Xrrrr}
\lsptoprule
& \textbf{N} & { \textbf{Signifikanz} } & \textbf{Korrelations-} & \textbf{Stärke}\\
&&\textbf{(p)} & \textbf{koeffizient} & \textbf{der}\\
&&& \textbf{(ρ)}  & \textbf{Korrelation}\\
\midrule
Korrelation zw. Differenz in der allg. Qualität und Differenz des TERbase-Scores (nach KS $-$ vor KS) & { 84} & < ,001 & ,551 & \makecell[tr]{starker\\Zusammen-\\hang}\\
\tablevspace
Korrelation zw. Differenz in der allg. Qualität und Differenz des hLEPOR-Scores (nach KS $-$ vor KS) & { 84} & < ,001 & ,582 & \makecell[tr]{starker\\Zusammen-\\hang}\\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:46} „Kondi. m. Wenn“ -- Korrelation zwischen den Differenzen der AEM-Scores und den Qualitätsdifferenzen }
\bspnote{schwache Korrelation (ρ >=0,1)\hspace{1em}  mittlere Korrelation (ρ >= 0,3)\hspace{1em}  starke Korrelation (ρ >= 0,5)}
\end{table}

Dieses Ergebnis weist darauf hin, dass -- nach der Formulierung der Konditionalsätze mit ‚Wenn‘ -- der Anstieg der Qualität mit einer Verbesserung der Scores der beiden AEMs einherging.

\subsubsection{\label{sec:5.3.3.7}Analyse der dritten Regel -- Validierung der Hypothesen}

Um die vorgestellten Ergebnisse auf die Forschungsfragen der Studie zurückzuführen, listet dieser Abschnitt die zugrunde liegenden Hypothesen der Forschungsfragen zusammen mit einer Zusammenfassung der Ergebnisse der dritten analysierten Regel in tabellarischer Form auf. Für einen schnelleren Überblick steht (+) für eine Verbesserung bzw. einen Anstieg z.~B. im Sinne eines Qualitätsanstiegs, verbesserter AEM-Scores oder eines Anstiegs der Fehleranzahl; ($-$) steht für einen Rückgang; die \txgreen{grüne} Farbe symbolisiert eine signifikante Veränderung; \textit{neg} steht für eine negative Korrelation und \textit{pos} für eine positive Korrelation; <{}<{}>{}> steht für eine starke Korrelation und <> für eine mittlere Korrelation.\footnote{\textrm{Schwache Korrelationen werden in dieser Übersicht nicht angezeigt.}}

\subsubsubsection*{\textbf{Regel 3: Konditionalsätze mit ‚Wenn‘ einleiten}}
\paragraph*{Erster Analysefaktor: Vergleich der Fehleranzahl bei Konditionalsätzen mit vs. ohne ‚Wenn‘}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Gibt es einen Unterschied in der Fehleranzahl nach der Anwendung der KS-Regel im Vergleich zu vor der Anwendung?
\item [H0 --] Es gibt keinen Unterschied in der Fehleranzahl vor vs. nach der Anwendung der KS-Regel.
\item [H1 --] Es gibt einen Unterschied in der Fehleranzahl vor vs. nach der Anwendung der KS-Regel.
\item [Resultat]
\end{description}
\noindent
\parbox[t]{.8\textwidth}{\textbf{Auf Regelebene:}}\\
\noindent
\parbox[t]{.8\textwidth}{
H0 wurde abgelehnt und somit H1 bestätigt.

Die Fehleranzahl sank signifikant, nachdem die Konditionalsätze mit ‚Wenn‘ formuliert wurden.}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.15\textwidth}{\textbf{Anz.F. ($-$)}\\
\\
}}

\medskip
\noindent
\parbox[t]{.8\textwidth}{\textbf{Auf Regel- und MÜ-Systemebene:}}\\
\noindent
\parbox[t]{.8\textwidth}{
Bei Bing und SDL sank die Fehleranzahl signifikant, nachdem die Konditionalsätze mit ‚Wenn‘ formuliert wurden.}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.15\textwidth}{{ \textbf{Bi ($-$)}}

{ \textbf{SD ($-$)}}}}

\medskip
\noindent
\parbox[t]{.8\textwidth}{Bei Lucy und Systran sank ebenfalls die Fehleranzahl, jedoch war der Rückgang nicht signifikant.}
\parbox[t]{.04\textwidth}{}
\parbox[t]{.15\textwidth}{\textbf{Lu ($-$)}

 \textbf{Sy ($-$)}}

\medskip
\noindent
\parbox[t]{.8\textwidth}{In Google war die Fehleranzahl sehr gering: 1 Fehler vor KS und 2 Fehler nach KS.}
\parbox[t]{.04\textwidth}{}
\parbox[t]{.15\textwidth}{\textbf{Go (+)}}
\smallskip
\hrule
\paragraph*{Zweiter Analysefaktor}\hfill
\begin{figure}[H]
\torte{25}{29}{6}{60}
\caption{Aufteilung der Annotationsgruppen auf Regelebene}
\end{figure}

\begin{figure}[H]
\begin{tikzpicture}
\tikzset{every node/.style={font=\scriptsize}};
	\begin{axis}[
	ybar,
	width = \textwidth,
  height = .5\textheight,
	axis lines* = left,
	ylabel = {\%},
	xtick = {3,9,15,21},
	xticklabels = {FF,FR,RF,RR},
	x tick label style ={yshift=-5pt},
% 	xtick=data,
%	x=12pt,
	enlarge x limits={.15},
	ymin=0,
	ymax = 20,
  y filter/.code={\pgfmathparse{#1/120*100}\pgfmathresult},
%	bar shift = 0pt,
%  	bar width=9,
%	nodes near coords,
%	legend pos= north east,
	legend style={at={(0.5,-0.1)},anchor=north},
	legend columns = {-1},
	]
	\addplot+[lsNightBlue]
	coordinates {
	(3,9)
	(9,14)
	(15,0)
	(21,1)
	};
	\addplot+[tmnlpone]
	coordinates {
	(3,1)
	(9,0)
	(15,1)
	(21,22)
	};
	\addplot+[tmnlptwo]
	coordinates {
	(3,5)
	(9,2)
	(15,0)
	(21,17)
	};
	\addplot+[tmnlpthree]
	coordinates {
	(3,4)
	(9,11)
	(15,3)
	(21,6)
	};
	\addplot+[tmnlpfour]
	coordinates {
	(3,6)
	(9,2)
	(15,2)
	(21,14)
	};
	\legend{Bing,Google,Lucy,SDL,Systran}
	\end{axis}
\end{tikzpicture}
\caption{Aufteilung der Annotationsgruppen auf Regel- und MÜ-Systemebene}
\end{figure}
\hrule
\paragraph*{Dritter Analysefaktor: Vergleich der Fehlertypen bei Konditionalsätzen mit vs. ohne ‚Wenn‘}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Beinhaltet die MÜ bestimmte Fehlertypen vor bzw. nach der Anwendung der KS-Regel?
\item [H0 --] Es gibt keinen Unterschied in der Häufigkeit der einzelnen Fehlertypen vor vs. nach der Anwendung der KS-Regel.
\item [H1 --] Es gibt einen Unterschied in der Häufigkeit der einzelnen Fehlertypen vor vs. nach der Anwendung der KS-Regel.
\item [Resultat]
\end{description}
\noindent
\parbox[t]{.8\textwidth}{\textbf{Auf Regelebene:}}\\
\noindent
\parbox[t]{.8\textwidth}{
H1 wurde nur für zwei Fehlertypen bestätigt.

Die Fehleranzahl von LX.3 „Wort ausgelassen“ und LX.4 „Zusätzliches Wort eingefügt“ sanken signifikant, nachdem die Konditionalsätze mit ‚Wenn‘ formuliert wurden.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.15\textwidth}{
\textbf{LX.3 ($-$)}

\textbf{LX.4 ($-$)}\\
\\
}}

\noindent
\parbox[t]{.8\textwidth}{\textbf{Auf Regel- und MÜ-Systemebene:}\\
Nachdem die Konditionalsätze mit ‚Wenn‘ formuliert wurden, sank \textbf{die} Fehleranzahl von LX.3 „Wort ausgelassen“ bei Bing und SDL und von GR.10 „Falsche Wortstellung“ bei Bing signifikant.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.15\textwidth}{
{ \textbf{LX.3 ($-$):}}

{ \textbf{Bi}}{ \textbf{SD}}

{ \textbf{GR.10 ($-$):\\Bi}}
}}

\medskip
\noindent
\parbox[t]{.8\textwidth}{
Alle weiteren Veränderungen waren nicht signifikant.
}

\hrule
\paragraph*{Vierter Analysefaktor: Vergleich der MÜ-Qualität bei Konditionalsätzen mit vs. ohne ‚Wenn‘}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Gibt es einen Unterschied in der Stil- und Inhaltsqualität der MÜ der KS-Stelle nach der Anwendung der KS-Regel im Vergleich zu vor der Anwendung?
\item [H0 --] Es gibt keinen Qualitätsunterschied vor vs. nach der Anwendung der KS-Regel.
\item [H1 --] Es gibt einen Qualitätsunterschied vor vs. nach der Anwendung der KS-Regel.
\item [Resultat]
\end{description}
\noindent
\parbox[t]{.75\textwidth}{\textbf{Auf Regelebene:}}\\
\noindent
\parbox[t]{.75\textwidth}{
H0 wurde abgelehnt und somit H1 bestätigt.

Sowohl die Stil- als auch die Inhaltsqualität stiegen signifikant.}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.2\textwidth}{
{ \textbf{SQ (+)}}

\textbf{CQ (+)}\\
}}

\noindent
\parbox[t]{.75\textwidth}{\textbf{Auf Regel- und MÜ-Systemebene:}}\\
\noindent
\parbox[t]{.75\textwidth}{
Die Stilqualität stieg nur bei Bing signifikant, während die Inhaltsqualität bei Bing und SDL signifikant stieg.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.09\textwidth}{
{ \textbf{SQ (+):}}

 \textbf{Bi}
}}
\colorbox{smGreen}{\parbox[t]{.09\textwidth}{
{ \textbf{CQ (+):}}

{ \textbf{Bi}} \textbf{SD}
}}

\medskip
\noindent
\parbox[t]{.75\textwidth}{Die Qualitätsdifferenzen bei allen anderen Systemen waren (sehr) klein und entsprechend nicht signifikant.}
\hrule
\paragraph*{Fünfter Analysefaktor: Korrelation zwischen den Fehlertypen und der Qualität}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Besteht ein Zusammenhang zwischen der Differenz der Fehleranzahl eines bestimmten Fehlertyps (Fehleranzahl nach KS $-$ vor KS) und der Differenz der Stil- bzw. Inhaltsqualität (Qualität nach KS $-$ vor KS)?
\item [H0 --] Es besteht kein Zusammenhang zwischen der Differenz der Fehleranzahl eines bestimmten Fehlertyps und der Differenz der Stil- bzw. Inhaltsqualität.
\item [H1 --] Es besteht ein Zusammenhang zwischen der Differenz der Fehleranzahl eines bestimmten Fehlertyps und der Differenz der Stil- bzw. Inhaltsqualität.
\item [Resultat]
\end{description}
\noindent
\parbox[t]{.7\textwidth}{\textbf{Auf Regelebene:}}\\
\noindent
\parbox[t]{.7\textwidth}{
H1 wurde nur für zwei Fehlertypen wie folgt bestätigt:

Es bestand ein signifikanter starker negativer Zusammenhang zwischen der Differenz der Fehleranzahl des LX.3 „Wort ausgelassen“ und der Differenz der Stilqualität und Inhaltsqualität.

Zudem bestand ein signifikanter mittlerer negativer Zusammenhang zwischen der Differenz der Fehleranzahl des GR.10 „Falsche Wortstellung“ und der Differenz der Stilqualität.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.25\textwidth}{
\textbf{\textit{neg} }\textbf{LX.3 <{}<{}>{}> SQ}

{ \textbf{\textit{neg}} \textbf{GR.10 <> SQ}}

 \textbf{\textit{neg}} \textbf{LX.3 <{}<{}>{}> CQ}\\
 \\
 \\
 \\
 \\
 \\
}}

\noindent
\parbox[t]{.7\textwidth}{\textbf{Auf Regel- und MÜ-Systemebene:}}\\
\noindent
\parbox[t]{.7\textwidth}{
Bei Bing bestand ein signifikanter starker negativer Zusammenhang zwischen der Differenz der Fehleranzahl des LX.3 „Wort ausgelassen“ und der Differenz der Stil- und Inhaltsqualität.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.25\textwidth}{
\textbf{Bi}

{ \textbf{\textit{neg}} \textbf{LX.3 <{}<{}>{}> SQ}}

 \textbf{\textit{neg}} \textbf{LX.3 <{}<{}>{}> CQ}\\
}}

\medskip
\noindent
\parbox[t]{.7\textwidth}{
Bei SDL besteht ebenfalls ein signifikanter starker negativer Zusammenhang zwischen der Differenz der Fehleranzahl des LX.3 „Wort ausgelassen“ und der Differenz der Stil- und Inhaltsqualität sowie ein signifikanter starker negativer Zusammenhang zwischen der Differenz der Fehleranzahl des GR.10 „Falsche Wortstellung“ und der Differenz der Stilqualität.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.25\textwidth}{
{ \textbf{SD}}

{ \textbf{\textit{neg}} \textbf{LX.3 <{}<{}>{}> SQ} }

{ \textbf{\textit{neg}} \textbf{LX.3 <{}<{}>{}> CQ}}

 \textbf{\textit{neg}} \textbf{GR.10 <{}<{}>{}> SQ}\\
 \\
 \\
}}

\medskip
\noindent
\parbox[t]{.7\textwidth}{Alle weiteren Korrelationen waren nicht signifikant.}

\hrule
\paragraph*{Sechster Analysefaktor: Vergleich der MÜ-Qualität bei Konditionalsätzen mit vs. ohne ‚Wenn‘ auf Annotationsgruppenebene}
\begin{description}[font=\normalfont\bfseries]
  \item [Fragestellung:] Gibt es einen Unterschied in der Stil- und Inhaltsqualität bei den einzelnen Annotationsgruppen nach der Anwendung der KS-Regel im Vergleich zu vor der Anwendung?
  \item [H0 --] Bei den Annotationsgruppen gibt es keinen Qualitätsunterschied vor vs. nach der Anwendung der KS-Regel.
  \item [H1 --] Bei den Annotationsgruppen gibt es einen Qualitätsunterschied vor vs. nach der Anwendung der KS-Regel.
  \item [Resultat]
\end{description}
\noindent
\parbox[t]{.8\textwidth}{
H1 wurde nur für die Gruppe FR bestätigt:

Bei der Annotationsgruppe FR stiegen die Stil- und Inhaltsqualität signifikant, nachdem die Konditionalsätze mit ‚Wenn‘ formuliert wurden.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.15\textwidth}{
\textbf{SQ (+)}

 \textbf{CQ (+)}\\
 \\
}}

\medskip
\noindent
\parbox[t]{.8\textwidth}{
Bei der Annotationsgruppe FF stiegen die Stil- und Inhaltsqualität leicht.
}
\parbox[t]{.04\textwidth}{}
\parbox[t]{.15\textwidth}{
\textbf{SQ (+)}

 \textbf{CQ (+)}
}

\medskip
\noindent
\parbox[t]{.8\textwidth}{
Bei der Annotationsgruppe RR sank die Stilqualität leicht und die Inhaltsqualität stieg minimal.
}
\parbox[t]{.04\textwidth}{}
\parbox[t]{.15\textwidth}{
\textbf{SQ ($-$)}

 \textbf{CQ (+)}
}

\medskip
\noindent
\parbox[t]{.8\textwidth}{
Bei der Annotationsgruppe RF sanken die Stil- und Inhaltsqualität insignifikant.
}
\parbox[t]{.04\textwidth}{}
\parbox[t]{.15\textwidth}{
\textbf{SQ ($-$)}

 \textbf{CQ ($-$)}
 }

\hrule
\paragraph*{Siebter Analysefaktor: Vergleich der AEM-Scores bei Konditionalsätzen mit vs. ohne ‚Wenn‘}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Gibt es einen Unterschied in den AEM-Scores von TERbase bzw. hLEPOR nach der Anwendung der KS-Regel im Vergleich zu vor der Anwendung?
\item [H0 --] Es gibt keinen Unterschied in den AEM-Scores vor vs. nach der Anwendung der KS-Regel.
\item [H1 --] Es gibt einen Unterschied in den AEM-Scores vor vs. nach der Anwendung der KS-Regel.
\item [Resultat]
\end{description}
\noindent
\parbox[t]{.75\textwidth}{
H0 wurde nicht abgelehnt und somit konnte H1 nicht bestätigt werden.

Die AEM-Scores von TERbase und hLEPOR stiegen nur leicht nachdem die Konditionalsätze mit ‚Wenn‘ formuliert wurden.
}
\parbox[t]{.04\textwidth}{}
\parbox[t]{.2\textwidth}{
\textbf{TERbase (+)\\hLEPOR (+)}\\
\\
\\
}

\smallskip
\hrule
\paragraph*{Achter Analysefaktor: Korrelation zwischen den Differenzen der AEM-Scores und der Qualität}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Besteht ein Zusammenhang zwischen der Differenz der AEM-Scores von TERbase bzw. hLEPOR (Mittelwert der AEM-Scores nach KS $-$ vor KS) und der Differenz der allgemeinen Qualität (Qualität nach KS $-$ vor KS)?
\item [H0 --] Es besteht kein Zusammenhang zwischen der Differenz der AEM-Scores und der Differenz der allgemeinen Qualität.
\item [H1 --] Es besteht ein Zusammenhang zwischen der Differenz der AEM-Scores und der Differenz der allgemeinen Qualität.
\end{description}
\noindent
\parbox[t]{.7\textwidth}{
H0 wurde abgelehnt und somit H1 bestätigt.

Es bestand ein signifikanter starker positiver Zusammenhang zwischen den Differenzen der Scores der beiden AEMs (TERbase und hLEPOR) und der Differenz der allgemeinen Qualität.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.25\textwidth}{
\textbf{\textit{pos}} \textbf{TERbase <{}<{}>{}> Q}

 \textbf{\textit{pos}} \textbf{hLEPOR <{}<{}>{}> Q}\\
 \\
 \\
}}


\subsection{VIERTE REGEL: Eindeutige pronominale Bezüge verwenden}
\label{sec:5.3.4}
\subsubsection{\label{sec:5.3.4.0}Überblick}

%In \tabref{tab:05:47}
Im Folgenden wird die KS-Regel „Eindeutige pronominale Bezüge verwenden“ kurz beschrieben.\footnote{\textrm{Die für diese Regel relevanten Kontraste im Sprachenpaar DE-EN sind unter \sectref{sec:4.4.2.3} erörtert.} } Zudem wird zusammenfassend und anhand von Beispielen demonstriert, wie die Regel bei der Analyse angewendet wurde. Anschließend wird die Aufteilung der Testsätze im Datensatz dargestellt:

\begin{description}[font=\normalfont\bfseries]
\item [Beschreibung der KS-Regel:] \textbf{Eindeutige pronominale Bezüge verwenden} (tekom-Regel-Nr. S 102)

Nach dieser Regel (\citealt{tekom2013}: 60) sollen die Pronomen vermieden werden, wenn sie mehrdeutig sein könnten. Anstelle des Pronomens soll das Bezugswort wiederholt werden, damit der Bezug eindeutig erkennbar wird.

Begründung: Der Leser eines technischen Dokuments ist in der Regel weniger mit der Thematik vertraut als der Autor (ebd.: 61).

\item[Umsetzungsmuster:]
~\\
\textbf{Vor KS:} Der Satz beinhaltet ein Pronomen.\\
\textbf{Nach KS:} Das Pronomen wird durch das Nomen ersetzt.

\item[KS-Stelle]
~\\
\textbf{Vor KS:} das Pronomen (Personalpronomen und Demonstrativpronomen)\\
\textbf{Nach KS:} das Nomen bzw. das Demonstrativpronomen und das Nomen (inkl. damit verbundener Fehler in der Wortstellung)

\item[Beispiele]
~\\
\textit{Je früher ein Fleck behandelt wird, umso größer ist die Wahrscheinlichkeit, \txgray{ihn} rückstandslos zu entfernen.}

\textit{Je früher ein Fleck behandelt wird, umso größer ist die Wahrscheinlichkeit, \txgray{den Fleck} rückstandslos zu entfernen.}
~\\
\textit{Sofern auf der Oberfläche alte Kleberreste anhaften, sind \txgray{diese} vollständig zu entfernen.}

\textit{Sofern auf der Oberfläche alte Kleberreste anhaften, sind \txgray{diese Kleberreste} vollständig zu entfernen.}

\item[Aufteilung der Testsätze:]
Die im Datensatz abgedeckten Pronomen sind 9 Personalpronomen in verschiedenen Kasus und 15 Demonstrativpronomen. Diese Verteilung der beiden Pronomenarten spiegelt deren Verteilung im Korpus wider, denn die Demonstrativpronomen kommen im Vergleich zu den Personalpronomen häufiger vor.

\end{description}

%\multicolumn{2}{p{6cm}}{\label{bkm:Ref36848468}Eckdaten der vierten Regel „Eindeutige pronominale Bezüge verwenden“}\\

Im Folgenden werden die Ergebnisse der einzelnen Analysefaktoren präsentiert.

\subsubsection{\label{sec:5.3.4.1}Vergleich der Fehleranzahl vor vs. nach der Verwendung von pronominalen Bezügen}

Die Fehleranzahl sank minimal um 9,3~\% von 43 Fehlern im Falle der Verwendung von Pronomen (M = ,36 / SD =,577 / N = 120) auf 39 Fehler bei der Verwendung von pronominalen Bezügen (M = ,33 / SD = ,610 / N = 120) (\figref{fig:05:59} und \figref{fig:05:60}). Der Mittelwert der Differenz (nach KS $-$ vor KS) der Fehleranzahl pro Satz lag somit bei $-$~,03 (SD = ,697) mit einem 95\%\nobreakdash-Konfidenzintervall zwischen einem Minimum von $-$~,16 (SD = ,577) und einem Maximum von ,09 (SD = ,803) (Bootstrapping mit 1000 Stichproben). Entsprechend war die Differenz (nach KS $-$ vor KS) der Fehleranzahl nicht signifikant (z~(N~= 120) = $-$~,503 / p = ,615).


\begin{figure}

%\includegraphics[height=.3\textheight]{figures/d3-img023.png}



%\includegraphics[height=.3\textheight]{figures/d3-img023.png}



%\includegraphics[height=.3\textheight]{figures/d3-img023.png} &  &
%\includegraphics[height=.3\textheight]{figures/d3-img024.png}



%\includegraphics[height=.3\textheight]{figures/d3-img024.png}

%\textbf{,22,44}

%\textbf{,26,46}



%\includegraphics[height=.3\textheight]{figures/d3-img024.png}\\
\captionsetup{width=.45\textwidth}
\begin{floatrow}
\ffigbox[.5\textwidth]{\caption{„Pronom. Bezüge verw.“ -- Fehlersumme vor vs. nach KS}
\label{fig:05:59}}{
\begin{tikzpicture}
	\begin{axis}[
	ybar,
	ymin = 0,
	ymax = 125,
	axis lines* = left,
	nodes near coords,
%         nodes near coords align = vertical,
  legend style={at={(0.5,-0.2)},anchor=north,cells={align=left}},
  xtick=\empty,
  width = .45\textwidth,
  enlarge x limits = .5
	]
	\addplot+[tmnlpone]
	coordinates{
	(1,43)
	};
	\addplot+[tmnlpthree]
	coordinates{
	(2,39)
	};
	\legend{Anzahl der  fehler\\innerh. KS vor KS,Anzahl der Fehler\\innerh. KS nach KS}
	\end{axis}
\end{tikzpicture}
}
\ffigbox[.45\textwidth]{\caption{„Pronom. Bezüge verw.“ -- Mittelwert der Fehleranzahl pro Satz vor vs. nach KS}\label{fig:05:60}}{
\includegraphics[width=.25\textwidth]{figures/Abb60.png}
\includegraphics[width=.4\textwidth]{figures/Abb21-legend.png}
}
\end{floatrow}

\end{figure}

Ein Vergleich der Annotationsgruppen RF und FR zeigt, dass relativ viele Fehler bei der Verwendung der Demonstrativpronomen (24~\%) im Vergleich zu den Personalpronomen (7~\%) auftraten und mit der Umsetzung der KS-Regel eliminiert wurden (\tabref{tab:05:48}).


\begin{table}
\begin{tabularx}{\textwidth}{Xll}

\lsptoprule
& \textbf{RF} & \textbf{FR}\\
\midrule
\textbf{Demonstrativpronomen}

Anz. d. Ausgangssätze 15;

bei 5 MÜ-Systemen = 15 * 5 = 75 MÜ & {8 MÜ}

 (11~\%) & \cellcolor{lsLightGray}{18 MÜ}

 (24~\%)\\
\textbf{Personalpronomen}

Anz. d. Ausgangssätze 9;

bei 5 MÜ-Systemen = 9 * 5 = 45 MÜ & {6 MÜ}

 (13~\%) & {3 MÜ}

 (7~\%)\\

\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:48}Daten der untersuchten Pronomen   }
\end{table}

Wie \tabref{tab:05:48} zeigt, war die Annotationsgruppe FR größer als RF. Dies führte zu der allgemeinen Abnahme der Fehleranzahl nach der Regelanwendung. Dennoch war die Annotationsgruppe RF relativ breit vertreten, daher ist die Differenz in der Fehleranzahl nicht hoch. Unter \sectref{sec:5.3.4.2} werden die Annotationsgruppen unter die Lupe genommen.

\subsubsubsection{Vergleich der Fehleranzahl auf Regel- und MÜ-Systemebene}

Eine genauere Betrachtung der einzelnen MÜ-Systeme zeigt, dass die Systeme sehr unterschiedlich auf die KS-Regel reagierten:

Die Fehleranzahl bei dem NMÜ-System Google Translate stieg signifikant Mdiff = 0,167 (z (N = 24) = $-$~2,000 / p = ,046), allerdings wäre eine bloße Betrachtung der quantitativen Daten in diesem Fall irreführend, denn Google Translate konnte in 83~\% der Fälle (20 von 24 Sätzen) eine korrekte MÜ sowohl für das Pronomen (vor KS) als auch für den pronominalen Bezug (nach KS) liefern (siehe \sectref{sec:5.3.4.2}). Nur in 17~\% der Sätze (4 von 24) stieg die Fehleranzahl (insgesamt +4 Fehler).


\begin{figure}

%\textbf{$-$ 37,5~\%}

%\textbf{$-$ 13,3~\%}

%\textbf{$-$ 25,0~\%}



%\includegraphics[height=.3\textheight]{figures/d3-img058.png}\\
%{\bfseries\itshape}

%\textbf{\textit{+~200~\%}}

%\textbf{\textit{0~\%}}
 %\textbf{\textit{Signifikante Differenz vor vs. nach KS} }


%\includegraphics[height=.3\textheight]{figures/d3-img023.png}\\
\begin{tikzpicture}
	\begin{axis}[
	ybar,
	ymin = 0,
	ymax = 15,
	axis lines* = left,
	nodes near coords,
  legend style={at={(0.5,-0.2)},anchor=north},
  xticklabels = {Bing,Google,Lucy,SDL,Systran},
  xtick=data,
  ylabel = {Summe},
  extra description/.code={
            \node at (axis cs:-.2, 8)[anchor=west] {0\%};
						\node at (axis cs:.5, 8)[anchor=west] {\bfitul{$+$ 200\%}};
						\node at (axis cs:1.5, 10)[anchor=west] {$-$ 37,5 \%};
						\node at (axis cs:2.5, 17)[anchor=west] {$-$ 13,3 \%};
						\node at (axis cs:3.5, 14)[anchor=west] {$-$ 25,0 \%};
						}
	]
	\addplot+[tmnlpone]
	coordinates{
	(0,6)
	(1,2)
	(2,8)
	(3,15)
	(4,12)
	};
	\addplot+[tmnlpthree]
	coordinates{
	(0,6)
	(1,6)
	(2,5)
	(3,13)
	(4,9)
	};
	\legend{Anzahl der  fehler innerh. KS vor KS,Anzahl der Fehler innerh. KS nach KS}
	\end{axis}
\end{tikzpicture}
\caption{\label{fig:05:61}„Pronom. Bezüge verw.“ -- Summe der Fehleranzahl vor vs. nach KS bei den einzelnen MÜ-Systemen   }
\bspnote{\bfitul{Signifikante Differenz vor vs. nach KS}}
\end{figure}

Auf der anderen Seite blieb die Fehleranzahl bei dem HMÜ-System Bing unverändert und sank bei den weiteren drei Systemen: RBMÜ-System Lucy (Mdiff = $-$~,125); HMÜ-System Systran (Mdiff = $-$~,125); SMÜ-System SDL\textbf{ }(Mdiff = $-$~,083). Dieser Rückgang erwies sich als insignifikant.

\tabref{tabex:05:42} zeigt einen der wenigen Fälle, in denen Google Translate nur bei der Verwendung eines pronominalen Bezugs (nach KS) eine falsche Übersetzung lieferte, wobei Lucy (siehe \tabref{tabex:05:44}) und Bing (siehe \tabref{tabex:05:45}) im selben Beispielsatz das Pronomen (vor KS) falsch und den pronominalen Bezug (nach KS) richtig übersetzten.


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & Nur Elektrofachkräfte dürfen Zugang zur Elektrik der Maschine haben und \textbf{diese} warten.\\
\tablevspace
GNMÜ & Only qualified electricians are allowed to access to the machine's electrical system and maintain \txblue{it}.\\
\midrule
\textbf{Nach-KS} & Nur Elektrofachkräfte dürfen Zugang zur Elektrik der Maschine haben und \textbf{die Maschine} warten.\\
\tablevspace
GNMÜ & Only qualified electricians are allowed to access to the machine's electrical system and \txred{the machine} maintain.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:42}Beispiel 42 }
\bspnote{ Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

In \tabref{tabex:05:42} handelt es sich um einen Wortstellungsfehler. Mehr zu den Fehlertypen und potenziellen Gründen dahinter wird unter \sectref{sec:5.3.4.3} diskutiert.

\subsubsection{\label{sec:5.3.4.2}Aufteilung der Annotationsgruppen}

Wie \figref{fig:05:62} veranschaulicht, war der Anteil der Annotationsgruppe RR besonders hoch (57,5~\%). Bei 17,5~\% der Sätze war die MÜ bei der Verwendung des Pronomens falsch und wurde nach der Verwendung des pronominalen Bezugs korrigiert (Gruppe FR).


\begin{figure}

%\includegraphics[height=.3\textheight]{figures/d3-img012.png}
%{\bfseries}



%\includegraphics[height=.3\textheight]{figures/d3-img059.png}
% 62
\torte{16}{21}{14}{69}
\caption{\label{fig:05:62}„Pronom. Bezüge verw.“ -- Aufteilung der Annotationsgruppen   }
\end{figure}

Die beiden weiteren Annotationsgruppen (FF und RF) waren ähnlich klein. Ein Anteil von nur 11,7~\% bei der Gruppe RF besagt, dass eine Falschübersetzung der Sätze erst nach der Anwendung der KS-Regel eine relative Seltenheit war.

\subsubsubsection{Vergleich der Aufteilung der Annotationsgruppen auf Regel- und MÜ-Systemebene}

Der dominante Anteil der Annotationsgruppe RR (richtig sowohl vor als auch nach der Anwendung der KS-Regel) ist bei allen MÜ-Systemen ohne Ausnahme zu sehen. Eine genaue Betrachtung der Gruppe RR (\figref{fig:05:63}) auf MÜ-Systemebene zeigt, dass das NMÜ-System Google Translate mit 83~\% seiner Übersetzungen auf den ersten Platz kommt; gefolgt vom RBMÜ-System Lucy mit 67~\%; dem HMÜ-System Bing mit 54~\%; dem HMÜ-System Systran mit 50~\% und zum Schluss mit dem SMÜ-System SDL mit 33~\%.


\begin{figure}

%\includegraphics[height=.3\textheight]{figures/d3-img060.png}

%  \textbf{8\%}   \textbf{8\%}   \textbf{29\% 21\%}            \textbf{25\%}          \textbf{21\%}  \textbf{25\% 17\%}            \textbf{21\%}  \textbf{8\%}    \textbf{4\%}   \textbf{13\% 13\%}           \textbf{54\%}  \textbf{83\% 67\% 33\%}  \textbf{50\%}



%\includegraphics[height=.3\textheight]{figures/d3-img026.png}\\
\begin{tikzpicture}
\tikzset{every node/.style={font=\scriptsize}};
	\begin{axis}[
	ybar,
	width = \textwidth,
	axis lines* = left,
	ylabel = {Anzahl},
	xtick = {3,9,15,21},
	xticklabels = {FF,FR,RF,RR},
  x tick label style ={yshift=-5pt},
	xtick=data,
  xlabel={Annotationsgruppe},
	ymin=0,
	ymax = 25,
%	bar shift = 0pt,
  bar width=9,
	nodes near coords,
%	legend pos= north east,
	legend style={at={(0.5,-0.15)},anchor=north},
	legend columns = {-1},
	extra description/.code={
	\node at (axis cs:1.3,4)[anchor = west]{1,7\%};
	\node at (axis cs:1.5,-.5)[anchor = west]{8\%};
	\node at (axis cs:2.2,4)[anchor = west]{1,7\%};
	\node at (axis cs:2.3,-.5)[anchor = west]{8\%};
	\node at (axis cs:3.1,9)[anchor = west]{5,8\%};
	\node at (axis cs:3.1,-.5)[anchor = west]{29\%};
	\node at (axis cs:4,7)[anchor = west]{4,2\%};
	\node at (axis cs:4,-.5)[anchor = west]{21\%};
	\node at (axis cs:6.8,8)[anchor = west]{5,6\%};
	\node at (axis cs:6.8,-.5)[anchor = west]{25\%};
	\node at (axis cs:8.3,7)[anchor = west]{4,2\%};
	\node at (axis cs:8.3,-.5)[anchor = west]{21\%};
	\node at (axis cs:9.2,8)[anchor = west]{5,0\%};
	\node at (axis cs:9.2,-.5)[anchor = west]{25\%};
  \node at (axis cs:10.1,6)[anchor=west]{3,3\%};
  \node at (axis cs:10.1,-.5)[anchor=west]{17\%};
  \node at (axis cs:12.7,7)[anchor=west]{4,2\%};
  \node at (axis cs:12.7,-.5)[anchor=west]{21\%};
  \node at (axis cs:13.6,4)[anchor=west]{1,7\%};
  \node at (axis cs:13.7,-.5)[anchor=west]{8\%};
  \node at (axis cs:14.3,3)[anchor=west]{0,8\%};
  \node at (axis cs:14.4,-.5)[anchor=west]{4\%};
	\node at (axis cs:15,5)[anchor = west]{2,5\%};
	\node at (axis cs:15.1,-.5)[anchor = west]{13\%};
  \node at (axis cs:16,5)[anchor=west]{2,5\%};
  \node at (axis cs:16,-.5)[anchor=west]{13\%};
	\node at (axis cs:18.4,15)[anchor = west]{10,8\%};
	\node at (axis cs:18.4,-.5)[anchor = west]{54\%};
	\node at (axis cs:19.3,22)[anchor = west]{16,7\%};
	\node at (axis cs:19.4,-.5)[anchor = west]{83\%};
	\node at (axis cs:20.3,18)[anchor = west]{13,3\%};
	\node at (axis cs:20.3,-.5)[anchor = west]{67\%};
	\node at (axis cs:21,10)[anchor = west]{6,7\%};
	\node at (axis cs:21.2,-.5)[anchor = west]{33\%};
	\node at (axis cs:22,14)[anchor = west]{10,0\%};
	\node at (axis cs:22,-.5)[anchor = west]{50\%};
	}
	]
	\addplot+[lsNightBlue]
	coordinates {
	(3,0)
	(9,6)
	(15,5)
	(21,13)
	};
	\addplot+[tmnlpone]
	coordinates {
	(3,2)
	(9,0)
	(15,2)
	(21,20)
	};
	\addplot+[tmnlptwo]
	coordinates {
	(3,2)
	(9,5)
	(15,1)
	(21,16)
	};
	\addplot+[tmnlpthree]
	coordinates {
	(3,7)
	(9,6)
	(15,3)
	(21,8)
	};
	\addplot+[tmnlpfour]
	coordinates {
	(3,5)
	(9,4)
	(15,3)
	(21,12)
	};
	\legend{Bing,Google,Lucy,SDL,Systran}
	\end{axis}
\end{tikzpicture}

\caption{\label{fig:05:63}„Pronom. Bezüge verw.“ -- Aufteilung der Annotationsgruppen bei den einzelnen MÜ-Systemen   }
\bspnote{Die oben angezeigten Prozentzahlen sind für alle Systeme, d. h. systemübergreifend, (N = 120) berechnet.

Die untenstehenden Prozentzahlen sind auf Systemebene (N = 24) berechnet.}
\end{figure}

SDL verzeichnete den niedrigsten Anteil bei der Gruppe RR und gleichzeitig den höchsten Anteil bei der Gruppe FF (\figref{fig:05:63}). Da dieses System rein statistisch arbeitet, zeigt dieses Ergebnis, dass ein Großteil der Testsätze selten bzw. nicht in den Trainingsdaten vorkommt.

\subsubsection{\label{sec:5.3.4.3}Vergleich der Fehlertypen vor vs. nach der Verwendung von pronominalen Bezügen}

Nach der Verwendung von pronominalen Bezügen verändert sich die Anzahl zweier Fehlertypen deutlich, und zwar stieg die Fehleranzahl bei Fehlertyp LX.6 „Lexik -- Konsistenzfehler“ und sank bei Fehlertyp SM.11 „Semantik -- Verwechslung des Sinns“. Beide Veränderungen erwiesen sich als signifikant p = ,013 beim LX.6 bzw. p = ,027 beim SM.11 (N = 120).


\begin{figure}

%\includegraphics[height=.3\textheight]{figures/d3-img061.png}

%\textbf{\textit{$-$ 58~\%}}

%\textbf{\textit{+++}}



%\includegraphics[height=.3\textheight]{figures/d3-img027.png}
%} &

%\includegraphics[height=.3\textheight]{figures/d3-img013.png}



%\includegraphics[height=.3\textheight]{figures/d3-img013.png} & vor KS
% 64
\pgfplotstableread{
1 0
2 0
3 0
4 0
5 5
6 1
7 0
8 0
9 0
10 0
11 0
12 8
13 0
14 0
15 0
16 0
17 10
18 9
19 7
20 11
21 19
22 8
23 2
24 2
25 0
26 0
}\datatable
\smbars[extra description/.code={
\node at (axis cs:10.5,10)[anchor = west]{\bfitul{+++}};
\node at (axis cs:21.2,18)[anchor = west]{\bfitul{$-$ 58\%}};
}]{}
\caption{\label{fig:05:64}„Pronom. Bezüge verw.“ -- Summe der Fehleranzahl der einzelnen Fehlertypen vor vs. nach KS   }
\bspnote{*Die X-Achse ist folgendermaßen zu lesen: Jeder Fehlertyp wird anhand von zwei Balken abgebildet. Der erste Balken repräsentiert die Summe der Fehler \textit{vor KS} und der zweite die Summe der Fehler \textit{nach KS}, somit steht z.~B. „OR\_1.v“ für „OR\_1: orthografischer Fehler Nr. 1“ und „v: vor KS“; „OR\_1.n“ wäre entsprechend das Pendant zu „OR\_1.v“ für das nach-KS-Szenario („n“). \\
**\bfitul{Signifikante Differenz vor vs. nach KS}\\
OR.1: Orthografie -- Zeichensetzung\\
OR.2: Orthografie -- Großschreibung\\
LX.3: Lexik -- Wort ausgelassen\\
LX.4: Lexik -- Zusätzliches Wort eingefügt\\
LX.5: Lexik -- Wort unübersetzt geblieben (auf DE wiedergegeben)\\
LX.6: Lexik -- Konsistenzfehler\\
GR.7: Grammatik -- Falsche Wortart / Wortklasse\\
GR.8: Grammatik -- Falsches Verb (Zeitform, Komposition, Person)\\
GR.9: Grammatik -- Kongruenzfehler (Agreement)\\
GR.10: Grammatik -- Falsche Wortstellung\\
SM.11: Semantik -- Verwechslung des Sinns\\
SM.12: Semantik -- Falsche Wahl\\
SM.13: Semantik -- Kollokationsfehle}
\end{figure}

Bei der Umsetzung dieser KS-Regel wird anstatt des Pronomens, der Pronominalbezug verwendet, entsprechend wird oft ein Nomen, das z.~B. im Hauptsatz vorkommt, im Nebensatz wiederholt. Die Systeme übersetzten jedoch die zweite Instanz des Nomens in manchen Fällen anders, wodurch der Fehlertyp LX.6 „Lexik -- Konsistenzfehler“ nach der Anwendung der KS-Regel (Mv = -- / SDv = -- / Mn = ,07 / SDn = ,250 / N = 120) auftrat. \tabref{tabex:05:43} veranschaulicht diese Problematik.


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & Fettreste müssen vollständig abgewaschen werden, da sich \textbf{diese} ansonsten in der Pfanne einbrennen können.\\
\tablevspace
SMÜ SDL & Grease residue must be completely washed off as \txblue{it} can otherwise burn in the pan.\\
\midrule
\textbf{Nach-KS} & Fettreste müssen vollständig abgewaschen werden, da sich \textbf{diese Reste} ansonsten in der Pfanne einbrennen können.\\
\tablevspace
SMÜ SDL & Grease residue must be completely washed off as \txblue{this} \txred{remains} can otherwise burn in the pan.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:43} Beispiel 43 }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

In \tabref{tabex:05:43} konnte das System das Pronomen (vor KS) problemlos übersetzen, während der Pronominalbezug (nach KS) abweichend übersetzt wurde. In der Regel führen die Unternehmen Terminologiedatenbanken und integrieren sie in ihre implementierten MÜ-Systeme, so dass ein Konsistenzfehler dieser Art (vgl. \citealt{Mertin2006}: 249) nur bei neuen bzw. nicht eingepflegten Termini vorkommen würde.

Auf der anderen Seite entstand bei der Verwendung von Pronomen (vor KS) ein semantisches Problem, nämlich die Verwechslung ihres Sinns; ein Fehler, der -- trotz der Forschungsfortschritte -- auf der weiterhin bestehenden Schwierigkeit einer Koreferenzauflösung (d.~h. Identifizierung der Entität, auf die sich die Koreferenz bzw. das Pronomen bezieht) beruht \citep{Ng2017}. Dieser Fehler kam insbesondere bei der Übersetzung von Demonstrativpronomen (‚dies‘ und ‚diese‘) vor. Nach der Verwendung des Pronominalbezugs sank entsprechend die Fehleranzahl des Fehlertyps SM.11 „Semantik – Verwechslung des Sinns“ von 19 auf 8 Fehler (-~57,9~\% / Mv = ,16 / SDv = ,367 / Mn = ,07 / SDn = ,250 / N = 120).


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & Nur Elektrofachkräfte dürfen Zugang zur Elektrik der Maschine haben und \textbf{diese} warten.\\
\tablevspace
RBMÜ Lucy & Only qualified electricians are allowed to\textbf{ }access to the machine's electrical system and maintain \txred{these}.\\
\midrule
\textbf{Nach-KS} & Nur Elektrofachkräfte dürfen Zugang zur Elektrik der Maschine haben und \textbf{die Maschine} warten.\\
\tablevspace
RBMÜ Lucy & Only qualified electricians are allowed to access to the machine's electrical system and maintain \txblue{the machine}.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:44}Beispiel 44   }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

In \tabref{tabex:05:44} wurde der Sinn des Demonstrativpronomens ‚diese‘ vom System nicht richtig erkannt. Auf der anderen Seite wurde der Pronominalbezug korrekt übersetzt.

\subsubsubsection{Vergleich der Fehlertypen auf Regel- und MÜ-Systemebene}

Eine genauere Untersuchung der Fehlertypen bei den verschiedenen MÜ-Systemen zeigt, dass gar kein Fehlertyp sich bei einem bestimmten System signifikant veränderte. Auch die Differenzen des Fehlertyps LX.6 „Lexik -- Konsistenzfehler“ und Fehlertyp SM.11 „Semantik -- Verwechslung des Sinns“ waren bei keinem der analysierten Systeme signifikant.


\begin{figure}
%\includegraphics[height=.3\textheight]{figures/d3-img062.png}



%\includegraphics[height=.3\textheight]{figures/d3-img026.png}\\
\begin{tikzpicture}
\tikzset{every node/.style={font=\scriptsize}};
	\begin{axis}[
	xbar,
	width = \textwidth,
	height = .83\textheight,
	axis lines* = left,
	xlabel = {Summe},
	ytick = {1,2,3,...,10},
	yticklabels = {IN\_LX\_3.v,
	IN\_LX\_3.n,
	IN\_LX\_6.v,
	IN\_LX\_6.n,
	IN\_GR\_9.v,
	IN\_GR\_9.n,
	IN\_GR\_10.v,
	IN\_GR\_10.n,
	IN\_SM\_11.v,
	IN\_SM\_11.n
	},
%	x tick label style={rotate=60,anchor=east,font=\scriptsize},
	enlarge y limits={.044},
	xmin=0,
	xmax =6,
%	bar shift = 1pt,
  	bar width=4,
	nodes near coords,
	legend pos = south east,
	reverse legend,
%	legend style={at={(0.5,-0.1)},anchor=north},
%	legend columns = {-1},
	]
	\addplot+[tmnlpone]
	coordinates {
	(1,1)
	(0,2)
	(0,3)
	(3,4)
	(2,5)
	(0,6)
	(0,7)
	(1,8)
	(2,9)
	(1,10)
	};
	\addplot+[lsLightOrange]
	coordinates {
	(0,1)
	(0,2)
	(0,3)
	(1,4)
	(2,5)
	(4,6)
	(0,7)
	(1,8)
	(0,9)
	(0,10)
	};
	\addplot+[smGreen]
	coordinates {
	(0,1)
	(0,2)
	(0,3)
	(0,4)
	(2,5)
	(3,6)
	(0,7)
	(1,8)
	(6,9)
	(1,10)
	};
	\addplot+[tmnlpthree]
	coordinates {
	(4,1)
	(1,2)
	(0,3)
	(4,4)
	(3,5)
	(2,6)
	(3,7)
	(4,8)
	(5,9)
	(1,10)
	};
	\addplot+[lsRed]
	coordinates {
	(0,1)
	(0,2)
	(0,3)
	(0,4)
	(1,5)
	(0,6)
	(4,7)
	(4,8)
	(6,9)
	(5,10)
	};
	\legend{Bing,Google,Lucy,SDL,Systran}
	\end{axis}
\end{tikzpicture}

\caption{\label{fig:05:65}„Pronom. Bezüge verw.“ -- Summe der Fehleranzahl der Fehlertypen vor vs. nach KS bei den einzelnen MÜ-Systemen   }
\bspnote{*Die Balken zeigen die Summe der Fehleranzahl bei jedem Fehlertyp, wobei „v“ für die Summe „vor der Anwendung der KS-Regel“ und „n“ für die Summe „nach der Anwendung der KS-Regel“ steht. Jeder Fehlertyp wird erst für alle Systeme für das Szenario „vor KS“ abgebildet, danach folgt derselbe Fehlertyp wieder für alle Systeme für das Szenario „nach KS“.

**Um die Übersichtlichkeit und Lesbarkeit der Grafik zu erhöhen, wurden in der Grafik die Fehlertypen ausgeblendet, die 0 oder nur einmal bei \textit{allen} MÜ-Systemen vorkamen: In dieser Grafik kamen die Fehlertypen 1, 2, 4, 5, 7, 8 und 13 bei gar keinem MÜ-System vor. Zudem kam der Fehlertyp 12 nur einmal jeweils bei 3 MÜ-Systemen vor.}
\end{figure}

Wesentliche (nicht signifikante) Veränderungen gab es jedoch bei zwei Systemen: Bei SDL stieg die Fehleranzahl vom Fehlertyp LX.6 „Lexik -- Konsistenzfehler“ von 0 auf 4 Fehler. Dies kann bei einem rein SMÜ-System auf das Nichtvorhandensein der Segmente in den Trainingsdaten zurückgeführt werden. Bei Lucy nahm die Fehleranzahl des Fehlertyps SM.11 „Semantik -- Verwechslung des Sinns“ von 6 auf 1 Fehler ab. Hierbei zeigte das RBMÜ-System eine Schwäche beim Übersetzen von Demonstrativpronomen, denn alle fünf korrigierten Fehler der Demonstrativpronomen waren für das System ambig.

\subsubsection{\label{sec:5.3.4.4}Vergleich der MÜ-Qualität vor vs. nach der Verwendung von pronominalen Bezügen sowie die Korrelation zwischen den Fehlertypen und der Qualität}

Nach der Verwendung der pronominalen Bezüge gab es einen kleinen insignifikanten Rückgang bei der Stilqualität gekoppelt mit einem kleinen insignifikanten Anstieg bei der Inhaltsqualität (\figref{fig:05:66}):\footnote{\textrm{Definitionen der Qualität unter \sectref{sec:4.4.5.1}.}}

Die Stilqualität sank um 1,5~\% (Mv = 4,04 / SDv = ,495 / Mn = 3,98 / SDn = ,401 / N = 77). Die Inhaltsqualität stieg um 2,3~\% (Mv = 4,43 / SDv = ,554 / Mn = 4,53 / SDn = ,494 / N = 77). Der Mittelwert der Differenz (nach KS $-$ vor KS) der vergebenen Qualitätspunkte pro Satz lag für die Stilqualität bei $-$~,063 (SD = ,460) mit einem 95\%\nobreakdash-Konfidenzintervall zwischen einem Minimum von $-$~,168 und einem Maximum von ,041 und für die Inhaltsqualität bei ,101 (SD = ,584) mit einem 95\%\nobreakdash-Konfidenzintervall zwischen einem Minimum von $-$~,032 und einem Maximum von ,233 (Bootstrapping mit 1000 Stichproben) (\figref{fig:05:67}). Die Differenzen (nach KS $-$ vor KS) in der Stil- und Inhaltsqualität waren nicht signifikant (z (N = 77) = $-$~1,333 / p = ,183) bzw. (z (N = 77) = $-$~1,719 / p = ,086).


\begin{figure}

%\textbf{4,424,65}



%\includegraphics[height=.3\textheight]{figures/d3-img029.png}

%\textbf{3,934,16}

%\textbf{3,894,07}

%\textbf{4,314,56}



%\includegraphics[height=.3\textheight]{figures/d3-img030.png}



%\includegraphics[height=.3\textheight]{figures/d3-img029.png} &  &
%\includegraphics[height=.3\textheight]{figures/d3-img017.png}




%\includegraphics[height=.3\textheight]{figures/d3-img017.png}


%\includegraphics[height=.3\textheight]{figures/d3-img017.png}
\captionsetup{width=.45\textwidth}
\begin{floatrow}
\ffigbox[.5\textwidth]{\caption{„Pronom. Bezüge verw.“ -- Mittelwerte der Qualität vor und nach KS}\label{fig:05:66}}{
\includegraphics[width=.25\textwidth]{figures/Abb66.png}
\includegraphics[width=.2\textwidth]{figures/Abb15-legend.png}
}
\ffigbox[.45\textwidth]{\caption{„Pronom. Bezüge verw.“ -- Mittelwert der Qualitätsdifferenzen}\label{fig:05:67}}{
\includegraphics[width=.25\textwidth]{figures/Abb16-legend.png}
\includegraphics[width=.3\textwidth]{figures/Abb67.png}
}
\end{floatrow}

\end{figure}

Grundsätzlich ist ein solches Ergebnis vorstellbar, denn die Wiederholung des Bezugs unterstützt durch eine höhere Eindeutigkeit die MÜ. Dies wiederum sorgt für eine bessere Verständlichkeit des MÜ-Outputs. Gleichzeitig wird auf stilistischer Ebene der MÜ-Output durch die Wiederholung des Bezugs beeinträchtigt.

In \tabref{tabex:05:45} wurde der Kongruenzfehler im Pronomen ‚them‘ nach der Anwendung der KS-Regel behoben. Daraufhin stieg die Inhaltsqualität der MÜ (+0,50 Punkte auf der Likert-Skala), während die Stilqualität sank ($-$~,13 Punkte auf der Likert-Skala).


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & Nur Elektrofachkräfte dürfen Zugang zur Elektrik der Maschine haben und \textbf{diese} warten.\\
\tablevspace
HMÜ Bing & Only qualified electricians are allowed to access to the machine's electrical system and maintain \txred{them}.\\
\midrule
\textbf{Nach-KS} & Nur Elektrofachkräfte dürfen Zugang zur Elektrik der Maschine haben und \textbf{die Maschine} warten.\\
\tablevspace
HMÜ Bing & Only qualified electricians are allowed to access to the machine's electrical system and maintain \txblue{the machine}.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:45}Beispiel 45  }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

Die Humanevaluation lieferte genauere Inputs zu den beeinflussten Qualitätskriterien. Wie die \figref{fig:05:68} zeigt, sanken alle Qualitätskriterien mit Ausnahme des Stilqualitätskriteriums SQ3 „natürliche bzw. idiomatische MÜ“ nach der Regelanwendung leicht. Da die Qualitätskriterien negativ formuliert sind, deutet ein Rückgang auf eine Verbesserung der Qualität hin (d.~h. alle Qualitätskriterien mit Ausnahme der Idiomatik (SQ3) wurden nach der Regelanwendung besser bewertet).


\begin{figure}
%\includegraphics[height=.3\textheight]{figures/d3-img063.png}

%\textbf{13~\%}

 %\textbf{$-$ 13~\%}

%\textbf{$-$ 29~\%}

%\textbf{$-$ 9~\%}

%\textbf{$-$ 24~\%}
\pgfplotstableread{
1 59
2 45
3 86
4 78
5 361
6 408
7 153
8 108
9 128
10 111
}\datatable
\begin{tikzpicture}
%    \tikzset{every node/.style={font=\scriptsize}};
    \begin{axis}[ybar,
  %              ylabel = {Summe},
  %              ylabel style={yshift=-.2cm},
                enlarge x limits={.05},
                width  = \textwidth,
                height = .45\textheight,
                axis lines*=left,
                axis on top,
                bar width=8.5,
                bar shift=0pt,
                ymin = 0,
                ymax=450,
                xtick = {1,2,...,10},
                xticklabels={SQ1\_v,
                SQ1\_n,
                SQ2\_v,
                SQ2\_n,
                SQ3\_v,
                SQ3\_n,
                CQ1\_v,
                CQ1\_n,
                CQ2\_v,
                CQ2\_n},
            x tick label style={font=\small},
            nodes near coords,
 %           legend style={at={(0.5,-0.25)},anchor=north},
 %           legend columns={-1},
 	 extra description/.code={
	 \node at (axis cs:1.1,100)[anchor = west]{$-$ 24\%};
	 \node at (axis cs:3,125)[anchor = west]{$-$ 9\%};
	  \node at (axis cs:5,450)[anchor = west]{13\%};
	   \node at (axis cs:7.2,200)[anchor = west]{$-$ 29\%};
	    \node at (axis cs:9,200)[anchor = west]{$-$ 13\%};
	  }
            ]
        \addplot +[shift={(.5,0)},lsDarkBlue,x filter/.code={\ifodd\coordindex\def\pgfmathresult{}\fi}] table {\datatable};
        \addplot +[shift={(-.5,0)},lsMidBlue,  x filter/.code={\ifodd\coordindex\relax\else\def\pgfmathresult{}\fi}] table {\datatable};
 %       \legend{vor KS,nach KS}
    \end{axis}
\end{tikzpicture}

\caption{\label{fig:05:68}„Pronom. Bezüge verw.“ -- Vergleich der Qualitätskriterien   }
\bspnote{\textbf{SQ1:} Ü ist \textbf{\textit{nicht}} korrekt bzw. \textbf{\textit{nicht}} klar dargestellt, d. h. nicht orthografisch.\\
{\textbf{SQ2:} Ü ist \textbf{\textit{nicht}} ideal für die Absicht des Satzes, d. h. motiviert den Nutzer \textbf{\textit{nicht} }zum Handeln, zieht \textbf{\textit{nicht} }seine Aufmerksamkeit an usw.}\\
\textbf{SQ3:} Ü klingt \textbf{\textit{nicht} }natürlich bzw. \textbf{\textit{nicht} }idiomatisch.\\
{\textbf{CQ1:} Ü gibt die Informationen im Ausgangstext \textbf{\textit{nicht}} exakt wieder.}\\
\textbf{CQ2:} Ü ist \textbf{\textit{nicht}} leicht zu verstehen, d. h. \textbf{\textit{nicht}} gut formuliert bzw. dargestellt.}
\end{figure}

An dieser Stelle folgt \tabref{tabex:05:46}, in dem die MÜ vor und nach der Anwendung der Regel fehlerfrei war, jedoch ging die Verwendung des pronominalen Bezugs mit einem Anstieg der Inhaltsqualität (+~0,50 Punkte auf der Likert-Skala) und einem Rückgang der Stilqualität ($-$~,88 Punkte auf der Likert-Skala) einher.


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & Um die Startlinie festzustellen, kann mit Kreide \textbf{diese} markiert werden. \\
\tablevspace
HMÜ Bing & In order to determine the starting line, \txblue{it} can be marked with chalk.\\
\midrule
\textbf{Nach-KS} & Um die Startlinie festzustellen, kann mit Kreide \textbf{diese Linie} markiert werden. \\
\tablevspace
HMÜ Bing & In order to determine the starting line, \txblue{this line} can be marked with chalk.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:46}Beispiel 46   }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

\subsubsubsection{Korrelation zwischen den Fehlertypen und der Qualität}

Auf Basis der Fehlerannotation zusammen mit der Humanevaluation gibt uns eine Spearman-Korrelationsanalyse Aufschluss, wie die Veränderung bei der Fehleranzahl bei jedem Fehlertyp (Anz. nach KS $–$ Anz. vor KS) mit den Qualitätsunterschieden (Q. nach KS $–$ Q. vor KS) zusammenhängt. Mithilfe des Spearman-Tests erwies sich ein signifikanter mittlerer negativer Zusammenhang zwischen der Differenz in den Fehlertypen GR.10 „Falsche Wortstellung“ und SM.11 „Verwechslung des Sinns“ einzeln und der Differenz in der Stilqualität; sowie ein signifikanter schwacher negativer Zusammenhang zwischen der Differenz im Fehlertyp LX.6 „Konsistenzfehler“ und der Differenz in der Stilqualität. (\tabref{tab:05:49})

Bezüglich der Inhaltsqualität erwies sich ein signifikanter mittlerer negativer Zusammenhang zwischen der Differenz in den Fehlertypen LX.6, GR.10 und SM.11 einzeln und der Differenz in der Inhaltsqualität; sowie ein signifikanter schwacher negativer Zusammenhang zwischen der Differenz in Fehlertyp LX.3 „Wort ausgelassen“ und der Differenz in der Inhaltsqualität. (\tabref{tab:05:49})

Weitere Korrelationen zwischen anderen einzelnen Fehlertypen und der Qualität konnten nicht nachgewiesen werden.


\begin{table}
\begin{tabularx}{\textwidth}{Xrrr}

\lsptoprule
& { \textbf{N}} & { \textbf{p}} & \textbf{ρ}\\
\midrule
\textbf{Differenz SQ (nach KS $-$ vor KS)} &  & &\\
Differenz der Anzahl der \textbf{LX.3 „W. ausgelassen“} & { 77} & \txgray{ ,084} & $-$~,198\\
Differenz der Anzahl der \textbf{LX.6 „Konsistenzfehler“} & { 77} &{ ,042} & $-$~,232\\
Differenz der Anzahl der \textbf{GR.10 „f. Wortstellung“} & { 77} & { ,003} & \txgreen{$-$~,330}\\
Differenz der Anzahl der \textbf{SM.11 „Verwechs. des Sinns“} & { 77} & { < ,001} & \txgreen{$-$~,394}\\
\midrule
\textbf{Differenz CQ (nach KS $-$ vor KS)} &  &  & \\
Differenz der Anzahl der \textbf{LX.3 „W. ausgelassen“} & { 77} & { ,025} & $-$~,256\\
Differenz der Anzahl der \textbf{LX.6 „Konsistenzfehler“} & { 77} & { ,006} & \txgreen{$-$~,309}\\
Differenz der Anzahl der \textbf{GR.10 „f. Wortstellung“} & { 77} & { ,004} & \txgreen{$-$~,327}\\
Differenz der Anzahl der \textbf{SM.11 „Verwechs. des Sinns“} & { 77} & { ,004} & \txgreen{$-$~,323}\\
\midrule
\textbf{Differenz allg. Q (nach KS $-$ vor KS)} &  &  & \\
Differenz der Anzahl der \textbf{LX.3 „W. ausgelassen“} & { 77} & { ,021} & $-$~,263\\
Differenz der Anzahl der \textbf{LX.6 „Konsistenzfehler“} & { 77} & { ,009} & $-$~,294\\
Differenz der Anzahl der \textbf{GR.10 „f. Wortstellung“} & { 77} & { ,001} & \txgreen{$-$~,371}\\
Differenz der Anzahl der \textbf{SM.11 „Verwechs. des Sinns“} & { 77} & { < ,001} & \txgreen{$-$~,388}\\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:49}„Pronom. Bezüge verw.“ -- Korrelation zwischen den Fehlertypen und der Qualität   }
\bspnote{*In der Tabelle werden nur die Fehlertypen dargestellt, die mindestens mit einer Qualitätsvariable signifikant korrelieren.
\begin{tabbing}
p: Signifikanz\hspace{2.5cm} \= \txgray{nicht signifikant (p ${\geq}$ 0,05)}\hspace{.5cm} \= ρ: Korrelationskoeffizient\\
schwache Korrelation (ρ >=0,1) \> \txgreen{mittlere Korrelation (ρ >= 0,3)} \> \boxblue{starke Korrelation (ρ >= 0,5)}
\end{tabbing}}
\end{table}

Diese signifikanten negativen Korrelationen deuten darauf hin, dass sobald die Fehleranzahl eines der genannten Fehler nach der Regelanwendung sank, die Qualität stieg und umgekehrt, bei einem Anstieg der Fehleranzahl, die Qualität sank. \tabref{tabex:05:43} demonstriert den zweiten Fall: In \tabref{tabex:05:43} trat bei der Wiederholung des Bezugs (nach KS) der lexikalische Fehlertyp „Konsistenzfehler“ (LX.6) in ‚remains‘ auf. Bei einer Formulierung des Satzes mit dem Pronomen (vor KS), konnte das MÜ-System (hier SDL) das Pronomen problemlos übersetzen. Daraufhin sanken die Stilqualität um 0,75 Punkte und Inhaltsqualität um 1,00 Punkte auf der Likert-Skala.

Umgekehrt wurde \tabref{tabex:05:47} der Wortstellungsfehler (GR.10) und der semantische Fehler SM.11 in ‚this‘ nach der Verwendung des Bezugs (nach KS) korrigiert:


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & Um die Startlinie festzustellen, kann mit Kreide \textbf{diese} markiert werden. \\
\tablevspace
SMÜ SDL & In order to determine the starting line, can be marked with chalk \txred{this}.\\
\midrule
\textbf{Nach-KS} & Um die Startlinie festzustellen, kann mit Kreide \textbf{diese Linie} markiert werden. \\
\tablevspace
SMÜ SDL & In order to determine the starting line, \txblue{this line} can be marked with chalk.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:47}Beispiel 47   }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

Daraufhin stiegen die Stilqualität um 1,25 Punkte und die Inhaltsqualität um 1,38 Punkte auf der Likert-Skala.

\subsubsubsection{Vergleich der Qualität auf Regel- und MÜ-Systemebene}

Wie \figref{fig:05:69} zeigt, waren die Inhalts- und Stilqualität in den meisten Fällen sowohl durchschnittlich als auch von ihren Intervallen vergleichbar.


\begin{figure}
\includegraphics[width=\textwidth]{figures/d3-img064.png}
%\includegraphics[height=.3\textheight]{figures/d3-img033.png}\\
\caption{\label{fig:05:69}„Pronom. Bezüge verw.“ -- Mittelwerte der Qualität vor vs. nach KS bei den einzelnen MÜ-Systemen   }
\end{figure}

Nur bei zwei MÜ-Systemen gab es signifikante Unterschiede (\tabref{tab:05:50}): Bei dem NMÜ-System Google Translate sank die Stilqualität ($-$ 5,1~\%) (z (N = 24) = $-$ 2,602 / p = ,009) und bei dem RBMÜ-System Lucy stieg die Inhaltsqualität (+~4,7~\%) (z (N = 14) = $-$ 2,187 / p = ,029).


\begin{table}
\begin{tabularx}{\textwidth}{Xrrrrrrrrr}

\lsptoprule
& \multicolumn{3}{c}{\textbf{Differenz SQ}} & \multicolumn{3}{c}{\textbf{Differenz CQ}} & \multicolumn{3}{c}{\textbf{Differenz allg. Q}}\\
&  \multicolumn{3}{c}{\textbf{(nach KS $-$ vor KS)}} &  \multicolumn{3}{c}{\textbf{(nach KS $-$ vor KS)}} & \multicolumn{3}{c}{\textbf{(nach KS $-$ vor KS)}}\\
\cmidrule(lr){2-4}\cmidrule(lr){5-7}\cmidrule(lr){8-10}
& \textbf{N} & \textbf{p} & \textbf{z} & \textbf{N} & \textbf{p} & \textbf{z} & \textbf{N} & \textbf{p} & \textbf{z}\\
\midrule
 \textbf{Bing} & 11 & \txgray{,685} & $-$~,405 & 11 & \txgray{,210} & $-$~1,254 & 11 & \txgray{,413} & $-$~,819\\
 \textbf{Google} & 24 & ,009 & $-$ 2,602 & 24 & \txgray{,370} & $-$~,897 & 24 & ,034 & $-$ 2,123\\
 \textbf{Lucy} & 14 & \txgray{,345} & $-$~,944 & 14 & ,029 & $-$ 2,187 & 14 & \txgray{,089} & $-$~1,699\\
 \textbf{SDL} & 17 & \txgray{,290} & $-$~1,059 & 17 & \txgray{,247} & $-$~1,157 & 17 & \txgray{,776} & $-$~,284\\
 \textbf{Systran} & 11 & \txgray{,823} & $-$~,223 & 11 & \txgray{,812} & $-$~,238 & 11 & \txgray{,929} & $-$~,089\\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:50}„Pronom. Bezüge verw.“ -- Signifikanz der Qualitätsveränderung bei den einzelnen MÜ-Systemen   }
\bspnote{p: Signifikanz\hspace{2.5cm} z: Teststatistik\hspace{2.5cm} \txgray{nicht signifikant (p ${\geq}$ 0,05)}}
\end{table}

In \tabref{tabex:05:48} fanden die Bewerter die Übersetzung von Google Translate stilistisch schlechter nach Verwendung des Bezugs anstatt des Pronomens (SQ: $-$~,50 Punkte auf der Likert-Skala), wobei die Bewertung der Inhaltsqualität im Durchschnitt unverändert blieb (CQ: 0,00 Punkte auf der Likert-Skala).


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & Überprüfen Sie die Zuweisung des Ports im Geräte-Manager und stellen Sie \textbf{diesen} ggf. um.\\
\tablevspace
GNMÜ & Check the assignment of the port in the Device Manager and, if necessary, modify \txblue{it}.\\
\midrule
\textbf{Nach-KS} & Überprüfen Sie die Zuweisung des Ports im Geräte-Manager und stellen Sie \textbf{diesen Port} ggf. um.\\
\tablevspace
GNMÜ & Check the assignment of the port in the Device Manager and, if necessary, modify \txblue{this port}.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:48}Beispiel 48   }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

Bei Lucy stieg z. B. im folgenden Satz (\tabref{tabex:05:49}) die Inhaltsqualität (CQ: +~0,75 Punkte auf der Likert-Skala) und die Stilqualität (SQ: +~0,38 Punkte auf der Likert-Skala).


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & Ist der c-Faktor mit einer anderen Luftdichte angegeben worden, so ist \textbf{dieser} im Feld $"$Luftdichte$"$ einzutragen.\\
\tablevspace
RBMÜ Lucy & If the c-factor has been \textbf{\textit{specified}} with a \textbf{\textit{different}} air density, \txblue{this} \textbf{\textit{must}} be entered in the $"$Air density$"$ field.\\
\midrule
\textbf{Nach-KS} & Ist der c-Faktor mit einer anderen Luftdichte angegeben worden, so ist \textbf{dieser Faktor} im Feld $"$Luftdichte$"$ einzutragen.\\
\tablevspace
RBMÜ Lucy & If the c-factor has been \textbf{\textit{specified}} with a \textbf{\textit{different}} air density, \txblue{this factor} \textbf{\textit{must}} be entered in the $"$Air density$"$ field.\\
\lspbottomrule
\end{tabularx}\caption{\label{tabex:05:49}Beispiel 49   }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

\subsubsubsection{Korrelation zwischen den Fehlertypen und der Qualität auf Regel- und MÜ-Systemebene}

Anhand der Spearman-Korrelationsanalyse erwies sich nur bei dem HMÜ-Sys\-tem Systran eine signifikante starke negative Korrelation zwischen der Differenz in Fehlertyp SM.11 „Verwechslung des Sinns“ und der Differenz in der Stilqualität. (\tabref{tab:05:51})


\begin{table}
\begin{tabularx}{\textwidth}{Xrrr}

\lsptoprule
&  \multicolumn{3}{c}{ \textbf{Systran}}\\
\cmidrule(lr){2-4}
& \textbf{N} & \textbf{p} & \textbf{ρ}\\
\midrule
\multicolumn{4}{l}{\textbf{Differenz SQ}

\textbf{(nach KS $-$ vor KS)}} \\
Diff. der Anzahl \textbf{SM.11 „Verwechs. des Sinns“} &  11 & ,035 & \boxblue{$-$~,638}\\
\midrule
\multicolumn{4}{l}{\textbf{Differenz CQ}

\textbf{(nach KS $-$ vor KS)}} \\
 Diff. der Anzahl \textbf{SM.11 „Verwechs. des Sinns“}  & 11 & \txgray{,071} & $-$~,564\\
 \midrule
\multicolumn{4}{l}{\textbf{Differenz Q}

\textbf{(nach KS $-$ vor KS)}} \\
 Diff. der Anzahl \textbf{SM.11 „Verwechs. des Sinns“} & 11 & ,038 & \boxblue{$-$~,629}\\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:51}„Pronom. Bezüge verw.“ -- Korrelationen zwischen den Fehlertypen und der Qualität bei den einzelnen MÜ-Systemen   }
\bspnote{*In der Tabelle werden nur die Fehlertypen dargestellt, die bei mind. einer Qualitätsvariable eine signifikante Korrelation aufweisen.
\begin{tabbing}
p: Signifikanz\hspace{2.5cm} \= \txgray{nicht signifikant (p ${\geq}$ 0,05)}\hspace{1cm} \= ρ: Korrelationskoeffizient\\
schwache Korrelation (ρ >=0,1) \> \txgreen{mittlere Korrelation (ρ >= 0,3)} \> \boxblue{starke Korrelation (ρ >= 0,5)}
\end{tabbing}}
\end{table}

Fehlertyp SM.11 erschien bei Systran sowohl vor als auch nach der Anwendung der KS-Regel (siehe \figref{fig:05:65}). Die negative Spearman-Korrelation besagt entsprechend, dass beim Auftreten dieses Fehlers, die Qualität deutlich sank. Umgekehrt stieg mit der Eliminierung dieses Fehlers die Qualität deutlich.

\subsubsection{\label{sec:5.3.4.5}Vergleich der MÜ-Qualität vor vs. nach der Verwendung von pronominalen Bezügen auf Annotationsgruppenebene}
\largerpage
Die Qualitätsunterschiede\footnote{\textrm{Definitionen der Qualität unter \sectref{sec:4.4.5.1}.}} waren nur bei den Annotationsgruppen FR und RF groß, während bei den Gruppen FF und RR das Qualitätsniveau relativ vergleichbar blieb (\figref{fig:05:70}).


\begin{figure}
\includegraphics[width=\textwidth]{figures/d3-img065.png}
%\includegraphics[height=.3\textheight]{figures/d3-img035.png}\\
\caption{\label{fig:05:70}„Pronom. Bezüge verw.“ -- Mittelwerte der Qualität vor vs. nach KS auf Annotationsgruppenebene   }
\end{figure}

In der Gruppe FF wurden die Sätze vor und nach der Anwendung der KS-Regel aus unterschiedlichen Gründen falsch übersetzt. Durchschnittlich sanken die Stil- und Inhaltsqualität leicht nachdem der Bezug wiederholt wurde (nach KS).


\begin{table}
\begin{tabularx}{\textwidth}{Xrrr}

\lsptoprule
& \textbf{N} & { \textbf{p}} & { \textbf{Z} }\\
& &  \textbf{(Signifikanz)} & \textbf{(Teststatistik)}\\
\midrule
{\textbf{Annotationsgruppe FF}} & {} & {} & \\
\textbf{Differenz SQ (nach KS $-$ vor KS)} & 8 & \txgray{,443} & $-$~,768\\
\textbf{Differenz CQ (nach KS $-$ vor KS)} & 8 & \txgray{,799} & $-$~,254\\
\textbf{Differenz allg. Q (nach KS $-$ vor KS)} & 8 & \txgray{,735} & $-$~,338\\
\midrule
{\textbf{Annotationsgruppe FR}} & {} & {} & \\
\textbf{Differenz SQ (nach KS $-$ vor KS)} & 12 & ,011 & $-$ 2,547\\
  \textbf{Differenz CQ (nach KS $-$ vor KS)} & 12 & ,002 & $-$ 3,072\\
\textbf{Differenz allg. Q (nach KS $-$ vor KS)} & 12 & ,002 & $-$ 3,065\\
\midrule
{\textbf{Annotationsgruppe RF}} & {} & {} & \\
\textbf{Differenz SQ (nach KS $-$ vor KS)} & 10 & ,012 & $-$ 2,509\\
  \textbf{Differenz CQ (nach KS $-$ vor KS)} & 10 & ,012 & $-$ 2,313\\
\textbf{Differenz allg. Q (nach KS $-$ vor KS)} & 10 & ,012 & $-$ 2,527\\
\midrule
{\textbf{Annotationsgruppe RR}} & {} & {} & \\
\textbf{Differenz SQ (nach KS $-$ vor KS)} & 47 & \txgray{,220} & $-$~1,227\\
  \textbf{Differenz CQ (nach KS $-$ vor KS)} & 47 & \txgray{,086} & $-$~1,718\\
   \textbf{Differenz allg. Q (nach KS $-$ vor KS)} & 47 & \txgray{,795} & $-$~,260\\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:52}„Pronom. Bezüge verw.“ -- Signifikanz der Qualitätsveränderung auf Annotationsgruppenebene   }
\end{table}

In der Gruppe FR stiegen erwartungsgemäß die Stil- und Inhaltsqualität signifikant (vgl. \tabref{tabex:05:47}), siehe \tabref{tab:05:52}: bei der Stilqualität (z (N = 12) = $-$~2,547 / p = ,011) bzw. bei der Inhaltsqualität (z (N = 12) = $-$~3,072/ p = ,002). Wie die Aufteilung der Annotationsgruppen (siehe \sectref{sec:5.3.4.2}) zeigte, betrug der Anteil dieser Gruppe 18~\% der analysierten Sätze bei dieser Regel. Die nach der Anwendung der Regel eliminierten Fehler waren unterschiedlich, sodass ein durch die Regel bestimmtes Fehlerbehandlungsmuster schwer erkennbar ist.

In der Gruppe RF sanken die Stil- und Inhaltsqualität signifikant (vgl. \tabref{tabex:05:43}), siehe \tabref{tab:05:52}: bei der Stilqualität (z (N = 10) = $-$ 2,509 / p = ,012) bzw. bei der Inhaltsqualität (z (N = 10) = $-$ 2,313/ p = ,012). Der Anteil der Sätze in dieser Gruppe betrug 12~\% der analysierten Sätze bei dieser Regel (siehe \sectref{sec:5.3.4.2}). Die nach der Regelanwendung vorgekommenen Fehler variierten.

Die Gruppe RR (Übersetzung vor und nach KS fehlerfrei) hatte den größten Anteil von 58~\% der analysierten Sätze (siehe \sectref{sec:5.3.4.2}). Bei dieser Gruppe stieg durchschnittlich die Inhaltsqualität leicht, während bei der Stilqualität eine leichte Minderung verzeichnet wurde (\figref{fig:05:70}). Hierbei fanden die Bewerter, dass die wiederholte Erwähnung des Bezugs eine Präzisierung des Inhalts der MÜ ermöglichte, dennoch litt der Stil unter dieser Wiederholung. In \tabref{tabex:05:46} war die MÜ vor und nach der Regelanwendung fehlerfrei. Nach der Regelanwendung stieg die Inhaltsqualität um 0,50, gleichzeitig sank die Stilqualität um 0,88 Punkte auf der Likert-Skala.

\subsubsection{\label{sec:5.3.4.6}Vergleich der AEM-Scores vor vs. nach der Verwendung von pronominalen Bezügen sowie die Korrelation zwischen den AEM-Scores und der Qualität}

Der Vergleich der AEM-Scores bei der Verwendung der Pronomen (vor KS) und nach der Wiederholung des Bezugs (nach KS) zeigte sowohl mit TERbase als auch mit hLEPOR eine geringe nicht signifikante Verschlechterung der AEM-Scores (\figref{fig:05:71}).


\begin{figure}
%\includegraphics[height=.3\textheight]{figures/d3-img022.png}




%\includegraphics[height=.3\textheight]{figures/d3-img022.png}


%\includegraphics[height=.3\textheight]{figures/d3-img022.png}
\includegraphics[width=.4\textwidth]{figures/Abb71.png}
\includegraphics[width=.35\textwidth]{figures/Abb19-legend.png}
\caption{\label{fig:05:71}„Pronom. Bezüge verw.“ -- Mittelwert der Differenz der AEM-Scores   }
\bspnote{Differenz = AEM-Score nach KS \textit{minus} AEM-Score vor KS}
\end{figure}

Der Mittelwert der Differenz (nach KS $-$ vor KS) im AEM-Score pro Satz lag für TERbase bei $-$~,061 (SD = ,240) und für die hLEPOR bei $-$~,015 (SD = ,141) mit einem 95\%\nobreakdash-Konfidenzintervall (Bootstrapping mit 1000 Stichproben) (\figref{fig:05:71}). Durch diese kleinen Unterschiede waren die Differenzen (nach KS $-$ vor KS) in TERbase und hLEPOR nicht signifikant (z (N = 77) = $-$~1,962 / p = ,050) bzw. (z (N = 77) = $-$~1,221 / p = ,222). Eine mögliche Interpretation, warum die Differenz der AEM-Scores klein war: Bei dieser Regel gab es signifikante Veränderungen in der Fehleranzahl bei zwei Fehlertypen: der lexikalische Fehlertyp LX.6 „Konsistenzfehler“ \textit{stieg} (vlg. \tabref{tabex:05:43}) und der semantische Fehlertype SM.11 „Verwechslung des Sinns“ \textit{sank} (vlg. \tabref{tabex:05:47}) nach der Wiederholung des Bezugs (nach KS). In anderen Worten musste nach den AEMs in beiden Szenarien einer der beiden Fehler korrigiert werden, und zwar SM.11 vor KS und LX.6 nach KS. Dadurch näherten sich möglicherweise die AEM-Scores der beiden Szenarien an und fiel die Differenz zwischen den AEM-Scores klein aus.

\subsubsubsection{Korrelation zwischen den Differenzen in den AEM-Scores und der Qualität}

Durch das Auftreten von Fehlern sowohl vor als auch nach der Anwendung der KS konnte auch kein signifikanter Unterschied in der Qualität nachgewiesen werden (siehe \sectref{sec:5.3.4.4}). Mithilfe des Spearman-Korrelationstests erwies sich ein signifikanter mittlerer positiver Zusammenhang zwischen den Differenzen der AEM-Scores von TERbase und hLEPOR und der Differenz der allgemeinen Qualität. \tabref{tab:05:53} demonstriert die Korrelationswerte:


\begin{table}
\begin{tabularx}{\textwidth}{Qrrrr}

\lsptoprule
& \textbf{N} & { \textbf{Signifikanz} } & \textbf{Korrelations-} & \textbf{Stärke}\\
& & \textbf{(p)} & \textbf{koeffizient} &  \textbf{der}\\
& & & \textbf{(ρ)} & \textbf{Korrelation}\\
\midrule
Korrelation zw. Differenz in der allg. Qualität und Differenz des TERbase-Scores (nach KS $-$ vor KS) & { 77} & ,003 & ,330 & \makecell[tr]{mittlerer\\Zusammen-\\hang}\\
\tablevspace
Korrelation zw. Differenz in der allg. Qualität und Differenz des hLEPOR-Scores (nach KS $-$ vor KS) & { 77} & < ,001 & ,467 & \makecell[tr]{mittlerer\\Zusammen-\\hang}\\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:53}„Pronom. Bezüge verw.“ -- Korrelation zwischen den Differenzen der AEM-Scores und den Qualitätsdifferenzen   }
\bspnote{{ schwache Korrelation (ρ >=0,1)}\hspace{1em} { mittlere Korrelation (ρ >= 0,3)} \hspace{1em} starke Korrelation (ρ >= 0,5)}
\end{table}

Diese Korrelation zeigt, dass die Scores der beiden AEMs sich relativ synchron in die gleiche Richtung wie die Qualität bewegten.

\subsubsection{\label{sec:5.3.4.7}Analyse der vierten Regel -- Validierung der Hypothesen}

Um die vorgestellten Ergebnisse auf die Forschungsfragen der Studie zurückzuführen, listet dieser Abschnitt die zugrunde liegenden Hypothesen der Forschungsfragen zusammen mit einer Zusammenfassung der Ergebnisse der vierten analysierten Regel in tabellarischer Form auf. Für einen schnelleren Überblick steht (+) für eine Verbesserung bzw. einen Anstieg z.~B. im Sinne eines Qualitätsanstiegs, verbesserter AEM-Scores oder eines Anstiegs der Fehleranzahl; ($-$) steht für einen Rückgang; die \txgreen{grüne} Farbe symbolisiert eine signifikante Veränderung; \textit{neg} steht für eine negative Korrelation und \textit{pos} für eine positive Korrelation; <{}<{}>{}> steht für eine starke Korrelation und <> für eine mittlere Korrelation.\footnote{\textrm{Schwache Korrelationen werden in dieser Übersicht nicht angezeigt.}}

\subsubsubsection*{\textbf{Regel 4: Eindeutige pronominale Bezüge verwenden}}

\paragraph*{Erster Analysefaktor: Vergleich der Fehleranzahl vor vs. nach der Verwendung der pronominalen Bezüge}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Gibt es einen Unterschied in der Fehleranzahl nach der Anwendung der KS-Regel im Vergleich zu vor der Anwendung?
\item [H0 --] Es gibt keinen Unterschied in der Fehleranzahl vor vs. nach der Anwendung der KS-Regel.
\item [H1 --] Es gibt einen Unterschied in der Fehleranzahl vor vs. nach der Anwendung der KS-Regel.
\item [Resultat]
\end{description}
\noindent
\parbox[t]{.8\textwidth}{\textbf{Auf Regelebene:}}\\
\noindent
\parbox[t]{.8\textwidth}{H0 wurde nicht abgelehnt und somit konnte H1 nicht bestätigt werden.

Die Fehleranzahl sank minimal nach der Verwendung der pronominalen Bezüge.}
\parbox[t]{.04\textwidth}{}
\parbox[t]{.15\textwidth}{\textbf{Anz.F. ($-$)}}

\noindent
\parbox[t]{.8\textwidth}{\textbf{Auf Regel- und MÜ-Systemebene:}}\\
\noindent
\parbox[t]{.8\textwidth}{Bei Google stieg die Fehleranzahl signifikant nach der Verwendung der pronominalen Bezüge.}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.15\textwidth}{\textbf{Go (+)}\\}}

\medskip
\noindent
\parbox[t]{.8\textwidth}{Bei Bing blieb die Fehleranzahl unverändert.}
\parbox[t]{.04\textwidth}{}
\parbox[t]{.15\textwidth}{\textbf{Bi (=)}}

\medskip
\noindent
\parbox[t]{.8\textwidth}{Bei den drei anderen Systemen sank die Fehleranzahl leicht.}
\parbox[t]{.04\textwidth}{}
\parbox[t]{.15\textwidth}{{ \textbf{Lu ($-$)}}

{ \textbf{SD ($-$)}}

 \textbf{Sy ($-$)}}

 \hrule
 \newpage
 \paragraph*{Zweiter Analysefaktor}\hfill

 \begin{figure}[H]
 % 62
 \torte{16}{21}{14}{69}
\caption{Aufteilung der Annotationsgruppen auf Regelebene}
 \end{figure}

 \begin{figure}[H]
 \begin{tikzpicture}
 \tikzset{every node/.style={font=\scriptsize}};
 	\begin{axis}[
 	ybar,
 	width = \textwidth,
  height = .5\textheight,
 	axis lines* = left,
 	ylabel = {\%},
 	xtick = {3,9,15,21},
 	xticklabels = {FF,FR,RF,RR},
   x tick label style ={yshift=-5pt},
 	xtick=data,
   xlabel={Annotationsgruppe},
 	ymin=0,
 	ymax = 20,
  y filter/.code={\pgfmathparse{#1/120*100}\pgfmathresult},
 %	bar shift = 0pt,
   bar width=9,
% 	nodes near coords,
 %	legend pos= north east,
 	legend style={at={(0.5,-0.15)},anchor=north},
 	legend columns = {-1},
 	]
 	\addplot+[lsNightBlue]
 	coordinates {
 	(3,0)
 	(9,6)
 	(15,5)
 	(21,13)
 	};
 	\addplot+[tmnlpone]
 	coordinates {
 	(3,2)
 	(9,0)
 	(15,2)
 	(21,20)
 	};
 	\addplot+[tmnlptwo]
 	coordinates {
 	(3,2)
 	(9,5)
 	(15,1)
 	(21,16)
 	};
 	\addplot+[tmnlpthree]
 	coordinates {
 	(3,7)
 	(9,6)
 	(15,3)
 	(21,8)
 	};
 	\addplot+[tmnlpfour]
 	coordinates {
 	(3,5)
 	(9,4)
 	(15,3)
 	(21,12)
 	};
 	\legend{Bing,Google,Lucy,SDL,Systran}
 	\end{axis}
 \end{tikzpicture}
\caption{Aufteilung der Annotationsgruppen auf Regel- und MÜ-Systemebene}
 \end{figure}

\hrule
\newpage
\paragraph*{Dritter Analysefaktor: Vergleich der Fehlertypen vor vs. nach der Verwendung der pronominalen Bezüge}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Beinhaltet die MÜ bestimmte Fehlertypen vor bzw. nach der Anwendung der KS-Regel?
\item [H0 --] Es gibt keinen Unterschied in der Häufigkeit der einzelnen Fehlertypen vor vs. nach der Anwendung der KS-Regel.
\item [H1 --] Es gibt einen Unterschied in der Häufigkeit der einzelnen Fehlertypen vor vs. nach der Anwendung der KS-Regel.
\item [Resultat]
\end{description}
\noindent
\parbox[t]{.8\textwidth}{\textbf{Auf Regelebene:}}\\
\parbox[t]{.8\textwidth}{
H1 wurde nur für zwei Fehlertypen bestätigt.

Die Fehleranzahl von LX.6 „Konsistenzfehler“ stieg signifikant und die Fehleranzahl von SM.11 „Verwechslung des Sinns“ sank signifikant nach der Verwendung der pronominalen Bezüge.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.15\textwidth}{
{ \textbf{LX.6 (+)}}

 \textbf{SM.11 ($-$)}\\
 \\
}}

\noindent
\parbox[t]{.8\textwidth}{\textbf{Auf Regel- und MÜ-Systemebene:}}\\
\parbox[t]{.8\textwidth}{
Auf Systemebene gab es keinen bestimmten Fehlertyp, der nach der Verwendung der pronominalen Bezüge statistisch signifikant beeinflusst wurde.

Dennoch wurde ein wesentlicher (nicht signifikanter) Anstieg in LX.6 „Konsistenzfehler“ bei SDL und ein wesentlicher (nicht signifikanter) Rückgang in SM.11 „Verwechslung des Sinns“ bei Lucy beobachtet.
}
\parbox[t]{.04\textwidth}{}
\parbox[t]{.15\textwidth}{
{ \textbf{SD:}}

{ \textbf{LX.6 (+)}}\\

{ \textbf{Lu:}}

 \textbf{SM.11 ($-$)}
}

\medskip
\noindent
\parbox[t]{.8\textwidth}{Alle weiteren Veränderungen der Fehlertypen waren sehr gering.}

\hrule
\paragraph*{Vierter Analysefaktor: Vergleich der MÜ-Qualität vor vs. nach der Verwendung der pronominalen Bezüge}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Gibt es einen Unterschied in der Stil- und Inhaltsqualität der MÜ der KS-Stelle nach der Anwendung der KS-Regel im Vergleich zu vor der Anwendung?
\item [H0 --] Es gibt keinen Qualitätsunterschied vor vs. nach der Anwendung der KS-Regel.
\item [H1 --] Es gibt einen Qualitätsunterschied vor vs. nach der Anwendung der KS-Regel.
\item [Resultat]
\end{description}
\noindent
\parbox[t]{.75\textwidth}{\textbf{Auf Regelebene:}}\\
\parbox[t]{.75\textwidth}{
H0 wurde nicht abgelehnt und somit konnte H1 nicht bestätigt werden.

Die Stilqualität sank leicht, während die Inhaltsqualität leicht stieg.
}
\parbox[t]{.04\textwidth}{}
\parbox[t]{.2\textwidth}{
{ \textbf{SQ ($-$)}}

 \textbf{CQ (+)}
}

\noindent
\parbox[t]{.75\textwidth}{\textbf{Auf Regel- und MÜ-Systemebene:}}\\
\parbox[t]{.75\textwidth}{
Die Stilqualität sank nur bei Google signifikant, während die Inhaltsqualität nur bei Lucy signifikant stieg.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.09\textwidth}{
{ \textbf{SQ ($-$):}}

 \textbf{Go}
 }}
\colorbox{smGreen}{\parbox[t]{.09\textwidth}{
{ \textbf{CQ (+):}}

 \textbf{Lu}
}}

\medskip
\noindent
\parbox[t]{.75\textwidth}{Die Qualitätsdifferenzen bei allen anderen Systemen fielen (sehr) gering aus und waren entsprechend nicht signifikant.}

\hrule
\paragraph*{Fünfter Analysefaktor: Korrelation zwischen den Fehlertypen und der Qualität}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Besteht ein Zusammenhang zwischen der Differenz der Fehleranzahl eines bestimmten Fehlertyps (Fehleranzahl nach KS $-$ vor KS) und der Differenz der Stil- bzw. Inhaltsqualität (Qualität nach KS $-$ vor KS)?
\item [H0 --] Es besteht kein Zusammenhang zwischen der Differenz der Fehleranzahl eines bestimmten Fehlertyps und der Differenz der Stil- bzw. Inhaltsqualität.
\item [H1 --] Es besteht ein Zusammenhang zwischen der Differenz der Fehleranzahl eines bestimmten Fehlertyps und der Differenz der Stil- bzw. Inhaltsqualität.
\item [Resultat]
\end{description}
\noindent
\parbox[t]{.7\textwidth}{\textbf{Auf Regelebene:}}\\
\parbox[t]{.7\textwidth}{
H1 wurde nur für drei Fehlertypen wie folgt bestätigt:

Es bestand ein signifikanter mittlerer negativer Zusammenhang zwischen der Differenz der Fehleranzahl des GR.10 „Falsche Wortstellung“ und SM.11 „Verwechslung des Sinns“ einzeln und der Differenz der Stilqualität.

Zudem bestand ein signifikanter mittlerer negativer Zusammenhang zwischen der Differenz der Fehleranzahl des LX.6 (Konsistenzfehler), GR.10 und SM.11 einzeln und der Differenz der Inhaltsqualität.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.25\textwidth}{
{ \textbf{\textit{neg} }\textbf{GR.10 <> SQ}}

{ \textbf{\textit{neg} }\textbf{SM.11 <> SQ}}\\

{ \textbf{\textit{neg} }\textbf{LX.6 <> CQ}}

{ \textbf{\textit{neg} }\textbf{GR.10 <> CQ}}

 \textbf{\textit{neg} }\textbf{SM.11 <> CQ}\\
 \\
 \\
}}

\noindent
\parbox[t]{.7\textwidth}{\textbf{Auf Regel- und MÜ-Systemebene:}}\\
\parbox[t]{.7\textwidth}{
Die einzige signifikante Korrelation bestand bei Systran und es handelte sich dabei um einen signifikanten starken negativen Zusammenhang zwischen der Differenz der Fehleranzahl des SM.11 „Verwechslung des Sinns“ und der Differenz der Stilqualität.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.25\textwidth}{
{ \textbf{Sy}}

 \textbf{\textit{neg} }\textbf{SM.11 <{}<{}>{}> SQ}\\
 \\
 \\
}}

\medskip
\noindent
\parbox[t]{.7\textwidth}{Alle weiteren Korrelationen waren nicht signifikant.}

\hrule
\paragraph*{Sechster Analysefaktor: Vergleich der MÜ-Qualität vor vs. nach der Verwendung der pronominalen Bezüge auf Annotationsgruppenebene}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Gibt es einen Unterschied in der Stil- und Inhaltsqualität bei den einzelnen Annotationsgruppen nach der Anwendung der KS-Regel im Vergleich zu vor der Anwendung?
\item [H0 --] Bei den Annotationsgruppen gibt es keinen Qualitätsunterschied vor vs. nach der Anwendung der KS-Regel.
\item [H1 --] Bei den Annotationsgruppen gibt es einen Qualitätsunterschied vor vs. nach der Anwendung der KS-Regel.
\item [Resultat]
\end{description}
\noindent
\parbox[t]{.8\textwidth}{
H1 wurde für die Gruppen FR und RF bestätigt:

Bei der Annotationsgruppe FR stiegen die Stil- und Inhaltsqualität signifikant nach der Verwendung der pronominalen Bezüge.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.15\textwidth}{
{ \textbf{SQ (+)}}

 \textbf{CQ (+)}\\
}}

\medskip
\noindent
\parbox[t]{.8\textwidth}{
Bei der Annotationsgruppe RF sanken die Stil- und Inhaltsqualität signifikant.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.15\textwidth}{
{ \textbf{SQ ($-$)}}

 \textbf{CQ ($-$)}
}}

\medskip
\noindent
\parbox[t]{.8\textwidth}{
Bei der Annotationsgruppe FF gingen die Stil- und Inhaltsqualität leicht zurück.
}
\parbox[t]{.04\textwidth}{}
\parbox[t]{.15\textwidth}{
{ \textbf{SQ ($-$)}}

 \textbf{CQ ($-$)}
}

\medskip
\noindent
\parbox[t]{.8\textwidth}{
Bei der Annotationsgruppe RR sank die Stilqualität leicht und die Inhaltsqualität nahm leicht zu.
}
\parbox[t]{.04\textwidth}{}
\parbox[t]{.15\textwidth}{
{ \textbf{SQ ($-$)}}

 \textbf{CQ (+)}
}

\hrule
\paragraph*{Siebter Analysefaktor: Vergleich der AEM-Scores vor vs. nach der Verwendung der pronominalen Bezüge}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Gibt es einen Unterschied in den AEM-Scores von TERbase bzw. hLEPOR nach der Anwendung der KS-Regel im Vergleich zu vor der Anwendung?
\item [H0 --] Es gibt keinen Unterschied in den AEM-Scores vor vs. nach der Anwendung der KS-Regel.
\item [H1 --] Es gibt einen Unterschied in den AEM-Scores vor vs. nach der Anwendung der KS-Regel.
\item [Resultat]
\end{description}
\noindent
\parbox[t]{.75\textwidth}{
H0 wurde nicht abgelehnt und somit konnte H1 nicht bestätigt werden.

Die AEM-Scores von TERbase und hLEPOR verschlechtern sich nur leicht nach der Verwendung der pronominalen Bezüge.
}
\parbox[t]{.04\textwidth}{}
\parbox[t]{.2\textwidth}{
\textbf{TERbase ($-$)\\hLEPOR ($-$)}
}

\hrule
\paragraph*{Achter Analysefaktor: Korrelation zwischen den Differenzen der AEM-Scores und der Qualität}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Besteht ein Zusammenhang zwischen der Differenz der AEM-Scores von TERbase bzw. hLEPOR (Mittelwert der AEM-Scores nach KS $-$ vor KS) und der Differenz der allgemeinen Qualität (Qualität nach KS $-$ vor KS)?
\item [H0 --] Es besteht kein Zusammenhang zwischen der Differenz der AEM-Scores und der Differenz der allgemeinen Qualität.
\item [H1 --] Es besteht ein Zusammenhang zwischen der Differenz der AEM-Scores und der Differenz der allgemeinen Qualität.
\item [Resultat]
\end{description}
\noindent
\parbox[t]{.7\textwidth}{
H0 wurde abgelehnt und somit H1 bestätigt.

Es bestand ein signifikanter mittlerer positiver Zusammenhang zwischen den Differenzen der Scores der beiden AEMs (TERbase und hLEPOR) und der Differenz der allgemeinen Qualität.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.25\textwidth}{
{ \textbf{\textit{pos}} \textbf{TERbase <> Q}}

 \textbf{\textit{pos}} \textbf{hLEPOR <> Q}\\
 \\
 \\
}}



\subsection{FÜNFTE REGEL: Partizipialkonstruktionen vermeiden}
\label{sec:5.3.5}

 \subsubsection{\label{sec:5.3.5.0}Überblick}

%In \tabref{tab:05:54}
Im Folgenden wird die KS-Regel „Partizipialkonstruktionen vermeiden“ kurz beschrieben.\footnote{\textrm{Die für diese Regel relevanten Kontraste im Sprachenpaar DE-EN sind unter \sectref{sec:4.4.2.3} erörtert.} } Zudem wird zusammenfassend und anhand eines Beispiels die Umsetzung der Regel bei der Analyse demonstriert. Anschließend wird die Aufteilung der Testsätze im Datensatz dargestellt:

\begin{description}[font=\normalfont\bfseries]
\item [Beschreibung der KS-Regel:] \textbf{Partizipialkonstruktionen vermeiden} (tekom-Regel-Nr. S 303)

Nach dieser Regel (\citealt{tekom2013}:~70) soll statt der Partizipialkonstruktion eine einfache Satzstruktur mit mehreren kurzen Sätzen oder Nebensätzen verwendet werden.

Begründung: Die Partizipialkonstruktion erschwert die Textverständlichkeit (ebd.).

\item[Umsetzungsmuster:]
~\\
\textbf{Vor KS:} Der Satz beinhaltet eine Partizipialkonstruktion.\\
\textbf{Nach KS:} aus der Partizipialkonstruktion einen Nebensatz bauen

\item[KS-Stelle]
~\\
\textbf{Vor KS:} alle Wörter, die das Nomen beschreiben, angefangen mit dem Artikel, falls vorhanden.\\
\textbf{Nach KS:} die konvertierten Wörter der Version vor KS (inkl. des Kommas innerhalb der KS-Stelle)

\item[Beispiele]
~\\
\textit{\txgray{Speziell auf diese Lautsprecher abgestimmtes Zubehör} erhalten Sie in unserem Webshop.}

\textit{\txgray{Zubehör, das speziell auf diese Lautsprecher abgestimmt ist}, erhalten Sie in unserem Webshop.}

\item[Aufteilung der Testsätze:]
Der Datensatz besteht aus 24 verschiedenen Partizipialkonstruktionen, die unterschiedliche Längen haben und an unterschiedlichen Stellen in den Sätzen erscheinen.

\end{description}

%\multicolumn{2}{p{6cm}}{\label{bkm:Ref36849446}Eckdaten der fünften Regel „Partizipialkonstruktionen vermeiden“}\\
%\end{tabularx}\caption{\label{tab:05:54}   }

Im Folgenden werden die Ergebnisse der einzelnen Analysefaktoren präsentiert.

\subsubsection{Vergleich der Fehleranzahl mit und ohne die Verwendung von Partizipialkonstruktionen}
\label{sec:5.3.5.1}

Die Fehleranzahl stieg um 26,4~\% von 110 Fehlern im Falle der Verwendung von Partizipialkonstruktionen (M = ,92 / SD = 1,089 / N = 120) auf 139 Fehler bei der Vermeidung der Partizipialkonstruktionen (M = 1,16 / SD = 1,167 / N = 120) (\figref{fig:05:72} und \figref{fig:05:73}). Der Mittelwert der Differenz (nach KS $-$ vor KS) der Fehleranzahl pro Satz lag somit bei ,24 (SD = 1,277) mit einem 95\%\nobreakdash-Kon\-fi\-denz\-in\-ter\-vall zwischen einem Minimum von ,01 (SD = 1,087) und einem Maximum von ,47 (SD = 1,464) (Bootstrapping mit 1000 Stichproben). Die Differenz (nach KS $-$ vor KS) der Fehleranzahl erwies sich als signifikant (z (N = 120) = $-$~1,980 / p = ,048).


\begin{figure}

%\includegraphics[height=.3\textheight]{figures/d3-img023.png}



%\includegraphics[height=.3\textheight]{figures/d3-img023.png}



%\includegraphics[height=.3\textheight]{figures/d3-img023.png} &  &
%\includegraphics[height=.3\textheight]{figures/d3-img024.png}


%\textbf{,951,38}

%\textbf{,721,10}



%\includegraphics[height=.3\textheight]{figures/d3-img024.png}


%\includegraphics[height=.3\textheight]{figures/d3-img024.png}

\captionsetup{width=.45\textwidth}
\begin{floatrow}
\ffigbox[.5\textwidth]{\caption{„Partizipialkonst. verm.“ -- Fehlersumme vor vs. nach KS}
\label{fig:05:72}}{
\begin{tikzpicture}
	\begin{axis}[
	ybar,
	ymin = 0,
	ymax = 150,
	axis lines* = left,
	nodes near coords,
%         nodes near coords align = vertical,
  legend style={at={(0.5,-0.2)},anchor=north,cells={align=left}},
  xtick=\empty,
  width = .45\textwidth,
  enlarge x limits = .5
	]
	\addplot+[tmnlpone]
	coordinates{
	(1,118)
	};
	\addplot+[tmnlpthree]
	coordinates{
	(2,139)
	};
	\legend{Anzahl der  fehler\\innerh. KS vor KS,Anzahl der Fehler\\innerh. KS nach KS}
	\end{axis}
\end{tikzpicture}
}
%
%
\ffigbox[.45\textwidth]{\caption{„Partizipialkonst. verm.“ -- Mittelwert der Fehleranzahl pro Satz vor vs. nach KS}\label{fig:05:73}}{
\includegraphics[width=.25\textwidth]{figures/Abb73.png}
\includegraphics[width=.4\textwidth]{figures/Abb21-legend.png}
}
\end{floatrow}
\end{figure}

Eine genauere Untersuchung der Fehlertypen anhand von Beispielen ist unter \sectref{sec:5.3.5.3}.

\subsubsubsection{Vergleich der Fehleranzahl auf Regel- und MÜ-Systemebene}

Wie \figref{fig:05:74} zeigt, stieg die Fehleranzahl bei allen Systemen außer dem SMÜ-System SDL nachdem die Sätze ohne Partizipialkonstruktionen formuliert wurden, allerdings war der Rückgang bei SDL insignifikant (Mdiff = $-$~0,125).


\begin{figure}
%\textbf{\textit{+~46,9~\%}}

%\textbf{+~19,2~\%}

%\textbf{$-$ 8,3~\%}



%\includegraphics[height=.3\textheight]{figures/d3-img068.png}

%\textbf{\textit{+~66,7~\%}}

%\textbf{\textit{+~100~\%}}


%\includegraphics[height=.3\textheight]{figures/d3-img023.png}\\
\begin{tikzpicture}
	\begin{axis}[
	ybar,
	ymin = 0,
	ymax = 50,
	axis lines* = left,
	nodes near coords,
  legend style={at={(0.5,-0.2)},anchor=north},
  xticklabels = {Bing,Google,Lucy,SDL,Systran},
  xtick=data,
  ylabel = {Summe},
  extra description/.code={
            \node at (axis cs:-.4, 25)[anchor=west] {$+$ 66,7 \%};
						\node at (axis cs:.5, 14)[anchor=west] {$+$ 100 \%};
						\node at (axis cs:1.5, 36)[anchor=west] {$+$ 19,2 \%};
						\node at (axis cs:2.5, 41)[anchor=west] {$-$ 8,3 \%};
						\node at (axis cs:3.5, 53)[anchor=west] {\bfitul{$+$ 46,9 \%}};
						}
	]
	\addplot+[tmnlpone]
	coordinates{
	(0,12)
	(1,4)
	(2,26)
	(3,36)
	(4,32)
	};
	\addplot+[tmnlpthree]
	coordinates{
	(0,20)
	(1,8)
	(2,31)
	(3,33)
	(4,47)
	};
	\legend{Anzahl der  fehler innerh. KS vor KS,Anzahl der Fehler innerh. KS nach KS}
	\end{axis}
\end{tikzpicture}
\caption{\label{fig:05:74}„Partizipialkonst. verm.“ -- Summe der Fehleranzahl vor vs. nach KS bei den einzelnen MÜ-Systemen   }
\bspnote{\bfitul{Signifikante Differenz vor vs. nach KS}}
\end{figure}

Die einzige signifikante Veränderung nach der Anwendung der KS-Regel entstand bei dem HMÜ-System Systran Mdiff = ,625; (z (N = 24) = $-$~2,156 / p = ,031). Die weiteren Anstiege waren nicht signifikant: Google Mdiff = ,167; Bing Mdiff = ,333; Lucy Mdiff = ,208.

Wie \figref{fig:05:74} zeigt, verzeichnete Google die niedrigste Fehleranzahl sowohl vor als auch nach der Regelanwendung; gleichzeitig stieg die Fehleranzahl nach KS. Auf der anderen Seite konnte das SMÜ-System SDL in manchen Fällen von der Regelanwendung profitieren, wie \tabref{tabex:05:50} demonstriert.


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & \textbf{Die für die Maschine benötigten Werkzeuge} sind im Lieferumfang nicht enthalten.\\
\tablevspace
SMÜ SDL & \textcolor{lsRed}{For the machine XXX tools required} are not included in the delivery.\\
GNMÜ & \textcolor{tmnlpthree}{The tools required for the machine} are not included in the delivery. \\
\midrule
\textbf{Nach-KS} & \textbf{Die Werkzeuge, die für die Maschine benötigt werden,} sind im Lieferumfang nicht enthalten.\\
\tablevspace
SMÜ SDL & \textcolor{tmnlpthree}{The tools that are required for the machine} are not included in the delivery.\\
GNMÜ & \textcolor{tmnlpthree}{The tools required for the machine} are not included in the delivery. \\
\lspbottomrule
\end{tabularx}\caption{\label{tabex:05:50}Beispiel 50   }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens; \txred{XXX} für ein fehlendes Wort oder Komma.}
\end{table}

Nachdem die Partizipialkonstruktion vermieden wurde, konnten der Wortstellungsfehler (GR10) und Auslassungsfehler (LX.3) in der KS-Stelle (in ‚For the machine tools required‘) korrigiert werden, während das NMÜ-System Google Translate in der Lage war, den Satz mit und ohne Partizipialkonstruktion fehlerfrei zu übersetzen.

\subsubsection{\label{sec:5.3.5.2}Aufteilung der Annotationsgruppen}

Wie \figref{fig:05:75} zeigt, war die größte Annotationsgruppe bei dieser Regel die Gruppe FF; 42~\% der Sätze wurden mit und ohne Partizipialkonstruktion falsch übersetzt.  Unter \sectref{sec:5.3.5.3} werden die persistenten Fehlertypen ins Visier genommen. Die zweitgrößte Gruppe war RR, repräsentiert mit 28~\%. Das zeigt, dass die Systeme mehr als ein Viertel der Sätze mit und ohne Partizipialkonstruktion fehlerfrei übersetzen konnten. Im nächsten Abschnitt werden die einzelnen Systeme auf Annotationsgruppenebene im Detail untersucht.


\begin{figure}
%\includegraphics[height=.3\textheight]{figures/d3-img012.png}

%\includegraphics[height=.3\textheight]{figures/d3-img069.png}
% 75
\torte{50}{11}{26}{33}
\caption{\label{fig:05:75}„Partizipialkonst. verm.“ -- Aufteilung der Annotationsgruppen   }
\end{figure}

Bei 22~\% der Sätze traten Fehler erst nach der Anwendung der Regel (Gruppe RF) auf, siehe \figref{fig:05:75}. Dies ist der höchste Prozentsatz der Gruppe RF unter allen analysierten Regeln. Wie oben erwähnt, war die Anwendung der Regel oft mit einer falschen Kommaplatzierung bei der Verwendung von Relativpronomen (‚which‘ vs. ‚that‘) verbunden, siehe \tabref{tabex:05:51}. Schließlich beinhaltete die MÜ in 9~\% der Fälle mindestens einen Fehler vor der Regelanwendung, der nach der Regelanwendung behoben wurde (Gruppe FR).

\subsubsubsection{Vergleich der Aufteilung der Annotationsgruppen auf Regel- und MÜ-Systemebene}

Mehr als die Hälfte der Sätze wurden bei drei MÜ-Systemen, dem RBMÜ-System Lucy (67~\%), SMÜ-System SDL (54~\%) und HMÜ-System Systran (54~\%), mit und ohne Partizipialkonstruktion (d.~h. sowohl vor als auch nach der Regelanwendung) falsch übersetzt (Annotationsgruppe FF). Bei den beiden HMÜ-Systemen Bing und Systran wurde jeweils ein Drittel der Übersetzungen (33~\%) mit Partizipialkonstruktion (vor KS) richtig und ohne Partizipialkonstruktion (nach KS) falsch übersetzt (Annotationsgruppe RF), mehr zu den Fehlertypen unter \sectref{sec:5.3.5.3}. Somit hatten die verschiedenen älteren MÜ-Ansätze Schwierigkeiten mit der Übersetzung in den beiden Szenarien.


\begin{figure}
%\includegraphics[height=.3\textheight]{figures/d3-img070.png}

% \textbf{25\%}  \textbf{8\%}   \textbf{67\% 54\%}  \textbf{54\%}           \textbf{13\%}   \textbf{8\%}           \textbf{17\%}  \textbf{8\%}             \textbf{33\%}  \textbf{13\% 17\% 13\%}  \textbf{33\%}            \textbf{29\% 71\% 17\%}  \textbf{17\%}  \textbf{4\%}

%\includegraphics[height=.3\textheight]{figures/d3-img026.png}\\
\begin{tikzpicture}
\tikzset{every node/.style={font=\scriptsize}};
	\begin{axis}[
  ybar,
	width = \textwidth,
	axis lines* = left,
	ylabel = {Anzahl},
	xtick = {3,9,15,21},
	xticklabels = {FF,FR,RF,RR},
  x tick label style ={yshift=-5pt},
	xtick=data,
  xlabel={Annotationsgruppe},
	ymin=0,
	ymax = 20,
%	bar shift = 0pt,
  bar width=9,
  enlarge x limits = .1,
	nodes near coords,
%	legend pos= north east,
	legend style={at={(0.5,-0.15)},anchor=north},
	legend columns = {-1},
	extra description/.code={
  \node at (axis cs:.9,7)[anchor = west]{5,0\%};
	\node at (axis cs:.7,-.5)[anchor = west]{25\%};
	\node at (axis cs:1.5,3)[anchor = west]{1,7\%};
	\node at (axis cs:1.6,-.5)[anchor = west]{8\%};
	\node at (axis cs:2.2,17)[anchor = west]{13,3\%};
	\node at (axis cs:2.2,-.5)[anchor = west]{67\%};
	\node at (axis cs:3,14)[anchor = west]{10,8\%};
	\node at (axis cs:3.1,-.5)[anchor = west]{54\%};
	\node at (axis cs:3.8,15)[anchor = west]{10,8\%};
	\node at (axis cs:4,-.5)[anchor = west]{54\%};
	\node at (axis cs:6.8,4)[anchor = west]{2,5\%};
	\node at (axis cs:6.8,-.5)[anchor = west]{13\%};
	\node at (axis cs:7.7,3)[anchor = west]{1,7\%};
	\node at (axis cs:7.7,-.5)[anchor = west]{8\%};
	\node at (axis cs:9,5)[anchor = west]{3,3\%};
	\node at (axis cs:9,-.5)[anchor = west]{17\%};
  \node at (axis cs:9.9,3)[anchor = west]{1,7\%};
  \node at (axis cs:9.9,-.5)[anchor = west]{8\%};
  \node at (axis cs:12.8,9)[anchor = west]{6,7\%};
  \node at (axis cs:12.7,-.5)[anchor = west]{33\%};
  \node at (axis cs:13.5,4)[anchor = west]{2,5\%};
  \node at (axis cs:13.5,-.5)[anchor = west]{13\%};
  \node at (axis cs:14.3,5)[anchor = west]{3,3\%};
  \node at (axis cs:14.3,-.5)[anchor = west]{17\%};
	\node at (axis cs:15,4)[anchor = west]{2,5\%};
	\node at (axis cs:15.1,-.5)[anchor = west]{13\%};
  \node at (axis cs:15.9,9)[anchor = west]{6,7\%};
  \node at (axis cs:15.9,-.5)[anchor = west]{33\%};
	\node at (axis cs:18.6,8)[anchor = west]{5,8\%};
	\node at (axis cs:18.6,-.5)[anchor = west]{29\%};
	\node at (axis cs:19.4,18)[anchor = west]{14,2\%};
	\node at (axis cs:19.5,-.5)[anchor = west]{71\%};
	\node at (axis cs:20.3,5)[anchor = west]{3,3\%};
	\node at (axis cs:20.3,-.5)[anchor = west]{17\%};
	\node at (axis cs:21,6)[anchor = west]{3,3\%};
	\node at (axis cs:21.2,-.5)[anchor = west]{17\%};
	\node at (axis cs:21.8,2)[anchor = west]{0,8\%};
	\node at (axis cs:22,-.5)[anchor = west]{4\%};
	}
	]
	\addplot+[lsNightBlue]
	coordinates {
	(3,6)
	(9,3)
	(15,8)
	(21,7)
	};
	\addplot+[tmnlpone]
	coordinates {
	(3,2)
	(9,2)
	(15,3)
	(21,17)
	};
	\addplot+[tmnlptwo]
	coordinates {
	(3,16)
	(9,0)
	(15,4)
	(21,4)
	};
	\addplot+[tmnlpthree]
	coordinates {
	(3,13)
	(9,4)
	(15,3)
	(21,4)
	};
	\addplot+[tmnlpfour]
	coordinates {
	(3,13)
	(9,2)
	(15,8)
	(21,1)
	};
	\legend{Bing,Google,Lucy,SDL,Systran}
	\end{axis}
\end{tikzpicture}
\caption{\label{fig:05:76}„Partizipialkonst. verm.“ -- Aufteilung der Annotationsgruppen bei den einzelnen MÜ-Systemen   }
\bspnote{Die oben angezeigten Prozentzahlen sind für alle Systeme, d. h. systemübergreifend, (N = 120) berechnet.

Die untenstehenden Prozentzahlen sind auf Systemebene (N = 24) berechnet.
}
\end{figure}

Dies steht in Kontrast zum neuen Ansatz der NMÜ von Google, bei dem 71~\% der Übersetzungen sowohl vor als auch nach der Anwendung der KS-Regel fehlerfrei waren (Annotationsgruppe RR).

\subsubsection{\label{sec:5.3.5.3}Vergleich der Fehlertypen mit und ohne die Verwendung von Partizipialkonstruktionen}

Nach der Anwendung dieser Regel verändert sich die Anzahl zweier Fehlertypen deutlich, und zwar stieg die Fehleranzahl bei Fehlertyp OR.1 „Orthografie -- Zeichensetzung“ und sank bei Fehlertyp GR.10 „Grammatik -- Falsche Wortstellung“. Beide Veränderungen erwiesen sich als signifikant p~<~,001 beim Fehlertyp OR.1 bzw. p = ,011 beim Fehlertyp GR.10 (N = 120).



\begin{figure}
%\includegraphics[height=.3\textheight]{figures/d3-img071.png}

%\textbf{\textit{1000~\%}}

%\textbf{\textit{$-$ 63,6~\%}}


%\includegraphics[height=.3\textheight]{figures/d3-img027.png}

%\includegraphics[height=.3\textheight]{figures/d3-img013.png}



%\includegraphics[height=.3\textheight]{figures/d3-img013.png} & vor KS
% 77
\pgfplotstableread{
1 5
2 55
3 2
4 0
5 17
6 16
7 6
8 2
9 0
10 0
11 0
12 0
13 2
14 1
15 0
16 5
17 9
18 8
19 33
20 12
21 23
22 24
23 10
24 10
25 3
26 6
}\datatable
\smbars[
extra description/.code={
\node at (axis cs:.3,60)[anchor = west]{\bfitul{1000\%}};
\node at (axis cs:18,38)[anchor = west]{\bfitul{$-$ 63,6\%}};
}
]{}
\caption{\label{fig:05:77}„Partizipialkonst. verm.“ -- Summe der Fehleranzahl der einzelnen Fehlertypen vor vs. nach KS   }
\bspnote{*Die X-Achse ist folgendermaßen zu lesen: Jeder Fehlertyp wird anhand von zwei Balken abgebildet. Der erste Balken repräsentiert die Summe der Fehler vor KS und der zweite die Summe der Fehler nach KS, somit steht z. B. „OR\_1.v“ für „OR\_1: orthografischer Fehler Nr. 1“ und „v: vor KS“; „OR\_1.n“ wäre entsprechend das Pendant zu „OR\_1.v“ für das nach-KS-Szenario („n“).

**\bfitul{Signifikante Differenz vor vs. nach KS}

OR.1: Orthografie -- Zeichensetzung\\
OR.2: Orthografie -- Großschreibung\\
LX.3: Lexik -- Wort ausgelassen\\
LX.4: Lexik -- Zusätzliches Wort eingefügt\\
LX.5: Lexik -- Wort unübersetzt geblieben (auf DE wiedergegeben)\\
LX.6: Lexik -- Konsistenzfehler\\
GR.7: Grammatik -- Falsche Wortart / Wortklasse\\
GR.8: Grammatik -- Falsches Verb (Zeitform, Komposition, Person)\\
GR.9: Grammatik -- Kongruenzfehler (Agreement)\\
GR.10: Grammatik -- Falsche Wortstellung\\
SM.11: Semantik -- Verwechslung des Sinns\\
SM.12: Semantik -- Falsche Wahl\\
SM.13: Semantik -- Kollokationsfehler\\
}
\end{figure}


Um diese KS-Regel umzusetzen, wird die Partizipialkonstruktion aufgelöst, indem daraus einen Nebensatz gebildet wird. Die Übersetzung des Nebensatzes ins Englische erfordert eine Ermittlung des adäquaten Relativpronomens, d.~h. eine Unterscheidung zwischen Relativpronomen wie ‚which‘ und ‚that‘.  Dieser Unterscheidung bedarf in der Regel Kontextinformationen und nicht selten ist sie auch für den Humanübersetzer problematisch (vgl. \citealt{Swan1980}:~527ff.).\footnote{\textrm{Man unterscheidet im Englischen zwischen restriktiven und nicht-restriktiven Relativsätzen: Im restriktiven Relativsatz wird die Bedeutung des Nomens, das beschrieben wird, begrenzt. Ohne den restriktiven Relativsatz ändert sich die Bedeutung des gesamten Satzes. Für restriktive Relativsätze verwendet man ‚that‘. Der nicht-restriktiver Relativsatz bietet lediglich zusätzliche Informationen über das Nomen und kann ohne Einfluss auf die Bedeutung entfernt werden. Für nicht-restriktive Relativsätze verwendet man ‚which‘. (vgl. \citealt{Swan1980}: 527ff.)} } Da die Entscheidung über Relativpronomen wie ‚which‘ und ‚that‘ engverbunden mit der Verwendung bzw. Nichtverwendung von Kommas ist (ebd.), stieg die Frequenz des Fehlertyps OR.1 „Orthografie -- Zeichensetzung“ jedes Mal, wenn ein falsches Relativpronomen bei der Übersetzung verwendet wurde, und zwar von 5 auf 55 (1000~\% / Mv = ,04 / SDv = ,239 / Mn = ,46 / SDn = ,660 / N = 120). In \tabref{tabex:05:51} fehlte nach der Regelanwendung das Komma bevor ‚which‘.


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & Das Gerät verbindet sich mit \textbf{der neu gewählten Netzwerkadresse.}\\
\tablevspace
GNMÜ & The device connects to \txblue{the newly selected network address}.\\
\midrule
\textbf{Nach-KS} & Das Gerät verbindet sich mit \textbf{der Netzwerkadresse, die neu gewählt wird.}\\
\tablevspace
GNMÜ & The device connects to \txblue{the network address}\txred{,} \txblue{which is selected} \txred{again}.\\
\lspbottomrule
\end{tabularx}\caption{\label{tabex:05:51}Beispiel 51   }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

Auf der anderen Seite erschwerten Partizipialkonstruktionen, insbesondere lange Partizipialkonstruktionen, den MÜ-Systemen die Aufgabe, eine korrekte Wortstellung zu produzieren. Eine Auflösung der Partizipialkonstruktion (nach KS) konnte helfen, die Fehleranzahl vom Fehlertyp GR.10 „Grammatik -- Falsche Wortstellung“ von 33 auf 12 ($-$~64~\% / Mv = ,28 / SDv = ,579 / Mn = ,10 / SDn = ,301 / N = 120) zu reduzieren (siehe \tabref{tabex:05:52}).

\subsubsubsection{Vergleich der Fehlertypen auf Regel- und MÜ-Systemebene}

Eine genauere Untersuchung der Fehlertypen bei den verschiedenen MÜ-Sys\-te\-men zeigt, dass der allgemein signifikante Unterschied in der Fehleranzahl des Fehlertyps OR.1 „Orthografie -- Zeichensetzung“ bei den Systemen Bing, SDL und Systran und des Fehlertyps GR.10 „Grammatik -- Falsche Wortstellung“ nur bei dem System SDL zu beobachten war (\figref{fig:05:78}). Bei den Systemen Google und Lucy gab es keinen bestimmten Fehlertyp, dessen Fehleranzahl nach der Regelanwendung eine signifikante Änderung aufwies. Darüber hinaus fiel die Fehleranzahl aller Fehlertypen bei Google sowohl vor als auch nach der Regelanwendung sehr gering aus.


\begin{figure}
%\includegraphics[height=.3\textheight]{figures/d3-img072.png}



%\includegraphics[height=.3\textheight]{figures/d3-img026.png}\\
\begin{tikzpicture}
\tikzset{every node/.style={font=\scriptsize}};
	\begin{axis}[
	xbar,
	width = \textwidth,
	height = .83\textheight,
	axis lines* = left,
	xlabel = {Summe},
	ytick = {1,2,3,...,18},
	yticklabels = {IN\_OR\_1.v,
  IN\_OR\_1.n,
  IN\_LX\_3.v,
	IN\_LX\_3.n,
	IN\_LX\_4.v,
	IN\_LX\_4.n,
	IN\_GR\_8.v,
	IN\_GR\_8.n,
  IN\_GR\_9.v,
	IN\_GR\_9.n,
	IN\_GR\_10.v,
	IN\_GR\_10.n,
	IN\_SM\_11.v,
	IN\_SM\_11.n,
	IN\_SM\_12.v,
	IN\_SM\_12.n,
	IN\_SM\_13.v,
	IN\_SM\_13.n
	},
%	x tick label style={rotate=60,anchor=east,font=\scriptsize},
	enlarge y limits={.032},
	xmin=0,
	xmax = 30,
%	bar shift = 1pt,
  	bar width=2,
	nodes near coords,
	legend pos = south east,
	reverse legend,
%	legend style={at={(0.5,-0.1)},anchor=north},
%	legend columns = {-1},
	]
	\addplot+[tmnlpone]
	coordinates {
	(1,1)
	(11,2)
	(2,3)
	(2,4)
	(1,5)
	(1,6)
	(0,7)
	(0,8)
	(1,9)
	(2,10)
	(3,11)
	(0,12)
	(3,13)
	(2,14)
  (0,15)
  (0,16)
  (0,17)
  (0,18)
	};
	\addplot+[lsLightOrange]
	coordinates {
	(0,1)
	(6,2)
	(2,3)
	(1,4)
	(1,5)
	(0,6)
	(0,7)
	(0,8)
	(0,9)
	(0,10)
	(0,11)
	(0,12)
	(1,13)
	(2,14)
  (0,15)
  (0,16)
  (0,17)
  (0,18)
	};
	\addplot+[smGreen]
	coordinates {
	(1,1)
	(3,2)
	(1,3)
	(2,4)
	(1,5)
	(0,6)
	(0,7)
	(2,8)
	(2,9)
	(2,10)
	(6,11)
	(7,12)
	(8,13)
	(8,14)
  (5,15)
  (5,16)
  (1,17)
  (2,18)
	};
	\addplot+[tmnlpthree]
	coordinates {
	(1,1)
	(8,2)
	(8,3)
	(9,4)
	(3,5)
	(1,6)
	(0,7)
	(2,8)
	(3,9)
	(2,10)
	(16,11)
	(5,12)
	(2,13)
	(4,14)
  (1,15)
  (1,16)
  (0,17)
  (1,18)
	};
	\addplot+[lsRed]
	coordinates {
	(2,1)
	(28,2)
	(4,3)
	(2,4)
	(0,5)
	(0,6)
	(0,7)
	(1,8)
	(3,9)
	(2,10)
	(8,11)
	(0,12)
	(9,13)
	(8,14)
  (4,15)
  (4,16)
  (2,17)
  (2,18)
	};
	\legend{Bing,Google,Lucy,SDL,Systran}
	\end{axis}
\end{tikzpicture}
\caption{\label{fig:05:78}„Partizipialkonst. verm.“ -- Summe der Fehleranzahl der Fehlertypen vor vs. nach KS bei den einzelnen MÜ-Systemen   }
\bspnote{*Die Balken zeigen die Summe der Fehleranzahl bei jedem Fehlertyp, wobei „v“ für die Summe „vor der Anwendung der KS-Regel“ und „n“ für die Summe „nach der Anwendung der KS-Regel“ steht. Jeder Fehlertyp wird erst für alle Systeme für das Szenario „vor KS“ abgebildet, danach folgt derselbe Fehlertyp wieder für alle Systeme für das Szenario „nach KS“.

**Um die Übersichtlichkeit und Lesbarkeit der Grafik zu erhöhen, wurden in der Grafik die Fehlertypen ausgeblendet, die 0 oder nur einmal bei \textit{allen} MÜ-Systemen vorkamen: In dieser Grafik kamen die Fehlertypen 5 und 6 bei gar keinem MÜ-System vor. Zudem kamen die Fehlertypen 2 und 7 nur einmal jeweils bei 2--3 MÜ-Systemen in vereinzelten Fällen vor.}
\end{figure}

Der Fehlertyp OR.1 stieg deutlich bei Bing von 1 auf 11 (+~1000~\%), bei SDL von 1 auf 8 (+~700~\%) und bei Systran von 2 auf 28 (+~1300~\%). Der Fehlertyp GR.10 sank bei SDL von 16 auf 5 ($-$~68,8~\%). Die Differenz in der Fehleranzahl der beiden Typen OR.1 und GR.10 erwies sich in den genannten Systemen folgendermaßen als signifikant (\tabref{tab:05:55}).


\begin{table}
\begin{tabularx}{.86\textwidth}{lrlll}

\lsptoprule
& \textbf{N} & \textbf{Mittelwert} & \textbf{Standard-} &{ \textbf{Signifikanz}}\\
& & & \textbf{abweichung} & \textbf{(McNemar-Test)}\\
\midrule
\multicolumn{5}{l}{\textbf{OR.1 „Zeichensetzung“}}\\
 \textbf{Bing} & 24 & vor KS = ,04 & vor KS = ,204 & p = ,002\\
& & nach KS = ,46 & nach KS = ,509 & \\
 \textbf{SDL} & 24 & vor KS = ,04 & vor KS = ,204 & p = ,016\\
& & nach KS = ,33 & nach KS = ,482 & \\
 \textbf{Systran} & 24 & vor KS = ,08 & vor KS = ,408 & p < ,001\\
& & nach KS = 1,17 & nach KS = ,702 & \\
\midrule
\multicolumn{5}{l}{\textbf{GR.10 „Falsche Wortstellung“}}\\
 \textbf{SDL} & 24 & vor KS = ,67 & vor KS = ,761 & p = ,016\\
& & nach KS = ,21 & nach KS = ,415 & \\
 \textbf{Systran} & 24 & vor KS = ,33 & vor KS = ,702 & p = ,037\\
& & nach KS = ,38 & nach KS = ,576 & \\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:55}„Partizipialkonst. verm.“ -- Fehlertypen mit signifikanter Veränderung nach KS   }
\end{table}

Bei dem SMÜ-System SDL und dem HMÜ-System Systran wurde der Fehlertyp GR.10 „Grammatik -- Falsche Wortstellung“ nach dem Zerlegen der Partizipialkonstruktion (nach KS) behoben. Dieses Ergebnis ist in SMÜ-Systemen im Falle von Partizipialkonstruktionen, die in den Trainingsdaten nicht (häufig) vorkommen, zu erwarten, da das Zerlegen solcher Partizipialkonstruktionen das SMÜ-System dabei unterstützt, eine korrekte Wortstellung zu produzieren.


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & Durch Eingabe \textbf{der mit einem roten Sternchen gekennzeichneten Parameter} erfolgt die minimale Konfigurierung.\\
\tablevspace
SMÜ SDL & By entering \txred{the marked with a red asterisk parameter}, the minimum configuration is performed.\\
\midrule
\textbf{Nach-KS} & Durch Eingabe \textbf{der Parameter, die mit einem roten Sternchen gekennzeichnet sind}, erfolgt die minimale Konfigurierung.\\
\tablevspace
SMÜ SDL & By entering \txblue{the parameters that are marked with a red asterisk}, the minimum configuration is performed.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:52}Beispiel 52   }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txblue{Rot} für die falschen Tokens.}
\end{table}

\tabref{tabex:05:52} zeigt, wie das Vermeiden der Partizipialkonstruktion SDL u. a. dabei unterstützte, den Wortstellungsfehler zu korrigieren.

\subsubsection{\label{sec:5.3.5.4}Vergleich der MÜ-Qualität mit und ohne die Verwendung von Partizipialkonstruktionen sowie die Korrelation zwischen den Fehlertypen und der Qualität}

Nachdem die Partizipialkonstruktionen vermieden wurden (nach KS), sanken sowohl die Stil- als auch die Inhaltsqualität.\footnote{\textrm{Definitionen der Qualität unter \sectref{sec:4.4.5.1}.}} Auf den ersten Blick erkennt man in \figref{fig:05:80}, dass der Einfluss auf die Stilqualität im Vergleich zur Inhaltsqualität größer ausfiel. Die Stilqualität sank um 7,8~\% (Mv = 3,97 / SDv = ,658 / Mn = 3,66 / SDn = ,535 / N = 98). Die Inhaltsqualität sank um 1,7~\% (Mv = 4,23 / SDv = ,789 / Mn = 4,16 / SDn = ,726 / N = 98) (\figref{fig:05:79}). Der Mittelwert der Differenz (nach KS $-$ vor KS) der vergebenen Qualitätspunkte pro Satz lag für die Stilqualität bei $-$~,312 (SD = ,575) mit einem 95\%\nobreakdash-Konfidenzintervall zwischen einem Minimum von $-$~,428 und einem Maximum von $-$~,196 und für die Inhaltsqualität bei $-$~,066 (SD = ,714) mit einem 95\%\nobreakdash-Konfidenzintervall zwischen einem Minimum von $-$~,210 und einem Maximum von ,078 (Bootstrapping mit 1000 Stichproben) (\figref{fig:05:80}). Nur die Differenz (nach KS $-$ vor KS) in der Stilqualität erwies sich als hochsignifikant (z (N = 98) = $-$ 4,997 / p < ,001). Bei der Inhaltsqualität war die Differenz insignifikant (z (N = 98) = $-$~,597 / p = ,550).


\begin{figure}
%\includegraphics[height=.3\textheight]{figures/d3-img029.png}

%\textbf{3,844,10}

%\textbf{3,554,76}

%\textbf{4,024,31}

%\textbf{4,074,39}



%\includegraphics[height=.3\textheight]{figures/d3-img030.png}



%\includegraphics[height=.3\textheight]{figures/d3-img029.png} &  & %%[Warning: Draw object ignored]


%\includegraphics[height=.3\textheight]{figures/d3-img017.png}

%\includegraphics[height=.3\textheight]{figures/d3-img017.png}

\captionsetup{width=.45\textwidth}
\begin{floatrow}
\ffigbox[.5\textwidth]{\caption{„Partizipialkonst. verm.“ -- Mittelwerte der Qualität vor und nach KS}\label{fig:05:79}}{
\includegraphics[width=.25\textwidth]{figures/Abb79.png}
\includegraphics[width=.2\textwidth]{figures/Abb15-legend.png}
}
\ffigbox[.45\textwidth]{\caption{„Partizipialkonst. verm.“ -- Mittelwert der Qualitätsdifferenzen}\label{fig:05:80}}{
\includegraphics[width=.25\textwidth]{figures/Abb16-legend.png}
\includegraphics[width=.3\textwidth]{figures/Abb80.png}
}
\end{floatrow}

\end{figure}

\tabref{tabex:05:53} zeigt einen Satz, der zwar mit und ohne Partizipialkonstruktion fehlerfrei übersetzt wurde, allerdings sanken sowohl die Stilqualität ($-$~,75 Punkte auf der Likert-Skala) als auch die Inhaltsqualität ($-$~,25 Punkte auf der Likert-Skala), nachdem die Partizipialkonstruktion vermieden wurde (nach KS).


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & \textbf{Die für Ihren Flug erlaubte Freigepäckmenge} ist auf Ihrem Flugschein angegeben.\\
\tablevspace
HMÜ Systran & \textcolor{tmnlpthree}{The free luggage quantity permitted for your flight} is provided on your ticket.\\
\midrule
\textbf{Nach-KS} & \textbf{Die Freigepäckmenge, die für Ihren Flug erlaubt ist,} ist auf Ihrem Flugschein angegeben.\\
\tablevspace
HMÜ Systran & \textcolor{tmnlpthree}{The free luggage quantity, which is permitted for your flight,} is provided on your ticket.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:53}Beispiel 53   }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

Eine genaue Betrachtung der in der Humanevaluation identifizierten Qualitätskriterien (\figref{fig:05:81}) verrät, dass der Rückgang bei der Stilqualität überwiegend an der unklaren Darstellung (SQ1) sowie der unnatürlichen Formulierung (SQ3) und bei der Inhaltsqualität insbesondere an der beeinträchtigen Verständlichkeit (CQ2) lag.


\begin{figure}
%\textbf{+~19~\%}

%\textbf{+~19~\%}

%\textbf{$-$ 1~\%}

%\textbf{+~149~\%}

%\textbf{+~2~\%}
\pgfplotstableread{
1 51
2 127
3 87
4 86
5 475
6 567
7 203
8 207
9 202
10 240
}\datatable

\begin{tikzpicture}
    \begin{axis}[ybar,
                enlarge x limits={.05},
                width  = \textwidth,
                height = .45\textheight,
                axis lines*=left,
                axis on top,
                bar width=8.5,
                bar shift=0pt,
                ymin = 0,
                ymax=600,
                xtick = {1,2,...,10},
                xticklabels={SQ1\_v,
                SQ1\_n,
                SQ2\_v,
                SQ2\_n,
                SQ3\_v,
                SQ3\_n,
                CQ1\_v,
                CQ1\_n,
                CQ2\_v,
                CQ2\_n},
            x tick label style={font=\small},
            nodes near coords,
 	 extra description/.code={
	 \node at (axis cs:0.9,200)[anchor = west]{$+$ 149\%};
	 \node at (axis cs:3,150)[anchor = west]{$-$ 1\%};
	  \node at (axis cs:4.8,600)[anchor = west]{$+$ 19\%};
	   \node at (axis cs:7,270)[anchor = west]{$+$ 2\%};
	    \node at (axis cs:9,300)[anchor = west]{$+$ 19\%};
	  }
            ]
        \addplot +[shift={(.5,0)},lsDarkBlue,x filter/.code={\ifodd\coordindex\def\pgfmathresult{}\fi}] table {\datatable};
        \addplot +[shift={(-.5,0)},lsMidBlue,  x filter/.code={\ifodd\coordindex\relax\else\def\pgfmathresult{}\fi}] table {\datatable};
    \end{axis}
\end{tikzpicture}
\caption{\label{fig:05:81}„Partizipialkonst. verm.“ -- Vergleich der Qualitätskriterien   }
\bspnote{\textbf{SQ1:} Ü ist \textbf{\textit{nicht}} korrekt bzw. \textbf{\textit{nicht}} klar dargestellt, d. h. nicht orthografisch.\\
\textbf{SQ2:} Ü ist \textbf{\textit{nicht}} ideal für die Absicht des Satzes, d. h. motiviert den Nutzer \textbf{\textit{nicht} }zum Handeln, zieht \textbf{\textit{nicht} }seine Aufmerksamkeit an usw.\\
\textbf{SQ3:} Ü klingt \textbf{\textit{nicht} }natürlich bzw. \textbf{\textit{nicht} }idiomatisch.\\
\textbf{CQ1:} Ü gibt die Informationen im Ausgangstext \textbf{\textit{nicht}} exakt wieder.
 \textbf{CQ2:} Ü ist \textbf{\textit{nicht}} leicht zu verstehen, d. h. \textbf{\textit{nicht}} gut formuliert bzw. dargestellt.}
\end{figure}

In \tabref{tabex:05:53} fanden die Bewerter die MÜ vor der Anwendung der KS-Regel (mit Partizipialkonstruktion) prägnanter und idiomatischer. In einem weiteren Beispiel, in dem die MÜ mit und ohne Partizipialkonstruktion Fehler beinhaltete, sanken die Stilqualität ($-$~,63 Punkte auf der Likert-Skala) und die Inhaltsqualität ($-$~,50 Punkte auf der Likert-Skala) nach der Regelanwendung (\tabref{tabex:05:54}).


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & \textbf{Die für Ihren Flug erlaubte Freigepäckmenge} ist auf Ihrem Flugschein angegeben.\\
\tablevspace
SMÜ SDL & \textcolor{tmnlpthree}{The} \txred{for your flight allowed free baggage allowance} is provided on your ticket.\\
\midrule
\textbf{Nach-KS} & \textbf{Die Freigepäckmenge, die für Ihren Flug erlaubt ist,} ist auf Ihrem Flugschein angegeben.\\
\tablevspace
SMÜ SDL & \textcolor{tmnlpthree}{The free baggage allowance}\txred{XXX} \txblue{for your flight} \txred{XXX is allowed}\txblue{,} is provided on your ticket.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:54}Beispiel 54   }
\bspnote{ Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens; \txred{XXX} für ein fehlendes Wort oder Komma.}
\end{table}

Die Wortstellungsfehler (GR.10) wurden nach der Regelanwendung nicht behoben. Zudem kamen zwei neue Fehler hinzu: der orthografische Fehler OR.1 (fehlendes Komma) und der lexikalische Fehler LX.3 (Auslassen des Relativpronomens ‚that‘). Entsprechend wurden die Verständlichkeit und Idiomatik der MÜ beeinträchtigt.

\subsubsection{Korrelation zwischen den Fehlertypen und der Qualität}

Auf Basis der Fehlerannotation zusammen mit der Humanevaluation gibt uns eine Spearman-Korrelationsanalyse Aufschluss, wie die Veränderung bei der Fehleranzahl jedes Fehlertyps (Anz. nach KS $–$ Anz. vor KS) mit den Qualitätsunterschieden (Q. nach KS $–$ Q. vor KS) zusammenhängt. Mithilfe des Spearman-Tests erwies sich ein signifikanter mittlerer negativer Zusammenhang zwischen der Differenz im Fehlertyp LX.4 und der Differenz in der Stilqualität. Außerdem erwies sich ein signifikanter schwacher negativer Zusammenhang zwischen der Differenz in den Fehlertypen OR.1, LX.3, GR.9, GR.10 und SM.11 einzeln und der Differenz in der Stilqualität. (\tabref{tab:05:56})

Bezüglich der Inhaltsqualität erwies sich ein signifikanter mittlerer negativer Zusammenhang zwischen der Differenz in den Fehlertypen LX.3, LX.4 und GR.10 einzeln und der Differenz in der Inhaltsqualität sowie ein signifikanter schwacher negativer Zusammenhang zwischen der Differenz in den Fehlertypen GR.9 und SM.11 einzeln und der Differenz in der Inhaltsqualität. (\tabref{tab:05:56})

Weitere Korrelationen zwischen anderen einzelnen Fehlertypen und der Qualität konnten nicht erwiesen werden.


\begin{table}
\begin{tabularx}{\textwidth}{Xrrr}

\lsptoprule
& \textbf{N} & \textbf{p} & \textbf{ρ}\\
\midrule
\textbf{Differenz SQ (nach KS $-$ vor KS)} &  &  & \\
Diff. der Anzahl der \textbf{OR.1 „Zeichensetzung“} & 97 & ,006 & $-$~,278\\
Diff. der Anzahl der \textbf{LX.3 „Wort ausgelassen“} & 97 & ,004 & {$-$~,293}\\
Diff. der Anzahl der \textbf{LX.4 „Zusätzliches Wort eingefügt“} & 97 & ,001 & \txgreen{$-$~,334}\\
Diff. der Anzahl der \textbf{GR.9 „Kongruenzfehler“} & 97 & ,038 & $-$~,211\\
Diff. der Anzahl der \textbf{GR.10 „Wortstellungsfehler“} & 97 & ,010 & {$-$~,260}\\
Diff. der Anzahl der \textbf{SM.11 „Verwechslung des Sinns“} & 97 & ,009 & $-$~,265\\
\midrule
\textbf{Differenz CQ (nach KS $-$ vor KS)} &  &  & \\
Diff. der Anzahl der \textbf{OR.1 „Zeichensetzung“} & 97 & \txgray{,395} & $-$~,087\\
Diff. der Anzahl der \textbf{LX.3 „Wort ausgelassen“} & 97 & < ,001 & \txgreen{$-$~,462}\\
Diff. der Anzahl der \textbf{LX.4 „Zusätzliches Wort eingefügt“} & 97 & ,001 & \txgreen{$-$~,338}\\
Diff. der Anzahl der \textbf{GR.9 „Kongruenzfehler“} & 97 & ,014 & $-$~,250\\
Diff. der Anzahl der \textbf{GR.10 „Wortstellungsfehler“} & 97 & ,002 & \txgreen{$-$~,307}\\
Diff. der Anzahl der \textbf{SM.11 „Verwechslung des Sinns“} & 97 & ,023 & $-$~,230\\
\midrule
\textbf{Differenz allg. Q (nach KS $-$ vor KS)} &  &  & \\
Diff. der Anzahl der \textbf{OR.1 „Zeichensetzung“} & 97 & ,037 & $-$~,212\\
Diff. der Anzahl der \textbf{LX.3 „Wort ausgelassen“} & 97 & < ,001 & \txgreen{$-$~,413}\\
Diff. der Anzahl der \textbf{LX.4 „Zusätzliches Wort eingefügt“} & 97 & < ,001 & \txgreen{$-$~,350}\\
Diff. der Anzahl der \textbf{GR.9 „Kongruenzfehler“} & 97 & ,011 & $-$~,257\\
Diff. der Anzahl der \textbf{GR.10 „Wortstellungsfehler“} & 97 & ,001 & \txgreen{$-$~,324}\\
Diff. der Anzahl der \textbf{SM.11 „Verwechslung des Sinns“} & 97 & ,010 & \txgreen{$-$~,260}\\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:56}„Partizipialkonst. verm.“ -- Korrelation zwischen den Fehlertypen und der Qualität   }
\bspnote{*In der Tabelle werden nur die Fehlertypen dargestellt, die mindestens mit einer Qualitätsvariable signifikant korrelieren.
\begin{tabbing}
p: Signifikanz\hspace{2.5cm} \= \txgray{nicht signifikant (p ${\geq}$ 0,05)}\hspace{.5cm} \= ρ: Korrelationskoeffizient\\
schwache Korrelation (ρ >=0,1) \> \txgreen{mittlere Korrelation (ρ >= 0,3)} \> \boxblue{starke Korrelation (ρ >= 0,5)}
\end{tabbing}}
\end{table}

Diese signifikanten negativen Korrelationen deuten darauf hin, dass sobald die Fehleranzahl der genannten Fehlertypen sank, die Qualität zunahm, und umgekehrt. In \tabref{tabex:05:55} wurden der lexikalische Fehler LX.4 „Zusätzliches Wort eingefügt“ (in ‚coordinated‘) und der Wortstellungsfehler GR.10 (in ‚accessories‘) eliminiert, daraufhin stieg die Qualität deutlich.


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & \textbf{Speziell auf diese Lautsprecher abgestimmtes Zubehör} erhalten Sie in unserem Webshop.\\
\tablevspace
SMÜ SDL & \textcolor{lsRed}{Designed specifically for these speakers coordinated accessories} are available in our webshop.\\
\midrule
\textbf{Nach-KS} & \textbf{Zubehör, das speziell auf diese Lautsprecher abgestimmt ist,} erhalten Sie in unserem Webshop.\\
\tablevspace
SMÜ SDL & \textcolor{tmnlpthree}{Accessories that are specially adapted to these speakers} are available in our webshop.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:55}Beispiel 55   }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

Die Stilqualität verbesserte sich um 1,25 Punkte und die Inhaltsqualität um 1,75 Punkte auf der Likert-Skala nach der Formulierung des Satzes ohne Partizipialkonstruktion (nach KS).

\subsubsubsection{Vergleich der Qualität auf Regel- und MÜ-Systemebene}

Wie \figref{fig:05:82} zeigt, sank die Stilqualität signifikant bei dem HMÜ-System Bing (SQ $-$~13,9~\%), dem MNÜ-System Google Translate (SQ $-$ 9,4~\%) sowie bei dem RBMÜ-System Lucy (SQ $-$~6,2~\%). Bei dem SMÜ-System SDL und dem HMÜ-System Systran sank ebenfalls die Stilqualität nach der Regelanwendung, allerdings war der Rückgang nicht groß und entsprechend insignifikant.

Auf der anderen Seite blieb die Inhaltsqualität vor und nach der Regelanwendung bei allen Systemen bis auf das HMÜ-System Systran ohne große Veränderung: Bei dem HMÜ-System Systran stieg die Inhaltsqualität signifikant um 6,2~\%. Gleichzeitig sank die Inhaltsqualität bei dem anderen HMÜ-System Bing\textbf{ }mit einem insignifikanten Prozentsatz von $-$ 7,9~\%. Bei den anderen Systemen war die Veränderung minimal und entsprechend insignifikant.


\begin{figure}
\includegraphics[width=\textwidth]{figures/d3-img073.png}
%\includegraphics[height=.3\textheight]{figures/d3-img033.png}\\
\caption{\label{fig:05:82}„Partizipialkonst. verm.“ -- Mittelwerte der Qualität vor vs. nach KS bei den einzelnen MÜ-Systemen   }
\end{figure}

\tabref{tab:05:57} zeigt, dass der Rückgang in der Stilqualität bei drei Systemen, nämlich Bing, Google und Lucy, signifikant war. Bei Bing und Google waren die größten Annotationsgruppen RR und RF, d.~h. dass die Mehrheit der Sätze vor der Regelanwendung fehlerfrei übersetzt wurde (siehe \sectref{sec:5.3.5.2}). Eine korrekt übersetzte Partizipialkonstruktion zeigte sich in der Analyse der Qualitätskriterien als idiomatischer bzw. stilistischer als eine korrekt übersetzte aufgelöste Partizipialkonstruktion. Dies erklärt den signifikanten Rückgang der Stilqualität bei Bing und Google.


\begin{table}
\begin{tabularx}{\textwidth}{lrrrrrrrrr}

\lsptoprule
& \multicolumn{3}{c}{ \textbf{Differenz SQ} } & \multicolumn{3}{c}{ \textbf{Differenz CQ}} & \multicolumn{3}{c}{ \textbf{Differenz allg. Q} }\\
& \multicolumn{3}{c}{\textbf{(nach KS $-$ vor KS)}} &  \multicolumn{3}{c}{\textbf{(nach KS $-$ vor KS)}}  & \multicolumn{3}{c}{\textbf{(nach KS $-$ vor KS)}} \\
\cmidrule(lr){2-4}\cmidrule(lr){5-7}\cmidrule(lr){8-10}
& \textbf{N} & \textbf{p} & \textbf{z} & \textbf{N} & \textbf{p} & \textbf{z} & \textbf{N} & \textbf{p} & \textbf{z}\\
\midrule
 \textbf{Bing} & 18 & ,003 & $-$ 3,004 & 18 & \txgray{,088} & $-$~1,707 & 18 & ,009 & $-$ 2,616\\
 \textbf{Google} & 23 & ,001 & $-$ 3,261 & 23 & \txgray{,094} & $-$~1,674 & 23 & ,001 & $-$ 3,436\\
 \textbf{Lucy} & 21 & ,006 & $-$ 2,734 & 21 & \txgray{,830} & $-$~,214 & 21 & \txgray{,058} & $-$~1,896\\
 \textbf{SDL} & 18 & \txgray{,522} & $-$~,641 & 18 & \txgray{,711} & $-$~,371 & 18 & \txgray{,868} & $-$~,166\\
 \textbf{Systran} & 17 & \txgray{,124} & $-$~1,538 & 17 & ,039 & $-$ 2,064 & 17 & \txgray{,812} & $-$~,238\\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:57}„Partizipialkonst. verm.“ -- Signifikanz der Qualitätsveränderung bei den einzelnen MÜ-Systemen   }
\bspnote{p: Signifikanz\hspace{2.5cm}  z: Teststatistik\hspace{2.5cm} \txgray{nicht signifikant (p ${\geq}$ 0,05)}}
\end{table}

Bei Lucy wurde die Mehrheit der Sätze vor und nach der Regelanwendung falsch übersetzt (Gruppe FF 67~\%, siehe \figref{fig:05:76}). Die Humanevaluation zeigte, dass knapp 65~\% (9 von 14 Sätzen) der Sätze der FF Gruppe bei Lucy nach der Regelanwendung stilistisch schlechter bewertet wurden. In \tabref{tabex:05:56} sank die Inhaltsqualität ($-$~,63 Punkte auf der Likert-Skala), während die Inhaltsqualität anstieg (+~0,38 Punkte auf der Likert-Skala) -- nach der Regelanwendung.


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & \textbf{Die in den Bedienungsanweisungen der eingebauten Geräte vorgeschriebenen Gebrauchsbedingungen} müssen strikt eingehalten werden.\\
\tablevspace
RBMÜ Lucy & \textcolor{tmnlpthree}{The} \txred{use conditions} \txblue{stipulated in the} \txred{service instructions} \txblue{of the built-in devices} must be strictly adhered to.\\
\midrule
\textbf{Nach-KS} & \textbf{Die Gebrauchsbedingungen, die in den Bedienungsanweisungen der eingebauten Geräte vorgeschrieben sind,} müssen strikt eingehalten werden.\\
\tablevspace
RBMÜ Lucy & \textcolor{tmnlpthree}{The} \txred{use conditions} \txblue{which are stipulated in the} \txred{service instructions} \txblue{of the built-in devices} must be strictly adhered to.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:56}Beispiel 56   }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens; \txred{XXX} für ein fehlendes Wort oder Komma.}
\end{table}

\subsubsubsection{Korrelation zwischen den Fehlertypen und der Qualität auf Regel- und MÜ-Systemebene}

Anhand der Spearman-Korrelationsanalyse erwies sich bei dem HMÜ-System Bing ein stark signifikanter negativer Zusammenhang zwischen Fehlertyp GR.10 „Wortstellungsfehler“ und der Stilqualität sowie ein signifikanter mittlerer negativer Zusammenhang zwischen Fehlertyp SM.11 „Verwechslung des Sinns“ und der Inhaltsqualität (\tabref{tab:05:58}). Bei dem HMÜ-System Systran erwies sich nur eine signifikante starke negative Korrelation zwischen Fehlertyp LX.3 „Wort ausgelassen“ und der Inhaltsqualität (\tabref{tab:05:58}).


\begin{table}
\footnotesize
\begin{tabularx}{\textwidth}{Xrrrrrrrrr}

\lsptoprule
& \multicolumn{3}{c}{ \textbf{Bing}} & \multicolumn{3}{c}{ \textbf{SDL}} & \multicolumn{3}{c}{ \textbf{Systran}}\\
\cmidrule(lr){2-4}\cmidrule(lr){5-7}\cmidrule(lr){8-10}
& \textbf{N} & \textbf{p} & \textbf{ρ} &  \textbf{N} & \textbf{p} & \textbf{ρ} & \textbf{N} & \textbf{p} & \textbf{ρ}\\
\midrule
\multicolumn{10}{l}{\textbf{Differenz der Anzahl SQ} \textbf{(nach KS $-$ vor KS)}}\\
\textbf{OR.1 „Zeichen“} &  &  &  & 18 & \txgray{,052} & $-$~,464 &  &  & \\
\textbf{LX.3 „W. fehlt“} &  &  &  & 18 & ,002 & \boxblue{$-$~,684} & 17 & \txgray{,275} & $-$~,281\\
\textbf{LX.4 „W. extra“} &  &  &  & 18 & ,011 & \boxblue{$-$~,586} &  &  & \\
\textbf{GR.9 „Kongru.“} &  &  &  & 18 & \txgray{,076} & $-$~,429 &  &  & \\
\textbf{GR.10 „Wortst.“} & 18 & ,028 & \boxblue{$-$~,518} & 18 & ,008 & \boxblue{$-$~,604} &  &  & \\
\textbf{SM.11 „Sinn“} & 18 & \txgray{,091} & $-$~,410 &  &  &  &  &  & \\
\midrule
\multicolumn{10}{l}{\textbf{Differenz der Anzahl CQ} \textbf{(nach KS $-$ vor KS)}}\\
\textbf{OR.1 „Zeichen“} &  &  &  & 18 & ,003 & \boxblue{$-$~,656} &  &  & \\
\textbf{LX.3 „W. fehlt“} &  &  &  & 18 & < ,001 & \boxblue{$-$~,754} & 17 & ,024 & \boxblue{$-$~,545}\\
\textbf{LX.4 „W. extra“} &  &  &  & 18 & ,017 & \boxblue{$-$~,555} &  &  & \\
\textbf{GR.9 „Kongru.“} &  &  &  & 18 & \txgray{,080} & $-$~,424 &  &  & \\
\textbf{GR.10 „Wortst.“} & 18 & \txgray{,765} & $-$~,076 & 18 & ,005 & \boxblue{$-$~,629} &  &  & \\
\textbf{SM.11 „Sinn“} & 18 & ,039 & \txgreen{$-$~,490} &  &  &  &  &  & \\
\midrule
\multicolumn{10}{l}{\textbf{Differenz der Anzahl Q} \textbf{(nach KS $-$ vor KS)}}\\
\textbf{OR.1 „Zeichen“} &  &  &  & 18 & ,007 & \boxblue{$-$~,608} &  &  & \\
\textbf{LX.3 „W. fehlt“} &  &  &  & 18 & < ,001 & \boxblue{$-$~,758} & 17 & ,047 & \txgreen{$-$~,487}\\
\textbf{LX.4 „W. extra“} &  &  &  & 18 & ,009 & \boxblue{$-$~,595} &  &  & \\
\textbf{GR.9 „Kongru.“} &  &  &  & 18 & ,039 & \txgreen{$-$~,490} &  &  & \\
\textbf{GR.10 „Wortst.“} & 18 & \txgray{,160} & $-$~,346 & 18 & ,002 & \boxblue{$-$~,689} &  &  & \\
\textbf{SM.11 „Sinn“} & 18 & ,011 & \boxblue{$-$~,581} &  &  &  &  &  & \\
\lspbottomrule
\end{tabularx}\caption{\label{tab:05:58}„Partizipialkonst. verm.“ -- Korrelationen zwischen den Fehlertypen und der Qualität bei den einzelnen MÜ-Systemen   }
\bspnote{*In der Tabelle werden nur die Fehlertypen dargestellt, die bei mind. einer Qualitätsvariable eine signifikante Korrelation aufweisen.
\begin{tabbing}
p: Signifikanz\hspace{2.5cm} \= \txgray{nicht signifikant (p ${\geq}$ 0,05)}\hspace{.5cm} \= ρ: Korrelationskoeffizient \\
schwache Korrelation (ρ >=0,1) \> \txgreen{mittlere Korrelation (ρ >= 0,3)} \>  \boxblue{starke Korrelation (ρ >= 0,5)}
\end{tabbing}}
\end{table}

Bei dem SMÜ-System SDL gab es schließlich mehrere signifikante Korrelationen: Bei der Stilqualität erwies sich ein signifikanter starker negativer Zusammenhang zwischen Fehlertyp LX.3, LX.4 und GR.10 einzeln und der Stilqualität. Bei der Inhaltsqualität erwies sich ein signifikanter starker negativer Zusammenhang zwischen Fehlertyp OR.1, LX.3, LX.4 und GR.10 einzeln und der Inhaltsqualität (siehe \tabref{tab:05:58} und \tabref{tabex:05:55}).

\subsubsection{\label{sec:5.3.5.5}Vergleich der MÜ-Qualität mit und ohne die Verwendung von Partizipialkonstruktionen auf Annotationsgruppenebene}

Die Qualitätsveränderung\footnote{\textrm{Definitionen der Qualität unter \sectref{sec:4.4.5.1}.}} der MÜ variierte nach Vermeidung der Partizipialkonstruktion (nach KS) in den verschiedenen Annotationsgruppen (\figref{fig:05:83}).


\begin{figure}
\includegraphics[width=\textwidth]{figures/d3-img074.png}

%\includegraphics[height=.3\textheight]{figures/d3-img035.png}\\
\caption{\label{fig:05:83}„Partizipialkonst. verm.“ -- Mittelwerte der Qualität vor vs. nach KS auf Annotationsgruppenebene   }
\end{figure}

Die Gruppe FF (Übersetzung vor und nach KS falsch) hatte den größten Anteil von 42~\% der analysierten Sätze (siehe \sectref{sec:5.3.5.2}). In dieser Gruppe stieg zwar die Inhaltsqualität leicht, allerdings sank die Stilqualität signifikant (N = 37) = $-$ 2,623 / p = ,008), siehe \tabref{tab:05:59}. Die Bewerter fanden in vielen Fällen die MÜ bei der Verwendung der Partizipialkonstruktion prägnanter. Bei \tabref{fig:05:57} sank die Stilqualität um 0,50 Punkte auf der Likert-Skala, während die Inhaltsqualität unverändert blieb. Neben der Bemängelung des Kongruenzfehlers beim Verb ‚is’ kommentierte ein Bewerter „I would also take out ‚that are‘ for the sake of conciseness. (‘Accessories specifically tailored to these speakers \ldots’)“


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & \textbf{Speziell auf diese Lautsprecher abgestimmtes Zubehör} erhalten Sie in unserem Webshop.\\
\tablevspace
HMÜ Bing & \textcolor{tmnlpthree}{Accessories tailored to these speakers} \txred{specifically} are available in our webshop.\\
\midrule
\textbf{Nach-KS} & \textbf{Zubehör, das speziell auf diese Lautsprecher abgestimmt ist,} erhalten Sie in unserem Webshop.\\
\tablevspace
HMÜ Bing & \textcolor{tmnlpthree}{Accessories that} \txred{is} \txblue{specifically tailored to these speakers} are available in our webshop.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:57}Beispiel 57   }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

\begin{table}
\begin{tabularx}{\textwidth}{Xrrr}

\lsptoprule
& \textbf{N} & { \textbf{p}} & { \textbf{Z} }\\
& & \textbf{(Signifikanz)} & \textbf{(Teststatistik)}\\
\midrule
{\textbf{Annotationsgruppe FF}} & {} & {} & \\
\textbf{Differenz SQ (nach KS $-$ vor KS)} & 37 & ,008 & $-$ 2,638\\
\textbf{Differenz CQ (nach KS $-$ vor KS)} & 37 & \txgray{,411} & $-$~,823\\
\textbf{Differenz allg. Q (nach KS $-$ vor KS)} & 37 & \txgray{,507} & $-$~,664\\
\midrule
{\textbf{Annotationsgruppe FR}} & {} & {} & \\
\textbf{Differenz SQ (nach KS $-$ vor KS)} & 9 & \txgray{,107} & $-$~1,612\\
  \textbf{Differenz CQ (nach KS $-$ vor KS)} & 9 & ,021 & $-$ 2,314\\
\textbf{Differenz allg. Q (nach KS $-$ vor KS)} & 9 & \txgray{,050} & $-$~1,958\\
\midrule
{\textbf{Annotationsgruppe RF}} & {} & {} & \\
\textbf{Differenz SQ (nach KS $-$ vor KS)} & 23 & < ,001 & $-$ 4,114\\
  \textbf{Differenz CQ (nach KS $-$ vor KS)} & 23 & ,012 & $-$ 2,526\\
\textbf{Differenz allg. Q (nach KS $-$ vor KS)} & 23 & < ,001 & $-$ 4,021\\
\midrule
{\textbf{Annotationsgruppe RR}} & {} & {} & \\
\textbf{Differenz SQ (nach KS $-$ vor KS)} & 28 & < ,001 & $-$ 3,540\\
  \textbf{Differenz CQ (nach KS $-$ vor KS)} & 28 & ,020 & $-$ 2,322\\
   \textbf{Differenz allg. Q (nach KS $-$ vor KS)} & 28 & < ,001 & $-$ 3,618\\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:59}„Partizipialkonst. verm.“ -- Signifikanz der Qualitätsveränderung auf Annotationsgruppenebene   }
\end{table}

Erwartungsgemäß stiegen die Stil- und Inhaltsqualität in der Gruppe FR (MÜ falsch vor KS; richtig nach KS) und sanken in der Gruppe RF (MÜ richtig vor KS; falsch nach KS). In der Gruppe RF sanken die Stil- und Inhaltsqualität signifikant bei der Formulierung des Satzes ohne Partizipialkonstruktion (nach KS) aufgrund der aufgetretenen Fehler im Vergleich zu der fehlerfreien Übersetzung der Partizipialkonstruktion (vor KS), siehe \tabref{tab:05:59}. In der Gruppe FR war der Anstieg der Stilqualität bei der Formulierung des Satzes ohne Partizipialkonstruktion (nach KS) insignifikant, während der Anstieg der Inhaltsqualität signifikant war, siehe \tabref{tab:05:59}. \tabref{tabex:05:58} veranschaulicht, dass die Stilqualität sank ($-$~,75 Punkte auf der Likert-Skala), obwohl die Inhaltsqualität durch den korrigierten Fehler stieg (+~0,38 Punkte auf der Likert-Skala), Durch den behobenen lexikalischen Fehler in ‚fristgerecht‘ (LX.3: Wort wurde vor KS ausgelassen) stieg die Genauigkeit der MÜ nach KS. Zudem kritisierte ein Bewerter den Stil nach KS und beschrieb ihn als „wordy“.


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & Bei \textbf{fristgerecht erfolgten berechtigten Mängelrügen} ist der Lieferer zu einer kostenlosen Ersatzlieferung verpflichtet.\\
\tablevspace
GNMÜ & In the case of \txred{XXX} \txblue{justified complaints}, the supplier shall deliver replacement goods free of charge.\\
\midrule
\textbf{Nach-KS} & Bei \textbf{berechtigten Mängelrügen, die fristgerecht erfolgen,} ist der Lieferer zu einer kostenlosen Ersatzlieferung verpflichtet.\\
\tablevspace
GNMÜ & In the case of \txblue{justified complaints which are made within the time limit}, the supplier shall deliver replacement goods free of charge.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:58}Beispiel 58   }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens; \txred{XXX} für ein fehlendes Wort oder Komma.}
\end{table}

In der Gruppe RR (Übersetzung mit und ohne Passiversatz richtig) sanken die Stil- und Inhaltsqualität signifikant (z (N = 28) = $-$ 3,540 / p < ,001) bzw. (z (N = 28) = 2,322 / p = ,020), siehe \tabref{tab:05:59}. Eine richtige Übersetzung der Partizipialkonstruktion (vor KS) fanden die Bewerter prägnanter und idiomatisch. In \tabref{tabex:05:59} kommentierte ein Bewerter die MÜ nach der Regalanwendung wie folgt: „’which go beyond this’ too closely mimics the structure of the source text. I suggest ‚exceeding this‘ instead“. Die Qualitätsdifferenz in diesem Beispiel betrug bei der Stilqualität $-$~,50 Punkte auf der Likert-Skala bzw. $-$~,38 Punkte auf der Likert-Skala bei der Inhaltsqualität.


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & \textbf{Alle darüberhinausgehenden Ansprüche} sind ausdrücklich von der Garantie ausgenommen.\\
\tablevspace
HMÜ Bing & \textcolor{tmnlpthree}{All claims that go beyond} are expressly excluded from the guarantee.\\
\midrule
\textbf{Nach-KS} & \textbf{Alle Ansprüche, die darüber hinausgehen,} sind ausdrücklich von der Garantie ausgenommen.\\
\tablevspace
HMÜ Bing & \textcolor{tmnlpthree}{All claims which go beyond this} are expressly excluded from the guarantee.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:59}Beispiel 59   }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

\subsubsection{\label{sec:5.3.5.6}Vergleich der AEM-Scores mit und ohne die Verwendung von Partizipialkonstruktionen sowie die Korrelation zwischen den AEM-Scores und der Qualität}

Der Vergleich der AEM-Scores mit und ohne die Verwendung von Partizipialkonstruktionen zeigte sowohl mit TERbase als auch mit hLEPOR eine Verschlechterung der AEM-Scores (\figref{fig:05:84}).


\begin{figure}
%\includegraphics[height=.3\textheight]{figures/d3-img022.png}




%\includegraphics[height=.3\textheight]{figures/d3-img022.png}


%\includegraphics[height=.3\textheight]{figures/d3-img022.png}
\includegraphics[width=.4\textwidth]{figures/Abb84.png}
\includegraphics[width=.35\textwidth]{figures/Abb19-legend.png}
\caption{\label{fig:05:84}„Partizipialkonst. verm.“ -- Mittelwert der Differenz der AEM-Scores   }
\bspnote{Differenz = AEM-Score nach KS \textit{minus} AEM-Score vor KS}
\end{figure}

Der Mittelwert der Differenz (nach KS $-$ vor KS) im AEM-Score pro Satz lag für TERbase bei ,164 (SD = ,214) und für die hLEPOR bei ,063 (SD = ,130) mit einem 95\%-Konfidenzintervall (Bootstrapping mit 1000 Stichproben) (\figref{fig:05:84}). Die Differenzen (nach KS $-$ vor KS) in TERbase und hLEPOR erwiesen sich als signifikant (z (N = 98) = $-$~6,238 / p < ,001) bzw. (z (N = 98) = $-$ 4,366 / p~<~,001). Dieses Ergebnis weist darauf hin, dass -- nach der Auflösung der Partizipialkonstruktion (nach KS) -- mehr Edits erforderlich waren.

\subsubsubsection{Korrelation zwischen den Differenzen in den AEM-Scores und der Qualität}

Mithilfe des Spearman-Korrelationstests erwies sich ein signifikanter mittlerer positiver Zusammenhang zwischen den Differenzen der AEM-Scores von TERbase und hLEPOR und der Differenz der allgemeinen Qualität (\tabref{tab:05:60}).


\begin{table}
\begin{tabularx}{\textwidth}{Qrrrr}

\lsptoprule
& \textbf{N} & { \textbf{Signifikanz} } & \textbf{Korrelations-} & \textbf{Stärke}\\
& & \textbf{(p)} & \textbf{koeffizient} & \textbf{der}\\
& & & \textbf{(ρ)} &  \textbf{Korrelation}\\
\midrule
Korrelation zw. Differenz in der allg. Qualität und Differenz des TERbase-Scores (nach KS $-$ vor KS) & { 97} & < ,001 & ,430 & \makecell[tr]{mittlerer\\Zusammen-\\hang}\\
\tablevspace
Korrelation zw. Differenz in der allg. Qualität und Differenz des hLEPOR-Scores (nach KS $-$ vor KS) & { 97} & < ,001 & ,426 & \makecell[tr]{mittlerer\\Zusammen-\\hang}\\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:60}„Partizipialkonst. verm.“ -- Korrelation zwischen den Differenzen der AEM-Scores und den Qualitätsdifferenzen   }
\bspnote{{ schwache Korrelation (ρ >=0,1)} { mittlere Korrelation (ρ >= 0,3) }  starke Korrelation (ρ >= 0,5)}
\end{table}

Diesem Ergebnis zufolge standen die Qualitätsveränderungen der Humanevaluation und der automatischen Evaluation in relativem Einklang, denn der Qualitätsrückgang ging mit dem Rückgang der AEM-Scores einher.

\subsubsection{\label{sec:5.3.5.7}Analyse der fünften Regel -- Validierung der Hypothesen}

Um die vorgestellten Ergebnisse auf die Forschungsfragen der Studie zurückzuführen, listet dieser Abschnitt die zugrunde liegenden Hypothesen der Forschungsfragen zusammen mit einer Zusammenfassung der Ergebnisse der fünften analysierten Regel in tabellarischer Form auf. Für einen schnelleren Überblick steht (+) für eine Verbesserung bzw. einen Anstieg z.~B. im Sinne eines Qualitätsanstiegs, verbesserter AEM-Scores oder eines Anstiegs der Fehleranzahl; ($-$) steht für einen Rückgang; die \txgreen{grüne} Farbe symbolisiert eine signifikante Veränderung; \textit{neg} steht für eine negative Korrelation und \textit{pos} für eine positive Korrelation; <{}<{}>{}> steht für eine starke Korrelation und <> für eine mittlere Korrelation.\footnote{\textrm{Schwache Korrelationen werden in dieser Übersicht nicht angezeigt.}}

\subsubsubsection*{\textbf{Regel 5: Partizipialkonstruktionen vermeiden}}
\paragraph*{Erster Analysefaktor: Vergleich der Fehleranzahl mit vs. ohne Partizipialkonstruktion}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Gibt es einen Unterschied in der Fehleranzahl nach der Anwendung der KS-Regel im Vergleich zu vor der Anwendung?
\item [H0 --] Es gibt keinen Unterschied in der Fehleranzahl vor vs. nach der Anwendung der KS-Regel.
\item [H1 --] Es gibt einen Unterschied in der Fehleranzahl vor vs. nach der Anwendung der KS-Regel.
\newpage
\item [Resultat]
\end{description}
\noindent
\parbox[t]{.75\textwidth}{\textbf{Auf Regelebene:}}\\
\parbox[t]{.75\textwidth}{
H0 wurde abgelehnt und somit H1 bestätigt.

Die Fehleranzahl stieg signifikant, nachdem die Partizipialkonstruktion vermieden wurde.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.2\textwidth}{
\textbf{Anz.F. (+)}\\
\\
}}

\noindent
\parbox[t]{.75\textwidth}{\textbf{Auf Regel- und MÜ-Systemebene:}}\\
\parbox[t]{.75\textwidth}{
Bei Systran stieg die Fehleranzahl signifikant, nachdem die Partizipialkonstruktion vermieden wurde.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.2\textwidth}{
\textbf{Sy (+)}\\
}}

\medskip
\noindent
\parbox[t]{.75\textwidth}{
Die Veränderungen der Fehleranzahl bei allen anderen Systemen waren nicht signifikant.
}
\parbox[t]{.04\textwidth}{}
\parbox[t]{.2\textwidth}{
{ \textbf{Bi (+)}}{ \textbf{Go (+)}}

{ \textbf{Lu (+)}} \textbf{SD ($-$)}
}

\hrule
\paragraph*{Zweiter Analysefaktor}\hfill\\
\begin{figure}[H]
% 75
\scalebox{.75}{
\torte{50}{11}{26}{33}
}
\caption{Aufteilung der Annotationsgruppen auf Regelebene}
\end{figure}
\begin{figure}[H]
\begin{tikzpicture}
\tikzset{every node/.style={font=\scriptsize}};
	\begin{axis}[
  ybar,
	width = \textwidth,
  height = .35\textheight,
	axis lines* = left,
	ylabel = {\%},
	xtick = {3,9,15,21},
	xticklabels = {FF,FR,RF,RR},
  x tick label style ={yshift=-5pt},
	xtick=data,
  xlabel={Annotationsgruppe},
	ymin=0,
	ymax = 15,
  y filter/.code={\pgfmathparse{#1/120*100}\pgfmathresult},
%	bar shift = 0pt,
  bar width=9,
  enlarge x limits = .1,
%	nodes near coords,
%	legend pos= north east,
	legend style={at={(0.5,-0.15)},anchor=north},
	legend columns = {-1},
	]
	\addplot+[lsNightBlue]
	coordinates {
	(3,6)
	(9,3)
	(15,8)
	(21,7)
	};
	\addplot+[tmnlpone]
	coordinates {
	(3,2)
	(9,2)
	(15,3)
	(21,17)
	};
	\addplot+[tmnlptwo]
	coordinates {
	(3,16)
	(9,0)
	(15,4)
	(21,4)
	};
	\addplot+[tmnlpthree]
	coordinates {
	(3,13)
	(9,4)
	(15,3)
	(21,4)
	};
	\addplot+[tmnlpfour]
	coordinates {
	(3,13)
	(9,2)
	(15,8)
	(21,1)
	};
	\legend{Bing,Google,Lucy,SDL,Systran}
	\end{axis}
\end{tikzpicture}
\caption{Aufteilung der Annotationsgruppen auf Regel- und MÜ-Systemebene}
\end{figure}

\hrule
\paragraph*{Dritter Analysefaktor: Vergleich der Fehlertypen mit vs. ohne Partizipialkonstruktion}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Beinhaltet die MÜ bestimmte Fehlertypen vor bzw. nach der Anwendung der KS-Regel?
\item [H0 --] Es gibt keinen Unterschied in der Häufigkeit der einzelnen Fehlertypen vor vs. nach der Anwendung der KS-Regel.
\item [H1 --] Es gibt einen Unterschied in der Häufigkeit der einzelnen Fehlertypen vor vs. nach der Anwendung der KS-Regel.
\end{description}
\noindent
\parbox[t]{.8\textwidth}{\textbf{Auf Regelebene:}}\\
\parbox[t]{.8\textwidth}{
H1 wurde für zwei Fehlertypen bestätigt.

Die Fehleranzahl von OR.1 „Zeichensetzung“ stieg signifikant, nachdem die Partizipialkonstruktion vermieden wurde.

Die Fehleranzahl von GR.10 „Wortstellungsfehler“ sank signifikant, nachdem die Partizipialkonstruktion vermieden wurde.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.15\textwidth}{
{\textbf{OR.1 (+)}}

\textbf{GR.10 ($-$)}\\
\\
\\
}}

\noindent
\parbox[t]{.8\textwidth}{\textbf{Auf Regel- und MÜ-Systemebene:}}\\
\parbox[t]{.8\textwidth}{
Bei Bing, SDL und Systran stieg die Fehleranzahl von OR.1 „Zeichensetzung“ signifikant, nachdem die Partizipialkonstruktion vermieden wurde.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.15\textwidth}{
{ \textbf{OR.1 (+):}}

{ \textbf{Bi}}{ \textbf{SD}} \textbf{Sy}\\
}}

\medskip
\noindent
\parbox[t]{.8\textwidth}{
Bei SDL und Systran sank die Fehleranzahl von GR.10 „Wortstellungsfehler“ signifikant (nach KS).
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.15\textwidth}{
{ \textbf{GR.10 ($-$):}}

{ \textbf{SD}} \textbf{Sy}
}}

\medskip
\noindent
\parbox[t]{.8\textwidth}{Alle weiteren Veränderungen waren nicht signifikant.}

\hrule
\paragraph*{Vierter Analysefaktor: Vergleich der MÜ-Qualität mit vs. ohne Partizipialkonstruktion}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:]  Gibt es einen Unterschied in der Stil- und Inhaltsqualität der MÜ der KS-Stelle nach der Anwendung der KS-Regel im Vergleich zu vor der Anwendung?
\item [H0 --] Es gibt keinen Qualitätsunterschied vor vs. nach der Anwendung der KS-Regel.
\item [H1 --] Es gibt einen Qualitätsunterschied vor vs. nach der Anwendung der KS-Regel.
\item [Resultat]
\end{description}
\noindent
\parbox[t]{.8\textwidth}{\textbf{Auf Regelebene:}}\\
\parbox[t]{.8\textwidth}{
Für die Stilqualität wurde H0 abgelehnt und somit H1 bestätigt.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.15\textwidth}{
\textbf{SQ ($-$)}
}}

\medskip
\noindent
\parbox[t]{.8\textwidth}{
Für die Inhaltsqualität wurde H0 nicht abgelehnt und somit konnte H1 nicht bestätigt werden.
}
\parbox[t]{.04\textwidth}{}
\parbox[t]{.15\textwidth}{
\textbf{CQ ($-$)}
}

\noindent
\parbox[t]{.8\textwidth}{\textbf{Auf Regel- und MÜ-Systemebene:}}\\
\parbox[t]{.8\textwidth}{
Die Stilqualität sank bei Bing, Google und Lucy signifikant (nach KS).
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.15\textwidth}{
{ \textbf{SQ ($-$):}}

{ \textbf{Bi}}{ \textbf{Go}} \textbf{Lu}
}}

\medskip
\noindent
\parbox[t]{.8\textwidth}{
Die Inhaltsqualität stieg bei Systran signifikant (nach KS).
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.15\textwidth}{
{ \textbf{CQ (+):}} \textbf{Sy}
}}

\medskip
\noindent
\parbox[t]{.8\textwidth}{
Alle weiteren Qualitätsveränderungen waren nicht signifikant; generell sanken sowohl die Stil- als auch die Inhaltsqualität in den weiteren Fällen mit Ausnahme der Inhaltsqualität von SDL, die leicht anstieg.
}

\hrule
\paragraph*{Fünfter Analysefaktor: Korrelation zwischen den Fehlertypen und der Qualität}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Besteht ein Zusammenhang zwischen der Differenz der Fehleranzahl eines bestimmten Fehlertyps (Fehleranzahl nach KS $-$ vor KS) und der Differenz der Stil- bzw. Inhaltsqualität (Qualität nach KS $-$ vor KS)?
\item [H0 --] Es besteht kein Zusammenhang zwischen der Differenz der Fehleranzahl eines bestimmten Fehlertyps und der Differenz der Stil- bzw. Inhaltsqualität.
\item [H1 --] Es besteht ein Zusammenhang zwischen der Differenz der Fehleranzahl eines bestimmten Fehlertyps und der Differenz der Stil- bzw. Inhaltsqualität.
\item [Resultat]
\end{description}
\noindent
\parbox[t]{.7\textwidth}{\textbf{Auf Regelebene:}}\\
\parbox[t]{.7\textwidth}{
H1 wurde für drei Fehlertypen wie folgt bestätigt:

Es bestand ein signifikanter mittlerer negativer Zusammenhang zwischen der Differenz der Fehleranzahl des LX.4 „Zusätzliches Wort eingefügt“ und der Stilqualität sowie ein signifikanter mittlerer negativer Zusammenhang zwischen der Differenz der Fehleranzahl des LX.3 „Wort ausgelassen“, LX.4 „Zusätzliches Wort eingefügt“ und GR.10 „Wortstellungsfehler“ einzeln und der Differenz der Inhaltsqualität.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.25\textwidth}{
{ \textbf{\textit{neg}} \textbf{LX.4 <> SQ}}\\

{ \textbf{\textit{neg}} \textbf{LX.3 <> CQ}}

{ \textbf{\textit{neg}} \textbf{LX.4 <> CQ}}

 \textbf{\textit{neg}} \textbf{GR.10 <> CQ}\\
 \\
 \\
 \\
}}

\noindent
\parbox[t]{.7\textwidth}{\textbf{Auf Regel- und MÜ-Systemebene:}}\\
\parbox[t]{.7\textwidth}{
Bei Bing bestand ein signifikanter starker negativer Zusammenhang zwischen der Differenz der Fehleranzahl des GR.10 „Wortstellungsfehler“ und der Differenz der Stilqualität sowie ein signifikanter mittlerer negativer Zusammenhang zwischen der Differenz der Fehleranzahl des SM.11 „Verwechslung des Sinns“ und der Differenz der Inhaltsqualität.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.25\textwidth}{
{ \textbf{Bi}}

{ \textbf{\textit{neg}} \textbf{GR.10 <{}<{}>{}> SQ}}

 \textbf{\textit{neg}} \textbf{SM.11 <> CQ}\\
 \\
 \\
 \\
}}

\medskip
\noindent
\parbox[t]{.7\textwidth}{
Bei SDL bestand ein signifikanter starker negativer Zusammenhang zwischen der Differenz der Fehleranzahl des LX.3 „Wort ausgelassen“, LX.4 „Zusätzliches Wort eingefügt“ und des GR.10 „Falsche Wortstellung“ einzeln und der Differenz der Stilqualität sowie ein signifikanter starker negativer Zusammenhang zwischen der Differenz der Fehleranzahl des OR.1 „Falsche Zeichensetzung“, LX.3, LX.4 und GR.10 einzeln und der Differenz der Inhaltsqualität.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.25\textwidth}{
{ \textbf{SD}}

{ \textbf{\textit{neg}} \textbf{LX.3 <{}<{}>{}> SQ}}

{ \textbf{\textit{neg}} \textbf{LX.4 <{}<{}>{}> SQ}}

{ \textbf{\textit{neg}} \textbf{GR.10 <{}<{}>{}> SQ}}\\

{ \textbf{\textit{neg}} \textbf{OR.1 <{}<{}>{}> CQ}}

{ \textbf{\textit{neg}} \textbf{LX.3 <{}<{}>{}> CQ}}

{ \textbf{\textit{neg}} \textbf{LX.4 <{}<{}>{}> CQ}}

{ \textbf{\textit{neg}} \textbf{GR.10 <{}<{}>{}> CQ}}
}}

\medskip
\noindent
\parbox[t]{.7\textwidth}{
Bei Systran bestand ein signifikanter starker negativer Zusammenhang zwischen der Differenz der Fehleranzahl des LX.3 „Wort ausgelassen“ und der Differenz der Inhaltsqualität.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.25\textwidth}{
{ \textbf{Sy}}

{ \textbf{\textit{neg}} \textbf{LX.3 <{}<{}>{}> CQ}}\\
\\
}}

\medskip
\noindent
\parbox[t]{.7\textwidth}{
Alle weiteren Korrelationen waren nicht signifikant.
}

\hrule
\paragraph*{Sechster Analysefaktor: Vergleich der MÜ-Qualität mit vs. ohne Partizipialkonstruktion auf Annotationsgruppenebene}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Gibt es einen Unterschied in der Stil- und Inhaltsqualität bei den einzelnen Annotationsgruppen nach der Anwendung der KS-Regel im Vergleich zu vor der Anwendung?
\item [H0 --] Bei den Annotationsgruppen gibt es keinen Qualitätsunterschied vor vs. nach der Anwendung der KS-Regel.
\item [H1 --] Bei den Annotationsgruppen gibt es einen Qualitätsunterschied vor vs. nach der Anwendung der KS-Regel.
\newpage
\item [Resultat]
\end{description}
\noindent
\parbox[t]{.8\textwidth}{H1 wurde bei der Annotationsgruppe FF nur für die Stilqualität bestätigt:}\\
\parbox[t]{.8\textwidth}{Die Stilqualität sank signifikant, nachdem die Partizipialkonstruktion vermieden wurde.}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.15\textwidth}{\textbf{SQ ($-$)}\\}}

\medskip
\noindent
\parbox[t]{.8\textwidth}{Die Inhaltsqualität stieg nur minimal an.}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.15\textwidth}{\textbf{CQ (+)}}}

\noindent
\parbox[t]{.8\textwidth}{H1 wurde bei der Annotationsgruppe FR nur für die Inhaltsqualität bestätigt:}\\
\parbox[t]{.8\textwidth}{Die Inhaltsqualität stieg nach der Vermeidung der Partizipialkonstruktion signifikant.}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.15\textwidth}{\textbf{CQ (+)}\\}}

\medskip
\noindent
\parbox[t]{.8\textwidth}{Die Stilqualität stieg nicht signifikant an.}
\parbox[t]{.04\textwidth}{}
\parbox[t]{.15\textwidth}{\textbf{SQ (+)}}

\medskip
\noindent
\parbox[t]{.8\textwidth}{Bei den Annotationsgruppen RF und RR sanken die Stil- und Inhaltsqualität signifikant (nach KS).}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.15\textwidth}{
{ \textbf{SQ ($-$)}}

 \textbf{CQ ($-$)}
}}

\hrule
\paragraph*{Siebter Analysefaktor: Vergleich der AEM-Scores mit vs. ohne Partizipialkonstruktion}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Gibt es einen Unterschied in den AEM-Scores von TERbase bzw. hLEPOR nach der Anwendung der KS-Regel im Vergleich zu vor der Anwendung?
\item [H0 --] Es gibt keinen Unterschied in den AEM-Scores vor vs. nach der Anwendung der KS-Regel.
\item [H1 --] Es gibt einen Unterschied in den AEM-Scores vor vs. nach der Anwendung der KS-Regel.
\item [Resultat]
\end{description}
\noindent
\parbox[t]{.75\textwidth}{
H0 wurde abgelehnt und somit H1 bestätigt.

Die AEM-Scores von TERbase und hLEPOR verschlechterten sich signifikant, nachdem die Partizipialkonstruktion vermieden wurde.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.2\textwidth}{
\textbf{TERbase ($-$)\\hLEPOR ($-$)}\\
\\
}}

\hrule
\newpage
\paragraph*{Achter Analysefaktor: Korrelation zwischen den Differenzen der AEM-Scores und der Qualität}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Besteht ein Zusammenhang zwischen der Differenz der AEM-Scores von TERbase bzw. hLEPOR (Mittelwert der AEM-Scores nach KS $-$ vor KS) und der Differenz der allgemeinen Qualität (Qualität nach KS $-$ vor KS)?
\item [H0 --] Es besteht kein Zusammenhang zwischen der Differenz der AEM-Scores und der Differenz der allgemeinen Qualität.
\item [H1 --] Es besteht ein Zusammenhang zwischen der Differenz der AEM-Scores und der Differenz der allgemeinen Qualität.
\item [Resultat]
\end{description}
\noindent
\parbox[t]{.7\textwidth}{
H0 wurde abgelehnt und somit H1 bestätigt.

Es bestand ein signifikanter mittlerer positiver Zusammenhang zwischen der Differenz des TERbase-Scores und der Differenz der allgemeinen Qualität sowie ein signifikanter mittlerer positiver Zusammenhang zwischen der Differenz des hLEPOR-Scores und der Differenz der allgemeinen Qualität.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.25\textwidth}{
{ \textbf{\textit{pos} }\textbf{TERbase <> Q}}

 \textbf{\textit{pos} }\textbf{hLEPOR <> Q}\\
 \\
 \\
 \\
 \\
}}




\subsection{SECHSTE REGEL: Passiv vermeiden}
\label{sec:5.3.6}
 \subsubsection{\label{sec:5.3.6.0}Überblick}

%In \tabref{tab:05:61}
Im Folgenden wird die KS-Regel „Passiv vermeiden“ kurz beschrieben.\footnote{\textrm{Die für diese Regel relevanten Kontraste im Sprachenpaar DE-EN sind unter \sectref{sec:4.4.2.3} erörtert.} } Zudem wird zusammenfassend und anhand von Beispielen demonstriert, wie die Regel bei der Analyse angewendet wurde. Anschließend wird die Aufteilung der Testsätze im Datensatz dargestellt:

\begin{description}[font=\normalfont\bfseries]
\item [Beschreibung der KS-Regel:] \textbf{Passiv vermeiden} (tekom-Regel-Nr. S 501, S 502, S 503, S 504)

Nach diesen vier Regeln (\citealt{tekom2013}:~79ff.) soll die Verwendung des Passivs vermieden und stattdessen sollen die Sätze im Aktiv formuliert werden.

Begründung: Die Passivkonstruktion ist oft nicht eindeutig und lässt den Handelnden unklar. Wenn der Täter genannt werden soll, eignet sich die Aktivformulierung. (ebd.:~79) Insbesondere bei Anweisungen, Sicherheits- und Warnhinweisen wird die Aktivkonstruktion empfohlen, damit dem Leser klar wird, wer die Handlung ausführt oder ausführen soll. Warnungen wirken motivierend, wenn sie im Aktiv formuliert sind, da der Leser direkt angesprochen wird. (ebd.:~81)

\item[Umsetzungsmuster:]
~\\
\textbf{Vor KS:} Satz formuliert im Passiv\\
\textbf{Nach KS:} Satz umformuliert im Aktiv

\item[KS-Stelle]
~\\
\textbf{Vor KS:} Form von ‚werden‘ +~Partizip II\\
\textbf{Nach KS:} das Verb bzw. das Subjekt +~das Verb, wenn das Subjekt im Passivsatz nicht enthalten war und erst im Aktivsatz hinzugefügt wurde

Die Subjekte können bei der MÜ semantisch falsch übersetzt werden, daher werden sie nur als Teil der KS-Stelle betrachtet, wenn sie im Passivsatz nicht existieren (vgl. folgende Beispiele).

\item[Beispiele]
~\\
\textit{Bei der Arbeit mit elektrischen Geräten \txgray{sollte} stets ein Sicherheitsstecker \txgray{verwendet werden}.}

\textit{Bei der Arbeit mit elektrischen Geräten \txgray{verwenden Sie} stets einen Sicherheitsstecker.}
~\\
\textit{Das Programm \txgray{wird} vom Hersteller wie folgt \txgray{eingestellt}.}

\textit{Der Hersteller \txgray{stellt} das Programm wie folgt \txgray{ein}.}

\item[Aufteilung der Testsätze:]
In den deutschen Benutzerhandbüchern und Bedienungsanleitungen kommt häufig das Passiv in Kombination mit Modalverben vor, entsprechend besteht der Datensatz aus 20 Passivsätzen mit Modalverben und 4 Sätzen mit Vorgangspassiv ohne Modalverben.

\end{description}

%\multicolumn{2}{p{6cm}}{\label{bkm:Ref36849451}Eckdaten der sechsten Regel „Passiv vermeiden“}\\
%\end{tabularx}\caption{\label{tab:05:61}   }

Im Folgenden werden die Ergebnisse der einzelnen Analysefaktoren präsentiert.

\subsubsection{Vergleich der Fehleranzahl beim Passiv vs. Aktiv}\label{sec:5.3.6.1}

Die Fehleranzahl stieg um 30,5~\% von 59 Fehlern im Falle der Verwendung von Passivkonstruktionen (M = ,49 / SD = ,733 / N = 120) auf 77 Fehler bei der Verwendung von Aktivkonstruktionen (M = ,64 / SD = ,914 / N = 120) (\figref{fig:05:85}). Der Mittelwert der Differenz (nach KS $-$ vor KS) der Fehleranzahl pro Satz lag somit bei ,15 (SD = ,932) mit einem 95\%\nobreakdash-Konfidenzintervall zwischen einem Minimum von $-$~,02 (SD = ,731) und einem Maximum von ,32 (SD = 1,111) (Bootstrapping mit 1000 Stichproben) (\figref{fig:05:86}). Die Differenz (nach KS $-$ vor KS) der Fehleranzahl war entsprechend nicht signifikant (z (N = 120) = $-$~1,688 / p = ,091).


\begin{figure}


%\includegraphics[height=.3\textheight]{figures/d3-img023.png}



%\includegraphics[height=.3\textheight]{figures/d3-img023.png}



%\includegraphics[height=.3\textheight]{figures/d3-img023.png} &  & \textbf{,48,80}



%\includegraphics[height=.3\textheight]{figures/d3-img024.png}



%\includegraphics[height=.3\textheight]{figures/d3-img024.png}

%\textbf{,37,61}



%\includegraphics[height=.3\textheight]{figures/d3-img024.png}\\
\captionsetup{width=.45\textwidth}
\begin{floatrow}

\ffigbox[.5\textwidth]{\caption{„Passiv verm.“ -- Fehlersumme vor vs. nach KS}
\label{fig:05:85}}{
\begin{tikzpicture}
	\begin{axis}[
	ybar,
	ymin = 0,
	ymax = 125,
	axis lines* = left,
	nodes near coords,
%         nodes near coords align = vertical,
  legend style={at={(0.5,-0.2)},anchor=north,cells={align=left}},
  xtick=\empty,
  width = .45\textwidth,
  enlarge x limits = .5
	]
	\addplot+[tmnlpone]
	coordinates{
	(1,59)
	};
	\addplot+[tmnlpthree]
	coordinates{
	(2,77)
	};
	\legend{Anzahl der  fehler\\innerh. KS vor KS,Anzahl der Fehler\\innerh. KS nach KS}
	\end{axis}
\end{tikzpicture}
}
%
%
\ffigbox[.45\textwidth]{\caption{„Passiv verm.“ -- Mittelwert der Fehleranzahl pro Satz vor vs. nach KS}\label{fig:05:86}}{
\includegraphics[width=.25\textwidth]{figures/Abb86.png}
\includegraphics[width=.4\textwidth]{figures/Abb21-legend.png}
}
\end{floatrow}
\end{figure}

Die Fehlertypen, die erst nach der Regelanwendung auftraten, waren sehr unterschiedlich (mehr dazu unter \sectref{sec:5.3.6.3}). Daher lässt sich kein Muster ableiten, mit dessen Hilfe die Ursache des Anstiegs der Fehleranzahl interpretiert werden kann.

\subsubsubsection{Vergleich der Fehleranzahl auf Regel- und MÜ-Systemebene}

Zwei signifikante gegensätzliche Reaktionen zeigten die beiden HMÜ-Systeme Bing und Systran: Während die Fehleranzahl bei Bing sank (Mdiff = $-$~,208; z (N = 24) = $-$ 2,236 / p = ,025) stieg sie deutlich bei Systran (Mdiff =~,542; z (N = 24) = $-$ 2,812 / p = ,005).


\begin{figure}
%\textbf{\textit{+~130,0~\% 66,7~\%}}

%\textbf{+~15,4~\%}



%\includegraphics[height=.3\textheight]{figures/d3-img076.png}\\


%\textbf{+~30,0~\%}


%\textbf{+~60,0~\%}

%\textbf{\textit{$-$ 62,5~\%}}


%\includegraphics[height=.3\textheight]{figures/d3-img023.png}\\
\begin{tikzpicture}
	\begin{axis}[
	ybar,
	ymin = 0,
	ymax = 30,
	axis lines* = left,
	nodes near coords,
  legend style={at={(0.5,-0.2)},anchor=north},
  xticklabels = {Bing,Google,Lucy,SDL,Systran},
  xtick=data,
  ylabel = {Summe},
  extra description/.code={
            \node at (axis cs:-.5, 12)[anchor=west] {\bfitul{$-$ 62,5 \%}};
						\node at (axis cs:.5, 12)[anchor=west] {$+$ 60,0 \%};
						\node at (axis cs:1.5, 17)[anchor=west] {$+$ 30,0 \%};
						\node at (axis cs:2, 30)[anchor=west] {$+$ 15,4 \%};
						\node at (axis cs:3.5, 27)[anchor=west] {\bfitul{$+$ 130,0 \%}};
						}
	]
	\addplot+[tmnlpone]
	coordinates{
	(0,8)
	(1,5)
	(2,10)
	(3,26)
	(4,10)
	};
	\addplot+[tmnlpthree]
	coordinates{
	(0,3)
	(1,8)
	(2,13)
	(3,30)
	(4,23)
	};
	\legend{Anzahl der  fehler innerh. KS vor KS,Anzahl der Fehler innerh. KS nach KS}
	\end{axis}
\end{tikzpicture}
\caption{\label{fig:05:87}„Passiv verm.“ -- Summe der Fehleranzahl vor vs. nach KS bei den einzelnen MÜ-Systemen   }
\bspnote{\bfitul{Signifikante Differenz vor vs. nach KS}}
\end{figure}

Unter den fünf analysierten Systemen stieg die Fehleranzahl nach der Verwendung der Aktivform bei allen Systemen mit Ausnahme von dem HMÜ-System Bing: Google (Mdiff = ,125); Lucy (Mdiff = ,125); SDL (Mdiff = ,167) (\figref{fig:05:87}). Die Zunahme der Fehleranzahl bei Google, Lucy und SDL bei der Verwendung des Aktivs (nach KS) war nicht signifikant. Bei dem NMÜ-System Google Translate und dem SMÜ-System SDL ist eine mögliche Interpretation des (insignifikanten) Anstiegs der Fehleranzahl bei der Verwendung des Aktivs (nach KS), dass mehr Passiv- als Aktivsätze in den Trainingsdaten dieser Systeme enthalten sind. Die Veränderung in der Fehleranzahl im Falle des RBMÜ-Systems und der Hybridsysteme lässt sich im Rahmen einer Black-Box-Analyse nicht interpretieren.

\subsubsection{\label{sec:5.3.6.2}Aufteilung der Annotationsgruppen}

Die größte Annotationsgruppe bei dieser Regel war die Gruppe RR; knapp die Hälfte der Sätze wurde sowohl im Passiv als auch im Aktiv fehlerfrei übersetzt (\figref{fig:05:88}). An der zweiten Stelle kommt die Gruppe FF mit ca. 29~\%; hier beinhalteten die MÜ in beiden Szenarien Fehler. Dann folgt die Gruppe RF mit ca. 13~\%, in der die Sätze im Passiv, aber nicht im Aktiv, fehlerfrei übersetzt wurden. Zum Schluss kommt die Gruppe FR mit ca. 8~\%, die nur im Aktiv fehlerfrei übersetzt werden konnte (\figref{fig:05:88}).


\begin{figure}

%\includegraphics[height=.3\textheight]{figures/d3-img077.png}




%\includegraphics[height=.3\textheight]{figures/d3-img012.png}
% 88
\torte{35}{10}{16}{59}
\caption{\label{fig:05:88}„Passiv verm.“ -- Aufteilung der Annotationsgruppen   }
\end{figure}

Im kommenden Abschnitt (\sectref{sec:5.3.6.3}) werden die Fehlertypen, die mit dem Passiv bzw. dem Aktiv verbunden sind, gegenübergestellt.

\subsubsubsection{Vergleich der Aufteilung der Annotationsgruppen auf Regel- und MÜ-Systemebene}

Die größten Anteile bei drei MÜ-Systemen waren bei der Gruppe RR: 71~\% der Sätze des NMÜ-Systems Google und des HMÜ-Systems Bing sowie 58~\% des RBMÜ-Systems Lucy wurden sowohl im Passiv (vor KS) als auch im Aktiv fehlerfrei übersetzt (\figref{fig:05:89}). Gleichzeitig beinhalteten bei Lucy 38~\% der Übersetzungen sowohl vor als auch nach der Anwendung der KS-Regel Fehler. Die Ergebnisse bei dem HMÜ-System Systran waren ebenfalls gemischt: 38~\% bei der Gruppe RR und 38~\% bei der Gruppe FF. Zudem waren 25~\% der Übersetzungen von Systran im Passiv korrekt und nach der Anwendung des Aktivs falsch (Gruppe RF). Das SMÜ-System SDL erzielte auch ein heterogenes Ergebnis: 38~\% in beiden Szenarien falsch (Gruppe FF); 29~\% nur im Aktiv falsch (Gruppe RF) und 25~\% nur im Passiv falsch (Gruppe FR).


\begin{figure}
%\includegraphics[height=.3\textheight]{figures/d3-img078.png}

 %\textbf{13\% 21\%38\% 38\%38\%}          \textbf{17\%}                \textbf{25\%}                           \textbf{8\%}   \textbf{4\% 29\% 25\%}          \textbf{71\% 71\%58\% 8\%}  \textbf{38\%}



%\includegraphics[height=.3\textheight]{figures/d3-img026.png}\\
\begin{tikzpicture}
\tikzset{every node/.style={font=\scriptsize}};
	\begin{axis}[
	ybar,
	width = \textwidth,
	axis lines* = left,
	ylabel = {Anzahl},
	xtick = {3,9,15,21},
	xticklabels = {FF,FR,RF,RR},
  x tick label style ={yshift=-5pt},
	xtick=data,
  xlabel={Annotationsgruppe},
	ymin=0,
	ymax = 20,
%	bar shift = 0pt,
  bar width=9,
  enlarge x limits = .2,
	nodes near coords,
%	legend pos= north east,
	legend style={at={(0.5,-0.15)},anchor=north},
	legend columns = {-1},
	extra description/.code={
  \node at (axis cs:.3,4)[anchor = west]{2,5\%};
	\node at (axis cs:.3,-.5)[anchor = west]{13\%};
	\node at (axis cs:1.2,6)[anchor = west]{4,2\%};
	\node at (axis cs:1.2,-.5)[anchor = west]{21\%};
	\node at (axis cs:2,10)[anchor = west]{7,5\%};
	\node at (axis cs:2.1,-.5)[anchor = west]{38\%};
	\node at (axis cs:3.1,11)[anchor = west]{7,5\%};
	\node at (axis cs:3.1,-.5)[anchor = west]{38\%};
	\node at (axis cs:4,10)[anchor = west]{7,5\%};
	\node at (axis cs:4.1,-.5)[anchor = west]{38\%};
	\node at (axis cs:6.4,5)[anchor = west]{3,3\%};
	\node at (axis cs:6.4,-.5)[anchor = west]{17\%};
%  \node at (axis cs:7.4,5)[anchor = west]{3,3\%};
%	\node at (axis cs:7.4,-.5)[anchor = west]{17\%};
%\node at (axis cs:8.4,5)[anchor = west]{3,3\%};
%\node at (axis cs:8.4,-.5)[anchor = west]{17\%};
	\node at (axis cs:9.2,7)[anchor = west]{5,0\%};
	\node at (axis cs:9.2,-.5)[anchor = west]{25\%};
%  \node at (axis cs:10.4,5)[anchor = west]{3,3\%};
%	\node at (axis cs:10.4,-.5)[anchor = west]{17\%};
%\node at (axis cs:12,5)[anchor = west]{3,3\%};
%\node at (axis cs:12,-.5)[anchor = west]{17\%};
  \node at (axis cs:13.3,3)[anchor = west]{1,7\%};
	\node at (axis cs:13.4,-.5)[anchor = west]{8\%};
	\node at (axis cs:14.1,2)[anchor = west]{0,8\%};
	\node at (axis cs:14.2,-.5)[anchor = west]{4\%};
  \node at (axis cs:15,8)[anchor = west]{5,8\%};
	\node at (axis cs:15,-.5)[anchor = west]{29\%};
  \node at (axis cs:16,7)[anchor = west]{5,0\%};
	\node at (axis cs:16,-.5)[anchor = west]{25\%};
	\node at (axis cs:18.4,18)[anchor = west]{14,2\%};
	\node at (axis cs:18.4,-.5)[anchor = west]{71\%};
	\node at (axis cs:19.3,19)[anchor = west]{14,2\%};
	\node at (axis cs:19.4,-.5)[anchor = west]{71\%};
	\node at (axis cs:20.3,15)[anchor = west]{11,7\%};
	\node at (axis cs:20.3,-.5)[anchor = west]{58\%};
	\node at (axis cs:21.1,3)[anchor = west]{1,7\%};
	\node at (axis cs:21.3,-.5)[anchor = west]{8\%};
	\node at (axis cs:22.1,10)[anchor = west]{7,5\%};
	\node at (axis cs:22.2,-.5)[anchor = west]{38\%};
	}
	]
	\addplot+[lsNightBlue]
	coordinates {
	(3,3)
	(9,4)
	(15,0)
	(21,17)
	};
	\addplot+[tmnlpone]
	coordinates {
	(3,5)
	(9,0)
	(15,2)
	(21,17)
	};
	\addplot+[tmnlptwo]
	coordinates {
	(3,9)
	(9,0)
	(15,1)
	(21,14)
	};
	\addplot+[tmnlpthree]
	coordinates {
	(3,9)
	(9,6)
	(15,7)
	(21,2)
	};
	\addplot+[tmnlpfour]
	coordinates {
	(3,9)
	(9,0)
	(15,6)
	(21,9)
	};
	\legend{Bing,Google,Lucy,SDL,Systran}
	\end{axis}
\end{tikzpicture}
\caption{\label{fig:05:89}„Passiv verm.“ -- Aufteilung der Annotationsgruppen bei den einzelnen MÜ-Systemen   }
\bspnote{Die oben angezeigten Prozentzahlen sind für alle Systeme, d. h. systemübergreifend, (N = 120) berechnet.

Die untenstehenden Prozentzahlen sind auf Systemebene (N = 24) berechnet.}
\end{figure}

Bei der Regel „Passiv vermeiden“ zeigt ein genauer Einblick in den Datensatz, dass die Annotationsgruppe RF aus insgesamt 16 MÜ besteht, wobei die meisten Fälle dieser MÜ bei hauptsächlich zwei MÜ-Systemen vorkamen; und zwar 7 Fälle bei SDL (47~\%) und 6 Fälle bei Systran (40~\%) (\figref{fig:05:89}).

\subsubsection{\label{sec:5.3.6.3}Vergleich der Fehlertypen beim Passiv vs. Aktiv}
\largerpage
Die Fehleranzahl zeigte bei keinem bestimmten Fehlertyp eine deutliche Veränderung. Sowohl bei der Formulierung im Aktiv als auch im Passiv kommen unterschiedliche Fehler(typen) vor (\figref{fig:05:90}).


\begin{figure}
%\includegraphics[height=.3\textheight]{figures/d3-img079.png}




%\includegraphics[height=.3\textheight]{figures/d3-img027.png}

%\includegraphics[height=.3\textheight]{figures/d3-img013.png}



%\includegraphics[height=.3\textheight]{figures/d3-img013.png}
% 90
\pgfplotstableread{
1 0
2 0
3 0
4 0
5 2
6 4
7 8
8 8
9 0
10 0
11 0
12 0
13 0
14 1
15 3
16 4
17 0
18 0
19 12
20 14
21 24
22 32
23 4
24 8
25 6
26 6
}\datatable
\smbars{}
\caption{\label{fig:05:90}„Passiv verm.“ -- Summe der Fehleranzahl der einzelnen Fehlertypen vor vs. nach KS   }
\bspnote{*Die X-Achse ist folgendermaßen zu lesen: Jeder Fehlertyp wird anhand von zwei Balken abgebildet. Der erste Balken repräsentiert die Summe der Fehler vor KS und der zweite die Summe der Fehler nach KS, somit steht z. B. „OR\_1.v“ für „OR\_1: orthografischer Fehler Nr. 1“ und „v: vor KS“; „OR\_1.n“ wäre entsprechend das Pendant zu „OR\_1.v“ für das nach-KS-Szenario („n“).\\
OR.1: Orthografie -- Zeichensetzung\\
OR.2: Orthografie -- Großschreibung\\
LX.3: Lexik -- Wort ausgelassen\\
LX.4: Lexik -- Zusätzliches Wort eingefügt\\
LX.5: Lexik -- Wort unübersetzt geblieben (auf DE wiedergegeben)\\
LX.6: Lexik -- Konsistenzfehler\\
GR.7: Grammatik -- Falsche Wortart / Wortklasse\\
GR.8: Grammatik -- Falsches Verb (Zeitform, Komposition, Person)\\
GR.9: Grammatik -- Kongruenzfehler (Agreement)\\
GR.10: Grammatik -- Falsche Wortstellung\\
SM.11: Semantik -- Verwechslung des Sinns\\
SM.12: Semantik -- Falsche Wahl\\
SM.13: Semantik -- Kollokationsfehler}
\end{figure}

\newpage
Dementsprechend erwies sich der Unterschied in der Fehleranzahl bei keinem Fehlertyp als signifikant. Die am häufigsten aufgetretenen Fehler waren der Wortstellungsfehler (GR.10) und die Verwechslung des Sinns (SM.11), siehe \figref{fig:05:90}. Beide Fehlertypen stiegen im Aktiv (nach KS) leicht an. Nachfolgend zwei Beispiele der beiden Fehlertypen (\tabref{tabex:05:60}).


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & Das Programm \textbf{wird} vom Hersteller wie folgt \textbf{eingestellt}.\\
\tablevspace
HMÜ Systran & The program \txblue{is} \txred{stopped} by the manufacturer as follows.\\
\midrule
\textbf{Nach-KS} & Der Hersteller \textbf{stellt} das Programm wie folgt \textbf{ein}.\\
\tablevspace
HMÜ Systran & The manufacturer \txred{stops} the program as follows.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:60}Beispiel 60   }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

In \tabref{tabex:05:60} wird das Verb ‚einstellen‘ verwendet. Es handelt sich dabei um ein ambiges Verb, das u.~a. als ‚stop‘ oder ‚set‘ übersetzt werden kann. Die Regel (Verwendung vom Passiv vs. Aktiv) kann bei solchen Fällen einen semantischen Fehler dieser Art nicht beeinflussen. Dies ist anders als der Wortstellungsfehler (GR.10) in \tabref{tabex:05:61}, bei dem man erwartet, dass Google Translate in der Lage sei, den Satz ohne Wortstellungsprobleme zu übersetzen.


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & Flecken \textbf{sollten} so schnell wie möglich \textbf{behandelt werden}.\\
\tablevspace
GNMÜ & Stains \txblue{should be treated} as soon as possible.\\
\midrule
\textbf{Nach-KS} & Flecken \textbf{sollten Sie} so schnell wie möglich \textbf{behandeln}.\\
\tablevspace
GNMÜ & Stains \txred{should treat you} as soon as possible.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:61} Beispiel 61   }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

Im nächsten Abschnitt wird die Fehleranzahl der verschiedenen Systeme pro Fehlertyp gegenübergestellt.

\subsubsubsection{Vergleich der Fehlertypen auf Regel- und MÜ-Systemebene}

Eine genauere Betrachtung der Fehlertypen auf Systemebene zeigt (\figref{fig:05:91}), dass die Fehleranzahl bei den einzelnen Fehlertypen im Allgemeinen gering war bzw. sich meistens vor KS im Vergleich zu nach KS kaum veränderte.


\begin{figure}

%\includegraphics[height=.3\textheight]{figures/d3-img080.png}



%\includegraphics[height=.3\textheight]{figures/d3-img026.png}\\
\begin{tikzpicture}
\tikzset{every node/.style={font=\scriptsize}};
	\begin{axis}[
	xbar,
	width = \textwidth,
	height = .83\textheight,
	axis lines* = left,
	xlabel = {Summe},
	ytick = {1,2,3,...,14},
	yticklabels = {IN\_LX\_3.v,
	IN\_LX\_3.n,
	IN\_LX\_4.v,
	IN\_LX\_4.n,
	IN\_GR\_8.v,
	IN\_GR\_8.n,
	IN\_GR\_10.v,
	IN\_GR\_10.n,
	IN\_SM\_11.v,
	IN\_SM\_11.n,
	IN\_SM\_12.v,
	IN\_SM\_12.n,
	IN\_SM\_13.v,
	IN\_SM\_13.n
	},
%	x tick label style={rotate=60,anchor=east,font=\scriptsize},
	enlarge y limits={.032},
	xmin=0,
	xmax = 13,
%	bar shift = 1pt,
  	bar width=3,
	nodes near coords,
	legend pos = south east,
	reverse legend,
%	legend style={at={(0.5,-0.1)},anchor=north},
%	legend columns = {-1},
	]
	\addplot+[tmnlpone]
	coordinates {
	(0,1)
	(0,2)
	(0,3)
	(0,4)
	(0,5)
	(0,6)
	(2,7)
	(0,8)
	(4,9)
	(2,10)
	(1,11)
	(0,12)
	(1,13)
	(1,14)
	};
	\addplot+[lsLightOrange]
	coordinates {
	(0,1)
	(0,2)
	(0,3)
	(0,4)
	(0,5)
	(0,6)
	(0,7)
	(2,8)
	(4,9)
	(4,10)
	(0,11)
	(1,12)
	(1,13)
	(1,14)
	};
	\addplot+[smGreen]
	coordinates {
	(0,1)
	(0,2)
	(0,3)
	(1,4)
	(1,5)
	(1,6)
	(0,7)
	(1,8)
	(8,9)
	(9,10)
	(1,11)
	(1,12)
	(0,13)
	(0,14)
	};
	\addplot+[tmnlpthree]
	coordinates {
	(2,1)
	(4,2)
	(8,3)
	(4,4)
	(2,5)
	(3,6)
	(8,7)
	(8,8)
	(3,9)
	(4,10)
	(2,11)
	(5,12)
	(1,13)
	(1,14)
	};
	\addplot+[lsRed]
	coordinates {
	(0,1)
	(0,2)
	(0,3)
	(3,4)
	(0,5)
	(0,6)
	(2,7)
	(3,8)
	(5,9)
	(13,10)
	(0,11)
	(1,12)
	(3,13)
	(3,14)
	};
	\legend{Bing,Google,Lucy,SDL,Systran}
	\end{axis}
\end{tikzpicture}

\caption{\label{fig:05:91}„Passiv. verm.“ -- Summe der Fehleranzahl der Fehlertypen vor vs. nach KS bei den einzelnen MÜ-Systemen   }
\bspnote{*Die Balken zeigen die Summe der Fehleranzahl bei jedem Fehlertyp, wobei „v“ für die Summe „vor der Anwendung der KS-Regel“ und „n“ für die Summe „nach der Anwendung der KS-Regel“ steht. Jeder Fehlertyp wird erst für alle Systeme für das Szenario „vor KS“ abgebildet, danach folgt derselbe Fehlertyp wieder für alle Systeme für das Szenario „nach KS“.

**Um die Übersichtlichkeit und Lesbarkeit der Grafik zu erhöhen, wurden in der Grafik die Fehlertypen ausgeblendet, die 0 oder nur einmal bei \textit{allen} MÜ-Systemen vorkamen: In dieser Grafik kamen die Fehlertypen 1, 2, 5, 6 und 9 bei gar keinem MÜ-System vor. Zudem kam der Fehlertyp 7 nur einmal jeweils bei einem MÜ-System vor.
}
\end{figure}

Auf Systemebene waren die am meisten aufgetretenen Fehlertypen LX.4 „Zusätzliches Wort eingefügt“, GR.10 „Wortstellungsfehler“ (\tabref{tabex:05:61}) und SM.11 „Verwechslung des Sinns“ (\tabref{tabex:05:60}). Ein Beispiel für den Fehlertyp LX.4 „Zusätzliches Wort eingefügt“ zeigt der folgende Fall (\tabref{tabex:05:62}):


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & Bei der Arbeit mit elektrischen Geräten \textbf{sollte} stets ein Sicherheitsstecker \textbf{verwendet werden}.\\
\tablevspace
HMÜ Systran & When working with electrical devices, a safety plug \txblue{should always be used}.\\
\midrule
\textbf{Nach-KS} & Bei der Arbeit mit elektrischen Geräten \textbf{verwenden Sie} stets einen Sicherheitsstecker.\\
\tablevspace
HMÜ Systran & When working with electrical devices, \txred{you} always \txblue{use} a safety plug.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:62}Beispiel 62   }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

In \tabref{tabex:05:62} handelt es sich um eine Sicherheitsanweisung. Bei dieser Art der technischen Kommunikation wird empfohlen, den Nutzer direkt anzusprechen, d. h. das Aktiv bzw. den Imperativ zu verwenden. Dennoch war Systran nicht in der Lage, die Imperativformulierung korrekt zu parsen.

Unabhängig von der Fehleranzahl und sogar bei fehlerfreien MÜ hat eine Formulierung im Passiv vs. Aktiv einen großen Einfluss auf den Stil. Daher werden im nächsten Abschnitt die Stil- und Inhaltsqualität analysiert und insbesondere bei der größten Annotationsgruppe RR näher betrachtet.

\subsubsection{\label{sec:5.3.6.4}Vergleich der MÜ-Qualität beim Passiv vs. Aktiv sowie die Korrelation zwischen den Fehlertypen und der Qualität}

Unter den neun analysierten Regeln kommt die Regel „Passiv vermeiden“ auf Platz eins mit dem höchsten Rückgang der Stil- und Inhaltsqualität nach der Regelanwendung:\footnote{\textrm{Definitionen der Qualität unter \sectref{sec:4.4.5.1}.}} Die Stilqualität sank um 5,9~\% (Mv = 4,41 / SDv = ,482 / Mn = 4,15 / SDn = ,506 / N = 83). Die Inhaltsqualität sank um 5,6~\% (Mv = 4,62 / SDv = ,597 / Mn = 4,36 / SDn = ,923 / N = 83), siehe \figref{fig:05:92}. Der Mittelwert der Differenz (nach KS $-$ vor KS) der vergebenen Qualitätspunkte pro Satz lag für die Stilqualität bei $-$~,265 (SD = ,610) mit einem 95\%\nobreakdash-Konfidenzintervall zwischen einem Minimum von $-$~,398 und einem Maximum von $-$~,132 und für die Inhaltsqualität bei $-$~,262 (SD = ,944) mit einem 95\%\nobreakdash-Konfidenzintervall zwischen einem Minimum von $-$~,468 und einem Maximum von $-$~,056 (Bootstrapping mit 1000 Stichproben), siehe \figref{fig:05:93}. Die Differenzen (nach KS $-$ vor KS) in der Stil- und Inhaltsqualität erwiesen sich als hochsignifikant (z (N = 83) = $-$~6,235 / p < ,001) bzw. (z (N = 83) = $-$ 4,740 / p < ,001).

\begin{figure}
%\textbf{4,31}



%\textbf{4,52}



%\textbf{4,15}



%\textbf{4,56}



%\textbf{4,04}



%\textbf{4,26}




%\includegraphics[height=.3\textheight]{figures/d3-img029.png}

%\textbf{4,494,75}



%\includegraphics[height=.3\textheight]{figures/d3-img030.png}



%\includegraphics[height=.3\textheight]{figures/d3-img029.png} &  &
%\includegraphics[height=.3\textheight]{figures/d3-img017.png}
 %%[Warning: Draw object ignored]



%\includegraphics[height=.3\textheight]{figures/d3-img017.png}\\

\captionsetup{width=.45\textwidth}
\begin{floatrow}
\ffigbox[.5\textwidth]{\caption{„Passiv verm.“ -- Mittelwerte der Qualität vor und nach KS}\label{fig:05:92}}{
\includegraphics[width=.25\textwidth]{figures/Abb92.png}
\includegraphics[width=.2\textwidth]{figures/Abb15-legend.png}
}
\ffigbox[.45\textwidth]{\caption{„Passiv verm.“ -- Mittelwert der Qualitätsdifferenzen}\label{fig:05:93}}{
\includegraphics[width=.25\textwidth]{figures/Abb16-legend.png}
\includegraphics[width=.3\textwidth]{figures/Abb93.png}
}
\end{floatrow}
\end{figure}

Die Humanevaluation deckt den Grund des Qualitätsrückgangs auf. Wie \figref{fig:05:94} zeigt, verschlechtern sich alle Qualitätskriterien nach der Verwendung einer Aktivformulierung (nach KS). Hierbei spielten das zweite Stilqualitätskriterium (SQ2 -- Stilistische Adäquatheit)\footnote{\textrm{Stilistische Adäquatheit im Sinne von \citet[163]{HutchinsSomers1992} ist „the extent to which the translation uses the language appropriate to its content and intention”. Mehr zu den Definitionen der Qualität unter \sectref{sec:4.4.5.1}.}} zusammen mit dem ersten Inhaltsqualitätskriterium (CQ1 -- Genauigkeit) die wesentliche Rolle bei der Qualitätsveränderung.


\begin{figure}
%\textbf{+~7~\%}

%\textbf{+~25~\%}

%\textbf{+~72~\%}

%\textbf{+~212~\%}

%\textbf{+~16~\%}
\pgfplotstableread{
1 28
2 35
3 49
4 153
5 251
6 268
7 102
8 175
9 64
10 74
}\datatable

\begin{tikzpicture}
    \begin{axis}[ybar,
                enlarge x limits={.05},
                width  = \textwidth,
                height = .45\textheight,
                axis lines*=left,
                axis on top,
                bar width=8.5,
                bar shift=0pt,
                ymin = 0,
                ymax=300,
                xtick = {1,2,...,10},
                xticklabels={SQ1\_v,
                SQ1\_n,
                SQ2\_v,
                SQ2\_n,
                SQ3\_v,
                SQ3\_n,
                CQ1\_v,
                CQ1\_n,
                CQ2\_v,
                CQ2\_n},
            x tick label style={font=\small},
            nodes near coords,
 	 extra description/.code={
	 \node at (axis cs:1,70)[anchor = west]{$+$ 25\%};
	 \node at (axis cs:2.8,195)[anchor = west]{$+$ 212\%};
	  \node at (axis cs:5,305)[anchor = west]{$+$ 7\%};
	   \node at (axis cs:6.8,210)[anchor = west]{$+$ 72\%};
	    \node at (axis cs:9,110)[anchor = west]{$+$ 16\%};
	  }
            ]
        \addplot +[shift={(.5,0)},lsDarkBlue,x filter/.code={\ifodd\coordindex\def\pgfmathresult{}\fi}] table {\datatable};
        \addplot +[shift={(-.5,0)},lsMidBlue,  x filter/.code={\ifodd\coordindex\relax\else\def\pgfmathresult{}\fi}] table {\datatable};
    \end{axis}
\end{tikzpicture}

\caption{\label{fig:05:94}„Passiv verm.“ -- Vergleich der Qualitätskriterien   }
\bspnote{\textbf{SQ1:} Ü ist \textbf{nicht} korrekt bzw. \textbf{nicht} klar dargestellt, d. h. nicht orthografisch\\
 \textbf{SQ2:} Ü ist \textbf{nicht} ideal für die Absicht des Satzes, d. h. motiviert den Nutzer \textbf{nicht} zum Handeln, zieht \textbf{nicht} seine Aufmerksamkeit an usw.\\
 \textbf{SQ3:} Ü klingt \textbf{nicht} natürlich bzw. \textbf{nicht} idiomatisch.\\
\textbf{CQ1:} Ü gibt die Informationen im Ausgangstext \textbf{nicht} exakt wieder.\\
\textbf{CQ2:} Ü ist \textbf{nicht} leicht zu verstehen, d. h. \textbf{nicht} gut formuliert bzw. dargestellt.}

\end{figure}

In \tabref{tabex:05:63} sanken die Stilqualität ($-$~,63 Punkte auf der Likert-Skala) und die Inhaltsqualität ($-$~,25 Punkte auf der Likert-Skala).


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & Die akustischen Signale \textbf{können} je nach Gerät \textbf{umprogrammiert werden}. \\
\tablevspace
GNMÜ & Depending on the device, the acoustic signals \txblue{can be reprogrammed}.\\
\midrule
\textbf{Nach-KS} & Die akustischen Signale \textbf{können Sie} je nach Gerät \textbf{umprogrammieren}. \\
\tablevspace
GNMÜ & Depending on the device, \txblue{you can reprogram} the acoustic signals.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:63}Beispiel 63   }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

Nach der Regelanwendung wird der Nutzer durch das Aktiv direkt angesprochen. Dies fanden die Bewerter stilistisch nicht erforderlich (SQ2). Einer der Bewerterkommentare lautete: „It's not common to directly address the reader as ‚you’ in these contexts. I'd recommend the passive voice instead.“ Der geringe Punktabzug bei der Inhaltsqualität erfolgte aufgrund der Unsicherheit bei der Genauigkeit der Übersetzung (CQ1) des Verbs ‚umprogrammieren‘ als ‚reprogram‘. Hierbei wünschten sich die Bewerter für eine adäquate Übersetzung mehr Kontextinformationen.

\subsubsubsection{Korrelation zwischen den Fehlertypen und der Qualität}

Auf Basis der Fehlerannotation zusammen mit der Humanevaluation gibt uns eine Spearman-Korrelationsanalyse Aufschluss, wie die Veränderung bei der Fehleranzahl bei jedem Fehlertyp (Anz. nach KS $–$ Anz. vor KS) mit den Qualitätsunterschieden (Q. nach KS $–$ Q. vor KS) zusammenhängt. Bei der Stilqualität gab es zwei signifikante mittlere negative Korrelationen zwischen der Differenz in den Fehlertypen LX.4 „Zusätzliches Wort eingefügt“ und GR.10 „Wortstellungsfehler“ einzeln und der Differenz in der Stilqualität. Die weiteren signifikanten Korrelationen zwischen der Differenz in den Fehlertypen LX.3 „Wort ausgelassen“ und SM.11 „Verwechslung des Sinns“ einzeln und der Differenz in der Stilqualität waren schwache negative Korrelationen. (siehe \tabref{tab:05:62})

Bei der Inhaltsqualität gab es drei signifikante mittlere negative Korrelationen zwischen der Differenz in den Fehlertypen GR.10, SM.11 und SM.12 „Falsche Wahl“ einzeln und der Differenz in der Inhaltsqualität. Die weiteren signifikanten Korrelationen zwischen der Differenz in den Fehlertypen LX.3 und LX.4 einzeln und der Differenz in der Inhaltsqualität waren schwache negative Korrelationen. (siehe \tabref{tab:05:62})

Weitere Korrelationen zwischen anderen einzelnen Fehlertypen und der Qualität konnten nicht erwiesen werden.


\begin{table}
\begin{tabularx}{\textwidth}{Xrrr}

\lsptoprule
& { \textbf{N}} & { \textbf{p}} & \textbf{ρ}\\
\midrule
\textbf{Differenz SQ (nach KS $-$ vor KS)} & {} & {} & \\
Diff. der Anzahl der \textbf{LX.3 „Wort ausgelassen“} & { 83} & { ,014} & $-$~,269\\
Diff. der Anzahl der \textbf{LX.4 „Zusätzliches Wort eingefügt“} & { 83} & { ,001} & \txgreen{$-$~,371}\\
Diff. der Anzahl der \textbf{GR.10 „Wortstellungsfehler“} & { 83} & { < ,001} & \txgreen{$-$~,431}\\
Diff. der Anzahl der \textbf{SM.11 „Verwechslung des Sinns“} & { 83} & { ,038} & $-$~,228\\
Diff. der Anzahl der \textbf{SM.12 „Falsche Wahl“} & { 83} & \txgray{,271} & $-$~,122\\
\midrule
\textbf{Differenz CQ (nach KS $-$ vor KS)} &  &  & \\
Diff. der Anzahl der \textbf{LX.3 „Wort ausgelassen“} &{ 83} & { ,007} & $-$~,293\\
Diff. der Anzahl der \textbf{LX.4 „Zusätzliches Wort eingefügt“} & { 83} & { ,008} & $-$~,290\\
Diff. der Anzahl der \textbf{GR.10 „Wortstellungsfehler“} & { 83} & { < ,001} & \txgreen{$-$~,473}\\
Diff. der Anzahl der \textbf{SM.11 „Verwechslung des Sinns“} & { 83} & { ,001} & \txgreen{$-$~,354}\\
Diff. der Anzahl der \textbf{SM.12 „Falsche Wahl“} & { 83} & { ,004} & \txgreen{$-$~,315}\\
\midrule
\textbf{Differenz allg. Q (nach KS $-$ vor KS)} &  & & \\
Diff. der Anzahl der \textbf{LX.3 „Wort ausgelassen“} & { 83} & { ,008} & $-$~,290\\
Diff. der Anzahl der \textbf{LX.4 „Zusätzliches Wort eingefügt“} & { 83} & { ,001} & \txgreen{$-$~,349}\\
Diff. der Anzahl der \textbf{GR.10 „Wortstellungsfehler“} & { 83} & { < ,001} & \txgreen{$-$~,441}\\
Diff. der Anzahl der \textbf{SM.11 „Verwechslung des Sinns“} & { 83} & { ,004} & \txgreen{$-$~,312}\\
Diff. der Anzahl der \textbf{SM.12 „Falsche Wahl“} & { 83} & { ,005} & \txgreen{$-$~,302}\\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:62}„Passiv verm.“ -- Korrelation zwischen den Fehlertypen und der Qualität   }
\bspnote{*In der Tabelle werden nur die Fehlertypen dargestellt, die mindestens mit einer Qualitätsvariable signifikant korrelieren.
\begin{tabbing}
p: Signifikanz\hspace{2.5cm} \= \txgray{nicht signifikant (p ${\geq}$ 0,05)}\hspace{.5cm} \= ρ: Korrelationskoeffizient\\
schwache Korrelation (ρ >=0,1)\> \txgreen{mittlere Korrelation (ρ >= 0,3)} \> \boxblue{starke Korrelation (ρ >= 0,5)}
\end{tabbing}}
\end{table}

Bei dieser Regel stiegen die vorgekommenen Fehlertypen entweder leicht oder blieben nach der Regelanwendung unverändert. Insgesamt sanken sowohl die Stilqualität als auch die Inhaltsqualität signifikant. In \tabref{tabex:05:64} beobachten wir, wie sich der Wortstellungsfehler in ‚you can connect‘ nach der Regelanwendung auf die MÜ auswirkt.


\begin{table}
\begin{tabularx}{\textwidth}{lX}
\lsptoprule
\textbf{Vor-KS} & Durch diese Öffnung \textbf{kann} der Stecker mit dem Regler \textbf{verbunden werden}.\\
\tablevspace
SMÜ SDL & Through this opening, the plug \txblue{can be connected} to the controller.\\
\midrule
\textbf{Nach-KS} & Durch diese Öffnung \textbf{können Sie} den Stecker mit dem Regler \textbf{verbinden}.\\
\tablevspace
SMÜ SDL & Through this opening, the plug \txred{you can connect} to the controller.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:64}Beispiel 64  }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

Nach der Formulierung des Satzes im Aktiv, trat der Wortstellungsfehler auf. Daraufhin sanken die Stilqualität um 1,25 Punkte und die Inhaltsqualität um 1,63 Punkte auf der Likert-Skala.

\subsubsubsection{Vergleich der Qualität auf Regel- und MÜ-Systemebene}

Wie \figref{fig:05:95} zeigt, sanken grundsätzlich die Stil- und Inhaltsqualität nach der Regelanwendung bei allen Systemen mit der Ausnahme eines leichten Anstiegs der Inhaltsqualität bei dem HMÜ-System Bing:


\begin{figure}
\includegraphics[width=.8\textwidth]{figures/d3-img081.png}
\includegraphics[width=.15\textwidth]{figures/Abb15-legend.png}
%\includegraphics[height=.3\textheight]{figures/d3-img033.png}\\
\caption{\label{fig:05:95}„Passiv verm.“ -- Mittelwerte der Qualität vor vs. nach KS bei den einzelnen MÜ-Systemen   }
\end{figure}

Die signifikanten Rückgänge der Stilqualität wurden bei zwei Systemen registriert: dem RBMÜ-System Lucy ($-$~8,4~\%) und dem HMÜ-System Systran ($-$~9,0~\%). Einen signifikanten Rückgang der Inhaltsqualität gab es nur bei Systran ($-$~15,6~\%). (siehe \tabref{tab:05:63})


\begin{table}
\begin{tabularx}{\textwidth}{lrrrrrrrrr}

\lsptoprule
& \multicolumn{3}{c}{ \textbf{Differenz SQ} } & \multicolumn{3}{c}{ \textbf{Differenz CQ} } & \multicolumn{3}{c}{ \textbf{Differenz allg. Q} }\\
& \multicolumn{3}{c}{\textbf{(nach KS $-$ vor KS)}} & \multicolumn{3}{c}{\textbf{(nach KS $-$ vor KS)}} & \multicolumn{3}{c}{\textbf{(nach KS $-$ vor KS)}}\\
\cmidrule(lr){2-4}\cmidrule(lr){5-7}\cmidrule(lr){8-10}
& \textbf{N} & \textbf{p} & \textbf{z} & \textbf{N} & \textbf{p} & \textbf{z} & \textbf{N} & \textbf{p} & \textbf{z}\\
\midrule
 \textbf{Bing} & 16 & \txgray{,130} & $-$~1,515 & 16 & \txgray{\enskip,138} & $-$~1,485 & 16 & \txgray{,909} & $-$~,114\\
 \textbf{Google} & 19 & \txgray{,138} & $-$~1,483 & 19 & \txgray{\enskip,200} & $-$~1,280 & 19 & \txgray{,114} & $-$~1,582\\
 \textbf{Lucy} & 17 & ,007 & $-$ 2,700 & 17 & \txgray{1,000} & ,000 & 17 & ,023 & $-$ 2,282\\
 \textbf{SDL} & 14 & \txgray{,329} & $-$~,975 & 14 & \txgray{\enskip,184} & $-$~1,329 & 14 & \txgray{,249} & $-$~1,154\\
 \textbf{Systran} & 17 & ,031 & $-$ 2,155 & 17 & ,009 & $-$ 2,603 & 17 & ,008 & $-$ 2,643\\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:63}„Passiv verm.“ -- Signifikanz der Qualitätsveränderung bei den einzelnen MÜ-Systemen   }
\bspnote{p: Signifikanz\hspace{2.5cm} z: Teststatistik\hspace{2.5cm} \txgray{nicht signifikant (p ${\geq}$ 0,05)}}
\end{table}

Der signifikante Rückgang der Stil- und Inhaltsqualität bei dem HMÜ-System Systran kam zum großen Teil dadurch, dass das Subjekt ‚Sie‘ in der aktiven Version (nach KS) als ‚they‘ anstatt ‚you‘ übersetzt wurde (Semantikfehler SM.11 „Verwechslung des Sinns“). Wie \tabref{tabex:05:65} zeigt, war dieser Semantikfehler der einzige Fehler nach der Anwendung der Regel.


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & \textbf{Der EIN/AUS-Schalter} \txred{kann} \textbf{komfortabel mit dem Fuß} \txred{betätigt werden}.\\
\tablevspace
HMÜ Systran & The ON/OFF switch \txblue{can be operated} conveniently with your foot.\\
\midrule
\textbf{Nach-KS} & \textcolor{lsRed}{Sie können} \textbf{den EIN/AUS-Schalter komfortabel mit dem Fuß} \txred{betätigen}.\\
\tablevspace
HMÜ Systran & \textcolor{lsRed}{They} \txblue{can operate} the ON/OFF switch conveniently with your foot.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:65}Beispiel 65   }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

Bei diesem Satz sank nach der Regelanwendung die Stilqualität ($-$~,25 auf der Likert-Skala) und die Inhaltsqualität ($-$~1,63 auf der Likert-Skala).

\subsubsubsection{Korrelation zwischen den Fehlertypen und der Qualität auf Regel- und MÜ-Systemebene}

Anhand der Spearman-Korrelationsanalyse erwies sich nur bei dem SMÜ-System SDL ein signifikanter starker negativer Zusammenhang zwischen der Differenz in den Fehlertypen LX.3 „Wort ausgelassen“, LX.4 „Zusätzliches Wort eingefügt“ und GR.10 „Wortstellungsfehler“ einzeln und der Stilqualität sowie ein signifikanter starker negativer Zusammenhang zwischen der Differenz in den Fehlertypen LX.3 und GR.10 einzeln und der Inhaltsqualität (siehe \tabref{tab:05:64}).


\begin{table}
\begin{tabularx}{\textwidth}{Xrrr}

\lsptoprule
&  \multicolumn{3}{c}{ \textbf{SDL}}\\
\cmidrule(lr){2-4}
& \textbf{N} & \textbf{p} & \textbf{ρ}\\
\midrule
\multicolumn{4}{l}{\textbf{Differenz SQ} \textbf{(nach KS $-$ vor KS)}} \\
Diff. der Anzahl \textbf{LX.3 „W. fehlt“} & 14 & ,048 & \boxblue{$-$~,536} \\
Diff. der Anzahl \textbf{LX.4 „W. extra“}  & 14 & ,028 & \boxblue{$-$~,584} \\
Diff. der Anzahl \textbf{GR.10 „Wortst.“}  & 14 & < ,001 & \boxblue{$-$~,807}\\
\midrule
\multicolumn{4}{l}{\textbf{Differenz CQ} \textbf{(nach KS $-$ vor KS)}}\\
Diff. der Anzahl \textbf{LX.3 „W. fehlt“} & 14 & ,032 & \boxblue{$-$~,573} \\
Diff. der Anzahl \textbf{LX.4 „W. extra“} & 14 & \txgray{,052} & $-$~,528 \\
Diff. der Anzahl \textbf{GR.10 „Wortst.“} & 14 & ,014 & \boxblue{$-$~,638} \\
\midrule
\multicolumn{4}{l}{\textbf{Differenz Q} \textbf{(nach KS $-$ vor KS)}}\\
Diff. der Anzahl \textbf{LX.3 „W. fehlt“} & 14 & ,033 & \boxblue{$-$~,572}\\
Diff. der Anzahl \textbf{LX.4 „W. extra“} & 14 & ,036 & \boxblue{$-$~,564} \\
Diff. der Anzahl \textbf{GR.10 „Wortst.“}  & 14 & ,006 & \boxblue{$-$~,697}\\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:64}„Passiv verm.“ -- Korrelationen zwischen den Fehlertypen und der Qualität bei den einzelnen MÜ-Systemen  }
\bspnote{*In der Tabelle werden nur die Fehlertypen dargestellt, die bei mind. einer Qualitätsvariable eine signifikante Korrelation aufweisen.
\begin{tabbing}
p: Signifikanz\hspace{2.5cm} \= \txgray{nicht signifikant (ρ ${\geq}$ 0,05)}\hspace{.5cm} \= ρ: Korrelationskoeffizient\\
schwache Korrelation (ρ >=0,1) \> \txgreen{mittlere Korrelation (ρ >= 0,3)} \> \boxblue{starke Korrelation (ρ >= 0,5)}
\end{tabbing}
}
\end{table}

In \tabref{tabex:05:66} erschienen der lexikalische Fehlertyp LX.3 „Wort ausgelassen“ (das Subjekt ‚you‘ sowie das Verb ‚treat‘ wurden ausgelassen) sowie der Wortstellungsfehler GR.10 (in ‚Stains should‘) nach der Verwendung des Aktivs (Nach KS).


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & Flecken \textbf{sollten} so schnell wie möglich \textbf{behandelt werden}.\\
\tablevspace
SMÜ SDL & Stains \txblue{should be treated} as soon as possible.\\
\midrule
\textbf{Nach-KS} & Flecken \textbf{sollten Sie} so schnell wie möglich \textbf{behandeln}.\\
\tablevspace
SMÜ SDL & \textcolor{lsRed}{XXX} Stains \txred{should XXX} as soon as possible.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:66}Beispiel 66   }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens; \txred{XXX} für ein fehlendes Wort oder Komma.}
\end{table}

Daraufhin sanken die Stilqualität (um 1,75 Punkte) und die Inhaltsqualität (um 3,50 Punkte auf der Likert-Skala) nach der Regelanwendung deutlich.

\subsubsection{\label{sec:5.3.6.5}Vergleich der MÜ-Qualität beim Passiv vs. Aktiv auf Annotationsgruppenebene}

Die MÜ-Qualität\footnote{\textrm{Definitionen der Qualität unter \sectref{sec:4.4.5.1}.}} sank nach der Regalanwendung in allen Annotationsgruppen mit zwei Ausnahmen: In der Gruppe FR (Passivsatz wurde falsch übersetzt; Aktivsatz wurde richtig übersetzt) stiegen die Stil- und Inhaltsqualität leicht; in der Gruppe RR (Satz wurde im Passiv und im Aktiv richtig übersetzt) stieg nur die Inhaltsqualität minimal (\figref{fig:05:96}).


\begin{figure}
\includegraphics[width=\textwidth]{figures/d3-img082.png}

%\includegraphics[height=.3\textheight]{figures/d3-img035.png}\\
\caption{\label{fig:05:96}„Passiv verm.“ -- Mittelwerte der Qualität vor vs. nach KS auf Annotationsgruppenebene   }
\end{figure}

In der Gruppe FF (Satz wurde im Passiv und im Aktiv falsch übersetzt) sank die Stilqualität signifikant (z (N = 25) = $-$ 2,566 / p = ,010) und die Inhaltsqualität nicht signifikant (z (N = 25) = $-$~1,351 / p = ,177), siehe \tabref{tab:05:65}.


\begin{table}
\begin{tabularx}{\textwidth}{Xrrr}

\lsptoprule
& \textbf{N} & { \textbf{p}} & { \textbf{Z} }\\
& & \textbf{(Signifikanz)} & \textbf{(Teststatistik)}\\
\midrule
{\textbf{Annotationsgruppe FF}} & {} & {} & \\
\textbf{Differenz SQ (nach KS $-$ vor KS)} & 25 & ,010 & $-$~2.566\\
\textbf{Differenz CQ (nach KS $-$ vor KS)} & 25 & \txgray{,177} & $-$~1,351\\
\textbf{Differenz allg. Q (nach KS $-$ vor KS)} & 25 & ,019 & $-$ 2,345\\
\midrule
{\textbf{Annotationsgruppe FR}} & {} & {} & \\
\textbf{Differenz SQ (nach KS $-$ vor KS)} & 6 & \txgray{,114} & $-$~1,581\\
  \textbf{Differenz CQ (nach KS $-$ vor KS)} & 6 & \txgray{,080} & $-$~1,753\\
\textbf{Differenz allg. Q (nach KS $-$ vor KS)} & 6 & \txgray{,075} & $-$~1,782\\
\midrule
{\textbf{Annotationsgruppe RF}} & {} & {} & \\
\textbf{Differenz SQ (nach KS $-$ vor KS)} & 12 & ,003 & $-$ 2,940\\
  \textbf{Differenz CQ (nach KS $-$ vor KS)} & 12 & ,002 & $-$ 3,062\\
\textbf{Differenz allg. Q (nach KS $-$ vor KS)} & 12 & ,002 & $-$ 3,061\\
\midrule
{\textbf{Annotationsgruppe RR}} & {} & {} & \\
\textbf{Differenz SQ (nach KS $-$ vor KS)} & 40 & \txgray{,061} & $-$~1,876\\
  \textbf{Differenz CQ (nach KS $-$ vor KS)} & 40 & \txgray{,427} & $-$~,794\\
   \textbf{Differenz allg. Q (nach KS $-$ vor KS)} & 40 & \txgray{,383} & $-$~,872\\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:65}„Passiv verm.“ -- Signifikanz der Qualitätsveränderung auf Annotationsgruppenebene   }
\end{table}

\tabref{tabex:05:67} zeigt, dass obwohl der semantische Fehler (in der Übersetzung des Verbs ‚einstellen‘ als ‚stop‘ anstatt ‚set‘) sich in beiden Szenarien (vor und nach KS) wiederholt, die Bewerter die Passivformulierung nicht kritisierten. Im Gegenteil -- eine der empfohlenen Korrekturen war eine Passivformulierung „The program \textit{has been set up} by the manufacturer as follows“. Entsprechend sank bei der Verwendung des Aktivs die Stilqualität um 0,38 Punkte und die Inhaltsqualität um 0,13 Punkte auf der Likert-Skala. Eine solche Empfehlung unterliegt der Einschätzung der Bewerter, inwiefern die Handlung mithilfe des Passivs in den Vordergrund gerückt werden sollte.


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & Das Programm \textbf{wird} vom Hersteller wie folgt \textbf{eingestellt}.\\
\tablevspace
HMÜ Systran & The program \txblue{is} \txred{stopped} by the manufacturer as follows.\\
\midrule
\textbf{Nach-KS} & Der Hersteller \textbf{stellt} das Programm wie folgt \textbf{ein}.\\
\tablevspace
HMÜ Systran & The manufacturer \txred{stops} the program as follows.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:67}Beipiel 67   }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

Erwartungsgemäß stiegen die Stil- und Inhaltsqualität in der Gruppe FR (MÜ falsch vor KS; richtig nach KS), dennoch war der Anstieg nicht signifikant, siehe \figref{fig:05:96} und \tabref{tab:05:65}, denn diese Gruppe war relativ klein (8~\%; 10 Sätze, siehe \figref{fig:05:88}).

In der Gruppe RF (MÜ richtig vor KS; falsch nach KS) sanken die Stil- und Inhaltsqualität signifikant, siehe \tabref{tab:05:65}. Dieses Ergebnis ist nachvollziehbar, denn die Humanevaluation zeigte, dass eine richtig übersetzte Passivformulierung stilistisch und inhaltlich besser als eine falsche Aktivformulierung ist.

In der Gruppe RR (Satz wurde im Passiv und im Aktiv richtig übersetzt) sank die Stilqualität leicht und die Inhaltsqualität stieg minimal. Eine insignifikante Veränderung der Qualität bei dieser Gruppe zeigt, dass eine Aktivformulierung nicht unbedingt vorteilhaft ist. In \tabref{tabex:05:68} empfahlen die Bewerter zur Verbesserung des Stils, den Satz im Passiv zu formulieren; einer der Bewerterkommentare lautete: „remove \textquotesingle you\textquotesingle\, and rewrite as passive: \textquotesingle The configuration of the module can be exported\ldots\textquotesingle“. Sie hielten somit eine direkte Anrede des Lesers nicht für erforderlich; dies hängt potenziell mit der Möglichkeitsformulierung (in ‚can be exproted‘) zusammen, die im Satz ausgedrückt werden soll.


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & Die Konfigurierung des Moduls \textbf{kann} in eine Datei \textbf{exportiert werden}.\\
\tablevspace
HMÜ Bing & The configuration of the module \txblue{can be exported} to a file.\\
\midrule
\textbf{Nach-KS} & \textbf{Sie können} die Konfigurierung des Moduls in eine Datei \textbf{exportieren}.\\
\tablevspace
HMÜ Bing & \textcolor{tmnlpthree}{You can export} the configuration of the module to a file.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:68}Beispiel 68  }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

\subsubsection{\label{sec:5.3.6.6}Vergleich der AEM-Scores beim Passiv vs. Aktiv sowie die Korrelation zwischen den AEM-Scores und der Qualität}

Der Vergleich der AEM-Scores nach der Verwendung des Aktivs (nach KS) zeigte sowohl mit TERbase als auch mit hLEPOR eine Verschlechterung der AEM-Scores.


\begin{figure}
%\includegraphics[height=.3\textheight]{figures/d3-img022.png}




%\includegraphics[height=.3\textheight]{figures/d3-img022.png}


%\includegraphics[height=.3\textheight]{figures/d3-img022.png}

\includegraphics[width=.4\textwidth]{figures/Abb97.png}
\includegraphics[width=.35\textwidth]{figures/Abb19-legend.png}

\caption{\label{fig:05:97}  „Passiv verm.“ -- Mittelwert der Differenz der AEM-Scores}
\bspnote{Differenz = AEM-Score nach KS \textit{minus} AEM-Score vor KS }
\end{figure}

Der Mittelwert der Differenz (nach KS $-$ vor KS) im AEM-Score pro Satz lag für TERbase bei ,12 (SD = ,210) und für die hLEPOR bei ,074 (SD = ,135) mit einem 95\%\nobreakdash-Konfidenzintervall (Bootstrapping mit 1000 Stichproben), siehe \figref{fig:05:79}. Die Differenzen (nach KS $-$ vor KS) in TERbase und hLEPOR erwiesen sich als hochsignifikant (z (N = 83) = $-$~4,717 / p < ,001) bzw. (z (N = 83) = $-$ 4,400 / p < ,001). Dieses Ergebnis weist darauf hin, dass für die Korrektur der Aktivsätze mehr Edits erforderlich wären.

\subsubsubsection{Korrelation zwischen den Differenzen in den AEM-Scores und der Qualität}

Wie der vierte Analysefaktor (\sectref{sec:5.3.6.4}) zeigte, sank die Qualität nach der Regelanwendung signifikant. Mithilfe des Spearman-Korrelationstests erwies sich ein signifikanter starker positiver Zusammenhang zwischen den Differenzen der AEM-Scores von TERbase und hLEPOR und der Differenz der allgemeinen Qualität. Nach der Verwendung der Aktivformulierung (nach KS) verschlechterten sich die Scores der beiden AEMs und es war ein Qualitätsabfall zu bemerken.


\begin{table}
\begin{tabularx}{\textwidth}{Xrrrr}

\lsptoprule
& \textbf{N} & { \textbf{Signifikanz} } & \textbf{Korrelations-} & \textbf{Stärke}\\
& & \textbf{(p)} & \textbf{koeffizient} & \textbf{der}\\
& & &  \textbf{(ρ)} &  \textbf{Korrelation}\\
\midrule
Korrelation zw. Differenz in der allg. Qualität und Differenz des TERbase-Scores (nach KS $-$ vor KS) & { 83} & < ,001 & ,504 & \makecell[tr]{starker\\Zusammen-\\hang}\\
\tablevspace
Korrelation zw. Differenz in der allg. Qualität und Differenz des hLEPOR-Scores (nach KS $-$ vor KS) & { 83} & < ,001 & ,553 & \makecell[tr]{starker\\Zusammen-\\hang}\\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:66}„Passiv verm.“ -- Korrelation zwischen den Differenzen der AEM-Scores und den Qualitätsdifferenzen   }
\bspnote{{schwache Korrelation (ρ >=0,1)}\hspace{1em}{ mittlere Korrelation (ρ >= 0,3)}\hspace{1em} starke Korrelation (ρ >= 0,5)}
\end{table}

Diese signifikante positive Korrelation deutet darauf hin, dass die in der Humanevaluation und automatischen Evaluation festgestellten Qualitätsveränderungen übereinstimmen bzw. sich gegenseitig bestätigen.

\subsubsection{\label{sec:5.3.6.7}Analyse der sechsten Regel -- Validierung der Hypothesen}

Um die vorgestellten Ergebnisse auf die Forschungsfragen der Studie zurückzuführen, listet dieser Abschnitt die zugrunde liegenden Hypothesen der Forschungsfragen zusammen mit einer Zusammenfassung der Ergebnisse der sechsten analysierten Regel in tabellarischer Form auf. Für einen schnelleren Überblick steht (+) für eine Verbesserung bzw. einen Anstieg z.~B. im Sinne eines Qualitätsanstiegs, verbesserter AEM-Scores oder eines Anstiegs der Fehleranzahl; ($-$) steht für einen Rückgang; die \txgreen{grüne} Farbe symbolisiert eine signifikante Veränderung; \textit{neg} steht für eine negative Korrelation und \textit{pos} für eine positive Korrelation; <{}<{}>{}> steht für eine starke Korrelation und <> für eine mittlere Korrelation.\footnote{\textrm{Schwache Korrelationen werden in dieser Übersicht nicht angezeigt.}}

\subsubsubsection*{\textbf{Regel 6: Passiv vermeiden}}
\paragraph*{Erster Analysefaktor: Vergleich der Fehleranzahl beim Passiv vs. Aktiv}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Gibt es einen Unterschied in der Fehleranzahl nach der Anwendung der KS-Regel im Vergleich zu vor der Anwendung?
\item [H0 --] Es gibt keinen Unterschied in der Fehleranzahl vor vs. nach der Anwendung der KS-Regel.
\item [H1 --] Es gibt einen Unterschied in der Fehleranzahl vor vs. nach der Anwendung der KS-Regel.
\item [Resultat]
\end{description}
\noindent
\parbox[t]{.8\textwidth}{\textbf{Auf Regelebene:}}\\
\parbox[t]{.8\textwidth}{
H0 wurde nicht abgelehnt und somit konnte H1 nicht bestätigt werden.

Die Fehleranzahl stieg nach der Verwendung des Aktivs (nach KS), allerdings war der Anstieg nicht signifikant.
}
\parbox[t]{.04\textwidth}{}
\parbox[t]{.15\textwidth}{
{ \textbf{Anz.F.}} \textbf{(+)}
}

\noindent
\parbox[t]{.8\textwidth}{\textbf{Auf Regel- und MÜ-Systemebene:}}\\
\parbox[t]{.8\textwidth}{
Bei Bing sank die Fehleranzahl signifikant, nach der Verwendung des Aktivs (nach KS).

Hingegen stieg bei Systran die Fehleranzahl.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.15\textwidth}{
{ \textbf{Bi ($-$)}}

 \textbf{Sy (+)}\\
}}

\medskip
\noindent
\parbox[t]{.8\textwidth}{
Bei den anderen drei Systemen stieg die Fehleranzahl nicht signifikant (nach KS).
}
\parbox[t]{.04\textwidth}{}
\parbox[t]{.15\textwidth}{
{ \textbf{Go (+)}}

{ \textbf{Lu (+)}}

 \textbf{SD (+)}
}

\hrule
\paragraph*{Zweiter Analysefaktor}\hfill\\

\begin{figure}[H]
% 88
\torte{35}{10}{16}{59}
\caption{Aufteilung der Annotationsgruppen auf Regelebene}
\end{figure}

\begin{figure}[H]
\begin{tikzpicture}
\tikzset{every node/.style={font=\scriptsize}};
	\begin{axis}[
	ybar,
	width = \textwidth,
  height = .5\textheight,
	axis lines* = left,
	ylabel = {\%},
	xtick = {3,9,15,21},
	xticklabels = {FF,FR,RF,RR},
  x tick label style ={yshift=-5pt},
	xtick=data,
  xlabel={Annotationsgruppe},
	ymin=0,
	ymax = 15,
%	bar shift = 0pt,
  bar width=9,
  enlarge x limits = .2,
  y filter/.code={\pgfmathparse{#1/120*100}\pgfmathresult},
%	nodes near coords,
%	legend pos= north east,
	legend style={at={(0.5,-0.15)},anchor=north},
	legend columns = {-1},
	]
	\addplot+[lsNightBlue]
	coordinates {
	(3,3)
	(9,4)
	(15,0)
	(21,17)
	};
	\addplot+[tmnlpone]
	coordinates {
	(3,5)
	(9,0)
	(15,2)
	(21,17)
	};
	\addplot+[tmnlptwo]
	coordinates {
	(3,9)
	(9,0)
	(15,1)
	(21,14)
	};
	\addplot+[tmnlpthree]
	coordinates {
	(3,9)
	(9,6)
	(15,7)
	(21,2)
	};
	\addplot+[tmnlpfour]
	coordinates {
	(3,9)
	(9,0)
	(15,6)
	(21,9)
	};
	\legend{Bing,Google,Lucy,SDL,Systran}
	\end{axis}
\end{tikzpicture}
\caption{Aufteilung der Annotationsgruppen auf Regel- und MÜ-Systemebene}
\end{figure}

\hrule
\paragraph*{Dritter Analysefaktor: Vergleich der Fehlertypen beim Passiv vs. Aktiv}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Beinhaltet die MÜ bestimmte Fehlertypen vor bzw. nach der Anwendung der KS-Regel?
\item [H0 --] Es gibt keinen Unterschied in der Häufigkeit der einzelnen Fehlertypen vor vs. nach der Anwendung der KS-Regel.
\item [H1 --] Es gibt einen Unterschied in der Häufigkeit der einzelnen Fehlertypen vor vs. nach der Anwendung der KS-Regel.
\item [Resultat]
\end{description}
\noindent
\parbox[t]{\textwidth}{\textbf{Auf Regelebene:}}\\
\parbox[t]{\textwidth}{
H0 wurde nicht abgelehnt und somit konnte H1 nicht bestätigt werden.

Der Unterschied in der Fehleranzahl erwies sich bei keinem der Fehlertypen als signifikant.
}

\noindent
\parbox[t]{\textwidth}{\textbf{Auf Regel- und MÜ-Systemebene:}}\\
\parbox[t]{\textwidth}{
Es gab bei keinem der Systeme signifikante Veränderungen in den Fehlertypen. Die Fehleranzahl bei den einzelnen Fehlertypen fiel im Allgemeinen gering aus bzw. veränderte sich meistens vor vs. nach KS kaum.
}
\smallskip
\hrule
\paragraph*{Vierter Analysefaktor: Vergleich der MÜ-Qualität beim Passiv vs. Aktiv}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:]  Gibt es einen Unterschied in der Stil- und Inhaltsqualität der MÜ der KS-Stelle nach der Anwendung der KS-Regel im Vergleich zu vor der Anwendung?
\item [H0 --] Es gibt keinen Qualitätsunterschied vor vs. nach der Anwendung der KS-Regel.
\item [H1 --] Es gibt einen Qualitätsunterschied vor vs. nach der Anwendung der KS-Regel.
\item [Resultat]
\end{description}
\noindent
\parbox[t]{.8\textwidth}{\textbf{Auf Regelebene:}}\\
\parbox[t]{.8\textwidth}{
H0 wurde abgelehnt und somit H1 bestätigt.

Sowohl die Stil- als auch die Inhaltsqualität sanken signifikant.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.15\textwidth}{
{ \textbf{SQ ($-$)}}

 \textbf{CQ ($-$)}
}}

\noindent
\parbox[t]{.8\textwidth}{\textbf{Auf Regel- und MÜ-Systemebene:}}\\
\parbox[t]{.8\textwidth}{
Die Stilqualität sank bei Lucy und Systran signifikant (nach KS).
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.15\textwidth}{
{ \textbf{SQ ($-$):}}

{ \textbf{Lu}} \textbf{Sy}
}}

\medskip
\noindent
\parbox[t]{.8\textwidth}{
Die Inhaltsqualität sank bei Systran signifikant (nach KS).
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.15\textwidth}{
{ \textbf{CQ ($-$):}} \textbf{Sy}
}}

\medskip
\noindent
\parbox[t]{.8\textwidth}{
Alle weiteren Qualitätsveränderungen waren nicht signifikant; generell sanken sowohl die Stil- als auch die Inhaltsqualität in den weiteren Fällen mit Ausnahme der Inhaltsqualität von Bing, die leicht anstieg.
}

\hrule
\paragraph*{Fünfter Analysefaktor: Korrelation zwischen den Fehlertypen und der Qualität}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Besteht ein Zusammenhang zwischen der Differenz der Fehleranzahl eines bestimmten Fehlertyps (Fehleranzahl nach KS $-$ vor KS) und der Differenz der Stil- bzw. Inhaltsqualität (Qualität nach KS $-$ vor KS)?
\item [H0 --] Es besteht kein Zusammenhang zwischen der Differenz der Fehleranzahl eines bestimmten Fehlertyps und der Differenz der Stil- bzw. Inhaltsqualität.
\item [H1 --] Es besteht ein Zusammenhang zwischen der Differenz der Fehleranzahl eines bestimmten Fehlertyps und der Differenz der Stil- bzw. Inhaltsqualität.
\item [Resultat]
\end{description}
\noindent
\parbox[t]{.7\textwidth}{\textbf{Auf Regelebene:}}\\
\parbox[t]{.7\textwidth}{
H1 wurde für vier Fehlertypen wie folgt bestätigt:

Es bestand ein signifikanter mittlerer negativer Zusammenhang zwischen der Differenz der Fehleranzahl des LX.4 „Zusätzliches Wort eingefügt“ und GR.10 „Wortstellungsfehler“ einzeln und der Stilqualität sowie ein signifikanter mittlerer negativer Zusammenhang zwischen der Differenz der Fehleranzahl des GR.10 „GR – Wortstellungsfehler“, SM.11 „Verwechslung des Sinns“ und SM.12 „Falsche Wahl“ einzeln und der Differenz der Inhaltsqualität.
\newpage
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.25\textwidth}{
{ \textbf{\textit{neg}} \textbf{LX.4 <> SQ}}

{ \textbf{\textit{neg}} \textbf{GR.10 <> SQ}}\\

{ \textbf{\textit{neg}} \textbf{GR.10 <> CQ}}

{ \textbf{\textit{neg}} \textbf{SM.11 <> CQ}}

 \textbf{\textit{neg}} \textbf{SM.12 <> CQ}\\
 \\
 \\
 \\
}}

\noindent
\parbox[t]{.7\textwidth}{\textbf{Auf Regel- und MÜ-Systemebene:}}\\
\parbox[t]{.7\textwidth}{
Bei SDL bestand ein signifikanter starker negativer Zusammenhang zwischen der Differenz der Fehleranzahl des LX.3 „Wort ausgelassen“, LX.4 „Zusätzliches Wort eingefügt“ und GR.10 „Wortstellungsfehler“ einzeln und der Differenz der Stilqualität sowie ein signifikanter starker negativer Zusammenhang zwischen der Differenz der Fehleranzahl des LX.3 „Wort ausgelassen“ und GR.10 „Wortstellungsfehler“ einzeln und der Differenz der Inhaltsqualität.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.25\textwidth}{
{ \textbf{SD}}

{ \textbf{\textit{neg}} \textbf{LX.3 <{}<{}>{}> SQ}}

{ \textbf{\textit{neg}} \textbf{LX.4 <{}<{}>{}> SQ}}

{ \textbf{\textit{neg}} \textbf{GR.10 <{}<{}>{}> SQ}}\\

{ \textbf{\textit{neg}} \textbf{LX.3 <{}<{}>{}> CQ}}

 \textbf{\textit{neg}} \textbf{GR.10 <{}<{}>{}> CQ}\\
 \\
}}

\medskip
\noindent
\parbox[t]{.7\textwidth}{Alle weiteren Korrelationen waren nicht signifikant.}

\hrule
\paragraph*{Sechster Analysefaktor: Vergleich der MÜ-Qualität beim Passiv vs. Aktiv auf Annotationsgruppenebene}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Gibt es einen Unterschied in der Stil- und Inhaltsqualität bei den einzelnen Annotationsgruppen nach der Anwendung der KS-Regel im Vergleich zu vor der Anwendung?
\item [H0 --] Bei den Annotationsgruppen gibt es keinen Qualitätsunterschied vor vs. nach der Anwendung der KS-Regel.
\item [H1 --] Bei den Annotationsgruppen gibt es einen Qualitätsunterschied vor vs. nach der Anwendung der KS-Regel.
\item [Resultat]
\end{description}
\noindent
\parbox[t]{.8\textwidth}{
H1 wurde bei der Annotationsgruppe FF nur für die Stilqualität bestätigt:
}\\
\parbox[t]{.8\textwidth}{
Die Stilqualität sank signifikant bei der Aktivformulierung (nach KS).
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.15\textwidth}{
\textbf{SQ ($-$)}\\
}}

\medskip
\noindent
\parbox[t]{.8\textwidth}{
Der Rückgang der Inhaltsqualität war gering.
}
\parbox[t]{.04\textwidth}{}
\parbox[t]{.15\textwidth}{
\textbf{CQ ($-$)}
}

\medskip
\noindent
\parbox[t]{.8\textwidth}{
Bei der Annotationsgruppen RF sanken die Stil- und Inhaltsqualität signifikant (nach KS).
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.15\textwidth}{
{\textbf{SQ ($-$)}}\newline
\textbf{CQ ($-$)}
}}

\medskip
\noindent
\parbox[t]{.8\textwidth}{
Bei der Annotationsgruppe FR stiegen die Qualitätswerte leicht.
}
\parbox[t]{.04\textwidth}{}
\parbox[t]{.15\textwidth}{
{ \textbf{SQ (+)}}

\textbf{CQ (+)}
}

\medskip
\noindent
\parbox[t]{.8\textwidth}{
Bei der Annotationsgruppe RR sank die Stilqualität leicht und die Inhaltsqualität stieg minimal.
}
\parbox[t]{.04\textwidth}{}
\parbox[t]{.15\textwidth}{
{ \textbf{SQ ($-$)}}

\textbf{CQ (+)}
}

\hrule
\paragraph*{Siebter Analysefaktor: Vergleich der AEM-Scores beim Passiv vs. Aktiv}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Gibt es einen Unterschied in den AEM-Scores von TERbase bzw. hLEPOR nach der Anwendung der KS-Regel im Vergleich zu vor der Anwendung?
\item [H0 --] Es gibt keinen Unterschied in den AEM-Scores vor vs. nach der Anwendung der KS-Regel.
\item [H1 --] Es gibt einen Unterschied in den AEM-Scores vor vs. nach der Anwendung der KS-Regel.
\item [Resultat]
\end{description}
\noindent
\parbox[t]{.75\textwidth}{
H0 wurde abgelehnt und somit H1 bestätigt.

Die AEM-Scores von TERbase und hLEPOR verschlechterten sich signifikant im Falle der Aktivformulierung (nach KS).
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.2\textwidth}{
 \textbf{TERbase ($-$)\\hLEPOR ($-$)}\\
}}

\hrule
\paragraph*{Achter Analysefaktor: Korrelation zwischen den Differenzen der AEM-Scores und der Qualität}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Besteht ein Zusammenhang zwischen der Differenz der AEM-Scores von TERbase bzw. hLEPOR (Mittelwert der AEM-Scores nach KS $-$ vor KS) und der Differenz der allgemeinen Qualität (Qualität nach KS $-$ vor KS)?
\item [H0 --] Es besteht kein Zusammenhang zwischen der Differenz der AEM-Scores und der Differenz der allgemeinen Qualität.
\item [H1 --] Es besteht ein Zusammenhang zwischen der Differenz der AEM-Scores und der Differenz der allgemeinen Qualität.
\item [Resultat]
\end{description}
\noindent
\parbox[t]{.7\textwidth}{
H0 wurde abgelehnt und somit H1 bestätigt.

Es bestand ein signifikanter mittlerer positiver Zusammenhang zwischen der Differenz des TERbase-Scores und der Differenz der allgemeinen Qualität sowie ein signifikanter mittlerer positiver Zusammenhang zwischen der Differenz des hLEPOR-Scores und der Differenz der allgemeinen Qualität.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.25\textwidth}{
{ \textbf{\textit{pos}} \textbf{TERbase <> Q}}

 \textbf{\textit{pos}} \textbf{hLEPOR <> Q}\\
 \\
 \\
 \\
 \\
}}




\subsection{SIEBTE REGEL: Konstruktionen mit „sein +~zu +~Infinitiv“ vermeiden}
\label{sec:5.3.7}

\subsubsection{\label{sec:5.3.7.0}Überblick}

%In \tabref{tab:05:67}
Im Folgenden wird die KS-Regel „Konstruktionen mit ‚sein~+~zu~+~Infinitiv‘ vermeiden“ kurz beschrieben.\footnote{\textrm{Die für diese Regel relevanten Kontraste im Sprachenpaar DE-EN sind unter \sectref{sec:4.4.2.3} erörtert.} } Zudem wird zusammenfassend und anhand von Beispielen demonstriert, wie die Regel bei der Analyse angewendet wurde. Anschließend wird die Aufteilung der Testsätze im Datensatz dargestellt:

\begin{description}[font=\normalfont\bfseries]
\item [Beschreibung der KS-Regel:] \textbf{Konstruktionen mit „sein + zu + Infinitiv“ vermeiden} (tekom-Regel-Nr. S 511)

Nach dieser Regel (\citealt{tekom2013}:~86) soll die Passiversatzkonstruktion „sein +~zu +~Infinitiv“ bei Anweisungen vermieden werden. Stattdessen sollen diese durch einen Infinitiv oder die direkte Anrede formuliert werden.

Begründung: Diese Passiversatzkonstruktion ist umständlich und der Leser wird nicht direkt angesprochen. Der Infinitiv bzw. eine direkte Anrede fördert die schnelle und richtige Umsetzung der Handlung (ebd.).

\item[Umsetzungsmuster:]
~\\
\textbf{Vor KS:} Der Satz ist mit einem Passiversatz (sein +~zu + Infinitiv) formuliert.\\
\textbf{Nach KS:} zwei Varianten sind möglich

-- Imperativ am Satzende

-- Imperativ am Satzanfang

Beide Varianten wurden bei der Übersetzung mit MÜ-Systemen getestet. Da die erste Variante mit mehr MÜ-Fehlern verbunden war, wurde entschieden, die zweite Variante als Umsetzungsmuster zu verwenden.

Wenn der Satz vor KS mit ‚so‘ formuliert ist, wurde ‚so‘ aus stilistischen Gründen nach KS entfernt.

\item[KS-Stelle]
~\\
\textbf{Vor KS:} sein +~zu +~Infinitiv\\
\textbf{Nach KS:} Imperativ +~Subjekt\\

\item[Beispiele]
~\\
\textit{Die Herstellerangaben \txgray{sind} stets zu \txgray{beachten}.}

\textit{\txgray{Beachten Sie} stets die Herstellerangaben.}
~\\
\textit{Ist ein mehrstufiges Modul parametriert, \ul{so} \txgray{sind} die externen Kontakte \txgray{zu} \txgray{verriegeln}.}

\textit{Ist ein mehrstufiges Modul parametriert, \txgray{verriegeln Sie} die externen Kontakte.}

\item[Aufteilung der Testsätze:]
Der Datensatz besteht aus 24 verschieden Verben im Passiversatz, die an unterschiedlichen Stellen in den Sätzen platziert sind.

\end{description}

%\multicolumn{2}{p{6cm}}{\label{bkm:Ref36849708}Eckdaten der siebten Regel „Passiversatz vermeiden“}\\
%\end{tabularx}\caption{\label{tab:05:67}   }

Im Weiteren werden die Ergebnisse der einzelnen Analysefaktoren demonstriert.

\subsubsection{Vergleich der Fehleranzahl mit vs. ohne die Konstruktion „sein +~zu +~Infinitiv“}
\label{sec:5.3.7.1}

Die Fehleranzahl sank um mehr als ein Drittel, nämlich um 37,2~\%, von 86 Fehlern bei der Verwendung des Passiversatzes mit „sein +~zu +~Infinitiv“ (M = ,72 / SD = ,881 / N = 120) auf 54 Fehler bei der Vermeidung des Passiversatzes (M = ,45 / SD = ,765 / N = 120), siehe \figref{fig:05:98}. Knapp 80~\% (19 von 24) der analysierten Sätze wurden von mindestens einem MÜ-System falsch übersetzt und mithilfe der KS-Regel korrigiert. Der Mittelwert der Differenz (nach KS $-$ vor KS) der Fehleranzahl pro Satz lag somit bei $-$~,27 (SD = 1,098) mit einem 95\%\nobreakdash-Konfidenzintervall zwischen einem Minimum von $-$~,47 (SD = ,864) und einem Maximum von $-$~,07 (SD = 1,311) (Bootstrapping mit 1000 Stichproben), siehe \figref{fig:05:99}. Die Differenz (nach KS $-$ vor KS) der Fehleranzahl erwies sich als signifikant (z (N = 120) = $-$ 3,059 / p = ,002).


\begin{figure}
%\includegraphics[height=.3\textheight]{figures/d3-img023.png}

%\includegraphics[height=.3\textheight]{figures/d3-img023.png}


%\includegraphics[height=.3\textheight]{figures/d3-img084.png} &  &
%                                                                \includegraphics[height=.3\textheight]{figures/d3-img024.png}
%                                                                \includegraphics[height=.3\textheight]{figures/d3-img024.png}

%                                                                \textbf{,33,59}

%                                                                \textbf{,57,87}%\hhline%%replace by cmidrule{-~-}
\captionsetup{width=.45\textwidth}
\begin{floatrow}
\ffigbox[.5\textwidth]{\caption{„Passiversatz verm.“ -- Fehlersumme vor vs. nach KS}
\label{fig:05:98}}{
\begin{tikzpicture}
	\begin{axis}[
	ybar,
	ymin = 0,
	ymax = 125,
	axis lines* = left,
	nodes near coords,
%         nodes near coords align = vertical,
  legend style={at={(0.5,-0.2)},anchor=north,cells={align=left}},
  xtick=\empty,
  width = .45\textwidth,
  enlarge x limits = .5
	]
	\addplot+[tmnlpone]
	coordinates{
	(1,86)
	};
	\addplot+[tmnlpthree]
	coordinates{
	(2,54)
	};
	\legend{Anzahl der  fehler\\innerh. KS vor KS,Anzahl der Fehler\\innerh. KS nach KS}
	\end{axis}
\end{tikzpicture}
}
%
%
\ffigbox[.45\textwidth]{\caption{„Passiversatz verm.“ -- Mittelwert der Fehleranzahl pro Satz vor vs. nach KS}\label{fig:05:99}}{
\includegraphics[width=.25\textwidth]{figures/Abb99.png}
\includegraphics[width=.4\textwidth]{figures/Abb21-legend.png}
}
\end{floatrow}
\end{figure}

Die Sätze, die falsch übersetzt wurden, haben keine gemeinsamen Eigenschaften. Sie sind unterschiedlich lang und der Passiversatz war unterschiedlich platziert. Es scheint, dass die MÜ-Systeme durch das zusätzliche Verb (sind) im Passiversatz irregeleitet werden und dadurch Schwierigkeiten haben, den Satz korrekt zu parsen. In \tabref{tabex:05:69} konnte das Verb nicht richtig übersetzt werden (‚is $\ldots$ turn off‘). Durch die Regelanwendung konnte dieses Problem gelöst werden.


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & Bei Funktionsstörungen \textbf{ist} die Maschine sofort \textbf{auszuschalten}.\\
\tablevspace
HMÜ Bing & In the event of malfunction, the machine \txred{is} immediately \txred{turn off}.\\
\midrule
\textbf{Nach-KS} & Bei Funktionsstörungen \textbf{schalten Sie} die Maschine sofort \textbf{aus}.\\
\tablevspace
HMÜ Bing & In the event of malfunction, \txblue{turn off} the machine immediately.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:69}Beispiel 69   }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

\subsubsubsection{Vergleich der Fehleranzahl auf Regel- und MÜ-Systemebene}

Ein genauer Einblick bei den einzelnen MÜ-Systemen zeigt, dass die Fehleranzahl bei zwei MÜ-Systemen sank (\figref{fig:05:100}).


\begin{figure}
%\includegraphics[height=.3\textheight]{figures/d3-img085.png}

%\textbf{\textit{+~133,3~\%}}

%\textbf{\textit{+~81,8~\%}}

%\textbf{\textit{$-$ 78,4~\%}}

%\textbf{0~\%}

%\textbf{\textit{$-$ 85,2~\%}}


%\includegraphics[height=.3\textheight]{figures/d3-img023.png}\\
\begin{tikzpicture}
	\begin{axis}[
	ybar,
	ymin = 0,
	ymax = 40,
	axis lines* = left,
	nodes near coords,
  legend style={at={(0.5,-0.2)},anchor=north},
  xticklabels = {Bing,Google,Lucy,SDL,Systran},
  xtick=data,
  ylabel = {Summe},
  extra description/.code={
            \node at (axis cs:-.3, 33)[anchor=west] {\bfitul{$-$ 85,2\%}};
						\node at (axis cs:.8, 6)[anchor=west] {0\%};
						\node at (axis cs:1.5, 25)[anchor=west] {\bfitul{$+$ 81,8 \%}};
						\node at (axis cs:2.5, 43)[anchor=west] {\bfitul{$-$ 78,4 \%}};
						\node at (axis cs:3.5, 26)[anchor=west] {$+$ 133,3 \%};
						}
	]
	\addplot+[tmnlpone]
	coordinates{
	(0,27)
	(1,1)
	(2,11)
	(3,37)
	(4,9)
	};
	\addplot+[tmnlpthree]
	coordinates{
	(0,4)
	(1,1)
	(2,20)
	(3,8)
	(4,21)
	};
	\legend{Anzahl der  fehler innerh. KS vor KS,Anzahl der Fehler innerh. KS nach KS}
	\end{axis}
\end{tikzpicture}
\caption{\label{fig:05:100}„Passiversatz verm.“ -- Summe der Fehleranzahl vor vs. nach KS bei den einzelnen MÜ-Systemen  }
\bspnote{\bfitul{Signifikante Differenz vor vs. nach KS}}
\end{figure}

Bei dem NMÜ-System Google Translate wurden 23 der 24 analysierten Sätze sowohl vor als auch nach der Anwendung der KS-Regel korrekt übersetzt. Mit Ausnahme von Google waren die Differenzen bei allen anderen MÜ-Systemen signifikant (\figref{fig:05:100}): Die Abnahme bei Bing betrug 85,2~\% (Mdiff = $-$~,958; z (N = 24) = $-$ 3,573 / p < ,001) und bei SDL 78,4~\% (Mdiff = $-$~1,208; z (N = 24) = $-$ 3,815 / p < ,001). Auf der anderen Seite belief sich die Zunahme bei Lucy auf 81,8~\% (Mdiff = ,375; z (N = 24) = $-$~2,496 / p = ,013) und bei Systran auf 133,3~\% (Mdiff = ,500; z (N = 24) = $-$ 2,126 / p =~,033). In \tabref{tabex:05:70} werden die MÜ von SDL vs. Google verglichen:


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & Das Kaufdatum \textbf{ist} durch eine Kaufquittung \textbf{zu belegen}.\\
\tablevspace
SMÜ SDL & The purchase date \txblue{is} through a purchase receipt \txred{to prove}.\\
GNMÜ & The purchase date \txblue{is to be confirmed} by a purchase receipt.\\
\midrule
\textbf{Nach-KS} & \textbf{Belegen Sie} das Kaufdatum durch eine Kaufquittung.\\
\tablevspace
SMÜ SDL & \textcolor{lsRed}{Assign} the purchase date by a purchase receipt.\\
GNMÜ & \textcolor{tmnlpthree}{Confirm} the purchase date with a purchase receipt.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:70} Beispiel 70  }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

Die Passiversatzkonstruktion war für SDL problematisch zu übersetzen. SDL hatte auf semantischer Ebene (die Ambiguität des Verbs ‚belegen‘ und auf syntaktischer Ebene (die Passiversatzkonstruktion) Schwierigkeiten bei der Übersetzung des Satzes vor und nach der Regelanwendung. Die Regelanwendung erleichterte für SDL die Übersetzung auf syntaktischer Ebene, dennoch blieb das Problem der Ambiguität des Verbs ungelöst. Auf der anderen Seite war Google in der Lage, den Satz vor und nach der Regelanwendung fehlerfrei zu übersetzen.

\subsubsection{\label{sec:5.3.7.2}Aufteilung der Annotationsgruppen}

Die größte Annotationsgruppe bei dieser Regel war die Gruppe RR; etwa 39~\% der analysierten Sätze wurden sowohl mit als auch ohne die Passiversatzkonstruktion fehlerfrei übersetzt (\figref{fig:05:101}). Eine weitere große Gruppe war FR, in der knapp 28~\% der Sätze erst nach der Regelanwendung korrekt übersetzt werden konnten. Die Gruppe FF war ebenfalls relativ groß; knapp 21~\% der Sätze konnten weder vor noch nach der Regelanwendung korrekt übersetzt werden.


\begin{figure}
%\includegraphics[height=.3\textheight]{figures/d3-img012.png}



%\includegraphics[height=.3\textheight]{figures/d3-img086.png}
% 101
\torte{25}{33}{15}{47}
\caption{\label{fig:05:101}„Passiversatz verm.“ -- Aufteilung der Annotationsgruppen   }
\end{figure}

Die kleinste Gruppe war RF (ca. 12~\%), in der die Passiversatzkonstruktion fehlerfrei übersetzt wurde und erst nach der Regelanwendung beinhaltete die Übersetzung Fehler (\figref{fig:05:101}). Im kommenden Abschnitt (\sectref{sec:5.3.7.3}) werden die aufgetretenen Fehlertypen analysiert.

\subsubsubsection{Vergleich der Aufteilung der Annotationsgruppen auf Regel- und MÜ-Systemebene}

Eine Analyse der Annotationsgruppenaufteilung zeigte Folgendes (\figref{fig:05:102}):


\begin{figure}

%\includegraphics[height=.3\textheight]{figures/d3-img087.png}

%  \textbf{13\% 4\%}  \textbf{33\% 25\%29\%}          \textbf{71\%}          \textbf{4\%}  \textbf{58\%}  \textbf{4\%}            \textbf{4\%}          \textbf{33\%}        \textbf{25\%}          \textbf{13\% 96\% 29\%17\% 42\%}



%\includegraphics[height=.3\textheight]{figures/d3-img026.png}\\
\begin{tikzpicture}
\tikzset{every node/.style={font=\scriptsize}};
	\begin{axis}[
	ybar,
	width = \textwidth,
	axis lines* = left,
	ylabel = {Anzahl},
	xtick = {3,9,15,21},
	xticklabels = {FF,FR,RF,RR},
  x tick label style ={yshift=-5pt},
	xtick=data,
  xlabel={Annotationsgruppe},
	ymin=0,
	ymax = 25,
%	bar shift = 0pt,
  bar width=9,
  enlarge x limits = .2,
	nodes near coords,
%	legend pos= north east,
	legend style={at={(0.5,-0.15)},anchor=north},
	legend columns = {-1},
	extra description/.code={
  \node at (axis cs:.3,4.5)[anchor = west]{2,5\%};
	\node at (axis cs:.3,-.5)[anchor = west]{13\%};
	\node at (axis cs:1.2,2.5)[anchor = west]{0,8\%};
	\node at (axis cs:1.3,-.5)[anchor = west]{4\%};
	\node at (axis cs:2,9.5)[anchor = west]{6,7\%};
	\node at (axis cs:2.1,-.5)[anchor = west]{33\%};
	\node at (axis cs:3.1,7.5)[anchor = west]{5,0\%};
	\node at (axis cs:3.1,-.5)[anchor = west]{25\%};
	\node at (axis cs:4,8.5)[anchor = west]{5,8\%};
	\node at (axis cs:4.1,-.5)[anchor = west]{29\%};
	\node at (axis cs:6.4,18.5)[anchor = west]{14,2\%};
	\node at (axis cs:6.4,-.5)[anchor = west]{71\%};
%  \node at (axis cs:7.4,5)[anchor = west]{3,3\%};
%	\node at (axis cs:7.4,-.5)[anchor = west]{17\%};
\node at (axis cs:8.2,2.5)[anchor = west]{0,8\%};
\node at (axis cs:8.3,-.5)[anchor = west]{4\%};
	\node at (axis cs:9.1,15.5)[anchor = west]{11,7\%};
	\node at (axis cs:9.2,-.5)[anchor = west]{58\%};
  \node at (axis cs:10,2.5)[anchor = west]{0,8\%};
	\node at (axis cs:10.2,-.5)[anchor = west]{4\%};
\node at (axis cs:12.3,2.5)[anchor = west]{0,8\%};
\node at (axis cs:12.4,-.5)[anchor = west]{4\%};
%  \node at (axis cs:13.3,3)[anchor = west]{1,7\%};
%	\node at (axis cs:13.4,-.5)[anchor = west]{8\%};
	\node at (axis cs:14.1,9.5)[anchor = west]{6,7\%};
	\node at (axis cs:14.2,-.5)[anchor = west]{33\%};
%  \node at (axis cs:15,8)[anchor = west]{5,8\%};
%	\node at (axis cs:15,-.5)[anchor = west]{29\%};
  \node at (axis cs:16,7.5)[anchor = west]{5,0\%};
	\node at (axis cs:16,-.5)[anchor = west]{25\%};
	\node at (axis cs:18.3,4.5)[anchor = west]{2,5\%};
	\node at (axis cs:18.3,-.5)[anchor = west]{13\%};
	\node at (axis cs:19.3,24.5)[anchor = west]{19,2\%};
	\node at (axis cs:19.3,-.5)[anchor = west]{96\%};
	\node at (axis cs:20.3,8.5)[anchor = west]{5,8\%};
	\node at (axis cs:20.3,-.5)[anchor = west]{29\%};
	\node at (axis cs:21.1,5.5)[anchor = west]{3,3\%};
	\node at (axis cs:21.3,-.5)[anchor = west]{17\%};
	\node at (axis cs:22.1,11.5)[anchor = west]{8,3\%};
	\node at (axis cs:22.2,-.5)[anchor = west]{42\%};
	}
	]
	\addplot+[lsNightBlue]
	coordinates {
	(3,3)
	(9,17)
	(15,1)
	(21,3)
	};
	\addplot+[tmnlpone]
	coordinates {
	(3,1)
	(9,0)
	(15,0)
	(21,23)
	};
	\addplot+[tmnlptwo]
	coordinates {
	(3,8)
	(9,1)
	(15,8)
	(21,7)
	};
	\addplot+[tmnlpthree]
	coordinates {
	(3,6)
	(9,14)
	(15,0)
	(21,4)
	};
	\addplot+[tmnlpfour]
	coordinates {
	(3,7)
	(9,1)
	(15,6)
	(21,10)
	};
	\legend{Bing,Google,Lucy,SDL,Systran}
	\end{axis}
\end{tikzpicture}
\caption{\label{fig:05:102}„Passiversatz verm.“ -- Aufteilung der Annotationsgruppen bei den einzelnen MÜ-Systemen   }
\bspnote{Die oben angezeigten Prozentzahlen sind für alle Systeme, d. h. systemübergreifend, (N = 120) berechnet.

Die untenstehenden Prozentzahlen sind auf Systemebene (N = 24) berechnet.}
\end{figure}

Bei zwei Systemen wurde die Mehrheit der falschen Übersetzungen mit Passiversatz (vor KS) nach der Regelanwendung korrekt übersetzt (Gruppe FR). Diese Systeme sind das HMÜ-System Bing mit 71~\% und das SMÜ-System SDL mit 58~\%. Auch bei dieser Regel waren 96~\% der Übersetzungen des NMÜ-Systems Google mit und ohne die Verwendung eines Passiversatzes korrekt (Gruppe RR). Dieser Prozentsatz ist mehr als doppelt so hoch wie die RR-Gruppe bei dem HMÜ-System Systran (42~\%) und mehr als dreimal so hoch wie bei dem RBMÜ-System Lucy (29~\%).

\subsubsection{\label{sec:5.3.7.3}Vergleich der Fehlertypen mit vs. ohne die Konstruktion „sein +~zu +~Infinitiv“}

Bei dieser Regel gab es signifikante Differenzen in der Fehleranzahl bei vier Fehlertypen: einen Anstieg beim lexikalischen Fehlertyp LX.4 „Zusätzliches Wort eingefügt“ sowie einen Rückgang bei den grammatischen Fehlertypen GR.8 „Falsches Verb (Zeitform, Komposition, Person)“, GR.9 „Kongruenzfehler“ und GR.10 „Falsche Wortstellung“. Der Unterschied bei den Fehlertypen LX.4, GR.8, GR.9 und GR.10 erwies sich wie folgt als signifikant: p < ,001 bei den Fehlertypen LX.4 und GR.8 bzw. p = ,008 bei den Fehlertypen GR.9 und GR.10 / N = 120 (\figref{fig:05:103}).


\begin{figure}
%\includegraphics[height=.3\textheight]{figures/d3-img088.png}

%\textbf{\textit{$-$ 100~\%}}

%\textbf{\textit{2500~\%}}

%\textbf{\textit{$-$ 70,6~\%}}

%\textbf{\textit{$-$ 94,1~\%}}



%\includegraphics[height=.3\textheight]{figures/d3-img027.png}
%\includegraphics[height=.3\textheight]{figures/d3-img013.png}



%\includegraphics[height=.3\textheight]{figures/d3-img013.png} & vor KS
% 103
\pgfplotstableread{
1 0
2 0
3 0
4 1
5 5
6 2
7 1
8 26
9 0
10 0
11 0
12 0
13 2
14 0
15 34
16 2
17 9
18 0
19 17
20 5
21 11
22 13
23 4
24 4
25 3
26 1
}\datatable
\smbars[extra description/.code={
\node at (axis cs:6,30)[anchor = west]{\bfitul{2500 \%}};
\node at (axis cs:14,38)[anchor = west]{\bfitul{$-$ 94,1 \%}};
\node at (axis cs:16,12)[anchor = west]{\bfitul{$-$ 100 \%}};
\node at (axis cs:18,21)[anchor = west]{\bfitul{$-$ 70,6\%}};
}
]{}
\caption{\label{fig:05:103}„Passiversatz verm.“ -- Summe der Fehleranzahl der einzelnen Fehlertypen vor vs. nach KS   }
\bspnote{*Die X-Achse ist folgendermaßen zu lesen: Jeder Fehlertyp wird anhand von zwei Balken abgebildet. Der erste Balken repräsentiert die Summe der Fehler vor KS und der zweite die Summe der Fehler nach KS, somit steht z. B. „OR\_1.v“ für „OR\_1: orthografischer Fehler Nr. 1“ und „v: vor KS“; „OR\_1.n“ wäre entsprechend das Pendant zu „OR\_1.v“ für das nach-KS-Szenario („n“).\\
**\bfitul{Signifikante Differenz vor vs. nach KS}\\
OR.1: Orthografie -- Zeichensetzung\\
OR.2: Orthografie -- Großschreibung\\
LX.3: Lexik -- Wort ausgelassen\\
LX.4: Lexik -- Zusätzliches Wort eingefügt\\
LX.5: Lexik -- Wort unübersetzt geblieben (auf DE wiedergegeben)\\
LX.6: Lexik -- Konsistenzfehler\\
GR.7: Grammatik -- Falsche Wortart / Wortklasse\\
GR.8: Grammatik -- Falsches Verb (Zeitform, Komposition, Person)\\
GR.9: Grammatik -- Kongruenzfehler (Agreement)\\
GR.10: Grammatik -- Falsche Wortstellung\\
SM.11: Semantik -- Verwechslung des Sinns\\
SM.12: Semantik -- Falsche Wahl\\
SM.13: Semantik -- Kollokationsfehler
}
\end{figure}

Um diese KS-Regel umzusetzen, wird der Passiversatz durch einen Imperativ ersetzt. Der Anstieg bei Fehlertyp LX.4 „Zusätzliches Wort eingefügt“ von 1 auf 26 (2500~\% / Mv = ,01 / SDv = ,091 / Mn = ,22 / SDn = ,414 / N = 120) entstand dadurch, dass einige Systeme den Imperativ (nach KS) nicht als solchen identifizieren konnten und stattdessen als normalen Ausgangssatz mit Subjekt ‚you‘ plus Verb übersetzten. \tabref{tabex:05:71} demonstriert diesen Fall:


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & Ist nur ein Gerät angeschlossen, so \textbf{ist} die Funktion PP \textbf{zu wählen}.\\
\tablevspace
HMÜ Systran & If only one device is connected, the $"$PP$"$ function \txblue{is to be selected}.\\
\midrule
\textbf{Nach-KS} & Ist nur ein Gerät angeschlossen, so \textbf{wählen Sie} die Funktion PP.\\
\tablevspace
HMÜ Systran & If only one device is connected, \txred{you} \txblue{select} the $"$PP$"$ function.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:71}Beispiel 71   }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

Hingegen sank die Fehleranzahl bei den Fehlertypen GR.8 „Falsches Verb (Zeitform, Komposition, Person)“ von 34 auf 2 ($-$~94,1~\% / Mv = ,28 / SDv = ,453 / Mn = ,02 / SDn = ,129 / N = 120) und GR.10 „Falsche Wortstellung“ von 17 auf 5 ($-$~70,6~\% / Mv = ,14 / SDv = ,350 / Mn = ,04 / SDn = ,201 / N = 120). Zudem wurde der Fehlertyp GR.9 „Kongruenzfehler (Agreement)“ nach der Regelanwendung vollständig behoben, von 9 auf 0, ($-$~100~\% / Mv = ,08 / SDv = ,264 / Mn = -- / SDn = -- / N = 120). Die grammatische Konstruktion eines Passiversatzes „sein + zu +~Infinitiv“ erschwert die syntaktische Analyse (Parsing) und lässt die MÜ ein falsches Verb, falsche Kongruenz bzw. falsche Wortstellung produzieren. Wenn wir den vorherigen Beispielsatz bei dem System Bing genauer betrachten, leuchtet diese grammatische Schwierigkeit ein (\tabref{tabex:05:72}).


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & Ist nur ein Gerät angeschlossen, so \textbf{ist} die Funktion $"$PP$"$ \textbf{zu wählen}.\\
\tablevspace
HMÜ Bing & If only one device is connected, the function \txred{is} $"$PP$"$ \txred{to choose}.\\
\midrule
\textbf{Nach-KS} & Ist nur ein Gerät angeschlossen, so \textbf{wählen Sie} die Funktion $"$PP$"$.\\
\tablevspace
HMÜ Bing & If only one device is connected, \txblue{select} the $"$PP$"$ function.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:72}Beispiel 72  }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

Die MÜ der Passiversatzkonstruktion wurde falsch gebildet (GR.8) und platziert (GR.10). In diesem Fall unterstützte die Regel Bing bei der Eliminierung beider Fehlertypen.

\subsubsubsection{Vergleich der Fehlertypen auf Regel- und MÜ-Systemebene}

Eine genauere Untersuchung der Fehlertypen bei den verschiedenen MÜ-Systemen zeigt (\figref{fig:05:104}), dass ein signifikanter Unterschied in der Fehleranzahl des Fehlertyps LX.4 „Zusätzliches Wort eingefügt“ bei dem RBMÜ-System Lucy von 1 auf 13 (+~1200~\%) und dem HMÜ-System Systran von 0 auf 10 (+~100~\%) zu beobachten ist (\tabref{tab:05:68}).


\begin{figure}
%\includegraphics[height=.3\textheight]{figures/d3-img089.png}



%\includegraphics[height=.3\textheight]{figures/d3-img026.png}\\
\begin{tikzpicture}
\tikzset{every node/.style={font=\scriptsize}};
	\begin{axis}[
	xbar,
	width = \textwidth,
	height = .83\textheight,
	axis lines* = left,
	xlabel = {Summe},
	ytick = {1,2,3,...,16},
	yticklabels = {IN\_LX\_3.v,
	IN\_LX\_3.n,
	IN\_LX\_4.v,
	IN\_LX\_4.n,
  IN\_GR\_7.v,
  IN\_GR\_7.n,
	IN\_GR\_8.v,
	IN\_GR\_8.n,
  IN\_GR\_9.v,
  IN\_GR\_9.n,
	IN\_GR\_10.v,
	IN\_GR\_10.n,
	IN\_SM\_11.v,
	IN\_SM\_11.n,
	IN\_SM\_12.v,
	IN\_SM\_12.n,
	},
%	x tick label style={rotate=60,anchor=east,font=\scriptsize},
	enlarge y limits={.032},
	xmin=0,
	xmax = 20,
%	bar shift = 1pt,
  	bar width=2.7,
	nodes near coords,
	legend pos = south east,
	reverse legend,
%	legend style={at={(0.5,-0.1)},anchor=north},
%	legend columns = {-1},
	]
	\addplot+[tmnlpone]
	coordinates {
	(0,1)
	(1,2)
	(0,3)
	(2,4)
	(0,5)
	(0,6)
	(19,7)
	(0,8)
	(2,9)
	(0,10)
	(2,11)
	(0,12)
	(1,13)
	(1,14)
  (2,15)
  (0,16)
	};
	\addplot+[lsLightOrange]
	coordinates {
	(0,1)
	(0,2)
	(0,3)
	(0,4)
	(0,5)
	(0,6)
	(0,7)
	(0,8)
	(1,9)
	(0,10)
	(0,11)
	(0,12)
	(0,13)
	(0,14)
  (0,15)
  (0,16)
	};
	\addplot+[smGreen]
	coordinates {
	(0,1)
	(0,2)
	(1,3)
	(13,4)
	(0,5)
	(0,6)
	(1,7)
	(0,8)
	(2,9)
	(0,10)
	(2,11)
	(2,12)
	(5,13)
	(5,14)
  (0,15)
  (0,16)
	};
	\addplot+[tmnlpthree]
	coordinates {
	(5,1)
	(1,2)
	(0,3)
	(1,4)
	(2,5)
	(0,6)
	(14,7)
	(2,8)
	(3,9)
	(0,10)
	(11,11)
	(1,12)
	(0,13)
	(2,14)
  (2,15)
  (0,16)
	};
	\addplot+[lsRed]
	coordinates {
	(0,1)
	(0,2)
	(0,3)
	(10,4)
	(0,5)
	(0,6)
	(0,7)
	(0,8)
	(1,9)
	(0,10)
	(2,11)
	(2,12)
	(5,13)
	(5,14)
  (0,15)
  (4,16)
	};
	\legend{Bing,Google,Lucy,SDL,Systran}
	\end{axis}
\end{tikzpicture}
\caption{\label{fig:05:104}„Passiversatz verm.“ -- Summe der Fehleranzahl der Fehlertypen vor vs. nach KS bei den einzelnen MÜ-Systemen   }
\bspnote{*Die Balken zeigen die Summe der Fehleranzahl bei jedem Fehlertyp, wobei „v“ für die Summe „vor der Anwendung der KS-Regel“ und „n“ für die Summe „nach der Anwendung der KS-Regel“ steht. Jeder Fehlertyp wird erst für alle Systeme für das Szenario „vor KS“ abgebildet, danach folgt derselbe Fehlertyp wieder für alle Systeme für das Szenario „nach KS“.

**Um die Übersichtlichkeit und Lesbarkeit der Grafik zu erhöhen, wurden in der Grafik die Fehlertypen ausgeblendet, die 0 oder nur einmal bei \textit{allen} MÜ-Systemen vorkamen: In dieser Grafik traten die Fehlertypen 1, 5 und 6 bei gar keinem MÜ-System auf. Zudem wurden die Fehlertypen 2 und 13 nur einmal jeweils bei 1--3 MÜ-Systemen in vereinzelten Fällen registriert.}
\end{figure}

Aus den signifikant veränderten grammatischen Fehlertypen GR.8, GR.9 und GR.10 wurde der Fehlertyp GR.8 „Falsches Verb (Zeitform, Komposition, Person)“ bei dem HMÜ-System Bing (von 19 auf 0; $-$~100~\%) nach der Anwendung der KS-Regel vollständig behoben und sank deutlich bei dem SMÜ-System SDL (von 14 auf 2; $-$~85,7~\%). Der Fehlertyp GR.9 „Kongruenzfehler (Agreement)“ zeigte bei keinem bestimmten System eine signifikante Veränderung. Der Fehlertyp GR.10 „Falsche Wortstellung“ verringerte sich bei dem SMÜ-System SDL (von 11 auf 1; $-$~90,9~\%). Die Differenz in der Fehleranzahl bei den Fehlertypen LX.4, GR.8 und GR.10 erwies sich in den genannten Systemen folgendermaßen als signifikant (\tabref{tab:05:68}).


\begin{table}
\begin{tabularx}{.86\textwidth}{lrlll}

\lsptoprule

{} & { \textbf{N}} & { \textbf{Mittelwert}} & { \textbf{Standard-}} & { \textbf{Signifikanz}}\\
& & & \textbf{abweichung} & \textbf{(McNemar-Test)}\\
\midrule
\multicolumn{5}{l}{\textbf{LX.4 „Zusätzliches Wort eingefügt“}}\\
{ \textbf{Lucy}} & { 24} & vor KS = ,04 & vor KS = ,204 & p < ,001\\
& & nach KS = ,54 & nach KS = ,509 & \\
{ \textbf{Systran}} & { 24} & vor KS = -- & vor KS = -- & p = ,004\\
& & nach KS = ,42 & {nach KS = ,504} & \\
\midrule
\multicolumn{5}{l}{\textbf{GR.8 „Falsches Verb (Zeitform, Komposition, Person)“}}\\
{ \textbf{Bing}} & { 24} & vor KS = ,79 & vor KS = ,415 & p < ,001\\
& & nach KS = -- & {nach KS = --} & \\
{ \textbf{SDL}} & { 24} & vor KS = ,58 & vor KS = ,504 & p < ,001\\
& & nach KS = ,08 & {nach KS = ,282} & \\
\midrule
\multicolumn{5}{l}{\textbf{GR.10 „Falsche Wortstellung“}}\\
{ \textbf{SDL}} & { 24} & vor KS = ,46 & vor KS = ,509 & p = ,002\\
& & nach KS = ,04 & {nach KS = ,204} & \\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:68} „Passiversatz verm.“ -- Fehlertypen mit signifikanter Veränderung nach KS  }
\end{table}

Die Verwendung eines Imperativs anstelle eines Passiversatzes vereinfachte die Satzstruktur für die älteren MÜ-Ansätze. Bei dem Neuronalen Ansatz hingegen konnte Google mit Ausnahme von einem Satz alle Sätze sowohl mit dem Passiversatz (vor KS) als auch mit dem Imperativ (nach KS) korrekt übersetzen (siehe \tabref{tabex:05:70}).

\subsubsection{\label{sec:5.3.7.4}Vergleich der MÜ-Qualität mit vs. ohne die Konstruktion „sein +~zu +~Infinitiv“ sowie die Korrelation zwischen den Fehlertypen und der Qualität}

Sowohl die Stil- als auch die Inhaltsqualität\footnote{\textrm{Definitionen der Qualität unter \sectref{sec:4.4.5.1}.}} stiegen nach der Verwendung des Imperativs anstelle der Passiversatzkonstruktion deutlich an (\figref{fig:05:105}): Die Stilqualität nahm um 12,9~\% zu (Mv = 3,73 / SDv = ,666 / Mn = 4,21 / SDn = ,569 / N = 97). Die Inhaltsqualität erhöhte sich um 10,6~\% (Mv = 4,17 / SDv = ,886 / Mn = 4,61 / SDn = ,633 / N = 97). Der Mittelwert der Differenz (nach KS $-$ vor KS) der vergebenen Qualitätspunkte pro Satz lag für die Stilqualität bei ,474 (SD = ,697) mit einem 95\%\nobreakdash-Konfidenzintervall zwischen einem Minimum von ,334 und einem Maximum von ,615 und für die Inhaltsqualität bei ,434 (SD = ,999) mit einem 95\%\nobreakdash-Konfidenzintervall zwischen einem Minimum von ,233 und einem Maximum von ,636 (Bootstrapping mit 1000 Stichproben) (\figref{fig:05:106}). Die Differenzen (nach KS $-$ vor KS) in der Stil- und Inhaltsqualität erwiesen sich als hochsignifikant (z (N = 97) = $-$~5,758 / p < ,001) bzw. (z (N = 97) = $-$ 3,806 / p < ,001).


\begin{figure}
%\textbf{4,484,73}

%\textbf{4,094,32}

%\textbf{3,603,87}

%\textbf{3,994,35}



%\includegraphics[height=.3\textheight]{figures/d3-img029.png}



%\includegraphics[height=.3\textheight]{figures/d3-img029.png}



%\includegraphics[height=.3\textheight]{figures/d3-img030.png} &  & %%[Warning: Draw object ignored]



%\includegraphics[height=.3\textheight]{figures/d3-img017.png}



%\includegraphics[height=.3\textheight]{figures/d3-img017.png}



%\includegraphics[height=.3\textheight]{figures/d3-img017.png}\\
\captionsetup{width=.45\textwidth}
\begin{floatrow}
\ffigbox[.5\textwidth]{\caption{„Passiversatz verm.“ -- Mittelwerte der Qualität vor und nach KS}\label{fig:05:105}}{
\includegraphics[width=.25\textwidth]{figures/Abb105.png}
\includegraphics[width=.2\textwidth]{figures/Abb15-legend.png}
}
\ffigbox[.45\textwidth]{\caption{„Passiversatz verm.“ -- Mittelwert der Qualitätsdifferenzen}\label{fig:05:106}}{
\includegraphics[width=.25\textwidth]{figures/Abb16-legend.png}
\includegraphics[width=.3\textwidth]{figures/Abb106.png}
}
\end{floatrow}

\end{figure}

Die Humanevaluation deckt den Grund des Qualitätsanstiegs auf. Wie \figref{fig:05:107} zeigt, spielten hierbei das zweite Stilqualitätskriterium (SQ2) zusammen mit dem ersten und zweiten Inhaltsqualitätskriterium (CQ1 und CQ2) die wesentliche Rolle bei der Qualitätsveränderung.


\begin{figure}
%\textbf{$-$ 58~\%}

%\textbf{$-$ 13~\%}

%\textbf{$-$ 38~\%}

%\textbf{$-$ 9~\%}

%\textbf{$-$ 62~\%}
\pgfplotstableread{
1 33
2 30
3 253
4 105
5 465
6 405
7 215
8 133
9 199
10 76
}\datatable

\begin{tikzpicture}
    \begin{axis}[ybar,
                enlarge x limits={.05},
                width  = \textwidth,
                height = .45\textheight,
                axis lines*=left,
                axis on top,
                bar width=8.5,
                bar shift=0pt,
                ymin = 0,
                ymax=500,
                xtick = {1,2,...,10},
                xticklabels={SQ1\_v,
                SQ1\_n,
                SQ2\_v,
                SQ2\_n,
                SQ3\_v,
                SQ3\_n,
                CQ1\_v,
                CQ1\_n,
                CQ2\_v,
                CQ2\_n},
            x tick label style={font=\small},
            nodes near coords,
 	 extra description/.code={
	 \node at (axis cs:1.1,100)[anchor = west]{$-$ 9 \%};
	 \node at (axis cs:3,325)[anchor = west]{$-$ 58\%};
	  \node at (axis cs:5.2,500)[anchor = west]{$-$ 13\%};
	   \node at (axis cs:7,275)[anchor = west]{$-$ 38\%};
	    \node at (axis cs:9,275)[anchor = west]{$-$ 62\%};
	  }
            ]
        \addplot +[shift={(.5,0)},lsDarkBlue,x filter/.code={\ifodd\coordindex\def\pgfmathresult{}\fi}] table {\datatable};
        \addplot +[shift={(-.5,0)},lsMidBlue,  x filter/.code={\ifodd\coordindex\relax\else\def\pgfmathresult{}\fi}] table {\datatable};
    \end{axis}
\end{tikzpicture}
\caption{\label{fig:05:107}„Passiversatz verm.“ -- Vergleich der Qualitätskriterien   }
\bspnote{\textbf{SQ1:} Ü ist \textbf{\textit{nicht}} korrekt bzw. \textbf{\textit{nicht}} klar dargestellt, d. h. nicht orthografisch.\\
{\textbf{SQ2:} Ü ist \textbf{\textit{nicht}} ideal für die Absicht des Satzes, d. h. motiviert den Nutzer \textbf{\textit{nicht} }zum Handeln, zieht \textbf{\textit{nicht} }seine Aufmerksamkeit an usw.}\\
\textbf{SQ3:} Ü klingt \textbf{\textit{nicht} }natürlich bzw. \textbf{\textit{nicht} }idiomatisch.\\
{\textbf{CQ1:} Ü gibt die Informationen im Ausgangstext \textbf{\textit{nicht}} exakt wieder.}\\
\textbf{CQ2:} Ü ist \textbf{\textit{nicht}} leicht zu verstehen, d. h. \textbf{\textit{nicht}} gut formuliert bzw. dargestellt.}
\end{figure}

\tabref{tabex:05:73} verdeutlicht, wie die genannten Qualitätskriterien durch die Regelanwendung beeinflusst wurden.


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & Ist nur ein Gerät angeschlossen, so \textbf{ist} die Funktion PP \textbf{zu wählen}.\\
\tablevspace
HMÜ Bing & If only one device is connected, the function \txred{is} $"$PP$"$ \txred{to choose}.\\
\midrule
\textbf{Nach-KS} & Ist nur ein Gerät angeschlossen, so \textbf{wählen Sie} die Funktion PP.\\
\tablevspace
HMÜ Bing & If\textbf{ }only one device is connected, \txblue{select} the $"$PP$"$ function.\\

\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:73}Beispiel 73   }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

In diesem Satz wurde der Nutzer (nach KS) durch den Imperativ direkt angesprochen. Dies erhöhte laut der Humanevaluation die Motivierung zum Handeln (SQ2). Außerdem wurden durch die Vereinfachung der Satzstruktur grammatische Fehler wie die falsche Verbform und Wortstellung korrigiert. Dadurch zeigte sich in der Humanevaluation eine deutliche Steigerung der Genauigkeit und Verständlichkeit der Übersetzung (CQ1 und CQ2).

\subsubsubsection{Korrelation zwischen den Fehlertypen und der Qualität}

Auf Basis der Fehlerannotation zusammen mit der Humanevaluation gibt uns eine Spearman-Korrelationsanalyse Aufschluss, wie die Veränderung in der Fehleranzahl bei jedem Fehlertyp (Anz. nach KS $–$ Anz. vor KS) mit den Qualitätsunterschieden (Q. nach KS $–$ Q. vor KS) zusammenhängt. Mithilfe des Spearman-Tests erwies sich ein signifikanter starker negativer Zusammenhang zwischen der Differenz im Fehlertyp GR.8 „Falsches Verb (Zeitform, Komposition, Person)“ und der Differenz in der Stilqualität. Außerdem erwies sich ein signifikanter mittlerer negativer Zusammenhang zwischen der Differenz in den Fehlertypen LX.4 „Zusätzliches Wort eingefügt“ und GR.10 „Wortstellungsfehler“ einzeln und der Differenz in der Stilqualität; sowie ein signifikanter schwacher negativer Zusammenhang zwischen der Differenz in den Fehlertypen LX.3 „Wort ausgelassen“, GR.7 „Falsche Wortart / Wortklasse“ und SM.12 „Falsche Wahl“ einzeln und der Differenz in der Stilqualität. (siehe \tabref{tab:05:69})

Bezüglich der Inhaltsqualität erwies sich ein signifikanter starker negativer Zusammenhang zwischen der Differenz im Fehlertyp GR.8 „Falsches Verb (Zeitform, Komposition, Person)“ und der Differenz in der Inhaltsqualität; ein signifikanter mittlerer negativer Zusammenhang zwischen der Differenz im Fehlertyp GR.10 „Wortstellungsfehler“ und der Differenz in der Inhaltsqualität; sowie ein signifikanter schwacher negativer Zusammenhang zwischen der Differenz in den Fehlertypen LX.3 „Wort ausgelassen“, LX.4 „Zusätzliches Wort eingefügt“, GR.7 „Falsche Wortart / Wortklasse“ und SM.12 „Falsche Wahl“ einzeln und der Differenz in der Inhaltsqualität. (siehe \tabref{tab:05:69})

Weitere Korrelationen zwischen anderen einzelnen Fehlertypen und der Qualität konnten nicht erwiesen werden.


\begin{table}
\begin{tabularx}{\textwidth}{Xrrr}

\lsptoprule
& { \textbf{N}} & { \textbf{p} } & \textbf{ρ}\\
\midrule
\textbf{Differenz SQ (nach KS $-$ vor KS)} &  &  & \\
Diff. der Anzahl der \textbf{LX.3 „Wort ausgelassen“} & { 97} & { ,023} & $-$~,230\\
Diff. der Anzahl der \textbf{LX.4 „Zusätzliches Wort eingefügt“} & { 97} & { < ,001} & \txgreen{$-$~,448}\\
Diff. der Anzahl der \textbf{GR.7 „Falsche Wortart“} & { 97} & { ,024} & $-$~,229\\
Diff. der Anzahl der \textbf{GR.8 „Falsches Verb“} & { 97} & { < ,001} & \boxblue{$-$~,617}\\
Diff. der Anzahl der \textbf{GR.10 „Wortstellungsfehler“} & { 97} & { < ,001} & \txgreen{$-$~,438}\\
Diff. der Anzahl der \textbf{SM.12 „Falsche Wahl“} & { 97} & { ,005} & {$-$~,282}\\
\midrule
\textbf{Differenz CQ (nach KS $-$ vor KS)} &  &  & \\
Diff. der Anzahl der \textbf{LX.3 „Wort ausgelassen“} & { 97} & { ,030} & $-$~,220\\
Diff. der Anzahl der \textbf{LX.4 „Zusätzliches Wort eingefügt“} & { 97} & { ,005} & $-$~,286\\
Diff. der Anzahl der \textbf{GR.7 „Falsche Wortart“} & { 97} & { ,014} & $-$~,248\\
Diff. der Anzahl der \textbf{GR.8 „Falsches Verb“} & { 97} & { < ,001} & \boxblue{$-$~,641}\\
Diff. der Anzahl der \textbf{GR.10 „Wortstellungsfehler“} & { 97} & { ,001} & \txgreen{$-$~,324}\\
Diff. der Anzahl der \textbf{SM.12 „Falsche Wahl“} & { 97} & { ,008} & $-$~,267\\
\midrule
\textbf{Differenz allg. Q (nach KS $-$ vor KS)} &  &  & \\
Diff. der Anzahl der \textbf{LX.3 „Wort ausgelassen“} & { 97} & { ,031} & $-$~,219\\
Diff. der Anzahl der \textbf{LX.4 „Zusätzliches Wort eingefügt“} & { 97} & { < ,001} & \txgreen{$-$~,367}\\
Diff. der Anzahl der \textbf{GR.7 „Falsche Wortart“} & { 97} & { ,016} & $-$~,244\\
Diff. der Anzahl der \textbf{GR.8 „Falsches Verb“} & { 97} & { < ,001} & \boxblue{$-$~,681}\\
Diff. der Anzahl der \textbf{GR.10 „Wortstellungsfehler“} & { 97} & { < ,001} & \txgreen{$-$~,418}\\
Diff. der Anzahl der \textbf{SM.12 „Falsche Wahl“} & { 97} & { ,004} & $-$~,287\\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:69}„Passiversatz verm.“ -- Korrelation zwischen den Fehlertypen und der Qualität   }
\bspnote{*In der Tabelle werden nur die Fehlertypen dargestellt, die mindestens mit einer Qualitätsvariable signifikant korrelieren.
\begin{tabbing}
p: Signifikanz\hspace{2.5cm}\= ρ: Korrelationskoeffizient\hspace{1cm}\= \hspace{4cm}\\
schwache Korrelation (ρ >=0,1)\> \txgreen{mittlere Korrelation (ρ >= 0,3)}\>\boxblue{starke Korrelation (ρ >= 0,5)}
\end{tabbing}}
\end{table}

Diese signifikanten negativen Korrelationen deuten darauf hin, dass mit dem Rückgang der Fehleranzahl der genannten Fehlertypen nach KS ein Qualitätsanstieg verzeichnet wurde. In \tabref{tabex:05:73} wurden die grammatischen Fehlertypen GR.8 „Falsches Verb“ und GR.10 „Wortstellung“ in ‚is $\ldots$ to choose‘ eliminiert, daraufhin stieg die Stilqualität um 1,63 Punkte und die Inhaltsqualität um 1,75 Punkte auf der Likert-Skala. In \tabref{tabex:05:74} wurde nur der Verbformfehler (GR.8) in ‚replace‘ korrigiert, nachdem der Imperativ anstelle des Passiversatzes verwendet wurde.


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & Die Bedienungsanleitung \textbf{ist} im Falle des Verlustes \textbf{zu ersetzen}.\\
\tablevspace
HMÜ Bing & The operating instructions \txblue{are to} \txred{replace} in case of loss.\\
\midrule
\textbf{Nach-KS} & \textbf{Ersetzen Sie} die Bedienungsanleitung im Falle des Verlustes.\\
\tablevspace
HMÜ Bing & \textcolor{tmnlpthree}{Replace} the operating instructions in case of loss.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:74}Beispiel 74   }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

Daraufhin stiegen die Stilqualität um 1,00 Punkte und die Inhaltsqualität um 0,75 Punkte auf der Likert-Skala.

\subsubsubsection{Vergleich der Qualität auf Regel- und MÜ-Systemebene}

Wie \figref{fig:05:108} zeigt, nahmen nicht bei allen Systemen die Stil- und Inhaltsqualität nach der Anwendung der KS-Regel zu.


\begin{figure}
\includegraphics[width=\textwidth]{figures/d3-img090.png}
%\includegraphics[height=.3\textheight]{figures/d3-img033.png}\\
\caption{\label{fig:05:108}„Passiversatz verm.“ -- Mittelwerte der Qualität vor vs. nach KS bei den einzelnen MÜ-Systemen   }
\end{figure}

Die Stilqualität stieg bei dem SMÜ-System SDL (+~37,6~\%), dem HMÜ-System Bing (+~24,4~\%) sowie dem HMÜ-System Systran (+~5,2~\%) signifikant, während die Inhaltsqualität nur bei Bing (+~33,4~\%) und SDL (+~33,5~\%) signifikant zunahm (\tabref{tab:05:70}).


\begin{table}
\begin{tabularx}{\textwidth}{lrrrrrrrrr}

\lsptoprule
& \multicolumn{3}{c}{\textbf{Differenz SQ} } & \multicolumn{3}{c}{\textbf{Differenz CQ}} & \multicolumn{3}{c}{\textbf{Differenz allg. Q} }\\
& \multicolumn{3}{c}{\textbf{(nach KS $-$ vor KS)}} &  \multicolumn{3}{c}{\textbf{(nach KS $-$ vor KS)}} & \multicolumn{3}{c}{\textbf{(nach KS $-$ vor KS)}}\\
\cmidrule(lr){2-4}\cmidrule(lr){5-7}\cmidrule(lr){8-10}
& \textbf{N} & \textbf{p} & \textbf{z} & \textbf{N} & \textbf{p} & \textbf{z} & \textbf{N} & \textbf{p} & \textbf{z}\\
\midrule
 \textbf{Bing} & 18 & ,001 & $-$ 3,342 & 18 & < ,001 & $-$ 3,519 & 18 & < ,001 & $-$ 3,616\\
 \textbf{Google} & 21 & \txgray{,104} & $-$~1,624 & 21 & \txgray{,774} & $-$~,287 & 21 & \txgray{,229} & $-$~1,203\\
 \textbf{Lucy} & 18 & \txgray{,819} & $-$~,229 & 18 & \txgray{,205} & $-$~1,268 & 18 & \txgray{,498} & $-$~,678\\
 \textbf{SDL} & 21 & < ,001 & $-$ 4,018 & 21 & ,003 & $-$ 2,958 & 21 & < ,001 & $-$ 3,702\\
 \textbf{Systran} & 19 & ,041 & $-$ 2,045 & 19 & \txgray{,551} & $-$~,597 & 19 & ,034 & $-$ 2,118\\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:70}„Passiversatz verm.“ -- Signifikanz der Qualitätsveränderung bei den einzelnen MÜ-Systemen   }
\bspnote{p: Signifikanz\hspace{2.5cm} z: Teststatistik\hspace{2.5cm} \txgray{nicht signifikant (p ${\geq}$ 0,05)}}
\end{table}

Wie die Aufteilung der Annotationsgruppen zeigte, waren 96~\% der Übersetzungen (23 von 24 Sätzen) des NMÜ-Systems Google Translate sowohl vor als auch nach der Regelanwendung (Annotationsgruppe RR) richtig. Entsprechend ist zu erwarten, dass das Qualitätsniveau sich nicht verändert.

Bei dem RBMÜ-System Lucy waren die Ergebnisse der Annotationsgruppen (\figref{fig:05:102}) sehr gemischt (d.~h. die Zahlen der Gruppen FF, RF und RR fielen ähnlich hoch aus), daher konnte keine signifikante Veränderung in der Qualität nachgewiesen werden.

\subsubsubsection{Korrelation zwischen den Fehlertypen und der Qualität auf Regel- und MÜ-Systemebene}

Anhand der Spearman-Korrelationsanalyse erwies sich bei dem HMÜ-System Bing ein signifikanter starker negativer Zusammenhang zwischen den grammatischen Fehlertypen GR.8 „Falsches Verb (Zeitform, Komposition, Person)“ und GR.10 „Wortstellungsfehler“ einzeln und der Stilqualität sowie ein signifikanter starker negativer Zusammenhang zwischen GR.8 und der Inhaltsqualität (\tabref{tab:05:71}).

Bei dem RBMÜ-System Lucy erwies sich nur eine signifikante starke negative Korrelation zwischen Fehlertyp GR.8 „Falsches Verb“ und der Inhaltsqualität (\tabref{tab:05:71}).

\newpage
Bei dem SMÜ-System SDL erwies sich nur eine signifikante starke negative Korrelation zwischen Fehlertyp GR.7 „Falsche Wortart / Wortklasse“ und der Inhaltsqualität (\tabref{tab:05:71}).

Bei dem HMÜ-System Systran erwies sich eine signifikante starke negative Korrelation zwischen dem lexikalischen Fehlertyp LX.4 „Zusätzliches Wort eingefügt“ und der Stilqualität sowie eine signifikante starke negative Korrelation zwischen den Fehlertypen LX.4 „Zusätzliches Wort eingefügt“ und GR.10 „Wortstellungsfehler“ einzeln und der Inhaltsqualität (\tabref{tab:05:71}).


\begin{sidewaystable}
\captionsetup{width=\textwidth}
\scriptsize
\begin{tabularx}{\textwidth}{Xrrrrrrrrrrrr}

\lsptoprule
& \multicolumn{3}{c}{\textbf{Bing}} & \multicolumn{3}{c}{\textbf{Lucy}} & \multicolumn{3}{c}{\textbf{SDL}} & \multicolumn{3}{c}{\textbf{Systran}}\\
\cmidrule(lr){2-4}\cmidrule(lr){5-7}\cmidrule(lr){8-10}\cmidrule(lr){11-13}
& \textbf{N} & \textbf{p} & \textbf{ρ} & \textbf{N} & \textbf{p} & \textbf{ρ} & \textbf{N} & \textbf{p} & \textbf{ρ} & \textbf{N} & \textbf{p} & \textbf{ρ}\\
\midrule
\multicolumn{13}{l}{\textbf{Differenz SQ} \textbf{(nach KS $-$ vor KS)}}\\
Diff. der Anzahl \textbf{LX.4 „W. extra eingefügt“} &  &  &  &  &  &  &  &  &  & 19 & ,006 & \boxblue{$-$~,605}\\
Diff. der Anzahl \textbf{GR.7 „Falsche Wortart“}  &  &  &  &  &  &  & 21 & \txgray{,060} & $-$~,417 &  &  & \\
Diff. der Anzahl \textbf{GR.8 „Falsches Verb“} & 18 & ,006 & \boxblue{$-$~,620} &  18 & \txgray{,051} & $-$~,466 &  &  &  &  &  & \\
Diff. der Anzahl \textbf{GR.10 „Wortstellungsfeh.“} & 18 & ,029 & \boxblue{$-$~,513}  &  &  &  &  &  &  & 19 & \txgray{,608} & $-$~,126\\
\midrule
\multicolumn{13}{l}{\textbf{Differenz CQ} \textbf{(nach KS $-$ vor KS)}}\\
Diff. der Anzahl \textbf{LX.4 „W. extra eingefügt“}  &  &  &  &  &  &  &  &  &  & 19 & ,006 & \boxblue{$-$~,605}\\
Diff. der Anzahl \textbf{GR.7 „Falsche Wortart“}  &  &  &  &  &  &  & 21 & ,018 & \boxblue{$-$~,511} &  &  & \\
Diff. der Anzahl \textbf{GR.8 „Falsches Verb“} & 18 & ,008 & \boxblue{$-$~,605}  & 18 & ,003 & \boxblue{$-$~,656} &  &  &  &  &  & \\
Diff. der Anzahl \textbf{GR.10 „Wortstellungsfeh.“} & 18 & \txgray{,054} & $-$~,461  &  &  &  &  &  &  & 19 & ,004 & \boxblue{$-$~,634}\\
\multicolumn{13}{l}{\textbf{Differenz Q} \textbf{(nach KS $-$ vor KS)}}\\
Diff. der Anzahl \textbf{LX.4 „W. extra eingefügt“}  &  &  &  &  &  &  &  &  &  & 19 & \txgray{,539} & $-$~,150\\
Diff. der Anzahl \textbf{GR.7 „Falsche Wortart“}  &  &  &  &  &  &  & 21 & ,018 & \boxblue{$-$~,509} &  &  & \\
Diff. der Anzahl \textbf{GR.8 „Falsches Verb“} & 18 & ,004 & \boxblue{$-$~,647}  & 18 & ,007 & \boxblue{$-$~,608} &  &  &  &  &  & \\
Diff. der Anzahl \textbf{GR.10 „Wortstellungsfeh.“} & 18 & ,030 & \boxblue{$-$~,512}  &  &  &  &  &  &  & 19 & ,007 & \boxblue{$-$~,601}\\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:71}„Passiversatz verm.“ -- Korrelationen zwischen den Fehlertypen und der Qualität bei den einzelnen MÜ-Systemen   }
\bspnote{*In der Tabelle werden nur die Fehlertypen dargestellt, die bei mind. einer Qualitätsvariable eine signifikante Korrelation aufweisen.
\begin{tabbing}
p: Signifikanz\hspace{2.5cm}\= \txgray{nicht signifikant (ρ ${\geq}$ 0,05)}\hspace{1cm}\= ρ: Korrelationskoeffizient\\
schwache Korrelation (ρ >=0,1)\> \txgreen{mittlere Korrelation (ρ >= 0,3)}\> \boxblue{starke Korrelation (ρ >= 0,5)}
\end{tabbing}}
\end{sidewaystable}

\subsubsection{\label{sec:5.3.7.5}Vergleich der MÜ-Qualität mit vs. ohne die Konstruktion „sein +~zu +~Infinitiv“ auf Annotationsgruppenebene}

Die Stil- und Inhaltsqualität\footnote{\textrm{Definitionen der Qualität unter \sectref{sec:4.4.5.1}.}} der MÜ stiegen in den Annotationsgruppen FF und FR. In der Annotationsgruppe RR stieg nur die Stilqualität, während die Inhaltsqualität unverändert blieb. In der Annotationsgruppe RF sanken beide Qualitätswerte. (siehe \figref{fig:05:109})


\begin{figure}
\includegraphics[width=\textwidth]{figures/d3-img091.png}
%\includegraphics[height=.3\textheight]{figures/d3-img035.png}\\
\caption{\label{fig:05:109}„Passiversatz verm.“ -- Mittelwerte der Qualität vor vs. nach KS auf Annotationsgruppenebene   }
\end{figure}

Nicht alle genannten Qualitätsveränderungen waren statistisch signifikant. \tabref{tab:05:72} zeigt die Signifikanz der Veränderungen der Qualitätswerte jeder Annotationsgruppe.


\begin{table}
\begin{tabularx}{\textwidth}{Xrrr}

\lsptoprule
& \textbf{N} & { \textbf{p}} & { \textbf{Z} }\\
& & \textbf{(Signifikanz)} & \textbf{(Teststatistik)}\\
\midrule
{\textbf{Annotationsgruppe FF}} & {} & {} & \\
\textbf{Differenz SQ (nach KS $-$ vor KS)} & 20 & ,003 & $-$ 3,021\\
\textbf{Differenz CQ (nach KS $-$ vor KS)} & 20 & \txgray{,136} & $-$~1,492\\
\textbf{Differenz allg. Q (nach KS $-$ vor KS)} & 20 & ,012 & $-$ 2,505\\
\midrule
{\textbf{Annotationsgruppe FR}} & {} & {} & \\
\textbf{Differenz SQ (nach KS $-$ vor KS)} & 27 & < ,001 & $-$ 4,463\\
  \textbf{Differenz CQ (nach KS $-$ vor KS)} & 27 & < ,001 & $-$ 4,544\\
\textbf{Differenz allg. Q (nach KS $-$ vor KS)} & 27 & < ,001 & $-$ 4,542\\
\midrule
{\textbf{Annotationsgruppe RF}} & {} & {} & \\
\textbf{Differenz SQ (nach KS $-$ vor KS)} & 13 & ,016 & $-$ 2,417\\
  \textbf{Differenz CQ (nach KS $-$ vor KS)} & 13 & ,007 & $-$ 2,680\\
\textbf{Differenz allg. Q (nach KS $-$ vor KS)} & 13 & ,001 & $-$ 3,192\\
\midrule
{\textbf{Annotationsgruppe RR}} & {} & {} & \\
\textbf{Differenz SQ (nach KS $-$ vor KS)} & 37 & < ,001 & $-$ 3,737\\
  \textbf{Differenz CQ (nach KS $-$ vor KS)} & 37 & \txgray{,522} & $-$~,640\\
   \textbf{Differenz allg. Q (nach KS $-$ vor KS)} & 37 & ,002 & $-$ 3,167\\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:72}„Passiversatz verm.“ -- Signifikanz der Qualitätsveränderung auf Annotationsgruppenebene   }
\end{table}

In der Gruppe FF (Übersetzung mit und ohne Passiversatz falsch) stieg die Stilqualität signifikant (z (N = 20) = $-$ 3,021 / p = ,003) und die Inhaltsqualität nicht signifikant (z (N = 20) = $-$~1,492 / p = ,136). Der Qualitätsanstieg in dieser Gruppe zeigt, dass die Bewerter die Fehler bei der Verwendung eines Passiversatzes (vor KS) schwerwiegender als die bei der Vermeidung eines Passiversatzes (nach KS) aufgetretenen Fehler wahrnahmen. Dieses Ergebnis wird außerdem durch den Analysefaktor 4 „Korrelation zwischen den Fehlertypen und der Qualität“ (\sectref{sec:5.3.7.4}) ersichtlich. \tabref{tabex:05:75} verdeutlicht diesen unterschiedlichen Schweregrad der aufgetretenen Fehler in den beiden Szenarien, vor vs. nach der Regelanwendung.


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & Ist ein mehrstufiges Modul parametriert, so \textbf{sind} die externen Kontakte \textbf{zu verriegeln}.\\
\tablevspace
HMÜ Bing & If a multi-stage module is parameterized, the external contacts \txred{are to lock}.\\
\midrule
\textbf{Nach-KS} & Ist ein mehrstufiges Modul parametriert, \textbf{verriegeln Sie} die externen Kontakte.\\
\tablevspace
HMÜ Bing & If a multi-stage module is parameterized, \txred{you} \txblue{lock} the external contacts.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:75}Beispiel 75   }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

Bei der Verwendung eines Passiversatzes (vor KS) trat der grammatische Fehler GR.8 „Falsches Verb“ (in ‚are to lock‘) auf. Die Bewerter fanden die Übersetzung irreführend und begründeten dies wie folgt: „\textquotesingle are to lock\textquotesingle\, sounds like the contacts will lock themselves. I suggest \textquotesingle are to be locked\textquotesingle\, instead”. Ein anderer Bewerter empfahl die Verwendung des Imperativs und kommentierte: „The text does not make clear that the reader should act at all“. Bei der Verwendung eines Imperativs (nach KS) trat der lexikalische Fehler LX.4 „Zusätzliches Wort eingefügt“ (in ‚you‘) auf. Die Bewerterkommentare zeigen, dass der Imperativ durch diesen Fehler nicht klar war und somit der Stil den Leser nicht adäquat zum Handeln anregen konnte. Ein Bewerterkommentar lautete „\textquotesingle you\textquotesingle\, should be deleted to keep the sentence in the imperative and motivate the user to act“. Durch die vergebenen Scores in den beiden Szenarien wird ersichtlich, dass die Bewerter den Fehlertyp im vor-KS-Szenario schwerwiegender als im nach-KS-Szenario empfanden, denn die Stil- und Inhaltsqualität stiegen nach~KS um +~0,25 Punkte bzw. +~1,50 Punkte auf der Likert-Skala.

Erwartungsgemäß nahmen die Stil- und Inhaltsqualität in der Gruppe FR (MÜ falsch vor KS; richtig nach KS) zu und sanken in der Gruppe RF (MÜ richtig vor KS; falsch nach KS) signifikant (siehe \tabref{tab:05:72}), wobei die Qualitätsdifferenz in der Gruppe FR deutlich höher (Diff\_SQ +~39,9~\%; Diff\_CQ +~48,0~\%) als in der Gruppe RF ausfiel (Diff\_SQ $-$ 8,2~\%; Diff\_CQ $-$ 9,7~\%). Gleichzeitig zeigte die Aufteilung der Annotationsgruppen (siehe \sectref{sec:5.3.7.2}), dass die Gruppe FR (28~\%) mehr als doppelt so häufig vertreten war als die Gruppe RF (13~\%), siehe \figref{fig:05:101}. Auf Basis dieses Vergleichs der Gruppen FR und RF lässt sich schlussfolgern, dass der potenzielle Qualitätsgewinn bei der Vermeidung eines Passiversatzes (Anwendung der KS-Regel) sehr hoch ausfällt.

In der Gruppe RR (Übersetzung mit und ohne Passiversatz richtig) stieg die Stilqualität signifikant (z (N = 37) = $-$ 3,737 / p < ,001), während die Inhaltsqualität unverändert blieb. Dieses Ergebnis ist nachvollziehbar, denn dank einer richtigen Übersetzung eines Passiversatzes (vor KS) oder eines Imperativs (nach KS) sind beide inhaltlich verständlich und präzise. Aus stilistischer Sicht fanden die Bewerter jedoch die Verwendung des Passiversatzes weniger geeignet für die Satzintention. \tabref{tabex:05:76} ist für einen Beispielsatz aus der Gruppe RR. Hierbei fanden die Bewerter den Stil bei der Verwendung des Imperativs (nach KS) geeigneter. Entsprechend stieg die Stilqualität um +~0,50 Punkte auf der Likert-Skala, während die Inhaltsqualität unverändert blieb.


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & Das Kaufdatum \textbf{ist} durch eine Kaufquittung \textbf{zu belegen}.\\
\tablevspace
GNMÜ & The purchase date \txblue{is to be confirmed} by a purchase receipt.\\
\midrule
\textbf{Nach-KS} & \textbf{Belegen Sie} das Kaufdatum durch eine Kaufquittung.\\
\tablevspace
GNMÜ & \textcolor{tmnlpthree}{Confirm} the purchase date with a purchase receipt.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:76}Beispiel 76   }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

\subsubsection{\label{sec:5.3.7.6}Vergleich der AEM-Scores mit vs. ohne die Konstruktion „sein + zu +~Infinitiv“ sowie die Korrelation zwischen den AEM-Scores und der Qualität}

Der Vergleich der AEM-Scores mit und ohne Verwendung des Passiversatzes zeigte sowohl mit TERbase als auch mit hLEPOR eine deutliche Verbesserung der AEM-Scores.


\begin{figure}
%\includegraphics[height=.3\textheight]{figures/d3-img022.png}




%\includegraphics[height=.3\textheight]{figures/d3-img022.png}


%\includegraphics[height=.3\textheight]{figures/d3-img022.png}
\includegraphics[width=.4\textwidth]{figures/Abb110.png}
\includegraphics[width=.35\textwidth]{figures/Abb19-legend.png}
\caption{\label{fig:05:110}„Passiversatz verm.“ -- Mittelwert der Differenz der AEM-Scores   }
\bspnote{Differenz = AEM-Score nach KS \textit{minus} AEM-Score vor KS}
\end{figure}

Der Mittelwert der Differenz (nach KS $-$ vor KS) im AEM-Score pro Satz lag für TERbase bei ,112 (SD = ,248) und für die hLEPOR bei ,051 (SD = ,152) mit einem 95\%-Konfidenzintervall (Bootstrapping mit 1000 Stichproben), siehe \figref{fig:05:110}. Die Differenzen (nach KS $-$ vor KS) in TERbase und hLEPOR erwiesen sich als signifikant (z (N = 97) = $-$~4,175 / p < ,001) bzw. (z (N = 97) = $-$ 3,396 / p = ,001). Dieses Ergebnis deutet darauf hin, dass nach der Verwendung des Imperativs (nach KS) weniger Edits erforderlich waren.

\subsubsubsection{Korrelation zwischen den Differenzen in den AEM-Scores und der Qualität}

Nach der Anwendung der KS-Regel stieg die Qualität signifikant (siehe \sectref{sec:5.3.7.4}). Mithilfe des Spearman-Korrelationstests erwies sich ein signifikanter mittlerer positiver Zusammenhang zwischen den Differenzen der AEM-Scores von TERbase und hLEPOR und der Differenz der allgemeinen Qualität. Nach der Verwendung des Imperativs anstelle des Passiversatzes (nach KS) verbesserten sich die Scores der beiden AEM-Score-Metriken und die Qualität nahm zu.


\begin{table}
\begin{tabularx}{\textwidth}{Xrrrr}

\lsptoprule
& \textbf{N} & { \textbf{Signifikanz}} & \textbf{Korrelations-} & \textbf{Stärke}\\
& & \textbf{(p)} & \textbf{koeffizient} & \textbf{der}\\
& & & \textbf{(ρ)} &  \textbf{Korrelation}\\
\midrule
Korrelation zw. Differenz in der allg. Qualität und Differenz des TERbase-Scores (nach KS $-$ vor KS) & { 97} & ,002 & ,311 & \makecell[tr]{mittlerer\\Zusammen-\\hang}\\
\tablevspace
Korrelation zw. Differenz in der allg. Qualität und Differenz des hLEPOR-Scores (nach KS $-$ vor KS) & 97 & < ,001 & ,473 & \makecell[tr]{mittlerer\\Zusammen-\\hang}\\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:73}„Passiversatz verm.“ -- Korrelation zwischen den Differenzen der AEM-Scores und den Qualitätsdifferenzen   }
\bspnote{{ schwache Korrelation (ρ >=0,1)}\hspace{1em}{ mittlere Korrelation (ρ >= 0,3)}\hspace{1em} starke Korrelation (ρ >= 0,5)}
\end{table}

\subsubsection{\label{sec:5.3.7.7}Analyse der siebten Regel -- Validierung der Hypothesen}

Um die vorgestellten Ergebnisse auf die Forschungsfragen der Studie zurückzuführen, listet dieser Abschnitt die zugrunde liegenden Hypothesen der Forschungsfragen zusammen mit einer Zusammenfassung der Ergebnisse der siebten analysierten Regel in tabellarischer Form auf. Für einen schnelleren Überblick steht (+) für eine Verbesserung bzw. einen Anstieg z.~B. im Sinne eines Qualitätsanstiegs, verbesserter AEM-Scores oder eines Anstiegs der Fehleranzahl; ($-$) steht für einen Rückgang; die \txgreen{grüne} Farbe symbolisiert eine signifikante Veränderung; \textit{neg} steht für eine negative Korrelation und \textit{pos} für eine positive Korrelation; <{}<{}>{}> steht für eine starke Korrelation und <> für eine mittlere Korrelation.\footnote{\textrm{Schwache Korrelationen werden in dieser Übersicht nicht angezeigt.}}

\subsubsubsection*{\textbf{Regel 7: Konstruktionen mit „sein + zu +~Infinitiv“ vermeiden}}

\paragraph*{Erster Analysefaktor: Vergleich der Fehleranzahl mit vs. ohne die Konstruktion „sein + zu +~Infinitiv“}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Gibt es einen Unterschied in der Fehleranzahl nach der Anwendung der KS-Regel im Vergleich zu vor der Anwendung?
\item [H0 --] Es gibt keinen Unterschied in der Fehleranzahl vor vs. nach der Anwendung der KS-Regel.
\item [H1 --] Es gibt einen Unterschied in der Fehleranzahl vor vs. nach der Anwendung der KS-Regel.
\item [Resultat]
\end{description}
\noindent
\parbox[t]{.8\textwidth}{\textbf{Auf Regelebene:}}\\
\parbox[t]{.8\textwidth}{
H0 wurde abgelehnt und somit H1 bestätigt.

Die Fehleranzahl sank signifikant, nachdem die Passiversatzkonstruktion als Imperativ umformuliert wurde.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.15\textwidth}{
{ \textbf{Anz.F.}} \textbf{($-$)}\\
\\
}}

\noindent
\parbox[t]{.8\textwidth}{\textbf{Auf Regel- und MÜ-Systemebene:}}\\
\parbox[t]{.8\textwidth}{
Bei Bing und SDL sank die Fehleranzahl nach KS signifikant.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.15\textwidth}{
\textbf{Bi ($-$)}

 \textbf{SD ($-$)}
}}

\medskip
\noindent
\parbox[t]{.8\textwidth}{
Bei Lucy und Systran stieg die Fehleranzahl nach KS signifikant.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.15\textwidth}{
{ \textbf{Lu (+)}}

\textbf{Sy (+)}
}}

\medskip
\noindent
\parbox[t]{.8\textwidth}{
Bei Google gab es nur einen Fehler bei jedem Szenario.
}
\parbox[t]{.04\textwidth}{}
\parbox[t]{.15\textwidth}{
\textbf{Go (=)}
}

\hrule
\paragraph*{Zweiter Analysefaktor}\hfill\\
\begin{figure}
% 101
\torte{25}{33}{15}{47}
\caption{Aufteilung der Annotationsgruppen auf Regelebene}
\end{figure}

\begin{figure}
\begin{tikzpicture}
\tikzset{every node/.style={font=\scriptsize}};
	\begin{axis}[
	ybar,
	width = \textwidth,
  height = .5\textheight,
	axis lines* = left,
	ylabel = {\%},
	xtick = {3,9,15,21},
	xticklabels = {FF,FR,RF,RR},
  x tick label style ={yshift=-5pt},
	xtick=data,
  xlabel={Annotationsgruppe},
	ymin=0,
	ymax = 20,
  y filter/.code={\pgfmathparse{#1/120*100}\pgfmathresult},
%	bar shift = 0pt,
  bar width=9,
  enlarge x limits = .2,
%	nodes near coords,
%	legend pos= north east,
	legend style={at={(0.5,-0.15)},anchor=north},
	legend columns = {-1},
	]
	\addplot+[lsNightBlue]
	coordinates {
	(3,3)
	(9,17)
	(15,1)
	(21,3)
	};
	\addplot+[tmnlpone]
	coordinates {
	(3,1)
	(9,0)
	(15,0)
	(21,23)
	};
	\addplot+[tmnlptwo]
	coordinates {
	(3,8)
	(9,1)
	(15,8)
	(21,7)
	};
	\addplot+[tmnlpthree]
	coordinates {
	(3,6)
	(9,14)
	(15,0)
	(21,4)
	};
	\addplot+[tmnlpfour]
	coordinates {
	(3,7)
	(9,1)
	(15,6)
	(21,10)
	};
	\legend{Bing,Google,Lucy,SDL,Systran}
	\end{axis}
\end{tikzpicture}
\caption{Aufteilung der Annotationsgruppen auf Regel- und MÜ-Systemebene}
\end{figure}

\hrule
\paragraph*{Dritter Analysefaktor: Vergleich der Fehlertypen mit vs. ohne die Konstruktion „sein +~zu +~Infinitiv“}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Beinhaltet die MÜ bestimmte Fehlertypen vor bzw. nach der Anwendung der KS-Regel?
\item [H0 --] Es gibt keinen Unterschied in der Häufigkeit der einzelnen Fehlertypen vor vs. nach der Anwendung der KS-Regel.
\item [H1 --] Es gibt einen Unterschied in der Häufigkeit der einzelnen Fehlertypen vor vs. nach der Anwendung der KS-Regel.
\item [Resultat]
\end{description}
\noindent
\parbox[t]{.8\textwidth}{\textbf{Auf Regelebene:}}\\
\parbox[t]{.8\textwidth}{
H1 wurde für vier Fehlertypen bestätigt.

Die Fehleranzahl von LX.4 „Zusätzliches Wort eingefügt“ stieg signifikant.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.15\textwidth}{
\textbf{LX.4 (+)}\\
\\
}}

\medskip
\noindent
\parbox[t]{.8\textwidth}{
Die Fehleranzahl von GR.8 „Falsches Verb“, GR.9 „Kongruenzfehler“ und GR.10 „Wortstellungsfehler“ sanken nach KS signifikant.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.15\textwidth}{
{ \textbf{GR.8 ($-$)} }

{ \textbf{GR.9 ($-$)}}

 \textbf{GR.10 ($-$)}
}}

\noindent
\parbox[t]{.8\textwidth}{\textbf{Auf Regel- und MÜ-Systemebene:}}\\
\parbox[t]{.8\textwidth}{
Bei Lucy und Systran stieg die Fehleranzahl von LX.4 „Zusätzliches Wort eingefügt“ nach KS signifikant.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.15\textwidth}{
{ \textbf{LX.4 (+):}}

{ \textbf{Lu}} \textbf{Sy}
}}

\medskip
\noindent
\parbox[t]{.8\textwidth}{
Bei Bing und SDL sank die Fehleranzahl von GR.8 „Falsches Verb“ nach KS signifikant.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.15\textwidth}{
{ \textbf{GR.8 ($-$):}}

{ \textbf{Bi}} \textbf{SD}
}}

\medskip
\noindent
\parbox[t]{.8\textwidth}{
Bei SDL sank die Fehleranzahl von GR.10 „Wortstellungsfehler“ nach KS signifikant.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.15\textwidth}{
{ \textbf{GR.10 ($-$):}}

\textbf{SD}
}}

\medskip
\noindent
\parbox[t]{.8\textwidth}{
Alle weiteren Veränderungen waren nicht signifikant.
}

\hrule
\paragraph*{Vierter Analysefaktor: Vergleich der MÜ-Qualität mit vs. ohne die Konstruktion „sein +~zu +~Infinitiv“}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Gibt es einen Unterschied in der Stil- und Inhaltsqualität der MÜ der KS-Stelle nach der Anwendung der KS-Regel im Vergleich zu vor der Anwendung?
\item [H0 --] Es gibt keinen Qualitätsunterschied vor vs. nach der Anwendung der KS-Regel.
\item [H1 --] Es gibt einen Qualitätsunterschied vor vs. nach der Anwendung der KS-Regel.
\item [Resultat]
\end{description}
\noindent
\parbox[t]{.75\textwidth}{\textbf{Auf Regelebene:}}\\
\parbox[t]{.75\textwidth}{
H0 wurde abgelehnt und somit H1 bestätigt.

Sowohl die Stil- als auch die Inhaltsqualität stiegen signifikant nach Verwendung des Imperativs (nach KS).
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.2\textwidth}{
{ \textbf{SQ (+)}}

 \textbf{CQ (+)}\\
}}

\noindent
\parbox[t]{.75\textwidth}{\textbf{Auf Regel- und MÜ-Systemebene:}}\\
\parbox[t]{.75\textwidth}{
Die Stil- und Inhaltsqualität stiegen bei Bing, und SDL signifikant, wobei bei Systran nur die Stilqualität signifikant zunahm.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.09\textwidth}{
{ \textbf{SQ (+):}}

{ \textbf{Bi}}{ \textbf{SD}}\\\textbf{Sy}
}}
\colorbox{smGreen}{\parbox[t]{.09\textwidth}{{ \textbf{CQ (+):}}

{ \textbf{Bi}}

\textbf{SD}
\vspace{2.5pt}
}}

\medskip
\noindent
\parbox[t]{.75\textwidth}{
Alle weiteren Qualitätsveränderungen waren nicht signifikant.
}
\smallskip
\hrule
\paragraph*{Fünfter Analysefaktor: Korrelation zwischen den Fehlertypen und der Qualität}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Besteht ein Zusammenhang zwischen der Differenz der Fehleranzahl eines bestimmten Fehlertyps (Fehleranzahl nach KS $-$ vor KS) und der Differenz der Stil- bzw. Inhaltsqualität (Qualität nach KS $-$ vor KS)?
\item [H0 --] Es besteht kein Zusammenhang zwischen der Differenz der Fehleranzahl eines bestimmten Fehlertyps und der Differenz der Stil- bzw. Inhaltsqualität.
\item [H1 --] Es besteht ein Zusammenhang zwischen der Differenz der Fehleranzahl eines bestimmten Fehlertyps und der Differenz der Stil- bzw. Inhaltsqualität.
\item [Resultat]
\end{description}
\noindent
\parbox[t]{.7\textwidth}{\textbf{Auf Regelebene:}}\\
\parbox[t]{.7\textwidth}{
H1 wurde für drei Fehlertypen bestätigt.

Es bestand ein signifikanter starker negativer Zusammenhang zwischen der Differenz der Fehleranzahl des GR.8 „Falsches Verb“ und der Differenz der Stil- und Inhaltsqualität.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.25\textwidth}{
{ \textbf{\textit{neg}} \textbf{GR.8 <{}<{}>{}> SQ}}

 \textbf{\textit{neg}} \textbf{GR.8 <{}<{}>{}> CQ}\\
 \\
 \\
}}

\medskip
\noindent
\parbox[t]{.7\textwidth}{
Es bestand ein signifikanter mittlerer negativer Zusammenhang zwischen der Differenz der Fehleranzahl des LX.4 „Zusätzliches Wort eingefügt“ und der Differenz der Stilqualität
sowie ein signifikanter mittlerer negativer Zusammenhang zwischen der Differenz der Fehleranzahl des GR.10 „Wortstellungsfehler“ und der Differenz der Stil- und Inhaltsqualität.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.25\textwidth}{
{ \textbf{\textit{neg}} \textbf{LX.4 <> SQ}}\\

{ \textbf{\textit{neg}} \textbf{GR.10 <> SQ}}

 \textbf{\textit{neg}} \textbf{GR.10 <> CQ}\\
 \\
 \\
}}

\noindent
\parbox[t]{.7\textwidth}{\textbf{Auf Regel- und MÜ-Systemebene:}}\\
\parbox[t]{.7\textwidth}{
Bei Bing bestand ein signifikanter starker negativer Zusammenhang zwischen der Differenz der Fehleranzahl des GR.8 „Falsches Verb“ und der Differenz der Stil- und Inhaltsqualität
sowie ein signifikanter starker negativer Zusammenhang zwischen der Differenz der Fehleranzahl des GR.10 „Wortstellungsfehler“ und der Differenz der Stilqualität.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.25\textwidth}{
{ \textbf{Bi}}

{ \textbf{\textit{neg}} \textbf{GR.8 <{}<{}>{}> SQ}}

{ \textbf{\textit{neg}} \textbf{GR.8 <{}<{}>{}> CQ}}

{ \textbf{\textit{neg}} \textbf{GR.10 <{}<{}>{}> SQ}}\\
\\
\\
}}

\medskip
\noindent
\parbox[t]{.7\textwidth}{
Bei Lucy bestand ein signifikanter \textit{starker} negativer Zusammenhang zwischen der Differenz der Fehleranzahl des GR.8 „Falsches Verb“ und der Differenz der Inhaltsqualität.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.25\textwidth}{
{ \textbf{Lu}}

{ \textbf{\textit{neg}} \textbf{GR.8 <{}<{}>{}> CQ}}\\
\\
}}

\medskip
\noindent
\parbox[t]{.7\textwidth}{
Bei SDL bestand ein signifikanter starker negativer Zusammenhang zwischen der Differenz der Fehleranzahl des GR.7 „Falsche Wortart“ und der Differenz der Inhaltsqualität.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.25\textwidth}{
{ \textbf{SD}}

{ \textbf{\textit{neg}} \textbf{GR.7 <{}<{}>{}> CQ}}\\
\\
}}

\medskip
\noindent
\parbox[t]{.7\textwidth}{
Bei Systran bestand ein signifikanter starker negativer Zusammenhang zwischen der Differenz der Fehleranzahl des LX.4 „Zusätzliches Wort eingefügt“ und der Differenz der Stil- und Inhaltsqualität
sowie ein signifikanter starker negativer Zusammenhang zwischen der Differenz der Fehleranzahl des GR.10 „Wortstellungsfehler“ und der Differenz der Inhaltsqualität.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.25\textwidth}{
{ \textbf{Sy}}

{ \textbf{\textit{neg}} \textbf{LX.4 <{}<{}>{}> SQ}}

{ \textbf{\textit{neg}} \textbf{LX.4 <{}<{}>{}> CQ}}

{ \textbf{\textit{neg}} \textbf{GR.10 <{}<{}>{}> CQ}}\\
\\
\\
}}

\medskip
\noindent
\parbox[t]{.7\textwidth}{
Alle weiteren Korrelationen waren nicht signifikant.
}

\hrule
\paragraph*{Sechster Analysefaktor: Vergleich der MÜ-Qualität mit vs. ohne die Konstruktion „sein +~zu +~Infinitiv“ auf Annotationsgruppenebene}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Gibt es einen Unterschied in der Stil- und Inhaltsqualität bei den einzelnen Annotationsgruppen nach der Anwendung der KS-Regel im Vergleich zu vor der Anwendung?
\item [H0 --] Bei den Annotationsgruppen gibt es keinen Qualitätsunterschied vor vs. nach der Anwendung der KS-Regel.
\item [H1 --] Bei den Annotationsgruppen gibt es einen Qualitätsunterschied vor vs. nach der Anwendung der KS-Regel.
\item [Resultat]
\end{description}
\noindent
\parbox[t]{.8\textwidth}{H1 wurde nur zum Teil bestätigt:}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.15\textwidth}{
\textbf{SQ (+)}
}}

%\medskip
\noindent
\parbox[t]{.8\textwidth}{
Bei der Annotationsgruppe FF stieg die Stilqualität signifikant und die Inhaltsqualität nicht signifikant.
}
\parbox[t]{.04\textwidth}{}
\parbox[t]{.15\textwidth}{
 \textbf{CQ (+)}
}

\medskip
\noindent
\parbox[t]{.8\textwidth}{
Bei der Annotationsgruppe FR stiegen die Stil- und Inhaltsqualität signifikant.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.15\textwidth}{
{ \textbf{SQ (+)}}

\textbf{CQ (+)}
}}

\medskip
\noindent
\parbox[t]{.8\textwidth}{
Bei der Annotationsgruppe RF sanken die Stil- und Inhaltsqualität signifikant.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.15\textwidth}{
{ \textbf{SQ ($-$)}}

\textbf{CQ ($-$)}
}}

\medskip
\noindent
\parbox[t]{.8\textwidth}{
Bei der Annotationsgruppe RR stieg die Stilqualität signifikant
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.15\textwidth}{
\textbf{SQ (+)}
}}

%\medskip
\noindent
\parbox[t]{.8\textwidth}{
und die Inhaltsqualität blieb unverändert.
}
\parbox[t]{.04\textwidth}{}
\parbox[t]{.15\textwidth}{
\textbf{CQ (=)}
}

\hrule
\paragraph*{Siebter Analysefaktor: Vergleich der AEM-Scores mit vs. ohne die Konstruktion „sein +~zu +~Infinitiv“ auf Annotationsgruppenebene}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Gibt es einen Unterschied in den AEM-Scores von TERbase bzw. hLEPOR nach der Anwendung der KS-Regel im Vergleich zu vor der Anwendung?
\item [H0 --] Es gibt keinen Unterschied in den AEM-Scores vor vs. nach der Anwendung der KS-Regel.
\item [H1 --] Es gibt einen Unterschied in den AEM-Scores vor vs. nach der Anwendung der KS-Regel.
\item [Resultat]
\end{description}
\noindent
\parbox[t]{.75\textwidth}{
H0 wurde abgelehnt und somit H1 bestätigt.

AEM-Scores sowohl von TERbase als auch von hLEPOR verbesserten sich nach Verwendung des Imperativs (nach KS) signifikant.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.2\textwidth}{
{ \textbf{TERbase (+)}}

 \textbf{hLEPOR (+)}\\
 \\
}}

\hrule
\paragraph*{Achter Analysefaktor: Korrelation zwischen den Differenzen der AEM-Scores und der Qualität}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Besteht ein Zusammenhang zwischen der Differenz der AEM-Scores von TERbase bzw. hLEPOR (Mittelwert der AEM-Scores nach KS $-$ vor KS) und der Differenz der allgemeinen Qualität (Qualität nach KS $-$ vor KS)?
\item [H0 --] Es besteht kein Zusammenhang zwischen der Differenz der AEM-Scores und der Differenz der allgemeinen Qualität.
\item [H1 --] Es besteht ein Zusammenhang zwischen der Differenz der AEM-Scores und der Differenz der allgemeinen Qualität.
\item [Resultat]
\end{description}
\noindent
\parbox[t]{.7\textwidth}{
H0 wurde abgelehnt und somit H1 bestätigt.

Es bestand ein signifikanter mittlerer positiver Zusammenhang zwischen der Differenz der AEM-Scores von TERbase und hLEPOR und der Differenz der allgemeinen Qualität.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.25\textwidth}{
{ \textbf{\textit{pos}} \textbf{TERbase <> Q}}

 \textbf{\textit{pos}} \textbf{hLEPOR <> Q}\\
 \\
 \\
}}





\subsection{ACHTE REGEL: Überflüssige Präfixe vermeiden}
\label{sec:5.3.8}
 \subsubsection{\label{sec:5.3.8.0}Überblick}

%In \tabref{tab:05:74}
Im Folgenden wird die KS-Regel „Überflüssige Präfixe vermeiden“ kurz beschrieben.\footnote{\textrm{Die für diese Regel relevanten Kontraste im Sprachenpaar DE-EN sind unter \sectref{sec:4.4.2.3} erörtert.} } Zudem wird zusammenfassend und anhand von Beispielen demonstriert, wie die Regel bei der Analyse angewendet wurde. Anschließend wird die Aufteilung der Testsätze im Datensatz dargestellt:

\begin{description}[font=\normalfont\bfseries]
\item [Beschreibung der KS-Regel:] \textbf{Überflüssige Präfixe vermeiden} (tekom-Regel-Nr. L 114)

Nach dieser Regel sollen Verben mit Präfixen vermieden werden, wenn das Verb ohne Präfix die gleiche Bedeutung hat (\citealt{tekom2013}: 111).

Begründung: Die Kürzung vereinfacht den Satz und reduziert Segmentvarianten bei der Übersetzung mithilfe eines Systems (ebd.).

\item[Umsetzungsmuster:]
~\\
\textbf{Vor KS:} Verb mit Präfix\\
\textbf{Nach KS:} Eliminierung des Präfixes

\item[KS-Stelle]
~\\
\textbf{Vor KS:} Verb mit Präfix (trennbare und untrennbare Verben)\\
\textbf{Nach KS:} Verb ohne Präfix

\item[Beispiele]
~\\
\textit{\txgray{Überprüfen} Sie, ob ausreichend Wasser im Wassertank vorhanden ist.}

\textit{\txgray{Prüfen} Sie, ob ausreichend Wasser im Wassertank vorhanden ist.}
~\\
\textit{\txgray{Wählen} Sie die Option $"$Software von einer bestimmten Liste installieren$"$ \txgray{aus}.}

\textit{\txgray{Wählen} Sie die Option $"$Software von einer bestimmten Liste installieren$"$.}

\item[Aufteilung der Testsätze:]
Die Platzierung des Präfixes bei trennbaren Verben kann den Schwierigkeitsgrad bzw. die Richtigkeit der Übersetzung beeinflussen, daher deckt der Datensatz Folgendes ab: 15 Sätze, in denen das Präfix getrennt am Satzende bzw. Nebensatzende erscheint sowie 9 Sätze mit untrennbaren Verben oder trennbaren Verben, in denen das Präfix ungetrennt vom Verb auftritt.

\end{description}

%\multicolumn{2}{p{6cm}}{\label{bkm:Ref36850581}Eckdaten der achten Regel „Überflüssige Präfixe vermeiden“}\\
%\end{tabularx}\caption{\label{tab:05:74}   }

Im Folgenden werden die Ergebnisse der einzelnen Analysefaktoren dargestellt.

\subsubsection{\label{sec:5.3.8.1}Vergleich der Fehleranzahl mit vs. ohne überflüssige Präfixe}

Die Fehleranzahl sank deutlich um 35,5~\% von 45 Fehlern bei der Verwendung von überflüssigen Präfixen (M = ,38 / SD = ,649 / N = 120) auf 29 Fehler bei der Vermeidung von überflüssigen Präfixen (M = ,24 / SD = ,550 / N = 120), siehe \figref{fig:05:111}. Der Mittelwert der Differenz (nach KS $-$ vor KS) der Fehleranzahl pro Satz lag somit bei $-$~,13 (SD = ,517) mit einem 95\%\nobreakdash-Konfidenzintervall zwischen einem Minimum von $-$~,23 (SD = ,401) und einem Maximum von $-$~,04 (SD = ,637) (Bootstrapping mit 1000 Stichproben), siehe \figref{fig:05:112}. Die Differenz (nach KS $-$ vor KS) der Fehleranzahl erwies sich als signifikant (z (N = 120) = $-$ 2,717 / p = ,007).


\begin{figure}
%\includegraphics[height=.3\textheight]{figures/d3-img023.png}



%\includegraphics[height=.3\textheight]{figures/d3-img023.png}



%\includegraphics[height=.3\textheight]{figures/d3-img023.png} &  & \textbf{,15,35}

%\textbf{,26,50}



%\includegraphics[height=.3\textheight]{figures/d3-img024.png}



%\includegraphics[height=.3\textheight]{figures/d3-img024.png}



%\includegraphics[height=.3\textheight]{figures/d3-img024.png}\\
\captionsetup{width=.45\textwidth}
\begin{floatrow}
\ffigbox[.5\textwidth]{\caption{„Überfl. Präfixe verm.“ -- Fehlersumme vor vs. nach KS}
\label{fig:05:111}}{
\begin{tikzpicture}
	\begin{axis}[
	ybar,
	ymin = 0,
	ymax = 125,
	axis lines* = left,
	nodes near coords,
%         nodes near coords align = vertical,
  legend style={at={(0.5,-0.2)},anchor=north,cells={align=left}},
  xtick=\empty,
  width = .45\textwidth,
  enlarge x limits = .5
	]
	\addplot+[tmnlpone]
	coordinates{
	(1,45)
	};
	\addplot+[tmnlpthree]
	coordinates{
	(2,29)
	};
	\legend{Anzahl der  fehler\\innerh. KS vor KS,Anzahl der Fehler\\innerh. KS nach KS}
	\end{axis}
\end{tikzpicture}
}
\ffigbox[.45\textwidth]{\caption{„Überfl. Präfixe verm.“ -- Mittelwert der Fehleranzahl pro Satz vor vs. nach KS}\label{fig:05:112}}{
\includegraphics[width=.25\textwidth]{figures/Abb112.png}
\includegraphics[width=.4\textwidth]{figures/Abb21-legend.png}
}
\end{floatrow}
\end{figure}

Insbesondere trennbare Verben waren oft schwer zu parsen; abhängig von der Satzstruktur stehen die Präfixe in manchen Fällen am Ende des Satzes -- weit entfernt vom Rest des Verbs. In solchen Fällen konnten mehrere Systeme den Satz zwar korrekt übersetzen, fügten aber am Satzende eine redundante Übersetzung für das Präfix hinzu. In \tabref{tabex:05:77} wurde ‚too‘ als Übersetzung von ‚zu‘ im Verb ‚zuschicken‘ zusätzlich hinzugefügt.


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & \textbf{Schicken} Sie das Gerät zusammen mit dem Original-Kaufbeleg an nachstehende Adresse \textbf{zu}.\\
\tablevspace
HMÜ Systran & \textcolor{tmnlpthree}{Send} the appliance together with the original receipt to the following address \txred{too}.\\
\midrule
\textbf{Nach-KS} & \textbf{Schicken} Sie das Gerät zusammen mit dem Original-Kaufbeleg an nachstehende Adresse.\\
\tablevspace
HMÜ Systran & \textcolor{tmnlpthree}{Send} the appliance together with the original receipt to the following address.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:77}Beispiel 77   }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

Daher war die Anwendung der Regel in dieser Hinsicht sinnvoll. Rund 59~\% (14 von 24) der analysierten Sätze wurden vor der Regelanwendung von mindestens einem MÜ-System falsch übersetzt und mithilfe der Regel korrigiert.

\subsubsubsection{Vergleich der Fehleranzahl auf Regel- und MÜ-Systemebene}

Die Fehleranzahl nach der Umsetzung der KS-Regel sank bei allen Systemen (\figref{fig:05:113}): Im Allgemeinen war die Fehleranzahl relativ klein im Vergleich zu den anderen Regeln.


\begin{figure}
%\textbf{$-$ 63,6~\%}

%\textbf{\textit{$-$ 41,2~\%}}

%\textbf{$-$ 52,2~\%}

%\textbf{$-$ 64,0~\%}{}
%\includegraphics[height=.3\textheight]{figures/d3-img093.png}


%\textbf{$-$ 66,7~\%}
%\includegraphics[height=.3\textheight]{figures/d3-img023.png}\\
\begin{tikzpicture}
	\begin{axis}[
	ybar,
	ymin = 0,
	ymax = 12,
	axis lines* = left,
	nodes near coords,
  legend style={at={(0.5,-0.2)},anchor=north},
  xticklabels = {Bing,Google,Lucy,SDL,Systran},
  xtick=data,
  ylabel = {Summe},
  extra description/.code={
            \node at (axis cs:-.4, 12)[anchor=west] {\bfitul{$-$ 41,2 \%}};
						\node at (axis cs:.5, 6)[anchor=west] {$-$ 66,7\%};
						\node at (axis cs:1.5, 13)[anchor=west] {$-$ 63,6 \%};
						\node at (axis cs:2.5, 14)[anchor=west] {$-$ 64,0 \%};
						\node at (axis cs:3.5, 10)[anchor=west] {$-$ 52,2 \%};
						}
	]
	\addplot+[tmnlpone]
	coordinates{
	(0,10)
	(1,4)
	(2,11)
	(3,12)
	(4,8)
	};
	\addplot+[tmnlpthree]
	coordinates{
	(0,3)
	(1,3)
	(2,7)
	(3,11)
	(4,5)
	};
	\legend{Anzahl der  fehler innerh. KS vor KS,Anzahl der Fehler innerh. KS nach KS}
	\end{axis}
\end{tikzpicture}
\caption{\label{fig:05:113}„Überfl. Präfixe verm.“ -- Summe der Fehleranzahl vor vs. nach KS bei den einzelnen MÜ-Systemen   }
\bspnote{\bfitul{Signifikante Differenz vor vs. nach KS}}
\end{figure}

Signifikant war nur der Rückgang bei dem HMÜ-System Bing Mdiff = -~0,292; z (N = 24) = $-$ 2,070 / p = ,038), siehe \figref{fig:05:113}. Bei den restlichen Systemen betrug der Mittelwert der Differenz in der Fehleranzahl (nach KS $-$ vor KS): HMÜ-System Systran (Mdiff = $-$~,125); RBMÜ-System Lucy (Mdiff = $-$~,167); NMÜ-System Google Translate (Mdiff = $-$~,042); SMÜ-System SDL (Mdiff = $-$~,042). Im Vergleich zu Systran in \tabref{tabex:05:77} konnten SDL und Google Translate beide Szenarien fehlerfrei und identisch (als ‚Check if there is sufficient water in the water tank‘) übersetzen. In den nächsten Abschnitten werden die aufgetretenen Fehlertypen sowie die Aufteilung der Annotationsgruppen näher erläutert.

\subsubsection{\label{sec:5.3.8.2}Aufteilung der Annotationsgruppen}

Die größte Annotationsgruppe stellte die Gruppe RR dar; die MÜ-Systeme konnten mehr als zwei Drittel der Sätze sowohl mit als auch ohne die überflüssigen Präfixe fehlerfrei übersetzen (\figref{fig:05:114}). An der zweiten Stelle kommt die Gruppe FF, die relativ klein war (ca. 16~\%). Die Gruppe FR (ca. 13~\%) zeigt, dass die Regel die MÜ-Systeme dabei unterstützen konnte, aufgetretene Fehler zu beheben. Zum Schluss folgt die Gruppe RF mit einem sehr kleinen Anteil von ca. 3~\% (\figref{fig:05:114}).


\begin{figure}
%\includegraphics[height=.3\textheight]{figures/d3-img094.png}

%\includegraphics[height=.3\textheight]{figures/d3-img012.png}
%114
\torte[pin]{19}{16}{4}{81}
\caption{\label{fig:05:114}„Überfl. Präfixe verm.“ -- Aufteilung der Annotationsgruppen   }
\end{figure}

Eine genaue Betrachtung der produzierten MÜ zusammen mit der Gruppenaufteilung zeigt, dass (1) die meisten Sätze der Gruppe RR identisch übersetzt wurden. (2) Vergleicht man die Gruppen FR vs. RF, so kann man argumentieren, dass diese Regel überwiegend hilfreich war. Insbesondere bei den Präfix-Verb-getrennten Fällen konnte die Regel dazu beitragen, MÜ-Fehler zu beheben; so bestand die FR-Gruppe (vor KS) aus 13 Präfix-Verb-getrennten Fällen und 3 Präfix-Verb-ungetrennten Fällen (d. h. Fälle mit untrennbaren Verben oder mit trennbaren Verben, die aber ungetrennt vom Präfix im Satz auftraten).

\subsubsubsection{Vergleich der Aufteilung der Annotationsgruppen auf Regel- und MÜ-Systemebene}

Unter allen analysierten KS-Regeln kommt die Regel „Überflüssige Präfixe vermeiden“ auf Platz eins mit den größten Prozentsätzen für die Gruppe RR bei allen Systemen. Unter den MÜ-Systemen waren 88~\% der Übersetzungen von dem NMÜ-System Google Translate richtig sowohl mit als auch ohne die Verwendung der Präfixe. Diesem Ergebnis folgen das HMÜ-System Bing mit 71~\%; das HMÜ-System Systran mit 67~\%; das SMÜ-System SDL mit 63~\% und zum Schluss das RBMÜ-System Lucy mit 50~\%. Somit war die Gruppe RR die dominanteste Annotationsgruppe unter allen MÜ-Systemen. (siehe \figref{fig:05:115})


\begin{figure}

%    \textbf{13\% 13\% 17\% 25\%}  \textbf{13\%}            \textbf{17\%}          \textbf{25\%}  \textbf{8\%}   \textbf{17\%}                              \textbf{8\%}   \textbf{4\%}    \textbf{4\%}             \textbf{71\%}  \textbf{88\% 50\% 63\%}  \textbf{67\%}
%\includegraphics[height=.3\textheight]{figures/d3-img095.png}
%\includegraphics[height=.3\textheight]{figures/d3-img026.png}\\
\begin{tikzpicture}
\tikzset{every node/.style={font=\scriptsize}};
	\begin{axis}[
	ybar,
	width = \textwidth,
	axis lines* = left,
	ylabel = {Anzahl},
	xtick = {3,9,15,21},
	xticklabels = {FF,FR,RF,RR},
  x tick label style ={yshift=-5pt},
	xtick=data,
  xlabel={Annotationsgruppe},
	ymin=0,
	ymax = 25,
%	bar shift = 0pt,
  bar width=9,
  enlarge x limits = .2,
	nodes near coords,
%	legend pos= north east,
	legend style={at={(0.5,-0.15)},anchor=north},
	legend columns = {-1},
	extra description/.code={
  \node at (axis cs:.3,5)[anchor = west]{2,5\%};
	\node at (axis cs:.3,-.5)[anchor = west]{13\%};
	\node at (axis cs:1.2,4.5)[anchor = west]{2,5\%};
	\node at (axis cs:1.2,-.5)[anchor = west]{13\%};
	\node at (axis cs:2,5.5)[anchor = west]{3,3\%};
	\node at (axis cs:2.1,-.5)[anchor = west]{17\%};
	\node at (axis cs:3.1,7.5)[anchor = west]{5,0\%};
	\node at (axis cs:3.1,-.5)[anchor = west]{25\%};
	\node at (axis cs:4,4.5)[anchor = west]{2,5\%};
	\node at (axis cs:4.1,-.5)[anchor = west]{13\%};
	\node at (axis cs:6.4,5.5)[anchor = west]{3,3\%};
	\node at (axis cs:6.4,-.5)[anchor = west]{17\%};
%  \node at (axis cs:7.4,5)[anchor = west]{3,3\%};
%	\node at (axis cs:7.4,-.5)[anchor = west]{17\%};
  \node at (axis cs:8.2,7.5)[anchor = west]{5,0\%};
  \node at (axis cs:8.2,-.5)[anchor = west]{25\%};
	\node at (axis cs:9,3.5)[anchor = west]{1,7\%};
	\node at (axis cs:9.3,-.5)[anchor = west]{8\%};
  \node at (axis cs:10.2,5.5)[anchor = west]{3,3\%};
	\node at (axis cs:10.2,-.5)[anchor = west]{17\%};
%\node at (axis cs:12,5)[anchor = west]{3,3\%};
%\node at (axis cs:12,-.5)[anchor = west]{17\%};
%  \node at (axis cs:13.3,3)[anchor = west]{1,7\%};
%	\node at (axis cs:13.4,-.5)[anchor = west]{8\%};
	\node at (axis cs:14.1,3.5)[anchor = west]{1,7\%};
	\node at (axis cs:14.2,-.5)[anchor = west]{8\%};
  \node at (axis cs:15.1,2.5)[anchor = west]{0,8\%};
	\node at (axis cs:15.1,-.5)[anchor = west]{4\%};
  \node at (axis cs:16,3)[anchor = west]{0,8\%};
	\node at (axis cs:16,-.5)[anchor = west]{4\%};
	\node at (axis cs:18.2,18.5)[anchor = west]{14,2\%};
	\node at (axis cs:18.3,-.5)[anchor = west]{71\%};
	\node at (axis cs:19.3,22.5)[anchor = west]{17,5\%};
	\node at (axis cs:19.3,-.5)[anchor = west]{88\%};
	\node at (axis cs:20.1,13.5)[anchor = west]{10,0\%};
	\node at (axis cs:20.3,-.5)[anchor = west]{50\%};
	\node at (axis cs:20.8,16.5)[anchor = west]{12,5\%};
	\node at (axis cs:21.3,-.5)[anchor = west]{63\%};
	\node at (axis cs:22.1,17.5)[anchor = west]{13,3\%};
	\node at (axis cs:22.3,-.5)[anchor = west]{67\%};
	}
	]
	\addplot+[lsNightBlue]
	coordinates {
	(3,3)
	(9,4)
	(15,0)
	(21,17)
	};
	\addplot+[tmnlpone]
	coordinates {
	(3,3)
	(9,0)
	(15,0)
	(21,21)
	};
	\addplot+[tmnlptwo]
	coordinates {
	(3,4)
	(9,6)
	(15,2)
	(21,12)
	};
	\addplot+[tmnlpthree]
	coordinates {
	(3,6)
	(9,2)
	(15,1)
	(21,15)
	};
	\addplot+[tmnlpfour]
	coordinates {
	(3,3)
	(9,4)
	(15,1)
	(21,16)
	};
	\legend{Bing,Google,Lucy,SDL,Systran}
	\end{axis}
\end{tikzpicture}
\caption{\label{fig:05:115}„Überfl. Präfixe verm.“ -- Aufteilung der Annotationsgruppen bei den einzelnen MÜ-Systemen   }
\bspnote{Die oben angezeigten Prozentzahlen sind für alle Systeme, d. h. systemübergreifend, (N = 120) berechnet.

Die untenstehenden Prozentzahlen sind auf Systemebene (N = 24) berechnet.}
\end{figure}

Die zweitgrößte Gruppe war FF: Am höchsten war sie bei SDL mit einem Viertel seiner MÜ repräsentiert (gefolgt von Lucy mit 17~\%). Bei den anderen drei Systemen (Bing, Google Translate und Systran) betrug der Anteil dieser Gruppe 13~\%. Übersetzungen, die mit überflüssigen Präfixen falsch waren und nach der Regelanwendung korrigiert wurden (Gruppe FR), kamen bei allen Systemen mit Ausnahme des NMÜ-Systems Google Translate vor. Zum Schluss folgt die kleinste Gruppe (RF), die nur für drei Systeme relevant war, nämlich Lucy, SDL und Systran. (siehe \figref{fig:05:115}) In \tabref{tabex:05:78} vergleichen wir den Output der Gruppen RR und FR dreier Systeme (Systran, Bing und Lucy).


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & \textbf{Speichern} Sie die angezeigten Werte lokal auf der Festplatte \textbf{ab}.\\
\tablevspace
HMÜ Systran & \textcolor{tmnlpthree}{Store} the displayed values locally on the hard disk.\\
HMÜ Bing & Locally, \txred{storing} the displayed values on the hard disk.\\
RBMÜ Lucy & \textcolor{tmnlpthree}{Save} the displayed values locally on the hard disk.\\
\midrule
\textbf{Nach-KS} & \textbf{Speichern} Sie die angezeigten Werte lokal auf der Festplatte.\\
\tablevspace
HMÜ Systran & \textcolor{tmnlpthree}{Store} the displayed values locally on the hard disk.\\
HMÜ Bing & \textcolor{tmnlpthree}{Save} the displayed values locally on the hard disk.\\
RBMÜ Lucy & \textcolor{tmnlpthree}{Store} the displayed values locally on the hard disk.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:78}Beispiel 78   }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

Systran und Lucy konnten den Satz mit und ohne überflüssige Präfixe fehlerfrei übersetzen (Gruppe RR). Bei Bing hingegen wurde das Verb mit Präfix (vor KS) falsch übersetzt und falsch platziert. Erst nach der Regelanwendung konnten die beiden Fehler behoben werden (Gruppe FR). Die Fehlertypen unter dieser Regel werden im folgenden Abschnitt diskutiert.

\subsubsection{\label{sec:5.3.8.3}Vergleich der Fehlertypen mit vs. ohne überflüssige Präfixe}

Nach Anwendung dieser Regel sank die Fehleranzahl bei dem Fehlertyp LX.4 „Lexik -- Zusätzliches Wort eingefügt“ von 9 auf 1 ($-$~88,8~\% / Mv = ,08 / SDv = ,264 / Mn = ,01 / SDn = ,091 / N = 120), siehe \figref{fig:05:116}. Dieser Unterschied in der Fehleranzahl erwies sich als signifikant (p = ,008 / N = 120). Bei trennbaren Verben steht in manchen Fällen das Präfix am Satzende (vor KS). Hierbei kam es bei einigen Systemen zu einem lexikalischen Fehler, da das Präfix losgelöst vom Satz übersetzt wurde. In solchen Fällen wurde durch das Vermeiden der überflüssigen Präfixe der Fehler behoben (nach KS). Folgende Beispiele beleuchten diesen Fehlertyp: In \tabref{tabex:05:79} übersetzte Systran ‚aus‘ in ‚auswählen‘ zusätzlich am Satzende als ‚out‘.


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & \textbf{Wählen} Sie die Option $"$Software von einer bestimmten Liste installieren$"$ \textbf{aus}.\\
\tablevspace
HMÜ Systran & \textcolor{tmnlpthree}{Select} the option $"$Install software from a specific list$"$ \txred{out}.\\
\midrule
\textbf{Nach-KS} & \textbf{Wählen} Sie die Option $"$Software von einer bestimmten Liste installieren$"$.\\
\tablevspace
HMÜ Systran & \textcolor{tmnlpthree}{Select} the option $"$Install software from a specific list$"$.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:79}Beispiel 79   }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

Ebenfalls übersetzte Lucy -- in \tabref{tabex:05:80} -- ‚ein‘ in ‚einschicken‘ losgelöst vom Verb als ‚one‘.


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & \textbf{Schicken} Sie das Gerät originalverpackt an unsere Serviceadresse \textbf{ein}.\\
\tablevspace
RBMÜ Lucy & Please \txblue{send} the appliance in its original packaging to our service address \txred{one}.\\
\midrule
\textbf{Nach-KS} & \textbf{Schicken} Sie das Gerät originalverpackt an unsere Serviceadresse.\\
\tablevspace
RBMÜ Lucy & Please \txblue{send} the appliance in its original packaging to our service address.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:80}Beispiel 80   }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

Dieser Fehler beeinträchtigte die MÜ-Qualität, wie unter \sectref{sec:5.3.8.4} demonstriert. Bei allen anderen Fehlertypen veränderte sich die Fehleranzahl im Vergleich zu nach der Umsetzung der Regel nicht deutlich (\figref{fig:05:116}).



\begin{figure}
%\includegraphics[height=.3\textheight]{figures/d3-img096.png}

%\textbf{\textit{$-$ 88,8~\%}}



%\includegraphics[height=.3\textheight]{figures/d3-img027.png}

%\includegraphics[height=.3\textheight]{figures/d3-img013.png}



%\includegraphics[height=.3\textheight]{figures/d3-img013.png} & vor KS
% 116
\pgfplotstableread{
1 0
2 0
3 1
4 0
5 1
6 2
7 9
8 1
9 0
10 0
11 0
12 0
13 1
14 1
15 5
16 2
17 7
18 8
19 8
20 6
21 10
22 7
23 3
24 2
25 0
26 0
}\datatable
\smbars[extra description/.code={
\node at (axis cs:6, 10)[anchor = west]{\bfitul{$-$ 88,8 \%}};
}]{}
\caption{\label{fig:05:116}„Überfl. Präfixe verm.“ -- Summe der Fehleranzahl der einzelnen Fehlertypen vor vs. nach KS}
\bspnote{*Die X-Achse ist folgendermaßen zu lesen: Jeder Fehlertyp wird anhand von zwei Balken abgebildet. Der erste Balken repräsentiert die Summe der Fehler \textit{vor KS} und der zweite die Summe der Fehler \textit{nach KS}, somit steht z.~B. „OR\_1.v“ für „OR\_1: orthografischer Fehler Nr. 1“ und „v: vor KS“; „OR\_1.n“ wäre entsprechend das Pendant zu „OR\_1.v“ für das nach-KS-Szenario („n“).\\
**\bfitul{Signifikante Differenz vor vs. nach KS}\\
OR.1: Orthografie -- Zeichensetzung\\
OR.2: Orthografie -- Großschreibung\\
LX.3: Lexik -- Wort ausgelassen\\
LX.4: Lexik -- Zusätzliches Wort eingefügt\\
LX.5: Lexik -- Wort unübersetzt geblieben (auf DE wiedergegeben)\\
LX.6: Lexik -- Konsistenzfehler\\
GR.7: Grammatik -- Falsche Wortart / Wortklasse\\
GR.8: Grammatik -- Falsches Verb (Zeitform, Komposition, Person)\\
GR.9: Grammatik -- Kongruenzfehler (Agreement)\\
GR.10: Grammatik -- Falsche Wortstellung\\
SM.11: Semantik -- Verwechslung des Sinns\\
SM.12: Semantik -- Falsche Wahl\\
SM.13: Semantik -- Kollokationsfehler
}
\end{figure}


\subsubsubsection{Vergleich der Fehlertypen auf Regel- und MÜ-Systemebene}

Eine genauere Untersuchung der Fehlertypen bei den verschiedenen MÜ-Syste\-men zeigt (\figref{fig:05:117}), dass die Fehleranzahl der einzelnen Fehlertypen auf Systemebene sehr gering war (max. 4). Am meisten beeinflusst durch die Regelanwendung war der Fehlertyp LX.4 „Lexik -- Zusätzliches Wort eingefügt“. Dieser Fehlertyp sank bei dem SMÜ-System SDL und wurde bei dem HMÜ-System Bing, dem RBMÜ-System Lucy und dem HMÜ-System Systran vollständig behoben. Jedoch erwies sich die Differenz aufgrund der geringen Fehleranzahl bei keinem der genannten Systeme als signifikant.


\begin{figure}
%\includegraphics[height=.3\textheight]{figures/d3-img097.png}



%\includegraphics[height=.3\textheight]{figures/d3-img026.png}\\
\begin{tikzpicture}
\tikzset{every node/.style={font=\scriptsize}};
	\begin{axis}[
	xbar,
	width = \textwidth,
	height = .83\textheight,
	axis lines* = left,
	xlabel = {Summe},
	ytick = {1,2,3,...,18},
	yticklabels = {IN\_OR\_2.v,
  IN\_OR\_2.n,
  IN\_LX\_3.v,
	IN\_LX\_3.n,
	IN\_LX\_4.v,
	IN\_LX\_4.n,
  IN\_GR\_7.v,
  IN\_GR\_7.n,
	IN\_GR\_8.v,
	IN\_GR\_8.n,
  IN\_GR\_9.v,
  IN\_GR\_9.n,
	IN\_GR\_10.v,
	IN\_GR\_10.n,
	IN\_SM\_11.v,
	IN\_SM\_11.n,
	IN\_SM\_12.v,
	IN\_SM\_12.n,
	},
%	x tick label style={rotate=60,anchor=east,font=\scriptsize},
	enlarge y limits={.032},
	xmin=0,
	xmax = 4,
%	bar shift = 1pt,
  bar width=2,
	nodes near coords,
	legend pos = south east,
	reverse legend,
%	legend style={at={(0.5,-0.1)},anchor=north},
%	legend columns = {-1},
	]
	\addplot+[tmnlpone]
	coordinates {
	(0,1)
	(0,2)
	(0,3)
	(0,4)
	(1,5)
	(0,6)
	(0,7)
	(0,8)
	(4,9)
	(1,10)
	(0,11)
	(1,12)
	(1,13)
	(0,14)
  (3,15)
	(1,16)
	(1,17)
	(0,18)
	};
	\addplot+[lsLightOrange]
	coordinates {
	(0,1)
	(0,2)
	(0,3)
	(0,4)
	(0,5)
	(0,6)
	(0,7)
	(0,8)
	(0,9)
	(0,10)
	(2,11)
	(2,12)
	(0,13)
	(0,14)
  (1,15)
	(1,16)
	(1,17)
	(0,18)
	};
	\addplot+[smGreen]
	coordinates {
	(0,1)
	(0,2)
	(0,3)
	(0,4)
	(3,5)
	(0,6)
	(0,7)
	(0,8)
	(1,9)
	(1,10)
	(2,11)
	(2,12)
	(3,13)
	(2,14)
  (2,15)
	(2,16)
	(0,17)
	(0,18)
	};
	\addplot+[tmnlpthree]
	coordinates {
	(1,1)
	(0,2)
	(1,3)
	(2,4)
	(3,5)
	(1,6)
	(1,7)
	(1,8)
	(0,9)
	(0,10)
	(0,11)
	(0,12)
	(3,13)
	(3,14)
  (2,15)
	(2,16)
	(1,17)
	(2,18)
	};
	\addplot+[lsRed]
	coordinates {
	(0,1)
	(0,2)
	(0,3)
	(0,4)
	(2,5)
	(0,6)
	(0,7)
	(0,8)
	(0,9)
	(0,10)
	(3,11)
	(3,12)
	(1,13)
	(1,14)
  (2,15)
	(1,16)
	(0,17)
	(0,18)
	};
	\legend{Bing,Google,Lucy,SDL,Systran}
	\end{axis}
\end{tikzpicture}
\caption{\label{fig:05:117}„Überfl. Präfixe verm.“ -- Summe der Fehleranzahl der Fehlertypen vor vs. nach KS bei den einzelnen MÜ-Systemen   }
\bspnote{*Die Balken zeigen die Summe der Fehleranzahl bei jedem Fehlertyp, wobei „v“ für die Summe „vor der Anwendung der KS-Regel“ und „n“ für die Summe „nach der Anwendung der KS-Regel“ steht. Jeder Fehlertyp wird erst für alle Systeme für das Szenario „vor KS“ abgebildet, danach folgt derselbe Fehlertyp wieder für alle Systeme für das Szenario „nach KS“.

**Um die Übersichtlichkeit und Lesbarkeit der Grafik zu erhöhen, wurden in der Grafik die Fehlertypen ausgeblendet, die 0 oder nur einmal bei \textit{allen} MÜ-Systemen vorkamen: In dieser Grafik kamen die Fehlertypen 1, 5, 6 und 13 bei gar keinem MÜ-System vor.}
\end{figure}

\subsubsection{\label{sec:5.3.8.4}Vergleich der MÜ-Qualität mit vs. ohne überflüssige Präfixe sowie die Korrelation zwischen den Fehlertypen und der Qualität}

Bei der Regel „Überflüssige Präfixe vermeiden“ stiegen zwar die Stil- und Inhaltsqualität,\footnote{\textrm{Definitionen der Qualität unter \sectref{sec:4.4.5.1}.}} dennoch fiel dieser Anstieg nur sehr niedrig aus. Die meisten Übersetzungen (68~\%) bei dieser Regel waren sowohl vor als auch nach der Anwendung der Regel richtig (Gruppe RR), siehe \figref{fig:05:114}. Daher ist eine statistisch signifikante Qualitätsveränderung schwer vorstellbar. Die Stilqualität stieg um 1,9~\% (Mv = 4,25 / SDv = ,554 / Mn = 4,33 / SDn = ,414 / N = 92). Die Inhaltsqualität stieg um 2,5~\% (Mv = 4,46 / SDv = ,768 / Mn = 4,57 / SDn = ,701 / N = 92). (siehe \figref{fig:05:118}) Der Mittelwert der Differenz (nach KS $-$ vor KS) der vergebenen Qualitätspunkte pro Satz lag im Fall der Stilqualität bei ,086 (SD = ,435) mit einem 95\%\nobreakdash-Konfidenzintervall zwischen einem Minimum von $-$~,005 und einem Maximum von ,176 sowie im Fall der Inhaltsqualität bei ,111 (SD = ,496) mit einem 95\%\nobreakdash-Konfidenzintervall zwischen einem Minimum von ,009 und einem Maximum von ,214 (Bootstrapping mit 1000 Stichproben), siehe \figref{fig:05:119}. Die Differenzen (nach KS $-$ vor KS) in der Stil- und Inhaltsqualität waren nicht signifikant (p = ,172 bzw. p = ,059).


\begin{figure}
%\textbf{4,424,71}

%\textbf{4,134,36}

%\textbf{4,304,61}

%\textbf{4,254,42}



%\includegraphics[height=.3\textheight]{figures/d3-img029.png}



%\includegraphics[height=.3\textheight]{figures/d3-img029.png}



%\includegraphics[height=.3\textheight]{figures/d3-img030.png} &  & {}



%\includegraphics[height=.3\textheight]{figures/d3-img017.png}



%\includegraphics[height=.3\textheight]{figures/d3-img017.png}



%\includegraphics[height=.3\textheight]{figures/d3-img017.png}\\
\captionsetup{width=.45\textwidth}
\begin{floatrow}
\ffigbox[.5\textwidth]{\caption{„Überfl. Präfixe verm.“ -- Mittelwerte der Qualität vor und nach KS}\label{fig:05:118}}{
\includegraphics[width=.25\textwidth]{figures/Abb118.png}
\includegraphics[width=.2\textwidth]{figures/Abb15-legend.png}
}
\ffigbox[.45\textwidth]{\caption{„Überfl. Präfixe verm.“ {}- Mittelwert der Qualitätsdifferenzen}\label{fig:05:119}}{
\includegraphics[width=.25\textwidth]{figures/Abb16-legend.png}
\includegraphics[width=.3\textwidth]{figures/Abb119.png}
}
\end{floatrow}
\end{figure}

Eine genaue Betrachtung der Ergebnisse der Humanevaluation zeigt, dass die Stil- und Inhaltsqualität bei der Behebung der lexikalischen Fehlertyp LX.4 „Zusätzliches Wort eingefügt“ stiegen. Bei der Verwendung von Verben mit überflüssigen Präfixen, wurden die Präfixe zusätzlich übersetzt. Die Behebung dieses Fehlers verbesserte die Übersetzung stilistisch sowie inhaltlich hinsichtlich der Genauigkeit und Verständlichkeit (CQ1 und CQ2).


\begin{figure}
%\includegraphics[height=.3\textheight]{figures/d3-img092.png}

%\textbf{$-$ 14~\%}

%\textbf{$-$ 25~\%}

%\textbf{$-$ 1~\%}

%\textbf{$-$ 21~\%}

%\textbf{$-$ 24~\%}
\pgfplotstableread{
1 67
2 51
3 98
4 97
5 296
6 254
7 169
8 127
9 113
10 89
}\datatable

\begin{tikzpicture}
    \begin{axis}[ybar,
                enlarge x limits={.05},
                width  = \textwidth,
                height = .45\textheight,
                axis lines*=left,
                axis on top,
                bar width=8.5,
                bar shift=0pt,
                ymin = 0,
                ymax=350,
                xtick = {1,2,...,10},
                xticklabels={SQ1\_v,
                SQ1\_n,
                SQ2\_v,
                SQ2\_n,
                SQ3\_v,
                SQ3\_n,
                CQ1\_v,
                CQ1\_n,
                CQ2\_v,
                CQ2\_n},
            x tick label style={font=\small},
            nodes near coords,
 	 extra description/.code={
	 \node at (axis cs:1.1,100)[anchor = west]{$-$ 24\%};
	 \node at (axis cs:3,150)[anchor = west]{$-$ 1\%};
	  \node at (axis cs:5.2,350)[anchor = west]{$-$ 14\%};
	   \node at (axis cs:7,200)[anchor = west]{$-$ 25\%};
	    \node at (axis cs:9,150)[anchor = west]{$-$ 21\%};
	  }
            ]
        \addplot +[shift={(.5,0)},lsDarkBlue,x filter/.code={\ifodd\coordindex\def\pgfmathresult{}\fi}] table {\datatable};
        \addplot +[shift={(-.5,0)},lsMidBlue,  x filter/.code={\ifodd\coordindex\relax\else\def\pgfmathresult{}\fi}] table {\datatable};
    \end{axis}
\end{tikzpicture}
\caption{\label{fig:05:120}„Überfl. Präfixe verm.“ -- Vergleich der Qualitätskriterien   }
\bspnote{\textbf{SQ1:} Ü ist \textbf{\textit{nicht}} korrekt bzw. \textbf{\textit{nicht}} klar dargestellt, d. h. nicht orthografisch.\\
{\textbf{SQ2:} Ü ist \textbf{\textit{nicht}} ideal für die Absicht des Satzes, d. h. motiviert den Nutzer \textbf{\textit{nicht} }zum Handeln, zieht \textbf{\textit{nicht} }seine Aufmerksamkeit an usw.}\\
\textbf{SQ3:} Ü klingt \textbf{\textit{nicht} }natürlich bzw. \textbf{\textit{nicht} }idiomatisch.\\
{\textbf{CQ1:} Ü gibt die Informationen im Ausgangstext \textbf{\textit{nicht}} exakt wieder.}\\ \textbf{CQ2:} Ü ist \textbf{\textit{nicht}} leicht zu verstehen, d. h. \textbf{\textit{nicht}} gut formuliert bzw. dargestellt.}
\end{figure}

Dennoch ist der Effekt, wie \tabref{tabex:05:81} zeigt, nur bei dem Präfix bemerkbar. In dem Fall betrug die Qualitätsveränderung auf der Likert-Skala +~0,75 bei der SQ bzw. +~0,63 bei der CQ.


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & \textbf{Wählt} man einen bestimmten Zeichensatz als Standardwert \textbf{aus}, wird dieser Zeichensatz in allen Stationen verwendet.\\
\tablevspace
SMÜ SDL & If you \txblue{select} a certain character set as a default value \txred{from}, this character set will be used in all stations.\\
\midrule
\textbf{Nach-KS} & \textbf{Wählt} man einen bestimmten Zeichensatz als Standardwert, wird dieser Zeichensatz in allen Stationen verwendet.\\
\tablevspace
SMÜ SDL & If you \txblue{select} a certain character set as a default value, this character set will be used in all stations.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:81}Beispiel 81   }
\bspnote{ Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

\subsubsubsection{Korrelation zwischen den Fehlertypen und der Qualität}

Auf Basis der Fehlerannotation zusammen mit der Humanevaluation gibt uns eine Spearman-Korrelationsanalyse Aufschluss, wie die Veränderung bei der Fehleranzahl bei jedem Fehlertyp (Anz. nach KS $–$ Anz. vor KS) mit den Qualitätsunterschieden (Q. nach KS $–$ Q. vor KS) zusammenhängt. Mithilfe des Spearman-Tests erwies sich ein signifikanter mittlerer negativer Zusammenhang zwischen der Differenz in den Fehlertypen LX.4 „Zusätzliches Wort eingefügt“ und SM.11 „Verwechslung des Sinns“ einzeln und der Differenz in der Stilqualität; sowie ein signifikanter schwacher negativer Zusammenhang zwischen der Differenz im Fehlertyp GR.8 „Falsches Verb (Zeitform, Komposition, Person)“ und der Differenz in der Stilqualität. (siehe \tabref{tab:05:75})


\begin{table}
\begin{tabularx}{\textwidth}{Xrrr}

\lsptoprule

 & { \textbf{N}} & { \textbf{p}} & \textbf{ρ}\\
\midrule
\textbf{Differenz SQ (nach KS $-$ vor KS)} &  &  & \\
Diff. der Anzahl der \textbf{LX.4 „Zusätzliches Wort eingefügt“} & { 92} & { < ,001} & \txgreen{$-$~,431}\\
Diff. der Anzahl der \textbf{GR.8 „Falsches Verb“} & { 92} & { ,045} & $-$~,210\\
Diff. der Anzahl der \textbf{SM.11 „Verwechslung des Sinns“} & { 92} & { ,002} & \txgreen{$-$~,323}\\
\midrule
\textbf{Differenz CQ (nach KS $-$ vor KS)} & &  & \\
Diff. der Anzahl der \textbf{LX.4 „Zusätzliches Wort eingefügt“} & { 92} & { < ,001} & \txgreen{$-$~,434}\\
Diff. der Anzahl der \textbf{GR.8 „Falsches Verb“} & { 92} & { ,005} & $-$~,288\\
Diff. der Anzahl der \textbf{SM.11 „Verwechslung des Sinns“} & { 92} & { ,001} & \txgreen{$-$~,337}\\
\midrule
\textbf{Differenz allg. Q (nach KS $-$ vor KS)} &  &  & \\
Diff. der Anzahl der \textbf{LX.4 „Zusätzliches Wort eingefügt“} & { 92} & { < ,001} & \txgreen{$-$~,452}\\
Diff. der Anzahl der \textbf{GR.8 „Falsches Verb“} & { 92} & { ,008} & $-$~,274\\
Diff. der Anzahl der \textbf{SM.11 „Verwechslung des Sinns“} & { 92} & { < ,001} & \txgreen{$-$~,388}\\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:75}„Überfl. Präfixe verm.“ -- Korrelation zwischen den Fehlertypen und der Qualität   }
\bspnote{*In der Tabelle werden nur die Fehlertypen dargestellt, die mindestens mit einer Qualitätsvariable signifikant korrelieren.
\begin{tabbing}
p: Signifikanz\hspace{2.5cm} \= \txgray{nicht signifikant (p ${\geq}$ 0,05)}\hspace{.5cm} \= ρ: Korrelationskoeffizient\\
schwache Korrelation (ρ >=0,1) \> \txgreen{mittlere Korrelation (ρ >= 0,3)}\> \boxblue{starke Korrelation (ρ >= 0,5)}
\end{tabbing}}
\end{table}

Bezüglich der Inhaltsqualität erwies sich ein signifikanter mittlerer negativer Zusammenhang zwischen der Differenz in den Fehlertypen LX.4 und SM.11 einzeln und der Differenz in der Inhaltsqualität; sowie ein signifikanter schwacher negativer Zusammenhang zwischen der Differenz im Fehlertyp GR.8 und der Differenz in der Inhaltsqualität. (siehe \tabref{tab:05:75}) Weitere Korrelationen zwischen anderen einzelnen Fehlertypen und der Qualität konnten nicht erwiesen werden.

Diese signifikanten negativen Korrelationen deuten darauf hin, dass mit dem Rückgang der Fehleranzahl der genannten Fehlertypen, die Qualität, wie es bei \tabref{tabex:05:81} zu beobachten war, zunahm.

\subsubsubsection{Vergleich der Qualität auf Regel- und MÜ-Systemebene}

Die großen Intervalle in \figref{fig:05:121} zeigen, dass die Stil- und Inhaltsqualität in den meisten Fällen sehr vergleichbar waren. Durchschnittlich stieg die Qualität bei allen Systemen mit Ausnahme des NMÜ-Systems Google Translate.


\begin{figure}
\includegraphics[width=\textwidth]{figures/d3-img098.png}



%\includegraphics[height=.3\textheight]{figures/d3-img033.png}\\
\caption{\label{fig:05:121}„Überfl. Präfixe verm.“ -- Mittelwerte der Qualität vor vs. nach KS bei den einzelnen MÜ-Systemen   }
\end{figure}

Die geringe Abnahme bei Google Translate von $-$~1,5~\% bei der Stilqualität bzw. $-$~,7~\% bei der Inhaltsqualität entstand durch kleine Unterschiede in Fällen wie \tabref{tabex:05:82}.


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & \textbf{\textcolor{lsRed}{Kaufen} Sie die Geräte in einem anderen Land \txred{ein}, werden Garantieleistungen nur in diesem Land erbracht.}\\
\tablevspace
GNMÜ & If you \txblue{purchase} the devices in another country, warranty services will only be provided in this country.\\
\midrule
\textbf{Nach-KS} & \textbf{\textcolor{lsRed}{Kaufen} Sie die Geräte in einem anderen Land, werden Garantieleistungen nur in diesem Land erbracht.}\\
\tablevspace
GNMÜ & If you \txblue{buy} the devices in another country, warranty services will only be provided in this country.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:82}Beispiel 82   }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

Obwohl ‚purchase‘ und ‚buy‘ Synonyme sind, wurde die MÜ vor KS ‚purchase‘ nicht nur stilistisch sondern auch inhaltlich höher bewertet (nach KS: $-$~,63 bei der SQ bzw. $-$~,25 bei der CQ auf der Likert-Skala). Außerdem wurden weitere Sätze, die vor und nach der Regelanwendung \textit{identisch} übersetzt wurden, durchschnittlich \textit{unterschiedlich} bewertet. Angesichts der allgemein hohen Intrarater-Agreements (siehe \sectref{sec:5.1.3}) werfen diese Bewertungsunterschiede eine Forschungsfrage für zukünftige Arbeiten auf. Insgesamt war die Veränderung sowohl in der Stilqualität als auch in der Inhaltsqualität bei keinem der MÜ-Systeme signifikant (\tabref{tab:05:76}).


\begin{table}
\begin{tabularx}{\textwidth}{lrrrrrrrrr}

\lsptoprule
& \multicolumn{3}{c}{ \textbf{Differenz SQ} } & \multicolumn{3}{c}{ \textbf{Differenz CQ} } & \multicolumn{3}{c}{ \textbf{Differenz allg. Q} }\\
& \multicolumn{3}{c}{\textbf{(nach KS $-$ vor KS)}} & \multicolumn{3}{c}{\textbf{(nach KS $-$ vor KS)}} & \multicolumn{3}{c}{\textbf{(nach KS $-$ vor KS)}}\\
\cmidrule(lr){2-4}\cmidrule(lr){5-7}\cmidrule(lr){8-10}
& \textbf{N} & \textbf{p} & \textbf{z} & \textbf{N} & \textbf{p} & \textbf{z} & \textbf{N} & \textbf{p} & \textbf{z}\\
\midrule
 \textbf{Bing} & 15 & \txgray{,284} & $-$~1,071 & 15 & \txgray{,074} & $-$~1,785 & 15 & \txgray{,139} & $-$~1,481\\
 \textbf{Google} & 23 & \txgray{,257} & $-$~1,135 & 23 & \txgray{,475} & $-$~,714 & 23 & \txgray{,289} & $-$~1,061\\
 \textbf{Lucy} & 20 & \txgray{,430} & $-$~,789 & 20 & \txgray{,959} & $-$~,052 & 20 & \txgray{,795} & $-$~,259\\
 \textbf{SDL} & 20 & \txgray{,154} & $-$~1,425 & 20 & \txgray{,165} & $-$~1,389 & 20 & \txgray{,169} & $-$~1,376\\
 \textbf{Systran} & 14 & \txgray{,472} & $-$~,719 & 14 & \txgray{,114} & $-$~1,581 & 14 & \txgray{,271} & $-$~1,100\\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:76}„Überfl. Präfixe verm.“ -- Signifikanz der Qualitätsveränderung bei den einzelnen MÜ-Systemen   }
\bspnote{p: Signifikanz\hspace{2.5cm} z: Teststatistik\hspace{2.5cm} \txgray{nicht signifikant (p ${\geq}$ 0,05)}}
\end{table}


\subsubsubsection{Korrelation zwischen den Fehlertypen und der Qualität auf Regel- und MÜ-Systemebene}

Anhand der Spearman-Korrelationsanalyse erwies sich bei dem HMÜ-System Bing nur ein signifikanter starker negativer Zusammenhang zwischen dem grammatischen Fehlertyp GR.8 und der Inhaltsqualität. Bei dem RBMÜ-System Lucy erwies sich eine signifikante starke negative Korrelation zwischen den Fehlertypen GR.8 und SM.11 einzeln und der Stilqualität; sowie eine signifikante starke negative Korrelation zwischen dem Fehlertyp GR.8 und der Inhaltsqualität. Bei dem SMÜ-System SDL erwies sich nur eine signifikante mittlere negative Korrelation zwischen dem Fehlertyp LX.4 und der Stilqualität. Bei dem HMÜ-System Systran erwies sich nur ein signifikanter starker negativer Zusammenhang zwischen dem lexikalischen Fehlertyp LX.4 und der Inhaltsqualität. (siehe \tabref{tab:05:77})


\begin{sidewaystable}
\scriptsize
\captionsetup{width=\textwidth}
\begin{tabularx}{\textwidth}{Xrrrrrrrrrrrr}

\lsptoprule
 & \multicolumn{3}{c}{ \textbf{Bing}} &  \multicolumn{3}{c}{ \textbf{Lucy}} & \multicolumn{3}{c}{ \textbf{SDL}} & \multicolumn{3}{c}{ \textbf{Systran}}\\
 \cmidrule(lr){2-4} \cmidrule(lr){5-7} \cmidrule(lr){8-10} \cmidrule(lr){11-13}
 & { \textbf{N}} & { \textbf{p}} & { \textbf{ρ}} & { \textbf{N}} & \textbf{p} & \textbf{ρ} & \textbf{N} & \textbf{p} & \textbf{ρ} & \textbf{N} & \textbf{p} & \textbf{ρ}\\
 \midrule
\multicolumn{13}{l}{\textbf{Differenz SQ} \textbf{(nach KS $-$ vor KS)}} \\
Diff. der Anzahl \textbf{LX.4 „Zusätzl. Wort eingef.“} &  &  &  &  &  &  & { 20} & ,039 & \txgreen{$-$~,465} & { 14} & \txgray{,120} & $-$~,435\\
Diff. der Anzahl \textbf{GR.8 „Falsches Verb“} & 15 & \txgray{,059} & { $-$~,498}  & { 20} & { ,003} & \boxblue{$-$~,626} &  &  &  &  & &  \\
Diff. der Anzahl \textbf{SM.11 „Verwechs. d. Sinns“} &  &  &  & { 20} & { ,022} & \boxblue{$-$~,510} &  &  &  &  &  & \\
\midrule
\multicolumn{13}{l}{\textbf{Differenz CQ} \textbf{(nach KS $-$ vor KS)}}\\
Diff. der Anzahl \textbf{LX.4 „Zusätzl. Wort eingef.“} &  &  &  &  &  &  & { 20} & \txgray{,089} & $-$~,390 & { 14} & { ,020} & \boxblue{$-$~,612} \\
Diff. der Anzahl \textbf{GR.8 „Falsches Verb“} & 15 & ,008 & \boxblue{$-$~,658} & { 20} & { ,005} & \boxblue{$-$~,598} &  &  &  & & & \\
Diff. der Anzahl \textbf{SM.11 „Verwechs. d. Sinns“} &  &  &  & { 20} & \txgray{,227} & { $-$~,283} &  &  &  & &  & \\
\midrule
\multicolumn{13}{l}{\textbf{Differenz Q} \textbf{(nach KS $-$ vor KS)}} \\
Diff. der Anzahl \textbf{LX.4 „Zusätzl. Wort eingef.“} &  &  & &  &  &  &{ 20} & \txgray{,055} & $-$~,435 & { 14} & { ,028} & \boxblue{$-$~,584}\\
Diff. der Anzahl \textbf{GR.8 „Falsches Verb“} & 15 & ,012 & \boxblue{$-$~,629} & { 20} & { ,003} & \boxblue{$-$~,623} &  &  &  &  &  &  \\
Diff. der Anzahl \textbf{SM.11 „Verwechs. d. Sinns“} &  &  &  & { 20} & \txgray{,053} & { ,439} &  &  &  &  &  &  \\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:77}„Überfl. Präfixe verm.“ -- Korrelationen zwischen den Fehlertypen und der Qualität bei den einzelnen MÜ-Systemen   }
\bspnote{*In der Tabelle werden nur die Fehlertypen dargestellt, die bei mind. einer Qualitätsvariable eine signifikante Korrelation aufweisen.
\begin{tabbing}
p: Signifikanz\hspace{2.5cm}\= \txgray{nicht signifikant (ρ ${\geq}$ 0,05)}\hspace{1cm}\= ρ: Korrelationskoeffizient\\
schwache Korrelation (ρ >=0,1)\> \txgreen{mittlere Korrelation (ρ >= 0,3)}\> \boxblue{starke Korrelation (ρ >= 0,5)}\\
\end{tabbing}}
\end{sidewaystable}

\tabref{tabex:05:83} zeigt den Effekt der Korrektur des Fehlertyps SM.11 „Verwechslung des Sinns“.


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & Sorgen Sie dafür, dass die Quelle ein einwandfreies Signal \textbf{absendet}.\\
\tablevspace
RBMÜ Lucy & Ensure that the source \txred{submits} a correct signal.\\
\midrule
\textbf{Nach-KS} & Sorgen Sie dafür, dass die Quelle ein einwandfreies Signal \textbf{sendet}.\\
\tablevspace
RBMÜ Lucy & Ensure that the source \txblue{sends} a correct signal.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:83}Beispiel 83   }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

In diesem Beispiel wurde der semantische Fehler SM.11 „Verwechslung des Sinns“ (in der Übersetzung von ‚absenden‘ als ‚submit‘), nachdem das überflüssige Präfix vermieden wurde, eliminiert. Daraufhin stiegen die Stil- und Inhaltsqualität um 0,13 bzw. 0,63 auf der Likert-Skala (nach KS) an.

\subsubsection{\label{sec:5.3.8.5}Vergleich der MÜ-Qualität mit vs. ohne überflüssige Präfixe auf Annotationsgruppenebene}

Mit Ausnahme der Gruppe FR war die Differenz in der Stil- und Inhaltsqualität\footnote{\textrm{Definitionen der Qualität unter \sectref{sec:4.4.5.1}.}} bei allen anderen Annotationsgruppen gering (\figref{fig:05:122}).


\begin{figure}
\includegraphics[width=\textwidth]{figures/d3-img099.png}

%\includegraphics[height=.3\textheight]{figures/d3-img035.png}\\
\caption{\label{fig:05:122}„Überfl. Präfixe verm.“ -- Mittelwerte der Qualität vor vs. nach KS auf Annotationsgruppenebene   }
\end{figure}

In der Gruppe FF blieb die MÜ bei 16~\% der Fälle (siehe \sectref{sec:5.3.8.2}) aus unterschiedlichen Gründen vor und nach der Regelanwendung falsch. Es gab keinen bestimmten schwerwiegenden Fehler, der bei einem der beiden Szenarien auftrat. Entsprechend war die Qualität vor und nach der Regelanwendung vergleichbar.

In der Gruppe FR stiegen erwartungsgemäß die Stil- und Inhaltsqualität signifikant (\tabref{tab:05:78}): bei der Stilqualität (z (N = 16) = $-$ 3,133 / p = ,002) bzw. bei der Inhaltsqualität (z (N = 16) = $-$ 3,462 / p = ,001).


\begin{table}
\begin{tabularx}{\textwidth}{Xrrr}

\lsptoprule
& \textbf{N} & { \textbf{p}} & { \textbf{Z} }\\
& & \textbf{(Signifikanz)} & \textbf{(Teststatistik)}\\
\midrule
{\textbf{Annotationsgruppe FF}} &  &  & \\
\textbf{Differenz SQ (nach KS $-$ vor KS)} & 11 & \txgray{,109} & $-$~1,602\\
\textbf{Differenz CQ (nach KS $-$ vor KS)} & 11 & \txgray{,765} & $-$~,299\\
\textbf{Differenz allg. Q (nach KS $-$ vor KS)} & 11 & \txgray{,439} & $-$~,775\\
\midrule
{\textbf{Annotationsgruppe FR}} & {} & {} & \\
\textbf{Differenz SQ (nach KS $-$ vor KS)} & 16 & ,002 & $-$ 3,133\\
\textbf{Differenz CQ (nach KS $-$ vor KS)} & 16 & ,001 & $-$ 3,462\\
\textbf{Differenz allg. Q (nach KS $-$ vor KS)} & 16 & ,001 & $-$ 3,410\\
\midrule
{\textbf{Annotationsgruppe RF}} & {} & {} & \\
\textbf{Differenz SQ (nach KS $-$ vor KS)} & 2 & \txgray{,180} & $-$~1,342\\
\textbf{Differenz CQ (nach KS $-$ vor KS)} & 2 & \txgray{,180} & $-$~1,342\\
\textbf{Differenz allg. Q (nach KS $-$ vor KS)} & 2 & \txgray{,180} & $-$~1,342\\
\midrule
{\textbf{Annotationsgruppe RR}} & {} & {} & \\
\textbf{Differenz SQ (nach KS $-$ vor KS)} & 62 & \txgray{,148} & $-$~1,448\\
\textbf{Differenz CQ (nach KS $-$ vor KS)} & 62 & \txgray{,828} & $-$~,217\\
\textbf{Differenz allg. Q (nach KS $-$ vor KS)} & 62 & \txgray{,122} & $-$~1,548\\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:78}„Überfl. Präfixe verm.“ -- Signifikanz der Qualitätsveränderung auf Annotationsgruppenebene   }
\end{table}

Oft wurden die getrennt aufgetretenen Präfixe (vor KS) in dieser Gruppe fehlerhaft zusätzlich übersetzt. Die MÜ-Systeme konnten die trennbaren Verben als solche nicht erkennen. Nachdem auf die Präfixe verzichtet wurde (nach KS), wurde die MÜ korrigiert und entsprechend stieg die Qualität. In \tabref{tabex:05:84} war der Anstieg relativ hoch und betrug bei der Stilqualität 1,00 bzw. bei der Inhaltsqualität 0,88 Punkte auf der Likert-Skala.


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & \textbf{Schicken} Sie das Gerät originalverpackt an unsere Serviceadresse \textbf{ein}.\\
\tablevspace
RBMÜ Lucy & \textbf{\textit{Please} }\txblue{send} the appliance in its original packaging to our service address \txred{one}.\\
\midrule
\textbf{Nach-KS} & \textbf{Schicken} Sie das Gerät originalverpackt an unsere Serviceadresse.\\
\tablevspace
RBMÜ Lucy & \textbf{\textit{Please}} \txblue{send} the appliance in its original packaging to our service address.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:84}Beispiel 84   }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

Die Gruppe RF war, wie die Aufteilung der Annotationsgruppen (\sectref{sec:5.3.8.2}) zeigte, sehr selten vertreten. Nur in 4 Fällen bzw. 3~\% der analysierten Sätze und davon wurde nur die Hälfte in der Humanevaluation bewertet, was das relativ große Intervall in der \figref{fig:05:122} erklärt.

In der Gruppe RR (Übersetzung vor und nach KS richtig) bleiben die Inhaltsqualität vor und nach der Anwendung der Regel fast unverändert. Hat das System das Präfix richtig geparst, so wurde der Satz fehlerfrei übersetzt und in den meisten Fällen war die MÜ vor und nach der Regelanwendung identisch oder es wurden Synonyme für die Verbübersetzung in den beiden Szenarien verwendet (siehe \tabref{tabex:05:82}).

\subsubsection{\label{sec:5.3.8.6}Vergleich der AEM-Scores mit vs. ohne überflüssige Präfixe sowie die Korrelation zwischen den AEM-Scores und der Qualität}

Der Vergleich der AEM-Scores mit vs. ohne die überflüssigen Präfixe zeigte sowohl mit TERbase als auch mit hLEPOR nur eine sehr geringe, nicht signifikante Verbesserung der AEM-Scores, nachdem die Sätze ohne die Präfixe formuliert wurden (nach KS), siehe \figref{fig:05:123}.


\begin{figure}
%\includegraphics[height=.3\textheight]{figures/d3-img022.png}




%\includegraphics[height=.3\textheight]{figures/d3-img022.png}


%\includegraphics[height=.3\textheight]{figures/d3-img022.png}
\includegraphics[width=.4\textwidth]{figures/Abb123.png}
\includegraphics[width=.35\textwidth]{figures/Abb19-legend.png}
\caption{\label{fig:05:123}„Überfl. Präfixe verm.“ -- Mittelwert der Differenz der AEM-Scores}
\bspnote{Differenz = AEM-Score nach KS \textit{minus} AEM-Score vor KS}
\end{figure}

Der Mittelwert der Differenz (nach KS $-$ vor KS) im AEM-Score pro Satz lag für TERbase bei ,015 (SD = ,191) und für die hLEPOR bei ,006 (SD = ,111) mit einem 95\%-Konfidenzintervall (Bootstrapping mit 1000 Stichproben), siehe \figref{fig:05:123}. Durch diese minimalen Unterschiede waren die Differenzen (nach KS $-$ vor KS) in TERbase und hLEPOR nicht signifikant (z (N = 92) = $-$~1,196 / p = ,232) bzw. (z (N = 92) = $-$~,735 / p = ,462).

\subsubsubsection{Korrelation zwischen den Differenzen in den AEM-Scores und der Qualität}

Nach der Regelanwendung stieg die Qualität leicht (nicht signifikant, \sectref{sec:5.3.8.4}). Mithilfe des Spearman-Korrelationstests erwies sich ein signifikanter mittlerer positiver Zusammenhang zwischen den Differenzen in den AEM-Scores von TERbase und hLEPOR und der Differenz in der allgemeinen Qualität. Bei der Vermeidung von überflüssigen Präfixen verbesserten sich die Scores der beiden AEMs und die Qualität nahm zu. \tabref{tab:05:79} demonstriert die Korrelationswerte.


\begin{table}
\begin{tabularx}{\textwidth}{Xrrrr}

\lsptoprule
& \textbf{N} & { \textbf{Signifikanz} } & \textbf{Korrelations-} & \textbf{Stärke}\\
& & \textbf{(p)} & \textbf{koeffizient} & \textbf{der}\\
& & &  \textbf{(ρ)} &  \textbf{Korrelation}\\
\midrule
Korrelation zw. Differenz in der allg. Qualität und Differenz des TERbase-Scores (nach KS $-$ vor KS) & { 92} & < ,001 & ,440 & \makecell[tr]{mittlerer\\Zusammen-\\hang}\\
\tablevspace
Korrelation zw. Differenz in der allg. Qualität und Differenz des hLEPOR-Scores (nach KS $-$ vor KS) & 92 & < ,001 & ,483 & \makecell[tr]{mittlerer\\Zusammen-\\hang}\\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:79}„Überfl. Präfixe verm.“ -- Korrelation zwischen den Differenzen der AEM-Scores und den Qualitätsdifferenzen   }
\bspnote{{ schwache Korrelation (ρ >=0,1)}\hspace{1em}{ mittlere Korrelation (ρ >= 0,3)}\hspace{1em}starke Korrelation (ρ >= 0,5)}
\end{table}

Die Korrelationswerte deuten darauf hin, dass die Scores der beiden AEMs sich relativ synchron in die gleiche Richtung wie die allgemeine Qualität bewegten.

\subsubsection{\label{sec:5.3.8.7}Analyse der achten Regel -- Validierung der Hypothesen}

Um die vorgestellten Ergebnisse auf die Forschungsfragen der Studie zurückzuführen, listet dieser Abschnitt die zugrunde liegenden Hypothesen der Forschungsfragen zusammen mit einer Zusammenfassung der Ergebnisse der achten analysierten Regel in tabellarischer Form auf. Für einen schnelleren Überblick steht (+) für eine Verbesserung bzw. einen Anstieg z.~B. im Sinne eines Qualitätsanstiegs, verbesserter AEM-Scores oder eines Anstiegs der Fehleranzahl; ($-$) steht für einen Rückgang; die \txgreen{grüne} Farbe symbolisiert eine signifikante Veränderung; \textit{neg} steht für eine negative Korrelation und \textit{pos} für eine positive Korrelation; <{}<{}>{}> steht für eine starke Korrelation und <> für eine mittlere Korrelation.\footnote{\textrm{Schwache Korrelationen werden in dieser Übersicht nicht angezeigt.}}

\subsubsubsection*{\textbf{Regel 8: Überflüssige Präfixe vermeiden}}

\paragraph*{Erster Analysefaktor: Vergleich der Fehleranzahl mit vs. ohne überflüssige Präfixe}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Gibt es einen Unterschied in der Fehleranzahl nach der Anwendung der KS-Regel im Vergleich zu vor der Anwendung?
\item [H0 --] Es gibt keinen Unterschied in der Fehleranzahl vor vs. nach der Anwendung der KS-Regel.
\item [H1 --] Es gibt einen Unterschied in der Fehleranzahl vor vs. nach der Anwendung der KS-Regel.
\item [Resultat]
\end{description}
\noindent
\parbox[t]{.75\textwidth}{\textbf{Auf Regelebene:}}\\
\parbox[t]{.75\textwidth}{H0 wurde abgelehnt und somit H1 bestätigt.

Die Fehleranzahl sank signifikant, nachdem die überflüssigen Präfixe vermieden wurden.}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.2\textwidth}{
{ \textbf{Anz.F.}} \textbf{($-$)}\\
\\
}}

\noindent
\parbox[t]{.75\textwidth}{\textbf{Auf Regel- und MÜ-Systemebene:}}\\
\parbox[t]{.75\textwidth}{
Nur bei Bing sank die Fehleranzahl signifikant nach der Regelanwendung.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.2\textwidth}{
\textbf{Bi ($-$)}\\
}}

\medskip
\noindent
\parbox[t]{.75\textwidth}{
Bei allen anderen Systemen sank die Fehleranzahl leicht.
}
\parbox[t]{.04\textwidth}{}
\parbox[t]{.2\textwidth}{
{ \textbf{Go ($-$)}}{ \textbf{Lu ($-$)}}

{ \textbf{SD ($-$)}} \textbf{Sy ($-$)}
}

\hrule
\paragraph*{Zweiter Analysefaktor}\hfill\\
\begin{figure}
\torte[pin]{19}{16}{4}{81}
\caption{Aufteilung der Annotationsgruppen auf Regelebene}
\end{figure}

\begin{figure}
\begin{tikzpicture}
\tikzset{every node/.style={font=\scriptsize}};
	\begin{axis}[
	ybar,
	width = \textwidth,
  height = .5\textheight,
	axis lines* = left,
	ylabel = {\%},
	xtick = {3,9,15,21},
	xticklabels = {FF,FR,RF,RR},
  x tick label style ={yshift=-5pt},
	xtick=data,
  xlabel={Annotationsgruppe},
	ymin=0,
	ymax = 20,
  y filter/.code={\pgfmathparse{#1/120*100}\pgfmathresult},
%	bar shift = 0pt,
  bar width=9,
  enlarge x limits = .2,
%	nodes near coords,
%	legend pos= north east,
	legend style={at={(0.5,-0.15)},anchor=north},
	legend columns = {-1},
	]
	\addplot+[lsNightBlue]
	coordinates {
	(3,3)
	(9,4)
	(15,0)
	(21,17)
	};
	\addplot+[tmnlpone]
	coordinates {
	(3,3)
	(9,0)
	(15,0)
	(21,21)
	};
	\addplot+[tmnlptwo]
	coordinates {
	(3,4)
	(9,6)
	(15,2)
	(21,12)
	};
	\addplot+[tmnlpthree]
	coordinates {
	(3,6)
	(9,2)
	(15,1)
	(21,15)
	};
	\addplot+[tmnlpfour]
	coordinates {
	(3,3)
	(9,4)
	(15,1)
	(21,16)
	};
	\legend{Bing,Google,Lucy,SDL,Systran}
	\end{axis}
\end{tikzpicture}
\caption{Aufteilung der Annotationsgruppen auf Regel- und MÜ-Systemebene}
\end{figure}
\hrule
\paragraph*{Dritter Analysefaktor: Vergleich der Fehlertypen mit vs. ohne überflüssige Präfixe}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Beinhaltet die MÜ bestimmte Fehlertypen vor bzw. nach der Anwendung der KS-Regel?
\item [H0 --] Es gibt keinen Unterschied in der Häufigkeit der einzelnen Fehlertypen vor vs. nach der Anwendung der KS-Regel.
\item [H1 --] Es gibt einen Unterschied in der Häufigkeit der einzelnen Fehlertypen vor vs. nach der Anwendung der KS-Regel.
\item [Resultat]
\end{description}
\noindent
\parbox[t]{.8\textwidth}{\textbf{Auf Regelebene:}}\\
\parbox[t]{.8\textwidth}{
H1 wurde nur für einen Fehlertyp bestätigt.

Die Fehleranzahl von LX.4 „Zusätzliches Wort eingefügt“ sank nach der Vermeidung der überflüssigen Präfixe signifikant.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.15\textwidth}{
\textbf{LX.4 ($-$)}\\
\\
}}

\noindent
\parbox[t]{.8\textwidth}{\textbf{Auf Regel- und MÜ-Systemebene:}}\\
\parbox[t]{.8\textwidth}{
Auf Systemebene war die Fehleranzahl sowohl vor als auch nach der Regelanwendung sehr niedrig; es gab keinen bestimmten Fehlertyp, der nach der Regelanwendung statistisch signifikant beeinflusst wurde.
}
\parbox[t]{.04\textwidth}{}
\parbox[t]{.15\textwidth}{}
\smallskip
\hrule

\newpage
\paragraph*{Vierter Analysefaktor: Vergleich der MÜ-Qualität mit vs. ohne überflüssige Präfixe}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Gibt es einen Unterschied in der Stil- und Inhaltsqualität der MÜ der KS-Stelle nach der Anwendung der KS-Regel im Vergleich zu vor der Anwendung?
\item [H0 --] Es gibt keinen Qualitätsunterschied vor vs. nach der Anwendung der KS-Regel.
\item [H1 --] Es gibt einen Qualitätsunterschied vor vs. nach der Anwendung der KS-Regel.
\item [Resultat]
\end{description}
\noindent
\parbox[t]{.8\textwidth}{\textbf{Auf Regelebene:}}\\
\parbox[t]{.8\textwidth}{
H0 wurde nicht abgelehnt und somit konnte H1 nicht bestätigt werden.

Die Stil- und Inhaltsqualität stiegen leicht nach der Regelanwendung.
}
\parbox[t]{.04\textwidth}{}
\parbox[t]{.15\textwidth}{
{ \textbf{SQ (+)}}

 \textbf{CQ (+)}
}

\noindent
\parbox[t]{.8\textwidth}{\textbf{Auf Regel- und MÜ-Systemebene:}}\\
\parbox[t]{.8\textwidth}{
Die Differenzen in der Stil- und Inhaltsqualität bei allen Systemen waren (sehr) klein und entsprechend nicht signifikant.
}
\parbox[t]{.04\textwidth}{}
\parbox[t]{.15\textwidth}{}
\smallskip
\hrule
\paragraph*{Fünfter Analysefaktor: Korrelation zwischen den Fehlertypen und der Qualität}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Besteht ein Zusammenhang zwischen der Differenz in der Fehleranzahl eines bestimmten Fehlertyps (Fehleranzahl nach KS $-$ vor KS) und der Differenz in der Stil- bzw. Inhaltsqualität (Qualität nach KS $-$ vor KS)?
\item [H0 --] Es besteht kein Zusammenhang zwischen der Differenz in der Fehleranzahl eines bestimmten Fehlertyps und der Differenz in der Stil- bzw. Inhaltsqualität.
\item [H1 --] Es besteht ein Zusammenhang zwischen der Differenz in der Fehleranzahl eines bestimmten Fehlertyps und der Differenz in der Stil- bzw. Inhaltsqualität.
\newpage
\item [Resultat]
\end{description}
\noindent
\parbox[t]{.7\textwidth}{\textbf{Auf Regelebene:}}\\
\parbox[t]{.7\textwidth}{
H1 wurde für zwei Fehlertypen wie folgt bestätigt:

Es bestand ein signifikanter mittlerer negativer Zusammenhang zwischen der Differenz in der Fehleranzahl des LX.4 „Zusätzliches Wort eingefügt“ und SM.11 „Verwechslung des Sinns“ einzeln und den Differenzen in der Stil- und Inhaltsqualität.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.25\textwidth}{
{ \textbf{\textit{neg}} \textbf{LX.4 <> SQ}}

{ \textbf{\textit{neg}} \textbf{SM.11 <> SQ}}\\

{ \textbf{\textit{neg}} \textbf{LX.4 <> CQ}}

{ \textbf{\textit{neg}} \textbf{SM.11 <> CQ}}\\
}}

\noindent
\parbox[t]{.7\textwidth}{\textbf{Auf Regel- und MÜ-Systemebene:}}\\
\parbox[t]{.7\textwidth}{
Bei Bing bestand ein signifikanter \textit{starker} negativer Zusammenhang zwischen der Differenz in der Fehleranzahl des GR.8 „Falsches Verb“ und der Differenz in der Inhaltsqualität.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.25\textwidth}{
{ \textbf{Bi}}

 \textbf{\textit{neg}} \textbf{GR.8 <{}<{}>{}> CQ}\\
 \\
}}

\medskip
\noindent
\parbox[t]{.7\textwidth}{
Bei Lucy bestand ein signifikanter starker negativer Zusammenhang zwischen der Differenz in der Fehleranzahl des GR.8 „Falsches Verb“ und SM.11 „Verwechslung des Sinns“ und der Differenz der Stilqualität sowie ein signifikanter starker negativer Zusammenhang zwischen der Differenz in der Fehleranzahl des GR.8 „Falsches Verb“ und der Differenz in der Inhaltsqualität.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.25\textwidth}{
{ \textbf{Lu}}

{ \textbf{\textit{neg}} \textbf{GR.8 <{}<{}>{}> SQ}}

{ \textbf{\textit{neg}} \textbf{SM.11 <{}<{}>{}> SQ}}

\textbf{\textit{neg}} \textbf{GR.8 <{}<{}>{}> CQ}\\
\\
\\
}}

\medskip
\noindent
\parbox[t]{.7\textwidth}{
Bei SDL bestand ein signifikanter mittlerer negativer Zusammenhang zwischen der Differenz in der Fehleranzahl des LX.4 „Zusätzliches Wort eingefügt“ und der Differenz in der Stilqualität.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.25\textwidth}{
{ \textbf{SD}}

\textbf{\textit{neg}} \textbf{LX.4 <> SQ}\\
\\
}}

\medskip
\noindent
\parbox[t]{.7\textwidth}{
Bei Systran bestand ein signifikanter starker negativer Zusammenhang zwischen der Differenz in der Fehleranzahl des LX.4 „Zusätzliches Wort eingefügt“ und der Differenz in der Inhaltsqualität.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.25\textwidth}{
{ \textbf{Sy}}

\textbf{\textit{neg}} \textbf{LX.4 <{}<{}>{}> CQ}\\
\\
}}

\medskip
\noindent
\parbox[t]{.7\textwidth}{
Alle weiteren Korrelationen waren nicht signifikant.
}
\parbox[t]{.04\textwidth}{}
\parbox[t]{.25\textwidth}{}
\smallskip
\hrule
\paragraph*{Sechster Analysefaktor: Vergleich der MÜ-Qualität mit vs. ohne überflüssige Präfixe auf Annotationsgruppenebene}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Gibt es einen Unterschied in der Stil- und Inhaltsqualität bei den einzelnen Annotationsgruppen nach der Anwendung der KS-Regel im Vergleich zu vor der Anwendung?
\item [H0 --] Bei den Annotationsgruppen gibt es keinen Qualitätsunterschied vor vs. nach der Anwendung der KS-Regel.
\item [H1 --] Bei den Annotationsgruppen gibt es einen Qualitätsunterschied vor vs. nach der Anwendung der KS-Regel.
\item [Resultat]
\end{description}
\noindent
\parbox[t]{.8\textwidth}{
H1 wurde nur für die Gruppe FR bestätigt:

Bei der Annotationsgruppe FR stiegen die Stil- und Inhaltsqualität signifikant, nachdem das überflüssige Präfix vermieden wurde.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.15\textwidth}{
{ \textbf{SQ (+)}}

 \textbf{CQ (+)}\\
 \\
}}

\noindent
\parbox[t]{.8\textwidth}{
Bei der Annotationsgruppe RF sanken die Stil- und Inhaltsqualität leicht.
}
\parbox[t]{.04\textwidth}{}
\parbox[t]{.15\textwidth}{
\textbf{SQ ($-$)}

\textbf{CQ ($-$)}
}

\medskip
\noindent
\parbox[t]{.8\textwidth}{
Bei der Annotationsgruppe FF stiegen die Stil- und Inhaltsqualität minimal.
}
\parbox[t]{.04\textwidth}{}
\parbox[t]{.15\textwidth}{
{ \textbf{SQ (+)}}

\textbf{CQ (+)}
}

\medskip
\noindent
\parbox[t]{.8\textwidth}{
Bei der Annotationsgruppe RR sanken die Stil- und Inhaltsqualität leicht.
}
\parbox[t]{.04\textwidth}{}
\parbox[t]{.15\textwidth}{
{ \textbf{SQ ($-$)}}

\textbf{CQ ($-$)}
}
\smallskip
\hrule
\paragraph*{Siebter Analysefaktor: Vergleich der AEM-Scores mit vs. ohne überflüssige Präfixe}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Gibt es einen Unterschied in den AEM-Scores von TERbase bzw. hLEPOR nach der Anwendung der KS-Regel im Vergleich zu vor der Anwendung?
\item [H0 --] Es gibt keinen Unterschied in den AEM-Scores vor vs. nach der Anwendung der KS-Regel.
\item [H1 --] Es gibt einen Unterschied in den AEM-Scores vor vs. nach der Anwendung der KS-Regel.
\item [Resultat]
\end{description}
\noindent
\parbox[t]{.75\textwidth}{
H0 wurde nicht abgelehnt und somit konnte H1 nicht bestätigt werden.

Die AEM-Scores von TERbase und hLEPOR verbesserten sich nur leicht, nachdem das überflüssige Präfix vermieden wurde.
}
\parbox[t]{.04\textwidth}{}
\parbox[t]{.2\textwidth}{
{ \textbf{TERbase (+)}}

 \textbf{hLEPOR (+)}
}
\smallskip
\hrule
\paragraph*{Achter Analysefaktor: Korrelation zwischen den Differenzen in den AEM-Scores und der Qualität}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Besteht ein Zusammenhang zwischen der Differenz in den AEM-Scores von TERbase bzw. hLEPOR (Mittelwert der AEM-Scores nach KS $-$ vor KS) und der Differenz in der allgemeinen Qualität (Qualität nach KS $-$ vor KS)?
\item [H0 --] Es besteht kein Zusammenhang zwischen der Differenz in den AEM-Scores und der Differenz in der allgemeinen Qualität.
\item [H1 --] Es besteht ein Zusammenhang zwischen der Differenz in den AEM-Scores und der Differenz in der allgemeinen Qualität.
\item [Resultat]
\end{description}
\noindent
\parbox[t]{.7\textwidth}{
H0 wurde abgelehnt und somit H1 bestätigt.

Es bestand ein signifikanter mittlerer positiver Zusammenhang zwischen den Differenzen der Scores der beiden AEMs (TERbase und hLEPOR) und der Differenz in der allgemeinen Qualität.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.25\textwidth}{
{ \textbf{\textit{pos}} \textbf{TERbase <> Q}}

 \textbf{\textit{pos}} \textbf{hLEPOR <> Q}\\
 \\
 \\
}}


\subsection{NEUNTE REGEL: Keine Wortteile weglassen}
\label{sec:5.3.9}
 \subsubsection{\label{sec:5.3.9.0}Überblick}

%In \tabref{tab:05:80}
Im Folgenden wird die KS-Regel „Keine Wortteile weglassen“ kurz beschrieben.\footnote{\textrm{Die für diese Regel relevanten Kontraste im Sprachenpaar DE-EN sind unter \sectref{sec:4.4.2.3} erörtert.} } Zudem wird zusammenfassend und anhand eines Beispiels demonstriert, wie die Regel bei der Analyse angewendet wurde. Anschließend wird die Aufteilung der Testsätze im Datensatz dargestellt:

\begin{description}[font=\normalfont\bfseries]
\item [Beschreibung der KS-Regel:] \textbf{Keine Wortteile weglassen} (tekom-Regel-Nr. S 204)

Nach dieser Regel sollen die Wörter vollständig geschrieben werden (\citealt[68]{tekom2013}).

Begründung: Ziel der Regel ist die Unterstützung des Verständnisses. Insbesondere bei der Übersetzung ist das Weglassen von Wortteilen ungeeignet. (ebd.)

\item[Umsetzungsmuster:]
~\\
\textbf{Vor KS:} Der Satz beinhaltet Wortteile.\\
\textbf{Nach KS:} Die fehlenden Wortteile werden vervollständigt.

\item[KS-Stelle]
~\\
\textbf{Vor KS:} Wörter mit den weggelassenen Teilen\\
\textbf{Nach KS:} vollständige Wörter

\item[Beispiele]
~\\
\textit{Die \txgray{Ist- und Sollwerte} des zweiten Regelkreises werden nach der Konfiguration angezeigt.}

\textit{Der \txgray{Istwert und der Sollwert} des zweiten Regelkreises werden nach der Konfiguration angezeigt.}

\item[Aufteilung der Testsätze:]
Der Datensatz besteht aus 24 verschiedenen Begriffen mit unterschiedlichen Wortteilen. Die Geläufigkeit der untersuchten Begriffe wurde anhand der Anzahl der Treffer bei einer Google-Suche gemessen. Die Aufteilung der untersuchten Begriffe war wie folgt:

1 Begriff mit > 1.000.000 Treffern;

3 Begriffe mit > 100.000 und < 1.000.000 Treffern;

7 Begriffe mit > 1.000 und < 100.000 Treffern;

13 Begriffe mit < 1.000 bis 0 Treffer.

\end{description}

%\multicolumn{2}{p{6cm}}{\label{bkm:Ref36850783}Eckdaten der neunten Regel „Keine Wortteile weglassen“}\\
%\lspbottomrule
%\end{tabularx}\caption{\label{tab:05:80}   }
%\end{table}

Im Weiteren werden die Ergebnisse der einzelnen Analysefaktoren präsentiert.

\subsubsection{Vergleich der Fehleranzahl vor vs. nach dem Weglassen von Wortteilen}
\label{sec:5.3.9.1}

Die Fehleranzahl sank minimal um 6,6~\% von 76 Fehlern bei dem Weglassen von Wortteilen (M = ,63 / SD = ,788 / N = 120) auf 71 Fehler bei der Verwendung von vollständigen Wörtern (M = ,59 / SD = ,815 / N = 120), siehe \figref{fig:05:124}. Der Mittelwert der Differenz (nach KS $-$ vor KS) in der Fehleranzahl pro Satz lag somit bei $-$~,04 (SD = ,864) mit einem 95\%\nobreakdash-Konfidenzintervall zwischen einem Minimum von $-$~,21 (SD = ,700) und einem Maximum von ,12 (SD = 1,014) (Bootstrapping mit 1000 Stichproben), siehe \figref{fig:05:125}. Die Differenz (nach KS $-$ vor KS) in der Fehleranzahl war entsprechend nicht signifikant (z (N = 120) = $-$~,445 / p = ,656).


\begin{figure}
%\includegraphics[height=.3\textheight]{figures/d3-img023.png}



%\includegraphics[height=.3\textheight]{figures/d3-img023.png}



%\includegraphics[height=.3\textheight]{figures/d3-img023.png} &  &
%\includegraphics[height=.3\textheight]{figures/d3-img024.png}

%\textbf{,45,73}

%\textbf{,49,78}



%\includegraphics[height=.3\textheight]{figures/d3-img024.png}



%\includegraphics[height=.3\textheight]{figures/d3-img024.png}\\
\captionsetup{width=.45\textwidth}
\begin{floatrow}
\ffigbox[.5\textwidth]{\caption{„Keine Wortteile wegla.“ -- Fehlersumme vor vs. nach KS}
\label{fig:05:124}}{
\begin{tikzpicture}
	\begin{axis}[
	ybar,
	ymin = 0,
	ymax = 125,
	axis lines* = left,
	nodes near coords,
%         nodes near coords align = vertical,
  legend style={at={(0.5,-0.2)},anchor=north,cells={align=left}},
  xtick=\empty,
  width = .45\textwidth,
  enlarge x limits = .5
	]
	\addplot+[tmnlpone]
	coordinates{
	(1,76)
	};
	\addplot+[tmnlpthree]
	coordinates{
	(2,71)
	};
	\legend{Anzahl der  fehler\\innerh. KS vor KS,Anzahl der Fehler\\innerh. KS nach KS}
	\end{axis}
\end{tikzpicture}
}
\ffigbox[.45\textwidth]{\caption{„Keine Wortteile wegla.“ -- Mittelwert der Fehleranzahl pro Satz vor vs. nach KS}\label{fig:05:125}}{
\includegraphics[width=.25\textwidth]{figures/Abb125.png}
\includegraphics[width=.4\textwidth]{figures/Abb21-legend.png}
}
\end{floatrow}
\end{figure}

Es wurde bei dieser Regel angenommen, dass der Geläufigkeitsgrad der abgekürzten Begriffe eine Rolle bei der Korrektheit von deren Übersetzung spielt.\footnote{\textrm{Da die Studie generische Black-Box-Systeme untersuchte, bei denen keine Terminologieintegration erfolgen konnte, wurden firmen- und produktspezifische Termini durch geläufige Begriffe ersetzt. Für die Auswahlkriterien der untersuchten Systeme siehe \sectref{sec:4.4.1}. Für den genauen Umgang mit den spezifischen Termini im Rahmen der Studie siehe Schritt [4] unter \sectref{sec:4.4.3.1}.}} Die Grundidee dieser Annahme ist, dass gebräuchliche abgekürzte Begriffe in ihrer abgekürzten Form in den MÜ-Systemen lexikalisch hinterlegt sind oder in den Trainingsdaten vorkommen). Dementsprechend wäre in diesem Fall die Wahrscheinlichkeit einer korrekten Übersetzung hoch und die Anwendung der Regel nicht erforderlich. Bei ungebräuchlichen abgekürzten Begriffen hingegen wurde erwartet, dass die Verwendung der vollständigen Wörter (d.~h. die Anwendung der Regel) eine korrekte MÜ fördert. Der Geläufigkeitsgrad der Begriffe wurde im Sinne der Anzahl der Treffer bei einer Google-Suche ermittelt (\tabref{tab:05:81}).


\begin{table}
\small
\begin{tabularx}{\textwidth}{Xllll}

\lsptoprule
& \multicolumn{4}{c}{\textbf{Abgekürzte Begriffe nach ihren Geläufigkeiten}}\\
\cmidrule(lr){2-5}
& \multicolumn{2}{c}{\textbf{hoch}} & \textbf{moderat}  & \textbf{niedrig} \\
\midrule
\textbf{Anz. Treffer Google-Suche} & > 1.000.000 & \makecell[tl]{> 100.000 und\\< 1.000.000} & \makecell[tl]{> 1.000 und\\< 100.000} & < 1.000 bis 0 \\
\tablevspace
\textbf{Anzahl der Fälle} & 1 x 5 MÜ & 3 x 5 MÜ & 7 x 5 MÜ & 13 x 5 MÜ\\
\tablevspace
\textbf{Durchschnittliche Diff. F.Anz. (nach KS $-$ vor KS)} & 0 & 0 & 0,29 & $-$~,69\\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:81}Daten und Fehleranzahlveränderung der untersuchten Fälle   }
\end{table}

\tabref{tab:05:81} zeigt die Aufteilung des Datensatzes (24 Sätze x 5 MÜ) nach dem Geläufigkeitsgrad der untersuchten Begriffe sowie die Differenz in der Fehleranzahl bei jeder Gruppe. Alle untersuchten Begriffe hatten im Suchvorgang deutlich mehr Treffer in ihrer abgekürzten Form als in ihrer vollständigen. Bei einer hohen Geläufigkeit (4 Fälle) gab es keine Differenz in der Fehleranzahl. Die MÜ-Systeme konnten die Begriffe sowohl in ihrer abgekürzten als auch in ihrer vollständigen Form fehlerfrei übersetzen. Wie die Qualitätswerte in den beiden fehlerfreien Szenarien ausfielen, wird unter \sectref{sec:5.3.9.4} erläutert. Bei einer moderaten Geläufigkeit (7 Fälle) stieg die Fehleranzahl bei der Verwendung der vollständigen Form der Wörter (nach KS). Ein Beispiel dieser Fälle ist der Begriff ‚Bedienungs- und Pflegehinweise‘. Dieser Begriff hat bei der Google-Suche 6.100 Treffer in seiner abgekürzten Form bzw. 9 Treffer in seiner vollständigen Form ergeben. Da diese Gruppe der Begriffe eher in ihrer abgekürzten Form geläufig ist, stieg die Fehleranzahl bei der Verwendung der vollständigen Form (nach KS) (durchschnittlicher Anstieg von 0,29). Bei einer sehr niedrigen Geläufigkeit der Begriffe (13 Fälle) handelt es sich um Begriffe, die in ihrer abgekürzten Form nicht geläufig sind. Hierbei war die Annahme, dass die Verwendung der vollständigen Form die MÜ erleichtern würde (z. B. ‚Soja- und laktosefreie Milch‘ als ‚Sojamilch und laktosefreie Milch‘). Tatsächlich sank die Fehleranzahl bei diesen Fällen nach der Regelanwendung (durchschnittlicher Rückgang von $-$~,69). Aufgrund der kleinen Anzahl der Fälle jeder Gruppe bedarf jedoch die Annahme über einen Zusammenhang zwischen dem Geläufigkeitsgrad und der Korrektheit der MÜ weiterer Forschung.

\subsubsubsection{Vergleich der Fehleranzahl auf Regel- und MÜ-Systemebene}

Auf Systemebene war die Veränderung in der Fehleranzahl insignifikant. Bei drei Systemen sank die Fehleranzahl (\figref{fig:05:126}): NMÜ-System Google Translate (Mdiff = $-$~0,083); HMÜ-System Systran (Mdiff = $-$~0,125); RBMÜ-System Lucy (Mdiff = $-$~0,125). Bei dem SMÜ-System SDL blieb die Fehleranzahl unverändert. Das HMÜ-System Bing\textbf{ }war das einzige System, bei dem die Fehleranzahl stieg (Mdiff =~0,125).


\begin{figure}
%\textbf{$-$ 13,0~\%}

%\textbf{$-$ 13,6~\%}

%\textbf{+~27,3~\%}

%\textbf{0~\%}{}

%\textbf{$-$ 28,6~\%}



%\includegraphics[height=.3\textheight]{figures/d3-img101.png}


%\includegraphics[height=.3\textheight]{figures/d3-img023.png}\\
\begin{tikzpicture}
	\begin{axis}[
	ybar,
	ymin = 0,
	ymax = 25,
	axis lines* = left,
	nodes near coords,
  legend style={at={(0.5,-0.2)},anchor=north},
  xticklabels = {Bing,Google,Lucy,SDL,Systran},
  xtick=data,
  ylabel = {Summe},
  extra description/.code={
            \node at (axis cs:-.5, 18)[anchor=west] {$+$ 27,3 \%};
						\node at (axis cs:.5, 10)[anchor=west] {$-$ 28,6 \%};
						\node at (axis cs:1.5, 26)[anchor=west] {$-$ 13,0 \%};
						\node at (axis cs:2.8, 18)[anchor=west] {0 \%};
						\node at (axis cs:3.5, 26)[anchor=west] {$-$ 13,6 \%};
						}
	]
	\addplot+[tmnlpone]
	coordinates{
	(0,11)
	(1,7)
	(2,23)
	(3,13)
	(4,22)
	};
	\addplot+[tmnlpthree]
	coordinates{
	(0,14)
	(1,6)
	(2,20)
	(3,13)
	(4,19)
	};
	\legend{Anzahl der  fehler innerh. KS vor KS,Anzahl der Fehler innerh. KS nach KS}
	\end{axis}
\end{tikzpicture}
\caption{\label{fig:05:126}„Keine Wortteile wegla.“ -- Summe der Fehleranzahl vor vs. nach KS bei den einzelnen MÜ-Systemen   }
\bspnote{\bfitul{Signifikante Differenz vor vs. nach KS}}
\end{figure}

\tabref{tabex:05:85} bietet einen Vergleich zwischen der MÜ von SDL und Google Translate an.


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & Die \textbf{Anwärm- und Entwässerungsvorgänge} sind gemäß der Betriebsanleitung zu beachten.\\
\tablevspace
SMÜ SDL & The \txblue{warm up and drainage operations} have to be observed in accordance with the operating instructions.\\
GNMÜ & The \txblue{heating and de-watering procedures} have to be observed in accordance with the operating instructions.\\
\midrule
\textbf{Nach-KS} & Der \textbf{Anwärmvorgang und der Entwässerungsvorgang} sind gemäß der Betriebsanleitung zu beachten.\\
\tablevspace
SMÜ SDL & The \txred{Anwarmvorgang} \txblue{and drainage operations} have to be observed in accordance with the operating instructions.\\
GNMÜ & The \txblue{heating process and the dewatering process} have to be observed in accordance with the operating instructions.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:85}Beispiel 85   }
\bspnote{ Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

Wie das Beispiel zeigt, konnte SDL die abgekürzte Form des Begriffs ‚Anwärmvorgang‘ vor der Regelanwendung übersetzen, während die vollständige Form desselben Begriffs unübersetzt blieb. Google Translate hingegen konnte beide Versionen fehlerfrei übersetzen. Inwiefern die Qualität der MÜ in den beiden Fällen akzeptabel ist, wird unter \sectref{sec:5.3.9.4} diskutiert.

\subsubsection{\label{sec:5.3.9.2}Aufteilung der Annotationsgruppen}

Wie \figref{fig:05:127} demonstriert, waren knapp 43~\% der Übersetzungen sowohl vor als auch nach dem Weglassen der Wortteile fehlerfrei (Gruppe RR). Gleichzeitig war die zweitgrößte Gruppe FF (ca. 28~\%) mit MÜ, die sowohl vor als auch nach dem Weglassen der Wortteile Fehler beinhalteten. Die Fehlertypen werden genauer unter \sectref{sec:5.3.9.3} analysiert.


\begin{figure}
%\includegraphics[height=.3\textheight]{figures/d3-img102.png}

%\includegraphics[height=.3\textheight]{figures/d3-img012.png}
% 127
\torte{34}{22}{13}{51}
\caption{\label{fig:05:127}„Keine Wortteile wegla.“ -- Aufteilung der Annotationsgruppen   }
\end{figure}

Bei ca. 18~\% der Fälle (Gruppe FR) unterstützte die Regel die MÜ-Systeme dabei, die vor KS aufgetretenen Fehler zu eliminieren. Gleichzeitig traten bei knapp 11~\% der Fälle Fehler erst nach der Regelanwendung auf (Gruppe RF). Inwiefern das Auftreten bzw. die Eliminierung von Fehlern die MÜ-Qualität beeinflusste, wird unter \sectref{sec:5.3.9.4} und \sectref{sec:5.3.9.5} diskutiert.

\subsubsubsection{Vergleich der Aufteilung der Annotationsgruppen auf Regel- und MÜ-Systemebene}

Die Gruppe RR war bei drei Systemen die größte, so war sie bei dem NMÜ-System Google Translate mit 75~\%, dem SMÜ-System SDL mit 46~\% und dem HMÜ-Systems Bing mit 38~\% repräsentiert (\figref{fig:05:128}). Diese drei Systeme waren in der Lage, die genannten Anteile der Sätze sowohl bei Verwendung der abgekürzten Form als auch der vollständigen Form der untersuchten Begriffe fehlerfrei zu übersetzen. Auf der anderen Seite war die Gruppe FF hoch repräsentiert bei dem HMÜ-System Systran mit 46~\% und dem RBMÜ-System Lucy mit 38~\%. Gleichzeitig -- wie \figref{fig:05:128} zeigt -- ist das Ergebnis bei allen Systemen mit Ausnahme des NMÜ-Systems Google Translate sehr gemischt. Nur bei Google Translate gab es gar keine Sätze, die vor der Regelanwendung richtig übersetzt wurden und nachher falsch (Gruppe RF).


\begin{figure}
%    \textbf{17\% 17\% 38\%25\% 46\%}          \textbf{25\%}  \textbf{8\%}  \textbf{25\% 17\% 17\%}          \textbf{21\%}         \textbf{13\%13\%}  \textbf{8\%}            \textbf{38\%75\% 25\% 46\% 29\%}



%\includegraphics[height=.3\textheight]{figures/d3-img103.png}



%\includegraphics[height=.3\textheight]{figures/d3-img026.png}\\
\begin{tikzpicture}
\tikzset{every node/.style={font=\scriptsize}};
	\begin{axis}[
	ybar,
	width = \textwidth,
	axis lines* = left,
	ylabel = {Anzahl},
	xtick = {3,9,15,21},
	xticklabels = {FF,FR,RF,RR},
  x tick label style ={yshift=-5pt},
	xtick=data,
  xlabel={Annotationsgruppe},
	ymin=0,
	ymax = 20,
%	bar shift = 0pt,
  bar width=9,
  enlarge x limits = .2,
	nodes near coords,
%	legend pos= north east,
	legend style={at={(0.5,-0.15)},anchor=north},
	legend columns = {-1},
	extra description/.code={
  \node at (axis cs:.3,5.5)[anchor = west]{3,3\%};
	\node at (axis cs:.3,-.5)[anchor = west]{17\%};
	\node at (axis cs:1.2,6)[anchor = west]{3,3\%};
	\node at (axis cs:1.2,-.5)[anchor = west]{17\%};
	\node at (axis cs:2,10.5)[anchor = west]{7,5\%};
	\node at (axis cs:2.1,-.5)[anchor = west]{38\%};
	\node at (axis cs:3.1,7.5)[anchor = west]{5,0\%};
	\node at (axis cs:3.1,-.5)[anchor = west]{25\%};
	\node at (axis cs:4,12.5)[anchor = west]{9,2\%};
	\node at (axis cs:4.1,-.5)[anchor = west]{46\%};
	\node at (axis cs:6.4,7.5)[anchor = west]{5,0\%};
	\node at (axis cs:6.4,-.5)[anchor = west]{25\%};
  \node at (axis cs:7.4,3.5)[anchor = west]{1,7\%};
	\node at (axis cs:7.4,-.5)[anchor = west]{8\%};
\node at (axis cs:8.4,7.5)[anchor = west]{5,0\%};
\node at (axis cs:8.2,-.5)[anchor = west]{25\%};
	\node at (axis cs:9.2,5.5)[anchor = west]{3,3\%};
	\node at (axis cs:9.2,-.5)[anchor = west]{17\%};
  \node at (axis cs:10.2,6)[anchor = west]{3,3\%};
	\node at (axis cs:10.2,-.5)[anchor = west]{17\%};
\node at (axis cs:12.5,6.5)[anchor = west]{4,2\%};
\node at (axis cs:12.5,-.5)[anchor = west]{21\%};
%  \node at (axis cs:13.3,3)[anchor = west]{1,7\%};
%	\node at (axis cs:13.4,-.5)[anchor = west]{8\%};
	\node at (axis cs:14.1,4.5)[anchor = west]{2,5\%};
	\node at (axis cs:14.1,-.5)[anchor = west]{13\%};
  \node at (axis cs:15,5)[anchor = west]{2,5\%};
	\node at (axis cs:15,-.5)[anchor = west]{13\%};
  \node at (axis cs:16,3.5)[anchor = west]{1,7\%};
	\node at (axis cs:16,-.5)[anchor = west]{8\%};
	\node at (axis cs:18.4,10.5)[anchor = west]{7,5\%};
	\node at (axis cs:18.4,-.5)[anchor = west]{38\%};
	\node at (axis cs:19.3,19.5)[anchor = west]{15,0\%};
	\node at (axis cs:19.4,-.5)[anchor = west]{75\%};
	\node at (axis cs:20.3,7.5)[anchor = west]{5,0\%};
	\node at (axis cs:20.3,-.5)[anchor = west]{25\%};
	\node at (axis cs:21.1,12.5)[anchor = west]{9,2\%};
	\node at (axis cs:21.3,-.5)[anchor = west]{46\%};
	\node at (axis cs:22.1,8.5)[anchor = west]{5,8\%};
	\node at (axis cs:22.2,-.5)[anchor = west]{29\%};
	}
	]
	\addplot+[lsNightBlue]
	coordinates {
	(3,4)
	(9,6)
	(15,5)
	(21,9)
	};
	\addplot+[tmnlpone]
	coordinates {
	(3,4)
	(9,2)
	(15,0)
	(21,18)
	};
	\addplot+[tmnlptwo]
	coordinates {
	(3,9)
	(9,6)
	(15,3)
	(21,6)
	};
	\addplot+[tmnlpthree]
	coordinates {
	(3,6)
	(9,4)
	(15,3)
	(21,11)
	};
	\addplot+[tmnlpfour]
	coordinates {
	(3,11)
	(9,4)
	(15,2)
	(21,7)
	};
	\legend{Bing,Google,Lucy,SDL,Systran}
	\end{axis}
\end{tikzpicture}
\caption{\label{fig:05:128}„Keine Wortteile wegla.“ -- Aufteilung der Annotationsgruppen bei den einzelnen MÜ-Systemen   }
\bspnote{Die oben angezeigten Prozentzahlen sind für alle Systeme, d. h. systemübergreifend, (N = 120) berechnet.

Die untenstehenden Prozentzahlen sind auf Systemebene (N = 24) berechnet.}
\end{figure}

Zu beobachten ist auch, dass die Gruppe FR größer als RF war. Welche Fehlertypen nach der Regelanwendung auftraten bzw. eliminiert wurden, werden unter \sectref{sec:5.3.9.3} dargestellt. Die Gruppe RF war -- vor allem bei Bing -- relativ hoch vertreten. Betrachten wir \tabref{tabex:05:86}, in dem Bing nur nach der Regelanwendung eine falsche MÜ lieferte, während Google Translate in beiden Szenarien fehlerfrei übersetzen konnte.


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & Trennen Sie alle  \textbf{Spannungs- und Druckquellen} von der Maschine.\\
\tablevspace
HMÜ Bing & Disconnect all \txblue{voltage and pressure sources} from the machine.\\
GNMÜ & Disconnect all \txblue{voltage and pressure sources} from the machine.\\
\midrule
\textbf{Nach-KS} & Trennen Sie alle \textbf{Spannungsquellen und Druckquellen} von der Maschine.\\
\tablevspace
HMÜ Bing & Disconnect all \txblue{power sources and} \txred{print} \txblue{sources} from the machine.\\
GNMÜ & Disconnect all \txblue{voltage sources and pressure sources} from the machine.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:86}Beispiel 86   }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

‚Spannungs- und Druckquellen‘ ist ein Begriff, der ungeläufig ist. In einer Google-Suche gab es gar keinen Treffer weder für diese abgekürzte Form (vor~KS) noch für die vollständige Form ‚Spannungsquellen und Druckquellen‘ (nach KS). Die Verwendung der vollständigen Form zeigte sich nicht sinnvoll im Fall von Bing. Es trat ein semantischer Fehler auf (‚print‘ anstelle von ‚pressure‘ als Übersetzung für ‚Druck‘). Dieser Fehler kann in der Praxis durch eine Terminologieintegration vermieden werden. Gleichzeitig konnte Google Translate beide Formen fehlerfrei übersetzen. Wie die Qualitätsanalyse unter \sectref{sec:5.3.9.4} mehr verrät, sanken die Qualitätswerte bei den beiden Systemen nach der Regelanwendung, wie es der Fall in \tabref{tabex:05:86} ist.

\subsubsection{\label{sec:5.3.9.3}Vergleich der Fehlertypen vor vs. nach dem Weglassen von Wortteilen}

Nach der Regelanwendung sank die Fehleranzahl bei dem Fehlertyp OR.1 „Orthografie – Zeichensetzung“ von 16 auf 6 ($-$~62,5~\% / Mv = ,13 / SDv = ,409 / Mn = ,05 / SDn = ,254 / N = 120), siehe \figref{fig:05:129}. Der Unterschied in der Fehleranzahl erwies sich als signifikant (p = ,039 / N = 120). Bei allen anderen Fehlertypen veränderte sich die Fehleranzahl nach der Regelanwendung nicht deutlich.


\begin{figure}
%\includegraphics[height=.3\textheight]{figures/d3-img104.png}

%\textbf{\textit{$-$ 62,5~\%}}



%\includegraphics[height=.3\textheight]{figures/d3-img027.png}

%\includegraphics[height=.3\textheight]{figures/d3-img013.png}



%\includegraphics[height=.3\textheight]{figures/d3-img013.png} & vor KS
% 129
\pgfplotstableread{
1 16
2 6
3 3
4 1
5 9
6 4
7 1
8 5
9 1
10 5
11 0
12 0
13 7
14 4
15 0
16 0
17 6
18 7
19 2
20 3
21 24
22 27
23 6
24 9
25 1
26 0
}\datatable
\smbars[extra description/.code={
\node at (axis cs:.2,20)[anchor = west]{\bfitul{$-$ 62,5 \%}};
}]{}
\caption{\label{fig:05:129}„Keine Wortteile wegla.“ -- Summe der Fehleranzahl der einzelnen Fehlertypen vor vs. nach KS   }
\bspnote{*Die X-Achse ist folgendermaßen zu lesen: Jeder Fehlertyp wird anhand von zwei Balken abgebildet. Der erste Balken repräsentiert die Summe der Fehler \textit{vor KS} und der zweite die Summe der Fehler \textit{nach KS}, somit steht z.~B. „OR\_1.v“ für „OR\_1: orthografischer Fehler Nr. 1“ und „v: vor KS“; „OR\_1.n“ wäre entsprechend das Pendant zu „OR\_1.v“ für das nach-KS-Szenario („n“).\\
**\bfitul{Signifikante Differenz vor vs. nach KS}\\
OR.1: Orthografie -- Zeichensetzung\\
OR.2: Orthografie -- Großschreibung\\
LX.3: Lexik -- Wort ausgelassen\\
LX.4: Lexik -- Zusätzliches Wort eingefügt\\
LX.5: Lexik -- Wort unübersetzt geblieben (auf DE wiedergegeben)\\
LX.6: Lexik -- Konsistenzfehler\\
GR.7: Grammatik -- Falsche Wortart / Wortklasse\\
GR.8: Grammatik -- Falsches Verb (Zeitform, Komposition, Person)\\
GR.9: Grammatik -- Kongruenzfehler (Agreement)\\
GR.10: Grammatik -- Falsche Wortstellung\\
SM.11: Semantik -- Verwechslung des Sinns\\
SM.12: Semantik -- Falsche Wahl\\
SM.13: Semantik -- Kollokationsfehler}
\end{figure}

Die Verwendung des Bindestriches (bzw. des Ergänzungsstriches) beim Weglassen von Wortteilen (vor KS) war mit einer falschen Zeichensetzung verbunden. Die Regeln der Bindestrichsetzung im Deutschen und im Englischen unterscheiden sich. Daher war eine korrekte Bindestrichsetzung (vor KS) in manchen Fällen problematisch. Nachdem vollständige Wörter verwendet wurden (nach KS), wurde dieser Fehler in mehreren Übersetzungen behoben. \tabref{tabex:05:87} demonstriert diesen Fall.


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & Sogar \textbf{Soja- und laktosefreie Milch} lassen sich mit dieser Maschine perfekt aufschäumen. \\
\tablevspace
RBMÜ Lucy & Even \txred{Soya-} \txblue{and lactose-free milk} can be perfectly frothed with this machine.\\
\midrule
\textbf{Nach-KS} & Sogar \textbf{Sojamilch und laktosefreie Milch} lassen sich mit dieser Maschine perfekt aufschäumen. \\
\tablevspace
RBMÜ Lucy & Even \txblue{soya milk and lactose-free milk} can be perfectly frothed with this machine.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:87}Beispiel 87   }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

Im Englischen wird der Bindestrich in Verbindung mit Adjektiven, nicht mit Substativen, wie es hier der Fall im Deutschen ist, verwendet. Daher trat der Zeichensetzungsfehler (OR.1) in ‚Soya-‘ auf. Zudem trat ein weiterer orthografischer Fehler auf, nämlich der Großschreibungsfehler (OR.2) ebenfalls in dem Wort ‚Soya‘. Nach der Regelanwendung wurden beide Fehler behoben.

\subsubsubsection{Vergleich der Fehlertypen auf Regel- und MÜ-Systemebene}

Eine genauere Untersuchung der Fehlertypen bei den verschiedenen MÜ-Syste\-men zeigt (\figref{fig:05:130}), dass Fehlertyp OR.1 „Zeichensetzung“ bei dem RBMÜ-System Lucy und dem HMÜ-System Systran sank und bei dem HMÜ-System Bing und dem NMÜ-System Google Translate vollständig behoben wurde.


\begin{figure}

%\includegraphics[height=.3\textheight]{figures/d3-img105.png}



%\includegraphics[height=.3\textheight]{figures/d3-img026.png}\\

\begin{tikzpicture}
\tikzset{every node/.style={font=\scriptsize}};
	\begin{axis}[
	xbar,
	width = \textwidth,
	height = .83\textheight,
	axis lines* = left,
	xlabel = {Summe},
	ytick = {1,2,3,...,20},
	yticklabels = {IN\_OR\_1.v,
  IN\_OR\_1.n,
  IN\_OR\_2.v,
  IN\_OR\_2.n,
  IN\_LX\_3.v,
	IN\_LX\_3.n,
	IN\_LX\_4.v,
	IN\_LX\_4.n,
  IN\_LX\_5.v,
	IN\_LX\_5.n,
  IN\_GR\_7.v,
	IN\_GR\_7.n,
	IN\_GR\_9.v,
	IN\_GR\_9.n,
	IN\_GR\_10.v,
	IN\_GR\_10.n,
	IN\_SM\_11.v,
	IN\_SM\_11.n,
	IN\_SM\_12.v,
	IN\_SM\_12.n
	},
%	x tick label style={rotate=60,anchor=east,font=\scriptsize},
	enlarge y limits={.032},
	xmin=0,
	xmax = 10,
%	bar shift = 1pt,
  	bar width=2,
	nodes near coords,
	legend pos = south east,
	reverse legend,
%	legend style={at={(0.5,-0.1)},anchor=north},
%	legend columns = {-1},
	]
	\addplot+[tmnlpone]
	coordinates {
	(1,1)
	(0,2)
	(0,3)
	(0,4)
	(5,5)
	(2,6)
	(0,7)
	(1,8)
	(0,9)
	(1,10)
	(0,11)
	(1,12)
	(1,13)
	(2,14)
  (0,15)
  (2,16)
  (4,17)
  (4,18)
  (0,19)
  (1,20)
	};
	\addplot+[lsLightOrange]
	coordinates {
	(3,1)
	(0,2)
	(0,3)
	(0,4)
	(0,5)
	(0,6)
	(0,7)
	(0,8)
	(0,9)
	(0,10)
	(0,11)
	(0,12)
	(1,13)
	(2,14)
  (0,15)
  (0,16)
  (3,17)
  (3,18)
  (0,19)
  (0,20)
	};
	\addplot+[smGreen]
	coordinates {
	(6,1)
	(1,2)
	(2,3)
	(0,4)
	(2,5)
	(2,6)
	(0,7)
	(0,8)
	(0,9)
	(1,10)
	(2,11)
	(1,12)
	(2,13)
	(3,14)
  (0,15)
  (0,16)
  (6,17)
  (7,18)
  (2,19)
  (5,20)
	};
	\addplot+[tmnlpthree]
	coordinates {
	(2,1)
	(2,2)
	(1,3)
	(1,4)
	(1,5)
	(0,6)
	(1,7)
	(4,8)
	(0,9)
	(1,10)
	(2,11)
	(1,12)
	(1,13)
	(0,14)
  (1,15)
  (1,16)
  (3,17)
  (3,18)
  (1,19)
  (0,20)
	};
	\addplot+[lsRed]
	coordinates {
  (4,1)
	(3,2)
	(0,3)
	(0,4)
	(1,5)
	(0,6)
	(0,7)
	(0,8)
	(1,9)
	(2,10)
	(3,11)
	(1,12)
	(1,13)
	(0,14)
  (1,15)
  (0,16)
  (8,17)
  (10,18)
  (3,19)
  (3,20)
	};
	\legend{Bing,Google,Lucy,SDL,Systran};
	\end{axis}
\end{tikzpicture}
\caption{\label{fig:05:130}„Keine Wortteile wegla.“ -- Summe der Fehleranzahl der Fehlertypen vor vs. nach KS bei den einzelnen MÜ-Systemen   }
\bspnote{*Die Balken zeigen die Summe der Fehleranzahl bei jedem Fehlertyp, wobei „v“ für die Summe „vor der Anwendung der KS-Regel“ und „n“ für die Summe „nach der Anwendung der KS-Regel“ steht. Jeder Fehlertyp wird erst für alle Systeme für das Szenario „vor KS“ abgebildet, danach folgt derselbe Fehlertyp wieder für alle Systeme für das Szenario „nach KS“.

**Um die Übersichtlichkeit und Lesbarkeit der Grafik zu erhöhen, wurden in der Grafik die Fehlertypen ausgeblendet, die 0 oder nur einmal bei \textit{allen} MÜ-Systemen vorkamen: In dieser Grafik kamen die Fehlertypen 6 und 8 bei gar keinem MÜ-System vor. Zudem kam der Fehlertyp 13 nur einmal jeweils bei einem MÜ-System vor.}
\end{figure}

Die Fehleranzahl beim Fehlertyp OR.1 „Zeichensetzung“ war jedoch nicht hoch und erwies sich bei keinem der genannten Systeme als signifikant. Weitere deutliche Veränderungen bei den anderen Fehlertypen waren ebenfalls nicht zu beobachten.

\subsubsection{Vergleich der MÜ-Qualität vor vs. nach dem Weglassen von Wortteilen sowie die Korrelation zwischen den Fehlertypen und der Qualität}\label{sec:5.3.9.4}

Wie unter \sectref{sec:5.3.9.1} dargestellt, war eine moderate Geläufigkeit der Begriffe in ihrer abgekürzten Form mit einer niedrigeren Fehleranzahl (im Vergleich zu der vollständigen Form) verbunden (\tabref{tab:05:82}). Auf der anderen Seite zeigten die Fälle mit einer sehr niedrigen Geläufigkeit in der abgekürzten Form eine Verbesserung im Sinne eines Rückgangs der Fehleranzahl bei der Verwendung der vollständigen Form (nach KS) (\tabref{tab:05:82}). Trotz der kleinen Anzahl der Fälle jeder Gruppe zeigt dieses Ergebnis eine Tendenz, dass je geläufiger ein Begriff in seiner abgekürzten Form war, desto fehlerfreier war auch seine MÜ (d. h. eine Anwendung der Regel war nicht erforderlich). Umgekehrt konnte die Regelanwendung bei ungeläufigen abgekürzten Begriffen dazu beitragen, die Fehleranzahl zu reduzieren. Eine Reduzierung der Fehleranzahl deutet nicht zwangsläufig auf eine verbesserte Qualität hin. Auf Basis der Ergebnisse der Humanevaluation sanken die Stil- und Inhaltsqualität\footnote{\textrm{Definitionen der Qualität unter \sectref{sec:4.4.5.1}.}} überall nach der Regelanwendung unabhängig davon, ob die Begriffe in ihrer abgekürzten Form geläufig oder ungeläufig waren (\tabref{tab:05:82}).


\begin{table}
\small
\begin{tabularx}{\textwidth}{Xllllllll}

\lsptoprule
& \multicolumn{8}{c}{\textbf{Abgekürzte Begriffe nach ihren Geläufigkeiten}}\\
\cmidrule(lr){2-9}
& \multicolumn{4}{c}{ \textbf{hoch}} & \multicolumn{2}{c}{ \textbf{moderat} } & \multicolumn{2}{c}{ \textbf{niedrig} }\\
\midrule
\textbf{Anz. Treffer Google-Suche} & \multicolumn{2}{l}{> 1.000.000} & \multicolumn{2}{l}{\makecell[tl]{> 100.000 und\\< 1.000.000}} & \multicolumn{2}{l}{\makecell[tl]{> 1.000 und\\< 100.000}} & \multicolumn{2}{l}{< 1.000 bis 0}\\
\tablevspace
\textbf{Anzahl der Fälle} & \multicolumn{2}{l}{1 x 5 MÜ} & \multicolumn{2}{l}{3 x 5 MÜ} & \multicolumn{2}{l}{7 x 5 MÜ} & \multicolumn{2}{l}{13 x 5 MÜ}\\
\tablevspace
\textbf{Durchschnittliche Diff. F.Anz. (nach KS $-$ vor KS)} & \multicolumn{2}{l}{0} & \multicolumn{2}{l}{0} & \multicolumn{2}{l}{0,29} & \multicolumn{2}{l}{$-$~,69}\\
\tablevspace
\textbf{Durchschnittliche Qualitäts-veränderung (nach KS $-$ vor KS)} & \makecell[tl]{SQ\\$-$~,41} & \makecell[tl]{CQ\\$-$~,19} & \makecell[tl]{SQ\\$-$~,25} & \makecell[tl]{CQ\\$-$~,16} & \makecell[tl]{SQ\\$-$~,25} & \makecell[tl]{CQ\\$-$~,16} & \makecell[tl]{SQ\\$-$~,18} & \makecell[tl]{CQ\\$-$~,15}\\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:82}Qualitätsveränderung bei den untersuchten Fällen   }
\end{table}

Der Einfluss auf die Stilqualität war größer im Vergleich zur Inhaltsqualität (\figref{fig:05:132}). Die Stilqualität sank um 5,7~\% (Mv = 4,23 / SDv = ,653 / Mn = 3,99 / SDn = ,557 / N = 87). Die Inhaltsqualität sank um 3,5~\% (Mv = 4,29 / SDv = ,745 / Mn = 4,14 / SDn = ,800 / N = 87). Der Mittelwert der Differenz (nach KS $-$ vor KS) der vergebenen Qualitätspunkte pro Satz lag im Fall der Stilqualität bei $-$~,246 (SD = ,536) mit einem 95\%\nobreakdash-Konfidenzintervall zwischen einem Minimum von $-$~,360 und einem Maximum von $-$~,131 und im Fall der Inhaltsqualität bei $-$~,158 (SD = ,781) mit einem 95\%\nobreakdash-Konfidenzintervall zwischen einem Minimum von $-$~,325 und einem Maximum von ,008 (Bootstrapping mit 1000 Stichproben), siehe \figref{fig:05:132}. Nur die Differenz (nach KS $-$ vor KS) in der Stilqualität erwies sich als hochsignifikant (z (N = 87) = $-$ 4,367 / p < ,001). Bei der Inhaltsqualität war die Differenz insignifikant (z (N = 87) = $-$~1,764 / p = ,078).


\begin{figure}
%\textbf{3,874,11}

%\textbf{3,974,31}

%\textbf{4,144,45}

%\textbf{4,134,34}



%\includegraphics[height=.3\textheight]{figures/d3-img030.png}



%\includegraphics[height=.3\textheight]{figures/d3-img029.png}



%\includegraphics[height=.3\textheight]{figures/d3-img029.png} &  &
%\includegraphics[height=.3\textheight]{figures/d3-img017.png}



%\includegraphics[height=.3\textheight]{figures/d3-img017.png}


%\includegraphics[height=.3\textheight]{figures/d3-img017.png}

\captionsetup{width=.45\textwidth}
\begin{floatrow}
\ffigbox[.5\textwidth]{\caption{„Keine Wortteile wegla.“ -- Mittelwerte der Qualität vor und nach KS}\label{fig:05:131}}{
\includegraphics[width=.25\textwidth]{figures/Abb131.png}
\includegraphics[width=.2\textwidth]{figures/Abb15-legend.png}
}
\ffigbox[.45\textwidth]{\caption{„Keine Wortteile wegla.“ -- Mittelwert der Qualitätsdifferenzen}\label{fig:05:132}}{
\includegraphics[width=.25\textwidth]{figures/Abb16-legend.png}
\includegraphics[width=.3\textwidth]{figures/Abb132.png}
}
\end{floatrow}
\end{figure}

Die Regelanwendung war aufgrund der Wiederholung der Wortteile mit einer stilistischen Inakzeptanz verbunden. An dieser Stelle muss wiederholt erwähnt werden, dass die Studie mithilfe generischer Black-Box{}-Systeme und entsprechend ohne Terminologieintegration durchgeführt wurde.\footnote{\textrm{Für die Auswahlkriterien der untersuchten Systeme siehe \sectref{sec:4.4.1}. Für den genauen Umgang mit den spezifischen Termini im Rahmen der Studie siehe Schritt [4] unter \sectref{sec:4.4.3.1}.}} In der Praxis haben die Unternehmen die Möglichkeit, bestimmte Begriffe als Termini einzupflegen und in ihre MÜ-Systeme zu integrieren, sodass bei einer MÜ je nach den festgelegten Termini übersetzt wird. Eine Anwendung dieser Regel kann daher bei kritischen Inhalten (wie z. B. bei Warnhinweisen) zwecks Klarheit sinnvoll sein, auch wenn der Text stilistisch nicht ideal ist. Je nach Kontext und Satzintention ist eine Abwägung zwischen Klarheit und stilistischer Akzeptanz erforderlich.


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & Die wichtigsten Parameter der \textbf{Ein- und Ausgangskonfiguration} sind voreingestellt.\\
\tablevspace
HMÜ Bing & The most important parameters of the \txblue{input and output configuration} are preset.\\
\midrule
\textbf{Nach-KS} & Die wichtigsten Parameter der \textbf{Eingangskonfiguration und Ausgangskonfiguration} sind voreingestellt.\\
\tablevspace
HMÜ Bing & The most important parameters of the \txblue{configuration of input and output configuration} are preset.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:88}Beispiel 88   }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

In \tabref{tabex:05:88} sanken sowohl die Stil- als auch die Inhaltsqualität nach der Regelanwendung ($-$~1,25 bei der Stilqualität bzw. $-$~,75 Punkte auf der Likert-Skala bei der Inhaltsqualität), obwohl der Satz mit und ohne die Verwendung von vollständigen Wörtern (d. h. vor und nach KS) fehlerfrei übersetzt wurde. Die Bewerter fanden die MÜ mit Wortteilen (vor der Anwendung der KS-Regel) prägnanter und idiomatischer im Vergleich zur vollständigen Form in ‚Eingangskonfiguration und Ausgangskonfiguration‘ (nach KS).


\begin{figure}
%\includegraphics[height=.3\textheight]{figures/d3-img100.png}

%\textbf{$-$ 42~\%}

%\textbf{+~17~\%}

%\textbf{+~4~\%}

%\textbf{+~44~\%}

%\textbf{+~44~\%}

\pgfplotstableread{
1 74
2 43
3 72
4 75
5 320
6 460
7 210
8 245
9 95
10 137
}\datatable

\begin{tikzpicture}
    \begin{axis}[ybar,
                enlarge x limits={.05},
                width  = \textwidth,
                height = .45\textheight,
                axis lines*=left,
                axis on top,
                bar width=8.5,
                bar shift=0pt,
                ymin = 0,
                ymax=500,
                xtick = {1,2,...,10},
                xticklabels={SQ1\_v,
                SQ1\_n,
                SQ2\_v,
                SQ2\_n,
                SQ3\_v,
                SQ3\_n,
                CQ1\_v,
                CQ1\_n,
                CQ2\_v,
                CQ2\_n},
            x tick label style={font=\small},
            nodes near coords,
 	 extra description/.code={
	 \node at (axis cs:1.1,120)[anchor = west]{$-$ 42\%};
	 \node at (axis cs:3,150)[anchor = west]{$+$ 4\%};
	  \node at (axis cs:4.9,500)[anchor = west]{$+$ 44\%};
	   \node at (axis cs:7,300)[anchor = west]{$+$ 17\%};
	    \node at (axis cs:9,200)[anchor = west]{$+$ 44\%};
	  }
            ]
        \addplot +[shift={(.5,0)},lsDarkBlue,x filter/.code={\ifodd\coordindex\def\pgfmathresult{}\fi}] table {\datatable};
        \addplot +[shift={(-.5,0)},lsMidBlue,  x filter/.code={\ifodd\coordindex\relax\else\def\pgfmathresult{}\fi}] table {\datatable};
    \end{axis}
\end{tikzpicture}
\caption{\label{fig:05:133}„Keine Wortteile wegla.“ -- Vergleich der Qualitätskriterien   }
\bspnote{\textbf{SQ1:} Ü ist \textbf{\textit{nicht}} korrekt bzw. \textbf{\textit{nicht}} klar dargestellt, d. h. nicht orthografisch.\\
{\textbf{SQ2:} Ü ist \textbf{\textit{nicht}} ideal für die Absicht des Satzes, d. h. motiviert den Nutzer \textbf{\textit{nicht} }zum Handeln, zieht \textbf{\textit{nicht} }seine Aufmerksamkeit an usw.}\\
\textbf{SQ3:} Ü klingt \textbf{\textit{nicht} }natürlich bzw. \textbf{\textit{nicht} }idiomatisch.\\
{\textbf{CQ1:} Ü gibt die Informationen im Ausgangstext \textbf{\textit{nicht}} exakt wieder.}\\
\textbf{CQ2:} Ü ist \textbf{\textit{nicht}} leicht zu verstehen, d. h. \textbf{\textit{nicht}} gut formuliert bzw. dargestellt.}
\end{figure}

Wie \figref{fig:05:133} zeigt, lag der Rückgang in der Stilqualität überwiegend an der mangelnden Idiomatik der Formulierung (SQ3) sowie bei der Inhaltsqualität insbesondere an der beeinträchtigen Verständlichkeit (CQ2). Für eine bessere Vorstellung dieses Rückgangs betrachten wir \tabref{tabex:05:89}, bei dem der Satz vor und nach der Formulierung mit Wortteilen falsch übersetzt wurde.


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & Schützen Sie das Gerät vor \textbf{Tropf- und Spritzwasser}.\\
\tablevspace
HMÜ Systran & Protect the device from \txblue{dripping and} \txred{splash-water}.\\
\midrule
\textbf{Nach-KS} & Schützen Sie das Gerät vor \textbf{Tropfwasser und Spritzwasser}.\\
\tablevspace
HMÜ Systran & Protect the device from \txblue{dripping water and} \txred{splash-water}.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:89}Beispiel 89   }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

In \tabref{tabex:05:89} sanken nach der Regelanwendung die Stilqualität ($-$~,88 Punkte auf der Likert-Skala) und die Inhaltsqualität ($-$~,50 Punkte auf der Likert-Skala). Die Zeichensetzungsfehler (OR.1) in ‚splash-water‘ und der Wortklassenfehler (GR.7) in ‚splash‘ (anstelle von ‚splashing‘) wurden nach der Anwendung der Regel nicht behoben. Zudem fanden die Bewerter, dass die Wiederholung des Wortes ‚water‘ (nach KS) die Idiomatik der MÜ beeinträchtigte und ablenkend wirkte.

\subsubsubsection{Korrelation zwischen den Fehlertypen und der Qualität}

Auf Basis der Fehlerannotation zusammen mit der Humanevaluation gibt uns eine Spearman-Korrelationsanalyse Aufschluss, wie die Veränderung in der Fehleranzahl bei jedem Fehlertyp (Anz. nach KS $–$ Anz. vor KS) mit den Qualitätsunterschieden (Q. nach KS $–$ Q. vor KS) zusammenhängt. Grundsätzlich sind die meisten Korrelationen bei dieser Regel schwach. Nur bei der Stilqualität gab es zwei signifikante mittlere negative Korrelationen zwischen der Differenz in den Fehlertypen OR.1 „Zeichensetzungsfehler“ und GR.10 „Falsche Wortstellung“ einzeln und der Differenz in der Stilqualität. Die weiteren signifikanten Korrelationen zwischen der Differenz in den Fehlertypen OR.2 „Großschreibungsfehler“ und SM.11 „Verwechslung des Sinns“ einzeln und der Differenz in der Stilqualität waren schwache negative Korrelationen. (siehe \tabref{tab:05:83})

Ebenfalls waren die signifikanten Korrelationen zwischen der Differenz in den Fehlertypen LX.3 „Wort ausgelassen“, LX.5 „Wort unübersetzt geblieben“, GR.10 „Falsche Wortstellung“, SM.11 „Verwechslung des Sinns“ und SM.12 „Falsche Wahl“ einzeln und der Differenz in der Inhaltsqualität schwache negative Korrelationen. (siehe \tabref{tab:05:83})

Weitere Korrelationen zwischen anderen einzelnen Fehlertypen und der Qualität konnten nicht nachgewiesen werden.


\begin{table}
\begin{tabularx}{\textwidth}{Xrrr}

\lsptoprule

 & { \textbf{N}} & { \textbf{p}} & \textbf{ρ}\\
\midrule
{\textbf{Differenz SQ (nach KS $-$ vor KS)}} &  &  & \\
{Diff. der Anzahl der \textbf{OR.1 „Zeichensetzungsfehl.“}} & { 87} & { ,001} & \txgreen{$-$~,338}\\
{Diff. der Anzahl der \textbf{OR.2 „Großschreibungsfehl.“}} & { 87} & { ,025} & $-$~,240\\
{Diff. der Anzahl der \textbf{LX.3 „Wort ausgelassen“}} & { 87} & \txgray{,358} & ,100\\
{Diff. der Anzahl der \textbf{LX.5 „W. unübers. geblieben“}} & { 87} & \txgray{,992} & ,001\\
{Diff. der Anzahl der \textbf{GR.10 „Falsche Wortstellung“}} & { 87} & { ,004} & \txgreen{$-$~,310}\\
{Diff. der Anzahl der \textbf{SM.11 „Verwechsl. des Sinns“}} & { 87} & { ,016} & $-$~,258\\
{Diff. der Anzahl der \textbf{SM.12 „Falsche Wahl“}} & { 87} & \txgray{,720} & ,039\\
\midrule
{\textbf{Differenz CQ (nach KS $-$ vor KS)}} & & & \\
{Diff. der Anzahl der \textbf{OR.1 „Zeichensetzungsfehl.“}} & { 87} & \txgray{,126} & $-$~,165\\
{Diff. der Anzahl der \textbf{OR.2 „Großschreibungsfehl.“}} & { 87} & \txgray{,089} & $-$~,183\\
{Diff. der Anzahl der \textbf{LX.3 „Wort ausgelassen“}} & { 87} & { ,029} & $-$~,234\\
{Diff. der Anzahl der \textbf{LX.5 „W. unübers. geblieben“}} & { 87} & { ,045} & $-$~,216\\
{Diff. der Anzahl der \textbf{GR.10 „Falsche Wortstellung“}} & { 87} & { ,008} & $-$~,282\\
{Diff. der Anzahl der \textbf{SM.11 „Verwechsl. des Sinns“}} & { 87} & { ,009} & $-$~,278\\
{Diff. der Anzahl der \textbf{SM.12 „Falsche Wahl“}} & { 87} & { ,012} & $-$~,267\\
\midrule
{\textbf{Differenz allg. Q (nach KS $-$ vor KS)}} &  &  & \\
{Diff. der Anzahl der \textbf{OR.1 „Zeichensetzungsfehl.“}} & { 87} & { ,002} & \txgreen{$-$~,325}\\
{Diff. der Anzahl der \textbf{OR.2 „Großschreibungsfehl.“}} & { 87} & { ,028} & $-$~,236\\
{Diff. der Anzahl der \textbf{LX.3 „Wort ausgelassen“}} & { 87} & \txgray{,086} & $-$~,185\\
{Diff. der Anzahl der \textbf{LX.5 „W. unübers. geblieben“}} & { 87} & \txgray{,165} & $-$~,150\\
{Diff. der Anzahl der \textbf{GR.10 „Falsche Wortstellung“}} & { 87} & { ,004} & \txgreen{$-$~,308}\\
{Diff. der Anzahl der \textbf{SM.11 „Verwechsl. des Sinns“}} & { 87} & { ,001} & \txgreen{$-$~,348}\\
{Diff. der Anzahl der \textbf{SM.12 „Falsche Wahl“}} & { 87} & \txgray{,152} & $-$~,155\\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:83}„Keine Wortteile wegla.“ -- Korrelation zwischen den Fehlertypen und der Qualität   }
\bspnote{*In der Tabelle werden nur die Fehlertypen dargestellt, die mindestens mit einer Qualitätsvariable signifikant korrelieren.
\begin{tabbing}
p: Signifikanz\hspace{2.5cm}\= \txgray{nicht signifikant (p ${\geq}$ 0,05)}\hspace{.5cm}\= ρ: Korrelationskoeffizient\\
schwache Korrelation (ρ >=0,1)\> \txgreen{mittlere Korrelation (ρ >= 0,3)}\> \boxblue{starke Korrelation (ρ >= 0,5)}\\
\end{tabbing}}
\end{table}

Bei dieser Regel fiel die Differenz in der Fehleranzahl bei den meisten Fehlertypen gering aus. Nur beim orthografischen Fehlertyp OR.1 „Zeichensetzung“ wurde eine signifikante Differenz registriert. Bei einer richtigen Zeichensetzung in Zusammenhang mit dieser Regel geht es um die richtige Verwendung des Bindestriches bei der Übersetzung aus dem Deutschen ins Englische aufgrund der orthografischen Unterschiede in den beiden Sprachen (siehe \sectref{sec:4.4.2.3} „Diskussion der analysierten Regeln“). Eine Korrektur des Zeichensetzungsfehlers führte zur Verbesserung der Qualität. Allerdings kam dieser Fehler oft zusammen mit anderen Fehlertypen vor, sodass der positive Einfluss seiner Korrektur auf die MÜ-Qualität durch den anderen Fehlertyp im Endeffekt geschwächt wurde. In \tabref{tabex:05:90} wurde der Zeichensetzungsfehler in ‚- cover buttons‘ nach KS behoben, allerdings blieb der semantische Fehler (in ‚cover buttons‘) unverändert.


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & \textbf{Kunststoffgriffe und -deckelknöpfe} werden bei Verwendung im Backofen heiß.\\
\tablevspace
HMÜ Systran & \textcolor{tmnlpthree}{Plastic handles and} \txred{- cover-buttons} become hot when used in the oven.\\
\midrule
\textbf{Nach-KS} & \textbf{Kunststoffgriffe und Kunststoffdeckelknöpfe} werden bei Verwendung im Backofen heiß.\\
\tablevspace
HMÜ Systran & \textcolor{tmnlpthree}{Plastic handles and plastic} \txred{cover buttons} become hot when used in the oven.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:90}Beispiel 90   }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

Daraufhin stieg die Stilqualität aufgrund der korrigierten orthografischen Darstellung um 0,25 Punkte und die Inhaltsqualität sank aufgrund der semantisch falschen Übersetzung um 0,38 Punkte auf der Likert-Skala.

\subsubsubsection{Vergleich der Qualität auf Regel- und MÜ-Systemebene}

Wie \figref{fig:05:134} zeigt, sanken sowohl die Stilqualität als auch die Inhaltsqualität bei allen Systemen mit Ausnahme des HMÜ-Systems Systran, bei dem die Inhaltsqualität durchschnittlich leicht stieg.


\begin{figure}
\includegraphics[width=.8\textwidth]{figures/d3-img106.png}
\includegraphics[width=.15\textwidth]{figures/Abb15-legend.png}


%\includegraphics[height=.3\textheight]{figures/d3-img033.png}\\
\caption{\label{fig:05:134}„Keine Wortteile wegla.“ -- Mittelwerte der Qualität vor vs. nach KS bei den einzelnen MÜ-Systemen   }
\end{figure}

Signifikante Rückgänge zeigten sich nur bei der Stilqualität und fanden bei drei MÜ-Systemen statt (\tabref{tab:05:84}): bei dem NMÜ-System Google Translate (Diff\_SQ $-$ 2,9~\%), dem RBMÜ-System Lucy (Diff\_SQ $-$ 5,7~\%) und dem SMÜ-System SDL (Diff\_SQ $-$~6,3~\%). Bei den anderen Systemen war die Veränderung niedrig und entsprechend insignifikant. Für die Inhaltsqualität fiel die Differenz ebenfalls gering aus, sodass bei keinem System signifikante Werte verzeichnet wurden.


\begin{table}
\begin{tabularx}{\textwidth}{lrrrrrrrrr}

\lsptoprule
& \multicolumn{3}{c}{{ \textbf{Differenz SQ} }} & \multicolumn{3}{c}{{ \textbf{Differenz CQ} }} & \multicolumn{3}{c}{{ \textbf{Differenz allg. Q} }}\\
& \multicolumn{3}{c}{\textbf{(nach KS $-$ vor KS)}} & \multicolumn{3}{c}{\textbf{(nach KS $-$ vor KS)}} &  \multicolumn{3}{c}{\textbf{(nach KS $-$ vor KS)}}\\
\cmidrule(lr){2-4}\cmidrule(lr){5-7}\cmidrule(lr){8-10}
& \textbf{N} & \textbf{p} & \textbf{z} & \textbf{N} & \textbf{p} & \textbf{z} & \textbf{N} & \textbf{p} & \textbf{z}\\
\midrule
 \textbf{Bing} & 15 & \txgray{,398} & $-$~,844 & 15 & \txgray{,414} & $-$~,818 & 15 & \txgray{,247} & $-$~1,157\\
 \textbf{Google} & 22 & ,007 & $-$ 2,684 & 22 & \txgray{,139} & $-$~1,479 & 22 & ,008 & $-$ 2,632\\
 \textbf{Lucy} & 22 & ,027 & $-$ 2,210 & 22 & \txgray{,264} & $-$~1,116 & 22 & ,029 & $-$ 2,181\\
 \textbf{SDL} & 14 & ,010 & $-$ 2,567 & 14 & \txgray{,207} & $-$~1,261 & 14 & \txgray{,069} & $-$~1,819\\
 \textbf{Systran} & 14 & \txgray{,310} & $-$~1,016 & 14 & \txgray{,925} & $-$~,094 & 14 & \txgray{,285} & $-$~1,069\\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:84}„Keine Wortteile wegla.“ -- Signifikanz der Qualitätsveränderung bei den einzelnen MÜ-Systemen   }
\bspnote{p: Signifikanz\hspace{2.5cm} z: Teststatistik\hspace{2.5cm} \txgray{nicht signifikant (p ${\geq}$ 0,05)}}
\end{table}

\tabref{tabex:05:91} zeigt, wie die Stil- und Inhaltsqualität durch die Regelanwendung unterschiedlich beeinflusst wurden.


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & Im Falle der Auswahl der freien Konfiguration kann der \textbf{Start- und Endpunkt} frei gewählt werden.\\
\tablevspace
HMÜ Systran & In case of choosing the free configuration, the \txblue{starting and} \txred{terminal} can be selected freely.\\
\midrule
\textbf{Nach-KS} & Im Falle der Auswahl der freien Konfiguration können der \textbf{Startpunkt und der Endpunkt} frei gewählt werden.\\
\tablevspace
HMÜ Systran & In case of choosing the free configuration, the \txblue{starting point and the} \txred{terminal} can be selected freely.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:91}Beispiel 91   }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

In diesem Beispiel blieb der semantische Fehler in der Übersetzung von ‚Punkt‘ als ‚terminal‘ anstelle von ‚point‘ unverändert in beiden Szenarien. Die Qualitätswerte veränderten sich folgendermaßen: Die Stilqualität sank um 0,63 Punkte und die Inhaltsqualität stieg um 0,38 Punkte auf der Likert-Skala. Die Bewerterkommentare geben uns mehr Einblick in dieses Ergebnis; sie lauteten: „‘starting point and terminal‘ is inconsistent construction“; „It sounds more natural to translate ‘Endpunkt’ as ‘end point’ since we already have ‘starting point’. Then one can just use the word ‘point’ once. I suggest ‘the starting and end points’”. Somit ist der Rückgang in der Stilqualität durch die Inkonsistenz und die Redundanz begründet, wobei die MÜ aus Sicht der Bewerter nach KS inhaltlich ein wenig besser im Vergleich zu vor KS ausfiel.

\subsubsubsection{Korrelation zwischen den Fehlertypen und der Qualität auf Regel- und MÜ-Systemebene}

Anhand der Spearman-Korrelationsanalyse erwiesen sich bei drei MÜ-Systemen einige signifikante negative Korrelationen (\tabref{tab:05:85}): Bei keiner weiteren KS-Regel zeigte das NMÜ-System Google Translate einen signifikanten Zusammenhang außer bei dieser Regel; hierbei gab es eine signifikante mittlere negative Korrelation zwischen der Differenz in Fehlertyp OR.1 „Zeichensetzungsfehler“ und der Inhaltsqualität. Allerdings war, wie \tabref{tab:05:85} zeigt, das Signifikanzniveau sehr schwach (p = 0,049). Insgesamt beinhalteten zwei Sätze Zeichensetzungsfehler (OR.1), bei diesen kamen insgesamt 3 Fehler vor, die nach der Anwendung der KS korrigiert wurden. Aufgrund dieser sehr niedrigen Anzahl der Fälle (2 von den 24 bewerteten Sätzen) ist die Bedeutung der vorgeführten Korrelation gering.


\begin{table}
\footnotesize
\begin{tabularx}{\textwidth}{Xrrrrrrrrr}

\lsptoprule
& \multicolumn{3}{c}{\textbf{Google}} & \multicolumn{3}{c}{\textbf{Lucy}} & \multicolumn{3}{c}{\textbf{SDL}}\\
\cmidrule(lr){2-4}\cmidrule(lr){5-7}\cmidrule(lr){8-10}
& \textbf{N} & \textbf{p} & {\textbf{ρ}} & \textbf{N} & \textbf{p} & {\textbf{ρ}} & \textbf{N} & \textbf{p} & {\textbf{ρ}}\\
\midrule
\multicolumn{10}{l}{\textbf{Differenz der Anzahl SQ} \textbf{(nach KS $-$ vor KS)}}\\
\textbf{OR.1 „Zeichen.“} & {22} & \txgray{,314} & {$-$~,225} &  &  &  & {14} & {,034} & \boxblue{$-$~,568}\\
\textbf{GR.10 „Wortst.“} &  &  &  &  &  &  & {14} & {,034} & \boxblue{$-$~,568}\\
\textbf{SM.12 „f. Wahl“} & &  & & {22} & \txgray{,609} & {$-$~,116} &  &  & \\
\midrule
\multicolumn{10}{l}{\textbf{Differenz der Anzahl CQ} \textbf{(nach KS $-$ vor KS)}}\\
\textbf{OR.1 „Zeichen.“} & {22} & {,049} & \txgreen{$-$~,424} &  &  &  & {14} & \txgray{,090} & {$-$~,470}\\
\textbf{GR.10 „Wortst.“} &  &  &  &  &  &  & {14} & \txgray{,110} & {$-$~,446}\\
\textbf{SM.12 „f. Wahl“} &  &  & & {22} & {,003} & \boxblue{$-$~,597} &  &  & \\
\midrule
\multicolumn{10}{l}{\textbf{Differenz der Anzahl Q} \textbf{(nach KS $-$ vor KS)}}\\
\textbf{OR.1 „Zeichen.“} & {22} & \txgray{,090} & {$-$~,370} &  &  &  & {14} & \txgray{,073} & {$-$~,493}\\
\textbf{GR.10 „Wortst.“} &  &  &  &  &  &  & {14} & \txgray{,090} & {$-$~,470}\\
\textbf{SM.12 „f. Wahl“} &  &  &  & {22} & {,010} & \boxblue{$-$~,534} &  &  & \\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:85}„Keine Wortteile wegla.“ -- Korrelationen zwischen den Fehlertypen und der Qualität bei den einzelnen MÜ-Systemen   }
\bspnote{*In der Tabelle werden nur die Fehlertypen dargestellt, die bei mind. einer Qualitätsvariable eine signifikante Korrelation aufweisen.
\begin{tabbing}
p: Signifikanz\hspace{2.5cm}\= \txgray{nicht signifikant (ρ ${\geq}$ 0,05)}\hspace{.5cm}\= ρ: Korrelationskoeffizient\\
schwache Korrelation (ρ >=0,1)\> \txgreen{mittlere Korrelation (ρ >= 0,3)}\> \boxblue{starke Korrelation (ρ >= 0,5)}\\
\end{tabbing}}
\end{table}

Bei dem RBMÜ-System Lucy konnte nur eine signifikante starke negative Korrelation zwischen der Differenz in Fehlertyp SM.12 „Falsche Wahl“ und der Inhaltsqualität nachgewiesen werden. Bei dem SMÜ-System SDL erwies sich eine signifikante starke negative Korrelation zwischen der Differenz in den Fehlertypen OR.1 „Zeichensetzungsfehler und GR.10 „Wortstellungsfehler“ einzeln und der Stilqualität. (siehe \tabref{tab:05:85})

\subsubsection{\label{sec:5.3.9.5}Vergleich der MÜ-Qualität vor vs. nach dem Weglassen von Wortteilen auf Annotationsgruppenebene}

Die Qualitätsveränderung\footnote{\textrm{Definitionen der Qualität unter \sectref{sec:4.4.5.1}.}} der MÜ variierte in den verschiedenen Annotationsgruppen, nachdem die untersuchten Wörter vollständig ausgeschrieben wurden (nach KS) (\figref{fig:05:135}).


\begin{figure}
\includegraphics[width=\textwidth]{figures/d3-img107.png}

%\includegraphics[height=.3\textheight]{figures/d3-img035.png}\\
\caption{\label{fig:05:135}„Keine Wortteile wegla.“ -- Mittelwerte der Qualität vor vs. nach KS auf Annotationsgruppenebene   }
\end{figure}

In der Gruppe FF (Übersetzung vor und nach KS falsch) sanken die Stil- und Inhaltsqualität, wobei nur der Rückgang in der Stilqualität signifikant war (\tabref{tab:05:86}). Die Bewerter fanden in vielen Fällen die MÜ bei der Formulierung in abgekürzter Form (vor KS) prägnanter und natürlicher.


\begin{table}
\begin{tabularx}{\textwidth}{Xrrr}

\lsptoprule
& \textbf{N} & { \textbf{p}} & { \textbf{Z} }\\
& & \textbf{(Signifikanz)} & \textbf{(Teststatistik)}\\
\midrule
{\textbf{Annotationsgruppe FF}} & {} & {} & \\
\textbf{Differenz SQ (nach KS $-$ vor KS)} & 24 & ,012 & $-$ 2,521\\
\textbf{Differenz CQ (nach KS $-$ vor KS)} & 24 & \txgray{,177} & $-$~1,351\\
\textbf{Differenz allg. Q (nach KS $-$ vor KS)} & 24 & ,018 & $-$ 2,361\\
\midrule
{\textbf{Annotationsgruppe FR}} & {} & {} & \\
\textbf{Differenz SQ (nach KS $-$ vor KS)} & 16 & \txgray{,266} & $-$~1,113\\
  \textbf{Differenz CQ (nach KS $-$ vor KS)} & 16 & ,001 & $-$ 3,221\\
\textbf{Differenz allg. Q (nach KS $-$ vor KS)} & 16 & ,010 & $-$ 2,582\\
\midrule
{\textbf{Annotationsgruppe RF}} & {} & {} & \\
\textbf{Differenz SQ (nach KS $-$ vor KS)} & 12 & ,028 & $-$ 2,201\\
  \textbf{Differenz CQ (nach KS $-$ vor KS)} & 12 & ,004 & $-$ 2,875\\
\textbf{Differenz allg. Q (nach KS $-$ vor KS)} & 12 & ,004 & $-$ 2,904\\
\midrule
{\textbf{Annotationsgruppe RR}} & {} & {} & \\
\textbf{Differenz SQ (nach KS $-$ vor KS)} & 35 & < ,001 & $-$ 4,575\\
  \textbf{Differenz CQ (nach KS $-$ vor KS)} & 35 & \txgray{,078} & $-$~1,765\\
   \textbf{Differenz allg. Q (nach KS $-$ vor KS)} & 35 & < ,001 & $-$ 4,175\\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:86}„Keine Wortteile wegla.“ -- Signifikanz der Qualitätsveränderung auf Annotationsgruppenebene   }
\end{table}

In \tabref{tabex:05:92} sanken die Stilqualität um 0,38 Punkte und die Inhaltsqualität um 0,25 auf der Likert-Skala. Bei der Formulierung in abgekürzter Form (vor KS) beeinflusste der semantische Übersetzungsfehler in ‚buttons‘ die Genauigkeit, die Verständlichkeit sowie die Idiomatik der MÜ. Auf der anderen Seite existierte nach der Anwendung der KS-Regel weiterhin der semantische Fehler und das Wort ‚plastic‘ wurde wiederholt. Diese Wiederholung fanden die Bewerter unnatürlich. So wurde die MÜ nach KS von den Bewertern folgendermaßen kommentiert: „I suggest deleting the second usage of ‘plastic’ because it's already clear that the first time refers to everything that follows”; „‘buttons’ is something that can be pressed (Knopf). I suggest ‘knobs’ instead (something that can be used to lift or turn), so it should be ‘Plastic handles and lid knobs’“


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & \textbf{Kunststoffgriffe und -deckelknöpfe} werden bei Verwendung im Backofen heiß.\\
\tablevspace
GNMÜ & \textcolor{tmnlpthree}{Plastic handles and lid} \txred{buttons} become hot when used in the oven.\\
\midrule
\textbf{Nach-KS} & \textbf{Kunststoffgriffe und Kunststoffdeckelknöpfe} werden bei Verwendung im Backofen heiß.\\
\tablevspace
GNMÜ & \textcolor{tmnlpthree}{Plastic handles and plastic} \txred{cover buttons} become hot when used in the oven.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:92}Beispiel 92   }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

Erwartungsgemäß stiegen die Stil- und Inhaltsqualität in der Gruppe FR (MÜ falsch vor KS; richtig nach KS) und sanken in der Gruppe RF (MÜ richtig vor KS; falsch nach KS). In der Gruppe RF sanken die Stil- und Inhaltsqualität signifikant, nachdem die untersuchten Wörter vollständig ausgeschrieben wurden (nach KS), aufgrund der aufgetretenen Fehler im Vergleich zu der fehlerfreien Übersetzung bei der Formulierung mit Wortteilen (vor KS), siehe \tabref{tab:05:86}. In der Gruppe FR war der Anstieg in der Stilqualität bei der Verwendung von vollständigen Wörtern (nach KS) insignifikant, während der Anstieg der Inhaltsqualität signifikant war (\tabref{tab:05:86}). In \tabref{tabex:05:93} verursachte die Verwendung von Wortteilen den semantischen Fehler in ‚is‘. Dies beeinträchtigte deutlich die Verständlichkeit der MÜ. Nachdem dieser Fehler bei der Formulierung mit vollständigen Wörtern (nach KS) behoben wurde, stieg die Inhaltsqualität um 1,25 und die Stilqualität um 0,25 auf der Likert-Skala.


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & Die \textbf{Ist- und Sollwerte} des zweiten Regelkreises werden nach der Konfiguration angezeigt.\\
\tablevspace
RBMÜ Lucy & The \txred{is-} \txblue{and required values} of the second control loop will be displayed after configuration.\\
\midrule
\textbf{Nach-KS} & Der \textbf{Istwert und der Sollwert} des zweiten Regelkreises werden nach der Konfiguration angezeigt.\\
\tablevspace
RBMÜ Lucy & The \txblue{actual value and the required value} of the second control loop will be displayed after configuration.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:93}Beispiel 93  }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

Die Gruppe RR (Übersetzung vor und nach KS fehlerfrei) hatte den größten Anteil von 43~\% der analysierten Sätze (siehe \sectref{sec:5.3.9.2}). In dieser Gruppe sanken sowohl die Stilqualität als auch die Inhaltsqualität, wobei nur der Rückgang in der Stilqualität signifikant war, siehe \tabref{tab:05:86}. Die Humanevaluation zeigt, dass solange die Wortteile richtig übersetzt werden können und eine vollständige Formulierung des Worts für die Verständlichkeit nicht erforderlich ist, die Verwendung von Wortteilen deutliche stilistische Vorteile mit sich bringt. In \tabref{tabex:05:94} kritisierten die Bewerter nach der Regelanwendung die Redundanz in ‚errors‘. Entsprechend sank die Stilqualität um 0,63 Punkte und die Inhaltsqualität um 0,13 Punkte auf der Likert-Skala.


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & Innerhalb der Garantiezeit beseitigen wir alle Mängel des Gerätes, die auf \textbf{Material- oder Fabrikationsfehlern} beruhen.\\
\tablevspace
GNMÜ & Within the guarantee period, we repair all device defects that are due to \txblue{material or manufacturing errors}.\\
\midrule
\textbf{Nach-KS} & Innerhalb der Garantiezeit beseitigen wir alle Mängel des Gerätes, die auf \textbf{Materialfehlern oder Fabrikationsfehlern} beruhen.\\
\tablevspace
GNMÜ & Within the guarantee period, we repair all device defects that are due to \txblue{material errors or manufacturing errors}.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:94}Beispiel 94   }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

Einer der wenigen Fälle (aus der Gruppe RR), in denen die Stil- und Inhaltsqualität nach der Regelanwendung stiegen (jeweils um 0,25 Punkte auf der Likert-Skala), demonstriert \tabref{tabex:05:95}.


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & Prüfen Sie, ob sich \textbf{Wasser$-$, Gasrohre} oder stromführende Leitungen im Bohrbereich befinden.\\
\tablevspace
GNMÜ & Check whether there are \txblue{water, gas pipes} or power lines in the drilling area.\\
\midrule
\textbf{Nach-KS} & Prüfen Sie, ob sich \textbf{Wasserrohre, Gasrohre} oder stromführende Leitungen im Bohrbereich befinden.\\
\tablevspace
GNMÜ & Check whether there are \txblue{water pipes, gas pipes} or power lines in the drilling area.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:95} Beispiel 95 }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

Hierbei fanden die Bewerter die MÜ nach KS genauer und verständlicher im Vergleich zu der vor KS. Folglich beeinträchtigte die Wiederholung den Stil nicht.

\subsubsection{\label{sec:5.3.9.6}Vergleich der AEM-Scores vor vs. nach dem Weglassen von Wortteilen sowie die Korrelation zwischen den AEM-Scores und der Qualität}

Der Vergleich der AEM-Scores vor vs. nach dem Weglassen von Wortteilen zeigte sowohl mit TERbase als auch mit hLEPOR eine Verschlechterung der AEM-Scores (\figref{fig:05:136}).


\begin{figure}
%\includegraphics[height=.3\textheight]{figures/d3-img022.png}




%\includegraphics[height=.3\textheight]{figures/d3-img022.png}


%\includegraphics[height=.3\textheight]{figures/d3-img022.png}
\includegraphics[width=.4\textwidth]{figures/Abb136.png}
\includegraphics[width=.35\textwidth]{figures/Abb19-legend.png}
\caption{\label{fig:05:136}„Keine Wortteile wegla.“ -- Mittelwert der Differenz der AEM-Scores   }
\bspnote{Differenz = AEM-Score nach KS \textit{minus} AEM-Score vor KS}
\end{figure}

Der Mittelwert der Differenz (nach KS $-$ vor KS) im AEM-Score pro Satz lag für TERbase bei ,063 (SD = ,160) und für die hLEPOR bei ,020 (SD = ,113) mit einem 95\%\nobreakdash-Konfidenzintervall (Bootstrapping mit 1000 Stichproben). Die Differenzen (nach KS $-$ vor KS) in TERbase und hLEPOR erwiesen sich als signifikant (z (N = 88) = $-$~3,777 / p = ,021) bzw. (z (N = 88) = $-$~1,843 / p = ,048). Dieses Ergebnis weist darauf hin, dass die Verwendung der vollständigen Form der Begriffe (nach KS) mit mehr Edits verbunden war.

\subsubsubsection{Korrelation zwischen den Differenzen in den AEM-Scores und der Qualität}

Nach der Anwendung der KS-Regel sank die Stilqualität signifikant und die Inhaltsqualität nicht signifikant, siehe \sectref{sec:5.3.9.4}. Mithilfe des Spearman-Kor\-re\-la\-tions\-tests erwies sich ein signifikanter mittlerer positiver Zusammenhang zwischen den Differenzen in den AEM-Scores von TERbase und hLEPOR und der Differenz in der allgemeinen Qualität. Bei der Formulierung der Begriffe in ihrer vollständigen Form verschlechterten sich die Scores der beiden AEMs und die Qualität sank.


\begin{table}
\begin{tabularx}{\textwidth}{Xrrrr}

\lsptoprule
& \textbf{N} & { \textbf{Signifikanz} } & \textbf{Korrelations-} & \textbf{Stärke}\\
& & \textbf{(p)} & \textbf{koeffizient} & \textbf{der}\\
& & & \textbf{(ρ)} &  \textbf{Korrelation}\\
\midrule
Korrelation zw. Differenz in der allg. Qualität und Differenz des TERbase{}-Scores (nach KS $-$ vor KS) & { 87} & < ,001 & ,465 & \makecell[tr]{mittlerer\\Zusammen-\\hang}\\
\tablevspace
Korrelation zw. Differenz in der allg. Qualität und Differenz des hLEPOR-Scores (nach KS $-$ vor KS) & { 87} & < ,001 & ,454 & \makecell[tr]{mittlerer\\Zusammen-\\hang}\\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:87}„Keine Wortteile wegla.“ -- Korrelation zwischen den Differenzen der AEM-Scores und den Qualitätsdifferenzen   }
\bspnote{{schwache Korrelation (ρ >=0,1)}\hspace{1em}{ mittlere Korrelation (ρ >= 0,3)}\hspace{1em}starke Korrelation (ρ >= 0,5)}
\end{table}

Nach diesem Ergebnis standen die Qualitätsveränderungen der Humanevaluation und der automatischen Evaluation in relativem Einklang, da der Qualitätsrückgang mit der Verschlechterung der AEM-Scores einherging.

\subsubsection{\label{sec:5.3.9.7}Analyse der neunten Regel -- Validierung der Hypothesen}
\largerpage
Um die vorgestellten Ergebnisse auf die Forschungsfragen der Studie zurückzuführen, listet dieser Abschnitt die zugrunde liegenden Hypothesen der Forschungsfragen zusammen mit einer Zusammenfassung der Ergebnisse der neunten analysierten Regel in tabellarischer Form auf. Für einen schnelleren Überblick steht (+) für eine Verbesserung bzw. einen Anstieg z.~B. im Sinne eines Qualitätsanstiegs, verbesserter AEM-Scores oder eines Anstiegs der Fehleranzahl; ($-$) steht für einen Rückgang; die \txgreen{grüne} Farbe symbolisiert eine signifikante Veränderung; \textit{neg} steht für eine negative Korrelation und \textit{pos} für eine positive Korrelation; <{}<{}>{}> steht für eine starke Korrelation und <> für eine mittlere Korrelation.\footnote{\textrm{Schwache Korrelationen werden in dieser Übersicht nicht angezeigt.}}

\subsubsubsection*{\textbf{Regel 9: Keine Wortteile weglassen}}
\paragraph*{Erster Analysefaktor: Vergleich der Fehleranzahl vor vs. nach dem Weglassen von Wortteilen}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Gibt es einen Unterschied in der Fehleranzahl nach der Anwendung der KS-Regel im Vergleich zu vor der Anwendung?
\item [H0 --] Es gibt keinen Unterschied in der Fehleranzahl vor vs. nach der Anwendung der KS-Regel.
\item [H1 --] Es gibt einen Unterschied in der Fehleranzahl vor vs. nach der Anwendung der KS-Regel.
\item [Resultat]
\end{description}
\noindent
\parbox[t]{.8\textwidth}{\textbf{Auf Regelebene:}}\\
\parbox[t]{.8\textwidth}{
H0 wurde nicht abgelehnt und somit konnte H1 nicht bestätigt werden.

Die Fehleranzahl sank leicht nach der Formulierung der Begriffe in vollständiger Form (nach KS).

Nach einer Aufteilung der untersuchten Begriffe nach Geläufigkeitsgrad zeigten abgekürzte Begriffe mit einer sehr niedrigen Geläufigkeit einen Rückgang der Fehleranzahl nach KS. Jedoch -- aufgrund der kleinen Anzahl der Fälle -- bedarf eine Analyse dieser Regel in Zusammenhang mit dem Geläufigkeitsgrad weiterer Forschung.
}
\parbox[t]{.04\textwidth}{}
\parbox[t]{.15\textwidth}{\textbf{Anz.F. ($-$)}}

\noindent
\parbox[t]{.8\textwidth}{
\textbf{Auf Regel- und MÜ-Systemebene:}
}\\
\parbox[t]{.8\textwidth}{
Alle Veränderungen in der Fehleranzahl nach der Regelanwendung waren nicht signifikant: ein Anstieg bei Bing, ein Rückgang bei Google, Lucy und Systran sowie gar keine Veränderung bei SDL.
}
\parbox[t]{.04\textwidth}{}
\parbox[t]{.15\textwidth}{
\textbf{Bi (+)}

{ \textbf{Go ($-$)}}

{ \textbf{Lu ($-$)}}

{ \textbf{Sy ($-$)}}

 \textbf{SD (=)}
}
\smallskip
\hrule
\newpage
\paragraph*{Zweiter Analysefaktor}\hfill\\
\begin{figure}[H]
% 127
\torte{34}{22}{13}{51}
\caption{Aufteilung der Annotationsgruppen auf Regelebene}
\end{figure}
\begin{figure}[H]
\begin{tikzpicture}
\tikzset{every node/.style={font=\scriptsize}};
	\begin{axis}[
	ybar,
	width = \textwidth,
  height = .5\textheight,
	axis lines* = left,
	ylabel = {\%},
	xtick = {3,9,15,21},
	xticklabels = {FF,FR,RF,RR},
  x tick label style ={yshift=-5pt},
	xtick=data,
  xlabel={Annotationsgruppe},
	ymin=0,
	ymax = 20,
  y filter/.code={\pgfmathparse{#1/120*100}\pgfmathresult},
%	bar shift = 0pt,
  bar width=9,
  enlarge x limits = .2,
%	nodes near coords,
%	legend pos= north east,
	legend style={at={(0.5,-0.15)},anchor=north},
	legend columns = {-1},
	]
	\addplot+[lsNightBlue]
	coordinates {
	(3,4)
	(9,6)
	(15,5)
	(21,9)
	};
	\addplot+[tmnlpone]
	coordinates {
	(3,4)
	(9,2)
	(15,0)
	(21,18)
	};
	\addplot+[tmnlptwo]
	coordinates {
	(3,9)
	(9,6)
	(15,3)
	(21,6)
	};
	\addplot+[tmnlpthree]
	coordinates {
	(3,6)
	(9,4)
	(15,3)
	(21,11)
	};
	\addplot+[tmnlpfour]
	coordinates {
	(3,11)
	(9,4)
	(15,2)
	(21,7)
	};
	\legend{Bing,Google,Lucy,SDL,Systran}
	\end{axis}
\end{tikzpicture}
\caption{Aufteilung der Annotationsgruppen auf Regel- und MÜ-Systemebene}
\end{figure}
\hrule
\paragraph*{Dritter Analysefaktor: Vergleich der Fehlertypen vor vs. nach dem Weglassen von Wortteilen}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Beinhaltet die MÜ bestimmte Fehlertypen vor bzw. nach der Anwendung der KS-Regel?
\item [H0 --] Es gibt keinen Unterschied in der Häufigkeit der einzelnen Fehlertypen vor vs. nach der Anwendung der KS-Regel.
\item [H1 --] Es gibt einen Unterschied in der Häufigkeit der einzelnen Fehlertypen vor vs. nach der Anwendung der KS-Regel.
\item [Resultat]
\end{description}
\noindent
\parbox[t]{.8\textwidth}{\textbf{Auf Regelebene:}}\\
\parbox[t]{.8\textwidth}{
H1 wurde nur für einen Fehlertyp bestätigt.

Die Fehleranzahl von OR.1 „Zeichensetzung“ sank signifikant nach der Verwendung der vollständigen Form der Begriffe (nach KS).
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.15\textwidth}{
\textbf{OR.1 ($-$)}\\
\\
\\
}}

\noindent
\parbox[t]{.8\textwidth}{\textbf{Auf Regel- und MÜ-Systemebene:}}\\
\parbox[t]{.8\textwidth}{
Es gab bei keinem der Systeme signifikante Veränderungen in den Fehlertypen. Die Fehleranzahl bei den einzelnen Fehlertypen fiel im Allgemeinen niedrig aus.
}
\parbox[t]{.04\textwidth}{}
\parbox[t]{.15\textwidth}{}
\smallskip
\hrule
\paragraph*{Vierter Analysefaktor: Vergleich der MÜ-Qualität vor vs. nach dem Weglassen von Wortteilen}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Gibt es einen Unterschied in der Stil- und Inhaltsqualität der MÜ der KS-Stelle nach der Anwendung der KS-Regel im Vergleich zu vor der Anwendung?
\item [H0 --] Es gibt keinen Qualitätsunterschied vor vs. nach der Anwendung der KS-Regel.
\item [H1 --] Es gibt einen Qualitätsunterschied vor vs. nach der Anwendung der KS-Regel.
\item [Resultat]
\end{description}
\noindent
\parbox[t]{.8\textwidth}{\textbf{Auf Regelebene:}}\\
\parbox[t]{.8\textwidth}{
H1 wurde nur für die Stilqualität bestätigt.

Die Stilqualität sank signifikant nach der Verwendung der vollständigen Form der Begriffe (nach KS).
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.15\textwidth}{\textbf{SQ ($-$)}\\
\\
}}

\medskip
\noindent
\parbox[t]{.8\textwidth}{
Die Inhaltsqualität sank leicht (nicht signifikant) nach KS.

Unabhängig vom Geläufigkeitsgrad der abgekürzten Begriffe sanken die SQ und CQ aller analysierten Fälle nach KS. Aufgrund der kleinen Anzahl der Fälle bedarf jedoch eine Analyse dieser Regel in Zusammenhang mit dem Geläufigkeitsgrad weiterer Forschung.
}
\parbox[t]{.04\textwidth}{}
\parbox[t]{.15\textwidth}{\textbf{CQ ($-$)}}

\noindent
\parbox[t]{.8\textwidth}{\textbf{Auf Regel- und MÜ-Systemebene:}}\\
\parbox[t]{.8\textwidth}{
Die Stilqualität sank bei Google, Lucy und SDL signifikant (nach KS).

Die Stilqualität sank ebenfalls bei Bing und Systran, aber nicht signifikant.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.15\textwidth}{
{ \textbf{SQ ($-$):}}

{ \textbf{Go}}

{ \textbf{Lu}}

\textbf{SD}
}}

\medskip
\noindent
\parbox[t]{.8\textwidth}{Die Inhaltsqualität sank bei allen Systemen leicht mit Ausnahme von Systran, bei dem die CQ leicht anstieg (nach KS).}
\parbox[t]{.04\textwidth}{}
\parbox[t]{.15\textwidth}{}
\smallskip
\hrule
\paragraph*{Fünfter Analysefaktor: Korrelation zwischen den Fehlertypen und der Qualität}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Besteht ein Zusammenhang zwischen der Differenz in der Fehleranzahl eines bestimmten Fehlertyps (Fehleranzahl nach KS $-$ vor KS) und der Differenz in der Stil- bzw. Inhaltsqualität (Qualität nach KS $-$ vor KS)?
\item [H0 --] Es besteht kein Zusammenhang zwischen der Differenz in der Fehleranzahl eines bestimmten Fehlertyps und der Differenz in der Stil- bzw. Inhaltsqualität.
\item [H1 --] Es besteht ein Zusammenhang zwischen der Differenz der Fehleranzahl eines bestimmten Fehlertyps und der Differenz der Stil- bzw. Inhaltsqualität.
\item [Resultat]
\end{description}
\noindent
\parbox[t]{.7\textwidth}{\textbf{Auf Regelebene:}}\\
\parbox[t]{.7\textwidth}{
H1 wurde für zwei Fehlertypen wie folgt bestätigt:

Es bestand ein signifikanter mittlerer negativer Zusammenhang zwischen der Differenz der Fehleranzahl des OR.1 „Zeichensetzungsfehler“ und GR.10 „Wortstellungsfehler“ einzeln und der Stilqualität.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.25\textwidth}{
\textbf{\textit{neg}} \textbf{OR.1 <> SQ}

 \textbf{\textit{neg}} \textbf{GR.10 <> SQ}\\
 \\
 \\
}}

\noindent
\parbox[t]{.7\textwidth}{\textbf{Auf Regel- und MÜ-Systemebene:}}\\
\parbox[t]{.7\textwidth}{
Bei Google bestand ein signifikanter mittlerer negativer Zusammenhang zwischen der Differenz in der Fehleranzahl des LX.1 „Zeichensetzungsfehler“ und der Differenz in der Inhaltsqualität.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.25\textwidth}{
{ \textbf{Go}}

 \textbf{\textit{neg}} \textbf{OR.1 <> CQ}\\
 \\
}}

\medskip
\noindent
\parbox[t]{.7\textwidth}{
Bei Lucy bestand ein signifikanter starker negativer Zusammenhang zwischen der Differenz in der Fehleranzahl des SM.12 „Falsche Wahl“ und der Differenz in der Inhaltsqualität.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.25\textwidth}{
{ \textbf{Lu}}

\textbf{\textit{neg}} \textbf{SM.12 <{}<{}>{}> CQ}\\
\\
}}

\medskip
\noindent
\parbox[t]{.7\textwidth}{
Bei SDL bestand ein signifikanter starker negativer Zusammenhang zwischen der Differenz in der Fehleranzahl des OR.1 „Zeichensetzungsfehler“ und GR.10 „Wortstellungsfehler“ einzeln und der Differenz in der Stilqualität.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.25\textwidth}{
{ \textbf{SD}}

{ \textbf{\textit{neg}} \textbf{OR.1 <{}<{}>{}> SQ}}

\textbf{\textit{neg}} \textbf{GR.10 <{}<{}>{}> SQ}\\
\\
}}

\medskip
\noindent
\parbox[t]{.7\textwidth}{Alle weiteren Korrelationen waren nicht signifikant.}
\parbox[t]{.04\textwidth}{}
\parbox[t]{.25\textwidth}{}
\smallskip
\hrule
\paragraph*{Sechster Analysefaktor: Vergleich der MÜ-Qualität vor vs. nach dem Weglassen von Wortteilen auf Annotationsgruppenebene}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Gibt es einen Unterschied in der Stil- und Inhaltsqualität bei den einzelnen Annotationsgruppen nach der Anwendung der KS-Regel im Vergleich zu vor der Anwendung?
\item [H0 --] Bei den Annotationsgruppen gibt es keinen Qualitätsunterschied vor vs. nach der Anwendung der KS-Regel.
\item [H1 --] Bei den Annotationsgruppen gibt es einen Qualitätsunterschied vor vs. nach der Anwendung der KS-Regel.
\item [Resultat]
\end{description}
\noindent
\parbox[t]{.8\textwidth}{
H1 wurde bei der Annotationsgruppe FF nur für die Stilqualität bestätigt:
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.15\textwidth}{\textbf{SQ ($-$)}\\}}

\noindent
\parbox[t]{.8\textwidth}{
Die Stilqualität sank signifikant bei der vollständigen Formulierung der Begriffe (nach KS).
}
\parbox[t]{.04\textwidth}{}
\parbox[t]{.15\textwidth}{
\textbf{CQ ($-$)}
}

\medskip
\noindent
\parbox[t]{.8\textwidth}{
Bei der Annotationsgruppe FR stiegen die Stil- und Inhaltsquali-
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.15\textwidth}{\textbf{CQ (+)}}}

\noindent
\parbox[t]{.8\textwidth}{
tät, allerdings war nur der Anstieg der Inhaltsqualität signifikant (nach KS).
}
\parbox[t]{.04\textwidth}{}
\parbox[t]{.15\textwidth}{
\textbf{SQ (+)}
}

\medskip
\noindent
\parbox[t]{.8\textwidth}{
Bei der Annotationsgruppe RF sanken die Stil- und Inhaltsquali-
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.15\textwidth}{{ \textbf{SQ ($-$)}}}}

\noindent
\parbox[t]{.8\textwidth}{
tät signifikant.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{
\parbox[t]{.15\textwidth}{
\textbf{CQ ($-$)}
}
}

\medskip
\noindent
\parbox[t]{.8\textwidth}{
Bei der Annotationsgruppe RR sanken die Stil- und Inhaltsquali-
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.15\textwidth}{\textbf{SQ ($-$)}}}

\noindent
\parbox[t]{.8\textwidth}{
tät, allerdings war nur der Rückgang der Stilqualität signifikant (nach KS).
}
\parbox[t]{.04\textwidth}{}
\parbox[t]{.15\textwidth}{
\textbf{CQ ($-$)}
}
\smallskip
\hrule
\paragraph*{Siebter Analysefaktor: Vergleich der AEM-Scores vor vs. nach dem Weglassen von Wortteilen}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Gibt es einen Unterschied in den AEM-Scores von TERbase bzw. hLEPOR nach der Anwendung der KS-Regel im Vergleich zu vor der Anwendung?
\item [H0 --] Es gibt keinen Unterschied in den AEM-Scores vor vs. nach der Anwendung der KS-Regel.
\item [H1 --] Es gibt einen Unterschied in den AEM-Scores vor vs. nach der Anwendung der KS-Regel.
\item [Resultat]
\end{description}
\noindent
\parbox[t]{.75\textwidth}{
H0 wurde abgelehnt und somit H1 bestätigt.

Die AEM-Scores von TERbase und hLEPOR verschlechterten sich signifikant nach der Verwendung der vollständigen Form der Begriffe (nach KS).
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.2\textwidth}{
\textbf{TERbase ($-$)\\hLEPOR ($-$)}\\
\\
}}
\smallskip
\hrule
\paragraph*{Achter Analysefaktor: Korrelation zwischen den Differenzen in den AEM-Scores und der Qualität}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Besteht ein Zusammenhang zwischen der Differenz in den AEM-Scores von TERbase bzw. hLEPOR (Mittelwert der AEM-Scores nach KS $-$ vor KS) und der Differenz in der allgemeinen Qualität (Qualität nach KS $-$ vor KS)?
\item [H0 --] Es besteht kein Zusammenhang zwischen der Differenz in den AEM-Scores und der Differenz in der allgemeinen Qualität.
\item [H1 --] Es besteht ein Zusammenhang zwischen der Differenz in den AEM-Scores und der Differenz in der allgemeinen Qualität.
\item [Resultat]
\end{description}
\noindent
\parbox[t]{.7\textwidth}{
H0 wurde abgelehnt und somit H1 bestätigt.

Es bestand ein signifikanter mittlerer positiver Zusammenhang zwischen der Differenz in den TERbase-Scores und der Differenz der allgemeinen Qualität sowie ein signifikanter mittlerer positiver Zusammenhang zwischen der Differenz in den hLEPOR-Scores und der Differenz in der allgemeinen Qualität.
}
\parbox[t]{.04\textwidth}{}
\colorbox{smGreen}{\parbox[t]{.25\textwidth}{
\textbf{\textit{pos}} \textbf{TERbase <> Q}

 \textbf{\textit{pos}} \textbf{hLEPOR <> Q}\\
 \\
 \\
 \\
 \\
}}


\subsection{Übersicht der Ergebnisse auf Regelebene}
\label{sec:5.3.10}

\tabref{tab:05:88} bietet eine Übersicht über die Ergebnisse auf Regelebene.


\begin{sidewaystable}
\scriptsize
\begin{tabularx}{\textwidth}{llQllllllll}

\lsptoprule

{Regel} & Fehler- & Fehler- & \multicolumn{2}{c}{Qualität} & \multicolumn{2}{c}{Fehlertypen <> Qualität} & \multicolumn{2}{c}{AEM-Scores} & \multicolumn{2}{c}{AEM-Scores <> allg. Qualität}\\
\cmidrule(lr){6-7}\cmidrule(lr){8-9}\cmidrule(lr){10-11}
& anzahl & typen &  &  & Stilqualität & Inhaltsqualität & {TERbase} & {hLEPOR} & {TERbase} & hLEPOR\\
\midrule
{1:

anz} & \cellcolor{smGreen}{($-$)} & \cellcolor{smGreen}{{$-$OR.2}

 $-$GR.10} & \cellcolor{smGreen}{+SQ} & \cellcolor{smGreen}+CQ & \cellcolor{smGreen}\textit{neg} GR.10 <{}<{}>{}> SQ & \cellcolor{smGreen}\textit{neg} GR.10 <{}<{}>{}> CQ & \cellcolor{smGreen}{+} & \cellcolor{smGreen}{+} & \cellcolor{smGreen}\textit{pos} TERbase <> Q & \cellcolor{smGreen}\textit{pos} hLEPOR <> Q\\
\midrule
{2:

fvg} & \cellcolor{smGreen}{($-$)} & \cellcolor{smGreen}{$-$SM.13} & \cellcolor{smGreen}{+SQ} & \cellcolor{smGreen}+CQ & \cellcolor{smGreen}\textit{neg} LX.4 <> SQ & \cellcolor{smGreen}\textit{neg} SM.12 <> CQ & \cellcolor{smGreen}{+} & \cellcolor{smGreen}{+} & \cellcolor{smGreen}{\textit{pos} TERbase <{}<{}>{}> Q} & \cellcolor{smGreen}\textit{pos} hLEPOR <{}<{}>{}> Q\\
& \cellcolor{smGreen} & \cellcolor{smGreen} & \cellcolor{smGreen}  & \cellcolor{smGreen}  & \cellcolor{smGreen}\textit{neg} SM.11 <> SQ & \cellcolor{smGreen}  & \cellcolor{smGreen} & \cellcolor{smGreen}  & \cellcolor{smGreen}  & \cellcolor{smGreen} \\
\midrule
{3:

kos} & \cellcolor{smGreen}{($-$)} & \cellcolor{smGreen}{$-$LX.3} & \cellcolor{smGreen}{+SQ} & \cellcolor{smGreen}+CQ & \cellcolor{smGreen}\textit{neg} LX.3 <{}<{}>{}> SQ & \cellcolor{smGreen}\textit{neg} LX.3 <{}<{}>{}> CQ & {+} & {+} & \cellcolor{smGreen}{\textit{pos} TERbase <{}<{}>{}> Q} & \cellcolor{smGreen}\textit{pos} hLEPOR <{}<{}>{}> Q\\
& \cellcolor{smGreen}  & \cellcolor{smGreen} $-$LX.4 & \cellcolor{smGreen}  & \cellcolor{smGreen}  & \cellcolor{smGreen}\textit{neg} GR.10 <> SQ & \cellcolor{smGreen} &  &  & \cellcolor{smGreen}  & \cellcolor{smGreen} \\
\midrule
{4:

nsp} & {($-$)} & \cellcolor{smGreen}{+LX.6} & {$-$SQ} & +CQ & \cellcolor{smGreen}\textit{neg} GR.10 <> SQ & \cellcolor{smGreen}\textit{neg} LX.6 <> CQ & {($-$)} & {($-$)} & \cellcolor{smGreen}{\textit{pos} TERbase <> Q} & \cellcolor{smGreen}\textit{pos} hLEPOR <> Q\\
&  &  \cellcolor{smGreen}$-$SM.11  &  &  & \cellcolor{smGreen}{\textit{neg} SM.11 <> SQ} & \cellcolor{smGreen}\textit{neg} GR.10 <> CQ &  &  & \cellcolor{smGreen} & \cellcolor{smGreen} \\
&  &  \cellcolor{smGreen}  &  &  & \cellcolor{smGreen} & \cellcolor{smGreen}\textit{neg} SM.11 <> CQ &  &  & \cellcolor{smGreen} & \cellcolor{smGreen} \\
\midrule
{5:

pak} & \cellcolor{smGreen}{+} & \cellcolor{smGreen}{+OR.1} & \cellcolor{smGreen}{$-$SQ} & $-$CQ & \cellcolor{smGreen}{\textit{neg} LX.4 <> SQ} & \cellcolor{smGreen}\textit{neg} LX.3 <> CQ & \cellcolor{smGreen}{($-$)} & \cellcolor{smGreen}{($-$)} & \cellcolor{smGreen}{\textit{pos} TERbase <> Q} & \cellcolor{smGreen}\textit{pos} hLEPOR <> Q\\
& \cellcolor{smGreen} &  \cellcolor{smGreen}$-$GR.10  & \cellcolor{smGreen} &  & \cellcolor{smGreen} & \cellcolor{smGreen}\textit{neg} LX.4 <> CQ & \cellcolor{smGreen} & \cellcolor{smGreen}  & \cellcolor{smGreen} &\cellcolor{smGreen} \\
& \cellcolor{smGreen} &  \cellcolor{smGreen}  & \cellcolor{smGreen} &  & \cellcolor{smGreen} & \cellcolor{smGreen}\textit{neg} GR.10 <> CQ & \cellcolor{smGreen} & \cellcolor{smGreen}  & \cellcolor{smGreen} &\cellcolor{smGreen} \\
\midrule
{6:

pas} & {+} & {} & \cellcolor{smGreen}{$-$SQ} & \cellcolor{smGreen}$-$CQ & \cellcolor{smGreen}\textit{neg} LX.4 <> SQ & \cellcolor{smGreen}\textit{neg} GR.10 <> CQ & \cellcolor{smGreen}{($-$)} & \cellcolor{smGreen}{($-$)} & \cellcolor{smGreen}\textit{pos} TERbase <{}<{}>{}> Q & \cellcolor{smGreen}\textit{pos} hLEPOR <{}<{}>{}> Q\\
&  &  &\cellcolor{smGreen}  &\cellcolor{smGreen}  & \cellcolor{smGreen}\textit{neg} GR.10 <> SQ & \cellcolor{smGreen}\textit{neg} SM.11 <> CQ & \cellcolor{smGreen}  & \cellcolor{smGreen}  &\cellcolor{smGreen}  &\cellcolor{smGreen} \\
&  &  &\cellcolor{smGreen}  &\cellcolor{smGreen}  & \cellcolor{smGreen} & \cellcolor{smGreen}\textit{neg} SM.12 <> CQ & \cellcolor{smGreen}  & \cellcolor{smGreen}  &\cellcolor{smGreen}  &\cellcolor{smGreen} \\
\midrule
{7:

per} & \cellcolor{smGreen}{($-$)} & \cellcolor{smGreen}{+LX.4} & \cellcolor{smGreen}{+SQ} & \cellcolor{smGreen}+CQ & \cellcolor{smGreen}\textit{neg} GR.8 <{}<{}>{}> SQ & \cellcolor{smGreen}\textit{neg} GR.8 <{}<{}>{}> CQ & \cellcolor{smGreen}{+} & \cellcolor{smGreen}{+} & \cellcolor{smGreen}{\textit{pos} TERbase <> Q} & \cellcolor{smGreen}\textit{pos} hLEPOR <> Q\\
& \cellcolor{smGreen}  & \cellcolor{smGreen}{$-$GR.8} & \cellcolor{smGreen} & \cellcolor{smGreen} & \cellcolor{smGreen}\textit{neg} LX.4 <> SQ & \cellcolor{smGreen}\textit{neg} GR.10 <> CQ &\cellcolor{smGreen}  &\cellcolor{smGreen}  & \cellcolor{smGreen} & \cellcolor{smGreen}\\
& \cellcolor{smGreen} & \cellcolor{smGreen}{{$-$GR.9}

 $-$GR.10}  & \cellcolor{smGreen}  & \cellcolor{smGreen} & \cellcolor{smGreen}\textit{neg} GR.10 <> SQ & \cellcolor{smGreen} & \cellcolor{smGreen} & \cellcolor{smGreen} & \cellcolor{smGreen} & \cellcolor{smGreen}\\
\midrule
{8:

prä} & \cellcolor{smGreen}{($-$)} & \cellcolor{smGreen}{$-$LX.4} & {+SQ} & +CQ & \cellcolor{smGreen}\textit{neg} LX.4 <> SQ & \cellcolor{smGreen}\textit{neg} LX.4 <> CQ & {+} & {+} & \cellcolor{smGreen}{\textit{pos} TERbase <> Q} & \cellcolor{smGreen}\textit{pos} hLEPOR <> Q\\
&\cellcolor{smGreen}  &\cellcolor{smGreen}  &  &  & \cellcolor{smGreen}\textit{neg} SM.11 <> SQ & \cellcolor{smGreen}\textit{neg} SM.11 <> CQ &  &  & \cellcolor{smGreen} & \cellcolor{smGreen}\\
\midrule
{9:

wte} & {($-$)} & \cellcolor{smGreen}{$-$OR.1} & \cellcolor{smGreen}{$-$SQ} & $-$CQ & \cellcolor{smGreen}\textit{neg} OR.1 <> SQ &  & \cellcolor{smGreen}{($-$)} & \cellcolor{smGreen}{($-$)} & \cellcolor{smGreen}{\textit{pos} TERbase <> Q} & \cellcolor{smGreen}\textit{pos} hLEPOR <> Q\\
&  & \cellcolor{smGreen} & \cellcolor{smGreen} &  & \cellcolor{smGreen}\textit{neg} GR.10 <> SQ &  & \cellcolor{smGreen} & \cellcolor{smGreen} & \cellcolor{smGreen} & \cellcolor{smGreen}\\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:88}Übersicht der Ergebnisse auf Regelebene   }
\bspnote{\scriptsize
SQ: Stilqualität; CQ: Inhaltsqualität; Q: allg. Qualität; \txgreen{Signifikant (p < 0,5)}; Blank: nicht signifikant; <> mittlere Korrelation (ρ >= 0,3);\\<{}<{}>{}> starke Korrelation (ρ >= 0,5); neg: negative Korrelation; pos: positive Korrelation\\
anz: Für zitierte Oberflächentexte gerade Anführungszeichen verwenden; fvg: Funktionsverbgefüge vermeiden; kos: Konditionalsätze mit ‚Wenn‘ einleiten; nsp: Eindeutige pronominale Bezüge verwenden; pak: Partizipial-konstruktionen vermeiden; pas: Passiv vermeiden; per: Konstruktionen mit „sein +~zu +~Infinitiv“ vermeiden; prä: Überflüssige Präfixe vermeiden; wte: Keine Wortteile weglassen\\
OR.1: Zeichensetzung; OR.2: Großschreibung; LX.3: Wort ausgelassen; LX.4: Zusätzliches Wort eingefügt; LX.5: Wort unübersetzt geblieben (auf DE wiedergegeben); LX.6: Konsistenzfehler; {GR.7: Falsche Wortart/Wortklasse}; GR.8: Falsches Verb (Zeitform, Komposition, Person); GR.9: Kongruenzfehler (Agreement); GR.10: Falsche Wortstellung; SM.11: Verwechslung des Sinns; SM.12: Falsche Wahl; SM.13: Kollokationsfehler
}
\end{sidewaystable}



Auf Regelebene hatten nur vier Regeln einen eindeutigen positiven Einfluss auf den MÜ-Output („anz -- Für zitierte Oberflächentexte gerade Anführungszeichen verwenden“, „fvg -- Funktionsverbgefüge vermeiden“, „kos -- Konditionalsätze mit ‚Wenn‘ einleiten“ und „per -- Konstruktionen mit ‚sein +~zu +~Infinitiv‘ vermeiden“): Die Fehleranzahl sank, die Stil- und Inhaltsqualität stiegen und die AEM-Scores von TERbase und hLEPOR verbesserten sich nach der Regelanwendung. Die positive Wirkung auf die Fehleranzahl, die Qualitätswerte sowie die AEM-Scores war bei den vier Regeln -- mit Ausnahme der Verbesserung der AEM-Scores bei der Regel „kos“ -- statistisch signifikant. Die signifikanten positiven Korrelationen zwischen den Veränderungen der Qualitätswerte und denen der AEM-Scores bekräftigen die positive Wirkung dieser Regeln (starke Korrelationen im Falle der Regeln „fvg“ und „kos“; mittlere Korrelationen im Falle der Regeln „anz“ und „per“). Unterschiedliche Fehlertypen gingen nach der Regelanwendung signifikant zurück. Der Rückgang dieser Fehlertypen korrelierte mit der Verbesserung der Stil- bzw. Inhaltsqualität. Auf der anderen Seite zeigten drei Regeln einen negativen Effekt („pak -- Partizipialkonstruktion vermeiden“, „pas -- Passiv vermeiden“ und „wte -- Keine Wortteile weglassen“), wobei die Ergebnisse nicht immer statistisch signifikant waren: Ein Anstieg der Fehleranzahl war nur bei der Regel „pak“ signifikant; die Stilqualität litt eindeutig bei allen drei Regeln, während der Rückgang der Inhaltsqualität nur bei der Regel „pas“ signifikant war; die Verschlechterung beider AEM-Scores war bei allen drei Regeln signifikant. Der negative Einfluss dieser Regeln konnte durch eine positive Korrelation zwischen den Veränderungen der Qualitätswerte und denen der AEM-Scores bestätigt werden. Auch hier waren die beeinflussten Fehlertypen, wie \tabref{tab:05:88} zeigt, unterschiedlich. Schließlich konnten die letzten zwei Regeln („nsp -- Eindeutige pronominale Bezüge verwenden“ und „prä -- Überflüssige Präfixe vermeiden“) keinen eindeutigen Effekt anzeigen: Nur bei der Regel „prä“ war der Rückgang der Fehleranzahl signifikant; ansonsten waren die Veränderungen in den Qualitätswerten und den AEM-Scores nach der Anwendung beider Regeln insignifikant.

\clearpage %for table
\section{Analyse auf MÜ-Systemebene}
\label{sec:5.4}

In diesem Kapitel werden die Studienergebnisse auf Systemebene regelübergreifend dargestellt. Ziel ist die fünf verschiedenen Systeme vor vs. nach der Anwendung der KS-Regeln zu vergleichen. Wie \sectref{sec:3.4.1} zeigt, beschäftigten sich die vorherigen Studien im Bereich der KS mit den älteren MÜ-Ansätzen. Ein Beitrag dieser Studie ist der (erstmalige) Vergleich eines NMÜ-Systems mit vier Systemen der früheren Ansätze im Hinblick auf die Anwendung von KS-Regeln. Hierbei wird folgender Frage nachgegangen: Inwiefern ist die Anwendung von KS-Regeln nach der Einführung der NMÜ zum Zwecke der maschinellen Übersetzbarkeit erforderlich?

Ein Überblick der analysierten MÜ-Systeme siehe \tabref{tab:05:89}.


\begin{table}
\begin{tabularx}{\textwidth}{lQ}

\lsptoprule

\textbf{Hybride MÜ-Systeme} & Bing von Microsoft, Systran\\
\tablevspace
\textbf{Statistisches MÜ-System} & SDL Free Translation\\
\tablevspace
\textbf{Regelbasiertes MÜ-System} & Lucy LT KWIK Translator von Lucy Software and Services GmbH\\
\tablevspace
\textbf{Neuronale Netze-basiertes MÜ-System} & Google Translate\\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:89}Überblick der analysierten MÜ-Systeme   }
\end{table}

Wie unter \sectref{sec:4.4.1} erläutert, wurden zwei Hybridsysteme analysiert, da sie unterschiedlich aufgebaut werden. Dies wurde auch durch die in vielen Fällen unterschiedlichen Outputs ersichtlich. Im Folgenden gibt uns der erste Abschnitt eine Übersicht über die Analysefaktoren, die zugrundeliegenden Fragestellungen und Hypothesen sowie die statistische Auswertung. Danach folgen die Ergebnisse der quantitativen und qualitativen Analyse auf Systemebene. Bezüge auf vorherige Studien werden nicht in diesem Unterkapitel, sondern im Rahmen der Diskussion in \sectref{ch:6} vorgenommen.

\subsection{Analysefaktoren}
\label{sec:5.4.0}

Der Vergleich des MÜ-Outputs vor vs. nach der Anwendung aller analysierten KS-Regeln auf Systemebene erfolgte nach den folgenden neun Analysefaktoren:

\subsubsection*{Erster Analysefaktor: Vergleich der Fehleranzahl vor vs. nach der Anwendung der KS-Regeln}

\begin{itemize}
\item Fragestellung: Gibt es \textit{bei einem bestimmten MÜ-System} einen Unterschied in der Fehleranzahl nach der Anwendung der KS-Regeln im Vergleich zu vor der Anwendung?

\item Variablen: Summe der Fehler und Mittelwert der Fehleranzahl (von allen Fehlertypen) innerhalb der KS-Stelle; Variablentyp: ordinal

\item Statistische Auswertung: Deskriptive Statistiken auf Basis der Fehlerannotation; Abbildungen: Balken

\item Hypothesen:

\begin{itemize}

\item[H0 --] Es gibt keinen Unterschied in der Fehleranzahl vor vs. nach der Anwendung der KS-Regeln.

\item[H1 --] Es gibt einen Unterschied in der Fehleranzahl vor vs. nach der Anwendung der KS-Regeln.

\end{itemize}
\item Signifikanztest: Wilcoxon; Begründung der Testauswahl: Die Variablen sind ordinal.

\end{itemize}

\subsubsection*{Zweiter Analysefaktor: Vergleich der Fehleranzahl vor vs. nach der Anwendung der KS-Regeln außerhalb der KS-Stelle bei der Gruppe RR}

\begin{itemize}
\item Fragestellung: Wurde die KS-Stelle \textit{bei einem bestimmten MÜ-System} vor und nach der Anwendung der KS-Regeln korrekt übersetzt und stieg \textit{gleichzeitig} die Fehleranzahl \textit{außerhalb} der KS-Stelle nach der Anwendung der KS-Regeln?

\item Variablen: Differenzen in der Fehleranzahl bei der Annotationsgruppe RR (RR: MÜ innerhalb der KS-Stelle ist vor und nach der Anwendung der KS-Regeln fehlerfrei); Variablentyp: ordinal.

\item Statistische Auswertung: Häufigkeitstabelle auf Basis der Fehlerannotation

\end{itemize}

\subsubsection*{Dritter Analysefaktor: Aufteilung der Annotationsgruppen}

\begin{itemize}
\item In der Studie werden die Ergebnisse der Fehlerannotation in vier Annotationsgruppen unterteilt:
(1) RR: MÜ ist vor und nach der Anwendung der KS-Regel fehlerfrei; (2) FF: MÜ beinhaltet vor und nach der Anwendung der KS-Regel Fehler; (3) RF: MÜ ist nur vor der Anwendung der KS-Regel fehlerfrei; (4) FR: MÜ ist nur nach der Anwendung der KS-Regel fehlerfrei.

\item Fragestellung: Wie hoch ist der Prozentsatz jeder Annotationsgruppe \textit{bei den einzelnen MÜ-Systemen}?

\item Statistische Auswertung: Häufigkeiten mit Bootstrapping\footnote{{{{Bootstrapping ist ein statistisches Verfahren zur Schätzung der Stichprobenverteilung eines Schätzers durch erneute Stichprobenerstellung mit Ersatz aus der ursprünglichen Stichprobe. Es wird als ein nützliches Verfahren zum Testen der Modellstabilität angesehen.~(\citealt{IBMnodate})}}}} auf Basis der Fehlerannotation; Abbildungen: Balken

\end{itemize}

\subsubsection*{Vierter Analysefaktor: Vergleich der Fehlertypen vor vs. nach der Anwendung der KS-Regeln}

\begin{itemize}
\item Es werden die 13 analysierten Fehlertypen vor vs. nach der Anwendung der KS-Regeln verglichen.

\item Fragestellung: Kommen bestimmte Fehlertypen \textit{bei einem bestimmten MÜ-System} vor bzw. nach der Anwendung der KS-Regeln vor?

Davon wird bei jedem MÜ-System abgeleitet, (1) ob bestimmte Fehlertypen, die vor der Anwendung der KS-Regeln existierten, nach der Anwendung der KS-Regeln eliminiert bzw. reduziert wurden; (2) ob bestimmte Fehlertypen erst nach der Anwendung der KS-Regeln auftraten bzw. deutlich stiegen (im Vergleich zu vor der Anwendung der KS-Regeln).

\item Variablen: Fehler existiert ja/nein; Fehlertyp: dichotom. Summe der Fehler sowie Mittelwert der Fehleranzahl innerhalb der KS-Stelle; Variablentyp: ordinal

\item Statistische Auswertung: Kreuztabellen auf Basis der Fehlerannotation; Abbildungen: Fehlerbalken

\item Hypothesen:

\begin{itemize}

\item[H0 --] Es gibt keinen Unterschied in der Häufigkeit der einzelnen Fehlertypen vor vs. nach der Anwendung der KS-Regeln.

\item[H1 --] Es gibt einen Unterschied in der Häufigkeit der einzelnen Fehlertypen vor vs. nach der Anwendung der KS-Regeln.

\end{itemize}
\item Signifikanztest: McNemar; Begründung der Testauswahl: Mithilfe des\linebreak McNe\-mar-Tests können zwei verbundene dichotome Parameter verglichen werden, somit kann eine mögliche signifikante Veränderung bei einem Fehlertyp vor vs. nach der Anwendung der KS-Regeln identifiziert werden.

\end{itemize}

\subsubsection*{Fünfter Analysefaktor: Vergleich der Qualität vor vs. nach der Anwendung der KS-Regeln}

\begin{itemize}
\item Fragestellung: Gibt es \textit{bei einem bestimmten MÜ-System} einen Unterschied in der Stil- und Inhaltsqualität der MÜ der KS-Stelle nach der Anwendung der KS-Regeln im Vergleich zu vor der Anwendung?

\item Variablen: Mittelwert der Qualitätspunktzahlen der acht Teilnehmer auf der Likert-Skala; Variablentyp: metrisch

\item Statistische Auswertung: Deskriptive Statistiken auf Basis der Humanevaluation; Abbildungen: Fehlerbalken

\item Hypothesen:

\begin{itemize}

\item[H0 --] Es gibt keinen Qualitätsunterschied vor vs. nach der Anwendung der KS-Regeln.

\item[H1 --] Es gibt einen Qualitätsunterschied vor vs. nach der Anwendung der KS-Regeln.

\end{itemize}
\item Signifikanztest: Wilcoxon; Begründung der Testauswahl: Nicht alle Qualitätswerte sind normalverteilt. Wilcoxon kann bei normalverteilten sowie nicht-normalverteilten Variablen verwendet werden.

\end{itemize}

\subsubsection*{Sechster Analysefaktor: Vergleich der Qualität vor vs. nach der Anwendung der KS-Regeln auf Annotationsgruppenebene}

\begin{itemize}
\item Fragestellung: Gibt es \textit{bei einem bestimmten MÜ-System} einen Unterschied in der Stil- und Inhaltsqualität bei den einzelnen Annotationsgruppen nach der Anwendung der KS-Regeln im Vergleich zu vor der Anwendung?

Davon wird abgeleitet, (1) ob bei der Gruppe RR die Stil- bzw. Inhaltsqualität vor bzw. nach der Anwendung der KS-Regeln höher ist, obwohl die MÜ in beiden Fällen fehlerfrei ausfällt; (2) ob bei der Gruppe FF die Stil- bzw. Inhaltsqualität vor bzw. nach der Anwendung der KS-Regeln höher ist, obwohl die MÜ in beiden Fällen Fehler beinhaltet; (3) ob bei der Gruppe RF die Stil- bzw. Inhaltsqualität nach der Anwendung der KS-Regeln stieg, obwohl die MÜ nach der Anwendung der KS-Regeln Fehler beinhaltet und davor fehlerfrei war; (4) ob bei der Gruppe FR die Stil- bzw. Inhaltsqualität nach der Anwendung der KS-Regeln sank, obwohl die MÜ nach der Anwendung der KS-Regeln fehlerfrei ist und davor Fehler beinhaltete.

\item Variablen: Mittelwert der Qualitätspunktzahlen der acht Teilnehmer auf der Likert-Skala in jeder Annotationsgruppe; Variablentyp: metrisch

\item Statistische Auswertung: Deskriptive Statistiken auf Basis der Humanevaluation unter Aufteilung der Daten nach den Annotationsgruppen; Abbildungen: Fehlerbalken

\item Hypothesen:

\begin{itemize}

\item[H0 --] Bei den Annotationsgruppen gibt es keinen Qualitätsunterschied vor vs. nach der Anwendung der KS-Regeln.

\item[H1 --] Bei den Annotationsgruppen gibt es einen Qualitätsunterschied vor vs. nach der Anwendung der KS-Regeln.

\end{itemize}
\item Signifikanztest: Wilcoxon; Begründung der Testauswahl: Nicht alle Qualitätswerte sind normalverteilt. Wilcoxon kann bei normalverteilten sowie nicht-normalverteilten Variablen verwendet werden.

\end{itemize}

\subsubsection*{Siebter Analysefaktor: Korrelation zwischen den Fehlertypen und der Qualität}

\begin{itemize}
\item Fragestellung: Besteht \textit{bei einem bestimmten MÜ-System} ein Zusammenhang zwischen der Differenz der Fehleranzahl eines bestimmten Fehlertyps (Fehleranzahl nach KS \textit{minus} Fehleranzahl vor KS) und der Differenz der Stil- bzw. Inhaltsqualität (Qualität nach KS \textit{minus} Qualität vor KS)?

\item Variablen: Differenz der Mittelwerte der Qualitätspunktzahlen der acht Teilnehmer auf der Likert-Skala; Variablentyp: metrisch. Differenz der Fehleranzahl der einzelnen Fehlertypen; Variablentyp: ordinal.

\item Statistische Auswertung: Spearman-Korrelationstest

\item Hypothesen:

\begin{itemize}

\item[H0 --] Es besteht kein Zusammenhang zwischen der Differenz der Fehleranzahl eines bestimmten Fehlertyps und der Differenz der Stil- bzw. Inhaltsqualität.

\item[H1 --] Es besteht ein Zusammenhang zwischen der Differenz der Fehleranzahl eines bestimmten Fehlertyps und der Differenz der Stil- bzw. Inhaltsqualität.

\end{itemize}
\item Signifikanztest: Spearman-Korrelationstest; Begründung der Testauswahl: Eine der Variablen ist ordinal. Zudem setzt Spearman keine Anforderung an die Verteilung und die Linearität voraus.

\end{itemize}

\subsubsection*{Achter Analysefaktor: Vergleich der AEM-Scores vor vs. nach der Anwendung der KS-Regeln}

\begin{itemize}
\item Fragestellung: Gibt es \textit{bei einem bestimmten MÜ-System} einen Unterschied in den AEM-Scores von TERbase bzw. hLEPOR nach der Anwendung der KS-Regeln im Vergleich zu vor der Anwendung?

\item Variablen: Mittelwert der AEM-Scores\footnote{\textrm{Bei jeder MÜ wurde der Mittelwert der AEM-Scores auf Basis von zwei Referenzübersetzungen ermittelt; für eine genaue Beschreibung des Verfahrens siehe \sectref{sec:4.4.6.4}.}} und Differenzen der AEM-Scores (AEM-Score nach KS \textit{minus} AEM-Score vor KS); Variablentyp: metrisch

\item Statistische Auswertung: Deskriptive Statistiken auf Basis der automatischen Evaluation; Abbildungen: Fehlerbalken für die Differenzen der AEM-Scores\footnote{\textrm{Bei der Auswertung werden nur die Differenzen der AEM-Scores (und nicht die Mittelwerte der AEM-Scores) verwendet. Der Grund dafür ist, dass die Bewerter die komplette MÜ editiert haben. Ihre Edits können daher Stellen außerhalb der KS-Stelle umfassen. Da aber die MÜ vor und nach KS außerhalb der KS-Stelle vereinheitlicht wurden, wird hier davon ausgegangen, dass wir durch die Verwendung der Differenz (AEM-Score nach KS minus AEM-Score vor KS) nur die Edits innerhalb der KS-Stelle betrachten; für eine detaillierte Erläuterung siehe \sectref{sec:4.4.6.4}.}}

\item Hypothesen:

\begin{itemize}

\item[H0 --] Es gibt keinen Unterschied in den AEM-Scores vor vs. nach der Anwendung der KS-Regeln.

\item[H1 --] Es gibt einen Unterschied in den AEM-Scores vor vs. nach der Anwendung der KS-Regeln.

\end{itemize}
\item Signifikanztest: Wilcoxon; Begründung der Testauswahl: Nicht alle Qualitätswerte sind normalverteilt. Wilcoxon kann bei normalverteilten sowie nicht-normalverteilten Variablen verwendet werden.

\end{itemize}

\subsubsection*{Neunter Analysefaktor: Korrelation zwischen den AEM-Scores-Differenzen und der Qualitätsdifferenz}

\begin{itemize}
\item Fragestellung: Besteht \textit{bei einem bestimmten MÜ-System} ein Zusammenhang zwischen der Differenz der AEM-Scores in TERbase bzw. hLEPOR (Mittelwert der AEM-Scores nach KS \textit{minus} Mittelwert der AEM-Scores vor KS) und der Differenz der allgemeinen Qualität\footnote{\textrm{Die allgemeine Qualität ist der Mittelwert der Stilqualität und der Inhaltsqualität, da bei der Untersuchung dieser Korrelation keine Unterscheidung zwischen} {{{der Stil- und Inhaltsqualität}}} \textrm{notwendig ist.}} (Qualität nach KS \textit{minus} Qualität vor KS)?

\item Variablen: Differenz der Mittelwerte der AEM-Scores sowie Differenz der Mittelwerte der Qualitätspunktzahlen der acht Teilnehmer auf der Likert-Skala; Variablentyp: metrisch

\item Statistische Auswertung: Spearman-Korrelationstest

\item Hypothesen:

\begin{itemize}

\item[H0 --] Es besteht kein Zusammenhang zwischen der Differenz der AEM-Scores und der Differenz der allgemeinen Qualität.

\item[H1 --] Es besteht ein Zusammenhang zwischen der Differenz der AEM-Scores und der Differenz der allgemeinen Qualität.

\end{itemize}
\item Signifikanztest: Spearman-Korrelationstest; Begründung der Testauswahl: Nicht alle Variablen sind normalverteilt. Spearman setzt keine Anforderung an die Verteilung und die Linearität voraus.

\end{itemize}


\subsection{Vergleich der Fehleranzahl vor vs. nach der Anwendung aller analysierten KS-Regeln}\label{sec:5.4.1}

Die Veränderungsrichtung in der Fehleranzahl nach der Umsetzung der KS-Re\-geln war unterschiedlich:


\begin{figure}
%\textbf{$-$ 16,1~\%}

%\textbf{\textit{$-$ 38,0~\%}}

%\textbf{\textit{$-$ 52,4~\%}}

%\textbf{+~6,1~\%}

%\textbf{+~10,1~\%}



%\includegraphics[height=.3\textheight]{figures/d3-img109.png}


%\includegraphics[height=.3\textheight]{figures/d3-img109.png}\\
\begin{tikzpicture}
	\begin{axis}[
	ybar,
	ymin = 0,
	ymax = 250,
	axis lines* = left,
	nodes near coords,
  legend style={at={(0.5,-0.2)},anchor=north},
  xticklabels = {Bing,Google,Lucy,SDL,Systran},
  xtick=data,
  ylabel = {Summe},
  extra description/.code={
            \node at (axis cs:-.4, 200)[anchor=west] {\bfitul{$-$ 52,4~\%}};
						\node at (axis cs:.5, 70)[anchor=west] {+~6,1~\%};
						\node at (axis cs:1.5, 200)[anchor=west] {$-$ 16,1~\%};
						\node at (axis cs:2.5, 250)[anchor=west] {\bfitul{$-$ 38,0~\%}};
						\node at (axis cs:3.5, 225)[anchor=west] {+~10,1~\%};
						}
	]
	\addplot+[tmnlpone]
	coordinates{
	(0,166)
	(1,33)
	(2,149)
	(3,221)
	(4,169)
	};
	\addplot+[tmnlpthree]
	coordinates{
	(0,79)
	(1,35)
	(2,125)
	(3,137)
	(4,186)
	};
	\legend{Anzahl der  fehler innerh. KS vor KS,Anzahl der Fehler innerh. KS nach KS}
	\end{axis}
\end{tikzpicture}
\caption{\label{fig:05:137}Summe der Fehleranzahl vor vs. nach KS auf MÜ-Systemebene   }
\bspnote{\bfitul{Signifikante Differenz vor vs. nach KS}}
\end{figure}

Die \textit{HMÜ}{}-Systeme reagierten unterschiedlich. Die Fehleranzahl sank nach der Anwendung der KS-Regeln bei Bing deutlich um 52~\% (\figref{fig:05:137}). Die Differenz (nach KS \textit{minus} vor KS) lag durchschnittlich bei $-$ ,403 und erwies sich als signifikant (z (N = 216) = $-$ 5,463 / p < ,001). Bei Systran hingegen gab es einen kleinen (insignifikanten) Anstieg in der Fehleranzahl von 10,1~\% mit einer durchschnittlichen Differenz von ,079 (\figref{fig:05:138}).\footnote{\figref{fig:05:138} ist wie folgt zu lesen: Die Punkte zeigen, wie hoch die durchschnittliche Fehleranzahl ausfällt (z.~B. ,77 vor KS bei Bing). Die Fehlerbalken zeigen das realisierte 95 \%-Konfidenzintervall (CI) für die durchschnittliche Fehleranzahl (in dem Fall beläuft sich das CI vor KS bei Bing auf ,65; ,89). Demnach würde die Fehleranzahl bei der Durchführung einer weiteren vergleichbaren Untersuchung mit einer Wahrscheinlichkeit von 95~\% zwischen ,65 und ,89 liegen (vgl. \citealt{Eckstein2008}: 81).}

Ebenfalls stieg die Fehleranzahl bei dem \textit{NMÜ}{}-System Google Translate minimal um 6,1~\%. Dies ist eine Differenz von nur zwei Fehlern (\figref{fig:05:137}). Zudem verzeichnete Google Translate die geringste Fehleranzahl sowohl vor als auch nach der Anwendung der KS-Regeln.


\begin{figure}
\includegraphics[width=\textwidth]{figures/d3-img110.png}\\


%\includegraphics[height=.3\textheight]{figures/d3-img110.png}\\
\caption{\label{fig:05:138}Mittelwert der Fehleranzahl pro Satz vor vs. nach KS auf MÜ-Systemebene   }
\end{figure}

Bei dem \textit{SMÜ}{}-System SDL sank die Fehleranzahl signifikant um 38~\% (\figref{fig:05:137}). Die Differenz (nach KS minus vor KS) lag durchschnittlich bei $-$ ,389 (z (N = 216) = $-$ 4,265 / p < ,001).

Bei dem \textit{RBMÜ}{}-System Lucy sank die Fehleranzahl insignifikant (p = ,050) um 16~\% mit einer durchschnittlichen Differenz von $-$ ,111 (\figref{fig:05:138}).


\subsection{Vergleich der Fehleranzahl vor vs. nach KS außerhalb der KS-Stelle bei der Gruppe RR}
\label{sec:5.4.2}

Eine Untersuchung der Fehleranzahl außerhalb der KS-Stelle bei der Gruppe RR war erforderlich, um herauszufinden, ob bei einem bestimmten MÜ-System die KS-Stelle vor und nach der Anwendung der KS-Regeln korrekt übersetzt wurde und \textit{gleichzeitig} die Fehleranzahl \textit{außerhalb} der KS-Stelle nach der Anwendung der KS-Regeln stieg. %In der folgenden Häufigkeitstabelle
In \tabref{tab:05:90} sind die Ergebnisse präsentiert (N = 490).


\begin{table}
\small
\begin{tabularx}{\textwidth}{rrrrrrr}

\lsptoprule

\makecell[tr]{\textbf{Differenz Fehleranzahl}\\\textbf{nach KS $-$} \textbf{vor KS}\\\textbf{außerhalb KS}} & \makecell[tr]{\textbf{HMÜ}\\\textbf{Bing}} & \textbf{GNMÜ} & \makecell[tr]{\textbf{RBMÜ}\\\textbf{Lucy}} & \makecell[tr]{\textbf{SMÜ}\\\textbf{SDL}} & \makecell[tr]{\textbf{HMÜ}\\\textbf{Systran}} & \textbf{Gesamt}\\
 \midrule
 \textbf{+~3} & 2 & 0 & 0 & 1 & 0 & 3\\
 \textbf{+~2} & 1 & 0 & 0 & 1 & 0 & 2\\
 \textbf{+~1} & \txgray{12} & \txgray{10} & 2 & 2 & 1 & 27\\
 \textbf{0} & 53 & 166 & 82 & 42 & 70 & 413\\
 \textbf{$-$ 1} & 7 & 7 & 5 & 8 & 3 & 30\\
 \textbf{$-$ 2} & 4 & 0 & 0 & 6 & 0 & 10\\
 \textbf{$-$ 3} & 2 & 0 & 1 & 1 & 0 & 4\\
 \textbf{$-$ 5} & 0 & 0 & 0 & 1 & 0 & 1\\
 \midrule
 \textbf{Gesamt} & 81 & 183 & 90 & 62 & 74 & 490\\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:90}Häufigkeit der Differenz der Fehleranzahl außerhalb der KS-Stelle bei einer korrekten Übersetzung der KS-Stelle auf MÜ-Systemebene   }
\end{table}

\tabref{tab:05:90} listet die Differenzen in der Fehleranzahl aller Übersetzungen auf, die innerhalb der KS-Stelle vor und nach der Anwendung der jeweiligen KS-Regel fehlerfrei waren, aber eine Veränderung in der Fehleranzahl außerhalb der KS-Stelle hatten. Aus den Ergebnissen geht hervor, dass kein deutlicher Anstieg der Fehleranzahl nach der Anwendung der KS bei einem bestimmten MÜ-System festgestellt werden konnte. Nur bei Google und Bing stieg die Fehleranzahl +~1 Fehler bei Google 10 Mal innerhalb von 183 Fällen und bei Bing 12 Mal innerhalb von 81 Fällen.

\subsection{Aufteilung der Annotationsgruppen}
\label{sec:5.4.3}

Der Vergleich der Annotationsgruppen deckte bemerkungswerte Ergebnisse auf. \figref{fig:05:139} verdeutlicht wie unterschiedlich die Verteilung der vier Annotationsgruppen in den drei älteren MÜ-Ansätzen (SMÜ, RBMÜ und HMÜ) auf einer Seite und dem neuronalen Ansatz auf der anderen Seite ausfällt.


\begin{figure}
%\textbf{18\% 35\%}  \textbf{9\%}    \textbf{38\%}          \textbf{9\%}    \textbf{4\%}    \textbf{4\%}   \textbf{83\%}         \textbf{33\%}  \textbf{17\%}  \textbf{10\% 39\%}          \textbf{30\%}  \textbf{30\% 12\% 29\%}          \textbf{39\%}  \textbf{13\% 14\%}  \textbf{34\%}



%\includegraphics[height=.3\textheight]{figures/d3-img111.png}



%\includegraphics[height=.3\textheight]{figures/d3-img012.png}\\
\begin{tikzpicture}
\tikzset{every node/.style={font=\scriptsize}};
	\begin{axis}[
	ybar,
  width=\textwidth,
	ymin = 0,
	ymax = 200,
	axis lines* = left,
	nodes near coords,
  legend style={at={(0.5,-0.1)},anchor=north},
  legend columns = {-1},
%  xtick = {1,2,3,4},
  xticklabels = {Bing,Google,Lucy,SDL,Systran},
  xtick=data,
  x tick label style ={yshift=-5pt},
  ylabel = {Anzahl},
  extra description/.code={
            \node at (axis cs:-.45, 51)[anchor=west] {3,8\%};
            \node at (axis cs:-.45, -2.5)[anchor=west] {18\%};
            \node at (axis cs:-.25, 90)[anchor=west] {7,0\%};
            \node at (axis cs:-.25, -2.5)[anchor=west] {35\%};
            \node at (axis cs:-.05, 40)[anchor=west] {1,9\%};
            \node at (axis cs:-.05, -2.5)[anchor=west] {9\%};
            \node at (axis cs:.14, 100)[anchor=west] {7,5\%};
            \node at (axis cs:.14, -2.5)[anchor=west] {38\%};
            \node at (axis cs:.6, 40)[anchor=west] {1,9\%};
            \node at (axis cs:.6, -2.5)[anchor=west] {9\%};
            \node at (axis cs:.78, 30)[anchor=west] {0,8\%};
            \node at (axis cs:.78, -2.5)[anchor=west] {4\%};
            \node at (axis cs:0.9, 25)[anchor=west] {0,7\%};
            \node at (axis cs:0.95, -2.5)[anchor=west] {4\%};
            \node at (axis cs:1.1, 200)[anchor=west] {16,6\%};
            \node at (axis cs:1.15, -2.5)[anchor=west] {83\%};
            \node at (axis cs:1.55, 90)[anchor=west] {6,7\%};
            \node at (axis cs:1.55, -2.5)[anchor=west] {33\%};
            \node at (axis cs:1.77, 55)[anchor=west] {3,4\%};
            \node at (axis cs:1.75, -2.5)[anchor=west] {17\%};
            \node at (axis cs:1.9, 40)[anchor=west] {2,0\%};
            \node at (axis cs:1.93, -2.5)[anchor=west] {10\%};
            \node at (axis cs:2.15, 100)[anchor=west] {7,9\%};
            \node at (axis cs:2.15, -2.5)[anchor=west] {39\%};
            \node at (axis cs:2.6, 80)[anchor=west] {5,9\%};
            \node at (axis cs:2.55, -2.5)[anchor=west] {30\%};
            \node at (axis cs:2.79, 85)[anchor=west] {6,0\%};
            \node at (axis cs:2.76, -2.5)[anchor=west] {30\%};
            \node at (axis cs:2.92, 45)[anchor=west] {2,3\%};
            \node at (axis cs:2.96, -2.5)[anchor=west] {12\%};
            \node at (axis cs:3.1, 80)[anchor=west] {5,7\%};
            \node at (axis cs:3.15, -2.5)[anchor=west] {29\%};
            \node at (axis cs:3.6, 100)[anchor=west] {7,8\%};
            \node at (axis cs:3.55, -2.5)[anchor=west] {39\%};
            \node at (axis cs:3.77, 50)[anchor=west] {2,5\%};
            \node at (axis cs:3.75, -2.5)[anchor=west] {13\%};
            \node at (axis cs:3.9, 55)[anchor=west] {2,9\%};
            \node at (axis cs:3.95, -2.5)[anchor=west] {14\%};
            \node at (axis cs:4.1, 90)[anchor=west] {6,9\%};
            \node at (axis cs:4.15, -2.5)[anchor=west] {34\%};
						}
	]
	\addplot+[tmnlpone]
	coordinates{
	(0,39)
	(1,20)
	(2,72)
	(3,64)
  (4,84)
	};
	\addplot+[tmnlptwo]
	coordinates{
	(0,76)
	(1,9)
	(2,37)
	(3,65)
	(4,27)
	};
  \addplot+[tmnlpthree]
	coordinates{
	(0,20)
	(1,8)
	(2,22)
	(3,25)
	(4,31)
	};
  \addplot+[tmnlpfour]
	coordinates{
	(0,81)
	(1,179)
	(2,85)
	(3,62)
	(4,74)
	};
	\legend{FF,FR,RR,RF}
	\end{axis}
\end{tikzpicture}
\caption{\label{fig:05:139}Aufteilung der Annotationsgruppen auf MÜ-Systemebene   }
\bspnote{Die oberen Prozentzahlen sind auf Basis des Gesamtdatensatzes (N = 1080) berechnet.

Die unteren Prozentzahlen sind auf Systemebene (N = 216) berechnet.}
\end{figure}

Das \textit{NMÜ}{}-System Google Translate produzierte die meisten Übersetzungen, die sowohl vor der Anwendung der KS-Regeln als auch nachher fehlerfrei (Gruppe RR) waren. Diese Gruppe betrug bei Google Translate 83~\% seiner Übersetzungen (N = 216) bzw. knapp 17~\% des Datensatzes (N = 1080). Mit 83~\% RR war Google Translate in der Lage, mehr als doppelt so viel wie alle anderen Systeme mit und ohne die Anwendung der KS-Regeln fehlerfrei zu übersetzen, denn die Gruppe RR war in den anderen Systemen höchstens mit 39~\% -- beim \textit{RBMÜ}{}-System Lucy -- präsent (\figref{fig:05:139}).

Zudem war beim \textit{RBMÜ}{}-System Lucy ein Drittel der Übersetzungen (33~\% / N = 216) sowohl vor als auch nach der KS (Gruppe FF) falsch. Ferner konnten die Regeln in nur 17~\% der Fälle Lucy dabei unterstützen, die vor-KS aufgetretenen Fehler zu beheben (Gruppe FR).

In den \textit{HMÜ}{}-Systemen: Bing konnte hingegen mehr als ein Drittel (35~\% / N = 216) der falschen Übersetzungen nach KS korrekt übersetzt werden (Gruppe FR). Im anderen HMÜ-System Systran war die Gruppe FF am meisten präsentiert (39~\% / N = 216).

Im \textit{SMÜ}{}-System SDL konnte etwas weniger als ein Drittel (30~\% / N = 216) der falschen Übersetzungen nach KS korrekt übersetzt werden (Gruppe FR). Gleichzeitig gab es genauso viele (30~\% / N = 216) Übersetzungen, die sowohl vor als auch nach der KS falsch übersetzt waren (Gruppe FF).

Die Ermittlung der Konfidenzintervalle (CI 95~\%) der Aufteilung der Annotationsgruppen mithilfe eines Bootstrapping mit 1000 Stichproben ergab
die Werte in \tabref{tab:05:91} (N = 216).%folgende Werte (N = 216):


\begin{table}
\small
\begin{tabularx}{\textwidth}{llrrrrr}

\lsptoprule

{\textbf{System}} & \textbf{Annota-} & \textbf{Häufigkeit} & \textbf{Prozente} & \multicolumn{3}{c}{\textbf{Bootstrapping}}\\
\cmidrule(lr){5-7}
& \textbf{tions-} &  &  &  & \multicolumn{2}{c}{\textbf{95\%-Konfidenzintervall}}\\
\cmidrule(lr){6-7}
 & \textbf{gruppe} &  &  & \textbf{\makecell[tr]{Verzer-\\rung}} & \textbf{\makecell[tr]{Unterer\\Wert}} & \textbf{\makecell[tr]{Oberer\\Wert}}\\
 \midrule
{\textbf{HMÜ}} &  FF & 39 & 18,1 & $-$ ,1 & 13,0 & 23,3\\
\textbf{Bing} &  FR & 76 & 35,2 & ,2 & 29,6 & 41,8\\
%\hhline%%replace by cmidrule{~------}
 &  RF & 20 & 9,3 & ,0 & 5,4 & 13,6\\
%\hhline%%replace by cmidrule{~------}
 &  RR & 81 & 37,5 & $-$ ,1 & 30,8 & 43,8\\
%\hhline%%replace by cmidrule{~------}
 &  Gesamt & 216 & 100,0 & 0,0 & 100,0 & 100,0\\
\midrule
{\textbf{GNMÜ}} &  FF & 20 & 9,3 & $-$ ,1 & 5,7 & 13,2\\
&  FR & 9 & 4,2 & ,0 & 1,8 & 7,2\\
%\hhline%%replace by cmidrule{~------}
 &  RF & 8 & 3,7 & ,0 & 1,4 & 6,4\\
%\hhline%%replace by cmidrule{~------}
 &  RR & 179 & 82,9 & ,0 & 78,1 & 87,8\\
%\hhline%%replace by cmidrule{~------}
 &  Gesamt & 216 & 100,0 & 0,0 & 100,0 & 100,0\\
\midrule
{\textbf{RBMÜ}} &  FF & 72 & 33,3 & ,0 & 27,2 & 39,9\\
\textbf{Lucy} &  FR & 37 & 17,1 & ,1 & 12,5 & 22,6\\
%\hhline%%replace by cmidrule{~------}
 &  RF & 22 & 10,2 & ,0 & 6,3 & 14,5\\
%\hhline%%replace by cmidrule{~------}
 &  RR & 85 & 39,4 & $-$ ,1 & 32,8 & 45,9\\
%\hhline%%replace by cmidrule{~------}
 &  Gesamt & 216 & 100,0 & 0,0 & 100,0 & 100,0\\
\midrule
{\textbf{SMÜ}} &  FF & 64 & 29,6 & ,0 & 23,6 & 36,0\\
\textbf{SDL} &  FR & 65 & 30,1 & ,0 & 23,9 & 36,9\\
%\hhline%%replace by cmidrule{~------}
 &  RF & 25 & 11,6 & ,0 & 7,5 & 16,1\\
%\hhline%%replace by cmidrule{~------}
 &  RR & 62 & 28,7 & $-$ ,1 & 22,7 & 35,2\\
%\hhline%%replace by cmidrule{~------}
 &  Gesamt & 216 & 100,0 & 0,0 & 100,0 & 100,0\\
\midrule
{\textbf{HMÜ}} &  FF & 84 & 38,9 & $-$ ,1 & 32,1 & 45,2\\
\textbf{Systran} &  FR & 27 & 12,5 & ,0 & 8,1 & 17,2\\
%\hhline%%replace by cmidrule{~------}
 &  RF & 31 & 14,4 & ,1 & 10,0 & 19,5\\
%\hhline%%replace by cmidrule{~------}
 &  RR & 74 & 34,3 & ,0 & 28,0 & 40,6\\
%\hhline%%replace by cmidrule{~------}
 &  Gesamt & 216 & 100,0 & 0,0 & 100,0 & 100,0\\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:91}Konfidenzintervalle (CI 95~\%) der Aufteilung der Annotationsgruppen auf MÜ-Systemebene   }
\end{table}

Das 95\%-Konfidenzintervall besagt, dass bei der Durchführung einer weiteren vergleichbaren Untersuchung die Aufteilung mit einer Wahrscheinlichkeit von 95~\% zwischen den aufgeführten Unter- und Oberwerten liegen würde. Deutlich kleiner und entsprechend sicherer sind die Konfidenzintervalle bei dem NMÜ-System Google Translate im Vergleich zu den Konfidenzintervallen aller anderen Systemen.

\subsection{Vergleich der Fehlertypen vor vs. nach der Anwendung aller analysierten KS-Regeln}
\label{sec:5.4.4}

Die folgende Grafik veranschaulicht die Veränderungen in der Fehleranzahl, die nach der Anwendung der KS-Regeln bei den einzelnen Fehlertypen auftraten, und vergleicht in dieser Hinsicht die verschiedenen MÜ-Systeme. In allen Systemen mit Ausnahme von Google gab es mindestens zwei Fehlertypen, bei denen die Differenz in der Fehleranzahl (nach KS \textit{minus} vor KS) signifikant war. Im Folgenden werden die signifikanten Fehlertypen bei den einzelnen Systemen erläutert.


\begin{figure}

\includegraphics[width=\textwidth]{figures/d3-img112.png}

%\includegraphics[height=.3\textheight]{figures/d3-img112.png}



%\includegraphics[height=.3\textheight]{figures/d3-img112.png}

\caption{\label{fig:05:140}Differenz der Fehleranzahl der einzelnen Fehlertypen auf MÜ-Systemebene   }
\bspnote{Differenz der Fehleranzahl = Summe der Fehler nach KS \textit{minus} Summe der Fehler vor KS\\
Fehlertyp 1: Orthografie -- Zeichensetzung\\
Fehlertyp 2: Orthografie -- Großschreibung\\
Fehlertyp 3: Lexik -- Wort ausgelassen\\
Fehlertyp 4: Lexik -- Wort zusätzlich falsch eingefügt\\
Fehlertyp 5: Lexik -- Wort unübersetzt geblieben (auf DE wiedergegeben)\\
Fehlertyp 6: Lexik -- Konsistenzfehler\\
Fehlertyp 7: Grammatik -- Falsche Wortart / Wortklasse\\
Fehlertyp 8: Grammatik -- Falsches Verb (Zeitform, Komposition, Person)\\
Fehlertyp 9: Grammatik -- Kongruenzfehler (Agreement)\\
Fehlertyp 10: Grammatik -- Falsche Wortstellung\\
Fehlertyp 11: Semantik -- Verwechslung des Sinns\\
Fehlertyp 12: Semantik -- Falsche Wahl\\
Fehlertyp 13: Semantik -- Kollokationsfehler}
\end{figure}

Wie in der Analyse der Fehleranzahl (siehe \sectref{sec:5.4.1}) ersichtlich sank die Fehleranzahl bei dem HMÜ-System Bing und dem SMÜ-System SDL signifikant. Konkret signifikant war der Rückgang bei den folgenden Fehlertypen (\tabref{tab:05:92} und \tabref{tab:05:93}).\footnote{\textrm{Die Tabellen in diesem Abschnitt demonstrieren nur die Fehlertypen, deren Unterschied signifikant ist.}}


\begin{table}
%\small
\begin{tabularx}{\textwidth}{llrrrrr}

\lsptoprule
& \textbf{KS} & \textbf{N} & \textbf{M} & \textbf{CI 95\%} & \textbf{SD} & \textbf{p}\\
\midrule
\textbf{OR.1 „Zeichensetzung“} & \textbf{vor} & 216 & ,01 & ,00/,02 & ,096 & ,012\\
& \textbf{nach} & & ,05 & ,02/,08 & ,220 & \\
\tablevspace
\textbf{OR.2 „Großschreibung“} & \textbf{vor} & 216 & ,10 & ,06/,14 & ,297 & < ,001\\
& \textbf{nach} & & ,00 & ,00/,01 & ,068 & \\
\tablevspace
\textbf{LX.3 „Wort ausgelassen“} & \textbf{vor} & 216 & ,16 & ,11/,21 & ,369 & < ,001\\
& \textbf{nach} &  & ,04 & ,01/,07 & ,200 & \\
\tablevspace
\textbf{GR.8 „Falsches Verb“}& \textbf{vor} & 216 & ,13 & ,08/,17 & ,331 & < ,001\\
& \textbf{nach} & & ,02 & ,00/,04 & ,151 & \\
\tablevspace
\textbf{GR.10 „Wortstellungsfehler“} & \textbf{vor} & 216 & ,14 & ,09/,19 & ,364 &  ,001\\
& \textbf{nach} & & ,06 & ,02/,09 & ,230 & \\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:92}Bing -- Fehlertypen mit signifikanter Veränderung nach der KS-Anwendung   }
\end{table}

\begin{table}
%\small
\begin{tabularx}{\textwidth}{llrrrrr}

\lsptoprule
& \textbf{KS} & \textbf{N} & \textbf{M} & \textbf{CI 95\%} & \textbf{SD} & \textbf{p}\\
 \midrule
\textbf{OR.1 „Zeichensetzung“} & \textbf{vor} & 216 & ,01 & ,00/,03 & ,117 & ,021\\
& \textbf{nach} & & ,05 & ,02/,08  & ,220 & \\
\tablevspace
\textbf{OR.2 „Großschreibung“} & \textbf{vor} & 216 & ,09 & ,05/,13 & ,291 & ,001\\
& \textbf{nach} & & ,02 & ,00/,04 & ,151 & \\
\tablevspace
\textbf{LX.3 „Wort ausgelassen“}  & \textbf{vor} & 216 & ,17 & ,12/,22 & ,390 & ,011\\
& \textbf{nach} &  & ,09 & ,05/,13 & ,300 & \\
\tablevspace
\textbf{LX.4 „Zusätzliches Wort} & \textbf{vor} & 216 & ,13 & ,07/,18 & ,407 & ,036\\
\textbf{eingefügt“} & \textbf{nach} & & ,05 & ,02/,08 & ,241 &\\
\tablevspace
\textbf{GR.9 „Kongruenzfehler“} & \textbf{vor} & 216 & ,05 & ,02/,08 & ,220 & ,004\\
& \textbf{nach} & & ,02 & $-$ ,01/,04 & ,192 & \\
\tablevspace
\textbf{GR.10 „Wortstellungsfehler“} & \textbf{vor} & 216 & ,26 & ,19/,32  & ,480& ,015\\
& \textbf{nach} & & ,16 & ,11/,21 & ,365 & \\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:93}SDL -- Fehlertypen mit signifikanter Veränderung nach der KS-Anwendung  }
\end{table}

Die Analyse auf Regel- und Systemebene zeigt, dass der Fehlertyp \textit{OR.1 „Orthografie -- Zeichensetzung“} bei den beiden \textit{HMÜ}{}-Systemen und dem \textit{SMÜ} SDL nur bei der Regel „Partizipialkonstruktion vermeiden“ signifikant stieg. In der Übersetzung nach der Anwendung der KS-Regel sollte ein Nebensatz mit ‚which‘ oder ‚that‘ gebildet werden (\tabref{tabex:05:96}).


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & Das Gerät verbindet sich mit \textbf{der neu gewählten Netzwerkadresse}.\\
\tablevspace
SMÜ SDL & The device connects to \txblue{the newly selected network address}.\\
\midrule
\textbf{Nach-KS} & Das Gerät verbindet sich mit \textbf{der Netzwerkadresse, die neu gewählt wird}.\\
\tablevspace
SMÜ SDL & The device connects to \txblue{the network address}\txred{, the XXX} \txblue{newly selected}.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:96}Beispiel 96   }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens; \txred{XXX} für ein fehlendes Wort oder Komma.}
\end{table}

Hierbei stellte das Relativpronomen für diese Systeme ein Ambiguitätsproblem dar. Das Relativpronomen wurde oft als Artikel interpretiert und dadurch entstand der Kommasetzungsfehler (in \tabref{tabex:05:96} wurde ‚die‘ als ‚the‘ anstatt ‚which‘ übersetzt). Dementsprechend wurden z. B. bei dem \textit{SMÜ}{}-System SDL 29~\% der Sätze (7 von 24) in Bezug auf Fehlertyp OR.1 mit Partizipialkonstruktion (vor KS) richtig und nach KS falsch übersetzt.

Fehlertyp \textit{OR.2 „Orthografie -- Großschreibung“} sank nur in Zusammenhang mit Regel 1 „Für zitierte Oberflächentexte gerade Anführungszeichen verwenden“ signifikant um 82~\%. Dank der Verwendung von Anführungszeichen konnten das \textit{SMÜ}{}-System SDL und das \textit{HMÜ}{}-System Bing die Oberflächentexte als spezifische Begriffe bzw. Mehrwortentitäten erkennen und sie entsprechend großschreiben.

Hochsignifikant war die Veränderung im Fehlertyp \textit{LX.3 „Lexik -- Wort ausgelassen“} bei der Regel „Konditionalsätze mit ‚Wenn‘ einleiten“: Alle 15 Fehler (N = 24), die vor der Verwendung der KS-Regel (bzw. bei einer Formulierung ohne ‚Wenn‘) auftreten, wurden nach der Verwendung von ‚Wenn‘ (nach-KS) eliminiert. Die Konstruktion einer Bedingung mit einem Verb am Satzbeginn (mit Ausnahme von ‚should‘) ist im Englischen nicht möglich. So stellen Verben am Satzbeginn von Konditionalsätzen die MÜ-Systeme vor ein Ambiguitätsproblem. Ein \textit{RBMÜ}{}-System wie Lucy kann durch die Verwendung einer Systemregel diese Sprachunterschiede behandeln. In einem \textit{SMÜ}{}-System wie SDL hingegen wäre es erforderlich, dass die Trainingsdaten diese Satzkonstruktion beinhalten, damit eine korrekte Übersetzung produziert werden kann. In \tabref{tabex:05:97} konnte SDL den Konditionalsatz vor der Regalanwendung aufgrund des Fehlens der Konjunktion ‚Wenn‘ nicht als Bedingung erkennen.


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & \textbf{Schließt} der Kontaktschalter, so wird der Raumdruck-Sollwert aktiv.\\
\tablevspace
SMÜ SDL & \textcolor{lsRed}{XXX} The contact switch closes, the room pressure setpoint becomes active.\\
\midrule
\textbf{Nach-KS} & \textbf{Wenn} der Kontaktschalter \textbf{schließt}, wird der Raumdruck-Sollwert aktiv.\\
\tablevspace
SMÜ SDL & \textcolor{tmnlpthree}{If} the contact switch \txblue{closes}, the room pressure setpoint becomes active.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:97}Beispiel 97   }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens; \txred{XXX} für ein fehlendes Wort oder Komma.}
\end{table}

Zudem wurde Fehlertyp \textit{LX.3 „Lexik -- Wort ausgelassen“} nach der Anwendung der KS-Regel 4 „Konstruktionen mit ‚sein +~zu +~Infinitiv‘ vermeiden“ korrigiert. Hierbei wurde das Verb (‚prüfen‘ in \tabref{tabex:05:98}) in der Passiversatzkonstruktion gar nicht übersetzt.


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & Die Teppichböden \textbf{sind} entsprechend den Liefer- und Zahlungsbedingungen \textbf{zu prüfen}. \\
\tablevspace
SMÜ SDL & The carpets \txblue{are} \txred{XXX} in accordance with the terms and conditions of delivery and payment.\\
\midrule
\textbf{Nach-KS} & \textbf{Prüfen Sie} die Teppichböden entsprechend den Liefer- und Zahlungsbedingungen. \\
\tablevspace
SMÜ SDL & \textcolor{tmnlpthree}{Check} the \textbf{\textit{carpets}} in accordance with the terms and conditions of delivery and payment.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:98}Beispiel 98   }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens; \txred{XXX} für ein fehlendes Wort oder Komma.}
\end{table}

Die Trennung der Bestandteile der Passiversatzkonstruktion („sein“ am Anfang des Satzes und das Hauptverb des Satzes am Ende) bildete eine Parsing{}-Schwierigkeit für das \textit{SMÜ}{}-System SDL und das \textit{HMÜ}{}-System Bing, die zur Auslassung des Verbs führte (vor-KS in \tabref{tabex:05:98}). Die verwendete KS-Regel sieht vor, den Imperativ anstatt des Passiversatzes zu verwenden, wodurch das Verb geparst und übersetzt werden konnte (nach-KS in \tabref{tabex:05:98}).

Fehlertyp \textit{LX.4 „Lexik -- Wort zusätzlich falsch eingefügt“} war bei Regel 3 „Konditionalsätze mit ‚Wenn‘ einleiten“ in 5 der analysierten 24 Sätzen zu beobachten (keine signifikanten Werte, aber beachtenswert). Alle 5 Sätze begannen die Bedingungsformulierung mit dem Verb ‚Ist‘, das vom \textit{SMÜ}{}-System SDL als zusätzliches ‚is‘ übersetzt wurde (\tabref{tabex:05:99}).


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & \textbf{\textcolor{lsRed}{Ist} das Gerät oder das Netzkabel \txred{beschädigt}, sofort den Netzstecker herausziehen.}\\
\tablevspace
SMÜ SDL & \textcolor{lsRed}{XXX Is} the \textbf{\textit{appliance}} or the power cord \txblue{is damaged}, immediately \textbf{\textit{disconnect} }the mains plug.\\
\midrule
\textbf{Nach-KS} & \textbf{\textcolor{lsRed}{Prüfen Sie} die Teppichböden entsprechend den Liefer- und Zahlungsbedingungen.} \\
\tablevspace
SMÜ SDL & \textcolor{tmnlpthree}{If} the \textbf{\textit{appliance}} or the power cord \txblue{is damaged}, immediately \textbf{\textit{disconnect} }the mains plug.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:99}Beispiel 99   }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens; \txred{XXX} für ein fehlendes Wort oder Komma.}
\end{table}

Fehlertyp \textit{GR.9 „Grammatik -- Kongruenzfehler“} trat in den Regeln vereinzelt auf und seine Veränderung vor und nach KS war bei keiner bestimmten Regel signifikant. Dies ist aber bei einem solchen grammatischen Fehler plausibel, denn ein Kongruenzfehler kann aus unterschiedlichen Gründen auftreten.

Die Verschachtelung einer Partizipialkonstruktion (Regel 5) war bei dem \textit{SMÜ}{}-System SDL oft mit dem Fehlertyp\textbf{ }\textit{GR.10 „Grammatik -- Falsche Wortstellung“} verbunden. Bei der Anwendung der KS-Regel wurde aus der Partizipialkonstruktion ein Nebensatz gebildet. Durch die Übersetzung des Nebensatzes mit SDL wurde der Wortstellungsfehler signifikant um knapp 69~\% reduziert (vgl. \tabref{tabex:05:100}).


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & \textbf{Die in der Betriebsanleitung angegebenen Fristen} für wiederkehrende Prüfungen sind einzuhalten.\\
\tablevspace
SMÜ SDL & \textcolor{lsRed}{The specified in the operating instructions deadlines} for periodic \textit{tests must} be observed.\\
\midrule
\textbf{Nach-KS} & \textbf{Die Fristen} für wiederkehrende Prüfungen\textbf{, die in der Betriebsanleitung angegeben sind,} sind einzuhalten.\\
\tablevspace
SMÜ SDL & \textcolor{tmnlpthree}{The deadlines} for \textit{periodic} tests \txblue{specified in the Operator Manual} \textit{must} be observed.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:100}Beispiel 100  }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

Ebenfalls sank Fehlertyp \textit{GR.10 „Grammatik -- Falsche Wortstellung“} bei Regel 7 „Konstruktionen mit ‚sein +~zu +~Infinitiv‘ vermeiden“ signifikant um 91~\%. Durch die Verwendung des Imperativs anstatt des Passiversatzes wurde der Satzbau für das \textit{SMÜ}{}-System SDL vereinfacht. Dies verbesserte wiederum das Parsen und löst weitgehend die Wortstellungsproblematik.

Bei HMÜ-Systemen kann man keine eindeutige Aussage treffen, warum ein bestimmter Fehler auftrat oder eliminiert wurde. Das kann aufgrund der Regeln, die das System verwendet bzw. die im System fehlen oder der Trainingsdaten seiner statistischen Komponente erfolgen. In einer Black-Box-Analyse ist der Grund für das Auftreten eines Fehlers nicht ermittelbar. Bei dem \textit{HMÜ}{}-System Systran war die Veränderung in der Fehleranzahl bei den folgenden Fehlertypen signifikant (\tabref{tab:05:94}).


\begin{table}
\begin{tabularx}{\textwidth}{llrrrrr}

\lsptoprule
& \textbf{KS} & \textbf{N} & \textbf{M} & \textbf{CI 95\%} & \textbf{SD} & \textbf{p}\\
 \midrule
\textbf{OR.1 „Zeichensetzung“} & \textbf{vor} & 216 & ,03 & ,00/,06 & ,214 & < ,001\\
& \textbf{nach} & & ,14 & ,08/,20 & ,455 & \\
\tablevspace
\textbf{LX.3 „Wort ausgelassen“} & \textbf{vor} & 216 & ,04 & ,01/,07 & ,212 & ,031\\
& \textbf{nach} & & ,01 & $-$ ,01/,03 & ,136 & \\
\tablevspace
\textbf{LX.4 „Zusätzliches Wort} & \textbf{vor} & 216 & ,01 & ,00/,03 & ,117 & ,035\\
\textbf{eingefügt“} & \textbf{nach} & & ,06 & ,03/,09 & ,257 & \\
\tablevspace
\textbf{SM.13 „Kollokationsfehler“} & \textbf{vor} & 216 & ,11 & ,07/,16 & ,343 & < ,001\\
& \textbf{nach} & & ,04 & ,01/,06 & ,189 & \\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:94}Systran -- Fehlertypen mit signifikanter Veränderung nach der KS-Anwendung }
\end{table}

Bei dem \textit{RBMÜ} Lucy war die Veränderung in der Fehleranzahl nur bei den folgenden zwei Fehlertypen signifikant (\tabref{tab:05:95}).

\begin{table}
\begin{tabularx}{\textwidth}{llrrrrr}

\lsptoprule
& \textbf{KS} & \textbf{N} & \textbf{M} & \textbf{CI 95\%} & \textbf{SD} & \textbf{p}\\
 \midrule
\textbf{OR.2 „Großschreibung“} & \textbf{vor} & 216 & ,09 & ,05/,13 & ,291 & ,004\\
& \textbf{nach} & & ,05 & ,02/,08 & ,220 & \\
\tablevspace
\textbf{SM.13 „Kollokationsfehler“} & \textbf{vor} & 216 & ,06 & ,02/,09 & ,230 & ,012\\
& \textbf{nach} & & ,01 & ,00/,03 & ,117 & \\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:95}Lucy -- Fehlertypen mit signifikanter Veränderung nach der KS-Anwendung }
\end{table}


Fehlertyp \textit{OR.2 „Orthografie -- Großschreibung“} sank nur in Zusammenhang mit Regel 1 „Für zitierte Oberflächentexte gerade Anführungszeichen verwenden“ signifikant um 39~\%. Dank der Verwendung von Anführungszeichen konnte das \textit{RBMÜ}{}-System Lucy die Oberflächentexte als spezifische Begriffe bzw. Mehrwortentitäten erkennen und sie entsprechend großschreiben.

Fehlertyp \textit{SM.13 „Semantik -- Kollokationsfehler“} sank in Verbindung mit Regel 2 „Funktionsverbgefüge vermeiden“ signifikant um 90~\%. Das \textit{RBMÜ}{}-System Lucy hatte Schwierigkeiten Kollokationen (‚Schaden nehmen‘ vor-KS in \tabref{tabex:05:101}) korrekt zu übersetzen. Die Verwendung des bedeutungstragenden Verbs (‚beschädigt werden‘ nach-KS in \tabref{tabex:05:101}) vereinfacht die Satzsemantik und ermöglicht Lucy eine korrekte Übersetzung.


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & Wird diese Regel nicht beachtet, kann der Motor \textbf{Schaden nehmen}. \\
\tablevspace
RBMÜ Lucy & If this rule is not observed, the motor can \txred{take damage}.\\
\midrule
\textbf{Nach-KS} & Wird diese Regel nicht beachtet, kann der Motor \textbf{beschädigt werden}.\\
\tablevspace
RBMÜ Lucy & If this rule is not observed, the motor can \txblue{be damaged}.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:101} Beispiel 101 }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

Bei dem \textit{NMÜ}{}-System Google Translate gab es \textit{keine} signifikanten Veränderungen in den Fehlertypen. Wie die Analyse der Fehleranzahl (unter \sectref{sec:5.4.1}) erwies, stieg die Fehleranzahl bei dem NMÜ-System Google Translate. Eine genaue Untersuchung der Regeln und der gestiegenen Fehlertypen bei diesem System zeigt, dass der Anstieg hauptsächlich bei Regel 5 „Partizipialkonstruktion vermeiden“ (+~6 Fehler, wobei 4 davon je 2 Kommas in 2 Sätzen waren) und der Regel 4 „Eindeutige pronominale Bezüge verwenden“ (+~4 Fehler) stattfand:

Das \textit{NMÜ}{}-System Google Translate hat keine Schwierigkeiten, Partizipialkonstruktionen (Regel 5) zu übersetzen. Bei der Übersetzung des Nebensatzes (nach-KS in \tabref{tabex:05:102}) trat Fehlertyp \textit{OR.1 „Orthografie -- Zeichensetzung“} auf, konkret bei der Kommasetzung und der Auswahl des Relativpronomens ‚which‘ vs. ‚that‘. Für Letzteres zeigt die Humanevaluation, dass es sich um umstrittene Fälle handelte, in denen die Humanübersetzer Kontextinformationen benötigten.


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & \textbf{Speziell auf diese Lautsprecher abgestimmtes Zubehör} erhalten Sie in unserem Webshop.\\
\tablevspace
GNMÜ & \textcolor{tmnlpthree}{Special accessories for these speakers} are available in our webshop.\\
\midrule
\textbf{Nach-KS} & \textbf{Zubehör, das speziell auf diese Lautsprecher abgestimmt ist,} erhalten Sie in unserem Webshop.\\
\tablevspace
GNMÜ & \textcolor{tmnlpthree}{Accessories}\txred{,} \txblue{specially designed for these loudspeakers}\txred{,} are available in our webshop.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:102}Beispiel 102   }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

Der Anstieg der Fehleranzahl in Regel 4 „Eindeutige pronominale Bezüge verwenden“ (+~4 Fehler) besteht aus 3 verschiedenen Fehlertypen: Fehlertyp LX.6  „Konsistenzfehler“ (+~1), Fehlertyp GR.9 „Kongruenzfehler“ (+~2) und Fehlertyp GR.10 „Wortstellungsfehler“ (+~1) und hat somit keinen erkennbaren Grund bzw. kein rückführbares Muster.

Zudem stieg Fehlertyp \textit{SM.11 „Semantik -- Verwechslung des Sinns“} in Regel 3 „Konditionalsätze mit ‚Wenn‘ einleiten“ nach der Regelanwendung in \textit{einem} Satz aufgrund von Ambiguität (‚wenn‘ wurde in \tabref{tabex:05:103} als ‚when‘ anstatt ‚if‘ übersetzt). Auch hierfür würde -- laut der Kommentare einiger Bewerter in der Humanevaluation -- ein Humanübersetzer Kontextinformationen benötigen, um die Ambiguität klären zu können.


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & \textbf{Schließt} der Kontaktschalter, so wird der Raumdruck-Sollwert aktiv.\\
\tablevspace
GNMÜ & \textcolor{tmnlpthree}{If} the contact switch \txblue{closes}, the room pressure setpoint becomes active.\\
\midrule
\textbf{Nach-KS} & \textbf{Wenn} der Kontaktschalter \textbf{schließt}, wird der Raumdruck-Sollwert aktiv.\\
\tablevspace
GNMÜ & \textcolor{lsRed}{When} the contact switch \txblue{closes}, the room pressure setpoint becomes active.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:103}Beispiel 103   }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

Ebenfalls trat Fehlertyp \textit{SM.11 „Semantik -- Verwechslung des Sinns“} in Regel 5 „Partizipialkonstruktion vermeiden“ nach der Anwendung der KS in \textit{einem} Satz auf, in dem ‚which‘ anstatt ‚that‘ als Relativpronomen verwendet wurde (\tabref{tabex:05:104}).


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & Das Gerät verbindet sich mit \textbf{der neu gewählten Netzwerkadresse}.\\
\tablevspace
GNMÜ & The device connects to \txblue{the newly selected network address}.\\
\midrule
\textbf{Nach-KS} & Das Gerät verbindet sich mit \textbf{der Netzwerkadresse, die neu gewählt wird}.\\
\tablevspace
GNMÜ & The device connects to \txblue{the network address}\txred{,} \txblue{which is selected} \txred{again}.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:104}Beispiel 104  }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

Nun kann die alleinige Untersuchung der Fehleranzahl und ihrer Differenz keineswegs einen hinreichenden Hinweis auf die Qualität der Übersetzung geben und aufgrund der unterschiedlichen Gewichtung der verschiedenen Fehlertypen keine aussagekräftigen Ergebnisse liefern. Daher war es erforderlich, die Qualität auf einem anderen Weg zu beurteilen. In den folgenden Abschnitten werden die Ergebnisse der Qualitätsbewertung aus Sicht der Bewerter im Rahmen der Humanevaluation präsentiert und erläutert.

\subsection{Vergleich der MÜ-Qualität vor vs. nach der Anwendung aller analysierten KS-Regeln}
\label{sec:5.4.5}

Ein Vergleich der Qualität vor vs. nach der Anwendung der KS-Regeln deckte Folgendes auf (\figref{fig:05:141} und \figref{fig:05:142}): Während die Stil- und Inhaltsqualität bei allen älteren MÜ-Ansätzen nach der Anwendung der KS-Regeln stiegen, sanken beide bei dem NMÜ-System. Im Folgenden wird auf die Ergebnisse jedes Systems näher eingegangen.


\begin{figure}

\includegraphics[width=\textwidth]{figures/d3-img113.png}

%\includegraphics[height=.3\textheight]{figures/d3-img015.png}\\
\caption{\label{fig:05:141}Mittelwerte der Qualität vor vs. nach KS auf MÜ-Systemebene   }
\end{figure}

Beide \textit{HMÜ}{}-Systeme Bing und Systran weisen einen Anstieg der Stil- und Inhaltsqualität auf, der Grad des Anstiegs war allerdings unterschiedlich (
\figref{fig:05:141} und \figref{fig:05:142}): Bei Bing war der Anstieg hochsignifikant und betrug für die Stilqualität +~5,23~\% und für die Inhaltsqualität +~10,25~\%. Die Differenzen (nach KS \textit{minus} vor KS) in der Stil- und Inhaltsqualität erwiesen sich als signifikant (z (N = 139) = $-$ 2,857 / p = ,004) bzw. (z (N = 139) = $-$ 4,746 / p < ,001). Bei Systran zeigen die Ergebnisse einen kleinen Anstieg, der insignifikant war: für die Stilqualität +~0,72~\% und für die Inhaltsqualität +~1,06~\%.

Bei dem \textit{SMÜ}{}-System SDL war der Anstieg der Stil- und Inhaltsqualität deutlich signifikant und betrug für die Stilqualität +~4,98~\% mit einem Signifikanzniveau von (z (N = 153) = $-$ 2,847 / p = ,004) und für die Inhaltsqualität +~6,31~\% mit einem höheren Signifikanzniveau von (z (N = 153) = $-$~3,005 / p~=~,003).


\begin{figure}


%,338,081

%,127$-$~,052

%,128$-$~,083

%,316,069

%,185$-$~,098

%,113$-$~,053

%,367,083

%,132$-$~,078

%,436,079

%$-$~,014$-$~,111

%,005$-$~,104

%$-$~,135$-$~,016

%,454,180

%,589,260

%,146$-$~,076



\includegraphics[width=\textwidth]{figures/Abb142.png}



%\includegraphics[height=.3\textheight]{figures/d3-img114.png}



%\includegraphics[height=.3\textheight]{figures/d3-img114.png}
\caption{\label{fig:05:142}Mittelwert der Qualitätsdifferenzen auf MÜ-Systemebene   }
\bspnote{Qualitätsdifferenz = Qualitätswert nach KS $-$ Qualitätswert vor KS}
\end{figure}

Im Falle des \textit{RBMÜ}-Systems Lucy war der Anstieg sehr niedrig +~0,95~\% für die Stilqualität bzw. +~0,53~\% für die Inhaltsqualität und konnte somit keine signifikante Veränderung erweisen.

Das \textit{NMÜ}{}-System Google Translate ist das einzige System, das einen Rückgang der Qualität verzeichnete: Die Stilqualität sank signifikant ($-$ 1,71~\% (z (N = 194) = $-$ 2,338 / p = ,019). Hingegen sank die Inhaltsqualität um $-$ 1,06~\% und konnte keine signifikante Veränderung (z (N = 194) = $-$ 1,481 / p = ,139) aufweisen.

Die Ergebnisse zeigen, dass die Anwendung der untersuchten Regeln für die vorherigen MÜ-Ansätze im Gegensatz zum NMÜ-Ansatz nützlich war. Wie die Analyse der Fehler zeigte, unterstützten die Regeln die RBMÜ-, SMÜ- und HMÜ-Systeme dabei, mehrere Fehlertypen zu reduzieren bzw. zu eliminieren. Die NMÜ-Architektur von Google Translate hingegen ermöglichte es, die Sätze vor und nach der Regelanwendung korrekt zu übersetzen. Ein genauer Einblick in die Bewertung der Teilnehmer zeigt, dass die Inhaltsqualität zweier korrekter MÜ vor und nach KS vergleichbar war. Gleichzeitig fanden die Teilnehmer die MÜ idiomatischer vor KS, was zum Rückgang der Stilqualität nach KS führte.

\subsection{Vergleich der MÜ-Qualität vor vs. nach der Anwendung aller analysierten KS-Regeln auf Annotationsgruppenebene}
\label{sec:5.4.6}

Die Analyse der Qualitätsattribute auf Annotationsgruppenebene ist von Bedeutung, da sie die Qualitätsveränderung bei den einzelnen Annotationsgruppen klar darlegt. Während die Qualitätsveränderung bei den Gruppen FR und RF vorhersehbar sein sollte, nämlich ein Qualitätsanstieg bei der Gruppe FR bzw. ein Qualitätsrückgang bei der Gruppe RF, ist die Ermittlung der Qualitätsveränderung bei den Gruppen RR und FF von besonderem Interesse. Wie \figref{fig:05:13} zeigt, waren die Gruppen RR und FF die größten Annotationsgruppen. Ein Vergleich des Qualitätsniveaus bei diesen dominanten Gruppen verrät, wie genau sich zwei vor- und nach-KS fehlerfreie Übersetzungen (Gruppe RR) bzw. zwei vor- und nach-KS fehlerhafte Übersetzungen (Gruppe FF) im Hinblick auf die Stil- und Inhaltsqualität unterscheiden. Das wiederum ermöglicht es, einen tieferen Einblick in den Einfluss der KS-Regeln zu gewinnen. Im Folgenden wird die Gegenüberstellung für jede Annotationsgruppe demonstriert:

Die \textit{Gruppe FF} zeigt einen kleinen nicht signifikanten Anstieg der Qualität bei dem \textit{HMÜ}{}-System Bing und dem \textit{SMÜ}{}-System SDL. Bei dem \textit{RBMÜ}{}-System Lucy und dem \textit{HMÜ}{}-System Systran blieben die Qualitätswerte fast unverändert (\figref{fig:05:143}).


\begin{figure}

\includegraphics[width=\textwidth]{figures/d3-img115.png}



%\includegraphics[height=.3\textheight]{figures/d3-img115.png}

\caption{\label{fig:05:143}Gruppe FF -- Qualitätsdifferenzen auf MÜ-Systemebene   }
\bspnote{Qualitätsdifferenz = Qualitätswert nach KS $-$ Qualitätswert vor KS}
\end{figure}

Nur bei dem \textit{NMÜ}{}-System Google Translate sanken beide Qualitätswerte bei der \textit{Gruppe FF} signifikant (\figref{fig:05:143}): die Stilqualität um $-$~4,95~\%, Mv = 4,340, Mn = 4,125, Mdiff = $-$~,215 (z (N = 18) = $-$~2,075 / \textit{p = ,038}) und die Inhaltsqualität um $-$ 2,72~\%, Mv = 4,590, Mn = 4,465, Mdiff = $-$~,125 (z (N = 18) = $-$~1,998 / p = ,046). Die großen Abnahmen in der allgemeinen Qualität waren bei Regel 4 „Eindeutige pronominale Bezüge verwenden“ und Regel 5 „Partizipialkonstruktion vermeiden“ infolge des Rückgangs der Stilqualität. Die Wiederholung des Nomens bei Regel 4 (nach KS) wurde von den Teilnehmern als redundant betrachtet bzw. als unidiomatisch empfunden, was zu einem niedrigeren Score der Stilqualität führte (Genaueres dazu unter \sectref{sec:5.3.4}). Zudem hat Google Translate keine Schwierigkeit bei der Übersetzung von Partizipialkonstruktionen, siehe \tabref{tabex:05:105}. Obwohl der semantische Fehler in ‚time limits‘ in \tabref{tabex:05:105} in beiden Szenarien unverändert blieb, wurde die Übersetzung der Partizipialkonstruktion (vor-KS) stilistisch höher bewertet.


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & \textbf{Die in der Betriebsanleitung angegebenen Fristen} für wiederkehrende Prüfungen sind einzuhalten.\\
\tablevspace
GNMÜ & \textcolor{tmnlpthree}{The} \txred{time limits} for \textbf{\textit{periodic}} tests \txblue{specified in the operating instructions} must be observed.\\
\midrule
\textbf{Nach-KS} & \textbf{Die Fristen} für wiederkehrende Prüfungen\textbf{, die in der Betriebsanleitung angegeben sind,} sind einzuhalten.\\
\tablevspace
GNMÜ & \textcolor{tmnlpthree}{The} \txred{time limits} for \textbf{\textit{periodic}} tests\txblue{, which are stated in the operating instructions,} must be observed.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:105}Beispiel 105  }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

Erwartungsgemäß sank die Qualität in der \textit{Gruppe RF} (Übersetzung vor KS richtig und nachher falsch) bei allen MÜ-Systemen.


\begin{figure}
\includegraphics[width=\textwidth]{figures/d3-img116.png}

%\includegraphics[height=.3\textheight]{figures/d3-img115.png}
\caption{\label{fig:05:144}Gruppe RF -- Qualitätsdifferenzen auf MÜ-Systemebene   }
\bspnote{Qualitätsdifferenz = Qualitätswert nach KS $-$ Qualitätswert vor KS}
\end{figure}

Der Rückgang in der Qualität erwies sich bei allen Systemen mit Ausnahme der Inhaltsqualität bei Google Translate als signifikant (\tabref{tab:05:96}). Insgesamt gab es 8 Übersetzungen (4~\% der annotierten Übersetzungen) bei Google Translate, die in die Gruppe RF fielen (\figref{fig:05:139}); eine geringe Prozentzahl. Die 8 Übersetzungen wurden in der Humanevaluation bewertet. Das Ergebnis ist insbesondere bei orthografischen Fehlern gut vorstellbar. Wenn eine Übersetzung nach KS einen orthografischen Fehler enthält, bleibt sie -- in vielen Fällen -- inhaltlich qualitativ vergleichbar mit einer fehlerfreien Übersetzung vor der Anwendung der KS-Regeln. Diesen Fall demonstriert \tabref{tabex:05:106}, in dem die CQdiff 0 und die SQdiff $-$~0,25 betrugen.


\begin{table}
\begin{tabularx}{\textwidth}{lX}

\lsptoprule

\textbf{Vor-KS} & \textbf{Die in den Bedienungsanweisungen der eingebauten Geräte vorgeschriebenen Gebrauchsbedingungen} müssen strikt eingehalten werden.\\
\tablevspace
GNMÜ & \textcolor{tmnlpthree}{The operating conditions specified in the operating instructions of the installed devices} must be strictly adhered to.\\
\midrule
\textbf{Nach-KS} & \textbf{Die Gebrauchsbedingungen, die in den Bedienungsanweisungen der eingebauten Geräte vorgeschrieben sind,} müssen strikt eingehalten werden.\\
\tablevspace
GNMÜ & \textcolor{tmnlpthree}{The operating conditions}\txred{,} \txblue{which are prescribed in the operating instructions of the installed devices}\txred{,} must be strictly adhered to.\\
\lspbottomrule
\end{tabularx}
\caption{\label{tabex:05:106}Beispiel 106   }
\bspnote{Die KS-Stelle ist \textbf{fett} dargestellt. \txblue{Blau} wird für die korrekten Tokens verwendet; \txred{Rot} für die falschen Tokens.}
\end{table}

\begin{table}
\begin{tabularx}{.7\textwidth}{lrrr}

\lsptoprule
& \textbf{N} & {\textbf{p}} & {\textbf{Z}}\\
& & \textbf{(Signifikanz)} & \textbf{(Teststatistik)}\\
\midrule
\multicolumn{4}{l}{\textbf{Differenz SQ (nach KS \textit{minus}} \textbf{vor KS)}}\\
 \textbf{HMÜ Bing} & 16 & ,001 & $-$ 3,184\\
 \textbf{GNMÜ} & 8 & ,028 & $-$ 2,201\\
 \textbf{RBMÜ Lucy} & 21 & ,009 & $-$ 2,625\\
 \textbf{SMÜ SDL} & 20 & < ,001 & $-$ 3,707\\
 \textbf{HMÜ Systran} & 18 & ,002 & $-$ 3,131\\
 \midrule
\multicolumn{4}{l}{\textbf{Differenz CQ (nach KS \textit{minus}} \textbf{vor KS)}}\\
 \textbf{HMÜ Bing} & 16 & ,001 & $-$ 3,176\\
 \textbf{GNMÜ} & 8 & \txgray{,063} & $-$ 1,859\\
 \textbf{RBMÜ Lucy} & 21 & ,001 & $-$ 3,387\\
 \textbf{SMÜ SDL} & 20 & < ,001 & $-$ 3,706\\
 \textbf{HMÜ Systran} & 18 & ,035 & $-$ 2,106\\
\midrule
\multicolumn{4}{l}{\textbf{Differenz allg. Q (nach KS \textit{minus}} \textbf{vor KS)}}\\
 \textbf{HMÜ Bing} & 16 & ,001 & $-$ 3,411\\
 \textbf{GNMÜ} & 8 & ,020 & $-$ 2,325\\
 \textbf{RBMÜ Lucy} & 21 & < ,001 & $-$ 3,927\\
 \textbf{SMÜ SDL} & 20 & < ,001 & $-$ 3,826\\
 \textbf{HMÜ Systran} & 18 & ,003 & $-$ 2,969\\
\lspbottomrule
\end{tabularx}\caption{\label{tab:05:96}Gruppe RF -- Signifikanz der Qualitätsdifferenzen auf MÜ-Systemebene   }
\end{table}

Ebenfalls stieg die Qualität in der \textit{Gruppe FR} (Übersetzung vor KS falsch und nachher richtig) erwartungsgemäß.


\begin{figure}
\includegraphics[width=\textwidth]{figures/d3-img117.png}




%\includegraphics[height=.3\textheight]{figures/d3-img115.png}
Qualitätsdifferenz = Qualitätswert nach KS $-$ Qualitätswert vor KS\\
\caption{\label{fig:05:145}Gruppe FR -- Qualitätsdifferenzen auf MÜ-Systemebene   }
\end{figure}

Der Rückgang in der Qualität erwies sich bei allen Systemen mit Ausnahme der Stilqualität bei Google Translate als signifikant (\tabref{tab:05:97}). Es gab bei Google Translate nur 9 Übersetzungen (4~\% der annotierten Übersetzungen), die in die Gruppe FR fielen (\figref{fig:05:139}). Ein sehr niedriger Prozentsatz, der darauf hinweist, dass das System selten falsch vor KS übersetzte und erst nach KS richtige Übersetzungen produzierte. Von den 9 Sätzen wurden nur 7 Sätze in der Humanevaluation bewertet.


\begin{table}
\begin{tabularx}{.7\textwidth}{lrrr}

\lsptoprule
& \textbf{N} & {\textbf{p}} & {\textbf{Z}}\\
& & \textbf{(Signifikanz)} & \textbf{(Teststatistik)}\\
\midrule
\multicolumn{4}{l}{\textbf{Differenz SQ (nach KS \textit{minus}} \textbf{vor KS)}}\\
 \textbf{HMÜ Bing} & 56 & < ,001 & $-$ 5,842\\
 \textbf{GNMÜ} & 7 & \txgray{,442} & $-$ ,769\\
 \textbf{RBMÜ Lucy} & 26 & < ,001 & $-$ 4,217\\
 \textbf{SMÜ SDL} & 50 & < ,001 & $-$ 5,794\\
 \textbf{HMÜ Systran} & 20 & ,001 & $-$ 3,344\\
 \midrule
\multicolumn{4}{l}{\textbf{Differenz CQ (nach KS \textit{minus}} \textbf{vor KS)}}\\
 \textbf{HMÜ Bing} & 56 & <   ,001 & $-$ 6,053\\
 \textbf{GNMÜ} & 7 & ,034 & $-$ 2,120\\
 \textbf{RBMÜ Lucy} & 26 & < ,001 & $-$ 3,965\\
 \textbf{SMÜ SDL} & 50 & < ,001 & $-$ 5,844\\
 \textbf{HMÜ Systran} & 20 & < ,001 & $-$ 3,851\\
 \midrule
\multicolumn{4}{l}{\textbf{Differenz allg. Q (nach KS \textit{minus}} \textbf{vor KS)}}\\
 \textbf{HMÜ Bing} & 56 & < ,001 & $-$ 6,102\\
 \textbf{GNMÜ} & 7 & \txgray{,115} & $-$ 1,577\\
 \textbf{RBMÜ Lucy} & 26 & < ,001 & $-$ 4,321\\
 \textbf{SMÜ SDL} & 50 & < ,001 & $-$ 5,924\\
 \textbf{HMÜ Systran} & 20 & < ,001 & $-$ 3,753\\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:97}Gruppe FR -- Signifikanz der Qualitätsdifferenzen auf MÜ-Systemebene   }
\end{table}

In der \textit{Gruppe RR} (Übersetzung vor und nach KS richtig) waren die Qualitätsveränderungen gering und somit bei allen Systemen nicht signifikant. Obwohl die Ergebnisse statistisch nicht signifikant sind, geben uns die Qualitätsveränderungen bei der Gruppe RR einen Hinweis, wie die Anwendung der KS-Regeln die Qualitätsattribute beeinflusst hat. \figref{fig:05:146} zeigt, dass bei dem Vergleich von zwei richtigen Übersetzungen vor und nach KS die Stilqualität nach KS bei fast allen Systemen sank. Nur bei dem HMÜ-System Systran stieg sie minimal (Mdiff = 0,006). Bei der Inhaltsqualität war das Ergebnis anders: Sie stieg bei dem HMÜ-System Bing, dem RBMÜ-System Lucy sowie dem HMÜ-System Systran und sank bei dem NMÜ-System Google Translate und dem SMÜ-System SDL.


\begin{figure}
\includegraphics[width=\textwidth]{figures/d3-img118.png}

%\includegraphics[height=.3\textheight]{figures/d3-img115.png}
\caption{\label{fig:05:146}Gruppe RR -- Qualitätsdifferenzen auf MÜ-Systemebene   }
\bspnote{Qualitätsdifferenz = Qualitätswert nach KS $-$ Qualitätswert vor KS}
\end{figure}

Im folgenden Abschnitt wird anhand der Berechnung der Korrelation zwischen der Differenz der Fehlertypen und den Qualitätsdifferenzen versucht, die hier ermittelten Qualitätsveränderungen näher zu beleuchten.

\subsection{Korrelation zwischen der Differenz der Fehlertypen und den Qualitätsdifferenzen}
\label{sec:5.4.7}

\tabref{tab:05:98} -- \ref{tab:05:98c} zeigen die verschiedenen Korrelationen zwischen der Differenz der Fehlertypen und den Qualitätsdifferenzen bei den fünf MÜ-Systemen. In der linken Spalte sind die Korrelationen zwischen den Fehlertypen und SQ [1], CQ [2] und der allgemeinen Qualität\footnote{\textrm{Die allgemeine Qualität ist der Mittelwert der Stilqualität und der Inhaltsqualität, da bei der Untersuchung dieser Korrelation keine Unterscheidung zwischen der Stil- und Inhaltsqualität notwendig ist.}} [3] aufgeführt. Der Korrelationskoeffizient einer signifikanten starken Korrelation (ρ >= 0,5) ist blau markiert. Mittlere Korrelationen (ρ >= 0,3) sind grün markiert. Schwache Korrelationen (ρ >=0,1) sind unmarkiert.


\begin{sidewaystable}
\captionsetup{width=.9\textwidth}
\small
\begin{tabularx}{\textwidth}{Qrrrrrrrrrrrrrrr}

\lsptoprule
& \multicolumn{3}{c}{\textbf{HMÜ Bing}} & \multicolumn{3}{c}{\textbf{GNMÜ}} & \multicolumn{3}{c}{\textbf{RBMÜ Lucy}} & \multicolumn{3}{c}{\textbf{SMÜ SDL}} & \multicolumn{3}{c}{ \textbf{HMÜ Systran}}\\
\cmidrule(lr){2-4}\cmidrule(lr){5-7}\cmidrule(lr){8-10}\cmidrule(lr){11-13}\cmidrule(lr){14-16}
& \textbf{N} & \textbf{p} & \textbf{ρ} & \textbf{N} & \textbf{p} & \textbf{ρ} & \textbf{N} & \textbf{p} & \textbf{ρ} & \textbf{N} & \textbf{p} & \textbf{ρ} & \textbf{N} & \textbf{p} & \textbf{ρ}\\
\midrule
\multicolumn{16}{l}{\textbf{[1] Differenz der Anzahl SQ} \textbf{(nach KS \textit{minus}} \textbf{vor KS)}} \\
\textbf{OR.1} & 139 & < ,001 & \cellcolor{smGreen}{$-$~,376} &  &  &  &  &  &  & 153 & ,001 & $-$~,277 &  &  & \\
\textbf{OR.2} & 139 & ,010 & $-$~,210 &  &  &  & 156 & < ,001 & \cellcolor{smGreen}{$-$~,367} &  &  &  &  &  & \\
\textbf{LX.3} & 139 & ,016 & $-$~,203 &  &  &  & 156 & \cellcolor{lsLightGray}{,628} & ,039 & 153 & < ,001 & \cellcolor{smGreen}{$-$~,401} &  &  & \\
\textbf{LX.4} &  &  &  &  &  &  & 156 & ,001 & $-$~,252 & 153 & < ,001 & \cellcolor{smGreen}{$-$~,323} & 133 & ,009 & $-$~,226\\
\textbf{LX.5} & 139 & \cellcolor{lsLightGray}{,166} & $-$~,118 &  &  &  & 156 & \cellcolor{lsLightGray}{,343} & $-$~,076 & 153 & \cellcolor{lsLightGray}{,289} & $-$~,086 &  &  & \\
\textbf{LX.6} &  &  &  & 194 & \cellcolor{lsLightGray}{,189} & $-$~,095 &  &  &  &  &  &  &  &  & \\
\textbf{GR.7} & 139 & ,024 & $-$~,192 &  &  &  & 156 & \cellcolor{lsLightGray}{,318} & $-$~,080 & 153 & \cellcolor{lsLightGray}{,123} & $-$~,125 &  &  & \\
\textbf{GR.8} & 139 & < ,001 & \cellcolor{smGreen}{$-$~,419} &  &  &  &  &  &  & 153 & < ,001 & \cellcolor{smGreen}{$-$~,395} &  &  & \\
\textbf{GR.10} & 139 & < ,001 & \cellcolor{smGreen}{$-$~,408} & 194 & < ,001 & \cellcolor{smGreen}{$-$~,325} & 156 & ,002 & $-$~,241 & 153 & < ,001 & \cellcolor{smBlue}{$-$~,528} & 133 & ,001 & $-$~,291\\
\textbf{SM.11} & 139 & \cellcolor{lsLightGray}{,291} & $-$~,090 & 194 & \cellcolor{lsLightGray}{,291} & $-$~,090 & 156 & ,012 & $-$~,200 & 153 & \cellcolor{lsLightGray}{,048} & $-$~,160 & 133 & ,001 & $-$~,285\\
\textbf{SM.12} &  &  &  & 194 & \cellcolor{lsLightGray}{,833} & ,015 & 156 & \cellcolor{lsLightGray}{,065} & $-$~,148 & 153 & ,012 & $-$~,203 & 133 & ,015 & $-$~,211\\
\textbf{SM.13} &  &  &  &  &  &  & 156 & ,049 & $-$~,158 &  &  &  & 133 & < ,001 & \cellcolor{smGreen}{$-$~,304}\\
\lspbottomrule
\end{tabularx}\caption{\label{tab:05:98}Korrelationen zwischen den Fehlertypen und der Qualität auf MÜ-Systemebene   }
\bspnote{*In der Tabelle werden nur die Fehlertypen dargestellt, die bei mindestens einer Qualitätsvariable signifikante Korrelationen aufweisen.\\
p: Signifikanz; \txgray{nicht signifikant (p > 0,05)}; ρ: Korrelationskoeffizient; schwache Korrelation (ρ >=0,1); \txgreen{mittlere Korrelation (ρ >= 0,3)}; \boxblue{starke Korrelation (ρ >= 0,5)}}
\end{sidewaystable}

\begin{sidewaystable}
\captionsetup{width=.9\textwidth}
\small
\begin{tabularx}{\textwidth}{Qrrrrrrrrrrrrrrr}

\lsptoprule
& \multicolumn{3}{c}{\textbf{HMÜ Bing}} & \multicolumn{3}{c}{\textbf{GNMÜ}} & \multicolumn{3}{c}{\textbf{RBMÜ Lucy}} & \multicolumn{3}{c}{\textbf{SMÜ SDL}} & \multicolumn{3}{c}{ \textbf{HMÜ Systran}}\\
\cmidrule(lr){2-4}\cmidrule(lr){5-7}\cmidrule(lr){8-10}\cmidrule(lr){11-13}\cmidrule(lr){14-16}
& \textbf{N} & \textbf{p} & \textbf{ρ} & \textbf{N} & \textbf{p} & \textbf{ρ} & \textbf{N} & \textbf{p} & \textbf{ρ} & \textbf{N} & \textbf{p} & \textbf{ρ} & \textbf{N} & \textbf{p} & \textbf{ρ}\\
\midrule
\multicolumn{16}{l}{\textbf{[2] Differenz der Anzahl CQ} \textbf{(nach KS \textit{minus}} \textbf{vor KS)}}\\
\textbf{OR.1} & 139 & ,015 & $-$~,207 &  &  &  &  &  &  & 153 & ,012 & $-$~,204 &  &  & \\
\textbf{OR.2} & 139 & \cellcolor{lsLightGray}{,487} & $-$~,059 &  &  &  & 156 & ,016 & $-$~,192 &  &  &  &  &  & \\
\textbf{LX.3} & 139 & < ,001 & \cellcolor{smGreen}{$-$~,397} &  &  &  & 156 & ,017 & $-$~,192 & 153 & < ,001 & \cellcolor{smBlue}{$-$~,534} &  &  & \\
\textbf{LX.4} &  &  &  &  &  &  & 156 & \cellcolor{lsLightGray}{,052} & $-$~,156 & 153 & ,001 & $-$~,261 & 133 & ,013 & $-$~,215\\
\textbf{LX.5} & 139 & ,047 & $-$~,169 &  &  &  & 156 & ,001 & $-$~,260 & 153 & ,018 & $-$~,192 &  &  & \\
\textbf{LX.6} &  &  &  & 194 & ,030 & $-$~,156 &  &  &  &  &  &  &  &  & \\
\textbf{GR.7} & 139 & ,006 & $-$~,230 &  &  &  & 156 & ,016 & $-$~,193 & 153 & ,001 & $-$ ,257 &  &  & \\
\textbf{GR.8} & 139 & < ,001 & \cellcolor{smGreen}{$-$~,312} &  &  &  &  &  &  & 153 & < ,001 & \cellcolor{smGreen}{$-$~,343} &  &  & \\
\textbf{GR.10} & 139 & < ,001 & \cellcolor{smGreen}{$-$~,368} & 194 & < ,001 & \cellcolor{smBlue}{$-$~,577} & 156 & ,001 & $-$~,266 & 153 & < ,001 & \cellcolor{smGreen}{$-$~,420} & 133 & < ,001 & \cellcolor{smGreen}{$-$~,398}\\
\textbf{SM.11} & 139 & ,018 & $-$~,200 & 194 & ,018 & $-$~,200 & 156 & ,021 & $-$~,184 & 153 & \cellcolor{lsLightGray}{,069} & $-$~,148 & 133 & < ,001 & \cellcolor{smGreen}{$-$~,399}\\
\textbf{SM.12} &  &  &  & 194 & ,002 & $-$ ,216 & 156 & < ,001 & \cellcolor{smBlue}{$-$~,556} & 153 & < ,001 & \cellcolor{smGreen}{$-$~,322} & 133 & < ,001 & \cellcolor{smGreen}{$-$~,391}\\
\textbf{SM.13} &  &  &  &  &  &  & 156 & \cellcolor{lsLightGray}{,352} & ,075 &  &  &  & 133 & ,002 & $-$~,260\\
\lspbottomrule
\end{tabularx}\caption{\label{tab:05:98b}Korrelationen zwischen den Fehlertypen und der Qualität auf MÜ-Systemebene (Fortsetzung)   }
\bspnote{*In der Tabelle werden nur die Fehlertypen dargestellt, die bei mindestens einer Qualitätsvariable signifikante Korrelationen aufweisen.\\
p: Signifikanz; \txgray{nicht signifikant (p > 0,05)}; ρ: Korrelationskoeffizient; schwache Korrelation (ρ >=0,1); \txgreen{mittlere Korrelation (ρ >= 0,3)}; \boxblue{starke Korrelation (ρ >= 0,5)}}
\end{sidewaystable}

\begin{sidewaystable}
\captionsetup{width=.9\textwidth}
\small
\begin{tabularx}{\textwidth}{Qrrrrrrrrrrrrrrr}

\lsptoprule
& \multicolumn{3}{c}{\textbf{HMÜ Bing}} & \multicolumn{3}{c}{\textbf{GNMÜ}} & \multicolumn{3}{c}{\textbf{RBMÜ Lucy}} & \multicolumn{3}{c}{\textbf{SMÜ SDL}} & \multicolumn{3}{c}{ \textbf{HMÜ Systran}}\\
\cmidrule(lr){2-4}\cmidrule(lr){5-7}\cmidrule(lr){8-10}\cmidrule(lr){11-13}\cmidrule(lr){14-16}
& \textbf{N} & \textbf{p} & \textbf{ρ} & \textbf{N} & \textbf{p} & \textbf{ρ} & \textbf{N} & \textbf{p} & \textbf{ρ} & \textbf{N} & \textbf{p} & \textbf{ρ} & \textbf{N} & \textbf{p} & \textbf{ρ}\\
\midrule
\multicolumn{16}{l}{\textbf{[3] Differenz der Anzahl Q} \textbf{(nach KS \textit{minus}} \textbf{vor KS)}} \\
\textbf{OR.1} & 139 & < ,001 & \cellcolor{smGreen}{$-$~,301} &  &  &  &  &  &  & 153 & ,002 & $-$~,248 &  &  & \\
\textbf{OR.2} & 139 & \cellcolor{lsLightGray}{,105} & $-$~,138 &  &  &  & 156 & < ,001 & \cellcolor{smGreen}{$-$~,320} &  &  &  &  &  & \\
\textbf{LX.3} & 139 & < ,001 & \cellcolor{smGreen}{$-$ ,335} &  &  &  & 156 & \cellcolor{lsLightGray}{,212} & $-$ ,101 & 153 & < ,001 & \cellcolor{smBlue}{$-$ ,510} &  &  & \\
\textbf{LX.4} &  &  &  &  &  &  & 156 & ,003 & $-$~,235 & 153 & < ,001 & \cellcolor{smGreen}{$-$~,304} & 133 & ,005 & $-$~,244\\
\textbf{LX.5} & 139 & \cellcolor{lsLightGray}{,065} & $-$~,157 &  &  &  & 156 & ,010 & $-$~,206 & 153 & \cellcolor{lsLightGray}{,051} & $-$~,158 &  &  & \\
\textbf{LX.6} &  &  &  & 194 & ,045 & $-$~,144 &  &  &  &  &  &  &  &  & \\
\textbf{GR.7} & 139 & ,007 & $-$~,229 &  &  &  & 156 & ,039 & $-$~,166 & 153 & ,007 & $-$~,215 &  &  & \\
\textbf{GR.8} & 139 & < ,001 & \cellcolor{smGreen}{$-$~,385} &  &  &  &  &  &  & 153 & < ,001 & \cellcolor{smGreen}{$-$~,387} &  &  & \\
\textbf{GR.10} & 139 & < ,001 & \cellcolor{smGreen}{$-$~,413} & 194 & < ,001 & \cellcolor{smBlue}{$-$~,518} & 156 & < ,001 & $-$~,299 & 153 & < ,001 & \cellcolor{smGreen}{$-$~,493} & 133 & < ,001 & \cellcolor{smGreen}{$-$~,391}\\
\textbf{SM.11} & 139 & \cellcolor{lsLightGray}{,056} & $-$~,163 & 194 & ,039 & $-$~,148 & 156 & ,005 & $-$~,225 & 153 & ,045 & $-$~,162 & 133 & < ,001 & $-$~,\cellcolor{smGreen}{$-$~,389}\\
\textbf{SM.12} &  &  &  & 194 & \cellcolor{lsLightGray}{,124} & $-$~,111 & 156 & < ,001 & \cellcolor{smGreen}{$-$~,433} & 153 & < ,001 & $-$~,290 & 133 & < ,001 & \cellcolor{smGreen}{$-$~,349}\\
\textbf{SM.13} &  &  &  &  &  &  & 156 & \cellcolor{lsLightGray}{,642} & $-$~,038 &  &  &  & 133 & < ,001 & \cellcolor{smGreen}{$-$~,309}\\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:98c}Korrelationen zwischen den Fehlertypen und der Qualität auf MÜ-Systemebene (Fortsetzung)   }
\bspnote{*In der Tabelle werden nur die Fehlertypen dargestellt, die bei mindestens einer Qualitätsvariable signifikante Korrelationen aufweisen.\\
p: Signifikanz; \txgray{nicht signifikant (p > 0,05)}; ρ: Korrelationskoeffizient; schwache Korrelation (ρ >=0,1); \txgreen{mittlere Korrelation (ρ >= 0,3)}; \boxblue{starke Korrelation (ρ >= 0,5)}}
\end{sidewaystable}

\paragraph*{Das \textit{HMÜ}{}-System Bing:}
Fehlertyp \textit{OR.1 „Orthografie -- Zeichensetzung“} korreliert mit einer signifikanten mittleren Korrelation mit der Stilqualität (ρ (N = 139) = $-$ ,376 / p < ,001). Die Veränderung bei diesem Fehler war bei Regel 5 „Partizipialkonstruktion vermeiden“. Durch die Bildung eines Nebensatzes mit ‚which‘ und ‚that‘ war die Kommasetzung für Bing problematisch, daher stieg die Fehleranzahl 10-fach (siehe \sectref{sec:5.3.5.3}).

Mit den grammatischen Fehlern korrelierte Bing mit Fehlertyp \textit{GR.8 „Falsches Verb (Zeitform, Komposition, Person)“} sowie mit Fehlertyp \textit{GR.10 „Falsche Wortstellung“} (\tabref{tab:05:98}): Fehlertyp GR.8 wurde bei Regel 7 „Konstruktionen mit ‚sein +~zu +~Infinitiv‘ vermeiden“ nach der Anwendung der Regel vollständig eliminiert (vorher war er in 19 von 24 Sätzen präsent). Bing hatte eine Schwierigkeit mit der Übersetzung des Passiversatzes. Nach der Verwendung des Imperativs wurden alle Fehler behoben (siehe \sectref{sec:5.3.7.3}). Ebenfalls sank Fehlertyp GR.8 „Falsches Verb“ (nicht signifikant) bei der Regel „Überflüssige Präfixe vermeiden“. Es war für Bing einfacher, Verben ohne Präfixe zu übersetzen (siehe \sectref{sec:5.3.8.3}). Entsprechend bestand eine signifikante mittlere negative Korrelation zwischen Fehlertyp~GR.8 und der Stilqualität (ρ (N = 139) = $-$~,419 / p < ,001) und der Inhaltsqualität (ρ (N = 139) = $-$~,312 / p~<~,001).

Fehlertyp \textit{GR.10 „Falsche Wortstellung“} sank in Bing bei Regel 1 „Für zitierte Oberflächentexte gerade Anführungszeichen verwenden“ (siehe \sectref{sec:5.3.1.3}) und Regel 3 „Konditionalsätze mit ‚Wenn‘ einleiten“ (siehe \sectref{sec:5.3.3.3}) signifikant: Die Verwendung von Anführungszeichen und die Formulierung von Bedingungen mit ‚Wenn‘ anstatt mit einem Verb waren für Bing sehr hilfreich, um die Wortstellung zu korrigieren. Daher besteht eine signifikante mittlere negative Korrelation zwischen Fehlertyp GR.8 und der Stilqualität (ρ (N = 139) = $-$~,408 / p < ,001) und der Inhaltsqualität (ρ (N = 139) = $-$~,368 / p < ,001).

Auf lexikalischer Ebene korreliert Fehlertyp \textit{LX.3 „Wort ausgelassen“} mit einer signifikanten mittleren Korrelation mit der Inhaltsqualität (ρ (N = 139) = $-$~,397 / p < ,001). Es gab eine hochsignifikante Veränderung ($-$ 91,3~\%) bei diesem Fehlertyp bei Regel 3 „Konditionalsätze mit ‚Wenn‘ einleiten“ (siehe \sectref{sec:5.3.3.3}). Durch die Formulierung von Bedingungen mit einem Verb vor KS hat Bing ‚If‘ bei der Übersetzung ausgelassen. Zudem sank Fehlertyp LX.3 bei Regel 9 „Keine Wortteile weglassen“ nicht signifikant in verschiedenen Fällen (siehe \sectref{sec:5.3.9.3}).

\paragraph*{Das \textit{HMÜ}{}-System Systran:}
Fehlertyp \textit{SM.13 „Semantik -- Kollokationsfehler“} korreliert mit einer signifikanten mittleren Korrelation mit der Stilqualität (ρ (N = 133) = $-$ ,304 / p < ,001). Die Veränderung bei diesem Fehlertyp war bei Regel 2 „Funktionsverbgefüge vermeiden“ (siehe \sectref{sec:5.3.2.3}). Systran hatte Schwierigkeiten Kollokationen korrekt zu übersetzen. Die Verwendung des bedeutungstragenden Verbs vereinfacht die Satzsemantik und ermöglicht Systran eine korrekte Übersetzung (eine Korrektur von knapp 94~\%).

Fehlertyp \textit{GR.10 „Falsche Wortstellung“} wurde in Systran nach Anwendung der Regel 5 „Partizipialkonstruktion vermeiden“ vollständig eliminiert (\sectref{sec:5.3.5.3}): Durch das Zerlegen der Partizipialkonstruktion und den Einbau eines Nebensatzes konnte Systran Fehlertyp GR.10 korrigieren (8 Fehler vorher; 0 nachher). Dementsprechend besteht eine signifikante mittlere negative Korrelation zwischen Fehlertyp GR.10 und der Inhaltsqualität (ρ (N = 133) = $-$ ,398 / p < ,001).

Auf semantischer Ebene stieg Fehlertyp \textit{SM.11 „Verwechslung des Sinns“} nach der Anwendung von Regel 6 „Passiv vermeiden“. Durch die Konvertierung des Passivs ins Aktiv (Bsp. „das Modul kann exportiert werden“ $\to$ „Sie können das Modul exportieren“) wurde das Subjekt ‚Sie‘ von Systran als ‚The‘ anstatt ‚You‘ übersetzt (siehe \sectref{sec:5.3.6.3}). Daher gibt es eine signifikante mittlere negative Korrelation zwischen Fehler SM.11 und der Inhaltsqualität (ρ (N = 133) = $-$ ,399 / p < ,001). Ebenfalls besteht eine signifikante mittlere negative Korrelation zwischen Fehlertyp \textit{SM.12 „Semantik -- Falsche Wahl“} und der Inhaltsqualität (ρ (N = 133) = $-$ ,391 / p < ,001). Allerdings ist Fehlertyp SM.12 in mehreren Regeln unterschiedlich auffindbar.

\paragraph*{Das \textit{SMÜ}{}-System SDL:}
Auf lexikalischer Ebene korreliert Fehlertyp \textit{LX.3 „Wort ausgelassen“} mit einer signifikanten mittleren Korrelation mit der Stilqualität (ρ (N = 153) = $-$~,401 / p < ,001) und einer signifikanten starken Korrelation mit der Inhaltsqualität (ρ (N = 153) = $-$~,534 / p < ,001). Alle Fehler, die bei Regel 3 „Konditionalsätze mit ‚Wenn‘ einleiten“ vor der Anwendung der Regel vorkamen, wurden nach der Anwendung der Regel eliminiert (15 Fehler vorher; 0 Fehler nachher). Vergleichbar mit dem HMÜ-System Bing hat das SMÜ-System SDL durch die Formulierung von Bedingungen mit einem Verb (vor KS) ‚If‘ bei der Übersetzung ausgelassen (siehe \sectref{sec:5.3.3.3}). Außerdem korreliert Fehlertyp \textit{LX.4 „Lexik -- Wort zusätzlich falsch eingefügt“} mit einer signifikanten mittleren Korrelation mit der Stilqualität (ρ (N = 153) = $-$~,323 / p < ,001). Fehlertyp LX.4 war bei mehreren Regeln vertreten.

Auf grammatischer Ebene sank Fehlertyp \textit{GR.8 „Falsches Verb (Zeitform, Komposition, Person)“} vergleichbar mit dem HMÜ-System Bing bei Regel 7 „Konstruktionen mit ‚sein +~zu +~Infinitiv‘ vermeiden“ nach der Anwendung der Regel um knapp 86~\% (siehe \sectref{sec:5.3.7.3}). Auch SDL hatte Schwierigkeiten mit der Übersetzung des Passiversatzes. Nach der Anwendung der Regel wurde der Imperativ korrekt übersetzt. Entsprechend besteht eine signifikante mittlere negative Korrelation zwischen Fehlertyp GR.8 und der Stilqualität (ρ (N = 153) = $-$~,395 / p < ,001) und der Inhaltsqualität (ρ (N = 153) = $-$ ,343 / p~<~,001).

Fehlertyp \textit{GR.10 „Falsche Wortstellung“} sank vergleichbar mit dem HMÜ-Sys\-tem Systran nach Anwendung der Regel 5 „Partizipialkonstruktion vermeiden“ um knapp 69~\% (siehe \sectref{sec:5.3.5.3}): Durch das Zerlegen der Partizipialkonstruktion und den Einbau eines Nebensatzes konnte SDL Fehlertyp GR.10 minimieren (16 Fehler vorher; 5 nachher). Zudem wurde Fehlertyp GR.10 bei Regel 7 „Konstruktionen mit ‚sein +~zu +~Infinitiv‘ vermeiden“ fast vollkommen eliminiert (11 Fehler vorher; 1 nachher). Auch hier wurde der Imperativ vom SMÜ-System SDL korrekt übersetzt (siehe \sectref{sec:5.3.7.3}). Dementsprechend besteht eine signifikante starke negative Korrelation zwischen Fehlertyp GR.10 und der Stilqualität (ρ (N = 153) = $-$ ,528 / p < ,001) sowie eine signifikante mittlere negative Korrelation mit der Inhaltsqualität (ρ (N = 153) = $-$ ,420 / p < ,001).

Auf semantischer Ebene besteht eine signifikante mittlere negative Korrelation zwischen Fehlertyp \textit{SM.12 „Semantik -- Falsche Wahl“} und der Inhaltsqualität (ρ (N = 153) = $-$ ,322 / p < ,001). Dennoch ist Fehlertyp SM.12 in mehreren Regeln unterschiedlich auffindbar.

\paragraph*{Das \textit{RBMÜ}{}-System Lucy:}
Fehlertyp \textit{OR.2 „Orthografie -- Großschreibung“} sank in Lucy bei der Regel „Für zitierte Oberflächentexte gerade Anführungszeichen verwenden“ signifikant um knapp 39~\% (siehe \sectref{sec:5.3.1.3}): die Verwendung von Anführungszeichen war für das RBMÜ-System Lucy hilfreich, um die Oberflächentexte als spezifische Begriffe bzw. Mehrwortentitäten zu erkennen und sie entsprechend großzuschreiben. Daher besteht eine signifikante mittlere negative Korrelation zwischen Fehlertyp OR.2 und der Stilqualität (ρ (N = 156) = $-$~,367 / p < ,001).

Vergleichbar mit dem SMÜ-System SDL wiederholte sich Fehlertyp \textit{SM.12 „Semantik -- Falsche Wahl“} in mehreren Regeln. Daher besteht eine signifikante starke negative Korrelation zwischen Fehlertyp SM.12 und der Inhaltsqualität (ρ (N = 156) = $-$ ,556 / p < ,001).

\paragraph*{Das \textit{NMÜ}{}-System Google Translate:}
Der einzige Fehler, der mit beiden Qualitätsattributen korreliert, ist Fehlertyp \textit{GR.10 „Grammatik -- Falsche Wortstellung“}: eine signifikante mittlere negative Korrelation mit der Stilqualität  (ρ (N = 194) = $-$ ,325 / p < ,001) und eine signifikante starke negative Korrelation mit der Inhaltsqualität  (ρ (N = 194) = $-$ ,577 / p < ,001). Allerdings ist Fehlertyp GR.10 in mehreren Regeln unterschiedlich auffindbar.

\subsection{Vergleich der AEM-Scores vor vs. nach der Anwendung aller analysierten KS-Regeln}
\label{sec:5.4.8}

Wie \figref{fig:05:147} veranschaulicht, waren die Differenzen\footnote{\textrm{Bei der Analyse der AEM-Scores wird nur die Differenz der Mittelwerte (nicht die Mittelwerte) berücksichtigt, da die Mittelwerte AEM-Scores außerhalb der KS-Stelle miteinbeziehen. Eine genaue Erklärung für die Berechnung des Mittelwerts der Differenz des TERbase-Scores und hLEPOR-Scores sowie seine Bedeutung ist unter \sectref{sec:4.4.6.4} „Basis des Vergleichs vor-KS vs. nach-KS zur Ermittlung des KS-Einflusses“ aufgeführt.}} der Mittelwerte der AEM-Scores sowohl mit TERbase als auch mit hLEPOR\footnote{\textrm{Näheres zu den AEMs TERbase und hLEPOR unter \sectref{sec:4.4.6.3} „Auswahl der automatischen Evaluationsmetriken“.}} bei allen MÜ-Systemen minimal und lagen zwischen +~0,017 und $-$~0,025. Es zeigte sich daher kein signifikanter Unterschied vor vs. nach der Anwendung der analysierten KS-Regeln.


\begin{figure}
\includegraphics[width=\textwidth]{figures/d3-img119.png}
\caption{\label{fig:05:147}Mittelwert der Differenz des TERbase-Scores und hLEPOR-Scores auf MÜ-Systemebene   }
\bspnote{Differenz = AEM-Score nach KS \textup{minus} AEM-Score vor KS}
\end{figure}


\subsection{Korrelation zwischen den Differenzen der AEM-Scores und den Qualitätsdifferenzen}
\label{sec:5.4.9}

Unter diesem Analysefaktor wurde untersucht, inwiefern die Differenz der Scores von TERbase und hLEPOR mit der Differenz in der allgemeinen Qualität korreliert (\figref{fig:05:148}).


\begin{figure}
\includegraphics[width=\textwidth]{figures/d3-img120.png}

% & Differenz Q



%\includegraphics[height=.3\textheight]{figures/d3-img121.png}
%Differenz hLEPOR

%Differenz TERbase\\
\caption{\label{fig:05:148}Differenz der allgemeinen Qualität und Differenz der AEM-Scores auf MÜ-Systemebene   }
\bspnote{Differenz = Szenario nach KS \textit{minus} Szenario vor KS}
\end{figure}

Bei allen MÜ-Systemen erwies die Spearman-Korrelationsanalyse hochsignifikante mittlere und starke Korrelationen zwischen den Differenzen der Scores von TERbase und hLEPOR und der Differenz der allgemeinen Qualität\footnote{\textrm{Die allgemeine Qualität ist der Mittelwert der Stilqualität und der Inhaltsqualität, da bei der Ermittlung dieser Korrelation keine Unterscheidung zwischen den beiden Qualitätsattributen notwendig ist.}} (\tabref{tab:05:99}).


\begin{table}
\begin{tabularx}{\textwidth}{lrrrrrr}

\lsptoprule
%\hhline%%replace by cmidrule{~------}
{} & \multicolumn{3}{p{4.5cm}}{{Korrelation zw. Differenz allg. Qualität und Differenz des \textbf{\textit{TERbase-Scores}}}

 (nach KS \textit{minus} vor KS)} & \multicolumn{3}{p{4.5cm}}{{Korrelation zw. Differenz allg. Qualität und Differenz des \textbf{\textit{hLEPOR-Scores}}}

 (nach KS \textit{minus} vor KS)}\\
\cmidrule(lr){2-4}\cmidrule(lr){5-7}
{} & \textbf{N} & \textbf{p} & \textbf{ρ} & \textbf{N} & \textbf{p} & \textbf{ρ}\\
\midrule
 \textbf{HMÜ Bing} & 139 & < ,001 & \boxblue{,589} & 139 & < ,001 & \boxblue{,580}\\
 \textbf{GNMÜ} & 194 & < ,001 & \boxblue{,606} & 194 & < ,001 & \boxblue{,611}\\
 \textbf{RBMÜ Lucy} & 156 & < ,001 & \txgreen{,491} & 156 & < ,001 & \txgreen{,495}\\
 \textbf{SMÜ SDL} & 153 & < ,001 & \txgreen{,418} & 153 & < ,001 & \txgreen{,436}\\
 \textbf{HMÜ Systran} & 133 & < ,001 & \boxblue{,518} & 133 & < ,001 & \txgreen{,476}\\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:05:99}Korrelation zwischen den Differenzen der AEM-Scores und den Qualitätsdifferenzen   }
\bspnote{\begin{tabbing}
p: Signifikanz\hspace{2.5cm}\= ρ: Korrelationskoeffizient\hspace{1cm}\= \hspace{4cm}\\
schwache Korrelation (ρ >=0,1)\> \txgreen{mittlere Korrelation (ρ >= 0,3)}\> \boxblue{starke Korrelation (ρ >= 0,5)}
\end{tabbing}}
\end{table}

Somit bestätigen sich die Ergebnisse der Humanevaluation und die der automatischen Evaluation gegenseitig, denn eine starke positive Korrelation besagt, dass ein positiver Effekt der KS-Anwendung auf Systemebene sich sowohl durch einen erhöhten Score in der Humanevaluation als auch einen verbesserten AEM-Score in der automatischen Evaluation zeigte. Umgekehrt gingen auch bei einem negativen Effekt der KS-Anwendung die Scores beider Evaluationen zurück.

Außerdem visualisiert \figref{fig:05:148} noch einmal deutlich, wie gering die Qualitäts- und AEM-Differenzen vor vs. nach KS bei Google Translate und Systran im Vergleich zu den anderen Systemen ausfielen: bei Google Translate aufgrund der kleinen Veränderung in den vielen fehlerfreien MÜ bzw. bei Systran aufgrund der kleinen Veränderung in den vielen fehlerhaften MÜ in den beiden Szenarien.

\subsection{Analyse auf MÜ-Systemebene: Validierung der Hypothesen}
\label{sec:5.4.10}

Um die vorgestellten Ergebnisse der Systeme auf die Forschungsfragen der Studie zurückzuführen, listet dieser Abschnitt die zugrunde liegenden Hypothesen der Forschungsfragen zusammen mit einer Zusammenfassung der obigen Ergebnisse in tabellarischer Form auf. Für einen schnelleren Überblick steht (+) für eine Verbesserung bzw. einen Anstieg z.~B. im Sinne eines Qualitätsanstiegs, verbesserter AEM-Scores oder eines Anstiegs der Fehleranzahl; ($-$) steht für einen Rückgang; die \txgreen{grüne} Farbe symbolisiert eine signifikante Veränderung; <{}<{}>{}> steht für eine starke Korrelation und <> für eine mittlere Korrelation.\footnote{\textrm{Schwache Korrelationen werden in dieser Übersicht nicht angezeigt.}}

\paragraph*{Vergleich der Fehleranzahl vor vs. nach der Anwendung der KS-Regeln}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Gibt es \textit{bei einem bestimmten MÜ-System} einen Unterschied in der Fehleranzahl nach der Anwendung der KS-Regeln im Vergleich zu vor der Anwendung?
\item [H0 --] Es gibt keinen Unterschied in der Fehleranzahl vor vs. nach der Anwendung der KS-Regeln.
\item [H1 --] Es gibt einen Unterschied in der Fehleranzahl vor vs. nach der Anwendung der KS-Regeln.RBMÜ
\item [Resultat:] Nur für Bing und SDL wurde H0 abgelehnt und somit H1 bestätigt: \\
\begin{tabbing}
\txgreen{\textbf{HMÜ Bing}  \textbf{($-$)}}\hspace{1cm}\= \txgreen{\textbf{SMÜ SDL ($-$)}}\hspace{1cm} \= \hspace{4cm} \\
\textbf{RBMÜ Lucy ($-$)}\> \textbf{GNMÜ +}\> \textbf{HMÜ Systran +}
\end{tabbing}
\end{description}

\hrule
\paragraph*{Vergleich der Fehlertypen vor vs. nach der Anwendung der KS-Regeln}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Kommen bestimmte Fehlertypen \textit{bei einem bestimmten MÜ-Sys\-tem} vor bzw. nach der Anwendung der KS-Regeln vor?
\item [H0 --] Es gibt keinen Unterschied in der Häufigkeit der einzelnen Fehlertypen vor vs. nach der Anwendung der KS-Regeln.
\item [H1 --] Es gibt einen Unterschied in der Häufigkeit der einzelnen Fehlertypen vor vs. nach der Anwendung der KS-Regeln.
\item [Resultat:] H0 wurde abgelehnt und somit H1 bestätigt, und zwar nur für die hier aufgeführten Fehlertypen bei dem jeweiligen System:
\end{description}
\begin{tabularx}{\textwidth}{XlXXX}
\lsptoprule
\cellcolor{smGreen}\textbf{HMÜ Bing:}

{ \textbf{+~OR.1}}

{ \textbf{$-$ OR.2}}

{ \textbf{$-$ LX.3}}

{ \textbf{$-$ GR.8}}

 \textbf{$-$ GR.10} & \textbf{GNMÜ} & \cellcolor{smGreen} { \textbf{RBMÜ Lucy:}}

 { \textbf{$-$ OR.2}}

  \textbf{$-$ SM.13} & \cellcolor{smGreen}{{ \textbf{SMÜ SDL:}}

 { \textbf{+~OR.1}}

 { \textbf{$-$ OR.2}}

 { \textbf{$-$ LX.3}}

 { \textbf{$-$ LX.4}}

 { \textbf{$-$ GR.9}}

  \textbf{$-$ GR.10}} & \cellcolor{smGreen}{ \textbf{HMÜ Systran:}}

 { \textbf{+~OR.1}}

 { \textbf{$-$ LX.3}}

 { \textbf{+~LX.4}}

  \textbf{$-$ SM.13}\\
\lspbottomrule
\end{tabularx}

\hrule
\paragraph*{Vergleich der Qualität vor vs. nach der Anwendung der KS-Regeln}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Gibt es \textit{bei einem bestimmten MÜ-System} einen Unterschied in der Stil- und Inhaltsqualität der MÜ der KS-Stelle nach der Anwendung der KS-Regeln im Vergleich zu vor der Anwendung?
\item [H0 --] Es gibt keinen Qualitätsunterschied vor vs. nach der Anwendung der KS-Regeln.
\item [H1 --] Es gibt einen Qualitätsunterschied vor vs. nach der Anwendung der KS-Regeln.
\item [Resultat:] H0 wurde abgelehnt und H1 bestätigt, und zwar wie folgt: SQ nur in Bing, Google und SDL; CQ nur in Bing und SDL.
\end{description}
\begin{tabularx}{\textwidth}{lXXXXX}
\lsptoprule
& \textbf{Bing:} & \textbf{Google:} & \textbf{Lucy:} & \textbf{SDL} & \textbf{Systran:}\\
\midrule
\textbf{SQ} & \cellcolor{smGreen} + & \cellcolor{smGreen} $-$ & + & \cellcolor{smGreen} + & + \\
\textbf{CQ} & \cellcolor{smGreen} + & $-$ & + & \cellcolor{smGreen} + & + \\
\lspbottomrule
\end{tabularx}

\hrule
\paragraph*{Vergleich der Qualität vor vs. nach der Anwendung der KS-Regeln auf Annotationsgruppenebene}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Gibt es \textit{bei einem bestimmten MÜ-System} einen Unterschied in der Stil- und Inhaltsqualität bei den einzelnen Annotationsgruppen nach der Anwendung der KS-Regeln im Vergleich zu vor der Anwendung?
\item [H0 --] Bei den Annotationsgruppen gibt es keinen Qualitätsunterschied vor vs. nach der Anwendung der KS-Regel.
\item [H1 --] Bei den Annotationsgruppen gibt es einen Qualitätsunterschied vor vs. nach der Anwendung der KS-Regel.
\item [Resultat:] Nur für die Gruppen RF und FR bei allen Systemen mit Ausnahme von zwei Fällen bei Google (CQ in RF und SQ in FR) wurde H0 abgelehnt und somit H1 bestätigt:
\end{description}
\begin{center}
\begin{tabularx}{.9\textwidth}{lllllllll}
\lsptoprule
\multirow{2}{*}{\diagbox{\textbf{System}}{\textbf{AnnoGr.}}} & \multicolumn{2}{c}{\textbf{FF}} & \multicolumn{2}{c}{\textbf{RF}} & \multicolumn{2}{c}{\textbf{FR}} & \multicolumn{2}{c}{\textbf{RR}}\\
\cmidrule(lr){2-3}\cmidrule(lr){4-5}\cmidrule(lr){6-7}\cmidrule(lr){8-9}
 & \textbf{SQ} & \textbf{CQ} & \textbf{SQ} & \textbf{CQ} & \textbf{SQ} & \textbf{CQ} & \textbf{SQ} & \textbf{CQ}\\
\midrule
\textbf{HMÜ Bing} & \textbf{+} & \textbf{+} & \cellcolor{smGreen}\textbf{($-$)} & \cellcolor{smGreen}\textbf{($-$)} & \cellcolor{smGreen}\textbf{+} & \cellcolor{smGreen}\textbf{+} & \textbf{($-$)} & \textbf{+}\\
\textbf{GNMÜ} & \textbf{($-$)} & \textbf{($-$)} & \cellcolor{smGreen}\textbf{($-$)} & \textbf{($-$)} & \textbf{+} & \cellcolor{smGreen}\textbf{+} & \textbf{($-$)} & \textbf{($-$)}\\
\textbf{RBMÜ Lucy} & \textbf{+} & \textbf{($-$)} & \cellcolor{smGreen}\textbf{($-$)} & \cellcolor{smGreen}\textbf{($-$)} & \cellcolor{smGreen}\textbf{+} & \cellcolor{smGreen}\textbf{+} & \textbf{($-$)} & \textbf{+}\\
\textbf{SMÜ SDL} & \textbf{+} & \textbf{+} & \cellcolor{smGreen}\textbf{($-$)} & \cellcolor{smGreen}\textbf{($-$)} & \cellcolor{smGreen}\textbf{+} & \cellcolor{smGreen}\textbf{+} & \textbf{($-$)} & \textbf{($-$)}\\
\textbf{HMÜ Systran} & \textbf{($-$)} & \textbf{($-$)} & \cellcolor{smGreen}\textbf{($-$)} & \cellcolor{smGreen}\textbf{($-$)} & \cellcolor{smGreen}\textbf{+} & \cellcolor{smGreen}\textbf{+} & \textbf{+} & \textbf{+}\\
\lspbottomrule
\end{tabularx}
\end{center}

\hrule
\paragraph*{Vergleich der Qualität vor vs. nach der Anwendung der KS-Regeln}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Besteht \textit{bei einem bestimmten MÜ-System} ein Zusammenhang zwischen der Differenz der Fehleranzahl eines bestimmten Fehlertyps (Fehleranzahl nach KS \textit{minus} Fehleranzahl vor KS) und der Differenz der Stil- bzw. Inhaltsqualität (Qualität nach KS \textit{minus} Qualität vor KS)?
\item [H0 --] Es besteht kein Zusammenhang zwischen der Differenz der Fehleranzahl eines bestimmten Fehlertyps und der Differenz der Stil- bzw. Inhaltsqualität.
\item [H1 --] Es besteht ein Zusammenhang zwischen der Differenz der Fehleranzahl eines bestimmten Fehlertyps und der Differenz der Stil- bzw. Inhaltsqualität.
\item [Resultat:] H0 wurde abgelehnt und somit H1 bestätigt, und zwar nur für den Zusammenhang zwischen den Qualitätswerten und den hier aufgeführten Fehlertypen bei dem jeweiligen System. Alle aufgelisteten Korrelationen sind negativ:
\end{description}
\begin{small}
\begin{tabularx}{\textwidth}{XllXX}
\lsptoprule
\textbf{HMÜ Bing} & \textbf{GNMÜ} & \textbf{RBMÜ Lucy} & \textbf{SMÜ SDL} & \textbf{HMÜ Systran}\\
\midrule
\cellcolor{smGreen}\textbf{OR.1<>SQ}

\textbf{GR.8<>SQ}

\textbf{GR.10<>SQ} & \cellcolor{smGreen}\textbf{GR.10<>SQ} & \cellcolor{smGreen}\textbf{OR.2<>SQ} & \cellcolor{smGreen}\textbf{LX.3<>SQ}

\textbf{LX.4<>SQ}

\textbf{GR.8<>SQ}

\textbf{GR.10<{}<{}>{}>SQ} & \cellcolor{smGreen}\textbf{SM.13<>SQ}\\
\cellcolor{smGreen}\textbf{LX.3<>CQ}

\textbf{GR.8<>CQ}

\textbf{GR.10<>CQ} & \cellcolor{smGreen}{\textbf{GR.10<{}<{}>{}>CQ}} & \cellcolor{smGreen}{\textbf{SM.12<{}<{}>{}>CQ}} & \cellcolor{smGreen}\textbf{LX.3<{}<{}>{}>CQ}

\textbf{GR.8<>CQ}

\textbf{GR.10<>CQ}

\textbf{SM.12<>CQ} & \cellcolor{smGreen}\textbf{GR.10<>CQ}

\textbf{SM.11<>CQ}

 \textbf{SM.12<>CQ}\\
\lspbottomrule
\end{tabularx}
\end{small}

\hrule
\paragraph*{Vergleich der AEM-Scores vor vs. nach der Anwendung der KS-Regel}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Gibt es \textit{bei einem bestimmten MÜ-System} einen Unterschied in den AEM-Scores von TERbase bzw. hLEPOR nach der Anwendung der KS-Regeln im Vergleich zu vor der Anwendung?
\item [H0 --] Es gibt keinen Unterschied in den AEM-Scores vor vs. nach der Anwendung der KS-Regeln.
\item [H1 --] Es gibt einen Unterschied in den AEM-Scores vor vs. nach der Anwendung der KS-Regeln.
\item [Resultat:] H0 wurde nicht abgelehnt und somit konnte H1 nicht bestätigt werden. Die Ergebnisse waren wie folgt:
\end{description}
\begin{center}
\begin{tabularx}{.7\textwidth}{llllll}
\lsptoprule
& {\textbf{Bing}} & {\textbf{Google}} & {\textbf{Lucy}} & {\textbf{SDL}} & {\textbf{Systran}}\\
\midrule
\textbf{TERbase} & ($-$) & {($-$)} & {($-$)} & {+} & ($-$)\\
\textbf{hLEPOR} & {+} & {($-$)} & {($-$)} & {+} & ($-$)\\
\lspbottomrule
\end{tabularx}
\end{center}

\hrule
\paragraph*{Korrelation zwischen den AEM-Scores-Differenzen und der Qualitätsdifferenz}
\begin{description}[font=\normalfont\bfseries]
\item [Fragestellung:] Besteht \textit{bei einem bestimmten MÜ-System} ein Zusammenhang zwischen der Differenz der AEM-Scores in TERbase bzw. hLEPOR (Mittelwert der AEM-Scores nach KS \textit{minus} Mittelwert der AEM-Scores vor KS) und der Differenz der allgemeinen Qualität  (Qualität nach KS \textit{minus} Qualität vor KS)?
\item [H0 --] Es besteht kein Zusammenhang zwischen der Differenz der AEM-Scores und der Differenz der allgemeinen Qualität.
\item [H1 --] Es besteht ein Zusammenhang zwischen der Differenz der AEM-Scores und der Differenz der allgemeinen Qualität.
\item [Resultat:] H0 wurde abgelehnt und H1 bestätigt, und zwar für den Zusammenhang zwischen der allgemeinen Qualität und den AEM-Scores wie folgt. Alle aufgelisteten Korrelationen sind positiv:
\end{description}
\begin{center}
\begin{small}
\begin{tabularx}{.93\textwidth}{llllll}
\lsptoprule
& {\textbf{SMÜ Bing}} & {\textbf{GNMÜ}} & {\textbf{RBMÜ Lucy}} & {\textbf{SMÜ SDL}} & {\textbf{HMÜ Systran}}\\
\midrule
\textbf{TERbase} & \cellcolor{smGreen}<{}<{}>{}> Q & \cellcolor{smGreen}<{}<{}>{}> Q & \cellcolor{smGreen}<> Q & \cellcolor{smGreen}<> Q & \cellcolor{smGreen}<{}<{}>{}> Q\\
\textbf{hLEPOR} & \cellcolor{smGreen}<{}<{}>{}> Q &\cellcolor{smGreen} <{}<{}>{}> Q & \cellcolor{smGreen}<> Q &\cellcolor{smGreen} <> Q & \cellcolor{smGreen}<> Q\\
\lspbottomrule
\end{tabularx}
\end{small}
\end{center}









\subsection{Übersicht der Ergebnisse auf MÜ-Systemebene}
\label{sec:5.4.11}

\tabref{tab:05:100} bietet eine Übersicht über die Ergebnisse auf Systemebene.


\begin{sidewaystable}
\scriptsize
\fittable{
\begin{tabular}{lllllllllll}

\lsptoprule

{} & {\textbf{Fehler-}} & \textbf{Fehler-} & \multicolumn{2}{c}{\textbf{Qualität}} & \multicolumn{2}{c}{\textbf{Fehlertypen <> Qualität}} & \multicolumn{2}{c}{\textbf{AEM-Scores}} & \multicolumn{2}{c}{\textbf{AEM-Scores <> Qualität}}\\
\cmidrule(lr){6-7}\cmidrule(lr){8-9}\cmidrule(lr){10-11}
& \textbf{anzahl} & \textbf{typen} &  & & \textbf{Stilqualität} & \textbf{Inhaltsqualität} & {\textbf{TERbase}} & {\textbf{hLEPOR}} & {\textbf{TERbase}} & \textbf{hLEPOR}\\
\midrule
{\textbf{HMÜ}} & \cellcolor{smGreen}{($-$)} & \cellcolor{smGreen}+~OR.1  & \cellcolor{smGreen}{+~SQ} & \cellcolor{smGreen}+~CQ & \cellcolor{smGreen}\textit{neg} OR.1<>SQ & \cellcolor{smGreen}\textit{neg} LX.3<>CQ & {($-$)} & {+} & \cellcolor{smGreen}\textit{pos} TERbase <{}<{}>{}> Q & \cellcolor{smGreen}\textit{pos} hLEPOR <{}<{}>{}> Q\\
\textbf{Bing} & \cellcolor{smGreen}& \cellcolor{smGreen}$-$ OR.2  &\cellcolor{smGreen} & \cellcolor{smGreen}& \cellcolor{smGreen}\textit{neg} GR.8<>SQ & \cellcolor{smGreen}\textit{neg} GR.8<>CQ &  &  &\cellcolor{smGreen} &\cellcolor{smGreen} \\
& \cellcolor{smGreen} & \cellcolor{smGreen}$-$ LX.3 &  \cellcolor{smGreen}& \cellcolor{smGreen}& \cellcolor{smGreen}\textit{neg} GR.10<>SQ & \cellcolor{smGreen}\textit{neg} GR.10<>CQ &  &  & \cellcolor{smGreen} & \cellcolor{smGreen}\\
& \cellcolor{smGreen} & \cellcolor{smGreen} $-$ GR.8 & \cellcolor{smGreen} & \cellcolor{smGreen} & \cellcolor{smGreen} & \cellcolor{smGreen} & & & \cellcolor{smGreen} & \cellcolor{smGreen}\\
& \cellcolor{smGreen} & \cellcolor{smGreen}$-$ GR.10 & \cellcolor{smGreen} & \cellcolor{smGreen} & \cellcolor{smGreen} & \cellcolor{smGreen} & & & \cellcolor{smGreen} & \cellcolor{smGreen}\\
\midrule
{\textbf{GNMÜ}} & {+} & & \cellcolor{smGreen}{$-$ SQ} & $-$ CQ & \cellcolor{smGreen}\textit{neg} GR.10<>SQ & \cellcolor{smGreen}\textit{neg} GR.10<{}<{}>{}>CQ & {($-$)} & {($-$)} & \cellcolor{smGreen}{\textit{pos} TERbase <{}<{}>{}> Q} & \cellcolor{smGreen}\textit{pos} hLEPOR <{}<{}>{}> Q\\
\midrule
{\textbf{RBMÜ}} & {($-$)} & \cellcolor{smGreen}{$-$ OR.2}  & {+~SQ} & +~CQ & \cellcolor{smGreen}\textit{neg} OR.2<>SQ & \cellcolor{smGreen}\textit{neg} SM.12<{}<{}>{}>CQ & {($-$)} & {($-$)} & \cellcolor{smGreen}{\textit{pos} TERbase <> Q} & \cellcolor{smGreen}\textit{pos} hLEPOR <> Q\\
\textbf{Lucy}& &\cellcolor{smGreen}{$-$ SM.13} & & & \cellcolor{smGreen} & \cellcolor{smGreen} & & &  \cellcolor{smGreen} & \cellcolor{smGreen} \\
\midrule
{\textbf{SMÜ}} & \cellcolor{smGreen}{($-$)} & \cellcolor{smGreen}{+~OR.1} &  \cellcolor{smGreen}{+~SQ} & \cellcolor{smGreen}+~CQ & \cellcolor{smGreen}\textit{neg} LX.3<>SQ & \cellcolor{smGreen}\textit{neg} LX.3<{}<{}>{}>CQ & {+} & {+} & \cellcolor{smGreen}\textit{pos} TERbase <> Q & \cellcolor{smGreen}\textit{pos} hLEPOR <> Q \\
\textbf{SDL}& \cellcolor{smGreen} & \cellcolor{smGreen}$-$ OR.2  &\cellcolor{smGreen} & \cellcolor{smGreen} & \cellcolor{smGreen}\textit{neg} LX.4<>SQ & \cellcolor{smGreen}\textit{neg} GR.8<>CQ &  &  & \cellcolor{smGreen} & \cellcolor{smGreen} \\
& \cellcolor{smGreen} & \cellcolor{smGreen}$-$ LX.3 & \cellcolor{smGreen} & \cellcolor{smGreen} & \cellcolor{smGreen}\textit{neg} GR.8<>SQ & \cellcolor{smGreen}\textit{neg} GR.10<>CQ &  &  & \cellcolor{smGreen} & \cellcolor{smGreen}\\
& \cellcolor{smGreen} & \cellcolor{smGreen}$-$ LX.4 & \cellcolor{smGreen} & \cellcolor{smGreen} & \cellcolor{smGreen}\textit{neg} GR.10<{}<{}>{}>SQ & \cellcolor{smGreen}\textit{neg} SM.12<>CQ &  &  & \cellcolor{smGreen} & \cellcolor{smGreen}\\
& \cellcolor{smGreen} & \cellcolor{smGreen}$-$ GR.9 & \cellcolor{smGreen} & \cellcolor{smGreen} & \cellcolor{smGreen} & \cellcolor{smGreen} & & & \cellcolor{smGreen} & \cellcolor{smGreen}\\
& \cellcolor{smGreen} & \cellcolor{smGreen}{$-$ GR.10} & \cellcolor{smGreen} & \cellcolor{smGreen} & \cellcolor{smGreen} & \cellcolor{smGreen} & & & \cellcolor{smGreen} & \cellcolor{smGreen}\\
\midrule
{\textbf{HMÜ}} & {+} & \cellcolor{smGreen}{+~OR.1} &  {+~SQ} & +~CQ & \cellcolor{smGreen}\textit{neg} SM.13<>SQ & \cellcolor{smGreen}\textit{neg} GR.10<>CQ & {($-$)} & {($-$)} & \cellcolor{smGreen}\textit{pos} TERbase <{}<{}>{}> Q & \cellcolor{smGreen}\textit{pos} hLEPOR <> Q\\
\textbf{Systran}& &\cellcolor{smGreen}$-$ LX.3 &  &  & \cellcolor{smGreen} &  \cellcolor{smGreen}\textit{neg} SM.11<>CQ &  &  & \cellcolor{smGreen} & \cellcolor{smGreen}\\
& & \cellcolor{smGreen}+~LX.4  &  &  & \cellcolor{smGreen} &  \cellcolor{smGreen}\textit{neg} SM.12<>CQ &  &  & \cellcolor{smGreen} & \cellcolor{smGreen}\\
& & \cellcolor{smGreen}$-$ SM.13 & & & \cellcolor{smGreen} & \cellcolor{smGreen} & & & \cellcolor{smGreen} & \cellcolor{smGreen}\\
\lspbottomrule
\end{tabular}
}
\caption{\label{tab:05:100}Übersicht der Ergebnisse auf MÜ-Systemebene   }
\bspnote{\scriptsize
\vspace{-8pt}\begin{tabbing}
SQ: Stilqualität\hspace{2.5cm}\= CQ: Inhaltsqualität\hspace{2cm}\= Q: allg. Qualität\hspace{1.5cm}\= \txgreen{Signifikant (p < 0,5)}\hspace{.5cm}\= Blank: nicht signifikant\\
<> mittlere Korrelation (ρ >= 0,3)\> <{}<{}>{}> starke Korrelation (ρ >= 0,5)\> \textit{neg}: negative Korrelation\> \textit{pos}: positive Korrelation\\
\end{tabbing}}
\end{sidewaystable}

Der Vergleich der fünf unterschiedlichen MÜ-Systeme vor vs. nach der Anwendung der neun KS-Regeln deckte folgendes Ergebnis auf: Bei den Systemen der älteren Ansätze stimmten die Ergebnisse mit denen mehrerer bisheriger Studien zu den älteren MÜ-Ansätzen überein, nämlich dass die KS-Anwendung den MÜ-Output verbessert (vgl. \citealt{NybergMitamura1996}; \citealt{Bernth1999}; \citealt{BernthGdaniec2001}: 208; \citealt{Drugan2013}: 98; \citealt{DrewerZiegler2014}: 196; \citealt{Wittkowsky2017}: 92). Dies ist der Fall mit Ausnahme eines der beiden analysierten HMÜ-Systeme (Systran), dessen Fehleranzahl sowohl vor-KS als auch nach-KS sehr hoch war und nach-KS insignifikant stieg. Das NMÜ-System hingegen war in der Lage, unter allen Systemen die Übersetzung mit der geringsten Fehleranzahl und den höchsten Qualitätswerten im Sinne der Verständlichkeit, der Genauigkeit und des Stils sowohl vor als auch nach der Anwendung der KS-Regeln zu produzieren. Ferner führte die Anwendung der analysierten Regeln bei dem NMÜ-System nicht zu einer Qualitätsverbesserung. Im Gegenteil fielen vor der KS-Anwendung die Fehleranzahl niedriger und die Verständlichkeit\nobreakdash-, Genauigkeits- und Stilbewertungen höher als nach der KS-Anwendung -- mit einem statistisch signifikanten Wert im Falle der Stilbewertungen -- aus. Wie bisherige Studien zeigen (vgl. \citealt{ToralSanchez-Cartagena2017}), zählt die Flüssigkeit bzw. der Stil zu den Stärken des NMÜ-Ansatzes. Obwohl die KS im Allgemeinen die Verständlichkeit und nicht den Stil im Fokus hat, bietet die NMÜ auf Basis der erzielten Ergebnisse nicht nur eine verbesserte Verständlichkeit und Genauigkeit, sondern schlägt sich auch positiv im Stil nieder.
