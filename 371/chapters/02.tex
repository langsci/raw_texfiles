\chapter{\label{ch:2}Kontrollierte Sprache}

\marzoukepigram{Unternehmen, die mehrsprachige Dokumentation erstellen, [\ldots] unterscheiden sich heute nicht mehr darin, ob sie eine Kontrollierte Sprache benutzen oder nicht, sondern nur noch darin, wie umfassend die Sammlung der Formulierungsregeln ist und wie streng sie eingehalten werden. \citep[19]{Göpferich2007a}}

\section{\label{sec:2.0}Einleitung}

Das vorliegende Kapitel befasst sich mit dem Thema Kontrollierte Sprache. Nach einer Erläuterung des Begriffs der Kontrollierten Sprache (KS), wird näher auf die Definition, die Ziele und den Aufbau der KS eingegangen. Anschließend werden die Entstehung und Entwicklung der KS beleuchtet sowie Beispiele von bekannten Kontrollierten Sprachen in verschiedenen Sprachen genannt. Da ausgewählte Regeln des Kontrollierten Deutsch bzw. der tekom-Leitlinie das Untersuchungsobjekt darstellen, werden das Kontrollierte Deutsch und die tekom-Leitlinie im Anschluss detaillierter betrachtet. Ferner werden die Stärken und Schwächen der KS gegenübergestellt. Da der Einsatz von einer KS in den Unternehmen in der Regel durch eine Software (CL-Checker) unterstützt wird, wird diese Software bzw. ihre Funktionsweise anschließend beschrieben.

\section{\label{sec:2.1}Kontrollierte Sprache: Eine Einführung}

\subsection{Kontrollierte Sprache -- Begriffsbestimmung und Definition}
\label{sec:2.1.1}
Die „Kontrollierte Sprache“ ist eine wörtliche Übersetzung der englischen Bezeichnung „Controlled Language“. Eine Sprache kann nicht kontrolliert werden. In der Fachkommunikation ist „kontrollieren“ keine treffende Übersetzung für das englische Verb „control“. Die Bezeichnungen „regulierte“, „gesteuerte“ oder „standarisierte Sprache“ wären zutreffendere Übersetzungen (vgl. \citealt{Schubert1999}: 434; \citealt{Göpferich2007a}). Ein weiterer Aspekt des Begriffs ist, dass das Wort „Kontrollieren“ im Deutschen negativ konnotiert ist. Dennoch blieb die Bezeichnung „Kontrollierte Sprache“ sowohl in der Forschung als auch in der Industrie die meist verwendete Bezeichnung. Aus diesem Grund wird die Bezeichnung „Kontrollierte Sprache“ in der vorliegenden Arbeit übernommen.

Grundsätzlich kann jede festgelegte Regelsammlung bzw. jeder Redaktionsleitfaden als eine Kontrollierte Sprache von unterschiedlichen Umfängen betrachtet werden (vgl. \citealt{Göpferich2007a}). Anhand einer genauen Betrachtung der Definitionen der Kontrollierten Sprache können die konkreten Merkmale einer Kontrollierten Sprache (KS) abgeleitet werden:

Nach \citet[366]{Göpferich2008} sind Kontrollierte Sprachen „Subsysteme natürlicher Sprachen, deren Wortschatz und zulässige grammatische Konstruktionen eine Teilmenge des Wortschatzes bzw. der möglichen grammatischen Konstruktionen der unkontrollierten natürlichen Sprache darstellen, aus denen sie abgeleitet sind“. Eine ähnliche Definition liefern \citet[192]{DrewerZiegler2014}, in der sie unter einer KS „ein Teilsystem einer natürlichen Sprache mit den folgenden Bestandteilen: Regelwerk mit festen Schreibregeln (v. a. Vorgaben zur Formulierung von Sätzen) sowie vorgegebener Wortschatz aus Basiswortschatz und Fachwortschatz in Form eines Lexikons“ verstehen. Auf Basis der beiden Definitionen zeichnet sich eine Kontrollierte Sprache hauptsächlich dadurch aus, dass sie einer bestimmten natürlichen Sprache entstammt, wobei der Unterschied zwischen der KS und ihrer natürlichen Sprache in dem eingeschränkten Lexikon und der vereinfachten Syntax liegt. Eine Kontrollierte Sprache besteht konkret aus den folgenden Bestandteilen: einem spezifischen Regelwerk für Schreibregeln und einem Wortschatz, der sowohl Basiswörter als auch Fachwörter beinhalten kann.

An dieser Stelle ist eine Abgrenzung zwischen einer Kontrollierten Sprache, einer Subsprache (Sublanguage) und einer Plansprache hilfreich, um einer Verwechslung vorzubeugen. Wie oben beschrieben ist eine \textit{Kontrollierte Sprache} eine Untermenge ihrer natürlichen Quellsprache, die nach festgelegten Regeln gesteuert bzw. standardisiert wird. Eine \textit{Subsprache} ist zwar eine (gruppen- oder bereichsspezifische) Untergruppe ihrer natürlichen Sprache \citep[33]{Lehrndorfer1996a}, allerdings wird sie \textit{nicht} künstlich gesteuert oder reguliert, sondern „it just happens to have a limited number of linguistic features“ \citep[47]{Roturier2006}. Ein bekanntes Beispiel für eine Subsprache ist die Sprache der Wettervorhersage. Bei einer \textit{Plansprache} schließlich handelt es sich um eine vollständig künstliche Sprache, wie die bekannte Sprache „Esperanto“ von Zamenhof. Der Wortschatz von Esperanto ist bewusst auf einer Kombination von germanischen, indogermanischen, romanischen und slawischen Wortwurzeln basiert und verfügt über eine einfache phonologische, morphologische und syntaktische Struktur (\citealt{LehrndorferReuther2008}: 100). Die Plansprachen zielten auf die internationale Verständigung im Allgemeinen -- nicht im technischen Bereich -- und die Solidarität der Völker ab, allerdings konnten sie sich aus unterschiedlichen Gründen nicht durchsetzen \citep[30]{Lehrndorfer1996a}. Somit unterscheidet sich eine Plansprache von einer KS nicht nur hinsichtlich des Aufbaus und Umfangs, sondern auch bezüglich des Fokus und der Ziele, denn der technische Bereich stellt herkömmlich den Haupteinsatzbereich der KS dar (vgl. \citealt{DrewerZiegler2014}: 197).

An dieser Stelle darf gleichzeitig nicht unerwähnt bleiben, dass weitere kontrollierte Sprachvarietäten, wie die Einfache bzw. Leichte Sprache, existieren, die in anderen Bereichen wie z. B. bei juristischen, politischen und administrativen Texten eingesetzt werden (\citealt{Hansen-SchirraGutermuth2018}). Die Einfache bzw. Leichte Sprache ist im Kern KS, die anhand von Regeln fachsprachliche Inhalte mit dem Ziel steuern, ihre Komplexität für Menschen mit geringer Sprachkompetenz oder kognitiven Einschränkungen zu reduzieren und somit ihre Verständlichkeit zu erhöhen.\footnote{Eine ausführliche Darstellung der kontrollierten Sprachvarietäten, die Einfache und Leichte Sprache, ist u. a. im Duden der Leichten Sprache von \citet{BredelMaaß2016} zu finden. Ihre Regeln, die vom „Netzwerk Leichte Sprache“ entworfen wurden, sind unter \url{http://www.bmas.de/SharedDocs/Downloads/DE/PDF-Publikationen/a752-ratgeber-leichte-sprache.pdf?blob=publicationFile\& v=2   verfügbar.}}  Diese Varietäten der KS haben im Zuge der geänderten Rechtslage zur Barrierefreiheit und Inklusion in den letzten Jahren vermehrt an Aufmerksamkeit gewonnen. (ebd.) Die vorliegende Arbeit beschäftigt sich jedoch mit dem herkömmlichen Einsatzbereich der KS, der technischen Dokumentation, daher werden die genauen Ziele der KS im Hinblick auf die technische Kommunikation im folgenden Abschnitt detaillierter beleuchtet.

\subsection{Ziele der Kontrollierten Sprache}
\label{sec:2.1.2}
Die Komplexität der natürlichen Sprachen war das Motiv hinter der Entstehung der Kontrollierten Sprachen. Im Bereich der technischen Kommunikation kommt hinzu, dass die technische Dokumentation ein hohes Maß an Verständlichkeit fordert, das sich durch eine natürliche Sprache schwer realisieren lässt. Mithilfe der Kontrollierten Sprachen will man der \textit{Mehrdeutigkeit bzw. Ambiguität} sowohl auf lexikalischer als auch auf syntaktischer Ebene \textit{entgegenwirken}. Konkret werden die Kontrollierten Sprachen eingesetzt, um die herkömmlichen Verständlichkeitshindernisse zu bewältigen, die Glasenapp schon 1972 im Zusammenhang mit „Caterpillar Fundamental English“ nannte (\citealt{Lehrndorfer1996a}: 40f.):

\begin{itemize}
\item Lange bzw. verschachtelte Sätze

\item Häufung von Nominalphrasen bzw. Aneinanderreihung von Adjektiven in einem Satz

\item Unterschiedliche bzw. inkonsistente Satzstrukturen

\item Komplexe und zusammengesetzte Zeitformen sowie unregelmäßige Verben

\item Inkonsequente Nomenklatur

\item Verkürzungen, Ellipsen und Kontraktionen

\item Inkonsequente oder falsche Zeichensetzung

\end{itemize}

Neben der \textit{Verständlichkeit} ist der Gebrauch der KS eine Möglichkeit, „gute \textit{Übersetzbarkeit} von technischer Dokumentation sicherzustellen“ \citep[339]{Lehrndorfer1996b}. Die Verständlichkeit und Übersetzbarkeit waren bereits die angestrebten Ziele von Caterpillar, die ersten Kontrollierten Sprachen (CFE bzw. CTE) zu entwickeln (Detail unter \sectref{sec:2.2}). Auch wenn die Anzahl der Regeln, die in einer KS gezielt für die Übersetzbarkeit bestimmt sind, limitiert sein kann, dient die Überwindung der obengenannten Verständlichkeitshindernisse und die Reduzierung der Ambiguität im Allgemeinen durch die KS nicht nur der Verständlichkeit, sondern auch indirekt der Übersetzbarkeit (vgl. \citealt{FiedererO’Brien2009}: 53).


Eine \textit{prägnante verständliche Satzstruktur} lässt sich vom Humanübersetzer\linebreak schneller übersetzen; dementsprechend sinken die Übersetzungskosten (\citealt{NybergEtAl2003}: 248; \citealt{Göpferich2007b}: 485; \citealt{Göpferich2008}: 366f.; \citealt{LehrndorferReuther2008}: 110f.; \citealt{DrewerZiegler2014}: 208). Ebenfalls zeigen vorherige Studien, dass eine einfache Satzstruktur sich von den MÜ-Systemen besser analysieren bzw. weiterverarbeiten lässt; entsprechend sinkt die Fehlerquote im MÜ-Output und die Notwendigkeit des Post-Editing wird minimiert (\citealt{NybergEtAl2003}: 248; \citealt{Göpferich2007b}: 481, 485; \citealt{Göpferich2008}: 366f.; \citealt{LehrndorferReuther2008}: 110f.). Diese Studien beziehen sich auf MÜ-Systeme der früheren Ansätze (RBMÜ, SMÜ, PBMÜ und HMÜ). Die vorliegende Studie untersucht, ob und inwiefern ein ähnlicher Effekt verschiedener KS-Regeln nach der Entwicklung des jüngsten MÜ\nobreakdash-An\-sa\-tzes der NMÜ nachweisbar ist. Darüber hinaus sorgt die Standardisierung für eine hohe \textit{Konsistenz}. Mit dem massiven Wachstum des Volumens der technischen Dokumentation und dem steigenden Bedarf an Übersetzungen in mehrere Sprachen spielt die Konsistenz eine Schlüsselrolle bei der Textproduktion und Übersetzung. Insbesondere beim Einsatz von Authoring-Memory-Systemen und Translation-Memory-Systemen\footnote{\textrm{Während Translation-Memory-Systeme (TMS) für die Erstellung des Zieltexts im Übersetzungsprozess verwendet werden, kommen Authoring-Memory-Systeme (AMS) bei der Erstellung des Ausgangstexts zum Einsatz. Ein AMS speichert die Textsegmente des Ausgangstexts ab und stellt sie zur Wiederverwendung bei der Erstellung neuer Texte zur Verfügung. (\citealt{DrewerSchmitz2017}: 196)} } oder MÜ-Systemen führt die hohe Konsistenz zu einer deutlich effizienteren Textproduktion bzw. Übersetzung (\citealt{DrewerZiegler2014}: 206).

Je nachdem welches Ziel der Einsatz der KS verfolgt, wurde über die letzten 20 Jahre zwischen zwei Typen der Kontrollierten Sprachen unterschieden: den Menschenorientierten und den Maschinenorientierten Kontrollierten Sprachen \citep{Huijsen1998}. Die \textit{Menschenorientierten} Kontrollierten Sprachen (HOCL)\footnote{{{{Die gängige englische Abkürzung für „Human-oriented Controlled Language“.}}}} zielen auf eine hohe Lesbarkeit und Verständlichkeit durch Regeln wie „Formulieren Sie keine Sätze mit mehr als 20 Wörtern.“, „Formulieren Sie eine Idee pro Satz.“ ab. Auf der anderen Seite versuchen die \textit{Maschinenorientierten} Kontrollierten Sprachen (MOCL),\footnote{{{{Die gängige englische Abkürzung für „Machine-oriented Controlled Language“.}}}} die Verarbeitung der Natürlichen Sprache (Natural Language Processing) in Anwendungen wie der Maschinellen Übersetzung (MÜ) zu unterstützen (vgl. \citealt{Huijsen1998}; \citealt{NybergEtAl2003}: 247). \citet[13f.]{Lehrndorfer1996a} bezeichnet diesen Typ als den \textit{Maschineneffizienten Ansatz}, der die MÜ oder andere automatische Verarbeitung von technischen Dokumentationen an Effizienz gewinnen lasse. Beispiele für Regeln der MOCL sind (\citealt{tekom2013}: 137) „Artikel verwenden“ und „Einen Satz nicht durch eine Liste unterbrechen“. Eine gewisse Überschneidung der Regeln beider Typen ist sicherlich vorhanden. Regeln, die die Anzahl der Wörter pro Satz z.~B. auf 20 Wörter limitieren oder für eine einfache Struktur sorgen, sind für beide Typen relevant.

\subsection{Aufbau einer Kontrollierten Sprache}
\label{sec:2.1.3}
Der Aufbau einer KS erfolgt nach einem der folgenden Ansätze (\citealt{Reuther2007}; \citealt{LehrndorferReuther2008}: 107): dem Präskriptiven Ansatz oder dem Proskriptiven Ansatz. Gleichzeitig findet man in der Praxis eine Mischung aus beiden im Einsatz (\citealt{LehrndorferReuther2008}: 108).

Bei dem \textit{Präskriptiven Ansatz} werden Positivregeln mit allen zulässigen grammatischen Strukturen und der zulässigen Lexik vorgegeben (ebd.: 107). Formuliert der Textproduzent einen Satz, der nicht den vorgegebenen Strukturen entspricht oder ein unzulässiges Wort enthält, wird dieser Satz (meistens von einem CL-Checker, siehe \sectref{sec:2.5}) markiert. Für den Textproduzenten bedeutet dies, dass jede nicht vorgegebene Struktur bzw. jedes nicht vorgegebene Wort nicht verwendet werden darf. Demzufolge hängt der Einschränkungsgrad beim Schreiben vom Umfang der Positivregeln ab. Im Gegensatz dazu werden bei dem \textit{Proskriptiven Ansatz} Negativregeln mit allen unzulässigen grammatischen Strukturen und Wörtern festgelegt (ebd.). Alle grammatischen Strukturen und Wörter außerhalb dieser Negativregeln sind zulässig. Es besteht somit die Gefahr, dass ein falsches Wort oder eine nicht ideale Struktur ungeprüft bleibt, wenn dies nicht in einer der Negativregeln miteinbezogen wurde. Dementsprechend hängt hierbei der Effizienzgrad vom Umfang der Negativregeln ab.

Nach diesem Vergleich wird deutlicher, dass -- obwohl beide Ansätze zu ähnlichen Ergebnissen führen -- jeder Ansatz seine Vor- und Nachteile hat (\citealt{Reuther2007}; \citealt{LehrndorferReuther2008}: 107f.): Der Effizienz- und Konsistenzgrad des präskriptiven Ansatzes ist höher, dennoch hat er die Nachteile eines hohen Lern- bzw. Schulungsaufwands und entsprechend niedrigerer Akzeptanz sowie unspezifischer Fehlererläuterung. Auf der anderen Seite verwandelt der proskriptive Ansatz die Nachteile des präskriptiven Ansatzes in Vorteile, indem er den Autoren spezifische Fehlererläuterung sowie größere Formulierungsfreiheit bietet und somit auf höhere Akzeptanz stößt. Zugleich ist die Textvarianz des proskriptiven Ansatzes höher und somit zeigt er sich weniger effizient.

In der vorliegenden Studie werden Regeln aus der Leitlinie „Regelbasiertes Schreiben, Deutsch für die Technische Kommunikation“ des \citet{tekom2013} untersucht. Die tekom-Leitlinie umfasst eine Mischung aus 167 Positiv- und Negativregeln (ebd.), die dem technischen Redakteur jeweils mit einer Entscheidungshilfe zur Verfügung gestellt werden (mehr dazu unter \sectref{sec:2.3}).

\section{\label{sec:2.2}Entwicklung der Kontrollierten Sprache}

In ihrer Forschungsarbeit „The Meaning of Meaning“ ermittelten \citet{RichardsOgden1989} eine begrenzte Anzahl von Wörtern, die in Wortdefinitionen ständig wiederkehren. Auf Basis dieser Ergebnisse entwickelte \citet{Ogden1935} in den 30er Jahren die erste Kontrollierte Sprache „BASIC English“ (British, American, Scientific, International, Commercial), die aus 850 Wörtern und eingeschränkter Grammatik bestand. Hauptziel damals war, weltweit so vielen Nicht-Eng\-lisch\-mut\-ter\-sprach\-lern wie möglich zu ermöglichen, Englisch in kürzester Zeit zu lernen und zu benutzen \citep{Schwitter2007}.

Aufbauend auf dem BASIC English wurde ca. 40 Jahre später (1972) im Bereich der technischen Kommunikation die erste firmeninterne KS in Caterpillar Inc. (1974) „Caterpillar Fundamental English“ (CFE) entworfen. Die Grundidee bestand darin, dass einerseits stark vereinfachtes Englisch in kurzer Zeit von Englisch-Nicht-Muttersprachlern erlernt und verstanden werden kann und andererseits zusammen mit dem Einsatz vieler Abbildungen Textproduktion und Übersetzungskosten eingespart werden (\citealt{DrewerZiegler2014}: 212). Jedoch stieß das CFE auf Probleme (ebd.), wie die hohe Textkomplexität, die mit einer nur auf 850 Wörter begrenzten KS schwer zu handhaben ist. Dies und die mangelnde Mitarbeiterschulung für die Umsetzung des CFE waren mit einer steigenden Ablehnung der CFE durch die Autoren gekoppelt (ebd.). Demzufolge war die Textqualität so niedrig, dass die Lesbarkeit der Dokumentation darunter litt \citep{KamprathEtAl1998}. Angesichts dieser Schwierigkeiten in Zusammenhang mit den wachsenden Märkten von Caterpillar war es unmöglich, alle Märkte mit einer vereinfachten Sprache zu bedienen (ebd.). Daraufhin wurde Mitte der 80er Jahre das CFE zu CTE „Caterpillar Technical English“ weiterentwickelt (ebd.). Im Fokus des CTE standen eine hohe Textqualität sowie die Erhöhung der Übersetzungsqualität und Reduzierung der Übersetzungskosten (ebd.). Dies sollte damals durch einen höheren Automatisierungsgrad – dank der damaligen schnellen Entwicklung von Soft- und Hardware – erreicht werden (\citealt{DrewerZiegler2014}: 212). Außerdem bestand der Wortschatz des CTE aus ca. 70.000 Wörtern, davon waren mehrere zehntausend Fachtermini (ebd.: 212f.). Zudem war Caterpillar bestrebt den Autoren große Freiheit beim Schreiben zu bieten (ebd.: 213). In der Tat ermöglichte die KS (CTE) Caterpillar Anfang der 90er Jahren sein Textproduktionsvolumen an technischen Dokumentationen erheblich zu steigern und in mehr als 30 Sprachen zu übersetzen (ebd.: 212).

\largerpage
Angesichts dieses Erfolgs begannen in den folgenden Jahren weitere Organisationen firmen- und branchenspezifische KS zu entwickeln, die ihre spezifischen Bedürfnisse berücksichtigen (vgl. \citealt{Schwanke1991}: 42), wie z.~B. das „NCR Fundamental English“, das „Plain English Program“ (PEP), die „International Language for Servicing and Maintenance“ (ILSAM) und das „Perkins Approved Clear English“ (\citealt{DouglasHurst1996}: 93), die auf Basis der CFE entwickelt wurden \citep[42]{Schwanke1991}. ILSAM wiederum war die Basis für die Entwicklung des „Simplified Englisch“ der AECMA, einer stark kontrollierten Sprache des Englischen, die im Flugzeugwartungsbereich sehr breite Anwendung fand \citep[370]{Göpferich2008}. Darüber hinaus fand die KS Anklang bei multinationalen Konzernen, wie Kodak (Kodak International Service Language), Xerox (Xerox Multilingual Customized English), Sun (Sun Controlled English), Attempto (Attempto Controlled English), Ericsson (Ericsson English), Nortel (Nortel Standard English) und KANT (KANT Controlled English) (\citealt{DrewerZiegler2014}: 211).

Nicht nur im Englischen, auch in anderen Sprachen erschienen in den 90er Jahren Kontrollierte Sprachen, z.~B. (ebd.) für Französisch das „Français Rationalisé“, für Spanisch das „Simplified Technical Spanish“ (STS), für Schwedisch das „Scania Swedish“, für Chinesisch das „Controlled Chinese“ und für Japanisch das „Plain Japanese“. Ebenfalls existieren für die deutsche Sprache einige Regulierungsansätze. Da ausgewählte KS-Regeln der deutschen Sprache der Untersuchungsgegenstand dieser Studie sind, wird das Kontrollierte Deutsch im Folgenden näher betrachtet.

\section{\label{sec:2.3}Kontrolliertes Deutsch}

Wie die Definition der Kontrollierten Sprache (KS) (unter \sectref{sec:2.1.1}) darlegt, besteht eine vollständige KS aus einem „Regelwerk mit festen Schreibregeln (v.~a. Vorgaben zur Formulierung von Sätzen) sowie vorgegebene[m] Wortschatz aus Basiswortschatz und Fachwortschatz in Form eines Lexikons“ (\citealt{DrewerZiegler2014}: 192). Für die deutsche Sprache existieren einige Ansätze zur Sprachregulierung sowohl im akademischen Bereich als auch in der Industrie. Diese Ansätze basieren jedoch auf Regelwerken ohne vorgegebene Lexika und somit sind sie nach der Standarddefinition der KS nicht als konventionelle vollständige KS zu betrachten. Dies stellt einen wesentlichen Unterschied zwischen englischen KS und dem Kontrollierten Deutsch dar, der auf die folgenden Gründe zurückgeführt wird: Englisch ist die größte Geschäfts- und Forschungssprache. Es ist unbestritten, dass die Anzahl der Englisch-Nicht-Muttersprachler, die leicht erlernbares und verständliches Englisch in ihrem Alltag benötigen, sehr groß ist. Dies ist absolut nicht der Fall bei der deutschen Sprache. Unabhängig von der Anzahl der Muttersprachler zeigt eine Statistik des Instituts SIL International aus dem Jahr 2019, dass Englisch von 753 Mio. Personen, gefolgt vom Chinesischen auf Platz zwei von 199 Mio. und vom Deutschen auf Platz 13 mit nur 38 Mio., als Zweitsprache gesprochen bzw. als erste Fremdsprache gelernt wird.\footnote{\url{https://de.wikipedia.org/wiki/Liste\_der\_meistgesprochenen\_Sprachen} [abgerufen am 03.08.2019]} Dementsprechend ist der fehlende Bedarf einer der primären Gründe, warum bisher keine vollständige deutsche KS existiert (ebd.: 216). Der zweite Grund ist linguistischer Natur: Die deutsche Sprache ist im Vergleich zu der englischen Sprache im Hinblick auf den Satzbau sowie die zahlreichen Flexions- und Wortbildungsmorpheme viel komplexer (\citealt{LehrndorferReuther2008}: 106). Diese Eigenschaften machen die deutsche Sprache schwer regulierbar. Vor diesem Hintergrund haben in der Regel die kontrollierten Varianten der deutschen Sprache die Verbesserung der Verständlichkeit und Konsistenz als Hauptziel (\citealt{DrewerZiegler2014}: 217). Dieses Ziel wird angesichts der Komplexität der Sprache durch grammatische und syntaktische Regeln zusammen mit terminologischen Vorgaben ohne die Festlegung eines kontrollierten Lexikons erreicht (ebd.). Hier wirft sich die Frage auf, ob die Festlegung eines Lexikons nicht erforderlich ist.

Zu den bekanntesten Ansätzen der deutschen KS zählt im akademischen\linebreak Bereich die Dissertation von \citet{Lehrndorfer1996a} mit dem Titel „Kontrolliertes Deutsch“. In ihrer Arbeit geht Lehrndorfer auf die Frage der Notwendigkeit eines Lexikons ein. Sie berücksichtigte die Schwierigkeiten, die mit einer lexikalischen Kontrolle verbunden sind, wie die schwere Lernbarkeit von umfangreichen Lexika, die fehlende Ausdruckmöglichkeit und die inhaltliche Fixierung auf vorgegebene Themenbereiche (ebd.: 139), die wiederum zur geringen Akzeptanz unter den Redakteuren beitragen (ebd.: 137). Demzufolge befürwortet Lehrndorfer, den Fokus bei der Sprachkontrolle eher auf die syntaktische Ebene zu verlagern, wobei das Lexikon durch die kontrollierte Syntax indirekt kontrolliert wird, z.~B. durch Regeln wie das Vermeiden von Partizipialkonstruktionen und Funktionsverbgefügen (ebd.: 138).

Mit dem Kontrollierten Deutsch verfolgt Lehrndorfer zwei Ziele (\citealt{DrewerZiegler2014}: 216): (1) die Verbesserung der Lesbarkeit, wobei die Zielgruppe Muttersprachler des Deutschen sind; anders als in der englischen Kontrollierten Sprache, für die  Nicht-Muttersprachler die Zielgruppe bilden, und (2) die Verbesserung des Outputs der MÜ. In ihrer Studie wird das Transfer-MÜ-System METAL der Firma Siemens in Kombination mit kontrolliertem Deutsch verwendet. Nach \citet[155]{Lehrndorfer1996a} erfolgt die Sprachkontrolle des Ausgangstexts zunächst durch die Unterscheidung des Redakteurs zwischen drei Aussageabsichten: Handlungsanweisung, Sicherheitshinweis und Aussage zum Produkt (z.~B. Produktbeschreibung). Der deutsche Text wird dann auf Konformität mit den KS-Regeln mithilfe der CL-Checker-Funktion\footnote{{{{Detail zu CL-Checkern unter \sectref{sec:2.5}.}}}} des MÜ-Systems METAL geprüft und anschließend mit dem System übersetzt.

In der Industrie ist das „Siemens-Dokumentationsdeutsch“ (SDD) das erste firmenspezifische Kontrollierte Deutsch \citep[375]{Göpferich2008}. Das SDD besteht aus Regeln zur Regulierung grammatischer Konstruktionen sowie linguistischer Eigenschaften wie z.~B. der syntaktischen Ambiguität \citep{Rascu2006}. Das primäre Ziel der Entwicklung des SDD war nicht die Optimierung der Verständlichkeit durch die Erstellung einfacher Texte -- wie der Fall bei der englischen KS (z.~B. Caterpillars CFE) --, sondern die Steigerung der maschinellen Übersetzbarkeit mit dem MÜ-System TopTrans von Siemens (\citealt{LehrndorferSchachtl1998}). Im Übersetzungsprozess prüft TopTrans zunächst, ob die Regeln im Ausgangstext eingehalten wurden (ebd.). Verstöße werden für den Redakteur markiert, damit er sie mit einer interaktiven Unterstützung vom System behebt (Pre-Editing). Nach Abschluss des Pre-Editing wird der Text von TopTrans übersetzt. Auf diese Weise war in der Regel kein Post-Editing mehr erforderlich (ebd.). Dennoch ist das SDD -- im Gegensatz z. B. zum Simplified English der AECMA -- als eine firmenspezifische Kontrollierte Sprache geblieben und hat sich nicht zu einem Branchenstandard entwickelt \citep[375]{Göpferich2008}. Siemens verfasst weiterhin seine Dokumentationen in Dokumentationsdeutsch, allerdings sind keine aktuellen Veröffentlichungen zu finden, die zeigen würden, wie sich das SDD in den letzten Jahren entwickelt hat. Nicht nur Siemens, sondern auch weitere deutsche Großunternehmen überlassen ihren öffentlichen Auftritt nicht allein dem Geschick der Mitarbeiter (vgl. \citealt{BaumertVerhein-Jarren2012}: 153); sie verfassen ihre Dokumentation nach festgelegten Regeln bzw. bestimmten Regelwerken, jedoch erfolgen dazu aus Datenschutz- und Konkurrenzgründen keine Veröffentlichungen.

Ein weiterer praxisbezogener Ansatz zur Steuerung der deutschen Sprache wurde von der tekom Deutschland~e.~V.\footnote{{{{\url{https://www.tekom.de}}}}} in Form einer branchenübergreifenden Leitlinie für die technische Dokumentation entwickelt. Die Regeln, die im Rahmen der vorliegenden Studie analysiert wurden, stammen aus der tekom-Leitlinie,\footnote{{{{Die Verwendung der tekom-Leitlinie sowie die Auswahl der analysierten Regeln sind unter \sectref{sec:4.4.2.1} begründet.}}}} daher wird diese im folgenden Abschnitt genauer betrachtet.

\subsection{Die tekom-Leitlinie}%eventuell subsubsesction verwenden

Als praxisnaher Ansatz entwickelte die Gesellschaft für Technische Kommunikation -- \citet{tekom2013} die Leitlinie „Regelbasiertes Schreiben, Deutsch für die Technische Kommunikation“. Anders als eine KS, stellt die Leitlinie einen branchenübergreifenden Standard für die technische Dokumentation mit einer umfangreichen Regelsammlung ohne vorgegebene kontrollierte Lexika dar. Die enthaltenen Regeln kann das Unternehmen u. a. je nach Branche, Zielgruppe und Informationsart an seinen unternehmensspezifischen Bedarf anpassen (\citealt{BaumertVerhein-Jarren2012}: 152). Bei der tekom-Leitlinie steht die Steigerung der Qualität und die Reduzierung der Kosten im Dokumentations- und Übersetzungsprozess im Mittelpunkt (\citealt{DrewerZiegler2014}: 217f.). Konkret richtete die tekom-Arbeitsgruppe ihr Augenmerk bei der Erstellung der Leitlinie auf fünf Nutzenziele: Verständlichkeit, Wiederverwendbarkeit, Konsistenz, übersetzungsgerechtes Schreiben und Überprüfbarkeit (\citealt{tekom2013}: 9).

Mittlerweile sind die Leitregeln der tekom sowohl in der Forschung als auch in der Industrie weitestgehend etabliert.\footnote{Die Tekom-Regeln sind der Kernregelsatz in zwei marktführenden CL-Checkern Acrolinx (\url{https://www.acrolinx.de /produktuberblick/}) und CLAT (vgl. \citealt{Geldbach2009}). Mehr zum CLAT und seiner Entwicklung unter \sectref{sec:2.5}.} Dank einer engen Zusammenarbeit zwischen Experten von Hochschulen, der Industrie, Dienstleistungsunternehmen sowie Softwarefirmen bieten die tekom-Regeln ein umfassendes Regelwerk auf sämtlichen Sprach- und Dokumentationsebenen (siehe \tabref{tab:02:1} ). Aus diesen Gründen stammen die KS-Regeln, die im Rahmen der vorliegenden Arbeit analysiert wurden, aus der tekom-Leitlinie 2013. Im \sectref{sec:4.4.2} werden die in der vorliegenden Studie analysierten Regeln detailliert präsentiert und ihre Auswahl begründet. Im Folgenden werden die Entwicklung sowie der Aufbau der tekom-Leitlinie näher aufgegriffen.

Der ursprüngliche Arbeitskreis für die Erstellung der Leitlinie strebte einen funktionsorientierten Textaufbau, stilistische Vorgaben auf Satzebene sowie terminologische Vorgaben an (\citealt{DrewerZiegler2014}: 218). Die Leitlinie sollte Regeln zur Benennungsbildung, d. h. Festlegung von Benennungen für neue Begriffe (vgl. \citealt{DrewerSchmitz2017}: 70ff), sowie ein Lexikon mit branchenübergreifendem Vokabular beinhalten (\citealt{DrewerZiegler2014}: 218). Die Festlegung von Regeln zur Benennungsbildung ist keine Neuheit, hingegen würde die Entwicklung eines Lexikons mit branchenübergreifendem Vokabular zu einer traditionellen KS führen. Nach einem Jahr wurde aus dem Arbeitskreis eine tekom-Arbeitsgruppe gegründet, die die Arbeit an den Regeln fortgesetzt hat. (ebd.)

Im Jahr 2011 wurde die erste Auflage der Leitlinie von der Arbeitsgruppe „Technisches Deutsch“ entworfen (\citealt{tekom2013}: 13). Die Regeln sollten eine „Leitlinie für professionelles Deutsch in der Technischen Kommunikation“ bilden (\citealt{DrewerZiegler2014}: 218). Inhalt der „Leitlinie Technisches Deutsch“ war ein „Regelsatz, der z. B. Vorschriften zur Verwendung bestimmter Wortformen, zur Wortbildung, zum Satzbau, zur Bildung von Abkürzungen, zur Zeichensetzung, [sic] sowie Regeln zur Festlegung von Benennungen“ umfasste (\citealt{tekom2009}). Wie der Inhalt zeigt, liegt der Fokus auf dem Satzbau und der Terminologie, nicht auf der Etablierung eines vollständigen Vokabulars. Somit bietet die tekom-Leitlinie eine Sammlung von Schreib- und Stilregeln und keine klassische KS (\citealt{DrewerZiegler2014}: 218).

Im Sommer 2010 führte die Arbeitsgruppe einen Beta-Test durch, um die Anwendbarkeit und den Praxisbezug der Leitlinie vor der Veröffentlichung zu prüfen. 39 Tester (Anfänger, Fortgeschrittene und Experten) haben die Leitlinie bewertet und die Ergebnisse flossen bei der Entwicklung der ersten Auflage ein (\citealt{Fleurynodate}).\footnote{{{{Angaben von \citet{Fleurynodate} tekom-Vorstandspatin der Arbeitsgruppe.}}}} Daraufhin erschien die erste Auflage der Leitlinie 2011 und zwei Jahre später wurde die zweite Auflage veröffentlicht (2013). In der Leitlinie werden die Regeln wie folgt dargestellt:

\begin{itemize}
\item Regelnummer: besteht aus einem Buchstaben und einer dreistelligen Zahl

\item Regelüberschrift

\item Regelbeschreibung

\item Handlungsanweisungen: zeigen, wie die Regel umgesetzt werden kann zusammen mit Tipps für die Umsetzung

\item Negative und positive Beispiele für die Umsetzung der Regel tabellarisch dargestellt

\item Entscheidungshilfe: erklärt, wann der Einsatz der Regel empfohlen ist und zeigt Alternative auf

\item Maschinelle Prüfbarkeit: gibt an, ob das Einhalten der Regel maschinell (d.\,h. mithilfe von Controlled-Language-Checkern) geprüft werden kann

\end{itemize}

Die zweite Auflage ist wie folgt aufgebaut \citep{tekom2013}:

\begin{table}
\setlength{\tabcolsep}{2pt}
\small
\begin{tabularx}{\textwidth}{rrQlQ}
\lsptoprule
\textbf{Anzahl} &  \multicolumn{2}{l}{\textbf{Regelebene / Kategorie}} & \multicolumn{2}{l}{\textbf{Beispiel}}\\
\cmidrule(lr){2-3}
&   & \textbf{Unterebene / Unterkategorie} & & \\
\midrule
 \textbf{40} & \textbf{1.} & {\textbf{Regeln auf Textebene}} & &\\
 29 &  &  Dokumentstruktur & T 105  & Redundanzen in Überschriften vermeiden\\
 \tablevspace
 11 &  & Informationsstruktur & S 306  & Aufzählungen als Liste darstellen\\
 \midrule
  \textbf{41} &\textbf{2.} & {\textbf{Regeln auf Satzebene}} & &\\
 7 &  &  Vermeidung von mehrdeutigen Konstruktionen & S 102 &  Eindeutige pronominale Bezüge verwenden \\
  \tablevspace
 4 &   & Vermeidung von unvollständigen Konstruktionen & S 204  & Keine Wortteile weglassen\\
 \tablevspace
 13 &   & Vermeidung von komplexen Konstruktionen & S 303 &  Partizipialkonstruktionen vermeiden\\
  \tablevspace
 2 &   & Wortstellung und Abfolge von Satzelementen & S 402 &  Eingeschobene Nebensätze vermeiden\\
 \tablevspace
 15 &  & Stilistische Regeln & S 501 &  Vorgangspassiv vermeiden\\
\midrule
\textbf{50} & \textbf{3.} & {\textbf{Regeln auf Wortebene}} & & \\
28 & & Wortbildung & B 108 &  Komposita mit Ziffern immer mit Bindestrich\\
\tablevspace
3 & & Abkürzung & B 203 &  Abkürzungsschreibweisen festlegen\\
\tablevspace
4 & & Verwendung von Benennungen und Zahlen & B 302a &  Zahlen von 1 bis 12 in Ziffern schreiben\\
\tablevspace
14 & & Lexikalische Vorgaben & L 103  & Funktionsverbgefüge vermeiden\\
\midrule
\textbf{1} & \textbf{4.} & {\textbf{Rechtschreibung} } & R 101 &  Einheitlichen Rechtsschreibstil verwenden\\
\midrule
\textbf{21} & \textbf{5.} & {\textbf{Zeichensetzung}} & Z 103b &  Für zitierte Oberflächentexte gerade Anführungszeichen $"$\ldots$"$ verwenden\\
\midrule
\textbf{6} & \textbf{6.} & {\textbf{Platzsparendes Schreiben}} & P 104 &  Wörter konsistent und nachvollziehbar kürzen\\
\midrule
\textbf{8} & \textbf{7.} & {\textbf{Übersetzungsgerechtes Schreiben}} & Ü 103  & Sinneinheiten mit einem Punkt oder Absatzwechsel abschließen\\
\lspbottomrule
\end{tabularx}
\caption{\label{tab:02:1}Übersicht des Aufbaus der tekom-Regeln. Quelle: \citealt{tekom2013}}
\end{table}



Wie \tabref{tab:02:1}  zeigt, deckt die tekom-Leitlinie mit insgesamt 167 Regeln sämtliche Sprach- und Dokumentebenen in der technischen Dokumentation umfassend ab \citep{tekom2013}. Aus diesen Regeln kann das Unternehmen individuell auswählen und somit seine Unternehmenssprache (Corporate Language) auf eine Weise gestalten, die es ihm ermöglicht, seine Unternehmensidentität (Corporate Identity) auszudrücken. So können Unternehmen derselben Branche Ihre Dokumentation nach unterschiedlichen Regeln erstellen und dabei einen unterschiedlichen Grad an Kundenorientierung (z.~B. Wert auf Kundenzufriedenheit) zum Ausdruck bringen.

Einer Ablehnung seitens der technischen Redakteure wird z. B. mittels der Bereitstellung von einer Entscheidungshilfe bei jeder Regel entgegengewirkt. Beispielsweise erklären die Entscheidungshilfen bei den Regeln zur Vermeidung vom Passiv, dass die Verwendung vom Passiv sinnvoll sein kann, „wenn der Handelnde nicht bekannt ist oder bewusst nicht genannt werden soll“ (\citealt{tekom2013}: 80). Auf der anderen Seite empfiehlt die Entscheidungshilfe die Verwendung des Aktivs z.~B. bei der Formulierung von handlungsorientierten Informationseinheiten, da das Aktiv verdeutlicht, „wer eine Handlung ausführt oder ausführen soll [\ldots] und motiviert den Leser die Anleitung zu befolgen“ \citep[81]{tekom2013}.

Die Parallelen zwischen dem Kontrollierten Deutsch von \citet{Lehrndorfer1996a} und der tekom-Leitlinie 2013 lassen sich deutlich erkennen: Beide Werke bestehen aus Regelsätzen und umfassen kein Lexikon. Das bietet insbesondere für eine Sprache mit reicher Morphologie wie Deutsch einen guten Ausweg aus der Problematik der geringen Akzeptanz bzw. der psychischen Abneigung der KS durch die Textproduzenten (vgl. \citealt{NybergEtAl2003}: 249; \citealt{DrewerZiegler2014}: 209) an. Diese Problematik wird bekanntlich oft in Zusammenhang mit der englischen KS genannt, da das Beachten eines Lexikons einschränkend ist, viel Vorsicht beim Schreiben erfordert und das Schreiben (zumindest in der Anfangsphase der Arbeit mit der KS) verlangsamen kann.

Hinsichtlich der (maschinellen) Übersetzbarkeit ist anschließend Folgendes anzumerken: Obwohl auf den ersten Blick in \tabref{tab:02:1}  nur Kategorie 7 „Übersetzungsgerechtes Schreiben“ mit acht Regeln gesondert für die Übersetzbarkeit zu sehen ist, zeigen weitere Regeln eine Wirkung auf die (maschinelle) Übersetzbarkeit. Diese Wirkung wurde von weiteren zitierten Studien (vgl. \citealt{BernthGdaniec2001}; \citealt{Reuther2003}; \citealt{Siegel2011}; \citealt{Congree2018}) in Zusammenhang mit den früheren MÜ-Ansätzen untersucht (siehe Überblick in \sectref{sec:4.4.2.2}). Die Grundidee bei diesen Studien ist, dass die KS im Allgemeinen die Ambiguität und die Satzkomplexität reduziert sowie die Satzstruktur vereinfacht; und auf diesem Wege indirekt zur Verbesserung der (maschinellen) Übersetzbarkeit beiträgt.

Nach dieser Darstellung des Kontrollierten Deutsch und seiner Besonderheiten sollen im Folgenden die Stärken und Schwächen der KS aus unterschiedlichen Perspektiven näher beleuchtet werden.\footnote{{{{Das Institut für technische Literatur (itl AG) bietet in einem aktuellen Leitfaden (Stand: November 2019) eine Übersicht der 14 wichtigsten Normen und Richtlinien für die technische Dokumentation, darunter die hier präsentierte Leitlinie der tekom. In dem Leitfaden werden die Normen zusammengefasst und kommentiert. Außerdem wird erläutert, warum sie wichtig sind. Näheres dazu unter: \url{https://www.itl.eu/de/nachrichten/details/der-itl-normenguide.html}.}}}}


\section{\label{sec:2.4}Stärken und Schwächen der Kontrollierten Sprache}

Der Einsatz der KS ist mit vielen Stärken verbunden, gleichzeitig dürfen ihre Schwächen nicht außer Acht gelassen werden. Je nachdem in welchem Umfang die KS eingesetzt wird, angefangen beim Einsatz einer vollständigen KS bis zum Einsatz einer Redaktionsleitlinie, können einige Stärken bzw. Schwächen entfallen bzw. in ihrer Gewichtung variieren. Im Folgenden werden die Stärken und Schwächen nach den vier Stakeholdern, also dem Unternehmen, dem Redakteur, dem Übersetzer und dem Rezipienten gegenübergestellt und erörtert:

\subsection{Für die Unternehmen}

Erstens bildet das Unternehmen durch das Einhalten von vordefinierten lexikalischen, syntaktischen und stilistischen Regeln eine Unternehmenssprache (Corporate Language), die einen Bestandteil seiner Unternehmensidentität (Corporate Identity) darstellt (vgl. \citealt{LehrndorferReuther2008}: 111; \citealt{DrewerZiegler2014}: 206). Zweitens erhöhen die Lesbarkeit und Verständlichkeit – als Teil der Hauptziele der KS – (vgl. \citealt{NybergEtAl2003}: 248; \citealt{LehrndorferReuther2008}: 110) die Kundenzufriedenheit und verringern gleichzeitig die Haftungsansprüche (\citealt{DrewerZiegler2014}: 206). Drittens verbessert der Einsatz einer KS die Qualität der Dokumentation und beschleunigt ihre Übersetzung (\citealt{NybergEtAl2003}: 255). Dies reduziert die Übersetzungskosten, ermöglicht den Unternehmen fremdsprachige Handbücher schneller zu erstellen und verkürzt somit die Time-to-Market der zugehörigen Produkte. Eine kürzere Time-to-Market fördert wiederum die Konkurrenzfähigkeit des Unternehmens. (ebd.)

Gleichzeitig ist die Entwicklung und Implementierung einer KS mit Zeit- und Kostenaufwand verbunden (vgl. \citealt{NybergEtAl2003}: 249): Die KS wird entweder vom Unternehmen entwickelt, gestaltet und verwaltet oder eine vorhandene KS wird lizenziert und nach Unternehmensbedürfnissen angepasst. Die Einführung einer KS umfasst mehrere Phasen der linguistischen Analyse, den Terminologieaufbau bzw. die Entwicklung oder den Kauf eines CL-Checkers. Ferner muss die KS nach der Einführung gepflegt und kontinuierlich zusammen mit der Terminologie an die aktuellen Standards und Bedürfnisse des Unternehmens angepasst werden. (ebd.) Zudem muss die Lern- und Umgewöhnungsphase der Redakteure und die während dieser Phase ggf. noch nicht hohe Qualität in Kauf genommen werden (\citealt{DrewerZiegler2014}: 209).

\subsection{Für die Redakteure}


In der technischen Kommunikation verfassen die Redakteure viele Dokumentationen, in denen zahlreiche Sätze sich vollständig oder teilweise wiederholen; Beispiele hierfür sind Installationsanweisungen bei Software-Updates, Bedienungsanleitungen von Geräten, Montageanweisungen von Maschinen sowie Allgemeine Geschäftsbedienungen. Durch die Einhaltung von Regeln der KS -- insbesondere bei dieser Art von Dokumentationen -- wird sichergestellt, dass sowohl die verwendeten Terminologien als auch Formulierungen konsistent sind. Das wird in der Regel durch den Einsatz der KS zusammen mit der Verwendung eines Authoring-Memory-Systems\footnote{{{{Während Translation-Memory-Systeme (TMS) für die Erstellung des Zieltexts im Übersetzungsprozess verwendet werden, kommen Authoring-Memory-Systeme (AMS) bei der Erstellung des Ausgangstexts zum Einsatz. Ein AMS speichert die}}} {{{Textsegmente des Ausgangstexts ab und stellt sie zur Wiederverwendung bei der Erstellung neuer Texte zur Verfügung. (\citealt{DrewerSchmitz2017}: 196)} }}} oder CL-Checkers\footnote{{{{Ein CL-Checker (Controlled-Language-Checker) ist eine spezielle Software zur Prüfung, ob die KS-Regeln eingehalten werden. Da in der vorliegenden Studie einen CL-Checker verwendet wurde, wird die Funktionsweise dieser Software detailliert unter \sectref{sec:2.5} erläutert.}}}} realisiert. Verfasst der Redakteur mithilfe eines Authoring-Memory-Systems einen Satz, der in dem aktuellen oder einem anderen Dokument vollständig (100\%-Match) oder zum Teil (Fuzzy-Match) vorkam, zeigt das System diesen Satz an (\citealt{DrewerSchmitz2017}: 196). Der Redakteur hat dann die Möglichkeit, den angezeigten Satz zu übernehmen und ggf. anzupassen (\citealt{DrewerSchmitz2017}: 196). Diese Möglichkeit erleichtert und beschleunigt die Arbeit des Redakteurs und steigert die Qualität durch die hohe terminologische und stilistische Konsistenz (vgl. \citealt{Göpferich2008}: 367; \citealt{DrewerSchmitz2017}: 197). Diese Konsistenz ist multiplizierbar, denn sollten mehrere Redakteure an einem Dokument gleichzeitig oder an mehreren Dokumenten über einen längeren Zeitraum arbeiten, bietet die KS eine enorme Unterstützung für die sprachliche und stilistische Vereinheitlichung, die durch den Einsatz von Software sichergestellt wird (vgl. \citealt{Göpferich2008}: 367; \citealt{DrewerZiegler2014}: 235). Ferner sehen einige Autoren in der KS einen Orientierungsrahmen, der sie bei einer schnellen Entscheidung über Formulierungen unterstützt (\citealt{DrewerZiegler2014}: 207).

Auf der anderen Seite können die Textproduzenten in manchen Fällen Fachspezialisten sein, die über ein begrenztes linguistisches Wissen verfügen, z.~B. in Kleinunternehmen. Diese Gruppe von Textproduzenten kann Schwierigkeiten haben, linguistische Regeln wie\footnote{{{{Beispiele aus der \citealt{tekom2013}.}}}} „Funktionsverbgefüge vermeiden“ oder „Komposita aus vier und mehr Basismorphemen immer mit Bindestrich schreiben“ umzusetzen. Eine weitere mögliche Problematik des Einsatzes von KS besteht darin (\citealt{NybergEtAl2003}: 248), dass das Schreiben durch die Einhaltung der KS-Regeln zeitaufwendiger ausfällt, manche Sätze müssen vollständig umformuliert werden. Die Verlangsamung des Schreibprozesses kann zu einer Abneigung gegen die Verwendung der KS führen. Manche Redakteure entwickeln eine psychische Abneigung gegen die Einhaltung der KS-Regeln. Sie finden, dass die KS ihre Kreativität und Motivation hemme, da sie beim Schreiben eingeschränkt seien (vgl. \citealt{NybergEtAl2003}: 249; \citealt{LehrndorferReuther2008}: 112; \citealt{DrewerZiegler2014}: 209). Zudem müssen die Redakteure den Lernaufwand der KS-Regeln und des dafür verwendeten Tools auf sich nehmen (\citealt{DrewerZiegler2014}: 209).

\subsection{Für die Übersetzer}


Erhält der Übersetzer vom technischen Redakteur einen terminologisch und stilistisch konsistenten und eindeutig formulierten Ausgangstext, erleichtert und beschleunigt dies seine Übersetzungsaufgabe, denn die lexikalische und syntaktische Klarheit sowie die Konsistenz erhöhen die Lesbarkeit und die Verständlichkeit für den Übersetzer als Textrezipient (vgl. \citealt{NybergEtAl2003}: 248; \citealt{Göpferich2008}: 366f.; \citealt{DrewerZiegler2014}: 208). Dies wiederum ermöglicht ihm, die Übersetzung in kürzerer Zeit anzufertigen und spiegelt sich in niedrigeren Übersetzungskosten wider. Ferner werden die Vorteile der KS bei der Übersetzung maximiert, wenn das Unternehmen ein Translation-Memory-System im Einsatz hat. In einem Translation-Memory-System werden vorherige Übersetzungen gespeichert. Erkennt das System einen Ausgangssatz, der vorher im selben oder in einem anderen Dokument vollständig (100\%-Match) oder zum Teil (Fuzzy-Match) übersetzt wurde, zeigt es diesen Satz zusammen mit seiner Übersetzung an (vgl. \citealt{DrewerZiegler2014}: 208; \citealt{DrewerSchmitz2017}: 213f.). Da das Einhalten von den KS-Regeln die Konsistenz im Ausgangstext erhöht, steigen im Translation-Memory-System die Matchquoten, d. h. die Wiederverwendbarkeit von vorherigen Übersetzungen (\citealt{NybergEtAl2003}: 248; \citealt{DrewerZiegler2014}: 206). Das wiederum resultiert in einer effizienten Übersetzung (\citealt{LehrndorferReuther2008}: 111; \citealt{DrewerZiegler2014}: 206).

Im Bereich der maschinellen Übersetzung kamen vorherige Studien zu dem Ergebnis, dass ein Pre-Editing mithilfe der KS-Regeln einen positiven Einfluss auf den MÜ-Output hat, unter anderem im Sinne eines geringen Post-Editing-Aufwands und niedriger Post-Editing-Zeit (vgl. \citealt{Göpferich2007b}: 481; \citealt{Göpferich2008}: 367; \citealt{LehrndorferReuther2008}: 110). Die Hauptidee dieser Studien lautet wie folgt: Achtet der Autor bei der Textproduktion~auf Eindeutigkeit und vermeidet komplexe Satzstrukturen, können viele Fehlerquellen für die Übersetzung eliminiert werden (vgl. \citealt{Göpferich2007b}: 485). Das System produziert folglich einen besseren Output (\citealt{NybergEtAl2003}: 248), insbesondere wenn die Terminologie zuvor in die Systemdatenbank eingepflegt wurde \citep[366]{Göpferich2008}. Diese Studien wurden für die frühen MÜ-Ansätze (RBMÜ, SMÜ, PBMÜ und HMÜ) durchgeführt. Ob und inwiefern der Einsatz der verschiedenen KS-Regeln nach der Entwicklung des jüngsten MÜ-Ansatzes der NMÜ den MÜ-Output verbessert, ist eine zentrale Fragestellung der vorliegenden Studie.

Diese Vorteile können in manchen Fällen mit Nachteilen für die Übersetzer gekoppelt sein. Die aufgrund der höheren Konsistenz gestiegenen Matchquoten können dazu führen, dass der Umfang der Arbeit für die Übersetzer stark abnimmt. Manche Unternehmen setzen die (englische) KS ein, um die Humanübersetzung von – meistens internen – Dokumenten zu vermeiden (\citealt{DrewerZiegler2014}: 208). Vergleichbar mit den Nachteilen bei den Redakteuren kann die Einhaltung von KS-Regeln auch bei den Übersetzern zeitaufwendiger und komplexer als das Übersetzen ohne den Einsatz von KS-Regeln ausfallen (\citealt{NybergEtAl2003}: 249). Ebenfalls nehmen einige Übersetzer wahr, dass ihre Schreibfähigkeiten durch den Einsatz der KS eingeschränkt sind (ebd.).

\subsection{Für die Rezipienten}



Auf Basis der oben diskutierten Wirkungen der KS lässt sich zusammenfassend schlussfolgern, dass der Rezipient -- insbesondere Nicht-Muttersprachler -- ebenfalls von dem Einsatz der KS durch die erhöhte Eindeutigkeit, die verbesserte Lesbarkeit und die optimierte Verständlichkeit profitiert (\citealt{Göpferich2008}: 366; \citealt{DrewerZiegler2014}: 208).

Auf der anderen Seite kann der Stil der KS von manchen Rezipienten als eintönig und unästhetisch empfunden werden, da sie gewöhnlich einen abwechslungsreichen Stil erwarten und diesen als lebendig empfinden (\citealt{LehrndorferReuther2008}: 112f.).

Angesichts der obengenannten Stärken und gleichzeitig des Aufwands und der Kosten des Einsatzes einer KS beschäftigten sich mehrere Studien (vgl. \citealt{NybergEtAl2003}: 248; \citealt{Göpferich2008}: 369; \citealt{LehrndorferReuther2008}: 108) mit der Frage, wann es empfohlen ist, eine KS zu implementieren. Die Antwort lässt sich wie folgt zusammenfassen:

\begin{itemize}
\item bei einem wachsenden Dokumentationsumfang, insbesondere wenn an der Dokumentation mehrere Personen oder Stellen arbeiten,
\item bei einer häufigen Kombinierung von mehreren Dokumenten oder bei einer häufigen Änderung des Inhalts,
\item für technische Inhalte insbesondere bei einer steigenden Komplexität des Inhalts bzw. einem zunehmenden Dokumentationsverwaltungsaufwand,
\item wenn große Textvolumen in verschiedene Sprachen übersetzt werden,
\item wenn die Kosten der Dokumentation bzw. der Übersetzung reduziert werden sollen.
\end{itemize}

\subsection{Diskussion der Stärken und Schwächen der KS}

Im Folgenden werden die obengenannten Stärken und Schwächen der KS (kritisch) reflektierend diskutiert:

Das Gegenargument, dass der Einsatz von KS mit hohen Kosten verbunden wäre, ist heutzutage nicht nachvollziehbar, denn jedes Unternehmen, das einen professionellen Dokumentations- und Übersetzungsprozess anstrebt, besitzt und pflegt bereits eine Terminologiedatenbank und wendet eine Form der Sprachkontrolle an, sei es in Form von Styleguide oder Redaktionsleitfaden (vgl. \citealt{Göpferich2007a}). In seinem Aufsatz „Implementing a Controlled Language is now cheaper and easier than ever“ nennt \citet{Mügge2013} Beispiele\footnote{{{{Der „ASD-STE100-Regelsatz“ der AeroSpace- und Defense Industries Association of Europe (ASD) sowie der Open-Source-Checker „STE Term Checker“, die für ASD-STE100 zur Grammatik, Stil- und Vokabelprüfung optimiert wurde, stehen kostenlos zur Verfügung.}}}} für kommerzielle Regelwerke und leistungsstarke Controlled-Language-Checker, die kostenlos zur Verfügung stehen und somit die Implementierung von KS auch für Kleinunternehmen attraktiv gestalten. Außerdem lässt sich die Kostenersparnis, die das Unternehmen durch den Einsatz von KS realisiert, anhand eines einfachen Rechenbeispiels verdeutlichen: Die technische Dokumentation beinhaltet zahlreiche Standardsätze, die sich in den Dokumentationen wiederholen. Wenn 30 Standardsätze in 5 Dokumenten vorkommen, wobei sie leicht an den Kontext angepasst werden sollen, hätten die Redakteure ohne Einsatz von KS-Regeln 150 Sätze (30 Sätze * 5 Dokumente), die neu formuliert werden müssen. Im Falle des Einsatzes von KS-Regeln müssten die 30 Sätze in den 5 Dokumenten nur an den Kontext angepasst werden. Dies bietet nicht nur eine große Zeitersparnis, sondern auch einen konsistenten Text. Sollten die 5 Dokumente in 3 Fremdsprachen übersetzt werden, steigt die Ersparnis deutlich (450 Sätze ohne KS (30 Sätze * 5 Dokumente * 3 Zielsprachen) im Vergleich zu 90 Sätzen (30 Sätze * 3 Zielsprachen) mit leichten Anpassungen bei dem Einsatz von KS-Regeln). Zudem spiegelt sich die Konsistenz in den Zielsprachen wider.

Bezüglich der Problematik der psychischen Abneigung: Es ist nachvollziehbar, dass jeder neue Prozess im Unternehmen von seiner Zielgruppe erlernt werden muss und dass die Lernphase einen gewissen Aufwand mit sich bringt. Nachdem jedoch ein Lerneffekt verzeichnet wird, geben die Redakteure in manchen Unternehmen an, dass sie eine „Sensibilisierung für sprachliche Sachverhalte und eine effizientere Texterstellung und -bearbeitung“ entwickelt haben (\citealt{LehrndorferReuther2008}: 111). In der Einführungsphase von KS wird empfohlen, die Redakteure und Übersetzer bei der KS-Definition und dem KS-Einsatz einzubeziehen, um einer potentiellen Abneigung vorzubeugen (vgl. \citealt{NybergEtAl2003}: 249). Allerdings ist dieser Ansatz in mittelständischen und Großunternehmen durch die hohe Anzahl der Redakteure und Übersetzer nur bedingt realisierbar. Außerdem benötigt jedes Unternehmen in fortgeschrittenen Phasen des KS-Einsatzes sowie mit der Rotation von neuen Redakteuren und Übersetzern eine solide Basis, um eine erreichte KS-Akzeptanz beizubehalten bzw. einer möglichen Abneigung entgegenzuwirken. Da die häufig genannten Schwierigkeiten des KS-Einsatzes auf den erhöhten Zeitaufwand, die erhöhte Schreibkomplexität sowie eingeschränkte Kreativität zurückgeführt werden, stehen den Unternehmen mehrere Wege zur Verfügung, um diese Schwierigkeiten zu bewältigen:

Erstens ist die Verwendung von einem Controlled-Language-Checker (CLC),\footnote{{{{Ein CLC ist ein Programm, das den technischen Redakteur unterstützt, die Regeln der KS (korrekt) einzusetzen (mehr dazu unter \sectref{sec:2.5}).} }}} Authoring-Memory-System und Translation-Memory-System\footnote{{{{Während Translation-Memory-Systeme (TMS) für die Erstellung des Zieltexts im Übersetzungsprozess verwendet werden, kommen Authoring-Memory-Systeme (AMS) bei der Erstellung des Ausgangstexts zum Einsatz. Ein AMS speichert die Textsegmente des Ausgangstexts ab und stellt sie zur Wiederverwendung bei der Erstellung neuer Texte zur Verfügung. (\citealt{DrewerSchmitz2017}: 196)}}} } erforderlich, um die Umsetzung der KS-Regeln zu erleichtern und entsprechend den damit verbundenen Zeitaufwand zu minimieren. In der Praxis muss nicht selten ein großes Volumen an technischen Dokumentationen unter Zeitdruck verfasst werden. Mithilfe eines Redaktionstools wird die Arbeit des Redakteurs strukturierter und vereinfacht, denn die Redaktionstools zentralisieren die relevanten Terminologiedaten und Redaktionsregeln vor dem Redakteur auf dem Bildschirm.

Zweitens stellt der Einsatz von einer Mischung aus präskriptiven und proskriptiven Regeln eine Lösung dar, um die Dokumente abhängig davon, wie kritisch sie sind (z.~B. Sicherheitsanweisung im Vergleich zu einem internen Mitteilungsdokument) -- mithilfe des CLC -- mit bestimmten KS-Regeln der beiden Arten zu verknüpfen. Auf diesem Weg kann den Redakteuren Flexibilität und Freiraum für Kreativität durch die proskriptiven Regeln verschafft werden, solange die Natur des Dokuments dies zulässt.

Der dritte Weg ist die Schulung von neuen Mitarbeitern. Schulungen sind zwar mit Kosten verbunden, sie tragen aber im Endeffekt zur Dokumentationsqualität bei, wodurch wiederum finanzielle Nutzen unter anderem durch eine höhere Kundenzufriedenheit, verringerte Haftungsansprüche sowie verbesserte Konkurrenzfähigkeit realisiert werden können.

Bezüglich der Arbeit der Übersetzer kann bei einer reinen Übersetzungsaufgabe der Arbeitsaufwand zwar abnehmen bzw. beim MÜ-Einsatz die Arbeit auf Post-Editing eingeschränkt werden, dennoch bleibt die Rolle der Übersetzer unentbehrlich und ihre Bedeutsamkeit maximiert sich zusammen mit den mit dem Gegenstand verbundenen Risiken, dessen Dokumentation übersetzt werden soll (z. B. Risiken der Produkthaftung oder der Produktsicherheit). Denn je höher diese Risiken sind, desto umfangreicher ist der Risikobewältigungsaufwand, der letztendlich von den Übersetzern geleistet wird (\citealt{CanforaOttmann2015}).

Abschließend sollte auf ein geläufiges Argument eingegangen werden, dass die Leser eine nach KS-Regeln verfasste Dokumentation als eintönig bzw. nicht abwechslungsreich empfinden. Ein vergleichbarer Effekt der verminderten Akzeptabilität wurde von \citet{Hansen-SchirraMaaß2020}  bei der Leichten Sprache, die als eine Varietät der KS gilt, festgestellt. Gezielt für die technische Dokumentation behandelte \citet[335f.]{Püschel1996} bereits 1996 in seinem Beitrag „Sprachstil -- ein Thema für Technische Redakteure?“ diese Frage und empfahl „den Text so abwechslungsreich wie möglich zu machen“, denn „auch ein Stilbruch kann die Aufmerksamkeit wecken“. In der technischen Dokumentation muss der Einfluss der KS auf den Stil je nach Textsorte bzw. Dokumentart differenziert betrachtet werden. Handelt es sich um Dokumentationen, die z. B. Verfahren oder Instruktionen vermitteln, wäre es unangebracht, die KS in dieser Hinsicht zu kritisieren, denn vor allem durch die konsistente Wortwahl und Satzstruktur sowie den einheitlichen Stil in solchen technischen Dokumentationen wird die Lesbarkeit gesteigert, wodurch der Leser Zeit spart und eine bessere Orientierung erhält (vgl. \citealt{Farkas1985}). Geht es hingegen um Dokumentationen, die zwar technische Angaben, allerdings z. B. für Zwecke des Marketings, vermitteln, kann ein eintöniger Stil fraglich sein.


\section{\label{sec:2.5}Controlled-Language-Checker (CL-Checker)}
\subsection{CL-Checker – Überblick}

Die IT-Unterstützung beim Dokumentationsprozess ist heutzutage unerlässlich. Aufgrund der Komplexität des Dokumentationsprozesses und -umfangs ist es insbesondere in großen Unternehmen kaum vorstellbar, auf Systeme der Terminologieverwaltung, Redaktion, Sprachkontrolle bzw. \nobreakdash-überprüfung, Übersetzung und des Content-Managements zu verzichten. Im Redaktionsprozess werden in der Regel Controlled-Language-Checker, Authoring-Memory-Systeme oder Content-Management-Systeme verwendet. Ein Content-Management-System (CMS) ist ein umfangreiches Softwaresystem zur Unterstützung des Content Managements. Es besteht i. d. R. aus drei Anwendungsmodulen: einem Redaktionssystem zur Bearbeitung und Verwaltung von Inhalten, einem Content Repository zur Speicherung der Inhalte und einem Publishing System zur Ausgabe der Inhalte.\footnote{\url{https://wirtschaftslexikon.gabler.de/definition/content-management-system-cms-31303}} Ein Authoring-Memory-System (AMS) ist ein Softwaresystem, das die Textsegmente des Ausgangstexts abspeichert und sie zur Wiederverwendung bei der Erstellung neuer Texte zur Verfügung stellt (\citealt{DrewerSchmitz2017}: 196). In diesem Abschnitt liegt der Fokus auf der für die Studie relevanten Software, dem Controlled-Language-Checker (CL-Checker).

Ein Controlled-Language-Checker (CLC) ist ein Programm, dessen Ziel darin besteht, die technischen Redakteure zu unterstützen, die Regeln der KS (korrekt) einzusetzen. Es handelt sich hierbei meistens\footnote{{{{Es gibt auch nicht frei konfigurierbare CLCs, die mit bestimmten Regeln geliefert werden. Die gelieferten Regeln können zwar eingeschränkt, aber nicht um kundenspezifische Regeln erweitert werden (\citealt{DrewerZiegler2014}: 232).}}}} um eine frei konfigurierbare Software, mit der Redaktionsleitlinien oder andere Regelbestände unternehmensspezifisch abgebildet und maschinell geprüft werden können (\citealt{DrewerZiegler2014}: 227). Die Software wird in der Regel mit Standardstil- und Grammatikregeln sowie Regeln zur Rechtschreibung und Zeichensetzung vom Hersteller geliefert \citep{Geldbach2009}. Die eingesetzten Regeln und ihren Umfang kann jedes Unternehmen frei bestimmen. Die Terminologie ist unternehmensspezifisch und wird daher vom erwerbenden Unternehmen individuell eingepflegt. Die hinterlegten Regeln können je nach Zielgruppe, Textsorte und anderen definierbaren Merkmalen angepasst werden (\citealt{DrewerZiegler2014}: 234). Dementsprechend spielen die CLCs eine bedeutende Rolle dabei, den Schwächen der KS entgegenzuwirken, indem ihre Konfigurierbarkeit dem Unternehmen und den Redakteuren mehr Flexibilität und Individualität bietet (vgl. \citealt{Rösener2010}).

Die Konzeption des Controlled-Language-Checkers hängt von den zwei Ansätzen der KS (siehe \sectref{sec:2.1.3}) ab (\citealt{DrewerZiegler2014}: 228ff.): Beim \textit{Präskriptiven Ansatz}\textbf{ }müssen alle zulässigen Vokabulare sowie syntaktischen Strukturen in dem CLC hinterlegt werden. Sollte der Autor ein Wort oder eine Struktur angeben, das/die nicht im CLC vorliegt, wird dies markiert, damit der Autor es/sie ersetzt. Man kann bei diesem Ansatz keine automatische Korrektur erwarten, da es nicht selten zu fehlerhaften Fehlermeldungen (Noise) kommt. Ob und wie eine Korrektur erfolgt, bleibt die Entscheidung des Autors. Daher ist dieser Ansatz sehr umfangreich und erfordert einen hohen Lern- bzw. Schulungsaufwand. Beim \textit{Proskriptiven Ansatz} hingegen müssen alle unzulässigen Vokabulare sowie syntaktischen Strukturen in dem CLC hinterlegt werden. Der Autor hat entsprechend einen größeren Freiraum im Vergleich zum präskriptiven Ansatz. Die Fehlermeldungen sind spezifisch und von daher gut umsetzbar. All dies führt zu einer höheren Akzeptanz bei den Autoren, bietet jedoch aufgrund des großen Freiraums weniger Konsistenz im Vergleich zu dem präskriptiven Ansatz. Aufgrund der Stärken und Schwächen der beiden Ansätze werden sie auch kombiniert eingesetzt (ebd.: 230).

\subsection{Die Software und ihre Funktionsweise}

CLCs haben eine Client-Server-Architektur,\footnote{{{{Eine Client-Server-Architektur ist „eine Systemarchitektur für verteilte Anwendungssysteme, bei der Subsysteme (Server) bestimmte Dienste anbieten, die von anderen Subsystemen (Clients) nutzbar sind“. \citep{Fettke2016}}}}} in der die Terminologie und die Regeln aus zwei Gründen auf dem Server hinterlegt werden: Erstens, damit sie zentral verwaltet werden; zweitens, damit sie nicht von den Anwendern (Clients) angepasst werden können (\citealt{DrewerZiegler2014}: 232). Die Software wird in der Regel in die Autoren- oder Übersetzungsumgebung integriert (\citealt{DrewerSchmitz2017}: 201). Je nach Unternehmenssituation kann sie als Plug-in in dem Textbearbeitungsprogramm installiert werden, als ein Modul innerhalb eines großen Systems für Textproduktion und Übersetzung oder als ein alleinstehendes Programm (stand-alone) verwendet werden. Die CLCs können den Autor interaktiv darauf hinweisen, sobald ein Verstoß gegen eine der implementierten Regeln vorliegt; alternativ kann der Autor erst nach der Texterstellung die Prüfung starten (ebd.). Im Prüfergebnis werden die Verstöße hervorgehoben, kurz erläutert und dem Autor zusammen mit einem Alternativvorschlag angezeigt.

Im Redaktionsprozess führen die CLCs vier Funktionen durch: Prüfung der Rechtschreibung und Zeichensetzung, der Grammatik und des Stils sowie der korrekten Terminologieverwendung, wobei die wichtigsten Funktionen die Stilkontrolle und Terminologieprüfung darstellen (vgl. ebd.: 200).

Die grundlegende Funktionsweise eines CLCs lautet wie folgt (\citealt{Siegel2013}: 52; \citealt{DrewerZiegler2014}: 230): Vor der Identifizierung von Verstößen gegen die KS-Regeln führt das Programm zunächst primäre Schritte durch, wie Tokenisierung,\footnote{{{{Bei der Tokenisierung werden die einzelnen Wörter und Satzzeichen jedes Satzes identifiziert (\citealt{DrewerZiegler2014}: 230).}}}} morphologische\footnote{{{{Bei einer morphologischen Analyse werden die Wörter in Morpheme zerlegt (\citealt{DrewerZiegler2014}: 230).}}}} und syntaktische\footnote{{{{Bei einer syntaktischen Analyse werden zusammengehörige Gruppen von Satzelementen identifiziert (\citealt{DrewerZiegler2014}: 230).}}}} Analyse. Auf Basis der morphologischen Analyse werden vorwiegend die Rechtschreib-, Grammatik- sowie Terminologieprüfungen durchgeführt. Die Syntaktische Analyse ist hingegen für die Stilprüfung erforderlich.

Nach Abschluss dieser Basisanalysen startet die Software die vier Prüfungen (\citealt{DrewerZiegler2014}: 231): Die \textit{Rechtschreibprüfung} ist umfangreicher als die bekannten Rechtschreibprüfungen von Textverarbeitungsprogrammen. Dank einer semantischen Komponente können Tippfehler, die zwar Wörter ergeben, aber semantisch im Satz falsch sind (z. B. „ins“ und „uns“), erkannt werden. Ebenfalls wird die Zeichensetzung geprüft. Die \textit{Grammatikprüfung} ist für die korrekte Grammatik zuständig. (\citealt{DrewerSchmitz2017}: 201)

Die \textit{Stilprüfung} hat die Aufgabe, schwer verständliche und für den Texttyp nicht adäquate Konstruktionen zu identifizieren (\citealt{Siegel2013}: 52; \citealt{DrewerZiegler2014}: 231), wodurch die Verständlichkeit und somit die Qualität des Texts erhöht wird (\citealt{DrewerSchmitz2017}: 201). Beispiele für Stilregeln aus der \citet{tekom2013} für deutsche technische Dokumentationen sind: „Konjunktiv zu vermeiden“, „Anweisungen als imperativischen Infinitiv formulieren“ und „Direkte Anrede verwenden“. Zudem entwickelt das Unternehmen durch die Stilprüfung seine Corporate Language, denn die Prüfung erkennt die Sätze, die zwar grammatisch korrekt sind, aber nicht nach dem vorgegebenen Stil verfasst wurden (\citealt{DrewerZiegler2014}: 232).

Für die \textit{Terminologieprüfung} benötigt das Programm eine Terminologiedatenbank, die die Vorzugsbenennungen, unzulässige Benennungen und zulässige Benennungen enthält. Auf Basis der durchgeführten Sprachanalyse zusammen mit dieser Terminologiedatenbank kann das Programm unzulässige Flexionsvarianten identifizieren und dem Autor eine Vorzugbenennung vorschlagen. Eine weitere Aufgabe der Terminologieprüfung ist die Identifizierung von Wörtern, deren Schreibweise nicht regelkonform ist (Beispiel aus der tekom-Leitlinie „Komposita aus zwei Basismorphemen immer ohne Bindestrich“). (\citealt{Siegel2013}: 52; \citealt{DrewerZiegler2014}: 232) Ferner sind die CLCs mit einer Terminologieextraktionskomponente ausgerüstet. Durch die \textit{Terminologieextraktion} werden domänenspezifische Termini automatisch erkannt und in einer vorgesehenen Tabelle gespeichert. Die Terminologieextraktion wird mithilfe von Regeln ausgeführt, die auf Part-of-Speech-Informationen und Lemmatisierung aufgebaut sind. \citep[52]{Siegel2013}

Die am meisten implementierten CLCs auf dem deutschen Markt sind die Softwareprodukte der Firmen „Acrolinx GmbH“ und „Congree Language Technologies GmbH“ (vgl. \citealt{Geldbach2009}; \citealt{DrewerZiegler2014}: 230). Die CLC-Komponente der Congree Software ist der Controlled-Language-Checker CLAT,\footnote{\url{http://www.iai-sb.de/de/produkte/clat} [abgerufen am 23.12.2014]} der vom Institut der Gesellschaft zur Förderung der Angewandten Informationsforschung (IAI)\footnote{Im Jahr 2002 hat das IAI die Software CLAT als ein Upgrade von MULTILINT freigegeben (\citealt{RamirezPoloHaller2005}). Bei den Bestandskunden ist die Software unter dem Namen CLAT im Einsatz. Seit 2011 wird CLAT nicht mehr von dem IAI sondern von der Congree Language Technologies GmbH vertrieben, an der das IAI beteiligt ist. (\citealt{DrewerZiegler2014}: 230)} der Universität des Saarlandes entwickelt wurde. Dank einer Forschungskooperation mit dem IAI wurde der vorliegenden Studie eine Lizenz für CLAT zu Forschungszwecken zur Verfügung gestellt. CLAT wurde in der Studie zur Prüfung der Verstöße gegen die analysierten KS-Regeln verwendet (siehe \sectref{sec:4.4.3.1}, Schritt [2]). Im nachstehenden Abschnitt erfolgt eine detaillierte Darstellung von CLAT.

\subsection{CLAT -- Controlled Language Authoring Technology}

CLAT steht für Controlled Language Authoring Technology (\citealt{HallerSchütz2001}). Ziel der Software ist es, technische Redakteure bei der Erstellung hochwertiger Dokumentationen, z. B. nach bestimmten Standards, zu unterstützen \citep{Rösener2010}. Die ersten deutschen Versionen von CLAT wurden bei BMW München und Heidelberger Druckmaschinen; und die ersten englischen Versionen bei Sun Microsystems implementiert (\citealt{HallerSchütz2001}). Die Software bietet keine Kontrollierte Sprache sondern eine Regelsammlung an, die auf langjähriger Forschung und fundierter Erfahrung des IAIs (Institut der Gesellschaft zur Förderung der Angewandten Informationsforschung) basiert \citep{Geldbach2009}. Das IAI hat bei der Entwicklung des „Technischen Deutsch“ von tekom mitgewirkt, daher sind die tekom-Regeln in CLAT abgedeckt (ebd.). Das erwerbende Unternehmen hat die Möglichkeit, vorhandene Regeln zu aktivieren bzw. deaktivieren (ebd.).

CLAT hat eine Client-Server-Architektur und deckt in seiner Prüfung die Bereiche Rechtschreibung, Grammatik, Stil, Terminologie und Termextraktion ab (\citealt{Geldbach2009}; \citealt{Rösener2010}). Anhand des Werkzeugs „UMMT“ (Utility for Mandate Management Tasks) erfolgt die Konfiguration der Regelwerke, Terminologie, Synonyme sowie Benutzerhandbücher entsprechend den Unternehmensanforderungen \citep{Geldbach2009}. Konkret kann man in UMMT folgende Haupteinstellungen vornehmen: Terminologie importieren und verwalten, stilistische und grammatische Regeln aktivieren und deaktivieren sowie spezielle Schreibweisen und Synonyme definieren \citep{Rösener2010}.

In einer primären Analyse wird der Text auf Grundlage der morphologischen und syntaktischen Analyse in Sätze und Wörter zerlegt (\citealt{HallerSchütz2001}). Bei der \textit{Rechtschreibprüfung} werden falsche bzw. unbekannte Wörter markiert \citep{Rösener2010}. Außerdem kann die Software im Rahmen der Rechtschreibprüfung zwischen Sprachvarianten (e.g. Britisches vs. Amerikanisches Englisch) unterscheiden (ebd.). Anders als die klassische Rechtschreibprüfung, die auf Basis eines Lexikons durchgeführt wird, erfolgt die Rechtschreibprüfung in CLAT auf Basis einer vollständigen Liste der Morpheme zusammen mit der unternehmensspezifischen Terminologie; so wird jedes Wort, das nach den morphologischen Regeln gebildet wird bzw. ein unternehmensspezifischer Terminus ist, als fehlerfrei erkannt (\citealt{HallerSchütz2001}). Auf diese Weise ist die Anzahl der als fehlerhaft markierten Wörter wesentlich geringer als die einer herkömmlichen Rechtschreibprüfung. Nicht selten führt ein Rechtschreibfehler zu einem lexikalisch korrekten Wort; diese Art von Rechtschreibfehlern kann nur durch die syntaktische Analyse des Satzes erkannt werden. (ebd.) Die \textit{Grammatikprüfung} ermittelt grammatische sowie typographische Fehler \citep{Rösener2010}. Hierbei werden Partial Parsings berechnet und Tests für Wort- oder Musterfehler durchgeführt (\citealt{HallerSchütz2001}). Der Stil im Sinne von Verständlichkeit, Klarheit und stilistischer Eignung ist die Aufgabe der \textit{Stilprüfung} \citep{Rösener2010}. Auf Basis von der unternehmensspezifischen Schreibregeln, die das Unternehmen bei der Konfiguration vom CLAT im UMMT festlegt, werden komplexe, ambige bzw. stilistisch problematische Stellen hervorgehoben. Die letzte Prüfungskomponente in CLAT beschäftigt sich mit der \textit{Terminologie}. CLAT ermittelt im Text nicht zugelassene bzw. veraltete Termini und schlägt dafür die entsprechenden bevorzugten Termini vor. Nach der Prüfung hat der technische Redakteur die Möglichkeit die ermittelten Regelverstöße zu überprüfen, den Text zu überarbeiten oder keine Überarbeitung durchzuführen. Neben den vier Prüfungen bietet CLAT die \textit{Termextraktionsfunktion}, mit der die Software den Terminologie-Workflow im Unternehmen unterstützt. Mithilfe dieser Funktion werden Substantive mit Terminieigenschaften ermittelt, so dass der technische Redakteur während der Prüfung entscheiden kann, ob sie als zulässig bzw. unzulässig in der Unternehmensdatenbank erfasst werden sollen. (ebd.)

Während der Anpassungsphase (customization phase) können die Fehlermeldungen und die darin enthaltenen Beispiele je nach Abteilung oder sogar Autor angepasst werden (\citealt{HallerSchütz2001}). Zudem können je nach Dokumenttyp unterschiedliche Regeln gelten; beispielsweise kann die Prüfung von Anleitungstexten strenger als die der Informationstexte gestaltet werden (ebd.). Schließlich unterstützen CL-Cherker das Unternehmen dabei, die technischen Dokumente in Bezug auf Lesbarkeit und Verständlichkeit zu verbessern. Dies wiederum stellt eine solide Grundlage für nachfolgende Prozesse wie die Übersetzung und Qualitätssicherung dar.

\section{\label{sec:2.6}Fazit}

Angesichts des zahlreichen Nutzens der Kontrollierten Sprache ist ihr Einsatz sehr weit verbreitet. Je nach den Unternehmensbedürfnissen wird sie in unterschiedlichem Umfang -- angefangen bei einzelnen Regeln bis hin zu vollständiger KS -- eingesetzt. Für die deutsche Sprache wird meist nach einem Regelwerk mit grammatischen und syntaktischen Regeln, terminologischen Vorgaben sowie Fachtermini (ohne den Einsatz eines Lexikons) gearbeitet. Mithilfe der KS zielen die Unternehmen auf eine bessere Lesbarkeit, Verständlichkeit und Übersetzbarkeit ab. Je nach Dokumenttyp können die zweckdienlichen KS-Regeln mithilfe von CL-Checkern aktiviert werden. Die Aktivierung der Regeln bewirkt im Allgemeinen eine vereinfachte Satzstruktur und -komplexität bzw. eine reduzierte Ambiguität. Das wiederum wirkt sich auf die Verständlichkeit, Lesbarkeit sowie Übersetzbarkeit -- wenn auch in unterschiedlichem Ausmaß -- aus. Daher sind die KS-Auswirkungen voneinander nicht scharf zu trennen. Vor diesem Hintergrund und angesichts des aktuell bemerkbaren MÜ-Fortschritts insbesondere bei der Lieferung eines flüssigen und stilistischen Outputs nimmt die Studie diverse KS-Regeln unter die Lupe, und zwar Regeln, die die Verständlichkeit und die Lesbarkeit, sowie weitere, die die Übersetzbarkeit, im Fokus haben, und analysiert ihre direkten bzw. indirekten Auswirkungen auf den MÜ-Output sowohl stilistisch als auch inhaltlich im Sinne der Verständlichkeit und Genauigkeit. Um all diese Qualitätsaspekte abdecken zu können, wird die Analyse auf Basis humaner sowie automatischer Evaluationen durchgeführt. Da die maschinelle Übersetzung (MÜ) einer der Hauptakteure der vorliegenden Arbeit ist, wird das Augenmerk im folgenden Kapitel auf die MÜ sowie vorherige MÜ-Studien im Kontext der KS gerichtet.
