\chapter{\label{Toc51705127}{}Kapitel 1 – Einleitung}


\marzoukepigram{The major obstacles to translating by computer are, as they have always been, not computational but linguistic.}{\citealt{HutchinsSomers1992}: 2}


\section{\label{Toc51705128}{}{{Hintergrund und Motivation}}}

Die Anwendung der Kontrollierten Sprache (KS) ist eine gängige Pre-Editing-Technik in der technischen Dokumentation. Eine KS wird wie folgt definiert: „an explicitly defined restriction of a natural language that specifies constraints on lexicon, grammar, and style“ \citep[2]{Huijsen1998}. Durch den Einsatz von lexikalischen, syntaktischen und stilistischen Restriktionen wird Ambiguität vermieden, die Satzstruktur vereinfacht und somit die Textkomplexität reduziert sowie Konsistenz und Standardisierung geschaffen. Das Ziel dabei ist es, die Textlesbarkeit, -verständlichkeit und \nobreakdash-wiederverwendbarkeit zu erhöhen sowie die Qualität der menschlichen und maschinellen Übersetzung (MÜ) zu verbessern und die Übersetzungskosten zu reduzieren (vgl. \citealt{HutchinsSomers1992}: 4; \citealt{Lehrndorfer1996a}; \citealt{Hujisen1998}; \citealt{NybergEtAl2003}: 245; \citealt{DrewerZiegler2014}: 197). Im Fokus der vorliegenden Studie liegt die Beziehung zwischen der KS und der maschinellen Übersetzbarkeit. Die MÜ gilt als „one of the most interesting computational applications of Controlled Language“ (\citealt{NybergEtAl2003}: 254f.). Die Grundidee des KS-Einsatzes im Kontext der MÜ ist es, dass je einfacher der Text auf linguistischer Ebene ist, desto höher die Qualität seiner MÜ ausfällt, wie Hutchins und Somers es bereits 1992 auf den Punkt brachten: „The major obstacles to translating by computer are, as they have always been, not computational but linguistic.“ (\citealt{HutchinsSomers1992}: 2) Auch Regeln, die die Verständlichkeit (und nicht die Übersetzbarkeit) im Fokus haben, optimieren die Verständlichkeit hauptsächlich auf dreierlei Weise, nämlich durch die Vereinfachung der Satzstruktur, Reduzierung der Satzkomplexität bzw. Vermeidung der Ambiguität;  dadurch tragen sie zudem indirekt zur Verbesserung der Übersetzbarkeit bei (vgl. Fiederer/O'\citealt{Brien2009}: 53).

Bereits Mitte der 80er Jahre entwickelte Caterpillar CTE „Caterpillar Technical English“. Im Mittelpunkt standen die Optimierung der Text- und Übersetzungsqualität sowie die Reduzierung der Übersetzungskosten. In der Tat gelang es Caterpillar mithilfe der CTE in Verbindung mit einem regelbasierten MÜ-System (RBMÜ), ein großes Textvolumen zu verfassen und es in mehr als 30 Sprachen zu übersetzen. (\citealt{KamprathEtAl1998}; \citealt{DrewerZiegler2014}: 212) Ebenfalls ermöglichte 1979 der Einsatz der KS (Multinational Customised English, MCE) in Kombination mit einem RBMÜ-System Xerox, das in mehr als 36 Ländern tätig war, seine Übersetzungsproduktivität zu vervierfachen \citep{Elliston1979}. Angesichts dieses Erfolgs begannen weitere Organisationen firmen- und branchenspezifische KS zu entwickeln, wie z. B. das „NCR Fundamental English“, das „Plain English Program“ (PEP) und die „International Language for Servicing and Maintenance“ (ILSAM) (vgl. \citealt{Schwanke1991}: 42). Zudem fand die KS Anklang bei multinationalen Konzernen, wie Kodak (Kodak International Service Language), Nortel (Nortel Standard English), Sun (Sun Controlled English), Ericsson (Ericsson English) und KANT (KANT Controlled English) (\citealt{DrewerZiegler2014}: 211).

In der Forschung zeigten mehrere Studien über das letzte Vierteljahrhundert, dass sich die Anwendung der KS aus verschiedenen Perspektiven positiv auf die MÜ auswirkt. \citet{KamprathEtAl1998} belegten einen signifikanten positiven Einfluss von CTE auf die MÜ-Produktivität. \citet{Reuther2003} kam zum Ergebnis, dass die Implementierung von KS-Regeln die Lesbarkeit und Übersetzbarkeit der maschinell übersetzten Texte verbessern könne. Eine weitere Studie ergab, dass die Kontrolle des Ausgangstexts einen großen Einfluss auf die Genauigkeit des MÜ-Outputs eines wissensbasierten interlingualen MÜ-Systems hat (\citealt{NybergMitamura1996}). Bernth und \citet{Gdaniec2001} führten 26 Regeln für Englisch als Ausgangssprache ein, die unterschiedliche Texteigenschaften abdecken, mit dem Ziel, die maschinelle Übersetzbarkeit zu verbessern. Sie testeten diese Regeln mit verschiedenen kommerziellen MÜ-Systemen und gaben an, dass sie auf verschiedene MÜ-Systeme und Sprachenpaare generalisierbar seien (ebd.). Darüber hinaus untersuchten weitere Studien die Auswirkungen der KS auf das Post-Editing. O’\citet{Brien2006} stellte fest, dass die KS die Post-Editing-Zeit verkürzt. Ein weiterer positiver Effekt war in Zusammenhang mit der Post-Editing-Produktivität nachweisbar \citep{AikawaEtAl2007}.

Die meisten KS-Studien haben den Einfluss vollständiger KS auf die (maschinelle) Übersetzbarkeit ganzheitlich untersucht (z. B. \citealt{SpyridakisEtAl1997}; \citealt{KamprathEtAl1998}; \citealt{Bernth1999}; \citealt{NybergEtAl2003}: 254f.). Die Ergebnisse dieser Untersuchungen liefern ein Gesamtbild des KS-Effekts (inkl. Regeln zur Verbesserung der Textlesbarkeit, -verständlichkeit und -übersetzbarkeit), bei dem der positive Effekt einiger Regeln den negativen Effekt anderer Regeln überschatten kann, was zu einem verzerrten Endergebnis führt und den individuellen Einfluss der einzelnen Regeln nicht erkennen lässt. Nur eine begrenzte Anzahl von Studien befasste sich mit der Analyse des Einflusses einzelner KS-Regeln. Die Ergebnisse dieser Studien (O’\citealt{Brien2006}; \citealt{Roturier2006}; \citealt{RoturierEtAl2012}) zeigen, dass die KS-Regeln die MÜ auf verschiedene Weise und in unterschiedlichem Maße beeinflussten. Diese Studien untersuchten KS-Regeln der englischen Sprache. \citet{RoturierEtAl2012} analysierten die Auswirkungen der KS-Regeln auf die MÜ-Qualität mithilfe von automatischen Evaluationsmetriken. Die Experimente wurden mit einem phrasenbasierten System (PBMÜ) für die Zielsprachen Französisch und Deutsch durchgeführt. In einer weiteren Studie konzentrierte sich \citet{Roturier2006} ebenfalls auf die gleichen Zielsprachen, verwendete jedoch ein RBMÜ-System mit dem Ziel, die Auswirkungen von KS-Regeln auf die Verständlichkeit zu analysieren. O'\citet{Brien2006} untersuchte die Auswirkungen von KS-Regeln auf den Post-Editing-Aufwand für Deutsch als Zielsprache bei einem anderen RBMÜ-System.

Die Untersuchung der individuellen Auswirkungen der KS-Regeln bei verschiedenen Systemen ermöglicht einen effizienten Einsatz der sich positiv auswirkenden Regeln. Ferner – je nach Implementierungskontext – besteht die Problematik: „some writing rules may even do more harm than good“ (\citealt{NybergEtAl2003}: 257). Dementsprechend können anhand solcher Untersuchungen sich negativ auswirkende Regeln ausgeschlossen werden. Darüber hinaus hat eine Reduktion der Regeln auf das Wesentliche den Vorteil, dass potenzielle Schwächen der KS-Anwendung begrenzt werden: Der Einsatz umfangreicher KS-Regeln kann mit einem Regel-Usability-Problem verbunden sein, die Autorenproduktivität beeinträchtigen \citep{Mitamura1999}, den Schreibprozess übermäßig komplex gestalten bzw. übermäßig in diesen eingreifen (O’\citealt{BrienRoturier2007}) und zur Ablehnung von den Autoren führen \citep[31]{Doherty2012}. Eine weitere Nebenwirkung der KS besteht darin, dass die Textakzeptabilität durch den Einsatz der Regeln beeinträchtigt werden kann \citep{Roturier2006}. Der Stil der KS kann von manchen Rezipienten als unästhetisch empfunden werden (\citealt{LehrndorferReuther2008}: 112f.). Im Bereich der Leichten Sprache (LS), als einer Varietät der KS (siehe \sectref{sec:2.1.1}), diskutierten Hansen-Schirra und Maaß \REF{ex:key:2020} den Trade-off zwischen der Verständlichkeit und der Akzeptanz, der oft in dieser Sprachvarietät beobachtet wird. Sie betonten die Bedeutung des Akzeptanzfaktors für die Zielgruppen dieser Sprachvarietät und modellierten folglich die LS „LS+“, die sowohl verständlich als auch akzeptabel ist (ebd.). Außerdem kann die Anwendung von großen KS-Regelsätzen – trotz der Verwendung von einem KS-Checker – aus Zeit- und Ressourcengründen schwierig ausfallen (\citealt{Govyaerts1996}; O’\citealt{BrienRoturier2007}). Schließlich wird die technische Dokumentation nicht selten von den jeweiligen Fachabteilungen bzw. Fachexperten verfasst, die über begrenztes linguistisches Wissen zum Verstehen und der Umsetzung aller Regeln verfügen (Van der \citealt{EijkEtAl1996}; \citealt{AranberriRoturier2009}). All diese potenziellen Schwächen unterstreichen die Notwendigkeit einer sorgfältigen Identifizierung der für bestimmte Ziele tatsächlich erforderlichen Regeln.

Eine empirische Analyse der Auswirkungen der einzelnen Regeln ist demzufolge erforderlich, um über die Anwendung bzw. Nicht-Anwendung der Regeln auf solider Basis entscheiden zu können. Allerdings stellt die Ermittlung der Auswirkung einer bestimmten Regel innerhalb eines Regelsatzes eine Herausforderung dar, die von Douglas und \citet[2]{Hurst1996} folgendermaßen beschrieben wurde:

While it might be possible to evaluate the quality of a document conforming to a specific CL [...], this does not allow us to say anything about the effects of particular elements in the definition of the CL, some of which may impose burdens on the writer disproportionate to their benefits to the reader. (\citealt{DouglasHurst1996}: 2)

In der Tat ist eine solche empirische Studie mit mehreren Herausforderungen verbunden, was die begrenzte Anzahl an Studien in diesem Bereich erklärt. Die Hauptherausforderungen umfassen:

\begin{itemize}
\item die Entwicklung einer Technik, die eine Isolierung der Auswirkung der einzelnen Regeln ermöglicht;
\item die Aufbereitung der Daten nach klar definierten Kriterien, um linguistische Schwierigkeiten, die für das getestete Problem irrelevant sind (sog. Noise), zu eliminieren bzw. möglichst zu reduzieren (vgl. \citealt{KingFalkedal1990});
\item die Umsetzung der Regeln nach einem begründeten festgelegten Muster, da die Regelumsetzungsmuster die Ergebnisse erheblich beeinflussen \citep[74]{Roturier2006};
\item die Arbeit mit einem Datensatz, mit dem diese Forschungsherausforderungen bewältigt werden können und der gleichzeitig über eine für die statistische Auswertung ausreichende Größe verfügt.
\end{itemize}

Im Allgemeinen sind MÜ-Studien im Bereich der KS aufgrund der Anzahl der unabhängigen Variablen ein komplexes Forschungsgebiet. Da die MÜ-Qualität je nach Sprachenpaar, Übersetzungsrichtung, Domäne und angewendetem MÜ-System variiert, ist es zu erwarten, dass die Auswirkung jeder KS-Regel auf den MÜ-Output zusammen mit diesen Variablen ebenfalls variiert. 

In den letzten Jahren wurde der neuronale MÜ-Ansatz (NMÜ) eingeführt; ein Ansatz, der mithilfe der künstlichen Intelligenz auf Basis neuronaler Netzmodelle versucht, das menschliche Gehirn bzw. Denken nachzuahmen, wodurch er sich signifikant von früheren Ansätzen abhebt. Das Vorhaben dieser Studie wurde durch die Entwicklung des NMÜ-Ansatzes in Gang gebracht. Angesichts des Quantensprungs in der MÜ-Qualität und der damit verbundenen Veränderung der Art der aufgetretenen Fehler ist es an der Zeit, die Auswirkungen der KS auf die maschinelle Übersetzbarkeit bei der NMÜ zu überprüfen. Mehrere Studien belegen den Erfolg dieses Ansatzes bei der Erstellung hochqualitativer Übersetzungen im Vergleich zu den früheren Ansätzen sowohl für das hier untersuchte Sprachenpaar als auch für weitere Sprachenpaare (vgl. \citealt{BentivogliEtAl2016}; \citealt{WuEtAl2016}; \citealt{CastilhoEtAl2017b}; \citealt{ToralSanchez-Cartagena2017}; Popović 2018). Während die vorherigen Ansätze mit schwerwiegenden Fehlern (u.~a. im Bereich der Morphologie und Grammatik, wie z.~B. Wortstellungsfehlern) zu kämpfen haben, kann die NMÜ diese Schwierigkeiten lösen und darüber hinaus eine im Wesentlichen flüssige Übersetzung liefern (vgl. \citealt{BentivogliEtAl2016}; \citealt{ToralSanchez-Cartagena2017}; Van \citealt{BrusselEtAl2018}). Eine relative Schwäche zeigt die NMÜ dennoch bei den Qualitätskriterien Genauigkeit bzw. Adäquatheit, inkl. wenig transparenten Fehlern wie z.~B. Fehlübersetzungen, Auslassungen und stilistischen Fehlern, die mit einem hohen Post-Editing-Aufwand verbunden sind (Van \citealt{BrusselEtAl2018}; \citealt{Volk2018}; \citealt{VardaroEtAl2019}). Solche Qualitätskriterien bedürfen einer Humanevaluation, in der die Evaluatoren trotz der hohen Flüssigkeit der Übersetzung (feine) Genauigkeits-, Adäquatheits- bzw. stilistische Fehler identifizieren, denn AEMs sind nicht immer in der Lage, sie differenziert auszuwerten (vgl. \citealt{MüllerEtAl2018}; \citealt{ShterionovEtAl2018}). Vor diesem Hintergrund dürfen die Genauigkeit bzw. Adäquatheit und der Stil bei der MÜ-Evaluation nicht außer Acht gelassen werden, und das, obwohl der Stil kein Hauptziel der KS ist. Die vorliegende Studie beleuchtet die einzelnen Regeln eingehender, um ihre Wirkung auf die MÜ-Qualität sowohl stilistisch als auch inhaltlich im Sinne der Verständlichkeit und Genauigkeit empirisch zu testen. Auf diese Weise kann die Entscheidung über die Anwendung einer Regel kontextabhängig unter Betrachtung aller Qualitätsperspektiven auf solider empirischer Basis getroffen werden.

Wie diese kurze Darstellung der MÜ-Studien im Bereich der KS zeigt, lag der Forschungsfokus auf der englischen KS im Kontext der RBMÜ, SMÜ bzw. PBMÜ. Das kontrollierte Deutsch wurde selten erforscht und – nach bestem Wissen – bislang nicht im Kontext der NMÜ betrachtet. Die vorliegende Arbeit versucht, durch die Abdeckung des NMÜ-Ansatzes und den Vergleich seines KS-Einflusses mit denen früherer Ansätze, diese Forschungslücke zu schließen. Wie oben erwähnt, wird die MÜ-Forschung im Bereich der KS im Allgemeinen als komplex angesehen, da die MÜ-Qualität sich je nach Sprachenpaar, Übersetzungsrichtung, Domäne und angewendetem MÜ-System unterscheidet und davon abhängig die Auswirkung jeder KS-Regel auf den MÜ-Output zusammen mit diesen Variablen variiert. Dieser Komplexität wurde begegnet, indem die Variablen Sprachenpaar, Übersetzungsrichtung und Domäne konstant gehalten wurden, mit dem Ziel, die individuellen Auswirkungen von neun KS-Regeln auf den Output von fünf MÜ-Systemen der RBMÜ-, SMÜ-, HMÜ- und NMÜ-Ansätze auf verschiedenen Ebenen zu analysieren und gegenüberzustellen. Die Studie wurde im technischen Bereich bzw. für die technische Dokumentation durchgeführt, da dies das Hauptanwendungsgebiet der KS darstellt. Aufgrund des Mangels an empirischen Untersuchungen der KS-Regeln der deutschen Sprache befasst sich die Arbeit mit dem Sprachenpaar Deutsch>Englisch. Angesichts der demonstrierten Notwendigkeit der KS-Untersuchung auf Regelebene, die gleichzeitig mit einer Reihe von Herausforderungen gekoppelt ist, widmet sich die Studie dieser Untersuchungsebene. Es wurde dafür ein Mixed-Methods-Triangulationsansatz angewendet und versucht, durch die Details der Analyseverfahren, den unterschiedlichen Herausforderungen gerecht zu werden.\footnote{{{{Alle diesbezüglichen Details sind unter \sectref{sec:3.4.3} „Forschungsherausforderungen der KS-Untersuchungen auf Regelebene“ ausführlicher diskutiert.}}}}

\section{{{Ziel der Studie}}}

Angesichts der jüngsten MÜ-Entwicklungen besteht das  Ziel der Studie darin, den Einfluss \textit{einzelner} KS-Regeln der deutschen Sprache auf die Qualität des MÜ-Outputs in der englischen Sprache bei verschiedenen MÜ-Ansätzen (RBMÜ, SMÜ, HMÜ und NMÜ) empirisch zu untersuchen und zu vergleichen. Der Einfluss der KS-Regeln auf die MÜ-Outputqualität wurde in Bezug auf die Anzahl und Typen der aufgetretenen Fehler, Stil- und Inhaltsqualität sowie AEM-Scores (Automatic Evaluation Metric) nach einem Mixed-Methods-Triangulationsansatz erforscht. Die Anzahl und Typen der aufgetretenen Fehler wurden im Rahmen einer Fehlerannotation basierend auf der Fehlertaxonomie von \citet{VilarEtAl2006} ermittelt (siehe \sectref{sec:4.4.4}). Die Stil- und Inhaltsqualität wurden in Anlehnung an Hutchins und \citet[163]{Somers1992} definiert, wobei die Inhaltsqualität die Attribute Genauigkeit und Verständlichkeit umfasst und die Stilqualität die Idiomatik der MÜ, die Eignung der MÜ für die Intention des Inhalts sowie die korrekte bzw. klare orthografische Darstellung der MÜ abdeckt (siehe Definitionen unter \sectref{sec:4.4.5.1}).\footnote{\textrm{Die Begriffe Verständlichkeit, Intention und Stil werden in verschiedenen Disziplinen und Subdisziplinen behandelt. Für jeden dieser Begriffe existieren dementsprechend zahlreiche konkurrierende Definitionen, die aus Platzgründen nicht alle präsentiert und gegeneinander abgewogen werden können. Im Rahmen dieser Studie wurden diese Begriffe aus computerlinguistischer Perspektive betrachtet und nach den Definitionen von Hutchins und \citet{Somers1992}, die seit den neunziger Jahren in der MÜ-Evaluation häufig herangezogen werden, bei der Evaluation umgesetzt. Unter \sectref{sec:4.4.5.1} werden die Definitionen genauer erläutert und ihre Auswahl begründet. Eine weiterführende Diskussion dieser Begriffe würde den Rahmen dieser Arbeit sprengen.}} Die Analyse der Stil- und Inhaltsqualität erfolgte anhand einer Humanevaluation. Die Scores von TERbase \citep{SnoverEtAl2006} und hLEPOR \citep{HanEtAl2013} wurden in einer automatischen Evaluation gemessen (siehe \sectref{sec:4.4.6}). Um das Ziel der Studie zu realisieren, wurden die zwei Szenarien „vor Anwendung der KS-Regel“ (nachstehend „vor-KS“ genannt) und „nach Anwendung der KS-Regel“ (nachstehend „nach-KS“ genannt) auf Satzebene verglichen. Der Vergleich fand auf vier Ebenen statt:

\begin{itemize}
\item \textit{Auf Sprachenpaarebene}: ein Vergleich der Szenarien vor-KS vs. nach-KS im gesamten Datensatz.
\item \textit{Auf Regelebene}: der Datensatz wurde nach Regel aufgeteilt (d. h. bei jeder Regel sind alle MÜ-Systeme enthalten). Die Szenarien vor-KS vs. nach-KS wurden bei den einzelnen Regeln verglichen.
\item \textit{Auf MÜ-Systemebene}: der Datensatz wurde nach MÜ-System aufgeteilt (d. h. bei jedem System sind alle Regeln enthalten). Die Szenarien vor-KS vs. nach-KS wurden bei den einzelnen MÜ-Systemen verglichen.
\item \textit{Auf Regel- und MÜ-Systemebene}: der Datensatz wurde nach Regel aufgeteilt und anschließend innerhalb jeder Regel nach MÜ-System aufgeteilt. Die Szenarien vor-KS vs. nach-KS wurden bei den einzelnen MÜ-Systemen innerhalb jeder Regel verglichen.
\end{itemize}

\section{\label{Toc51705130}{}{{Forschungsfragen und Hypothesen}}}

Die Hauptfragestellung der Studie lautet: Wo liegen die Unterschiede im maschinellen Übersetzungsoutput vor vs. nach der Anwendung der einzelnen analysierten KS-Regeln in Bezug auf die aufgetretenen Fehler, Stil- und Inhaltsqualität sowie AEM-Scores regel- und systemübergreifend, regelspezifisch sowie systemspezifisch?  

Um diese Hauptfragestellung umfassend zu beantworten, musste sie in detaillierte Fragestellungen unterteilt werden, die neun Analysefaktoren zugeordnet wurden. Im Folgenden sind die Analysefaktoren zusammen mit den Fragestellungen, Hypothesen, Analyseebenen sowie angewandten Analysemethoden in einer Übersicht aufgeführt:

\subsection*{Erster Analysefaktor: Vergleich der Fehleranzahl vor vs. nach dem Einsatz der KS-Regel}

Anhand des ersten Analysefaktors wird die Fehleranzahl auf Basis der Fehlerannotation vor vs. nach der KS-Anwendung innerhalb der KS-Stelle\footnote{{{{Die KS-Stelle ist der Teil des Ausgangssatzes, der bei dem Einsatz der KS-Regel modifiziert werden muss, und seine Äquivalenz im Zielsatz. Mehr dazu unter Abschnitt \sectref{sec:4.4.2.1}.}}}} verglichen (Fragestellung [1]):

\begin{table}
\caption{\label{fs:1:1} [1] Fragestellung}
\begin{tabularx}{\textwidth}{QQl}
\lsptoprule
{\textbf{Fragestellung}} & {\textbf{Analyseebene}} & \textbf{Analysemethode}\\
\midrule
{Gibt es einen Unterschied in der Fehleranzahl nach dem Einsatz der KS-Regel im Vergleich zu vor dem Einsatz?} & {{\textbullet} Sprachenpaarebene

{\textbullet} Regelebene

{\textbullet} MÜ-Systemebene

{\textbullet} Regel- und MÜ-Systemebene} & Fehlerannotation\\
\\
\multicolumn{3}{p{\textwidth}}{\textbf{Hypothesen:}}\\
\midrule
\multicolumn{3}{p{\textwidth}}{\textbf{H0} – Es gibt keinen Unterschied in der Fehleranzahl vor- und nach-KS.}\\
\multicolumn{3}{p{\textwidth}}{\textbf{H1} – Es gibt einen Unterschied in der Fehleranzahl vor- und nach-KS.} \\
\lspbottomrule
\end{tabularx}
\end{table}

\section*{Zweiter Analysefaktor: Vergleich der Fehleranzahl vor vs. nach dem Einsatz der KS-Regel außerhalb der KS-Stelle bei einer korrekten Übersetzung der KS-Stelle}

Bei einer korrekten Übersetzung der KS-Stelle sowohl vor als auch nach der KS-Anwendung wird anhand des zweiten Analysefaktors die Fehleranzahl außerhalb der KS-Stelle vor vs. nach der KS-Anwendung verglichen. Ziel hierbei ist es, eine weitere potenzielle Wirkung der Regeln außerhalb der KS-Stelle – trotz der korrekt übersetzten KS-Stelle – einzubeziehen (Fragestellung [2]):

\begin{table}
\caption{\label{fs:1:2} [2] Fragestellung}
\begin{tabularx}{\textwidth}{QQl}
\lsptoprule
\textbf{Fragestellung} & \textbf{Analyseebene} & \textbf{Analysemethode}\\
\midrule
Stieg die Fehleranzahl außerhalb der KS-Stelle nach dem Einsatz der KS im Vergleich zu davor, obwohl die MÜ innerhalb der KS-Stelle sowohl vor als auch nach dem Einsatz der KS richtig waren? & {\textbullet} Sprachenpaarebene

{\textbullet} Regelebene

{\textbullet} MÜ-Systemebene & Fehlerannotation\\
\lspbottomrule
\end{tabularx}
\end{table}

\section*{Dritter Analysefaktor: Aufteilung der Annotationsgruppen}

In der Studie werden die Ergebnisse der Fehlerannotation auf Basis der Existenz und Nicht-Existenz von Fehlern in vier Gruppen unterteilt, bezeichnet als „Annotationsgruppen“. Diese Annotationsgruppen sind: \REF{ex:key:1} RR – MÜ ist vor und nach der Anwendung der KS-Regel fehlerfrei; \REF{ex:key:2} FF – MÜ beinhaltet vor und nach der Anwendung der KS-Regel Fehler; \REF{ex:key:3} RF – MÜ ist nur vor der Anwendung der KS-Regel fehlerfrei; \REF{ex:key:4} FR – MÜ ist nur nach der Anwendung der KS-Regel fehlerfrei. Bei dem dritten Analysefaktor geht es um die prozentuale Aufteilung dieser Annotationsgruppen (Fragestellung [3]):

\begin{table}
\caption{\label{fs:1:2} [3] Fragestellung}
\begin{tabularx}{\textwidth}{QQl}
\lsptoprule
\textbf{Fragestellung} & \textbf{Analyseebene} & \textbf{Analysemethode}\\
\midrule
Wie hoch ist der Prozentsatz jeder Annotationsgruppe? & {\textbullet} Sprachenpaarebene

{\textbullet} Regelebene

{\textbullet} MÜ-Systemebene

{\textbullet} Regel- und MÜ-Systemebene & Fehlerannotation\\
\lspbottomrule
\end{tabularx}
\end{table}

\section*{Vierter Analysefaktor: Vergleich der Fehlertypen vor vs. nach dem Einsatz der KS-Regel}

Durch den vierten Analysefaktor werden nach einer Fehlertaxonomie 13 Fehlertypen vor vs. nach der KS-Anwendung verglichen, um herauszufinden, ob bestimmte Fehlertypen in Verbindung mit der Regelanwendung ab- oder zunahmen (Fragestellung [4]):

\begin{table}
\caption{\label{fs:1:4} [4] Fragestellung}
\begin{tabularx}{\textwidth}{QQl}
\lsptoprule
{\textbf{Fragestellung}} & {\textbf{Analyseebene}} & \textbf{Analysemethode}\\
\midrule
{Beinhaltet die MÜ bestimmte Fehlertypen vor bzw. nach dem Einsatz der KS-Regel?

Davon wird abgeleitet, 

(1)
         ob bestimmte Fehlertypen, die vor dem Einsatz der KS-Regel existierten, nach dem Einsatz der KS-Regel eliminiert bzw. reduziert wurden; 

(2)
         ob bestimmte Fehlertypen erst nach dem Einsatz der KS-Regel erschienen bzw. deutlich stiegen (im Vergleich zu vor dem Einsatz der KS-Regel).} & {{\textbullet} Sprachenpaarebene

{\textbullet} Regelebene

{\textbullet} MÜ-Systemebene

{\textbullet} Regel- und MÜ-Systemebene} & Fehlerannotation\\
\\
\multicolumn{3}{p{\textwidth}}{\textbf{Hypothesen}}\\
\midrule
\multicolumn{3}{p{\textwidth}}{\textbf{H0 – Es gibt keinen Unterschied in der Häufigkeit der einzelnen Fehlertypen vor vs. nach dem Einsatz der KS-Regel.}}\\
\multicolumn{3}{p{\textwidth}}{\textbf{H1 – Es gibt einen Unterschied in der Häufigkeit der einzelnen Fehlertypen vor vs. nach dem Einsatz der KS-Regel.}}\\
\lspbottomrule
\end{tabularx}
\end{table}

\subsection*{Fünfter Analysefaktor: Vergleich der Qualität vor vs. nach dem Einsatz der KS-Regel}

Bei dem fünften Analysefaktor werden die im Rahmen der Humanevaluation vergebenen Qualitätscores vor vs. nach der KS-Anwendung verglichen (Fragestellung [5]):

\begin{table}
\caption{\label{fs:1:5} [5] Fragestellung}
\begin{tabularx}{\textwidth}{QQl}
\lsptoprule
{\textbf{ Fragestellung}} & {\textbf{Analyseebene}} & \textbf{Analysemethode}\\
\midrule
{Gibt es einen Unterschied in der Stil- und Inhaltsqualität der MÜ der KS-Stelle nach dem Einsatz der KS-Regel im Vergleich zu vor dem Einsatz?} & {{\textbullet} Sprachenpaarebene

{\textbullet} Regelebene

{\textbullet} MÜ-Systemebene

{\textbullet} Regel- und MÜ-Systemebene} & Humanevaluation\\
\\
\multicolumn{3}{p{\textwidth}}{\textbf{Hypothesen}}\\
\midrule
\multicolumn{3}{p{\textwidth}}{\textbf{H0 – Es gibt keinen Unterschied in der Qualität vor vs. nach dem Einsatz der KS-Regel.}}\\
\multicolumn{3}{p{\textwidth}}{\textbf{H1 – Es gibt einen Unterschied in der Qualität vor vs. nach dem Einsatz der KS-Regel.}}\\
\lspbottomrule
\end{tabularx}
\end{table}

\section*{Sechster Analysefaktor: Vergleich der Qualität vor vs. nach dem Einsatz der KS-Regel auf Annotationsgruppenebene}

Auf Basis einer Triangulation der Ergebnisse der Fehlerannotation mit denen der Humanevaluation wird bei den einzelnen Annotationsgruppen untersucht, ob die Stil- und Inhaltsqualität vor vs. nach der KS-Anwendung sanken bzw. stiegen. Während ein Qualitätsanstieg bei der Gruppe FR bzw. ein Qualitätsrückgang bei der Gruppe RF erwartet wird, ist es von Interesse zu analysieren, wie die Qualitätsveränderung bei zwei fehlerfreien MÜ (Gruppe RR) bzw. bei zwei fehlerhaften MÜ (Gruppe FF) ausfiel (Fragestellung [6]):

\begin{table}
\caption{\label{fs:1:6} [6] Fragestellung}
\begin{tabularx}{\textwidth}{p{5cm}X@{}p{2.8cm}}
\lsptoprule
{\textbf{Fragestellung}} & {\textbf{Analyseebene}} & \textbf{Analysemethode}\\
\midrule
{Gibt es einen Unterschied in der Stil- und Inhaltsqualität bei den einzelnen Annotationsgruppen nach dem Einsatz der KS-Regel im Vergleich zu vor dem Einsatz?\medskip

Davon wird abgeleitet, 

(1)
         ob bei der Gruppe RR die Stil- bzw. Inhaltsqualität vor bzw. nach dem Einsatz der KS-Regel höher ist, obwohl die MÜ in beiden Fällen fehlerfrei ist; 

(2)
         ob bei der Gruppe FF die Stil- bzw. Inhaltsqualität vor bzw. nach dem Einsatz der KS-Regel höher ist, obwohl die MÜ in beiden Fällen Fehler beinhaltet; 

(3)
         ob bei der Gruppe RF die Stil- bzw. Inhaltsqualität nach dem Einsatz der KS-Regel stieg, obwohl die MÜ nach dem Einsatz der KS-Regel Fehler beinhaltet und davor fehlerfrei war; 

(4)
         ob bei der Gruppe FR die Stil- bzw. Inhaltsqualität nach dem Einsatz der KS-Regel sank, obwohl die MÜ nach dem Einsatz der KS-Regel fehlerfrei ist und davor Fehler beinhaltete.} & {{\textbullet} Sprachenpaarebene

{\textbullet} Regelebene

{\textbullet} MÜ-Systemebene} & Fehlerannotation

Humanevaluation\\
\\
\multicolumn{3}{p{\textwidth}}{\textbf{Hypothesen}}\\
\midrule
\multicolumn{3}{p{\textwidth}}{\textbf{H0 – Bei den Annotationsgruppen gibt es keinen Unterschied in der Qualität vor vs. nach dem Einsatz der KS-Regel.}}\\
\multicolumn{3}{p{\textwidth}}{\textbf{H1 – Bei den Annotationsgruppen gibt es einen Unterschied in der Qualität vor vs. nach dem Einsatz der KS-Regel.}}\\
\lspbottomrule
\end{tabularx}
\end{table}

\section*{Siebter Analysefaktor: Korrelation zwischen den Fehlertypen und der Qualität}

Mithilfe der triangulierten Ergebnisse der Fehlerannotation und der Humanevaluation wird beim siebten Analysefaktor der potenzielle Zusammenhang zwischen den Fehlertypen und der Qualität anhand einer Korrelationsberechnung untersucht (Fragestellung [7]):

\begin{table}
\caption{\label{fs:1:7} [7] Fragestellung}
\begin{tabularx}{\textwidth}{QQQ}
\lsptoprule
{\textbf{ Fragestellung}} & {\textbf{Analyseebene}} & \textbf{Analysemethode}\\
\midrule
{Besteht ein Zusammenhang zwischen der Differenz der Fehleranzahl eines bestimmten Fehlertyps (Fehleranzahl nach KS $-$ Fehleranzahl vor KS) und der Differenz der Stil- bzw. Inhaltsqualität (Qualität nach KS $-$ Qualität vor KS)?} & {{\textbullet} Sprachenpaarebene

{\textbullet} Regelebene

{\textbullet} MÜ-Systemebene

{\textbullet} Regel- und MÜ-Systemebene} & Fehlerannotation

Humanevaluation\\
\\
\multicolumn{3}{p{\textwidth}}{\textbf{Hypothesen}}\\
\midrule
\multicolumn{3}{p{\textwidth}}{\textbf{H0 – Es gibt keinen Unterschied in der Qualität vor vs. nach dem Einsatz der KS-Regel.}}\\
\multicolumn{3}{p{\textwidth}}{ \textbf{H1 – Es gibt einen Unterschied in der Qualität vor vs. nach dem Einsatz der KS-Regel.}}\\
\lspbottomrule
\end{tabularx}
\end{table}

\section*{Achter Analysefaktor: Vergleich der Scores der AEMs vor vs. nach dem Einsatz der KS-Regel}

Die bei der Humanevaluation angegebenen Referenzübersetzungen werden bei der automatischen Evaluation zur Berechnung der AEM-Scores angewendet. Anhand des achten Analysefaktors werden die Scores von TERbase und hLEPOR vor vs. nach der KS-Anwendung verglichen (Fragestellung [8]):

\begin{table}
\caption{\label{fs:1:8} [8] Fragestellung}
\begin{tabularx}{\textwidth}{QQQ}
\lsptoprule
{\textbf{Fragestellung}} & {\textbf{Analyseebene}} & \textbf{Analysemethode}\\
\midrule
{Gibt es einen Unterschied in den Scores von TERbase bzw. hLEPOR nach dem Einsatz der KS-Regel im Vergleich zu vor dem Einsatz?} & {{\textbullet} Sprachenpaarebene

{\textbullet} Regelebene

{\textbullet} MÜ-Systemebene} & Humanevaluation

Automatische Evaluation\\
\\
\multicolumn{3}{p{\textwidth}}{\textbf{Hypothesen}}\\
\midrule
\multicolumn{3}{p{\textwidth}}{\textbf{H0 – Es gibt keinen Unterschied in den AEM-Scores vor vs. nach dem Einsatz der KS-Regel.}}\\
\multicolumn{3}{p{\textwidth}}{\textbf{H1 – Es gibt einen Unterschied in den AEM-Scores vor vs. nach dem Einsatz der KS-Regel.}}\\
\lspbottomrule
\end{tabularx}
\end{table}

\section*{Neunter Analysefaktor: Korrelation zwischen den Differenzen der AEM-Scores und der Qualitätsdifferenz}

Auf Basis einer Triangulation der Ergebnisse der Humanevaluation mit denen der automatischen Evaluation wird beim neunten Analysefaktor der potenzielle Zusammenhang zwischen den Differenzen der AEM-Scores und der Qualitätsdifferenz anhand einer Korrelationsberechnung analysiert (Fragestellung [9]):

\begin{table}
\caption{\label{fs:1:9} [9] Fragestellung}
\begin{tabularx}{\textwidth}{QQQ}
\lsptoprule
{\textbf{ Fragestellung}} & {\textbf{Analyseebene}} & \textbf{Analysemethode}\\
\midrule
{Besteht ein Zusammenhang zwischen der Differenz der Scores von TERbase bzw. hLEPOR (Mittelwert der Scores nach KS $-$ Mittelwert der Scores vor KS) und der Differenz der allgemeinen Qualität (Qualität nach KS $-$ Qualität vor KS)?} & {{\textbullet} Sprachenpaarebene

{\textbullet} Regelebene

{\textbullet} MÜ-Systemebene} & Humanevaluation

Automatische Evaluation\\
\\
\multicolumn{3}{p{\textwidth}}{\textbf{Hypothesen}}\\
\midrule
\multicolumn{3}{p{\textwidth}}{\textbf{H0 – Es besteht kein Zusammenhang zwischen der Differenz der AEM-Scores und der Differenz der allgemeinen Qualität.}}\\
\multicolumn{3}{p{\textwidth}}{\textbf{H1 – Es besteht ein Zusammenhang zwischen der Differenz der AEM-Scores und der Differenz der allgemeinen Qualität.}}\\
\lspbottomrule
\end{tabularx}
\end{table}

\section{\label{Toc51705131}{}{{Struktur der Studie}}}

Nachdem der Hintergrund der Arbeit, die Motivation zur Untersuchung, das Ziel sowie die Fragestellungen und Hypothesen der Studie in diesem Kapitel demonstriert wurden, folgen die drei Hauptteile der Arbeit: 

Der erste Hauptteil beschäftigt sich mit der theoretischen Grundlage der Kontrollierten Sprache (Kapitel 2) und der Maschinellen Übersetzung (Kapitel 3). In Kapitel 2 wird auf die Definition, die Ziele, den Aufbau und die Entwicklung der KS näher eingegangen. Anschließend erfolgt eine detaillierte Betrachtung des Kontrollierten Deutsch bzw. der tekom-Leitlinie als Basis für das Untersuchungsobjekt der Arbeit. Daraufhin werden die Stärken und Schwächen der KS diskutiert. Zum Schluss werden die CL-Checker und ihre Funktionsweise beschrieben. Kapitel 3 beginnt mit einer Erläuterung des MÜ-Begriffs und dem Motiv eines KS-Einsatzes im Kontext der MÜ. Anschließend wird die Entwicklung der MÜ und ihrer Ansätze dargestellt. Darauffolgend befasst sich das Kapitel mit der Thematik der MÜ-Qualität sowie den verschiedenen Methoden der MÜ-Qualitätsevaluation und dem Evaluationsdesign. Zum Schluss werden MÜ-Studien im Kontext der KS diskutiert.

Der zweite Hauptteil widmet sich der angewandten Methodologie (Kapitel 4). Zunächst wird die Forschungsmethodik gefolgt von der Operationalisierung und der Validität der Arbeit genauer erläutert. Im Abschnitt Studiendesign wird die Auswahl des analysierten Sprachenpaars, der untersuchten Regeln und MÜ-Systeme sowie der Aufbau des Datensatzes ausführlich dargestellt. Zudem werden die methodischen Überlegungen und Testläufe, die zum Design der drei implementierten Evaluationsmethoden geführt haben, sowie die Vorgehensweisen und schließlich die Struktur der Ergebnisse der durchgeführten Analysen detailliert präsentiert.

Der letzte Hauptteil der Arbeit befasst sich mit den Studienergebnissen und umfasst Kapitel 5 und 6. In Kapitel 5 werden die Ergebnisse auf vier Analyseebenen in drei Unterkapiteln darstellt: Im ersten Unterkapitel werden zunächst der Datensatz zusammen mit den Ergebnissen einer allgemeinen Analyse der Entwicklung der MÜ-Qualität, des Interrater- und Intrarater-Agreements sowie der Profildaten der Teilnehmer präsentiert. Zudem ist eine Darstellung der Ergebnisse auf Sprachenpaarebene in diesem Unterkapitel vorgesehen. Im zweiten und dritten Unterkapitel werden die Ergebnisse auf Systemebene bzw. auf Regelebene sowie auf Regel- und Systemebene demonstriert. Abschließend liefert Kapitel 6 eine Zusammenfassung sowie eine Diskussion der Studienergebnisse. 

Abschließend folgt das Fazit in Kapitel 7, in dem die Schlussfolgerungen dargestellt und die Implikationen rück- und ausblickend demonstriert werden, zudem erfolgt eine Präsentation des Beitrags, der Einschränkungen der Studie sowie von Ideen zur Anregung von zukünftiger Forschung; durch das Schlusswort wird die Arbeit abgerundet. Das Literaturverzeichnis und die Anhänge machen die verbleibenden Elemente aus.

