\documentclass[output=paper]{langscibook}
\ChapterDOI{10.5281/zenodo.14922287}


\author{Dorothy Kenny\orcid{0000-0002-4793-9256}\affiliation{都柏林城市大学}}
\title{人工翻译和机器翻译}
\abstract{本章旨在向读者介绍何为人工翻译和机器翻译。作者不仅试图拨开翻译的迷雾，还强调译者在创造原文与译文之间对等关系中发挥的重要作用。本章的根本目标是帮助读者理解人工译文如何成为机器翻译的训练数据。此外，本章还从系统类型和输出用途两个方面区分机器翻译。作者还特别指出，当代机器翻译是人工智能的分支——机器学习，更确切地说，是深度学习的应用。}

\begin{document}
\maketitle

\section{何为翻译？}\label{sec:kenny:1}
本书以机器翻译为题，简要定义为由计算机程序完成的翻译。但这一定义仍然无法回答“何为翻译”。其实，已有大量翻译学学者对此进行深入研究，并探究翻译在文化、科学和政治等领域中的作用。翻译学研究内容丰富，无法在此详述，欲深入了解的读者可参考\citet{Baker2020}。本章采用的是大多数评论家都认可的定义，即翻译是基于一种语言（即源语）的文本而产生的另一种语言（即目标语）的文本。“文本”的概念很重要，指的是真实的口头或书面语言的使用。一般来说，文本应符合以下标准：连贯一致且正确“组合”；用途明确，即便只是一句用于问候的“你好”。此外，文本还应符合特定语言和交际场景的需求。例如，本章作为一本供教学使用的英语论文集章节，应该满足读者的相关期待。本章内容围绕特定主题或领域（即机器翻译）展开，并遵照特定体裁（即教材）惯例撰写。

在翻译界人士看来，“翻译关乎文本”这一观点是已是老生常谈，无需多言。但对于不太了解翻译的人群，我们想提请注意，翻译的对象是文本，而非语言。语言是个庞大且复杂的抽象系统，在人类交流和表达中的使用有无限可能；文本则是语言使用的具体实例，通常有可识别的起止点。即便脱离语境而孤立使用的语言看似潜力无限，会出现无法预知的含义或较大歧义，但这种潜力在特定文本中会大大减弱。例如，英语中的\emph{shower}一词有以下含义：（1）阵雨；（2）淋浴设备；（3）送礼会，因此在法语等语言中会有不同译法。但如果我们正在为浴室配件制造商翻译淋浴器安装指南，就不用担心一词多义的问题。这种情况下，该词应取第二种含义，除非作者在玩文字游戏（但不可能出现在这种体裁的文本中）。关注文本而非语言，可以让翻译更贴近实际情况且易于处理。

上述翻译定义的第二个要素是，翻译的文本产出基于另一个已存在的文本。这说明，翻译涉及源语文本和目的语文本之间的关系\footnote{显然，该定义的第三个要素是，源语文本和目的语文本为两种不同的语言。因此，我们关注的是\textit{语际翻译}（interlingual translation）。有些学者，最著名的是雅柯布逊\citet{Jakobson1959}，认为还存在其他类型的翻译，如语内翻译（intralingual translation）和符际翻译（intersemiotic），但这些翻译类型不在本章的讨论范围内。} 还有些学者就该问题展开了更深入的论述，认为这种关系还意味着具有“相同意义”（same meaning），但许多哲学家和语言学家对“意义”的理解诚然更复杂深入，他们避免称翻译具有“相同意义”。这是因为，文本的意义难以与创造和使用的情境剥离开来。我们可以认为意义就是作者或说话人想表达的意思，但我们常常无法明确他们的真正意图；也可以将意义与自己对文本的阐释联系起来，但不得不承认，对同一文本，其他人的阐释会有所不同。翻译还会产生的问题是，一个完全合理的译文，其意义可能比源语文本更多或更少，而这只是目的语的要求使然。

下面来看个例子。最近出版的一本回忆录\citep{Tammet2006}的开篇如例（1）所示：

\ea
I was born on 31 January 1979 – a Wednesday.（我出生于1979年1月31日，一个星期三。）
\z

其法语译文\citep{Tammet2009}见例（2）：

\ea
Je suis né le 31 janvier 1979. Un Mercredi.
\z

尽管这两句话几乎词词对应，但实际上，法语译文传达的信息要比英语原文多。从法语译文可以看出，原文作者\textit{I}是男性，因为如果是女性，那么例（2）中的正确用词应该是\textit{née}，而不是\textit{né}。法语中一些动词在特定时态下的变位形式必须标注主语的性别。

可是，法语译者又从何得知，原文中的“我”是男性呢？毕竟，这是该书开篇的第一句话。不过，这是本回忆录，根据此类体裁的惯例，叙述者即作者，而译者也知道该书作者是谁，这在翻译合同和书的封面上都写着。因此，尽管英语原文有时并未说明某人的性别，译文还是得明确指出性别信息，不过，这对译者而言并非难事。虽算不上是问题，但这个简单的例子还是反映了两个重点：第一，如上文所述，译文的信息有时比原文更多；第二，有时无法从原文语句中获取翻译该句子所需的信息。相反，译者应该关注（1）范围更大的文本，有时也称为\emph{共现语篇(co-text)}，即与给定语段相关的文本，例如封面；（2）\textit{语境(context)}（此处理解为与文本相关的更大范围的语境），以找到解决办法。

还有些时候，译文包含的信息比原文的多，其原因不在于目的语，而在于体裁。在一项针对计算机辅助设计工具的用户界面研究中，\citet{Moorkens2012}发现，英语标题\textit{Selecting}（选择）的译文通常明确指出所选择的对象，因此该词有不同译法。以下例子为译文到英语的回译：

\ea selection of polygon（选择多边形）
\ex selection of line（选择线条）
\ex selection of ellipse（选择椭圆形）
\ex selection of rectangle（选择矩形）
\z
等等。

这种译文表达信息比原文多的情况并不少见。当然，反之亦然，若译文无法表达原文所有信息，译者可以选择省略部分信息。这种情况的出现有时与语言类型相关。例如，英语经常使用动词来描述某物或某人移动的方式（manner），而西班牙语则倾向于用动词来描述行动的路径（path），使用状语短语来表示移动方式，但西语译者有时选择不翻译这种移动方式，以免刻意且生硬的表达。具体可参考\citet{Slobin2003}给出的例句（7）和（8）。英语动词stomped意指“迈着沉重步子”的走路方式，而西语动词salió只表示该人物离开房子的这个动作。

\ea He stomped from the trim house（他踩着重步走出整洁的房子）
\ex Salió de la pulcra casa（走出整洁的房子）
\glt `exited from the trim house.'
\z

例（8）的西语句子比例（7）的英语句子还少了一处信息，即前者没有使用与英语单词he对应的主语代词。这是因为西班牙语属于代词脱落语言（pro-drop language），可省略主语代词，而这些代词所含的大部分信息都可根据动词词尾获知。如例（8）的salió为动词过去式的第三人称单数，与例（7）相比，例（8）缺少了主语性别。但西班牙语读者可以从前文获知主语的性别信息（男性），而不是对此浑然不知。所以，省略代词的译法既遵照了目的语语言规范，又没有造成小说读者的阅读障碍。

上述论点和例句旨在说明，为什么很多学者不赞同译文与原文的意思相同。我们更认同的说法是，译文接近原文。出于各种各样的原因，译者必须决定翻译时优先考虑什么，需要表达什么，以及应该让读者自己去弄懂什么。\footnote{我们所示的例句主要源于语言系统之间的差异，但译者可能考虑到文化因素而省略或更改原文的细节，以免读者看到不熟悉的引用感到困惑，甚至是为了避免冒犯读者或审查人员。译者还可能受到篇幅限制，如字幕翻译。}译者帮助译文读者自行构建的意义，可能在很大程度上与源语文本的读者构建的意义相一致，但在许多情况下，二者并不完全相同。一般来说，这不是什么问题。

可是，如果源语文本和目的语文本之间（或更可能只是文本中的语段）并不是“意思相同”的关系，那又是什么呢？有人称之为“对等(equivalence)”关系。翻译学对“对等”这一术语的研究历程堪称跌宕起伏。但如果它被认为是译者决策使然的关系（即两个文本语段之间的关系），因为译者认为两个文本在各自的共同文本和语境中具有同等价值，那么完全可以用“对等”来描述原文和译文的关系。也就是说，例（7）的“salió”与例（8）的“he stomped”对等。显然，这种对等关系不会一成不变，也不可能用于“stomped”一词的所有其他语境，但如果我们认为在该语境下，“salió”与“he stomped”对等，这点便无关紧要。\footnote{翻译学者Anthony Pym在其研究中提出了基于交换价值的对等概念，可参见\citet{Pym2010}。}

\section{翻译难在何处？}
关于机器翻译的书通常以讨论翻译的难点开篇，聚焦于上文提及的单语歧义和语言系统的差异。语际差异还可见于在两种语言的对等句子中，句义在词中分布不同。如摘自欧洲议会会议记录的例句（9）和（10），英语用动词“like”来表达“喜欢”，而喜欢的对象则使用“working with you”作为动词“like”的补语来表述。但德语用动词“kooperiere”来表达喜欢的对象，而“喜欢”则用副词“gern”来表达。

\ea I like working with you.（我喜欢跟你合作。）
\ex Ich kooperiere gern mit Ihnen.（我高兴地跟你合作。）
\glt ‘I cooperate happily with you.
\z

这类例子展示了英语和德语表达心理状态的不同方式，但该差异并非翻译难点，至少对人类来说是如此。具备初级英语水平的德语使用者可以毫不费力地翻译出例句（9）。语言之间的非同构性（Non-isomorphism），即语言的结构方式不同，本身不会给译者带来翻译困难。

另一种很棘手的语言现象是不连续的依存关系（discontinuous dependencies），即由两个单词组成的短语被一个或多个单词隔开。例如，例（11）中“Send”和“back”相当于“return”单个词项的意义。不过，掌握基础英语知识的读者通常能够正确理解。

\ea
Send your certificate of motor insurance back.（把你的汽车保险凭证寄回来。）\footnote{在本例句中，动词短语“send back”中间有五个单词，是英国国家语料库（ British National Corpus）中最长的不连续短语动词例子之一。}
\z

另一个常见的翻译难题是习语。在本文中，“习语”是指无法根据其构成词语来推断意思的短语。换句话说，习语具有非组合特性（non-compositional），如本章\ref{sec:kenny:1} \textbf{第一节}中的例子“old hat”，意指所论之事为人熟知，已是老生常谈。这个短语与帽子毫不相干。和其他类型的修辞语一样，习语有时会给不了解该表达的读者造成困惑，不能望文生义。但是，即使阅读本章第一次看到“old hat”时并不理解其意思，你或许还是能推断出，讨论内容与帽子无关，不应按字面意思来理解这个短语。如果遇到不懂的习语，译者认为它应该是收录在词典中的常用表达，只需查一查在线词典即可。换句话说，虽然习语具有非组合特性和修辞作用，但仍属于约定俗成的表达。尽管译者遇到翻译难题，也就是说其翻译节奏被打断，但问题并不难解决。而找到解决方法，很可能会给译者带来极大的满足感（和所有语言学家一样，译者也乐于学到工作语言的新知识。）

但有时，就连经验丰富的译者也坦言会在翻译技术性强且了解不足的文本时犯难。法律专业出身或从事法律工作的译者可能喜欢法律翻译，而汽车工程师对此则望而却步。此外，即便是自己熟悉的领域，译者也会遇到质量低下、不完整或极难理解的原文。他们或许能够理解原文，但要在目的语中找到恰当的术语来表示原文的专业概念，这却是个很大的挑战。交稿日期太紧迫或软件程序故障，也都是可能让专业译者犯难的因素。不过，我们很少听到专业译者抱怨歧义、非同构性、不连续依存现象或非组合性的语言现象对他们造成困扰。

当然，在讨论机器翻译时，这些现象之所以被常提起，是因为它们在某些情况下会给机器带来问题。

\section{译者通常如何解决翻译问题？}
前文讨论了专业译者有时会在现实场景中遇到的问题。现在，我们一起来看看译者在翻译过程中还会有哪些困难。在无法理解原文，或者不知道如何用目的语表达某个术语，又或者难以用目的语来阐述某个意思的时候，专业译者通常先将手头的文本放一边，转而查看资料。例如，译者想要了解废水处理的细节时，可能会浏览各个地方政府网站，看看他们如何解释相关技术，可能在开放术语库找到特定术语的译法，还可能会查阅客户公司的其他文件或咨询工程师。译者还可以请教同事，或者在翻译论坛求助。最重要的是，大多数译者都意识到自己在专业知识上有所欠缺或需要灵感，从而认真研习以查漏补缺，努力解决问题，继续完成翻译任务。

你可能会问，为什么一本介绍机器翻译的书，却着力叙述人工翻译过程。原因有二：首先，真实的人工翻译过程（详见\citetv{chapters/rossi}）可为机器翻译设定评估标准，一切有助提升人工翻译质量的方法也能用于改善机器翻译质量。同样，人工翻译过程可以突显机器翻译偶尔出现的缺陷。换句话说，人工翻译有助于机器翻译的质量评估和错误诊断。其次，也是更重要的一点，目前大多数机器翻译系统都以人工翻译为基础学习如何翻译。下文将对此进行详述。

在结束对人工翻译过程的讨论前，我们还要介绍一项对许多译者来说不可或缺的技术——翻译记忆库。


\section{翻译记忆库}\label{sec:kenny:4}
20世纪90年代，蓬勃发展的软件本地化行业的翻译人员发现，他们翻译的文本要么自身重复率高，要么有大段内容与同一文档的早期版本相同，如软件使用手册，只要软件推出新版本，手册也必须随之更新。译者并不会像翻译全新文本那样，从头开始翻译每个句子，而是开发出被称为“翻译记忆”的工具，用于存储翻译过的文本，以便重复使用。该工具被称为“翻译记忆库”，将新导入的原文分成句段（句子或其他有意义的翻译单元，如标题或表格的单元格），然后将这些句段与记忆库中的源语言句段进行比较。如果找到完全匹配或非常相似的句段，那么相应的目的语句段会被调出供重复使用，译者可以对其进行或不做修改。译者在翻译新文本时，可以使用翻译记忆库，接受、拒绝或编辑现有译文，并在翻译过程中更新记忆库，为没有匹配结果的源语句段添加自己的译文。随着时间的推移，翻译记忆库变得越来越大。有些较早开始使用该技术的公司创建的翻译记忆库含有数十万甚至数百万“翻译单元”（translation units），即源语和目的语对齐的平行句段。例（12）为某个标题的翻译单元（英语-德语），摘自由欧洲议会官网数据组成的翻译记忆库，格式为tmx（translation memory exchange，翻译记忆库交换）。\texttt{<tu>}和\texttt{</tu>}元素表示翻译单元的起始，\texttt{<tuv>}和\texttt{</tuv>}元素表示翻译单元变体（variant），\footnote{本例中的第一个变体是英语（“EN”），第二个是德语（“DE”）。}\texttt{<seg>}和\texttt{</seg>}元素则表示相应语言的句段或文本字符串。

\ea\ttfamily
<tu>\\
<tuv xml:lang=“EN">\\
<seg>A common blacklist for unsafe airlines</seg>\\
</tuv>\\
<tuv xml:lang=“DE">\\
<seg>Unsichere Luftfahrtunternehmen kommen auf eine schwarze Liste</seg>\\
</tuv>\\
</tu>\\
\z

私营翻译企业也积累了大规模的翻译记忆库，这些宝贵的语言资产有利于控制翻译成本和提高竞争力。欧盟机构等国际组织也采用这项技术，创建了庞大的多语言翻译记忆库，并免费提供给计算机科学家，用于自然语言处理研究。

虽然翻译记忆库最初的作用之一是提高人工翻译的工作效率，但最终也有助于提高翻译行业的自动化。一方面，翻译记忆库可产出海量翻译数据，且数据格式便于机器翻译研发使用（见下文），另一方面，用于管理记忆库的工具还提供编辑环境，译者不仅可以编辑记忆库的人工翻译，还可以编辑机器译文。

翻译记忆库可以算是特殊的平行语料库，即句对齐的原文和译文构成的语料集合。即便在翻译过程中并未使用翻译记忆库，也可以在翻译之后再将译文与原文对齐。例如，使用多种语言的欧洲议会的会议记录译文可从网站上获取，对齐后创建多语言Europarl语料库\citep{Koehn2005}，这继而又极大推动了机器翻译研究。对齐的平行语料库不必是tmx格式，而是通常采用具有数千（甚至数百万）行的文档形式，每行一个句段。源语句段在源语文档中的位置，与其译文在目的语文档中的位置一一对应，因此，目的语文档的第\textit{x}行为源语文件第\textit{x}行的翻译。

\section{何为机器翻译？}
根据本章开篇给出的定义，机器翻译是指在源语文本的基础上，自动生成目的语文本的过程。与其他类型的翻译一样，我们也期待该目的语文本的阐释与源语文本的大致相符。不得不承认的是，人工翻译可能会与原文意思有些许差异，所以我们也应该允许机器翻译出现类似情况。重要的是，源语文本和目的语文本之间的明显差异，例如，日语比英语提供的信息更多，应该是由语言对、体裁或其他合理的原因引起的。

机器翻译是出现在二战后的、数字计算机的首批非数字应用之一。以今天的标准来看，早期的自动化翻译似乎很简陋，但必须承认的是，在20世纪50年代和60年代，研究者能使用的资源极其有限\citep{Hutchins2000}。到了20世纪60年代末和70年代，自动翻译系统主要用于国防、政府和国际组织，直至20世纪末才开始大规模商用。1997年，美国搜索引擎AltaVista推出免费在线机器翻译工具“宝贝鱼”（Babel Fish），当时的用户达数百万人。随后的几十年里，互联网发展迅速，目前用户约有46.6亿人\citep{Johnson2021}。据报道，截至2016，最著名的免费在线机器翻译系统“谷歌翻译”的用户超过5亿人，每天翻译超过1000亿字，支持103种语言 \citep{Turovsky2016}。\footnote{截至2022年5月，谷歌翻译支持133种语言，但不同语言的支持深度和翻译质量有所不同。\citep{Caswell2022}。}例如，与谷歌搜索或微软必应等搜索引擎相结合，机器翻译可用来扩大搜索范围，然后将相关的外语网页译成用户的母语。

但机器翻译并不仅用于网页，还可以与自动语音识别和语音合成，或光学字符识别和数字图像处理等技术结合使用，让用户能使用两种以上的语言进行口语对话，或看懂不熟悉的语言体系的路标。通常，用户只需使用安装在手机里的翻译应用软件即可，这些软件如今甚至能离线使用，可以说是名副其实的口袋式机器翻译系统。而机器翻译也越来越多地用于以前被认为超出其技术能力范围的领域，如视听翻译，将外语电影和电视剧的字幕翻译成其他市场受众的语言。事实上，订阅视频流媒体服务的蓬勃发展是基于一种模式，这种模式将鲜为人知的“长尾”标题展示给新观众，而这些标题之所以不那么为人熟知，是因为最初用外语书写。因此，视听内容正成为众多商业产品中的最新产品，可以通过机器翻译来扩大其市场。自诞生以来的大约70年里，机器翻译已经从政府和国际组织的专享技术，变成了大众消费品。

尽管机器翻译在上述情况下的作用毋庸置疑，并且在人道主义领域\citep{Nurminen2020}等场景中也有用武之地，但仍存在一些不足。首先，和人工翻译一样，机器翻译也会出错。这些错误可能无伤大雅，也可能后果严重（如医疗保健、新闻翻译或国际外交等领域）。因此，大量研究致力于“评估”机器翻译系统的质量，“测评”机器译文，通过“译后编辑”来提高译文质量，或在进行机器翻译之前预先对原文进行加工，使其更易翻译，从而改善译文质量，这一过程称为“译前编辑”。这些研究领域将在本书的第3章到第5章中详细讨论。机器翻译也引出了大量的道德和法律问题，\textcitetv{chapters/moorkens}讨论了伦理问题，\textcitetv{chapters/carre}也略微涉及机器翻译对语言学习者的影响。

许多临时用户可能认为，这些方面的考虑对自己的机器翻译需求来说并非必要的。这在某些使用场景下确实如此，例如只想借助机器翻译理解文本主旨或了解网页的基本内容。在机器翻译的范畴内，此类用途通常称为“同化”（assimilation），一般涉及低风险且供个人使用的翻译文本，几乎不存在名誉受损等风险。但是，如果想借助机器翻译达到“传播”（dissemination）目的，例如用第二语言来发布博客、进行商业推广，那么明智的做法是了解潜在风险，甚至有必要采取降低风险的措施。这种能力是“机器翻译素养(machine translation literacy)”的要素之一\citep{BowkerCiro2019}。其他要素还包括基本了解机器翻译的运行原理及其使用对社会、经济和环境具有哪些更广泛的影响。这些知识看似深奥，但实际上是可迁移的技能，因为现代机器翻译与许多其他技术都基于相同的原则，这些技术深刻改变了现代生活的很多方面，尤其是我们的工作方式。简而言之，目前的机器翻译在很大程度上是机器学习的应用，更具体地说是深度学习的应用。我们会在下文详细解释这些概念，\textcitetv{chapters/perez}也会深入介绍神经机器翻译的运行原理。如果你是翻译专业的学生、职业译者或在翻译行业中担任其他职务，那么你可能迫不及待想要打开机器翻译系统的“黑匣子”。或想了解如何通过定制，以最大化地让机器翻译系统为己所用。这些方面的讨论参见\textcitetv{chapters/ramirez}。接下来，我们一起了解机器翻译为何被称作“引领语言学家进入机器学习这一奇妙世界的‘大门’”。


\section{人工智能、机器学习与机器翻译}
如今的机器翻译经常伴随很多其他相关概念出现，如人工智能、机器学习、人工神经网络和深度学习，非专业人士很难区分其中某些概念。\cite{deeplearningbook}等借助维恩图来展示这些概念之间的关系。在上述概念中，人工智能包含的范畴最广，用最大的圆圈表示，通常被定义为计算机科学的分支，旨在创造机器，更具体地说是计算机程序，来解决通常需要人类智能的问题。这种机器不一定要像人类一样“思考”，但要像人类一样“行动”。它们可能只专注于特定问题，比如识别人脸，被称为“狭义人工智能”，或说得不好听，就是“弱人工智能”。而所谓的“强人工智能”则让人更加充满期待。它涉及“通用人工智能”（即机器会拥有类人智能、自我意识以及学习和规划未来的能力），或“超级智能”（即超过人类能力的智能）。可以说，产出比肩人类译者的翻译需要依赖强人工智能，但机器翻译系统目前并不具备这种智能。

\subsection{基于规则的机器翻译}
应对人工智能开发的挑战的一种方法是，给计算机程序输入解决特定问题所需的一切知识，并运用这些知识的规则。以机器翻译为例，给程序输入源语和目的语的所有单词列表，以及连词成句的规则；然后，规定两种语言的单词和结构如何相互匹配，并向机器提供如何使用这些信息来翻译句子的逐步指令（即“算法”）。这种方法被称为“基于规则的机器翻译”（rule-based machine translation, RBMT），在本世纪初之前一直占据主导地位，如1997年首次推出的免费在线机器翻译正是基于RBMT\citep{Joscelyne1998}。然而，RBMT存在很多问题，如需要高水平的语言学家为每个语言对编写规则，因此开发成本昂贵。此外，和其他基于知识的人工智能方法一样\citep{deeplearningbook}，RBMT也受到知识瓶颈的制约：在许多情况下，根本无法预测使RBMT系统如愿运行所需的一切知识，无论是语言知识，还是与更广大世界有关的知识，即所谓的“现实世界知识”。\footnote{在撰写本书时，尽管RBMT已经不再占据主导地位，但仍用于少数机翻系统，尤其针对密切相关的语言之间的翻译，例子可参见Apertium \citep{Forcada2011}。}

\subsection{数据驱动的机器翻译}
此类机器翻译运用到了机器学习技术。机器学习的基本原理是，与其向计算机程序输入所需知识，不如让其自行获取。要做到这点，机器可以通过观察待解决问题以往的解决方案。我们已经了解到，如何借助翻译记忆库和其他平行语料库来存储翻译单元的语段，从而实现待译文本的已存译文抓取。这些翻译单元组成了“训练数据”，供现代机器翻译系统学习。因此，这类通常被归为“数据驱动型”系统。“从数据中学习”正是机器学习与其他类型人工智能的不同之处。

数据驱动的机器翻译还可进一步划分为“统计机器翻译”(statistical machine translation)和“神经机器翻译”(neural machine translation)，对此下文均有详细介绍。

\subsection{统计机器翻译}
统计机器翻译（SMT）系统依靠训练数据可构建两大类统计模型。\footnote{统计模型是被观察数据的数学表征。}第一类是双语“翻译模型”，即训练数据的源语单词和短语及其目的语译文一一对照形成表格，以及每种译法的概率。这种表格叫做“短语表”。\tabref{tab:1:n-grams}为短语表的摘选例子。\footnote{这个例子被大大简化了，因为它只展示了从意大利语到英语的合理译法。实际上，SMT系统会学习包含许多无意义配对的翻译模型，不过其中大多数的概率很低。此外，还要给从未见过的译法保留一些概率。}

\begin{table}
\caption{选自短语表，展示了短语\textit{a me piace}在Europarl语料库中的不同译法及其出现概率}
\label{tab:1:n-grams}
 \begin{tabular}{l rrc}
  \lsptoprule
            & 英语 & 概率\\
  \midrule
  a me piace  &   I like  &    0.78\\
  a me piace  &   I should like to  &    0.11\\
  a me piace  &   I admire  &    0.11\\
  \lspbottomrule
 \end{tabular}
\end{table}

然而，在这里使用“短语”一词有些不恰当，因为所讨论的字符串不一定对应于语言学领域的“短语”，而是$n$元组(gram)，即在训练数据中连续出现的一个、两个、三个或$n$个单词的字符串。例如，在前面的句子中，“appear contiguously”是二元组，而“appear contiguously in”是三元组。

SMT需要从数据中学习的第二类统计模型是“语言模型”，即目的语的单语模型（或模型组合），同样基于$n$元组。假设已知前两个单词，那么三元组的目的语语言模型可以算出第三个特定词出现的概率。例如， 基于Europarl语料库训练的三元组模型，可以算出“gorgonzola”出现在“I like”之后的概率为0.024，这说明尽管“I like gorgonzola”确实出现在训练数据中（共4次），但除“gorgonzola”之外的许多词出现在“I like”之后的概率更大。\footnote{此处和\tabref{tab:1:n-grams}中使用的Europarl版本可通过点击Sketch Engine的界面链接\url{sketchengine.eu}访问。}   

在SMT系统中，翻译模型主要捕捉有关如何将单词和$n$元组译成目的语的知识，而语言模型则首先告诉你哪些是目的语的常见用词或短语。从目前的角度来看，这种方法的核心在于语言学家不必自行构建这些模型。模型由机器在训练阶段直接从数据中学习而得。到了第二阶段，即“调优”阶段，系统开发人员计算出应该分配给每个模型的权重，以获得最佳输出。一旦训练和调优完毕，系统就可以翻译训练数据以外的源语语句。在SMT系统中，翻译（相对于“训练”）被称为“解码”，在这一过程中，系统会为输入的句子生成数千个候选译文，并基于某个源语语句、系统已学习的模型以及系统分配权重的情况下，计算哪个译文出现的概率最大。

截至2015年，SMT作为最先进的机器翻译技术的地位至少保持了十年之久。与之前的RBMT系统相比，SMT取得了技术上的飞跃，但也存在许多缺陷，主要原因是使用了相对较短的$n$元组来建模，且系统将一个句子拆成孤立的n元组后分开翻译。SMT尤其不擅长处理黏着语和高度屈折性语言。其他不足还包括单词丢失（word drop，即某种语言体系无法翻译某个单词）、译法不一致（即同一个源语单词在译文中对应两种译法，有时甚至在同一句子中出现不同译法）。到了2015年，SMT已经被同为数据驱动的另一种方法所取代，也就是上述的“神经机器翻译”，这一技术转向的完成只花了两年时间。

你可能觉得奇怪，既然SMT已经过时了，为什么还要在此提及呢？其实，我们是想借此将读者引入机器学习领域。SMT表明了，从数据中学习的机器翻译系统比其他系统的性能更好，从而为机器学习方法在机器翻译中的运用铺平了道路。另外，SMT开发者为机器翻译研究做出了重要贡献，比如通过提倡新方法和共享程序代码，以及从双语和多语的议会、国际组织、万维网等渠道收集翻译数据，并与全球的研究者共享数据，为机器翻译研究做出了显著贡献。还应注意的是，尽管范围有限，但SMT在翻译行业中仍有运用。例如，机器翻译服务供应商可能会先创建SMT系统来检验项目的可行性，再看看是否值得继续投入时间和精力开发神经系统。

然而，我们之所以讨论SMT，主要是想说明从数据中学习的方法不止一种\footnote{其实，我们几乎没有讨论SMT系统的具体学习算法。感兴趣的读者可参阅\citet{Koehn2010}。}，更重要的是，就本章的目的来说，这些数据不止有一种表征方法。我们已在前文看到，SMT借助短语表来表示翻译知识，还借助单独的n元组模型来表示目的语知识。在这些模型中，单词（和单词串）仍保留自身形态，但最重要的是，它们通过概率相互关联。正是这些概率让机器翻译系统得以运行。某个目的语句子是某个源语句子的译文的概率，只需在短语表中找到组成该句子的各个$n$元组的翻译概率，然后将概率相乘即可。此外，某个目的语句子出现的概率也可以通过计算组成该句子的各个$n$元组的概率乘积得到，如从单语语言模型找出每个n元组出现的概率并计算乘积。然后，用一个方程将不同的模型组合在一起，以计算出概率最大的译法。\footnote{此处所指的方程基于贝叶斯定理，SMT有助于翻译学者初步了解“贝叶斯优化”的机器学习方法。}

本文介绍SMT的另一个原因是方便引出一些概念，如“n元组”。如\textcitetv{chapters/rossi}所述，“n元组”这一概念对自然语言处理的其他领域，特别是机器翻译测评来说极其重要。


\subsection{神经机器翻译}
2004年至2014年是SMT发展的全盛时期。机器翻译的大多数主要用户和供应商，包括谷歌翻译（始于2007年）和欧盟委员会（始于2010年），在此期间都使用这项技术，并且在“共享任务评估”（shared task
evaluations）\footnote{在共享任务评估中，计算机科学家选定某个语言对并使用不同类型的训练数据，从而对比看哪个系统的表现最好。}中，SMT不断取得喜人的成果。直到2015年，斯坦福大学开发了神经机器翻译（neural machine translation, NMT），不仅以明显优势击败了许多SMT系统，还能应用于难以处理的语言对，如英语-德语\citep{Bentivogli2016}。斯坦福大学的成功宣告\citet{Bentivogli2016}所谓“NMT新时代”的到来。研究人员和媒体对此的兴奋之情溢于言表。例如，媒体大肆宣扬这项新技术，称其可与职业译者相提并论，已经达到了“与人类同等的水平”。\footnote{这一说法由一直致力于中文-英语语言对的微软研究人员提出\citep{Marking2016}。包括\citet{Toral-etal-2018}在内的许多评论家都对此提出了质疑。} 还有人声称，NMT不仅可以学习“惯用表达和隐喻”，还可以“在另一种语言中找到文化对等表达，而不是直译”\citep{Marking2016}。\footnote{这些评论是脸书的艾伦·帕克(Alan Packer)在2016年发表的 \citep{Marking2016}。} 尽管这么说确有几分道理，但不应被过度解读。NMT系统的确可以翻译惯用表达，但这通常是因为它的学习数据中含有数百甚至数千个该翻译的例子。NMT系统（本例使用了谷歌翻译）在正确翻译德语的习语时，并不“知道”这是惯用表达，也不知道自己使用了文化对等表达：

\ea
Ich habe die Nase voll.
\glt ‘I have the nose full.'（我鼻子塞满了。）
\z

\noindent as

\newpage
\ea
I'm sick of it.（我受够了。）
\z

该系统不过是在输出从数据中学到的表达。\footnote{这一翻译示例也已由谷歌翻译的用户社区验证。}

但如果只是简单从数据中学习，为什么NMT要比SMT好得多呢？SMT不也是学习数据吗？原因在于NMT系统使用的表示方式及其学习模型。


\subsubsection{神经机器翻译的模型}
先从模型说起。计算机“模型”是一些现实生活的事件、系统或现象的抽象数学表示。这类模型的用途之一是为新问题预测答案。例如，用于翻译的计算模型应能将新的源语语句翻译成目的语。\footnote{提及数学模型，常会说到“预测”答案。但就本章目的而言，“预测”（predicting）和“输出”（outputting）答案并无实际区别，都是机器翻译系统的实际运用状态。} 

我们已经了解到，SMT系统使用翻译和目的语的概率模型，这些模型以短语表和$n$-gram概率来表示。相比之下，NMT系统使用的模型受到人脑启发，尽管神经网络只是基于对人类神经网络的简化设计。这些模型使用人工神经网络，其中成千上万的独立单元（即“人工神经元”，以下简称“神经元”）相互连接。在神经网络中，来自其他神经元的刺激以及神经元相互连接的强度（或称“权重”）决定每个神经元的激活状态。正如\citet{Forcada2017}所说，单个神经元的激活状态本身意义不大。表示单个单词及其与其他单词之间关系的，是大量相互连接的神经元的激活状态。训练NMT系统的关键在于，精确学习会生成最佳性能翻译模型（即激活状态能预测最佳译文的模型）的权重。

如何才能做到这一点呢？和所有机器学习一样，NMT系统也要从数据中学习。神经网络翻译模型是通过让学习算法处理大量平行数据，逐步建立而成。在不断处理数据的过程中，算法会学习并不断调整权重，使模型的预测越来越接近预期的“正确”答案。算法学习的详细过程可参阅\textcitetv{chapters/perez}，而更全面的NMT技术讨论可参考\citet{Koehn2020}。阅读本章只需了解，数据驱动的机器翻译是典型的机器学习，因为它涉及到为解决人类已知答案的问题而开发的技术，且人类其实已经给出了至少一个正确答案。正确答案可出现在训练数据中，或基于训练数据进行推断而得出。要检验某个机器翻译系统在训练期间的翻译质量是否有所改善，或在训练结束后将其与另一系统进行比较时，我们也可以通过让系统解决已经知道答案的问题来测试。比如，我们通常会要求系统输出几个新句子的翻译，但这些句子都已经有专门用来进行对比的优质人工译文。   

NMT系统被训练到令我们满意的状态时，便可用于实际的翻译任务。这时谈论的不再是“测试”，而是“使用”系统。大多数人都认为，实际使用中的NMT系统是在进行“翻译”。与SMT系统一样，计算机科学家也使用术语“解码”来描述NMT系统产生目的语的输出过程。


\subsubsection{神经机器翻译的词表示}\largerpage
我们已经说过，数学模型是一些系统、事件或现象的表示。关于数学和其他科学模型的地位存在很多争论，但不在此展开叙述。我们认为，模型所表示的内容很复杂，包括很多相互联系的部分。如果要讨论更简单或颗粒度更小的实体，如数字5或“苹果”，只需用泛指术语“表示”(representation)来指代描述该实体的方式。

表示方式很重要，因为正如\citet{deeplearningbook}所述，在计算机科学和日常生活中，概念的表示方式会影响我们对其的处理方式。阿拉伯数字和罗马数字之间的差异对人类数学运算能力的影响，就是一个很好的例子。大多数人会发现计算125除以5，比CXXV除以V容易得多，即使CXXV和125（以及V和5）所表示的数值相等。

词语也可视为概念的表示。例如，可以用“苹果”这个词来表示某类水果，也可以用一幅画来表示。当然，词语和图片的属性不同，也就意味着用处不同。例如，我们可以对词语进行拼写检查，但图片则不行。

NMT系统还使用了另一种表示方式——向量（vector），即固定大小的数字列表。例如，“苹果”一词可用向量[1.20，2.80，6.10]来表示。对许多人来说，这似乎不可思议。很难理解如何用数字列表来表示一个单词。\footnote{请注意，我们在此的讨论从思想的表示，转移到了词语的表示。训练语料库包含数百万个可识别的词语，我们的目标是，在NMT系统中将这些词语表示出来。}如果说向量能很好地表示单词之间的关系，事情就开始变得合理。例如，单词“梨”可用向量[1.20，2.80，5.50]来表示，该向量与表示“苹果”的向量只有最后一个数字之差。若把向量中每个数字看作想象的三维空间中的一个维度，那么“苹果”和“梨”这两个词的位置则非常接近。而且还可以推测出，它们与不太相关的词语也离得较远，如“直升机”或“非常”。向量还具备其他有意思的属性，引起计算机科学家的极大兴趣，例如多个向量可以相加或相乘。但表示“苹果”和“梨”的词语或图像都不能进行这些运算！

那么，在上述例子中，“苹果”和“梨”的向量为何如此相似呢？其实，我们只是瞎编的。在真实的NMT系统中，我们会让计算机程序直接从语料库中“学习”所有单词的所有实例的合适向量。（记住，在机器学习中，无论是否有人工监督，计算机程序必须自行解决问题。）供机器学习的基于向量的单词表示称为“词嵌入”(word embeddings)。相关单词的词嵌入相似，是因为它们都根据特定单词在训练数据中的位置而定。若两个单词总是出现在相同或相似的共同文本中，如“苹果”和“梨”都很有规律地出现在单词“树”之前，且在“去皮”、“切片”和“切丁”之后，则它们最终的词嵌入也会相似。

\textcitetv{chapters/perez}指出，词嵌入的生成并非一步到位，而是通过连续的多个“神经层”才构建完成。在其外层之间夹有多层结构的人工神经网络被称为“深度神经网络”（deep neural network）。

进一步而言，“深度学习”（deep learning）只是机器学习的分支，使用多个神经层来建立词语表示。在深度神经网络中，两个外层对应网络的输入和输出，且对人类分析师可见。而中间层或“隐藏”层却一直很难观察得到，这让“深度学习”给人以神秘莫测的感觉，导致一些评论者误导性地使用“魔法”一词来描述深度神经网络的内部运作。当大型科技公司宣告自己成功建立多语言翻译模型，有时不仅涉及数百种语言，还可以处理没有“直接”双语训练数据的语言之间的翻译，NMT系统便更添一份神秘感。\footnote{参见 \url{https://ai.googleblog.com/2016/11/zero-shot-translation-with-googles.html} 和 \url{https://about.fb.com/news/2020/10/first-multilingual-machine-translation-model}.} 然而，人工智能的研究人员意识到了系统透明度不足所引发的问题。在“可解释的人工智能”(explainable AI, XAI)和“可诠释的人工智能”(interpretable AI)这两个领域，研究者正努力打开深度学习的“黑匣子”，以便用户更容易理解其内部运作，为输出提供解释，从而改进系统（示例可参见\citet{Vashishth2019}）。



\section{神经机器翻译的优缺点}\label{sec:kenny:7}
NMT系统被普遍认为是迄今为止性能最好的机器翻译系统。例如，NMT系统之所以优于SMT系统，是因为它可以在考虑整个源语言句子，而不仅仅考虑n元组的情况下，为源语文本的单词建立非常丰富的词表示。产出译文时，NMT系统还可以同时考虑到这些丰富的表示和新产生的译文。正是由于NMT系统处理完整的句子，因此它更擅长处理棘手的语言特征（如不连续的依赖关系），且在处理各种一致现象方面的表现也比SMT系统更好。

尽管当前的NMT系统能考虑完整语句，但仍只限于正在处理的语句。这意味着这类系统还无法使用前一句子的信息，来判断代词（如it）在当前句子的具体所指，也无法获知某个西班牙语动词的主语是阴性（如西班牙语的空主语现象）。句级处理的这些缺点会导致许多其他问题，而这些问题只在用户翻译全文，而非单独语句时才显现出来。不过，目前已有“文档级机器翻译”的研究人员正努力解决这些问题（详见\citet{bao-etal-2021-g}）。此外，NMT系统还会输出实际上不存在于目的语中的单词。更严重的不足是，NMT系统的译文可能很流畅，但并不准确。当译文看上去和听起来都不错时，人们可能会忘了检查它是否与原文相符。再者，正如在大量现有文本上训练的其他技术一样，NMT也会放大训练数据中的偏见。已有大量研究讨论过性别偏见问题。以一个没有主语代词的西班牙语句子为例，如示例（8），许多NMT系统的英语译文都默认使用阳性主语代词。NMT开发者正在努力解决这个问题。现在有些系统同时输出阳性和阴性代词，供用户选择。本书也会在第4章和第5章中介绍用户如何才能充分利用某个NMT系统。

NMT系统的其他潜在不足与输出译文无关，而是关乎环境和社会问题。例如，NMT系统比以往系统的训练时间更长、算力要求更高，因此训练所耗费的能源更多。NMT系统不仅需要使用昂贵的专用图形处理器（graphical processing units, GPU），还需要大量的训练数据，但并非每个语言对都有如此大量的数据。

NMT技术的进步也引起人们对外语学习的质疑：如果机器能把其他语言的语音或文本翻译成自己的语言，为什么还要大费周章去学习这门外语呢？不过，这种观点体现出对第二语言或外语学习益处的狭隘认知，也忽略了机器翻译只适用于世界上少数语言。他们还倾向于将机器翻译与语言学习对立起来，而不认为前者是后者的辅助手段。机器翻译在语言学习和生活方面的使用还引发了很多伦理和社会问题，本书的第1、6和9章对此均有论述。


\section{系统、引擎和定制化神经机器翻译}
本章到目前为止，我们试图概括性地解释何为翻译，何为机器翻译，以及不同类型机器翻译的运作模式。最后，我们还想简要介绍一下特定的机器翻译系统以及机器翻译引擎的相关概念。

在常见用法中，机器翻译“系统”（system）通常是指由单个供应商或开发商提供的机器翻译产品或服务。因此，谷歌翻译（ Google Translate）可以说是谷歌的机器翻译系统，而微软翻译器（Microsoft Translator）则是微软的机器翻译系统。用户可以在不同平台访问这些系统，如安装谷歌翻译的手机应用程序，或者通过网络浏览器在线使用谷歌翻译，又或者在第三方软件中借助“应用程序接口”（application programming interface，API）来访问。\footnote{我们在此以谷歌翻译为例，只因它可能是最为人熟知的机器翻译服务商。和专门的机器翻译供应商一样，所有科技巨头也都提供不同的机器翻译“解决方案”。}  

在专业性更高的语境中，如学术论文或职业翻译，通常听到的概念是机器翻译“引擎”（engine）。这种语境下的“引擎”基本上是个机器翻译程序（甚至可以说是“模型”），训练过程使用特定语言对，且通常针对某个领域或体裁。例如，某家商业机器翻译公司以财务报表的平行语料库为训练数据，为客户提供英语-法语的机器翻译引擎，或者以医学领域文本为训练数据，提供汉语-德语的机器翻译引擎。客户甚至可以使用自己的数据，来创建或定制自己的机器翻译引擎。KantanAI一度是提供这类服务是的领先企业。\footnote{\url{https://www.kantanai.io}} \textcitetv{chapters/ramirez}对定制化机器翻译进行了更深入的讨论。此外，MultiTraiNMT项目也为此专门开发了教学界面，让学生可以自行训练NMT引擎。\footnote{\url{http://www.multitrainmt.eu}}


\section {关于机器翻译，你需要知道的最后四要点}
许多读者可能只使用免费在线机器翻译，因此只会用到为其感兴趣的语言对而构建的通用型引擎。但即便如此，这些读者也应当了解：

\begin{itemize}
    \item 不同的系统可能输出不同的译文；
    \item 同一系统中的不同引擎可能输出不同的译文；
    \item 即便输入内容相同，系统也可能因共现语篇不同而产出不同的译文；
    \item 某个系统的输出可能会随着时间的推移而有所不同。
\end{itemize}

例如，在撰写本文时，DeepL的“法语-英式英语”机翻引擎将原文（15）译成译文（16），该法语表达mon petit doigt me dit（字面意思是“我的小指告诉我”）的含义是“我有预感”或“有人告诉了我”。读者可能也注意到，英式英语译文（16）使用了意思相似的恰当修辞手法。


\ea Mon petit doigt me dit que tu es marié.（意为“我的小指告诉我你结婚了”）
\ex A little birdie tells me that you are married. (意为“一只小鸟告诉我你结婚了”，译自DeepL UK)
\z

相反，出自谷歌翻译的译文（17）采用了不恰当的直译。

\ea
My little finger tells me you're married. (意为“我的小手指告诉我你结婚了”，译自谷歌翻译)
\z

同样在撰写本文时，DeepL的法语-美式英语机翻引擎输出译文（18），但如果改变原句中的一个单词，如原文（19），那么DeepL的法语-美式英语机翻引擎的性能要好得多，如译文（20）所示。

\ea
My little finger tells me that you are married. (意为“我的小手指告诉我你已经结婚了。”，译自DeepL US)
\ex
Mon petit doigt me dit que tu es parti.（意为“我的小指告诉我你走了”）
\ex
A little birdie tells me that you've left. (意为“一只小鸟告诉我你已经走了”，译自DeepL US)
\z

不过，读者阅读到这儿时，这两个系统的输出可能已经完全改变了，因为模型会被重新训练，且用户可以纠正错误译文。


\section{结语}
尽管崛起势头强劲，NMT也不过是众多自动化翻译技术的先进代表。它的成功让政策制定者和普通公民对外语学习或译者培训的价值产生质疑。但是，这类立场忽略了一个事实，那就是NMT仍然依赖人工翻译，或至少依赖经过人工审核的翻译作为训练数据。和其他类型的机器翻译一样，NMT并非完美无缺，其译文仍然需要熟练掌握源语和目的语的专业译者来测评或改进。提升用户机器翻译素养迫在眉睫，即便对于一般用户亦是如此,这样他们才能少走弯路。在合适的条件下，NMT能成为促进和维护多语制、语言学习和由人类完成或监督的持续翻译的重要支柱。本书其余章节都正致力帮助创造这些条件。



\sloppy
\printbibliography[heading=subbibliography,notkeyword=this]

\end{document}
