\chapter[Piloting semantic factors]{Modeling the semantic transparency of  English compounds: piloting semantic factors}
\label{cha:empirical-1}
% all includegraphics commands changed to ./figures/
\section{Introduction}
\label{sec:intro:piloting-semantic-factors}

This chapter introduces and critically discusses statistical models for the
semantic transparency ratings of English
compounds collected in \citet{Reddyetal:2011}. The initial idea for
the models presented here is quite simple: if the aim is to model
semantic transparency, would the best predictors not be predictors
that directly encode core aspects of the semantic structure of the compounds?  In contrast to the
distributional models used by \citet{Reddyetal:2011}, the models
presented here therefore include 2 semantic
features of the target compounds as predictors: on the one hand, the semantic relation between the constituents of the
compounds, and on the other hand, meaning shifts exhibited by the compounds and/or
their constituents.

The semantic coding used in this chapter is joint work by Melanie
Bell and me, and was already used for the analyses in \citet{BellandSchaefer:2013}. The
models presented in \citet{BellandSchaefer:2013} are reproduced in
Section \ref{sec:bell-and-schaefer-2013}. What is new in this chapter is first
a more thorough description of the data and the coding scheme. Secondly, in Section \ref{sec:bell-schaefer-2013-model1-diagnostics}, the first model proposed in \citet{BellandSchaefer:2013} is exemplarily
subjected to a model criticism routine, and the effect of re-running
the models on the same dataset after a more rigorous outlier-removal is presented. 
Thirdly, I show that by using statistically more
appropriate models for the data, core results of
\citet{BellandSchaefer:2013} disappear (cf. Section \ref{sec:bell-schaefer-lmer}). And finally, I argue that
the semantic predictors that remain in the final models are doubtful
because the annotation scheme we used itself was questionable
(cf. Section \ref{sec:bell&schaefer2013_shifts}). 

This extensive
reevaluation of \citet{BellandSchaefer:2013} is the basis for the new
way of modeling the data presented in the following chapter, Chapter \ref{cha:empirical-2}.
 
\section{The Reddy et al. data: a descriptive overview}
\label{sec:reddy_et_al}

The analysis presented in \citet{Reddyetal:2011} and the way in which they selected their
data has already been described in detail in Chapter \ref{cha:modPrevious}, Section
\ref{sec:Reddyetal2011sum}. The aim of this section is to give a
descriptive overview of the data, starting with the characteristics of
the compounds themselves in Section
\ref{sec:linguistic-characeterization}, followed by the
characteristics of the rating data in Section
\ref{sec:descriptive-statistics}. \tabref{tab:reddy-items} shows
all the compounds rated in \citet{Reddyetal:2011} in alphabetical
order.

\begin{table}[!htb]
\small
  \centering
  \begin{tabularx}{1\textwidth}{rllll}\lsptoprule
{}[1]&acid test       & agony aunt      & application form& balance sheet    \\{}
[5]&bank account     &blame game       &brass ring       &brick wall       \\{}
[9]&call centre      &car park         &case study       &cash cow         \\{}
[13]&chain reaction   &cheat sheet      &china clay       &climate change   \\{}
[17]&cloud nine       &cocktail dress   &couch potato     &crash course     \\{}
[21]&credit card      &crocodile tears  &cutting edge     &diamond wedding  \\{}
[25]&end user         &engine room      &eye candy        &face value       \\{}
[29]&fashion plate    &fine line        &firing line      &flea market      \\{}
[33]&front runner     &game plan        &gold mine        &graduate student \\{}
[37]&grandfather clock&graveyard shift  &gravy train      &ground floor     \\{}
[41]&guilt trip       &head teacher     &health insurance &human being      \\{}
[45]&interest rate    &ivory tower      &kangaroo court   &law firm         \\{}
[49]&lip service      &lotus position   &mailing list     &melting pot      \\{}
[53]&memory lane      &monkey business  &nest egg         &night owl        \\{}
[57]&number crunching &panda car        &parking lot      &pecking order    \\{}
[61]&polo shirt       &public service   &radio station    &rat race         \\{}
[65]&rat run          &research project &rock bottom      &rocket science   \\{}
[69]&role model       &rush hour        &sacred cow       &search engine    \\{}
[73]&shrinking violet &silver bullet    &silver screen    &silver spoon     \\{}
[77]&sitting duck     &smoking gun      &smoking jacket   &snail mail\\       {}
[81]&snake oil        &speed limit      &spelling bee     &spinning jenny\\   {}
[85]&swan song        &swimming pool    &think tank       &video game      \\ {}
[89]&web site        & zebra crossing  &&\\\lspbottomrule
   
  \end{tabularx}

  \caption{The compounds used in \citet{Reddyetal:2011}}
  \label{tab:reddy-items}
\end{table}

\subsection{Linguistic characterization of the selected compounds}
\label{sec:linguistic-characeterization}
In this section, I first describe purely form-based linguistic properties of the
set of compounds, cf. Section
\ref{sec:con-wordclass}. Secondly, in Section \ref{sec:arg-struc}, I discuss whether those combinations in
which the head is either formally identical to a verb or is deverbal allow an analysis of
the corresponding compounds as argument-head combinations. 

\subsubsection{Word class and morphological properties of the constituents}
\label{sec:con-wordclass}

All constituents belong either to the class of adjectives,
verbs, or nouns. The majority of the compounds are standard noun noun
combinations. Allowing for meaning shifts,
all are \isi{endocentric}. \emph{Cloud nine} is the only compound that contains a numeral. Of this set of compounds, 3 are special with
regard to their morphological structure: \emph{cocktail dress}, \emph{grandfather clock} and
\emph{graveyard shift} all have a first constituent that is itself a
compound form. \emph{Cocktail} and \emph{graveyard} are noun noun
combinations, whereas \emph{grandfather} consists of the combining
form \emph{grand} and the noun \emph{father}.
% , with combining forms here .
% \marginpar{\textbf{TODO ADD: what is a  combining form; use oxford morphology reference guide}}

This section disregards the standard noun noun compounds and instead focuses on the minority cases, starting
with combinations involving adjectives and ending with combinations
involving verbs or deverbal nouns.

\paragraph{Compounds containing adjectives}

\is{adjective noun constructions!{in the Reddy et al. dataset}|(}
\emph{Sacred cow} presents the only example of an unambiguous
adjective noun combination in the data. \emph{Fine line}, although the
adjective \emph{fine} is homonymous with the noun \emph{fine}, is also
clearly an adjective noun combination, with the meaning contribution
of \emph{fine}, `very thin', being that of the adjective. Since in
both cases the main stress falls on the second element, both are
traditionally considered not as compounds but as phrasal constructions.

Formally and semantically ambiguous
between adjective noun and noun noun compounds are the 6 combinations
in \Next.

\ex. \a. \label{ex:promiscuous} \emph{public service}, \emph{graduate student}, \emph{human
  being} 
\b. \emph{silver bullet}, \emph{silver spoon}, \emph{silver screen}

For the examples in \Last[a], analyzing them as either adjective noun compounds or noun noun
compounds leads to \emph{promiscuity} (for this term,
cf. \citealt[427--428]{Jackendoff:2010}; cf. also the discussion of analytic indeterminacy in Chapter \ref{cha:semantics}, Section \ref{sec:levi_predicates_overview}). \is{analytic indeterminacy}\is{semantic relations!{analytic indeterminacy}}\is{semantic relations!{promiscuity}}
Promiscuity is
intended as a counterpart to ambiguity. Promiscuity captures
those compounds which can be explained, that is, analyzed, in
different ways, with the different analyses still leading to
the same interpretation (in contrast to the different interpretations in
the case of ambiguity). 
\is{compound!{ambiguity}!{vs. promiscuity}}
\is{ambiguity!{vs. promiscuity}}
\is{promiscuity}

To see the promiscuity exhibited by the compounds in \Last[a],
consider the combination \emph{public service}: If we take the meaning \emph{Service to the community,
  esp. under the direction of the government or other official agency;
  an instance of this} from the OED, 
% (cf. the first meaning for "public service,
% n.". OED Online. September 2016. Oxford University
% Press. \url{http://www.oed.com/view/Entry/239618?rskey=conbyX&result=1}
% (accessed October 17, 2016)
then both \emph{service for the public}, where \emph{public} is used as
a noun,
as well as \emph{service that is public}, where \emph{public} is used
as an adjective, are acceptable paraphrases,
and, more importantly, they mean the same thing (note, too, that these 2 possibilities remain even when \emph{service}
is read as \emph{religious service}).

In contrast, the compounds in \Last[b] are ambiguous depending on
whether \emph{silver} is taken to refer to the material or to the color. This
ambiguity is in principle independent of whether \emph{silver} is
analyzed as an adjective or a noun (cf. the remarks concerning
material nouns in Chapter \ref{cha:semantics}, Section
\ref{sec:intersectives}).\is{noun!{material}}\is{modification!{with material modifier}}
 Take \emph{silver bullet}. When
paraphrasing the meaning as `a bullet made from silver', one makes use
of one of the noun senses of \emph{silver}, refering to the
metal. When the paraphrase is, instead, `a bullet that is silver', one could
argue that \emph{silver} is used as an adjective, but as long as the
adjective meaning still describes the material (e.g., \emph{composed
  of silver}), it would only lead to promiscuity as discussed
above. An ambiguity arises only when contrasting the material
with the color reading. However, the color reading of \emph{silver} by
itself can also be analyzed as being linked to a noun or an adjectival
use.\is{ambiguity}
\is{adjective noun constructions!{in the Reddy et al. dataset}|)}

\paragraph{Compounds containing verbs}

\is{compound!{with deverbal head}!{in the Reddy et al. dataset}|(}
For verbs, it is helpful to distinguish between compounds containing \emph{-ing} forms
and those that do not contain \emph{-ing} forms. Starting with the
latter, and within this group with verb noun combinations, there are 2 clear cases of verb
noun compounds,
\emph{think tank} and \emph{cheat sheet}. In addition, there are 6 cases
which are formally ambiguous between verb noun and noun noun compounds,
cf. \Next.

\ex. \emph{research project, 	blame game, call centre, search engine,
balance sheet, rush hour}

For all compounds in \Last, whether we analyze the first element as a
noun or as a verb seems to make no difference to the meaning we arrive
at (see also the discussion of promiscuity above in the context of the
examples in \ref{ex:promiscuous}).\is{ambiguity!{vs. promiscuity}}
\is{compound!{ambiguity}!{vs. promiscuity}}

While there are no true noun verb compounds in this group, 4 compounds
contain second constituents that are homonyms of the verbs from which the
nouns were converted: % are form-wise ambiguous between noun noun and noun verb compound:
\emph{climate change}, \emph{case study}, \emph{rat race}, and \emph{rat run}.

Among the compounds containing V\emph{-ing} constituents, \emph{number
  crunching} is the sole example for an \emph{-ing} form in second position. The 13
examples of compounds starting with V\emph{-ing} forms are given in \Next.

\ex. \emph{parking lot, spelling bee, shrinking violet, smoking gun, smoking jacket,
mailing list, melting pot, swimming pool, spinning jenny, firing line, cutting edge, sitting
duck, pecking order}

The nouniness of the \emph{-ing} forms differs. Some are lexicalized deverbal nouns (e.g. \emph{spelling} in \emph{spelling bee}),
others are gerund-participles used attributively (e.g. \emph{smoking gun}), or they are ambiguous between gerund-participles functioning as a noun or
gerundial nouns (e.g. \emph{pecking} in \emph{pecking
  order}) (the terminology follows \citealt[Chapter 3, \S 1.4]{HuddlestonandPullum:2002}).
% The nouniness of the \emph{-ing} forms varies,
% cf. e.g. \emph{smoking} in \emph{smoking jacket} vs. \emph{smoking} in
% \emph{smoking gun}. 
% \emph{pecking} in
% \emph{pecking order}.

% \paragraph{Nouns}

% All instances of compounds not mentioned so far, 57 tokens, are clear cases of noun noun
% compounds. The clear NN compounds thus constitute the majority of
% tokens. If the ambigous cases are added, we have 72 tokens.


\subsubsection{Argument-structure based properties}
\label{sec:arg-struc}

For those cases where the head is or could formally be a verb, and for cases
with deverbal nouns as head, the question arises whether these constitute
argument-head structures. The dataset contains 3 deverbal noun heads
formed by adding the suffix \emph{-er}: \emph{teacher} in
\emph{head teacher}, \emph{runner} in \emph{front runner} and
\emph{user} in \emph{end user}. In all 3 cases,
the first constituent does not correspond to an argument of the underlying
verbal base. For the 4 ambiguous cases, \emph{climate change}, \emph{case
  study}, \emph{rat race} and \emph{rat run}, an argument-based analysis seems possible, with
the first constituent serving either as the theme or the agent. Similarly, for
\emph{number crunching} the first constituent can be seen as expressing the
theme argument linked to the argument structure of the underlying verb.
\is{compound!{with deverbal head}!{in the Reddy et al. dataset}|)}


\subsubsection{Conclusion: linguistic characteristics}
\label{sec:conclusion-linguistic-properties}

Most of the compounds in the dataset are standard noun noun
compounds. Apart from noun noun compounds, the dataset also contains adjective noun
combinations and verb noun combinations, as well as a few combinations
that have second constituents that are formally identical to
nouns. Thus, the dataset is not completely homogeneous. 
% On the other
% hand, items that unambiguously contain
% non-noun constituents are relatively few in number. 

As the semantic coding can be applied to all combinations
regardless of their characteristics, and as the number of items that
are unambiguously not noun noun compounds or exhibit a specific
pattern within the group of noun noun compounds is too small to include
corresponding predictors in the statistical analysis, these different characteristics will
not play a further role in the analyses presented in this
chapter. However, the non-homogeneity in the dataset is one of the
motivations to eventually use mixed effects regression models, cf. the
comments in Section \ref{sec:bell-schaefer-lmer}.
\enlargethispage{1\baselineskip}
The distinction between standard noun noun compounds and other compound
types in the dataset will also play a role in Chapter
\ref{cha:empirical-2}, cf. especially Section
\ref{sec:restricted-target}. 


\subsection{Descriptive overview of the rating data}
\label{sec:descriptive-statistics}
The following descriptive statistics are all based on the means file
provided with the Reddy et al. (2011) dataset. For all 3 transparency ratings, I give
an overview of the distribution of the mean ratings across the data
and comment on the distribution of the standard deviations. 
\subsubsection{Transparency of constituent 1}

\figref{fig:reddy-means-constituent-1} gives an overview of the
means of the ratings for constituent 1 of the compound dataset. While
the plot of the mean values in the left panel already shows that
the mean values are clustered towards the lower and higher end of the
Likert scale, this becomes much clearer when considering the histogram
in the middle panel, where one can also observe an asymmetry in the distribution of the means towards the 2 ends of the scale, with more ratings
at the higher end than at the lower end. The means are clearly not
normally distributed, resulting in the Q-Q plot in the right-hand
panel: instead of a straight line, the high number of low mean values
lets the graph stay relatively low, only to rise very steeply and bend
sharply to accommodate the even greater number of high and very high mean values.
\begin{figure}[!htb]
  \centering
% \includegraphics[scale=.97,clip, trim= 0mm 60mm 0mm 50mm]{/home/martin/Dropbox/statistics/habil-stat/word1-mean-diagnostics.png}
% \includegraphics[scale=.72,clip, trim= 0mm 60mm 0mm 50mm]{/home/martin/Dropbox/statistics/habil-stat/word1-mean-diagnostics.pdf}
\includegraphics[scale=.72,clip, trim= 0mm 60mm 5mm 70mm]{./figures/word1-mean-diagnostics.pdf}
  
  \caption{Mean transparency ratings of constituent 1: The panel on
    the left shows the mean compound ratings. The panel in the middle shows the distribution of the mean ratings. The Q-Q plot in the right
    panel compares the distribution of the mean
    ratings against the normal distribution.}
  \label{fig:reddy-means-constituent-1}
\end{figure}

\tabref{tab:constituent1-ratings} illustrates the data further by
showing the 5 compounds with the lowest mean rating for their first
constituent, the 5 compounds closest to the 2.5 value (the mean of the
mean of the ratings is 2.68), and the 5 compounds with the highest
rating for their first constituent.

\begin{table}[!htb]
  \centering
\footnotesize
\begin{tabular}{@{}lcclcclcc@{}}\lsptoprule
\multicolumn{2}{c}{lowest ratings}&\phantom{abc}&\multicolumn{2}{c}{medium ratings}&\phantom{abc}&\multicolumn{2}{c}{highest ratings}\\
\cmidrule{1-2}\cmidrule{4-5}\cmidrule{7-8}
% kangaroo court&0.166667&&shrinking violet&   2.275862&&bank account   &4.866667\\     
% crocodile tear&0.185185&&cheat sheet &  2.300000     &&climate change   &4.896552\\   
% rat race&0.250000      &&chain reaction  & 2.407407  &&car park   &4.896552\\         
% gravy train&   0.296296&&web site   &2.678571        &&research project   &4.900000\\ 
% snake oil &  0.370370  &&game plan  & 2.821429       &&speed limit   &4.933333\\
kangaroo court&0.167&&shrinking violet&   2.276&&bank account   &4.867\\     
crocodile tear&0.185&&cheat sheet &  2.300     &&climate change   &4.897\\   
rat race&0.250      &&chain reaction  & 2.407  &&car park   &4.897\\         
gravy train&   0.296&&web site   &2.679        &&research project   &4.900\\ 
snake oil &  0.370  &&game plan  & 2.821       &&speed limit   &4.933\\
      \lspbottomrule  
\end{tabular}

% \begin{tabular}{lc}
% compound&mean constituent 1 score\\\hline
% kangaroo court&0.166667\\
% crocodile tear&0.185185\\
% rat race&0.250000\\
% gravy train&   0.296296\\
% snake oil &  0.370370\\\hline
% shrinking violet&   2.275862\\
% cheat sheet &  2.300000\\
% chain reaction  & 2.407407\\
% web site   &2.678571\\
% game plan  & 2.821429\\\hline
% bank account   &4.866667\\
% climate change   &4.896552\\
% car park   &4.896552\\
% research project   &4.900000\\
% speed limit   &4.933333
% \end{tabular}
  \caption{Selected mean ratings for constituent 1. In the leftmost
    column the 5 items with the lowest mean ratings for the first
    constituent, in the middle column the 5 items whose mean
    constituent 1 ratings
    are closest to 2.5, and in the rightmost column the 5 items whose
    mean constituent 1 rating is closest to 5, the highest possible rating.}
  \label{tab:constituent1-ratings}

\end{table}

Turning now to the standard deviations, the following observations can be made: The 5 items with the lowest standard deviations occur with words with high transparency scores for the first constituent
(ordered by increasing standard deviation: \emph{speed limit}, \emph{research
  project}, \emph{climate change}, \emph{bank account}, \emph{human
  being}).
% (in increasingorder of sds)
The 5 items with the highest standard deviation, in contrast, have
mean transparency scores between 2.00 and 3.73 (in increasing order of
standard deviation: \emph{web site}, \emph{china clay}, \emph{brass
  ring}, \emph{game plan}, \emph{brick wall}). Note that the final
3 all have been rated with 2 definitions, which in all 3
cases is one of the main reasons for the high standard deviation, in
the case of \emph{brick wall} it is the sole reason: 14 subjects chose
the second meaning as the basis for their rating, and they
consistently gave it the highest transparency rating, `5'. The first reading by itself,
chosen by 11 subjects and a mean rating of 0.818, % 0.8181818, 
yields a
standard deviation of 1.17, but its their combination which leads to a
standard deviation of 2.29.  
% ReddySd1Word1[1:5,1:4]
%                    word Word1_mean Word1_std Word2_mean
% 88      speed-n limit-n   4.933333  0.249444   4.827586
% 80 research-n project-n   4.900000  0.300000   4.533333
% 56   climate-n change-n   4.896552  0.304543   4.827586
% 90     bank-n account-n   4.866667  0.339935   4.827586
% 34      human-n being-n   4.862069  0.344828   4.333333
% > ReddySd1Word1[86:91,1:4]
%             word Word1_mean Word1_std Word2_mean
% 6    web-n site-n   2.678571  1.691440   3.933333
% 13 china-n clay-n   2.000000  1.839732   4.620690
% 78 brass-n ring-n   3.733333  1.948219   3.866667
% 3   game-n plan-n   2.821429  1.964935   4.862069
% 87 brick-n wall-n   3.160000  2.203270   3.533333

The transparency score and standard deviation of the first constituent are slightly negatively
correlated (Spearman's $\rho$ -0.29, p-value $<$0.01), that is, the
lower the transparency score, the higher the standard deviation.
% S = 156143.3, p-value = 0.00642
% alternative hypothesis: true rho is not equal to 0
% sample estimates:
%        rho 
% -0.2852885 

\subsubsection{Transparency of constituent 2}

\figref{fig:reddy-means-constituent-2} gives an overview of the
means of the ratings for constituent 2 of the compound dataset. Just
as for constituent 1,  it can be observed that the ratings are not normally distributed
but concentrate towards the 2 ends of the scale, here with an even
clearer tendency towards the high end of the scale.

\begin{figure}[!htb]
  \centering
\includegraphics[scale=.72,clip, trim= 0mm 60mm 5mm 70mm]{./figures/word2-mean-diagnostics.pdf}
% \includegraphics[scale=.72,clip, trim= 0mm 60mm 0mm 50mm]{/home/martin/Dropbox/statistics/habil-stat/word2-mean-diagnostics.pdf}
% \includegraphics[scale=.97,clip, trim= 0mm 60mm 5mm 50mm]{/home/martin/Dropbox/statistics/habil-stat/word2-mean-diagnostics.png}
  
  \caption{Mean transparency ratings of constituent 2: The panel on
    the left shows the mean compound ratings. The panel in the middle shows the distribution of the mean ratings. Q-Q plot in the right
    panel compares the distribution of the mean
    ratings against the normal distribution.}
  \label{fig:reddy-means-constituent-2}
\end{figure}
\tabref{tab:constituent2-ratings} gives the 5 compounds with the lowest mean rankings for the second constituent, the 5 items
closest to the 2.5 value (the mean of the mean values is 3.06), and the 5 highest
rated items. 

\begin{table}[!htb]
  \centering
\footnotesize
\begin{tabular}{@{}lcclcclcc@{}}\lsptoprule
\multicolumn{2}{c}{lowest ratings}&\phantom{abc}&\multicolumn{2}{c}{medium ratings}&\phantom{abc}&\multicolumn{2}{c}{highest ratings}\\
\cmidrule{1-2}\cmidrule{4-5}\cmidrule{7-8}
shrinking violet&   0.233&&       rat race &  2.036&&   cocktail dress &         5\\
      cloud nine&   0.233&&  search engine &  2.250&&       video game &         5\\
    couch potato&   0.345&&        rat run &  2.333&&       polo shirt &         5\\
        cash cow&   0.370&&      rush hour &  2.862&& graduate student &         5\\
  spinning jenny&   0.414&&  silver screen &  3.231&&      engine room  &        5\\
% shrinking violet&   0.233333&&       rat race &  2.035714&&   cocktail dress &         5\\
%       cloud nine&   0.233333&&  search engine &  2.250000&&       video game &         5\\
%     couch potato&   0.344828&&        rat run &  2.333333&&       polo shirt &         5\\
%         cash cow&   0.370370&&      rush hour &  2.862069&& graduate student &         5\\
%   spinning jenny&   0.413793&&  silver screen &  3.230769&&      engine room  &        5\\
      \lspbottomrule  
\end{tabular}
% \begin{tabular}{lc}
% compound&mean constituent 2 score\\\hline
% shrinking violet&   0.233333\\
%       cloud nine&   0.233333\\
%     couch potato&   0.344828\\
%         cash cow&   0.370370\\
%   spinning jenny&   0.413793\\\hline
%        rat race &  2.035714\\
%   search engine &  2.250000\\
%         rat run &  2.333333\\
%       rush hour &  2.862069\\
%   silver screen &  3.230769\\\hline
% grandfather clock&          5\\
%    cocktail dress &         5\\
%        video game &         5\\
%        polo shirt &         5\\
%  graduate student &         5\\
%       engine room  &        5
% \end{tabular}
  \caption{Selected mean ratings for constituent 2. In the leftmost column the 5 items with the lowest mean ratings, in the middle column the 5 items whose ratings are closest to 2.5, and in the rightmost column the 5 items closest to 5, the highest possible rating.}
  \label{tab:constituent2-ratings}
\end{table}

\newpage
The highest ranked are also those with the lowest
standard deviation, viz. zero. In contrast, the 5 items with the highest
standard deviation for constituent 2 (in increasing order of
standard deviations: \emph{sacred cow}, \emph{silver spoon},
\emph{brick wall}, \emph{brass ring}, \emph{fashion plate}) have transparency scores ranging
from 0.96 (\emph{sacred cow}) to 3.87 (\emph{brass ring}). Similar to
the constituent 1 ratings, for the 3 items with the highest standard
deviations subjects used both available definitions.
%  search-n engine-n   2.250000  1.703463
% 35    sacred-n cow-n   0.964286  1.721340
% 11  silver-n spoon-n   1.444444  1.770820
% 87    brick-n wall-n   3.533333  1.857118
% 78    brass-n ring-n   3.866667  1.978776
% 68 fashion-n plate-n   3.307692  2.071217

% \enlargethispage{1\baselineskip}
The transparency score and standard deviation of the second constituent are negatively
correlated (Spearman's $\rho$ -0.45, p-value $<$0.01), that is, the
lower the transparency rating for the second constituent, the higher
the standard deviation.
% S = 176277.2, p-value = 8.15e-06
% alternative hypothesis: true rho is not equal to 0
% sample estimates:
%       rho 
% -0.4510207 

 
\paragraph{Transparency of the whole compound}

\figref{fig:reddy-means-whole-compound} gives an overview of the
means of the whole compound ratings. Just
as for the constituent 1 and the constituent 2 ratings,  the graphs
and plots show that the ratings are not normally distributed. However,
in contrast to those 2 distributions, the concentration of the ratings
towards the 2 ends of the scale is less extreme, and there are more
mid-level rating means.

\begin{figure}[!htb]
  \centering

% \includegraphics[scale=.97,clip, trim= 0mm 60mm 0mm 50mm]{/home/martin/Dropbox/statistics/habil-stat/compound-mean-diagnostics.png}
% \includegraphics[scale=.72,clip, trim= 0mm 60mm 0mm 50mm]{/home/martin/Dropbox/statistics/habil-stat/compound-mean-diagnostics.pdf}
\includegraphics[scale=.72,clip, trim= 0mm 60mm 5mm 70mm]{./figures/compound-mean-diagnostics.pdf}
  
  \caption{Mean transparency ratings for the whole compound. The panel on
    the left shows the mean compound ratings. The panel in the middle is a
    histogram showing the distribution of the mean ratings. The right
    panel is a Q-Q plot, comparing the distribution of the mean
    ratings against the normal distribution.}
  \label{fig:reddy-means-whole-compound}
\end{figure}



\tabref{tab:whole-constituent-ratings} gives the 5 lowest ranked, the 5 items
closest to the 2.5 value (the mean of the mean values is 2.66), and the 5 highest
rated items. 

\begin{table}[!htb]
  \centering
\footnotesize
\begin{tabular}{@{}lcclcclcc@{}}\lsptoprule
\multicolumn{2}{c}{lowest ratings}&\phantom{abc}&\multicolumn{2}{c}{medium ratings}&\phantom{abc}&\multicolumn{2}{c}{highest ratings}\\
\cmidrule{1-2}\cmidrule{4-5}\cmidrule{7-8}
gravy train& 0.310&&silver screen& 2.379&&      speed limit& 4.828\\       
cloud nine& 0.333&&spelling bee& 2.448&&       swimming pool& 4.867\\     
ivory tower& 0.464&&lotus position& 2.483&&     graduate student& 4.900\\  
melting pot& 0.538&&grandfather clock& 2.643&&  engine room& 4.931\\       
silver bullet& 0.667&&front runner& 2.655&&       climate change& 4.966\\      
% gravy train& 0.310345&&silver screen& 2.379310&&      speed limit& 4.827586\\       
% cloud nine& 0.333333&&spelling bee& 2.448276&&       swimming pool& 4.866667\\     
% ivory tower& 0.464286&&lotus position& 2.482759&&     graduate student& 4.900000\\  
% melting pot& 0.538462&&grandfather clock& 2.642857&&  engine room& 4.931034\\       
% silver bullet& 0.666667&&front runner& 2.655172&&       climate change& 4.965517\\      
      \lspbottomrule   
\end{tabular}
% \begin{tabular}{lc}
% compound&mean compound score\\\hline
% gravy train& 0.310345\\
% cloud nine& 0.333333\\
% ivory tower& 0.464286\\
% melting pot& 0.538462\\
% silver bullet& 0.666667\\\hline
% silver screen& 2.379310\\
% spelling bee& 2.448276\\
% lotus position& 2.482759\\
% grandfather clock& 2.642857\\
% front runner& 2.655172\\\hline
% speed limit& 4.827586\\
% swimming pool& 4.866667\\
% graduate student& 4.900000\\
% engine room& 4.931034\\
% climate change& 4.965517
% \end{tabular}
  \caption{Selected mean ratings for the whole compound. In the leftmost column the 5 items with the lowest mean ratings, in the middle column the 5 items whose ratings are closest to 2.5, and in the rightmost column the 5 items closest to 5, the highest possible rating.}

  \label{tab:whole-constituent-ratings}
\end{table}

As far as standard deviations are concerned, the compounds with the
lowest standard deviations (in order of increasing
standard deviations: \emph{climate change, engine room, graduate
student, swimming pool, research project}) all have very high transparency scores (in fact,
the top four exactly correspond to the transparency top four). For the
compounds with the highest standard deviations (in order of increasing
standard deviations: \emph{sacred cow, silver
screen, firing line, brick wall and brass ring}), the transparency ratings
range from 1.52 (\emph{sacred cow}) to 3.79 (\emph{brass ring}). For
all 5 items, subjects made use of 2 different definitions.
% > ReddySdCompound[1:5,c(1,6:7)]
%                   word Cpd_mean  Cpd_std
%56   climate-n change-n 4.965517 0.182466
%76      engine-n room-n 4.931034 0.253395
%50 graduate-n student-n 4.900000 0.300000
%89    swimming-n pool-n 4.866667 0.339935
%80 research-n project-n 4.821429 0.382993
%> ReddySdCompound[86:90,c(1,6:7)]
%                word Cpd_mean  Cpd_std
%35    sacred-n cow-n 1.518519 1.524379
%37 silver-n screen-n 2.379310 1.627645
%2    firing-n line-n 1.703704 1.717337
%87    brick-n wall-n 3.793103 1.749469
%78    brass-n ring-n 3.724138 1.836349

There is a slight negative correlation (Spearman's $\rho$ -0.21, p-value $<$0.05), that is, the lower the transparency score, the higher the standard deviation. 
% S = 147150, p-value = 0.04563
% alternative hypothesis: true rho is not equal to 0
% sample estimates:
%        rho 
% -0.2112607 

% \newpage

\section{\citet{BellandSchaefer:2013}}
\label{sec:bell-and-schaefer-2013}

This section presents \citet{BellandSchaefer:2013}. First, Section
\ref{sec:bell-and-schaefer-2013_subset} describes the subset of the Reddy
et al. dataset that we used. Second, Section
\ref{sec:bell-schaefer-sem-annotation} describes the semantic annotation
scheme. This is followed by an overview of the
annotation results in Section
\ref{sec:bell-schaefer-annotation-results} and finally the 4 statistical models in
Section \ref{sec:bell-and-schaefer-models}. The main difference to the
presentation in \citet{BellandSchaefer:2013} lies in the more detailed
discussion and more extensive illustration of the results of our
study. This is particularly evident in the discussion of the annotation results.
% Although parts were
% rewritten, I made no effort
% to change the wording of every single sentence.

\subsection{Subsetting the Reddy et al. dataset}
\label{sec:bell-and-schaefer-2013_subset}
% The Reddy et al. dataset contains 30 ratings for each of the three
% tasks (a-c above) for all 90 compounds: in other words, a total of
% 8100 ratings. However, because tasks were assigned randomly to raters,
% the same rater did not necessarily perform all three tasks for any
% given compound. Since \citet{BellandSchaefer:2013} wanted to use the perceived literality of the
% constituents to predict the perceived literality of the compound, we
% chose to use within-subject comparisons: this would allow us to model
% how well  an individual's perception of constituent literality
% predicts their compound literality rating. 
% \textbf{BUT THEN WHY DIDN'T WE USE A MIXED MODEL?}
In \citet{BellandSchaefer:2013}, we did not use the whole dataset from Reddy
et al. (2011), because we decided to use a within-sub\-ject design. The
main reason for a within-subject design was that we wanted to include models that
used the constituent ratings as predictors for whole compound
transparency, and the usage of a within-subject design means that for
a given rating on the whole compound, we always used the ratings
by the same subjects on N1 and N2 transparency as  the input to the
regression formula. This has the main advantage that we can, at least to a certain degree, disregard
the role of any individual differences between the subjects on the
dependent variable, because these individual differences will also
have influenced the other measures from the same subject. However, it
also has the disadvantage that being exposed to the same item several
times might affect one's rating on that item. In addition, the order
of the presentation might play a role here. Since the Reddy et
al. dataset does not contain any information with regard to the order
of representation of the materials to individual subjects, we could
not explore whether or not there was such a relationship. 
% , \citet{BellandSchaefer:2013}
% therefore 
Extracting only those items for which the same rater had performed all
3 tasks from the total dataset produced a set of 1,337 tokens for
which transparency judgments for each constituent as well as the
compound as a whole had been given by a single person.\footnote{This
  number excludes the compound \emph{number crunching}. Why we
  excluded it at this point is not clear to me (in constrast to its
  exclusion for the models presented in Chapter \ref{cha:empirical-2},
  cf. the explanation in Section \ref{sec:restricted-target}).}  The
ratings come from a total number of 40 raters, with individual
contributions ranging from one token (6 raters) to more than 80 (9
raters). On average, every rater contributed ratings on 33 tokens.
% was
% excluded, because \emph{crunching} does
% not occur as a noun in the WordNet database, and in order to get
% additional distributional data, we needed to be able to search for
% noun noun strings. 
Within this
set, 12 of the 90 compound types showed variation in the definition
assigned, i.e. each of the possible definitions had been chosen by at
least one rater. A list of these 12 compounds is given in \Next.

\ex. List of compounds for which subjects differed in their choice of definition\\
\begin{tabular}{lll}
\emph{brass ring}&\emph{brick wall}&\emph{case study}\\
\emph{chain reaction}&\emph{face value}&\emph{fashion plate}\\
\emph{firing line}&\emph{game plan}&\emph{public service}\\
\emph{sacred cow}&\emph{silver screen}&\emph{snake oil}\\
\end{tabular}
% \a. case study
% \b. fashion plate
% \c. chain reaction
% \d. sacred cow
% \d. silver screen
% \d. firing line
% \d. game plan
% \d. public service
% \d. snake oil
% \d. face value
% \d. brass ring
% \d. brick wall

Because we were interested in the relationship
between semantic structure
and transparency ratings, we coded
and analyzed these different readings separately from one another. A
token-based analysis allowed us to do this since, for each token, the
dataset indicates the definition assigned by the rater in question. 


\subsection{Semantic annotation of the compounds}
\label{sec:bell-schaefer-sem-annotation}

In order to capture and classify the internal semantic relations involved in
semantic transparency, we start from the underspecified predicate
logic notation in \Next, which repeats \ref{ex:underspec} from Section
\ref{sec:compositionality} in Chapter \ref{cha:theo} (note that it is left open when and how this relation is eventually existentially bound). In \Next, A stands for the first  constituent of a complex
nominal, and B for the second constituent. 
% This representation is one common
% way to introduce underspecified semantic representations, cf. the
% discussion of compositionality in section 

% \ex. $\lambda$ y $\lambda$ x [A(x) \& R(x,y) \& B(y)]
\ex. \label{ex:underspecified}
$\lambda$B $\lambda$A $\lambda$y $\lambda$ x [A(x) \& R(x,y)
\& B(y)]

% The annotation used can be seen as an extension of Levi's system to a
% wider range of cases, especially to cases including meaning shifts
% like metaphor or metonomy.
We assume that an underspecified relation R links the denotations of A
and B in a given construction.
\is{underspecification!{in scheme for compound combinatorics}}
% The denotations that A and B predicate over are linked by an underspecified
% relation R. 
% In order to be able to classify compounds where constituents or the
% whole compound have undergone meaning shifts, we assume that the
% predicates themselves can be metaphorically or metonymically shifted.
Based on this, we developed the scheme given in \figref{fig:AN_combinatorics}, where, for reasons
of perspicuity, we omitted the arguments of the predicates. Shifted
predicates are followed by an apostrophe.
%  (note that in a
% full model, they are needed, because they can be shifted independently from
% the predicates).


\begin{figure}[h]
  \centering
\begin{tikzpicture}[>=stealth]
\node [shape= rectangle, draw] (context) {context/world knowledge};
% \node (context) {};
\node (placeholder_firstline) [below=of context]  {};
\draw (0,-1) node (label_context-R)  {specifies};
\node (relationR) [below=of placeholder_firstline]  {R};
\node (placeholder_thirdline) [below=of relationR]  {};
% \node (compoundpartA) [left=of placeholder_firstline]{A(x)};
\node (compoundpartA) [left=of placeholder_firstline]{A};
\node (compoundpartB) [right=of placeholder_firstline] {B};
% \node (compoundpartB) [right=of placeholder_firstline] {B(y)};
\draw (4.8,-1) node (label_west)  {initiates shifts};
\draw (-4.8,-1) node (label_east)  {initiates shifts};
\node (shiftedcompoundpartB) [right=of placeholder_thirdline] {B'};
\node (shiftedcompoundpartA) [left=of placeholder_thirdline] {A'};
% \node (shiftedcompoundpartB) [right=of placeholder_thirdline] {B'(y)};
% \node (shiftedcompoundpartA) [left=of placeholder_thirdline] {A'(x)};
\node (placeholder_secondlinewest) [left=of relationR]  {};
\node (placeholder_secondlineeast) [right=of relationR]  {};
\draw (0,-5.95) node (shiftedAB) {(AB)'};

\draw [->,thick] (compoundpartA) -- (shiftedcompoundpartA);
\draw [->,thick] (compoundpartB) -- (shiftedcompoundpartB);
\draw [-] (compoundpartA.east) -- (relationR.west);
\draw [-] (compoundpartB.west) -- (relationR.east);
\draw [-] (shiftedcompoundpartA.east) -- (relationR.west);
\draw [-] (shiftedcompoundpartB.west) -- (relationR.east);
\draw[thick,dotted] [-] (context.south) to  (label_context-R);
\draw[thick,dotted] [->] (label_context-R.south) to  (relationR);
\draw[densely dashed] [->] (context.east) to [bend left=45]
(placeholder_secondlineeast);
\draw[densely dashed] [->,thick] (context.east) to [bend left=70]
(2.5,-5.25);
\draw[densely dashed] [->,thick] (context.west) to [bend right=70]
(-2.5,-5.25);

\draw[densely dashed] [->,thick] (context.west) to [bend right=45] (placeholder_secondlinewest);
\draw[densely dashed] [->,thick] (0,-4.9) to  (0,-5.5);

\draw [decoration={brace,mirror,amplitude=0.5em},decorate,thick]
 (-2,-4.75) -- (2,-4.75);
% ($(right)!(2nd.north)!($(right)-(0,1)$)$) --  ($(right)!(4th.south)!($(right)-(0,1)$)$); 

\end{tikzpicture}  

  \caption{Scheme for A B combinatorics}
  \label{fig:AN_combinatorics}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%    FRITZ-THYSSEN/TOULOUSE VERSION!!
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{figure}[h]
%   \centering
% \begin{tikzpicture}
% \node [shape= rectangle, draw] (context) {context/world knowledge};
% \node (placeholder_firstline) [below=of context]  {};
% \draw (0,-1) node (label_context-R)  {specifies};
% \node (relationR) [below=of placeholder_firstline]  {R};
% \node (placeholder_thirdline) [below=of relationR]  {};
% \node (compoundpartA) [left=of placeholder_firstline]{A};
% \node (compoundpartB) [right=of placeholder_firstline] {B};
% % \node (label_east) [right=of compoundpartB] {initiates shift};
% \draw (3.5,-1) node (label_west)  {initiates shift};
% \draw (-3.5,-1) node (label_east)  {initiates shift};
% \node (shiftedcompoundpartB) [right=of placeholder_thirdline] {B'};
% \node (shiftedcompoundpartA) [left=of placeholder_thirdline] {A'};
% \node (placeholder_secondlinewest) [left=of relationR]  {};
% \node (placeholder_secondlineeast) [right=of relationR]  {};
% \draw [->] (compoundpartA) -- (shiftedcompoundpartA);
% \draw [->] (compoundpartB) -- (shiftedcompoundpartB);
% \draw [-] (compoundpartA.east) -- (relationR.west);
% \draw [-] (compoundpartB.west) -- (relationR.east);
% \draw [-] (shiftedcompoundpartA.east) -- (relationR.west);
% \draw [-] (shiftedcompoundpartB.west) -- (relationR.east);
% \draw[densely dashed] [-] (context.south) to  (label_context-R);
% \draw[densely dashed] [->] (label_context-R.south) to  (relationR);
% % \draw [->] (context.south) to  (compoundpartA);
% % \draw [->] (context.south) to  (compoundpartB);
% \draw[densely dashed] [->] (context.east) to [bend left=45]
% (placeholder_secondlineeast);
% % node[below,text width=2cm, align=center, midway] {initiates shift};
% \draw[densely dashed] [->] (context.west) to [bend right=45] (placeholder_secondlinewest);
% % \draw   [->] (0,0) node[below] {R} -- (3,-0.0) node[below,text width=3cm,text centered]
% % {B};
% % \draw   [->] (0,0)  -- (-3,-0.0) node[below,text width=3cm,text centered]
% % {A};
% % % \draw [->] (-1.5,-0.3) -- (1.7,-0.3);
% \end{tikzpicture}  
%   \caption{Scheme for A B combinatorics}
%   \label{fig:AN_combinatorics}
% \end{figure}
% AUCH LINK VON A DIREKT ZU B!
As the scheme indicates, we assume that context and world knowledge are
responsible for any further specification of the meaning of an AB combination. 
\is{meaning shifts|(}
Specifically, we assume that
A as well as B can be shifted from their literal meaning to a
secondary meaning, labeled A' and B'. \is{literal meaning!{meaning shifts and}}
Metaphors and metonyms present
types of well-known shifts, other candidates would be e.g. the process
of \isi{meaning differentiation}, cf. \citet{Bierwisch:1982}.\is{metaphor}\is{metonymy}
% confined
% ourselves to metaphorical and  metonymical in nature. \textbf{[Rev2: are there
%   additional shifts that might be predictors?]}
However, even after a shift,
they are still linked to the other part of the construction via the R
relation. This kind of semantics for AB combinations therefore clearly falls
into the category of radically underspecified approaches (cf. the
characterization in \citealt[128]{Blutner:1998}, and the approaches discussed in Chapter \ref{cha:semantics}, Section \ref{sec:other_solutions}). \is{underspecification!radical}
At the same time, it is
much in the spirit of the analyses of determinative compounds presented in \citet{Fanselow:1981}, cf. Chapter \ref{cha:semantics}, Section \ref{sec:fanselow_1981}. With him we assume
that the specification of the exact relationship between the
denotations as well as the shifts of the A and B parts fall into the
domain of pragmatics. 

\newpage
The most basic configuration possible would be one where A and B
retain their original meaning, and the relationship is set to
identity. That is, the property expressed by A and by B hold of the
very same entity, and the semantics is thus intersective. 
These combinations might be regarded as the most
transparent AB combinations. Classic examples result from the combination of
Kamp's (1975) predicative adjectives with a nominal head,
e.g. \emph{four-legged animal}. Feeding \emph{four-legged} and
\emph{animal} into the underspecified template above,
cf. \ref{ex:underspecified} and setting the relation parameter to
identity results in \Next, and since x and y are
identical, the formula can be simplified, cf. \NNext.

\ex. \label{ex:four-legged_underspecified}
$\lambda$y $\lambda$ x [FOUR-LEGGED(x) \& =(x,y) \& ANIMAL(y)]

\ex. \label{ex:four-legged_simplified}
$\lambda$ x [FOUR-LEGGED(x) \& ANIMAL(x)]

In our scheme, this configuration can be represented as in \figref{fig:fourlegged-animal}.

\begin{figure}[!htb]
  \centering
\begin{tikzpicture}[>=stealth]
\node [shape= rectangle, draw] (context) {context/world knowledge};
\node (placeholder_firstline) [below=of context]  {};
\draw (0,-1) node (label_context-R)  {specifies};
\node (relationR) [below=of placeholder_firstline]  {\textbf{=}};
\node (placeholder_thirdline) [below=of relationR]  {};
% \node (compoundpartA) [left=of placeholder_firstline]{FOUR-LEGGED};
\node (compoundpartA) [left=of placeholder_firstline]{\textbf{A}};
\node (compoundpartB) [right=of placeholder_firstline] {\textbf{B}};
\draw (4.8,-1) node (label_west)  {initiates shifts};
\draw (-4.8,-1) node (label_east)  {initiates shifts};
\node (shiftedcompoundpartB) [right=of placeholder_thirdline] {B'};
\node (shiftedcompoundpartA) [left=of placeholder_thirdline] {A'};
\node (placeholder_secondlinewest) [left=of relationR]  {};
\node (placeholder_secondlineeast) [right=of relationR]  {};
%\draw (0,-5.95) node (shiftedAB) {(AB)'};

\draw [->,thin] (compoundpartA) -- (shiftedcompoundpartA);
\draw [->,thin] (compoundpartB) -- (shiftedcompoundpartB);
\draw [-,very thick] (compoundpartA.east) -- (relationR.west);
\draw [-,very thick] (compoundpartB.west) -- (relationR.east);
\draw [-] (shiftedcompoundpartA.east) -- (relationR.west);
\draw [-] (shiftedcompoundpartB.west) -- (relationR.east);
\draw[thick,dotted] [-] (context.south) to  (label_context-R);
\draw[thick,dotted] [->] (label_context-R.south) to  (relationR);
\draw[densely dashed] [->] (context.east) to [bend left=45]
(placeholder_secondlineeast);
% \draw[densely dashed] [->,thick] (context.east) to [bend left=70] (2.5,-5.25);
% \draw[densely dashed] [->,thick] (context.west) to [bend right=70] (-2.5,-5.25);

\draw[densely dashed] [->,thick] (context.west) to [bend right=45] (placeholder_secondlinewest);

% \draw[densely dashed] [->,thick] (0,-4.9) to  (0,-5.5);

%\draw [decoration={brace,mirror,amplitude=0.5em},decorate,thick]
% (-2,-4.75) -- (2,-4.75);


\end{tikzpicture}  
  
  \caption{Schematic semantic representation of the combination \emph{four-legged animal}. Both constituents remain unshifted, and the relation parameter is set to identity.}
  \label{fig:fourlegged-animal}
\end{figure}

\nocite{Kamp:1975} 
However, even for standard examples of intersective modification further
differentiation is needed, cf. the discussion in Chapter
\ref{cha:semantics}, Section \ref{sec:problems_basic}.
% overview in 
% \citet{Blutner:1998}, and
% \citet{Kennedy:2007} specifically for gradable adjectives. 
Examples for shifted As and Bs are presented in Section \ref{sec:bell-schaefer-annotation-results}.

% \paragraph{The relation R}

In order to use the abstract scheme for classification, 
% we decided to
% use 
% As mentioned above, the underlying semantic format we assume is radically
% underspecified, and it is pragmatics and world knowledge that determine how
% the parameter R is specified. Since we hypothesize that the exact
% specification of R will have an influence on the semantic transparency of the
% AB combination, we need a way to distinguish between different possibilities of
% fixing R. Proposals for generalizations over this R relation can be taken from
% the large literature essentially concerned with developing generalizations
% over possible relations, for English most famously in \citet{Lees:1970},
% \citet{Warren:1978} and \citet{Levi:1978}. We 
we chose the classification scheme
based on the recoverably deletable predicates introduced in
\citet{Levi:1978}.\is{semantic relations!recoverably deletable predicates}
%  (cf. the overview of relation-based
% compound analyses and the introduction to Levi's system in chapter
% \ref{cha:semantics},  section \ref{sec:relation-based-approaches}). 
% To encode the relations that can be used to specify the R-parameter,
% we used the classification system of \citet{Levi:1978} which 
% \enlargethispage{1\baselineskip}
Levi's system has 
proven itself to be useful in computational linguistics as well as in psycholinguistic approaches
(cf. the discussion in Chapter
\ref{cha:semantics}, where Section \ref{sec:levi_predicates_overview} introduces her recoverably
deletable predicates in detail and Section
\ref{sec:semrel-compound-classification} discusses the continued
popularity of her approach as a classification scheme). 
% ; for
% its usefulness in computational linguistics approaches,
% cf. \citealt{Oseaghdha:2008}; its usefulness for psycholinguistic
% approaches is demonstrated by the many experiments that use her system
% or an extented variant thereof, cf. the discussion of the conceptual
% combination approaches in  Chapter \ref{cha:semTranPsycho}, Section
% \ref{sec:conceptual_combination}, and the discussion of
% \citealt{PhamandBaayen:2013} in  Chapter \ref{cha:modPrevious}, Section \ref{sec:phambaayen2013}). 


For the 2 cases where we couldn't classify
the compounds into one of her recoverably deletable predicates, we used the label
\textsc{none}. In Levi's analysis, these 2 compounds, \emph{rat
  race} and \emph{number crunching}, fall into the category of
predicate nominalizations. 
%  (cf. also the discussion in \citet{Oseaghdha:2008}),
% fully aware that her scheme, or in fact any generalized scheme, will not allow
% one to reproduce the exact meaning nor all the possible meanings of AB
% combinations (for comprehensive criticism to this end,
% cf. \citet{Downing:1977,Fanselow:1981}). On the other hand, note that
% \citet{Gagneetal:2009}, in a series of priming experiments, find that the ease
% of deriving the meaning of a compound word `is mutually determined by the ease
% with which the constituents can be assigned to a particular role within a
% relational structure and by the availability of the appropriate relational
% structure.' Since there is evidence that these relational structures have psychological reality, it seems likely that not only the semantics of the
% individual constituents, but also the relation between them, contributes to
% overall level of transparency. 
 

% \paragraph{Whole compound shifts}

In our scheme, we also allow for whole compound shifts. At this point, we just
indicate this possibility by the (AB)' in the scheme, without distinguishing
in detail between the further internal possibilities. A very clear example of
a whole compound shift is the derogative \emph{asshole}, examples from the
Reddy et al. dataset used in the analysis include \emph{ivory tower}
and \emph{cloud nine}. Concurrent shifts of constituents and the whole
compound can be illustrated by a combination like
\emph{buttercup} which was already used as an example in the
introductory chapter: both \emph{butter} and \emph{cup} are
metaphorically shifted, standing for the color and the shape of the
flower of the plant. The compound as a whole can be analyzed as
metonymically shifted, referring to the plant and not just the flower
of the plant. \is{meaning shifts|)}

\subsection{Annotation results}
\label{sec:bell-schaefer-annotation-results}

We coded the set of compounds for the semantic variables that are
contained in the
scheme introduced in the last section, Section
\ref{sec:bell-schaefer-sem-annotation}. For the shifts, we distinguished
between metaphoric and metonymic shifts (for more on the encoding of
shifts, including the distinction between the 2 types of shifts, compare the discussion in Section \ref{sec:bell&schaefer2013_shifts}). \is{meaning shifts!coding}\is{metaphor!{coding metaphoric shifts}}\is{metonymy!{coding metonymic shifts}}
The semantic codings used in
that paper are available at
\url{www.martinschaefer.info/publications/TFDS-2013/TFDS-2013_Bell_Schaefer.zip}. The
semantic coding was reading-specific: each token was coded
according to the reading chosen by the particular rater,
so different tokens of the same compound did not necessarily receive
identical coding.  This coding was done by Melanie Bell and me; we first coded independently, and then discussed the results
to reach a consensus about those items where we initially
disagreed. For 2 compounds, \emph{kangaroo court} and \emph{flea
  market}, we were unable to reach consensus and these were therefore
subsequently excluded. That no agreement could be reached on these 2
items is perhaps not surprising, since in both cases the etymology is
quite unclear: For \emph{kangaroo court}, a term originating from the
US, one finds the following remark in the Merriam-Webster online
dictionary \citep{Merriam-Webster:2015}: ``A \emph{kangaroo court} has never been a court by or for kangaroos, but beyond that, little is known for sure about the term's origins."   
% (OED: n. orig. U.S. an improperly constituted court having no legal standing, e.g. one held by strikers, mutineers, prisoners, etc.) http://www.merriam-webster.com/dictionary/kangaroo%20court is sometimes explained
\emph{Flea market} is often explained with reference to the French \emph{marché aux puces}, see \cite{Mike:2012} for this and alternative theories.
%  https://web.archive.org/web/20120321163308/http://blog.aurorahistoryboutique.com/tag/fly-market/
Excluding the ratings for these 2 items left us with 1,310 ratings. 
% One compound,
% \emph{rat race}, was coded with the relation \textsc{None}.

\figref{fig:number-of-coded-relations} gives an overview of the
distribution of the compound readings over the coded relations.
\begin{figure}[!htb]
  \centering
\includegraphics[scale=.72,clip, trim= 0mm 5mm 15mm 20mm]{./figures/frequency-of-coded-relations.pdf}
% \includegraphics[scale=.72,clip, trim= 0mm 0mm 0mm 0mm]{/home/martin/Dropbox/statistics/habil-stat/bell-schaefer-2013-revisited/frequency-of-coded-relations.pdf}
% \includegraphics[scale=.85,clip, trim= 0mm 0mm 0mm 0mm]{/home/martin/Dropbox/statistics/habil-stat/bell-schaefer-2013-revisited/frequency-of-coded-relations.png}
  
  \caption{Distribution of compound readings over the semantic
    relations in the
    data used in Bell \& Schäfer 2013.}
  \label{fig:number-of-coded-relations}
\end{figure}
What \figref{fig:number-of-coded-relations} shows very clearly is that most of the relations
occur in the dataset only very rarely. One relation, \textsc{cause1},
does not occur at all. An overview of the semantic coding by relation
can be found in Appendix A.% , section \ref{sec:appendix_semantic-coding-2013}.

% As far as shifts of the A and B constituents were concerned, we only
% distinguished between metaphorical and metonymic shifts. 

The following examples from the dataset illustrate our coding scheme:
\emph{application form}, in its reading as \emph{a form to use when making an application}, was classified as having unshifted first and second
constituents, and the parameter R was set to \textsc{for} (`a form for an application').
In contrast, \emph{crash course}, defined as \emph{a rapid and intense course of training or research}, contains a metaphorical shift of the
first element (`something fast and intense'), and R is set to \textsc{be}. A
metaphorical shift of the second element is exemplified by \emph{eye
  candy}, where \emph{candy} is shifted to mean \emph{something
  pleasing but intellectually undemanding}. Again, the relationship is \textsc{for}. \emph{Ground
  floor} exemplifies the \textsc{in}-relation, which includes temporal and spatial location, and \emph{brick wall}
exemplifies the \textsc{make2} relation.

We also coded whether the compound as a whole had been shifted, as in \emph{ivory tower} for example. \emph{Ivory tower} as a whole stands for `A
condition of seclusion or separation from the world' (OED online), and it is not possible
to synchronically decompose it further in any sensible way. However, it is
clear to the native speaker that there has been a shift; otherwise it
is inexplicable why, although neither \emph{ivory} nor \emph{tower} have anything to do
with its current meaning, the concept of \emph{tower} still shines
through in expressions like \emph{live in ivory towers/assault their
  ivory towers/geek atop an ivory tower}. 
% Note that in coding we tried
% to keep R simple, that is, for \emph{silver screen} we set R to BE
%  (note that here the information that it is derived
% from the French \emph{tour d'ivoire} does not at all change this).

As the examples already show, in the case of constituent shifts the
relation between the constituents was classified after the application
of the shifts. 
In contrast, as noted in Section \ref{sec:levi_scope}
in Chapter \ref{cha:semantics}, \citet{Levi:1978} excluded shifted
compounds, in fact, all lexicalized compounds.

Because we annotated the specific senses and not the compound types, we ended
up with 100 annotated compound readings (2 of the 12 compounds where both
definitions were used did not occur in our chosen subset of the data).

\figref{fig:frequency-of-coded-shifts} shows the distribution of
compound readings over the different types of
shifts.\is{metaphor!{in the Bell \& Schäfer (2013) coding}}\is{metonymy!{in the Bell \& Schäfer (2013) coding}}

\begin{figure}[!htb]
  \centering
% \includegraphics[scale=.85,clip, trim= 0mm -1mm 0mm 0mm]{/home/martin/Dropbox/statistics/habil-stat/bell-schaefer-2013-revisited/frequency-of-coded-shifts.png}
% \includegraphics[scale=.72,clip, trim= 0mm -1mm 0mm 0mm]{/home/martin/Dropbox/statistics/habil-stat/bell-schaefer-2013-revisited/frequency-of-coded-shifts.pdf}
\includegraphics[scale=.72,clip, trim= 0mm 10mm 10mm 20mm]{./figures/frequency-of-coded-shifts.pdf}
  
  \caption{Frequency of compound readings per coded shifts  in the
    data used in Bell \& Schäfer 2013.}
  \label{fig:frequency-of-coded-shifts}
\end{figure}

% \enlargethispage{1\baselineskip}
As the histogram shows, metaphoric shifts are relatively frequent in our
data, whereas there are only very few compound readings that we coded
as metonymic shifts.\is{frequency!of shifts in the Reddy et al. dataset}
An overview of the semantic coding by shift can be found in Appendix
A.% the appendix, section \ref{sec:appendix_semantic-coding-2013}.



           

\subsubsection{Additional frequency-based variables}
\label{sec:bell-schaefer-freq}

\is{frequency!{based variables in Bell \& Schäfer (2013)}|(}
In addition to the semantic variables, we extracted a number of frequency
measures from the British National Corpus (cf. \citealt{BNCxml}), namely the lemmatized
frequencies of the individual constituents and of the whole
compound. For the latter, we extracted the frequencies for all 3
possible forms, that is, spaced, hyphenated or concatenated (=written as a
single word) occurrences. The concatenated and hyphenated occurrences were
summed into the single category unspaced.  
All frequencies where logarithmized, using the natural logarithm.
% , that is, the logarithm with the base \emph{e}, Euler's number. 
Because
some frequency counts were 0, we always added 1 to all frequency
counts.
% , in order to avoid taking the logarithm of 0 (which for the
% natural logarithm is $-\infty$). 
The effect of logarithmizing the
data is that the effect of skewing is reduced and distributions become
more symmetrical. Many statistical techniques do not
work appropriately with skewed data (cf. \citealt[31]{Baayen:2008a}).
\citet[954]{KupermanandBertram:2013} use logarithmization on their
dependent variable (lexical decision times) and all frequency-based
measures ``to attenuate
the influence of outliers on the predictions of statistical models'' \citep[954]{KupermanandBertram:2013}.
% ``We (natural-)log transformed lexical
% decision latencies, as well as all frequency-based measures in this dataset to attenuate
% the influence of outliers on the predictions of statistical models:''\citet[954]{KupermanandBertram:2013}

\is{compound measures!{spelling ratio}|(}
On the basis of the frequency measures, we calculated an additional
derivative measure, 
the `spelling ratio' for each compound: this is the proportion of
tokens that are written unspaced. The formula we used for the
calculation is given in \Next and illustrated with the help of 2
compounds from our data, \emph{bank account} and \emph{swan song}, in
\NNext. This measure has previously been hypothesized to be a
correlate of lexicalization, cf. \citet[496]{BellandPlag:2012}.
% \is{spelling ratio}

% \ex. `spelling ratio': proportion of tokens (in BNC) that are written unspaced
\ex. spelling ratio: proportion of tokens that are written unspaced\\[.5em]
\( \displaystyle \text{spelling ratio} =  log(\frac{\text{unspaced freq}}{\text{spaced frequency}}) \)
% hamburg$spellingRatio <- hamburg$logNonspacedFreq - hamburg$logSpacedFreq 
% Recall: ln(x/y) = ln(x) - ln(y) ('quotient rule')

\ex. \a. bank account:  
\a. raw frequencies in the BNC:
\a. $<$bank account$>$\hspace*{.01cm} 286
\b.$<$bank-account$>$\hspace*{.41cm} 2
\c. $<$bankaccount$>$\hspace*{.55cm} 0 \vspace*{.5em}
\z.
\b. spelling ratio = \( \displaystyle log(\frac{3}{287}) = -4.561 \) %$-4.56087$
\z.
\b. swan song:  
\a. raw frequencies in the BNC:
\a. $<$swan song$>$\hspace*{1cm} 11
\b.$<$swan-song$>$\hspace*{.98cm} 11
\c. $<$swansong$>$\hspace*{1.1cm} 29 \vspace*{.5em}
\z.
\b. spelling ratio = \( \displaystyle log(\frac{41}{12}) = 1.229 \) %1.228665$
% log(41/12)
% [1] 1.228665

% hamburg$spellingRatio <- hamburg$logNonspacedFreq - hamburg$logSpacedFreq 
%
%
%
% which is taken to be a measure of
% the degree of lexicalization (\citealt{BellandPlag:2012}).
%
% head_teacher	head	44347	teacher	20068	196	head-teacher	6	headteacher	413
% 193 	91.9%
% 2 	NN1 NN1 	17 	8.1%
% \newpage
Note that a measure very similar to the spelling ratio is introduced
in \citet[954]{KupermanandBertram:2013} as BiasC, the bias towards
concatenated spelling which is calculated by dividing the number of
concatenated forms by the total number of compound realizations
(cf. also the discussion of Experiment 2 of \citealt{Marellietal:2014}
in Chapter \ref{cha:modPrevious}, Section
\ref{sec:marelli-et-al-2014-ex2}).
% \is{BiasC}
\is{compound measures!{BiasC}}\is{compound measures!{spelling ratio}|)}
\is{frequency!{based variables in Bell \& Schäfer (2013)}|)}




\subsection{Bell and Schäfer (2013): the models}
\label{sec:bell-and-schaefer-models}

A first decision to be taken when modeling data from a Likert scale
rating exercise is to decide how to treat the data. On the face of
it, Likert scales produce ordinal data, that is, the relationship
between the values only establishes a ranking, nothing more. However,
it is common practice to treat the results as interval-level
measurements, and \citet{BellandSchaefer:2013}
follow this practice. For more detailed discussion, 
cf. the arguments against this practice in \citet{Jamieson:2004} and
the arguments for this practice in \citet{Norman:2010}.\is{Likert scale!{as ordinal or continuous data}}

The frequency and semantic variables were used as predictors in
ordinary least squares regression analyses with transparency of the
compound or its constituents as the dependent variables. 
% To alleviate
% the potentially harmful effects of extreme values on our statistical
% models, all quantitative predictors were first logarithmatised. 
Some
of the semantic categories, including all metonymical shifts and
several values of the free parameter R, applied to very few compounds in the
dataset. This would greatly reduce the power of any statistical
analysis involving these variables: failure to reach significance
could be the result of low frequency in this particular set of
compounds or significant effects could be due to other features of
those particular types. We therefore included in the analyses only
metaphorical shifts and the 3 most frequent values of R, namely
\textsc{for, in} and \textsc{be}. Each of the classes coded was
represented by at least 9 types (i.e. compound senses) and 140 tokens
in our data. % \marginpar{\textbf{CHECK: Do I mention this elsewhere?}}

All statistical analysis was done with R \citep{Rbase}. For the effect plots, I used the effects package, cf. \citet{effects}.\is{r-packages!\texttt{effects}} 

\is{collinearity|(}
We also investigated to what extent the
different numerical predictors we intended to use are correlated with
each other, that is, to what extent there exists collinearity in our
data. For 2 explanatory variables to be collinear means that there
exists an exact linear relationship between them, that is, when mapped
against each other on a graph, the result is a straight line. To
investigate and reduce the collinearity in our data, we follow the
procedure in \citet[181--183]{Baayen:2008a}, using the condition number
provided by the function \texttt{collin.fnc()} from \citet{languageR} to
indicate the overall degree of collinearity (this way of calculating
the condition number follows \citealt{Belsleyetal:1980}).\is{r-packages!\texttt{languageR}} 
 Further, we
used the \texttt{varclus()}
function from \citet{Hmisc} to perform hierarchical cluster analysis
allowing us to visually inspect the correlational structure.\is{r-packages!\texttt{Hmisc}}
Based on this procedure, we decided to exclude all direct compound
based frequency measures, and instead we just used the spelling ratio. 
This yields a condition number of 22.562, %22.56191
indicating a moderate but
not harmful level of collinearity in the explanatory variables (cf. \citealt[182]{Baayen:2008a}). \is{collinearity|)}


The explanatory variables used in the models are listed in \Next.

\ex. \a. numerical explanatory variables
\a. logarithmized frequency N1
\b. logarithmized frequency N2
\c. spelling ratio
\d. transparency rating N1
\d. transparency rating N2
\z.
% # [1] "STN1"          "STN2"          "logFreqN1"     "logFreqN2"    
% # [5] "spellingRatio"
\b. categorical (binary) explanatory variables
\a. \textsc{for}
\b. \textsc{in}
\c. \textsc{be}
\d. N1 metaphor
\d. N2 metaphor
\d. whole compound metaphor
\z.

\subsubsection{Model 1}
We first modeled the overall transparency of the compound, as given by
the human raters, using our semantic and frequency-based variables as
predictors. Since \textsc{be} is not significant, we removed it from the model,
resulting in the final model shown in \tabref{potsdam-table-rev-1}.
% and represented graphically in \figref{fig:bellschaefer2013_model_1}.
%  shows the final model, from which all
% non-significant predictors have been removed step-wise, following
% standard procedures of model simplification. 
Positive coefficients indicate a tendency towards higher transparency, while negative coefficients indicate a tendency
towards lower transparency, i.e. opacity. 
The significant predictors are
represented graphically in \figref{fig:bellschaefer2013_model_1}. In all cases,
the vertical axis represents the semantic transparency of the whole compound as given by the human raters. For the categorical variables,
the dots indicate the mean transparency ratings in the presence or
absence of the pertinent semantic feature. For the continuous
variables, the graphs show regression lines. In addition, the rug plot on the horizontal axis gives the marginal distribution of the
predictor, in other words, it shows the actual distribution of the
values of that predictor in the data. Confidence bounds are indicated
by error bars for the categorical variables and by confidence bands
for the continuous variables, using 95\% confidence limits. 
To show the effect of
each predictor in turn, the other predictors are adjusted to their
reference level (for categorical variables) or to their means (for
continuous predictors). The reference level for the categorical
variables is ‘no’: in other words, the model shows the effect of
independently varying each predictor in a situation where none of the
(other) semantic categories applies.



% \input{potsdam-table-rev-1}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%
%%%%%  BEGIN TABLE Revised Model 1
%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% # Linear Regression Model
% # 
% # ols(formula = ST ~ Ametaphor + Bmetaphor + ABmetaphor + In + 
% #     For + logFreqN1 + logFreqN2 + spellingRatio, data = j)
% # 
% #                 Model Likelihood     Discrimination    
% #                    Ratio Test           Indexes        
% # Obs     1310    LR chi2    813.04    R2       0.462    
% # sigma 1.3415    d.f.            8    R2 adj   0.459    
% # d.f.    1301    pr(> chi2) 0.0000    g        1.413    
% # 
% # Residuals
% # 
% #     Min      1Q  Median      3Q     Max 
% # -3.8745 -0.9690  0.1255  0.9951  3.8359 
% # 
% #                Coef    S.E.   t      pr(>|t|)
% # Intercept      -0.5861 0.3207  -1.83 0.0678  
% # Ametaphor=Yes  -0.6397 0.0939  -6.82 <0.0001 
% # Bmetaphor=Yes  -0.4841 0.0920  -5.26 <0.0001 
% # ABmetaphor=Yes -1.8411 0.0910 -20.23 <0.0001 
% # In=Yes          0.6041 0.1273   4.75 <0.0001 
% # For=Yes         0.2363 0.0882   2.68 0.0074  
% # logFreqN1       0.2830 0.0243  11.63 <0.0001 
% # logFreqN2       0.1535 0.0283   5.42 <0.0001 
% # spellingRatio  -0.1240 0.0249  -4.98 <0.0001 


% # Linear Regression Model
% # 
% # ols(formula = ST ~ Ametaphor + Bmetaphor + ABmetaphor + In + 
% #     For + logFreqN1 + logFreqN2 + spellingRatio, data = j)
% # 
% #                 Model Likelihood     Discrimination    
% #                    Ratio Test           Indexes        
% # Obs     1310    LR chi2    813.04    R2       0.462    
% # sigma 1.3415    d.f.            8    R2 adj   0.459    
% # d.f.    1301    pr(> chi2) 0.0000    g        1.413    
% # 
% # Residuals
% # 
% #     Min      1Q  Median      3Q     Max 
% # -3.8745 -0.9690  0.1255  0.9951  3.8359 
% \begin{table}[H]
\begin{table}[!htb]
  \centering
\begin{tabular}[h]{lrrrr}\lsptoprule
&      {estimate}&    {std. error}&   {t}  &    {pr($>|z|$)}\\\midrule
% &                      Coef&    S.E.&   t  &    pr($>|z|$)\\
(intercept)      &-0.5861 &0.3207&  -1.83& 0.0678\\  
N1 metaphor  &-0.6397 &0.0939&  -6.82& $<$0.0001 \\
N2 metaphor  &-0.4841 &0.0920&  -5.26& $<$0.0001 \\
N1N2 metaphor &-1.8411 &0.0910& -20.23& $<$0.0001 \\
\textsc{in}         & 0.6041 &0.1273&   4.75& $<$0.0001 \\
\textsc{for}         &0.2363 &0.0882&   2.68& 0.0074  \\
N1 frequency       &0.2830 &0.0243&  11.63& $<$0.0001 \\
N2 frequency       &0.1535 &0.0283&   5.42& $<$0.0001 \\
% logFreqN1       &0.2830 &0.0243&  11.63& $<$0.0001 \\
% logFreqN2       &0.1535 &0.0283&   5.42& $<$0.0001 \\
spelling ratio  &-0.1240 &0.0249&  -4.98& $<$0.0001 \\\tablevspace
\multicolumn{5}{l}{number of observations: 1310, d.f. 1301}\\\lspbottomrule
\end{tabular}
  \caption{Final model for compound transparency using semantic and frequency-based predictors, adjusted R\textsuperscript{2} = 0.459} % Frequencies are logarithmized.}
\label{potsdam-table-rev-1}
\end{table}

% table 1

% \begin{figure}[H]
\begin{figure}[!htb]
  \centering
% \includegraphics[scale=.5,trim=0 0 0 0, clip]{/home/martin/Dropbox/statistics/habil-stat/bell-schaefer-2013-revisited/bell-schaefer-2013_allEffects_model1_gridlayout.png}
% \includegraphics[scale=.4,trim=0 0 0 0, clip]{/home/martin/Dropbox/statistics/habil-stat/bell-schaefer-2013-revisited/bell-schaefer-2013_allEffects_model1_gridlayout.pdf}
\includegraphics[scale=.4,trim=0 0 0 10mm, clip]{./figures/bell-schaefer-2013_allEffects_model1_gridlayout.pdf}
  
  \caption{Effects in the final model for compound transparency using semantic and
    frequency-based predictors. The effects associated with meaning
    shifts are shown in the first row, the second row shows the
    effects associated with semantic relations and the frequency-based
  effects are shown in the third row.}
\label{fig:bellschaefer2013_model_1}
\end{figure}

It can be seen that both types of
predictor, semantic and frequency-based, were found to be
statistically significant. 
Transparency rating is lower when
either constituent, or the whole compound, is metaphorical. While the
coefficients associated with the metaphorical shifts of the
constituents are relatively small, a metaphoric shift of the whole
compound has a much bigger effect. 
In contrast, both semantic relations, \textsc{for} and \textsc{in}, are associated
with greater perceived transparency. 
% On the assumption that literality is a measure of semantic
% transparency, 
This suggests that the relation between constituents, as well as the semantics of the constituents themselves, contributes to transparency.
% frequency predictors
Transparency increases with increasing frequency of either constituent
and falls as the proportion of unspaced tokens increases. Both of
these findings are not unexpected. Higher frequency in general
facilitates processing and might therefore also make items appear to
be more transparent across the board. The
negative correlation with spelling ratio is in line with the
assumption that spelling ratio
can be used as a stand-in for lexicalization, and, in turn, the
additional assumption that 
lexicalization is associated with more opacity.
%, even in the presence of very strong predictors such as lexicalization and constituent frequencies. 

%The line graphs show that literality increases with increasing frequency of either constituent and that, as might be
%expected, literality falls as the proportion of unspaced tokens increases (i.e. as lexicalization increases). The first 3 graphs on the bottom row show that literality rating is lower when either constituent, or the whole compound, is metaphorical. Most significantly, however,
%the remaining 2 graphs show that certain semantic relations (\textsc{for} and \textsc{in}) are also associated with greater literality. On the assumption that literality is a measure of semantic transparency, this is the first evidence that the relation between constituents, as well as the

%semantics of the constituents themselves, contributes to transparency, even in the presence of very strong predictors such as lexicalization and constituent frequencies. \citet[156, 174ff, 192ff]{Fanselow:1981} argues for a semantic classification of compounds into those that show basic relations (`Grundrelationen') and those that show stereotypical relations (`Stereotypenrelationen').  Basic relations arise from basic properties common to all things: size, shape, location, material etc, whereas stereotypical relations arise from the stereotypes represented by particular nouns. Our results are suggestive of the idea that compounds involving basic relations might be more semantically transparent than those with stereotypical relations, and this is worthy of further investigation. A further finding is that, in this model,  only metaphorical shifts, and not metonymical ones, are significant in predicting degree of transparency. This suggests that metaphorical shifts are semantically more costly than metonymic ones, and again this warrants further research.

%Although the model has limited success in accounting for
%the total variance in literality (R$^2$ adj = 0.459), it should be
%remembered that these results are based on a very small sample of
%lexicalized compounds: we hypothesise that replication on a
%larger and more widely representative set of data would lead to stronger results.



\subsubsection{Model 2}
Model 2 is a second model for whole compound transparency, this time
including the ratings for constituent transparency as predictors. Why
did we want to include those ratings? The main reason was that
\citet[213--214]{Reddyetal:2011} show that there is a strong
correlation between the average transparency scores for the compounds
and those for their constituents (cf. also Chapter
\ref{cha:modPrevious}, Section \ref{sec:inter-score-relations}), so it
is to be expected that they would also be highly significant
predictors in our model. More importantly, though, on the assumption
that the properties of a constituent contribute to its degree of
transparency, we hypothesized that the constituent transparency
ratings would subsume the other constituent-based variables, namely
constituent frequency and semantic shifts of the constituents. We
therefore expected that these variables would become less significant
or even insignificant in the presence of the 2 predictors for
constituent transparency. \enlargethispage{1\baselineskip}
On the other hand, we expected that the
effects of semantic relations and whole-compound metaphorical shifts
would remain significant, since they are properties of the whole
compound, rather than either constituent.

%\begin{figure}[h]
\begin{figure}[H]
  \centering
% \includegraphics[scale=.5,trim=0 0 0 0, clip]{/home/martin/Dropbox/statistics/habil-stat/bell-schaefer-2013-revisited/bell-schaefer-2013_allEffects_model2_gridlayout.png}
% \includegraphics[scale=.4,trim=0 0 0 0, clip]{/home/martin/Dropbox/statistics/habil-stat/bell-schaefer-2013-revisited/bell-schaefer-2013_allEffects_model2_gridlayout.pdf}
\includegraphics[scale=.4,trim=0 0 0 10mm, clip]{./figures/bell-schaefer-2013_allEffects_model2_gridlayout.pdf}
  
  \caption{Effects in the final model for compound transparency
    including constituent transparencies as predictors. The effects associated with meaning
    shifts are shown in the first row, the second row shows the frequency-based
  effects and the effects of constituent transparency are shown in the third row.}
\label{fig:bellschaefer2013_model_2}
\end{figure}

% We next included the human ratings for , alongside those used in the previous
% model. \citet[213-214]{Reddyetal:2011} show that there is a strong correlation between the average
% transparency scores for the compounds and those for their constituents,
% so we expected that the constituent literality scores would be  



% \input{potsdam-table-rev-2}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%
%%%%%  BEGIN TABLE 2 revised model 2
%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Revised Model 2

% # Linear Regression Model
% # 
% # ols(formula = ST ~ Ametaphor + Bmetaphor + ABmetaphor + logFreqN1 + 
% #     logFreqN2 + STN1 + STN2, data = j)
% # 
% #                 Model Likelihood     Discrimination    
% #                    Ratio Test           Indexes        
% # Obs     1310    LR chi2   1765.10    R2       0.740    
% # sigma 0.9324    d.f.            7    R2 adj   0.739    
% # d.f.    1302    pr(> chi2) 0.0000    g        1.800    
% # 
% # Residuals
% # 
% #     Min      1Q  Median      3Q     Max 
% # -4.6554 -0.4753  0.1326  0.5045  3.1380 
% # 
% #                Coef    S.E.   t     pr(>|t|)
% # Intercept      -0.8117 0.2211 -3.67 0.0003  
% # Ametaphor=Yes  -0.2361 0.0720 -3.28 0.0011  
% # Bmetaphor=Yes  -0.2059 0.0726 -2.84 0.0046  
% # ABmetaphor=Yes -0.1849 0.0752 -2.46 0.0141  
% # logFreqN1       0.0804 0.0179  4.50 <0.0001 
% # logFreqN2       0.0506 0.0196  2.58 0.0100  
% # STN1            0.4558 0.0179 25.43 <0.0001 
% # STN2            0.4147 0.0180 23.03 <0.0001 

\begin{table}[!htb]
  \centering
\begin{tabular}[h]{lrrrr}\lsptoprule
%&                      coef&    st. error&   t  &    pr($>|z|$)\\
&      {estimate}&    {std. error}&  {t}  &    {pr($>|z|$)}\\\midrule
(intercept)      &-0.8117 &0.2211 &-3.67 &0.0003\\  
N1 metaphor  &-0.2361 &0.0720 &-3.28 &0.0011  \\
N2 metaphor  &-0.2059 &0.0726 &-2.84 &0.0046  \\
N1N2 metaphor &-0.1849 &0.0752 &-2.46 &0.0141  \\
N1 frequency      & 0.0804 &0.0179 & 4.50 &$<$0.0001 \\
N2 frequency     & 0.0506 &0.0196 & 2.58 &0.0100  \\
N1 transparency           & 0.4558 &0.0179 &25.43 &$<$0.0001 \\
N2 transparency            & 0.4147 &0.0180 &23.03 &$<$0.0001\\\tablevspace
\multicolumn{5}{l}{number of observations: 1310, d.f. 1302}\\\lspbottomrule
\end{tabular}


  \caption{Final model for compound transparency including constituent transparency ratings, R\textsuperscript{2} = 0.739}
\label{potsdam-table-rev-2}
\end{table}


The final model, from which all
non-significant predictors have been eliminated, is shown in \tabref{potsdam-table-rev-2}. The significant predictors are
represented graphically in \figref{fig:bellschaefer2013_model_2}.
As expected, the transparency ratings of the constituents are
highly significant predictors of overall transparency: in each case, the
more transparent the constituent, the more transparent the
compound. Surprisingly, however, the other constituent-based variables
remain significant even in the presence of the
constituent transparency ratings: though the effects are much weakened, an increase in frequency of either N1
or N2 still leads to greater overall transparency, while metaphorical shifts
of either constituent lead to greater opacity. It might be argued
that the strong effects in our models of metaphorical shifts are a
result of the data collection method: asking subjects to rate
literality may have led them actually to rate the presence or absence
of metaphor. However, if this were true, we would not expect the effects of metaphorical shift of A or B to survive in Model 2 alongside the constituent transparency ratings, since both types of predictor would be accounting for the same portion of the variance. An even more
unexpected finding is that, once constituent transparency ratings are
included in the model, lexicalization and semantic relations become insignificant as
predictors of overall transparency. This suggests that these relations
are correlated with the transparency of the constituents, so that they
account for the same portion of the overall variation.

\subsubsection{Models 3 and 4}
To test the hypothesis that the semantic relation between compound
constituents influences the extent to which the constituents are
perceived as transparent, we constructed 2 models with
the transparency ratings of A and B respectively as the dependent
variables, and our semantic and frequency-based variables as the
predictors.


\tabref{potsdam-table-rev-3} shows the final model for transparency of
the first constituent, with non-significant predictors removed. The significant predictors are
represented graphically in \figref{fig:bellschaefer2013_model_3}. 

% \input{potsdam-table-rev-3}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%
%%%%%  BEGIN TABLE 3 revised
%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Revised Model 3

% # Linear Regression Model
% # 
% # ols(formula = STN1 ~ Ametaphor + Bmetaphor + ABmetaphor + In + 
% #     logFreqN1 + logFreqN2 + spellingRatio, data = j)
% # 
% #                 Model Likelihood     Discrimination    
% #                    Ratio Test           Indexes        
% # Obs     1310    LR chi2    912.71    R2       0.502    
% # sigma 1.4462    d.f.            7    R2 adj   0.499    
% # d.f.    1302    pr(> chi2) 0.0000    g        1.662    
% # 
% # Residuals
% # 
% #      Min       1Q   Median       3Q      Max 
% # -4.55544 -0.96527  0.05439  1.07920  5.58317 
% # 
% #                Coef    S.E.   t      pr(>|t|)
% # Intercept      -0.3791 0.3418  -1.11 0.2676  
% # Ametaphor=Yes  -1.7234 0.1003 -17.19 <0.0001 
% # Bmetaphor=Yes   0.8728 0.0987   8.85 <0.0001 
% # ABmetaphor=Yes -1.8728 0.0939 -19.95 <0.0001 
% # In=Yes          0.9275 0.1344   6.90 <0.0001 
% # logFreqN1       0.3406 0.0262  12.99 <0.0001 
% # logFreqN2       0.0953 0.0305   3.13 0.0018  
% # spellingRatio  -0.0674 0.0268  -2.51 0.0122  

% \begin{table}[!htb]
\begin{table}[H]
  \centering
\begin{tabular}[h]{lrrrr}\lsptoprule
&      {estimate}&    {std. error}&   {t}  &    {pr($>|z|$)}\\\midrule
% &                      Coef&    S.E.&   t  &    pr($>|z|$)\\
(intercept)      &-0.3791 &0.3418 & -1.11 &0.2676\\  
N1 metaphor  &-1.7234 &0.1003 &-17.19 &$<$0.0001\\   
N2 metaphor  & 0.8728 &0.0987 &  8.85 &$<$0.0001\\   
N1N2 metaphor &-1.8728 &0.0939 &-19.95 &$<$0.0001\\   
\textsc{in}       & 0.9275 &0.1344 &  6.90 &$<$0.0001\\
N1 frequency      & 0.3406 &0.0262 & 12.99 &$<$0.0001\\   
N2 frequency      & 0.0953 &0.0305 &  3.13 &0.0018\\    
spelling ratio  &-0.0674 &0.0268 & -2.51 &0.0122\\ \tablevspace
\multicolumn{5}{l}{number of observations: 1310, d.f. 1302}\\\lspbottomrule
\end{tabular}

  \caption{Final model for transparency of N1 using semantic and
    frequency-based predictors. R\textsuperscript{2} =  0.499}
\label{potsdam-table-rev-3}
\end{table}

\begin{figure}[!htb]
  \centering
% \includegraphics[scale=.5,trim=0 0 0 0, clip]{/home/martin/Dropbox/statistics/habil-stat/bell-schaefer-2013-revisited/bell-schaefer-2013_allEffects_model3_gridlayout.png}
% \includegraphics[scale=.4,trim=0 0 0 0, clip]{/home/martin/Dropbox/statistics/habil-stat/bell-schaefer-2013-revisited/bell-schaefer-2013_allEffects_model3_gridlayout.pdf}
\includegraphics[scale=.4,trim=0 0 0 10mm, clip]{./figures/bell-schaefer-2013_allEffects_model3_gridlayout.pdf}
  
  \caption{Effects in the final model for N1 transparency. The effects associated with meaning
    shifts are shown in the first row, the second row shows the effect
    of semantic relations, and frequency-based
  effects  are shown in the third row.}
\label{fig:bellschaefer2013_model_3}
\end{figure}

It can be seen that of the 3 semantic relations, only \textsc{in} is a
significant predictor, being
associated with an increase in perceived transparency. Constituent 1
is also perceived as more transparent as the frequency of either
constituent increases. On the other hand, when the compound has a
higher spelling ratio, or when the whole compound has undergone
a metaphorical shift, the first constituent is perceived as less transparent;
similarly, when the first constituent itself has shifted
metaphorically, it is perceived as less transparent. 

However, in contrast
to the effects associated with metaphorical shifts of the first
constituent or the whole compound, a metaphorical shift of the second constituent
leads to the first constituent being perceived as more
transparent.\enlargethispage{1\baselineskip}
One possible explanation for this is that the
second constituent is used as a foil in assessing the transparency of
the first constituent, e.g., the more opaque the second constituent,
the higher the perceived transparency of the first constituent relative to the second constituent. 

\tabref{potsdam-table-rev-4} shows the final model for transparency
of the second constituent, again with non-significant predictors
removed. The significant predictors are
represented graphically in
\figref{fig:bellschaefer2013_model_4}. 

% \input{potsdam-table-rev-4}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%
%%%%%  BEGIN TABLE 4 revised
%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Revised Model 4

% # Linear Regression Model
% # 
% # ols(formula = STN2 ~ Ametaphor + Bmetaphor + ABmetaphor + For + 
% #     logFreqN1 + logFreqN2 + spellingRatio, data = j)
% # 
% #                 Model Likelihood     Discrimination    
% #                    Ratio Test           Indexes        
% # Obs     1310    LR chi2    906.28    R2       0.499    
% # sigma 1.4431    d.f.            7    R2 adj   0.497    
% # d.f.    1302    pr(> chi2) 0.0000    g        1.635    
% # 
% # Residuals
% # 
% #     Min      1Q  Median      3Q     Max 
% # -4.8529 -1.0834  0.2355  0.9553  4.2573 
% # 
% #                Coef    S.E.   t      pr(>|t|)
% # Intercept       1.2383 0.3448   3.59 0.0003  
% # Ametaphor=Yes   0.8382 0.1009   8.31 <0.0001 
% # Bmetaphor=Yes  -1.6511 0.0989 -16.70 <0.0001 
% # ABmetaphor=Yes -2.0563 0.0978 -21.02 <0.0001 
% # For=Yes         0.2241 0.0929   2.41 0.0160  
% # logFreqN1       0.1224 0.0259   4.73 <0.0001 
% # logFreqN2       0.1443 0.0304   4.75 <0.0001 
% # spellingRatio  -0.1563 0.0264  -5.93 <0.0001 
% \begin{table}[!htb]
\begin{table}[!htb]
  \centering
\begin{tabular}[h]{lrrrr}\lsptoprule
% &                      Coef&    S.E.&   t  &    pr($>|z|$)\\
&      {estimate}&   {std. error}&  {t}  &    {pr($>|z|$)}\\\midrule
(intercept)       &1.2383 &0.3448   &3.59 &0.0003 \\ 
N1 metaphor   &0.8382 &0.1009   &8.31 &$<$0.0001 \\
N2 metaphor  &-1.6511 &0.0989 &-16.70 &$<$0.0001 \\
N1N2 metaphor &-2.0563 &0.0978 &-21.02 &$<$0.0001 \\
\textsc{for}        & 0.2241 &0.0929  & 2.41 &0.0160\\
N1 frequency      & 0.1224 &0.0259   &4.73 &$<$0.0001 \\
N2 frequency      & 0.1443 &0.0304   &4.75 &$<$0.0001 \\
spelling ratio  &-0.1563 &0.0264  &-5.93 &$<$0.0001\\ \tablevspace
\multicolumn{5}{l}{number of observations: 1310, d.f. 1302}\\\lspbottomrule
\end{tabular}
  \caption{ Final model for transparency of N2, R\textsuperscript{2} =  0.498}
\label{potsdam-table-rev-4}
\end{table}

\begin{figure}[!htb]
  \centering
% \includegraphics[scale=.5,trim=0 0 0 0, clip]{/home/martin/Dropbox/statistics/habil-stat/bell-schaefer-2013-revisited/bell-schaefer-2013_allEffects_model4_gridlayout.png}
% \includegraphics[scale=.4,trim=0 0 0 0, clip]{/home/martin/Dropbox/statistics/habil-stat/bell-schaefer-2013-revisited/bell-schaefer-2013_allEffects_model4_gridlayout.pdf}
\includegraphics[scale=.4,trim=0 0 0 0, clip]{./figures/bell-schaefer-2013_allEffects_model4_gridlayout.pdf}
  
  \caption{Effects in the final model for N2 transparency. The effects associated with meaning
    shifts are shown in the first row, the second row shows the effect
    of semantic relations, and frequency-based
  effects  are shown in the third row.}
\label{fig:bellschaefer2013_model_4}
\end{figure}


This model is very similar to the model
for constituent 1, both concerning the number of significant
predictors as well as the direction of the effects. However, instead of the relation \textsc{in}, which
does not reach significance, it is
the relation \textsc{for} that is associated with an increase in
perceived transparency. Note that the magnitude of this effect is very
small. The effect of the constituent frequencies is likewise smaller
than the frequency effects in the model for constituent 1, and
the magnitude of the effect associated with N2 frequency is only
slightly bigger than that associated with N1 frequency. Perhaps most
interestingly, just as N2 metaphor was positively correlated with N1
transparency, N1 metaphor is positively correlated with N2
transparency. This supports the interpretation of the
constituent ratings as always relative to the transparency of the
respective other constituent.

That the effect of semantic relation on
compound transparency is mediated through the transparency of the
constituents, and that each constituent is associated with a different
relation allows one to tie in the results with recent work on
prosodic prominence in English noun noun compounds. \citet{Plagetal:2008}, for example, demonstrate that the \textsc{for} relation is correlated with stress on N1, whereas \textsc{in} is correlated with stress on N2. Furthermore \citet{BellandPlag:2012} show that stress tends to fall on the most informative constituent. If \textsc{for} is associated with greater transparency of N2, that might explain why in such compounds stress tends to fall on N1, the assumption being that the less transparent constituent is also the more informative. The reverse pattern would hold in the case of compounds with R set to \textsc{in}: N1 is more transparent, hence N2 is relatively more informative, hence prone to be stressed.

% However, the other predictors closely mirror the model for A. When either constituent is more frequent, B is perceived as more literal; when the compound is more highly lexicalized (as indicated by a higher spelling ratio), or when the whole compound has undergone metaphorical shift, constituent B is perceived as less literal.  Similarly, when B itself is metaphorical its literality rating is lower. Metaphorical shift of A, on the other hand, leads to B being perceived as more literal, presumably relative to A.

\section{\citet{BellandSchaefer:2013} revisited}
\label{sec:bell-and-schaefer-2013-revisited}

%
%  R code for this section:  r-bell-schaefer-rev-habil.R)
This section has 3 aims. Firstly, in Section \ref{sec:bell-schaefer-2013-model1-diagnostics} I will subject the first model
of \citet{BellandSchaefer:2013} to a standard model criticism routine
and report the results from running the models on slightly smaller
datasets with more outliers removed. 
Secondly, Section \ref{sec:bell-schaefer-lmer} will argue that mixed effects regression should be used
for the kind of data under investigation here, and all 4 models will
be rerun using this regression technique.
Finally, Section \ref{sec:bell&schaefer2013_shifts} will take a closer look at the role of the
meaning shifts and discuss in detail why the approach taken to meaning shifts in \citet{BellandSchaefer:2013} in retrospect does not
seem to be a convincing idea.
%  for the
% In general: why is the model using the ST1 and ST2 values doing so
% comparatively bad, given that it did so good with the mean values?
% BTW: A model using only ST1 and ST2 as predictors yiels an R$^2$
% adjusted of 0.727, but the model including the metaphoric shifts and
% frequency predictors is a significantly better model.

% Proceed in 3 steps:
% \begin{enumerate}
% \item Model internal criticism
% \item Using mixed effect regression
% \item Critizising the general idea of using shifts/relations in the
%   way we did
% \end{enumerate}


\subsection{Classic model criticism}
\label{sec:bell-schaefer-2013-model1-diagnostics}
In order to evaluate models using ordinary least square regression,
one can use a variety of diagnostics. Here, I will go through the
diagnostics for Model 1 from \citet{BellandSchaefer:2013} in some detail, before giving
short summaries of the results of using the same reduced dataset in
re-running the 3 other models.

\subsubsection{Model 1 revisited}
\label{sec:bell-schaefer-2013-model1-diagnostics:Model1}


\figref{fig:residual-plots} shows the distribution of the
residuals. By and large, their distribution follows the normal
distribution, although, as the quantile-quantile plot shows, the
distributions differ in their tails, with the residuals being larger
in the lower tail, and smaller in the upper tail. 
% That is, it is somewhat difficult for the model to predict the smaller   

\begin{figure}[!htb]
  \centering
% \includegraphics[scale=.85,clip, trim= 0mm 0mm 0mm 0mm]{/home/martin/Dropbox/statistics/habil-stat/bell-schaefer-2013-revisited/bell-schaefer-2013-model-1_residuals.png}
% \includegraphics[scale=.7,clip, trim= 0mm 0mm 0mm 0mm]{/home/martin/Dropbox/statistics/habil-stat/bell-schaefer-2013-revisited/bell-schaefer-2013-model-1_residuals.pdf}
\includegraphics[scale=.7,clip, trim= 0mm 0mm 0mm 0mm]{./figures/bell-schaefer-2013-model-1_residuals.pdf}
  
  \caption{Density and quantile-quantile plot of the residuals of
    Model 1 presented in \citet{BellandSchaefer:2013}}
  \label{fig:residual-plots}
\end{figure}


Plotting the standardized
residuals against the fitted values, that is, the values predicted by the
model formula allows us to
check whether there is a correlation between the residuals and the
fitted values. If there is no correlation, that is, the variance in
the error term is constant across the x-values, then the assumption of
homoscedasticity is fulfilled. 
\figref{fig:residual-fitted-plots} shows the standardized
residuals of Model 1 plotted against the corresponding fitted values.
\begin{figure}[!htb]
  \centering
% \includegraphics[scale=.80,clip, trim= 0mm 05mm 0mm 20mm]{/home/martin/Dropbox/statistics/habil-stat/bell-schaefer-2013-revisited/bell-schaefer-2013-model-1_residuals-vs-fitted.png}
% \includegraphics[scale=.65,clip, trim= 0mm 05mm 0mm 20mm]{/home/martin/Dropbox/statistics/habil-stat/bell-schaefer-2013-revisited/bell-schaefer-2013-model-1_residuals-vs-fitted.pdf}
\includegraphics[scale=.65,clip, trim= 0mm 05mm 0mm 20mm]{./figures/bell-schaefer-2013-model-1_residuals-vs-fitted.pdf}
  
  \caption{Standardized residuals vs. fitted values of the 
    Model 1 presented in \citet{BellandSchaefer:2013}}
  \label{fig:residual-fitted-plots}
\end{figure}
Ideally, the mean should be on the horizontal line at 0, and there
should be no change in variance across the fitted values. As the error
terms should be randomly distributed, we also would not expect to see
a pattern in the plot. 

Inspecting the plot, we see that the mean does not form a straight
line, note especially the upward swerve toward the left edge of the
plot, where the prediction of values outside of the original scale
used, `-1', led to large and unbalanced residuals. However, one can
also see that this is caused by only a few data points which can
be identified using dedicated outlier detection functions, see
the discussion below. Furthermore, one notices a pattern as
there are 6 horizontal evenly distanced stripes running from the upper
left to the lower right. This pattern is due to the fact
that the actual values to be modeled all come from a 6 point Likert
scale. That is, fitted values with zero residuals are only possible at
the 6 discrete values of the scale. This pattern is therefore a
natural consequence of treating Likert scale ratings like continuous
data. 
% (cf. the points in \textbf{WHERE?}).
% \marginpar{TODO: idendify the residual vs. fitted points!}

Having seen that the model, as the standardized
residuals vs. fitted values plot has shown,  is still considerably
influenced by a few single datapoints, I now turn to
diagnostics for outlier detection. One method is to look at the differences in the fits, that is, the
difference in the fitted value for an observed data point in a model
that was built with that data point as opposed to a model where that
data point has not been used in the model building. If the difference
is large, this means that this single data point has high leverage on
the resulting model, that is, its inclusion changes the model
considerably. \figref{fig:diffits} shows the values for Model 1.

\begin{figure}[!htb]
  \centering
% \includegraphics[scale=.85,clip, trim= 0mm 05mm 0mm 20mm]{/home/martin/Dropbox/statistics/habil-stat/bell-schaefer-2013-revisited/bell-schaefer-2013-model-1_diffits.png}
% \includegraphics[scale=.65,clip, trim= 0mm 05mm 0mm 20mm]{/home/martin/Dropbox/statistics/habil-stat/bell-schaefer-2013-revisited/bell-schaefer-2013-model-1_diffits.pdf}
\includegraphics[scale=.65,clip, trim= 0mm 05mm 0mm 20mm]{./figures/bell-schaefer-2013-model-1_diffits.pdf}
  
  \caption{Differences in the fits for the 
    Model 1 presented in \citet{BellandSchaefer:2013}}
  \label{fig:diffits}
\end{figure}


The 5 spikes in the plot crossing the 0.25 value are caused by 2 datapoints for
\emph{crocodile tears}, and one each for \emph{silver bullet},
\emph{silver screen}, \emph{silver spoon}, and \emph{web site}. As
all 5 compounds are only rated on one of their readings, the only
difference between these datapoints and the other datapoints coming
from the same compound types lies in the
ratings themselves. Thus, the mean of the transparency ratings for
\emph{crocodile tears} is 1.727, % 1.727273
and the 2 datapoints identified here
are the only 2 points where the subjects chose a rating of 3, the
highest rating selected for this compound type.

A further diagnostic, the dfbetas, allows us to detect datapoints not
via their leverage for the whole model but via their influence on the model's individual
predictors. Here, the only predictor unduly influenced is the
logarithmized N2 frequency, and the responsible 7 datapoints come all
from the ratings on \emph{crocodile tears}. Not surprisingly, these 7
datapoints include the 2 points already identified by using the
differences in fit. Notably, the ratings are those where the item was rated with
2 or 3, which is not in line with it having the lowest N2 frequency
(the unsuspicious datapoints have been rated with 0 or 1). This
finding is confirmed when looking at the flagged output of the generic
outlier detection function for regression models build with the \texttt{lm()} function,
\texttt{influence.measures()}. 
% both from R's base, in the stats package.
Just as we have seen for the datapoints identified before, the
common pattern in the compounds containing the outliers is huge variation in the given transparency ratings.

What this suggests is that it would be helpful to exclude outliers in
the ratings more thoroughly.
% If
% we use other diagnostics, the problems have in one case to do with
% high variation in the ratings, perhaps most extreme in the first
% reading of \emph{brass ring}. This was chosen 4 times and judged with
% "1","2","3","5". However, other items show similar high
% variation. 
Reddy et al. did not accept all judgments and applied a 1.5 deviation
from the mean criterion to exclude outliers, but this was only applied
when subjects fell under a certain correlation threshold, not across
the board (cf. the remarks in Chapter \ref{cha:modPrevious}, Section
\ref{sec:Reddyetal2011sum}). If applying the $\pm$1.5 deviation from
the mean across the board, the 1,310 observations are reduced by 163
datapoints, leaving 1,147 transparency judgments. Note that other
procedures, e.g., examining the contribution of every subject and of
every item in terms of its conformity with the normal distribution, do
not make sense here, because (1) many subjects made too few
contributions and (2) the distribution of the ratings overall does not
follow the normal distribution in the first place (see the discussion
and especially \figref{fig:reddy-means-whole-compound} in Section
\ref{sec:descriptive-statistics} above).\enlargethispage{1\baselineskip}
\tabref{bell-schaefer-2013-table-revisited-1} shows the final model
for compound transparency using the reduced dataset.

% # [1] 1147   62
% jena1Cleaner.lm <- lm(ST ~ Ametaphor  + Bmetaphor  + ABmetaphor   + In  + For + logFreqN1 + logFreqN2 + spellingRatio, data=jexClean)
% # summary(jena1Cleaner.lm)
% # Call:
% # lm(formula = ST ~ Ametaphor + Bmetaphor + ABmetaphor + In + For + 
% #     logFreqN1 + logFreqN2 + spellingRatio, data = jexClean)
% # 
% # Residuals:
% #     Min      1Q  Median      3Q     Max 
% # -3.3682 -0.8343  0.0646  0.9158  3.1477 
% # 
% # Coefficients:
% #               estimate std. Error t value pr(>|t|)    
% # ---
% # Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
% # 
% # Residual standard error: 1.184 on 1138 degrees of freedom
% # Multiple R-squared:  0.5796,	Adjusted R-squared:  0.5766 
% # F-statistic: 196.1 on 8 and 1138 DF,  p-value: < 2.2e-16

% # Resultat: Um einiges verbessert, der Hammer
\begin{table}[!htb]
  \centering
\begin{tabular}[h]{lrrrr}\lsptoprule
% &                      Coef&    S.E.&   t  &    pr($>|z|$)\\
&      {estimate}&    {std. error}&  {t}  &    {pr($>|z|$)}\\\midrule
(intercept)  &-0.81071  & 0.30576& -2.651& 0.00813\\
N1 metaphor &-0.73237  & 0.08952& -8.181&7.45e-16\\
N2 metaphor &-0.51709  & 0.08803& -5.874&5.59e-09\\
N1N2 metaphor&-1.97219  & 0.08550&-23.067& $<$ 2e-16\\
\textsc{in}        & 0.59291  & 0.12281&  4.828&1.57e-06\\
\textsc{for}       & 0.35582  & 0.08261&  4.307&1.80e-05\\
N1 frequency    & 0.32807  & 0.02318& 14.156& $<$ 2e-16\\
N2 frequency    & 0.14550  & 0.02730&  5.329&1.19e-07\\
spelling ratio&-0.11825  & 0.02321& -5.095&4.09e-07\\\tablevspace
\multicolumn{5}{l}{number of observations: 1147, d.f. 1138}\\\lspbottomrule
\end{tabular}
  \caption{Final model for compound literality using semantic and
    frequency-based predictors, with outliers removed across all
    subjects and items, adjusted R\textsuperscript{2} = 0.5766}
\label{bell-schaefer-2013-table-revisited-1}
\end{table}
As the adjusted R\textsuperscript{2} value of 0.577 % 0.5766
shows, the
resulting model has a much better fit to the data (cf. the adjusted
R\textsuperscript{2} value of the original model, 0.459). The
magnitude and direction of the predictors themselves do not change very
much. The predictors for the meaning shifts and the relations and N1
frequency become slightly more pronounced, with the effect of N2
frequency and spelling ratio is slightly reduced.
Note that both
models do not differ much with regard to overfitting. 
When validating the models using bootstrap sampling with replacement on 1000
bootstrap runs, using the validate function provided by
\citet{rms:2016}, all factors are retained and we get minimal adjustments of the unadjusted R$^2$
value by  0.0066 and  0.0068 respectively. That is, the models do not overfit.\is{r-packages!\texttt{rms}}
% \begin{center}
% \includegraphics[scale=.85,clip, trim= 0mm 0mm 0mm 0mm]{/home/martin/Dropbox/statistics/habil-stat/bell-schaefer-2013-revisited/diagnostics-model-1.png}
% \end{center}

\subsubsection{The other 3 models}
\label{sec:the-other-three}

Instead of going through the model criticism individually, I will here
just present the results of running similar outlier cleaning
algorithms on the corresponding data. 

Model 2 shares the dependent variable, building a model using the same predictors on the
reduced dataset considerably increases the fit, yielding an adjusted R$^2$ of 0.813. %  (the adjusted 0.739)
% R2 adj   0.813
Using the cleaned transparency judgments for N1 and N2 leaves 979 observations and again increases the fit considerably (adjusted R$^2$ of 0.840).

\enlargethispage{1\baselineskip}
For Model 3, the fit increases from an adjusted R$^2$ of 0.499 to
an adjusted R$^2$ of 0.608. Note that the small effect associated with spelling ratio
becomes less significant, and a model without it results in an R$^2$
of 0.607.
%  (although there is only a minute difference in the fit of the
% 2 models, this difference is marginally signiit is
% significant at the 0.09708 level).

For Model 4, the fit increases from an adjusted R$^2$ value of 0.498 to an adjusted R$^2$ of 
0.587. As with models 1 and 2, the predictors are retained and the
size and direction of the effects is similar.



\subsection{Linear mixed effects modeling}
\label{sec:bell-schaefer-lmer}
\is{linear mixed effects modeling|(}
Model 1 was based on 1,310 observations for 99 compound readings given by
40 different raters. That is, the transparency ratings include
multiple contributions by the same subjects as well as multiple
ratings for each compound reading. Therefore the individual data points are
not statistically independent of one another. In other words, the
simple least square regression models are actually not appropriate for
this kind of data. A statistically sound solution that allows one to
retain all the data even though statistical independence is not given
is the usage of mixed effects regression models. These models allow
the inclusion of effects associated with particular subjects and items
as random effects.
% In order to conform with
% the expectations of statistical testing, both of these aspects, that
% is, subjects, as well as items, should be treated as random variables.
% However, independence of
% observations is a core assumption of linear regressions \marginpar{(\textbf{SOURCE!})}.  
% Major violation of assumptions! \textbf{CHECK LITERATURE! READ BAAYEN SECTION ON MIXED EFFECTS MODELLING!}
Note that this is not just a step motivated by the requirements of
statistics. Quite on the contrary, idiosyncratic effects associated
with individual raters as well as individual items are to be
expected. 

The individual raters might use different strategies for their ratings
on the Likert scale, resulting e.g. in the usage of different ranges
of values from the scale, and in different usage of the steps given on
the scale. In addition, raters might react differently to the aspects
of the compounds encoded by the explanatory variables. Take, e.g., the
distributional variables frequency and spelling ratio. Here, raters
will react according to their individual experience with the
language, for spelling ratio in particular in accordance with their
exposure to written language. This individual experience will be the
same regardless of which item any given rater rates, but it might differ
considerably across the range of raters. 

The individual items contribute to the model via the selected
predictors, while all their other properties are left out of
consideration. However, these other properties, and there are many
more than just the linguistic characteristics discussed in Section
\ref{sec:linguistic-characeterization}, might 
affect transparency judgments. Consider for
example effects due to differences in age of acquisition, preference
for certain text types, or reference to either concrete or abstract
objects etc. Even embeddings in collocations spanning more than 2
words might play a role, take e.g. \emph{cloud nine}, which usually
occurs in the phrase \emph{on cloud nine}. Furthermore, these
properties might also lead to differentiated patterns of interaction
with the other predictors. Consider the predictor spelling ratio,
which we used as a stand in for lexicalization, and an item like
\emph{agony aunt}. Since \emph{agony} ends in a vowel and \emph{aunt}
starts with a vowel, or alternatively, because the letter sequence
$<$yau$>$ does not occur in the orthography of English, concatenation
of the 2 words is not expected, regardless of how lexicalized the
sequence is.

Note that the item and rater specific influences are of 2 different
types. On the one hand, the baseline transparency might vary. On the
other hand, the effect of the other predictors on transparency might
vary. To take the example of individual raters and their employment of
the Likert scale: Raters A and B might employ a different baseline
transparency in that rater A always uses `3' to indicate medium
transparency, but rater B always uses `2'. This kind of variance is
handled in a mixed effects model by adjusting the intercept for the
individual raters accordingly. The random effects can also capture a
difference in sensitivity to the effects of the predictors. Thus, let us say that
rater A and rater B both use `3' to indicate medium transparency, but
that they are influenced more or less strongly by N1 frequency: High
N1 frequency leads rater A to rate items with `5', but rater B only
rates them with `4'. Similarly, low N1 frequency leads rater A to rate
items with `1' but rater B with `2'. This variance is captured by
allowing the slopes for the various
predictors to vary with the individual subjects.
% To allow for this possibility, we included a by-item
% random intercept in our models; in other words, we allowed baseline
% transparency to vary according to the compound being rated. Similarly,
% individual annotators may tend to give higher or lower ratings
% overall, or may differ in their sensitivity to particular
% predictors. To accommodate these possibilities we
% included by-annotator random intercepts and .

Catering for all these possible influences on rating choice via random
effects ensures that the remaining effects in the model, the fixed
effects, are in fact due to the semantic and distributional predictors
and not to any other peculiarity of either specific items or specific annotators. 
% Because the transparency ratings include multiple contributions by
% each annotator, as well as multiple ratings on each compound type, the
% individual data points are not statistically independent of one
% another. 
% This is more then just a formal requirement;
%  it seems very plausible that single raters make use of
% the rating space offered by the Likert scales in different ways, and
% it seems likewise plausible that the compounds tested come with
% further properties that are not represented by the predictor variables
% but that might nevertheless influence rating choices.


There are different types of mixed models. In the following, I will
use linear mixed effects regression models including crossed
random effects for annotators and items (for an introduction to these types
of linear mixed effects models, see \citealt{Baayenetal:2008}). 
% This type of model allows us
% to treat effects due to specific items and specific annotators as
% random effects, thus ensuring that the remaining effects in the
% resulting models, the fixed effects, are truly due to the semantic and
% distributional predictors of interest and not due to any peculiarity
% of particular items or annotators 
% For example,
% there may be idiosyncratic reasons, unrelated to our predictors, why a
% particular compound is perceived as being more or less transparent
% than others. 



In building the mixed effects models, I started with the maximal model
for compound transparency
with all the explanatory variables used in coming to the original
Model 1. The maximal model is a model that includes random intercepts for items and for
subjects as well as possibly interacting random slopes for all
explanatory variables. This model fails to converge. Models without
interaction terms for the random slopes likewise fail to converge. In
a next step, I considered only random slopes for the distributional
predictors, that is, frequency N1, frequency N2, and spelling
ratio. Again, these models did not converge, and I ended up comparing
models with random slopes for both frequencies and with random slopes
for spelling ratio. Using ANOVAs for model comparison, I arrived at
a model with random intercepts for items and subjects and random
slopes for the influence of N2 frequency on subjects and items. This
random effect structure was then used for the other 3 models, too.

% \newpage
\enlargethispage{1\baselineskip}
Marginal and conditional R$^2$ values were calculated with the
\texttt{r.squaredGLMM()} function in the MuMIn package \citep{MuMIn}, an
implementation which is in turn based on \textsf{R} code from
\citet{NakagawaandSchielzeth:2013} and \citet{Johnson:2014}. For mixed
effects models, marginal R$^2$ values give the variance explained by the
fixed factors, and conditional R$^2$ values represent the variance
explained by the whole model, that is, by the random and fixed effects
taken together.\is{r-packages!\texttt{MuMIn}}
\is{linear mixed effects modeling|)}

% Given that the subset of the data used always had three ratings for a
% given compound from one subject, it seems reasonable to use a mixed
% model to account for subject dependent variation. Interestingly, the
% main coefficients stay the same if a random intercept for subjects is
% added. If a random intercept for wordSenseID is added, the effect of
% FOR is not significant anymore.

% In other news: I do not know how to compare the lmer models to the
% other models: MUST START WITH THAT PREDICT STUFF!

\subsubsection{Compound transparency with mixed effects models}
\label{sec:bs2013_mixed-effects}

% lmerTest

Just as in \citet{BellandSchaefer:2013}, I will first consider a model
without the N1 and N2 ratings as predictors, and then look at a model
that includes these as predictors. The final model for semantic
transparency excluding constituent transparency as predictors is shown in
 \tabref{tab:mixed-1} and graphically represented in \figref{fig:bellschaefer2013_model_1-mixed-effects}.

The top section of \tabref{tab:mixed-1} shows the random effects:
the model includes random intercepts for items, as well as random
intercepts for raters. In addition, for both items and raters it
includes random slopes for the effects of N2 frequency. The bottom section of \tabref{tab:mixed-1} shows the fixed effects.
 
% \centering
% summary(jena1.max.NoInteraction.noSem.noSpelling.noFreq1.noBe.noFor.noSpelling.noIn.lmer)
% Linear mixed model fit by REML t-tests use Satterthwaite approximations to
%   degrees of freedom [lmerMod]
% Formula: ST ~ Ametaphor + Bmetaphor + ABmetaphor + logFreqN1 + logFreqN2 +  
%     (1 + logFreqN2 | workerID) + (1 + logFreqN2 | wordSenseID)
%    Data: j

% REML criterion at convergence: 3742.7

% Scaled residuals: 
%     Min      1Q  Median      3Q     Max 
% -3.9778 -0.6173  0.0455  0.5633  3.7784 

% random effects:
%  Groups      Name        Variance std.Dev. Corr 
%  wordSenseID (intercept) 7.291617 2.70030       
%              logFreqN2   0.044884 0.21186  -0.97
%  workerID    (intercept) 1.681205 1.29661       
%              logFreqN2   0.009137 0.09559  -1.00
%  Residual                0.790487 0.88909       
% Number of obs: 1310, groups:  wordSenseID, 99; workerID, 40

% fixed effects:
%               estimate std. Error       df t value pr(>|t|)    
% (intercept)   -0.34407    0.98678 70.00000  -0.349 0.728375    
% AmetaphorYes  -1.00774    0.22692 71.08000  -4.441 3.22e-05 ***
% BmetaphorYes  -0.54721    0.24503 88.30000  -2.233 0.028060 *  
% ABmetaphorYes -2.14365    0.21611 74.21000  -9.919 3.11e-15 ***
% logFreqN1      0.23668    0.06189 73.20000   3.824 0.000274 ***
% logFreqN2      0.23596    0.09170 47.82000   2.573 0.013231 *  
% ---
% Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

% Correlation of fixed Effects:
%             (Intr) AmtphY BmtphY ABmtpY lgFrN1
% AmetaphorYs -0.115                            
% BmetaphorYs -0.285  0.072                     
% ABmetaphrYs -0.235  0.195  0.085              
% logFreqN1   -0.411  0.216  0.117  0.227       
% logFreqN2   -0.816 -0.083  0.186  0.038 -0.168
% > 

% r.squaredGLMM(jena1.max.NoInteraction.noSem.noSpelling.noFreq1.noBe.noFor.noSpelling.noIn.lmer)
%      R2m       R2c 
% 0.4600827 0.7835695
% \begin{table}[!htb]
% \small
% \hspace*{-1.2cm}\begin{tabular}{lllll}\lsptoprule
% \multicolumn{4}{l}{\textbf{random effects:}}\\
%  \textbf{Groups}     &\textbf{Name}       &\textbf{Variance}&\textbf{std.Dev.} \\%&Corr\\ 
%  wordSenseID&(intercept)&7.291617&2.70030  \\%&     \\
%             &logFreqN2  &0.044884&0.21186  \\%&-0.97\\
%  workerID   &(intercept)&1.681205&1.29661  \\%&\\     
%             &logFreqN2  &0.009137&0.09559  \\%&-1.00\\
%  Residual   &           &0.790487&0.88909       \\
% \multicolumn{4}{l}{Number of obs: 1310, groups:  wordSenseID, 99; workerID, 40}
  
% \end{tabular}
% \vspace*{1ex}

% \hspace*{-8cm}\begin{tabular}{lllllll}
% \multicolumn{7}{l}{\textbf{fixed effects:}}\\
% % &&&&&\\
%               &estimate& std. Error   &    df& t value &pr($>|t|$)\\    
% (intercept)  &-0.34407 &  0.98678 &70.00000 &-0.349&0.728375\\    
% N1 metaphor &-1.00774 &  0.22692 &71.08000 &-4.441&3.22e-05\\
% N2 metaphor &-0.54721 &  0.24503 &88.30000 &-2.233&0.028060\\
% N1N2 metaphorYes&-2.14365 &  0.21611 &74.21000 &-9.919&3.11e-15\\
% logFreqN1    & 0.23668 &  0.06189 &73.20000 & 3.824&0.000274\\
% logFreqN2    & 0.23596 &  0.09170 &47.82000 & 2.573&0.013231\\
% \lspbottomrule
% \end{tabular}
%   \caption{Final mixed effects model for compound transparency,
%     marginal R$^2$= 0.46, conditional R$^2$= 0.78}
%   \label{tab:mixed-1}
% \end{table}

\begin{table}[!htb]
\small
% \hspace*{-1.2cm}
\begin{tabularx}{.95\textwidth}{llrrrrr}\lsptoprule
\multicolumn{7}{l}{\textbf{random effects:}}\\
 {groups}     &{name}       &{variance}&{std. dev.} &&\\\midrule %[.2ex]\cline{1-4}%&Corr\\ 
 wordSenseID&(intercept)&7.291617&2.70030&&  \\%&     \\
            &logFreqN2  &0.044884&0.21186&&  \\%&-0.97\\
 workerID   &(intercept)&1.681205&1.29661&&  \\%&\\     
            &logFreqN2  &0.009137&0.09559&&  \\%&-1.00\\
 Residual   &           &0.790487&0.88909 &&      \\\tablevspace
\multicolumn{7}{l}{number of obs: 1310, groups:  wordSenseID, 99; workerID, 40}\\[1ex]
\multicolumn{7}{l}{\textbf{fixed effects:}}\\
% &&&&&\\
              &{estimate}& {std. error}   &    {df}& {t value} &{pr($>|t|$)}\\\midrule    
(intercept)  &-0.34407 &  0.98678 &70.00000 &-0.349&0.728375\\    
N1 metaphor &-1.00774 &  0.22692 &71.08000 &-4.441&3.22e-05\\
N2 metaphor &-0.54721 &  0.24503 &88.30000 &-2.233&0.028060\\
N1N2 metaphorYes&-2.14365 &  0.21611 &74.21000 &-9.919&3.11e-15\\
N1 frequency    & 0.23668 &  0.06189 &73.20000 & 3.824&0.000274\\
N2 frequency    & 0.23596 &  0.09170 &47.82000 & 2.573&0.013231\\
\lspbottomrule
\end{tabularx}
  \caption{Final mixed effects model for compound transparency,
    marginal R$^2$= 0.46, conditional R$^2$= 0.78}
  \label{tab:mixed-1}
\end{table}

\begin{figure}[!htb]
  \centering
% \includegraphics[scale=.5,trim=0 0 0 0, clip]{/home/martin/Dropbox/statistics/habil-stat/bell-schaefer-2013-revisited/bell-schaefer-2013_partialEffects_model1_mixed.png}
% \includegraphics[scale=.4,trim=0 0 0 0, clip]{/home/martin/Dropbox/statistics/habil-stat/bell-schaefer-2013-revisited/bell-schaefer-2013_partialEffects_model1_mixed.pdf}
\includegraphics[scale=.4,trim=0 0 0 15mm, clip]{./figures/bell-schaefer-2013_partialEffects_model1_mixed.pdf}
  
  \caption{Partial effects in the final mixed effects model for
    compound transparency using distributional and semantic predictors.}
\label{fig:bellschaefer2013_model_1-mixed-effects}
\end{figure}

Although the proportion of variance explained by the explanatory
variables in this model is equal to the proportion of variance
explained by Model 1 in \citet{BellandSchaefer:2013} (adjusted R$^2$
for Model 1 and marginal R$^2$ for this model are both 0.46),
this variance is accounted for in this model by just 5 explanatory variables. Note also that the
conditional R$^2$ value (the R$^2$ value showing the total variation
accounted for by the model) is  0.78, far higher than the adjusted R$^2$ value
for the model using the cleaned data (R$^2$ 0.58). The crucial difference
between this and the original model are the missing
predictors. Whereas in the original model and in the
model run on the cleaned data the predictors \textsc{in} and \textsc{for} positively
correlated with transparency, none of
the variables encoding semantic relations survives in the mixed effect
model. Spelling ratio also does not make a significant
contribution. The explanatory
variables that stay in the final model, however, come with
coefficients that are, generally speaking, similar to the coefficients in the original model. Thus, all meaning shifts are
associated with less semantic transparency, with the largest effect
again coming from whole compound meaning shifts. The magnitude of the
effect is slightly higher in this model than in Model 1. Similarly,
the effect associated with N1 metaphor is more pronounced in this
model than in Model 1. Just as in the previous model, the constituent frequencies are
associated with more transparency, that is, the more frequent either
constituent, the more transparent the compound. Differing from model
1, the magnitudes of the effects are the same for both N1 and N2 frequency.

The random effects in the model are illustrated in \figref{fig:bellschaefer2013_model_1-mixed-effects_random-effects-by-rater} and \figref{fig:bellschaefer2013_model_1-mixed-effects_random-effects-by-item}.
% INCLUDE FIGURES! 
\begin{figure}[!htb]
  \centering
% \includegraphics[scale=.5,trim=0 0 0 0, clip]{/home/martin/Dropbox/statistics/habil-stat/bell-schaefer-2013-revisited/bellschaefer2013model1mixed_random-intercept_by-rater.pdf}
 % \includegraphics[scale=.7,trim=0 0 0 0, clip]{/home/martin/Dropbox/statistics/habil-stat/bell-schaefer-2013-revisited/bellschaefer2013model1mixed_random-intercept-and-slopes_by-rater.pdf}
\includegraphics[scale=.7,trim=0 0 0 15mm, clip]{./figures/bellschaefer2013model1mixed_random-intercept-and-slopes_by-rater.pdf}
  \caption{By-rater random intercepts and by-rater random slopes for the effect of N2 frequency in the final mixed effects model for compound transparency excluding constituent ratings.}
\label{fig:bellschaefer2013_model_1-mixed-effects_random-effects-by-rater}
\end{figure}

\figref{fig:bellschaefer2013_model_1-mixed-effects_random-effects-by-rater}
shows the random effects associated with the different raters. In the
left hand plot, the dots represent the adjustment of the intercept
for each of the 40 raters. Dots to the right of the vertical line at 0
indicate a positive adjustment, that is, the rater exhibits a
tendency to give higher ratings. Dots to the left of the vertical line
at 0 indicate a tendency towards lower transparency ratings. The horizontal lines show the 95\%
confidence intervals for these intercept adjustments. While for 28
raters 0 is included in this interval, 12 show a clear tendency
towards either higher or lower ratings. The individual adjustments
range from -3.6 to 3.6 and show considerable variation. 
The right hand plot shows the adjustments of the slope of the
N2 frequency predictor for the individual raters, which range from
-0.27 to 0.27. Again, for 12 out of the 40 raters the adjustments
show clear positive or negative tendencies, while 28 include 0 in
their confidence intervals. 



\begin{figure}[!htb]
  \centering
%  \includegraphics[scale=.7,trim=0 0 0 0, clip]{/home/martin/Dropbox/statistics/habil-stat/bell-schaefer-2013-revisited/bellschaefer2013model1mixed_random-intercept-and-slopes_by-item.pdf}
  \includegraphics[scale=.7,trim=0 0 0 15mm, clip]{./figures/bellschaefer2013model1mixed_random-intercept-and-slopes_by-item.pdf}
  \caption{By-item random intercepts and by-rater random slopes for the effect of N2 frequency in the final mixed effects model for compound transparency excluding constituent ratings.}
\label{fig:bellschaefer2013_model_1-mixed-effects_random-effects-by-item}
\end{figure}

\pagebreak[4]
\figref{fig:bellschaefer2013_model_1-mixed-effects_random-effects-by-item}
shows the random effects associated with the different items. As in
\figref{fig:bellschaefer2013_model_1-mixed-effects_random-effects-by-rater},
the left hand plot represents the adjustment of the intercepts, while
the right hand plot shows the adjustments of the slope associated with
the predictor N2 frequency. For the intercepts, 16 of the 99 items
lead to a clear preference for lower or higher ratings, while 83
include 0 in their confidence intervals. The adjustments themselves
range from -10.5 to 7.0, the variance is very high.  For the slopes, 8
items show a clear preference, and adjustments range from -0.55 to
0.81. For both the adjustments of the intercepts as well as the
adjustments of the slopes, the random effects associated with the
items are far more pronounced than those associated with the
individual raters.

Including constituent transparency as predictors leads to the final
model in \tabref{tab:mixed-2}, graphically represented in
\figref{fig:bellschaefer2013_model_2-mixed-effects}.
% model2.bs.2013.mixedEffects4.noFreq2.simplerandom.lmer <- lmer (ST ~ Ametaphor  + Bmetaphor  + ABmetaphor  + logFreqN1 + STN1 + STN2 + (1 |workerID) + (1|wordSenseID), data=j)
% summary(model2.bs.2013.mixedEffects4.noFreq2.simplerandom.lmer)
% # Linear mixed model fit by REML t-tests use Satterthwaite approximations to
% #   degrees of freedom [lmerMod]
% # Formula: ST ~ Ametaphor + Bmetaphor + ABmetaphor + logFreqN1 + STN1 +  
% #     STN2 + (1 | workerID) + (1 | wordSenseID)
% #    Data: j
% # 
% # REML criterion at convergence: 3378.2
% # 
% # Scaled residuals: 
% #     Min      1Q  Median      3Q     Max 
% # -5.1417 -0.5639  0.0587  0.5761  3.8972 
% # 
% # random effects:
% #  Groups      Name        Variance std.Dev.
% #  wordSenseID (intercept) 0.16305  0.4038  
% #  workerID    (intercept) 0.09023  0.3004  
% #  Residual                0.65733  0.8108  
% # Number of obs: 1310, groups:  wordSenseID, 99; workerID, 40
% # 
% # fixed effects:
% #                estimate std. Error        df t value pr(>|t|)    
% # (intercept)    -0.02528    0.29028  79.50000  -0.087 0.930812    
% # AmetaphorYes   -0.31868    0.12246  83.20000  -2.602 0.010963 *  
% # BmetaphorYes   -0.28440    0.12231  84.00000  -2.325 0.022476 *  
% # ABmetaphorYes  -0.51419    0.12331  97.70000  -4.170  6.6e-05 ***
% # logFreqN1       0.11151    0.03114  75.90000   3.581 0.000602 ***
% # STN1            0.37030    0.02169 735.20000  17.069  < 2e-16 ***
% # STN2            0.35393    0.02224 629.50000  15.916  < 2e-16 ***
% # ---
% # Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
% # 
% # Correlation of fixed Effects:
% #             (Intr) AmtphY BmtphY ABmtpY lgFrN1 STN1  
% # AmetaphorYs -0.256                                   
% # BmetaphorYs -0.264 -0.048                            
% # ABmetaphrYs -0.421  0.218  0.197                     
% # logFreqN1   -0.867  0.116  0.108  0.120              
% # STN1        -0.007  0.329 -0.195  0.263 -0.236       
% # STN2        -0.230 -0.178  0.366  0.356 -0.044 -0.160
% r.squaredGLMM(model2.bs.2013.mixedEffects4.noFreq2.simplerandom.lmer)
% #      R2m       R2c 
% # 0.6967715 0.7811126 
\begin{table}[!htb]
\small
% \hspace*{-1.2cm}
\begin{tabularx}{.95\textwidth}{llrrrrr}\lsptoprule
\multicolumn{7}{l}{\textbf{random effects:}}\\
 {groups}     &{name}       &{variance}&{std. dev.}&&&\\\midrule %Corr 
wordSenseID&(intercept)&0.16305  &0.4038&&&\\       
workerID   &(intercept)&0.09023 & 0.3004&&& \\      
residual   &           &0.65733 & 0.8108&&&  \\\tablevspace     
% #  Groups      Name        Variance std.Dev.
% #  wordSenseID (intercept)   
% #  workerID    (intercept)   
% #  Residual                  
% # Number of obs: 1310, groups:  wordSenseID, 99; workerID, 40
\multicolumn{7}{l}{number of obs: 1310, groups:  wordSenseID, 99; workerID, 40}\\[1ex]
% \end{tabular}
% \vspace*{1ex}
% \hspace*{-8cm}\begin{tabular}[h]{lllllll}
\multicolumn{7}{l}{\textbf{fixed effects:}}\\
              &{estimate}& {std. error}   &    {df}& {t value} &{pr($>|t|$)}\\\midrule    
(intercept)    &0.02528    &.29028  &9.50000  &.087&0.930812\\   
N1 metaphor   &-0.31868    &.12246  &3.20000  &.602&0.010963\\
N2 metaphor   &-0.28440    &.12231  &4.00000  &.325&0.022476\\
N1N2 metaphor  &-0.51419    &.12331  &7.70000  &.170& 6.6e-05\\
N1 frequency      &0.11151    &.03114  &5.90000  &.581&0.000602\\
N1 transparency           &0.37030 &   0.02169& 735.20000&  17.069& $<$ 2e-16\\%***
N2 transparency           &0.35393   & 0.02224& 629.50000 & 15.916& $<$ 2e-16\\%***
\lspbottomrule
% # STN1              < 2e-16 ***
% # STN2              < 2e-16 ***
\end{tabularx}
  \caption{Final mixed effects model for compound transparency,
    including N1 and N2 constituent transparency as predictors, marginal R$^2$=0.70, conditional R$^2$= 0.78}
  \label{tab:mixed-2}
\end{table}

\begin{figure}[!htb]
  \centering
% \includegraphics[scale=.5,trim=0 30 0 0, clip]{/home/martin/Dropbox/statistics/habil-stat/bell-schaefer-2013-revisited/bell-schaefer-2013_partialEffects_model2_mixed.png}
% \includegraphics[scale=.4,trim=0 30 0 0, clip]{/home/martin/Dropbox/statistics/habil-stat/bell-schaefer-2013-revisited/bell-schaefer-2013_partialEffects_model2_mixed.pdf}
\includegraphics[scale=.4,trim=0 30 5mm 0, clip]{./figures/bell-schaefer-2013_partialEffects_model2_mixed.pdf}
  
  \caption{Partial effects in the final model for compound
    transparency, including N1 and N2 constituent transparency as predictors}
\label{fig:bellschaefer2013_model_2-mixed-effects}
\end{figure}
This time, all but one of the fixed effects in the original model
also occur in the mixed effects model. The predictor variable
N2 frequency does not play a significant role in this model. Since N2
frequency is no longer a fixed effect, it is not featured in the
random part of the model. For the remaining predictors, the direction of the influence is always the
same as in the original models. However, the strengths of the effects of the individual predictors
differ slightly. The negative effects of the shifts are stronger, only slightly so in
the case of the constituent shifts, but considerably stronger in the case of a
metaphoric shift of the whole compound, where the negative coefficient increases
from -0.18 to -0.52. The positive effect associated with N1
frequency is smaller. The effect of
constituent transparency becomes slightly smaller. This can be
explained by assuming that some of the variance originally accounted for by constituent
ratings is now accounted for by the random effects. This explains also
why the marginal R$^2$ value of the mixed effects model is lower than
the R$^2$ value of the original model (0.70 vs. 0.74). The variance in
the random effects for the items is much lower than in the previous model. This is a
side effect of the rater and item specific constituent ratings. That
is, as explained in Section \ref{sec:bell-and-schaefer-2013_subset},
we only included data where we had ratings on both constituents and
the whole compound by the same rater, using a within subject
design. Plausibly, much of the influence of the individual items not encoded
in the predictor variables had a similar influence on the subject
regardless which transparency rating (N1, N2, or the whole compound)
they were making.

\subsubsection{Constituent transparency with mixed effects models}
\label{sec:bs2013_mixed-effects-for-constituents}

The final mixed effects model for the transparency of the first constituent is given in
 \tabref{tab:mixed-model3-bellschaefer2013}, and graphically
represented in
\figref{fig:bellschaefer2013_model_3-mixed-effects}. Again, I started by
using the same
random effect structure as for the first model. However, since N2
frequency was not significant, the corresponding random
slopes were also taken out of the model. The variance coming with
the random intercept by item is higher than the variance in the
second model, but still lower than the variance in the first model.

\begin{table}[!htb]
% # Linear mixed model fit by REML t-tests use Satterthwaite approximations to
% #   degrees of freedom [lmerMod]
% # Formula: STN1 ~ Ametaphor + Bmetaphor + ABmetaphor + In + logFreqN1 +  
% #     (1 | workerID) + (1 | wordSenseID)
% #    Data: j
% # 
% # REML criterion at convergence: 3865.9
% # 
% # Scaled residuals: 
% #     Min      1Q  Median      3Q     Max 
% # -4.6102 -0.5317  0.0542  0.5033  3.4108 
% # 
% # random effects:
% #  Groups      Name        Variance std.Dev.
% #  wordSenseID (intercept) 1.27456  1.1290  
% #  workerID    (intercept) 0.09922  0.3150  
% #  Residual                0.86663  0.9309  
% # Number of obs: 1310, groups:  wordSenseID, 99; workerID, 40
% # 
% # fixed effects:
% #               estimate std. Error      df t value pr(>|t|)    
% # (intercept)     0.8507     0.6902 93.4900   1.233  0.22084    
% # AmetaphorYes   -1.8480     0.2856 91.9600  -6.470 4.68e-09 ***
% # BmetaphorYes    0.7838     0.2818 90.5700   2.781  0.00659 ** 
% # ABmetaphorYes  -1.9549     0.2703 91.7400  -7.231 1.40e-10 ***
% # InYes           0.8567     0.4104 88.5700   2.087  0.03972 *  
% # logFreqN1       0.3281     0.0754 91.9000   4.352 3.50e-05 ***
% # ---
% # Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
% # 
% # Correlation of fixed Effects:
% #             (Intr) AmtphY BmtphY ABmtpY InYes 
% # AmetaphorYs -0.310                            
% # BmetaphorYs -0.226  0.073                     
% # ABmetaphrYs -0.395  0.232  0.146              
% # InYes        0.088 -0.107 -0.019 -0.132       
% # logFreqN1   -0.960  0.198  0.118  0.267 -0.127
% r.squaredGLMM(jena3.noFor.noBe.noSpelling.nologFreqN2.randomSimple.lmer)
% #       R2m       R2c 
% # 0.4797291 0.7987492 
\small
% \hspace*{-1.2cm}
\begin{tabularx}{.95\textwidth}{llrrrrr}\lsptoprule
\multicolumn{7}{l}{\textbf{random effects:}}\\
% \small
% \hspace*{-1.2cm}\begin{tabular}[h]{lllll}
% \multicolumn{4}{l}{\textbf{random effects:}}\\
 {groups}     &{name}       &{variance}&{std. dev.}&&&\\\midrule %Corr 
wordSenseID&(intercept)&1.27456& 1.1290&&&\\ 
workerID   &(intercept)&0.09922& 0.3150&&&\\ 
residual   &           &0.86663& 0.9309&&&\\ \tablevspace
\multicolumn{7}{l}{number of obs: 1310, groups:  wordSenseID, 99; workerID, 40}\\[1ex]
% \end{tabular}
% 
% \vspace*{1ex}
% 
% \hspace*{-8cm}\begin{tabular}[h]{lllllll}
\multicolumn{7}{l}{\textbf{fixed effects:}}\\
             &{estimate}&{std. error}&      {df}&{t value}&{pr($>|t|$)}\\\midrule   
(intercept)   & 0.8507   &0.6902&93.4900& 1.233& 0.22084\\   
N1 metaphor  &-1.8480   &0.2856&91.9600&-6.470&4.68e-09\\
N2 metaphor  & 0.7838   &0.2818&90.5700& 2.781& 0.00659\\
N1N2 metaphor &-1.9549   &0.2703&91.7400&-7.231&1.40e-10\\
\textsc{in}         & 0.8567   &0.4104&88.5700& 2.087& 0.03972\\
N1 frequency     & 0.3281   &0.0754&91.9000& 4.352&3.50e-05\\\lspbottomrule
\end{tabularx}
  \caption{Final mixed effects model for the semantic transparency of
    first constituent (N1) transparency, marginal R$^2$= 0.48, conditional R$^2$= 0.80
}
  \label{tab:mixed-model3-bellschaefer2013}
\end{table}

Comparing this model to the original Model 3, we see that the
variation explained by the fixed effects corresponds closely to the
variation explained by the original model (cf. the marginal R$^2$ of
0.48 to the adjusted R$^2$ of 0.50 of Model 3). However, spelling
ratio and N2 frequency are not significant in the mixed
effects model, which therefore needs 2 predictors less to explain
almost the
same variation. Looking at the predictors that are shared by both
models, we see that the 2 negative predictors, N1 metaphor and N1N2
metaphor become more pronounced, while the predictor N2 metaphor
becomes slightly smaller (but remains positive). Likewise, the
predictor \textsc{in} becomes slightly less pronounced, as does the  
remaining frequency-based predictor, frequency N1.

\begin{figure}[!htb]
  \centering
% \includegraphics[scale=.53,trim=0 50 0 40, clip]{/home/martin/Dropbox/statistics/habil-stat/bell-schaefer-2013-revisited/bell-schaefer-2013_partialEffects_model3_mixed.png}
% \includegraphics[scale=.43,trim=0 50 0 40, clip]{/home/martin/Dropbox/statistics/habil-stat/bell-schaefer-2013-revisited/bell-schaefer-2013_partialEffects_model3_mixed.pdf}
\includegraphics[scale=.42,trim=0 40 25 40, clip]{./figures/bell-schaefer-2013_partialEffects_model3_mixed.pdf}
  
  \caption{Partial effects in the final model for N1 transparency}
\label{fig:bellschaefer2013_model_3-mixed-effects}
\end{figure}

% Note: one of the models on the way to the final model did not converge!

The mixed effects model for N2 transparency is shown in \tabref{tab:mixed-model4-bellschaefer2013}
and graphically represented in
\figref{fig:bellschaefer2013_model_4-mixed-effects}. What we see here is
first of all a massive increase of variance in the adjustment to the
intercept by item. Why is that? If we look at the 4 items with the
highest adjustments in the positive and negative direction, we can
throw some light on the issue.
The 2 items with the highest negative adjustments are one word sense
of \emph{gold
  mine}, with a mean N2 rating of 0.54, and \emph{gravy train}, with a
mean N2 rating of 0.08 respectively. Although \emph{gold
  mine} came with 2 senses to choose from, it was
only rated with the word sense \emph{a good source of something that
  is desired}. In the semantic annotation, it is marked as
not shifted. 
\emph{Gravy train} only has one possible word sense, \emph{income
  obtained with a minimum of effort}.
As far as the shifts are concerned, it is annotated as containing
metaphorically shifted first and second constituents, N1 and N2, whereas
the whole compound, N1N2, is annotated as unshifted. So here,
both items are given extremely low transparency values, but neither of
them falls under the strong negative predictor N1N2 metaphor
(though \emph{gravy train} falls under the less strongly negative
predictor N2 metaphor). For the positive predictors, the
logarithmized N1 frequency
of \emph{gold} and \emph{gravy} are 8.92 and 5.59 respectively,
placing them in middle and low regions of the frequency spectrum
exhibited by the N1 constituents. In contrast, both logarithmized N2
frequencies, 8.99 for \emph{mine} and 9.54 for \emph{train}, place
them in the highest region of the frequency spectrum
exhibited by the N2 constituents.

The 2 items with the highest positive adjustments are one word sense
of \emph{face
  value}, with a mean N2 rating of 4.78, and one word sense of
\emph{acid test}, with a mean N2 rating of 3.92.  For \emph{face
  value}, raters chose actually both of the available senses, the
one in question here is \emph{the apparent worth as opposed to the
  real worth}. It is coded as N1 metaphor and N1N2 metaphor. For \emph{acid test}, the only
definition chosen by raters was \emph{a rigorous or crucial
  appraisal}. It is coded as N1N2 metaphor. So in both cases, there are
 very high respectively high transparency ratings, but items
falling under the strongest negative predictor for N2 transparency,
N1N2 metaphor. Of the logarithmized constituent frequencies, the
values for both \emph{face} and \emph{value} correspond to the top
spectrum, with 10.71 for N1 and 10.18 for N2, while for \emph{acid
  test} the values are slightly lower, with  8.69 for N1 and 10.02 for
N2, placing \emph{acid} in the middle of the spectrum, and \emph{test}
again in the top region.

% face_value1         -0.5203463  0.044755488
% the value of a security that is set by the company issuing it; unrelated to market value

% Model4/Transparency of N2
\begin{table}[!htb]
% summary(jena4.noBe.noFor.noIn.noSpelling.noAmetaphor.lmer)
% Linear mixed model fit by REML t-tests use Satterthwaite approximations to
%   degrees of freedom [lmerMod]
% Formula: STN2 ~ Bmetaphor + ABmetaphor + logFreqN1 + logFreqN2 + (1 +  
%     logFreqN2 | workerID) + (1 + logFreqN2 | wordSenseID)
%    Data: j

% REML criterion at convergence: 3734.7

% Scaled residuals: 
%     Min      1Q  Median      3Q     Max 
% -4.7327 -0.4918  0.0315  0.4836  4.7802 

% random effects:
%  Groups      Name        Variance  std.Dev. Corr 
%  wordSenseID (intercept) 27.222122 5.21748       
%              logFreqN2    0.201389 0.44876  -1.00
%  workerID    (intercept)  0.166860 0.40848       
%              logFreqN2    0.003522 0.05935  -0.86
%  Residual                 0.783607 0.88522       
% Number of obs: 1310, groups:  wordSenseID, 99; workerID, 40

% fixed effects:
%               estimate std. Error       df t value pr(>|t|)    
% (intercept)   -0.03739    1.05793 94.86000  -0.035 0.971879    
% BmetaphorYes  -1.28548    0.24290 46.93000  -5.292 3.12e-06 ***
% ABmetaphorYes -2.10421    0.19513 34.36000 -10.784 1.43e-12 ***
% logFreqN1      0.08553    0.05341 26.29000   1.601 0.121223    
% logFreqN2      0.37295    0.09838 91.97000   3.791 0.000268 ***
% ---
% Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

% Correlation of fixed Effects:
%             (Intr) BmtphY ABmtpY lgFrN1
% BmetaphorYs -0.213                     
% ABmetaphrYs -0.138 -0.152              
% logFreqN1   -0.337  0.114  0.159       
% logFreqN2   -0.890  0.145  0.024 -0.113

% r.squaredGLMM(jena4.noBe.noFor.noIn.noSpelling.noAmetaphor.lmer)
%       R2m       R2c 
% 0.4043971 0.8225629 
\small
\begin{tabularx}{.95\textwidth}{llrrrrr}\lsptoprule
\multicolumn{7}{l}{\textbf{random effects:}}\\
% \hspace*{-1.2cm}\begin{tabular}[h]{lllll}
% \multicolumn{4}{l}{\textbf{random effects:}}\\
 \textbf{groups}     &\textbf{name}       &\textbf{variance}&\textbf{std. dev.}&&&\\\midrule %Corr 
 wordSenseID&(intercept)&27.222122&5.21748&&&\\      
            &logFreqN2  & 0.201389&0.44876&&&\\ %-1.00
 workerID   &(intercept)& 0.166860&0.40848&&&\\      
            &logFreqN2  & 0.003522&0.05935&&&\\ %-0.86
 Residual   &           & 0.783607&0.88522&&&\\      
\multicolumn{7}{l}{number of obs: 1310, groups:  wordSenseID, 99; workerID, 40}\\[1ex]
% \end{tabular}
% \vspace*{1ex}
% 
% \hspace*{-8cm}\begin{tabular}[h]{lllllll}
\multicolumn{7}{l}{\textbf{fixed effects:}}\\
             &{estimate}&{std. error}&      {df}&{t value}&{pr($>|t|$)}\\\midrule   
(intercept)  &-0.03739&   1.05793&94.86000& -0.035&0.971879\\   
N2 metaphor &-1.28548&   0.24290&46.93000& -5.292&3.12e-06\\
N1N2 metaphor&-2.10421&   0.19513&34.36000&-10.784&1.43e-12\\
N1 frequency    & 0.08553&   0.05341&26.29000&  1.601&0.121223\\   
N2 frequency    & 0.37295&   0.09838&91.97000&  3.791&0.000268\\\lspbottomrule
\end{tabularx}
  \caption{Final mixed effects model for the semantic transparency of N2,
    the second constituent, marginal R$^2$= 0.404, conditional
    R$^2$=  0.823}
% marginal R$^2$= 0.4043971, conditional R$^2$=  0.8225629 }
  \label{tab:mixed-model4-bellschaefer2013}
\end{table}


\begin{figure}[!htb]
  \centering
% \includegraphics[scale=.5,trim=0 30 0 50, clip]{/home/martin/Dropbox/statistics/habil-stat/bell-schaefer-2013-revisited/bell-schaefer-2013_partialEffects_model4_mixed.png}
% \includegraphics[scale=.5,trim=0 30 0 50, clip]{/home/martin/Dropbox/statistics/habil-stat/bell-schaefer-2013-revisited/bell-schaefer-2013_partialEffects_model4_mixed.pdf}
\includegraphics[scale=.5,trim=0 30 0 50, clip]{./figures/bell-schaefer-2013_partialEffects_model4_mixed.pdf}
  
  \caption{Partial effects in the final model for N2 transparency}
\label{fig:bellschaefer2013_model_4-mixed-effects}
\end{figure}

% \pagebreak[4]
As for the fixed effects, one can again observe that the
variation explained by them is lower than the variation
explained by the original Model 4, with a marginal R$^2$ of 0.40 against
an adjusted R$^2$ value of 0.50. In contrast to the original model,
the relational predictor \textsc{for} does not become significant. Likewise,
and just as in the 3 previous mixed effects models, the predictor
spelling ratio does not become significant. Of the meaning shifts,
only the 2 predictors that were negatively correlated with N1
transparency, N1N2 metaphor and N2 metaphor, survive. Comparing the predictors
occurring in both models, the effect associated with N2 metaphor is
less pronounced in the new model, while the effect associated with
N1N2 metaphor is slightly more pronounced in the new model. As far as
the frequency-based predictors are concerned, we see a massive
increase of the role of N2 frequency while the role of N1 frequency
decreases. As the p-values show, the effect associated with N1
frequency is also not significant. However, models without this
predictor did not converge.

The high variance in the random effects led me to reconsider the random effects structure for this model.
% It appears, thus, that there might be something strange going on with this model. 
Recall that the reason for using the random effect structure
was based on the testing done for the first model, and following the
general logic that since the sources for the random effects remain the
same across all 4 models, so should the random effect
structure. Given the high variance in the random effects and
the failure to converge when trying to build a model without N1
frequency as a predictor, it seems amply justified to test whether or
not a simpler random effect structure would perhaps lead to better
results. However, comparing the models in question via ANOVA shows
that the random effect structure including the random slopes yields
models with significantly lower AICs and BICs than those models
without the random slopes.

\subsubsection{Conclusion: the results of the mixed effects modeling}
\label{sec:results-of-mixed-effect-models}

At the beginning of this section, I argued that the nature of the data
that was used in \citet{BellandSchaefer:2013} required mixed effect
modeling. Thus, the models discussed in this section are preferable over the models discussed in Section \ref{sec:bell-and-schaefer-models} which only used ordinary least square regressions.
Any predictors occurring in the models reported in
\citet{BellandSchaefer:2013} but not in the mixed effects models are
best seen as artefacts of idiosyncrasies of either
the individual raters or the individual items. The most important
result from the mixed effects models is that the semantic relations
almost completely disappear from the models. Only \textsc{in} survives in the
model for N1 transparency. In contrast, except for the absence of an
effect of N1 metaphor on N2 transparency, the 3 semantic shifts
remained as significant predictors in all models. These results are
very intriguing; as far as the relations are concerned, the fact that
the relations as such are not associated with more or less perceived
transparency is expected from the point of view of the conceptual
combination models by Gagné and collaborators (cf. the discussion of
the CARIN and RICE models in Chapter
\ref{cha:semTranPsycho}, Section \ref{sec:conceptual_combination}):
the relations only play a role relative to the constituents involved,
that is, a given relation might be associated with increased
transparency for some constituent while at the same time being
associated with decreased transparency for some other constituent. 

As far as the distributional predictors are concerned, it is
interesting that both constituent frequencies together only become
significant predictors in the model for whole compound transparency
excluding constituent transparency judgments. Another interesting
finding is the failure of spelling ratio to become significant in any
of these models. There are a number of possible explanations for
this. Assuming that spelling ratio is a good stand-in for
lexicalization, this finding could be taken to show that there is no significant correlation
between lexicalization and transparency. Alternatively, the role of
lexicalization could also be already subsumed
by the codings for the meaning shifts. 
\is{compound measures!{spelling ratio}!{remarks on its nature}}
Finally, spelling ratio might not be suitable
 to effectively represent lexicalization. Consider in this
respect also the nature of the dataset: since part of the original
criteria for selection was that the combinations have to occur at
least 50 times in the ukWaC corpus, none of the compounds are new or
ad-hoc formations. Therefore, it might well be that the proportion of
items in this set that are not spelled as one word is
disproportionately influenced by the phonological and/or orthographic
properties of the items (cf. the remarks on \emph{agony aunt} in
Section \ref{sec:bell-schaefer-lmer}), thus distorting the assessment
of a possible role of
concatenation as indicator of semantic opaqueness. Note in this
context also the findings by \citet{Marellietal:2014} with regard to distributional models for one
and the same compound based on its occurrence in either open or solid
form discussed in Chapter \ref{cha:modPrevious}, Section
\ref{sec:marellietal2014}: if it is correct that these different forms
are regurlarly associated with different meanings, then spelling ratio
picks out the balance of these meanings (if both forms are possible)
rather than presenting lexicalization as such.


\subsection{The role of the meaning shifts}
\label{sec:bell&schaefer2013_shifts}
\is{meaning shifts|(}
The innovative aspect of \citet{BellandSchaefer:2013} was the usage of
semantic annotations in the modeling. As evidenced by the mixed
effects models, the semantic relations do not contribute significantly
to transparency, except in the model for N1 transparency, where \textsc{in}
is a significant predictor, though barely so. In contrast, the meaning shifts
reoccurred in all mixed effects models, moreover, except for the model
of N2 transparency, all 3, that is N1 metaphor, N2 metaphor, and
N1N2 metaphor were significant predictors. 

Here, I want to argue that there are more fundamental problems with
these predictors. In order to do so, I will proceed in 2
steps. First, I will take a closer look at the relationship between
the codings for the shifts and the actual annotator
judgments. Secondly, I will argue that these relationship but also
principled considerations show that a binary category shift/no shift is
not able to adequately capture the nature of the data (for these
points, cf. also \citealt{BellandSchaefer:2016}).





\subsubsection{Relationship between the shift codings and the actual annotator judgments}
\label{sec:rel-codings-shifts}

One reason for the meaning shifts remaining in all models is likely to
be the very nature of the original task: Recall that raters were asked
for the literality of compounds and constituents. So if we model these
ratings with meaning shifts, which arguably are based on the idea that
there is a departure from a \isi{literal meaning} to some other
interpretation, we are actually coding the same thing that the raters
have rated (note that it is not coded in quite the same way, though, as
in the coding, 2 categories of shifts, metaphoric and metonymic,
were used, and the decisions were only categorical, while the raters
had a 6 point scale at their disposal).
% So, to put it quite clearly: 
But if the predictors encode the same things
as the dependent variable, it is not surprising that the predictors
become significant. In fact, if anything, it is surprising that the
predictors did not perform even better than they did. One
straightforward way of delving into this issue is by simply plotting
the actual ratings against the semantic annotation. Below, this is
done for the 3 possible metaphoric shifts (N1, N2, N1N2) and the
constituent as well as the whole compound ratings.

\figref{fig:bell&schaefer2013_ametaphor-ratings} shows the
distribution of the rater judgments for N1, N2, and N1N2
respectively against wheth\-er the compound was annotated as containing a
meta\-phorically shifted first constituent.
% rated with any of the 3 metaphorical meaning shifts.
\begin{figure}[!htb]
  \centering
% \includegraphics[scale=.3,clip, trim= 0mm 0mm 0mm 0mm]{/home/martin/Dropbox/statistics/habil-stat/bell-schaefer-2013-revisited/bell-schaefer-2013_Ratings-vs-Ametaphor.png}  
% \includegraphics[scale=.32,clip, trim= 0mm 0mm 0mm 0mm]{/home/martin/Dropbox/statistics/habil-stat/bell-schaefer-2013-revisited/bell-schaefer-2013_Ratings-vs-Ametaphor.pdf}  
\includegraphics[scale=.32,clip, trim= 0mm 0mm 0mm 0mm]{./figures/bell-schaefer-2013_Ratings-vs-Ametaphor.pdf}  
  \caption{The N1 is metaphor coding vs. rater judgments on N1, N2,
    and whole compound transparency. The 3 panels are all
    divided into 2 parts. On the left, they
    show the distribution of the transparency ratings for those items
    that are annotated as containing a metaphorically shifted first
    constituent, on the right, they show the distribution over the
    other items. The histograms on the left show the distribution of
    the N1 transparency ratings. The histograms in the middle show the
    distribution of the N2 transparency ratings. The histograms on the
    right show the distribution of the compound transparency ratings.}
  \label{fig:bell&schaefer2013_ametaphor-ratings}
\end{figure}

\enlargethispage{1\baselineskip}
The panel on the left hand side depicts the distribution of the N1 ratings,
the panel in the middle depicts the distribution of the N2 ratings,
and the panel on the right hand side depicts the distribution of the
N1N2 ratings. The Likert scale ratings are ordered form 0, the lowest
rating, to 5, the highest rating, with the lowest rating in black and
the higher ratings in increasingly lighter shades of gray. 

The patterns in \figref{fig:bell&schaefer2013_ametaphor-ratings} are
partially reassuring: in the left panel, one sees that for those items
that have been coded as N1 metaphor, there is a clear trend in the
ratings for lower transparency judgments, while the right-hand panel
with the whole compound ratings shows no clear trend. Of interest is
also the clear trend for high N2 ratings given an N1 coded as
metaphorically shifted. Of central interest for the discussion here,
though, is the fact that although there is a clear trend in the
left-hand panel, it is also clear that many N1 constituents were rated
as being quite or even fully transparent, although they are annotated
as shifted. This misalignment of rater judgments and semantic
annotation is even more apparent in the data for N2
transparency. \figref{fig:bell&schaefer2013_bmetaphor-ratings}
shows similar plots for the distribution of the ratings against
whether the items were annotated as containing a metaphorically
shifted second constituent. Focusing on the middle panel, where N2
ratings are plotted against the N2 metaphoric shift, one can see that
even though the lowest 2 ratings still account for the 2 most highly
populated bins, many constituents received very high transparency
ratings, so that it is difficult to speak of a general trend in the
distribution. 
Again, there is a still clearer trend for the other
constituent in the other direction, whereas there does not appear to
be a trend in the distribution of the whole compound ratings.



\begin{figure}[!htb]
  \centering
% \includegraphics[scale=.3,clip, trim= 0mm 0mm 0mm 0mm]{/home/martin/Dropbox/statistics/habil-stat/bell-schaefer-2013-revisited/bell-schaefer-2013_Ratings-vs-Bmetaphor.png}  
% \includegraphics[scale=.32,clip, trim= 0mm 0mm 0mm 0mm]{/home/martin/Dropbox/statistics/habil-stat/bell-schaefer-2013-revisited/bell-schaefer-2013_Ratings-vs-Bmetaphor.pdf}  
\includegraphics[scale=.32,clip, trim= 0mm 0mm 0mm 0mm]{./figures/bell-schaefer-2013_Ratings-vs-Bmetaphor.pdf}  
  \caption{The N2 is metaphor coding vs. rater judgments on N1 (left),
    N2 (middle),
    and whole compound transparency (right). The 3 panels contrast the
    distribution of the ratings for items coded as containing a
    metaphorically shifted N2 (left) with those that do not (right). }
  \label{fig:bell&schaefer2013_bmetaphor-ratings}
\end{figure}
\enlargethispage{1\baselineskip}
Finally, \figref{fig:bell&schaefer2013_abmetaphor-ratings} shows the distribution
of the ratings against wheth\-er the whole compound was annotated
as metaphorically shifted. Here, we see the expected pattern: as the
right hand panel shows, for those items coded as containing whole
compound shifts, almost none of the raters gave a high transparency
rating, and the trend towards low ratings is very
clear. Interestingly, this trend also occurs in the other 2 panels,
resulting in a much clearer pattern for the N2 ratings than what we
found for the N2 ratings of items rated as containing a shifted second constituent, cf. the middle panel in \figref{fig:bell&schaefer2013_bmetaphor-ratings}.
 
\begin{figure}[!htb]
  \centering
% \includegraphics[scale=.3,clip, trim= 0mm 0mm 0mm 0mm]{/home/martin/Dropbox/statistics/habil-stat/bell-schaefer-2013-revisited/bell-schaefer-2013_Ratings-vs-ABmetaphor.png}  
% \includegraphics[scale=.32,clip, trim= 0mm 0mm 0mm 0mm]{/home/martin/Dropbox/statistics/habil-stat/bell-schaefer-2013-revisited/bell-schaefer-2013_Ratings-vs-ABmetaphor.pdf}  
\includegraphics[scale=.32,clip, trim= 0mm 0mm 0mm 0mm]{./figures/bell-schaefer-2013_Ratings-vs-ABmetaphor.pdf}  
  \caption{The whole compound is metaphor coding vs. rater judgments on N1, N2, and whole compound transparency}
  \label{fig:bell&schaefer2013_abmetaphor-ratings}
\end{figure}


% Section: AB metaphors


% 

% > count(bellSchaefer2013Amet$wordSenseID)
%                     x freq
% 1        call_centre1   16
% 2     chain_reaction1   14
% 3     chain_reaction2    1
% 4       crash_course1   14
% 5    diamond_wedding1   17
% 6           end_user1   16
% 7         face_value1    6
% 8         face_value2    9
% 9          game_plan1    7
% 10 grandfather_clock1   12
% 11   graveyard_shift1   14
% 12       gravy_train1   13
% 13      head_teacher1   12
% 14    lotus_position1   17
% 15         panda_car1   12
% 16     pecking_order1   15
% 17          rat_race1   13
% 18           rat_run1   17
% 19        role_model1   17
% 20  shrinking_violet1   15
% 21    smoking_jacket1   16
% 22        snail_mail1   17
% 23          web_site1   13
% 24    zebra_crossing1   14


% \ex. A metaphor [note:standard deviation, e.g. for web values all over the place!]
% \a. chain reaction  (2 senses) 2.285714/2 
% % \b. chain reaction    
% \b. crash course 1      
% \c. diamond wedding 0.7647059  
% \d. head teacher  2.833333    
% \d. lotus position 0.7058824   
% \d. panda car 0.4166667        
% \d. shrinking violet 2.6 
% \d. zebra crossing 0.6428571   
% \d. grandfather clock 0.1666667 
% \d. call centre 4.6875      
% \d. game plan 1        
% \d. pecking order 0.8    
% \d. role model 3.294118       
% \d. smoking jacket 0.875   
% \d. gravy train 0.1538462      
% \d. face value (2 senses)   2.166667/0.8888889
% % \d. face value        
% \d. rat run 0.3529412          
% \d. end user 3.8125         
% \d. graveyard shift 0.4285714  
% \d. web site 2.923077         
% \d. rat race 0.3076923         
% \d. snail mail 0.5294118       

% \ex. B metaphor: 23 types, 24 senses
% \a. blame game        
% \b. spelling bee      
% \c. guilt trip        
% \d. agony aunt        
% \d. car park          
% \d. credit card       
% \d. eye candy         
% \d. firing line  (two senses)     
% % \d. firing line       
% \d. search engine     
% \d. spinning jenny    
% \d. think tank        
% \d. balance sheet     
% \d. memory lane       
% \d. couch potato      
% \d. number crunching  
% \d. lip service       
% \d. shrinking violet  
% \d. call centre       
% \d. gravy train       
% \d. web site          
% \d. rat race          
% \d. cheat sheet       
% \d. cash cow          

% Hier WEITER!
% > count(bellSchaefer2013Amet$wordSenseID)
%                     x freq
% 1        call_centre1   16
% 2     chain_reaction1   14
% 3     chain_reaction2    1
% 4       crash_course1   14
% 5    diamond_wedding1   17
% 6           end_user1   16
% 7         face_value1    6
% 8         face_value2    9
% 9          game_plan1    7
% 10 grandfather_clock1   12
% 11   graveyard_shift1   14
% 12       gravy_train1   13
% 13      head_teacher1   12
% 14    lotus_position1   17
% 15         panda_car1   12
% 16     pecking_order1   15
% 17          rat_race1   13
% 18           rat_run1   17
% 19        role_model1   17
% 20  shrinking_violet1   15
% 21    smoking_jacket1   16
% 22        snail_mail1   17
% 23          web_site1   13
% 24    zebra_crossing1   14
% > AmetMatch <- bellSchaefer2013Amet[,c("wordSenseID","MeanLitScoreN1","sdLitScoreN1")]
% > unique(AmetMatch)

% \begin{table}[h!]
%   \centering
%   \begin{tabular}[h]{rrr}
% \begin{tabular}[h]{rrr}
%             wordSenseID& MeanLitScoreN1& sdLitScoreN1\\
%        call\_centre1&     4.6875000&   0.4787136\\
%     chain\_reaction1&     2.2857143&   1.4373358\\
%     chain\_reaction2&     2.0000000&          NA\\
%       crash\_course1&     1.0000000&   0.9607689\\
%    diamond\_wedding1&     0.7647059&   0.9034249\\
%           end\_user1&     3.8125000&   1.3275918\\
%         face\_value1&     2.1666667&   1.1690452\\
%         face\_value2&     0.8888889&   0.9279607\\
%          game\_plan1&     1.0000000&   1.2909944\\
%  grandfather\_clock1&     0.1666667&   0.3892495\\
%    graveyard\_shift1&     0.4285714&   0.6462062\\
%        gravy\_train1&     0.1538462&   0.3755338\\
%       head\_teacher1&     2.8333333&   1.8989630\\
%     lotus\_position1&     0.7058824&   0.5878675\\
%          panda\_car1&     0.4166667&   0.5149287\\
%      pecking\_order1&     0.8000000&   1.0141851\\
%           rat\_race1&     0.3076923&   0.6304252\\
%            rat\_run1&     0.3529412&   0.4925922\\
%         role\_model1&     3.2941176&   1.4476147\\
%   shrinking\_violet1&     2.6000000&   1.5946339\\
%     smoking\_jacket1&     0.8750000&   0.7187953\\
%         snail\_mail1&     0.5294118&   0.7174301\\
%           web\_site1&     2.9230769&   1.8466880\\
%     zebra\_crossing1&     0.6428571&   0.4972452\\
%   \end{tabular}
    
%   \end{tabular}
%   \caption{Items with shifted first constituent with mean and standard deviations of their literality scores}
% \end{table}
% % > # Collect the Bmetaphor items
% % > bellSchaefer2013Bmet <- subset(bellSchaefer2013,bellSchaefer2013$Bmetaphor == "Yes")
% % > count(bellSchaefer2013Bmet$wordSenseID)
% %                    x freq
% % 1        agony_aunt1   17
% % 2     balance_sheet1   17
% % 3        blame_game1   14
% % 4       call_centre1   16
% % 5          car_park1   20
% % 6          cash_cow1   13
% % 7       cheat_sheet2   15
% % 8      couch_potato1   16
% % 9       credit_card1   14
% % 10        eye_candy1   14
% % 11      firing_line1    1
% % 12      firing_line2   12
% % 13      gravy_train1   13
% % 14       guilt_trip1   14
% % 15      lip_service1   17
% % 16      memory_lane1   11
% % 17         rat_race1   13
% % 18    search_engine1   13
% % 19 shrinking_violet1   15
% % 20     spelling_bee1   14
% % 21   spinning_jenny1   15
% % 22       think_tank1   14
% % 23         web_site1   13
% % > BmetMatch <- bellSchaefer2013Bmet[,c("wordSenseID","MeanLitScoreN2","sdLitScoreN2")]
% % > unique(BmetMatch)
% \begin{table}[h!]
%   \centering
% \begin{tabular}[h]{rrr}
%       wordSenseID&MeanLitScoreN2& sdLitScoreN2\\
%       agony\_aunt1&    0.47058824&   0.6242643\\
%    balance\_sheet1&    3.70588235&   0.9851844\\
%       blame\_game1&    1.71428571&   1.4898927\\
%      call\_centre1&    4.31250000&   0.7041543\\
%         car\_park1&    3.80000000&   1.1964861\\
%         cash\_cow1&    0.46153846&   0.8770580\\
%      cheat\_sheet2&    4.13333333&   0.6399405\\
%     couch\_potato1&    0.25000000&   0.4472136\\
%      credit\_card1&    4.85714286&   0.3631365\\
%        eye\_candy1&    0.92857143&   0.9168748\\
%      firing\_line1&    5.00000000&          NA\\
%      firing\_line2&    1.25000000&   1.2154311\\
%      gravy\_train1&    0.07692308&   0.2773501\\
%       guilt\_trip1&    0.71428571&   0.7262730\\
%      lip\_service1&    1.70588235&   1.5315313\\
%      memory\_lane1&    0.90909091&   0.9438798\\
%         rat\_race1&    2.23076923&   1.4806444\\
%    search\_engine1&    2.30769231&   1.9741925\\
% shrinking\_violet1&    0.46666667&   0.7432234\\
%     spelling\_bee1&    0.64285714&   1.3926810\\
%   spinning\_jenny1&    0.26666667&   0.4577377\\
%       think\_tank1&    0.35714286&   0.6333237\\
%         web\_site1&    3.30769231&   1.4366985\\
%   \end{tabular}
%   \caption{Items with shifted second constituent with mean and standard deviations of their literality score}
% \end{table}
% \begin{table}[h!]
%   \centering
% \begin{tabular}[h]{rrr}
% wordSenseID& MeanLitScoreN1N2 &sdLitScoreN1N2\\\hline  
%         acid\_test1&        1.0769231      &1.1151636\\
%        brass\_ring1 &       2.7500000      &1.7078251\\
%        brick\_wall1  &      1.1666667      &1.1690452\\
%        cloud\_nine1   &     0.3684211      &0.5972647\\
%      couch\_potato1&        1.5625000      &1.1528949\\
%   crocodile\_tears1 &       1.4285714      &1.0163499\\
%      cutting\_edge1&        1.2307692      &1.0127394\\
%        face\_value2 &       2.6666667      &0.5000000\\
%     fashion\_plate1  &      1.3333333      &1.1547005\\
%         fine\_line1   &     2.7058824      &1.4037764\\
%       firing\_line2    &    0.6666667      &0.7784989\\
%      front\_runner1     &   2.6428571      &1.2774459\\
%       ivory\_tower1      &  0.6000000      &0.7367884\\
%       lip\_service1       & 1.7647059      &1.0914103\\
%       melting\_pot1       & 0.6000000      &0.6324555\\
%   monkey\_business1        &0.8125000      &0.6551081\\
%          nest\_egg1        &0.7647059      &0.9701425\\
%         night\_owl1        &1.6428571      &1.3363062\\
%          rat\_race1        &0.9230769      &1.0377490\\
%           rat\_run1        &0.7058824      &0.6859943\\
%       rock\_bottom1        &2.4285714      &1.2224997\\
%    rocket\_science2        &0.9375000      &1.1236103\\
%         rush\_hour1        &2.9411765      &1.4348601\\
%        sacred\_cow1        &0.8461538      &1.1435437\\
%  shrinking\_violet1        &1.1333333      &1.1254629\\
%     silver\_bullet1        &0.4285714      &0.6462062\\
%      sitting\_duck1        &0.8666667      &1.1254629\\
%       smoking\_gun1        &0.8125000      &0.9105859\\
%         snake\_oil1        &1.0000000      &0.0000000\\
%         snake\_oil2        &0.6250000      &0.7440238\\
%         swan\_song1        &0.6250000      &0.7187953
% \end{tabular}
%   \caption{Shifted items with mean and standard deviations of their literality score}
% \end{table}

% > # Collect the ABmetaphor items
% > bellSchaefer2013ABmet <- subset(bellSchaefer2013,bellSchaefer2013$ABmetaphor == "Yes")
% > count(bellSchaefer2013ABmet$wordSenseID)
%                    x freq
% 1         acid_test1   13
% 2        brass_ring1    4
% 3        brick_wall1    6
% 4        cloud_nine1   19
% 5      couch_potato1   16
% 6   crocodile_tears1   14
% 7      cutting_edge1   13
% 8        face_value2    9
% 9     fashion_plate1    3
% 10        fine_line1   17
% 11      firing_line2   12
% 12     front_runner1   14
% 13      ivory_tower1   15
% 14      lip_service1   17
% 15      melting_pot1   15
% 16  monkey_business1   16
% 17         nest_egg1   17
% 18        night_owl1   14
% 19         rat_race1   13
% 20          rat_run1   17
% 21      rock_bottom1   14
% 22   rocket_science2   16
% 23        rush_hour1   17
% 24       sacred_cow1   13
% 25 shrinking_violet1   15
% 26    silver_bullet1   14
% 27     sitting_duck1   15
% 28      smoking_gun1   16
% 29        snake_oil1    2
% 30        snake_oil2    8
% 31        swan_song1   16
% > ABmetMatch <- bellSchaefer2013ABmet[,c("wordSenseID","MeanLitScoreN1N2","sdLitScoreN1N2")]
% > unique(ABmetMatch)
Another interesting observation is that the total number of items
coded as containing shifts is actually higher than the number of items
judged by the raters as departing from literality.\is{literal meaning} 
As
seen earlier, in \figref{fig:frequency-of-coded-shifts}, the
individual shift categories contain at most 31 compound readings,
however, since the different shifts are distributed over all the
items, there are actually only
28 compound readings that are annotated as containing no shift at all. In
contrast, 40 compound readings where given unanimously `5' ratings on
all 3 transparency categories, that is, N1, N2, and N1N2. Thus,
although the semantic annotators had to make a categorical decision and
the raters could choose from a scale, the semantic annotators were
more prone to judge items as departing from literality than the
raters.

In the following section, I want to argue that the actual coding of
the meaning shifts and the conclusion one can draw from the annotation
results go a long way towards explaining this discrepancy.

\subsubsection{Coding the meaning shifts}
\label{sec:bell&schaefer2013_shifts}

% it is hard to argue that write:''Metaphors and
% metonyms presents types of well-known shifts, other candidates would be e.g.  the process of meaning
% differentiation, cf. Bierwisch (1982)."

In \citet[3]{BellandSchaefer:2013}, we just mention that the shifts that we
coded, \emph{metaphor} and \emph{metonymy}, are well-known, and refrain
from any further explanation. In fact, both types of meaning shifts
are part of, if not everyday knowledge, then at least common
knowledge that linguists acquire at the very early stages of their
education. If we look at introductory semantics textbooks, we
find definitions like
cf. \Next and \NNext, taken from \citet[52--53]{Loebner:2013}, his
Definition 5 and 6 respectively.\is{literal meaning}

\pagebreak[4]
\ex. Metonymy\\
An expression is used metonymically if it is used to refer to things
that belong to the kind of objects to which the expression refers in
its literal meaning.
% Definition 5, \citet[52]{Loebner:2013}
\is{metonymy!{definition of}}

\ex. \label{def:metaphor-loebner-2013}
Metaphor\\
An expression is used metaphorically if it is used to refer to things
that are in crucial aspects similar to the kind of objects to which
the expression refers in its literal meaning.\\
% Definition 6, \citet[53]{Loebner:2013}
\is{metaphor!{definition of}}

In annotating the compounds for meaning shifts, I think that we had definitions of this kind in mind. Note that both definitions use the concept of `literal meaning', a
point we will come back to later (see also the discussion of the term
in Chapter \ref{cha:theo}, Section \ref{sec:literality}).\is{literal meaning}

\subsubsection{Coding metonymic shifts}
\label{sec:bellschaefer2013-coding-metonymic}
\is{metonymy!{coding metonymic shifts}|(}
As mentioned above, the metonymic shifts were not very frequent and were therefore not considered in the statistical models. Even so,
if I look at the coding by us in \citet{BellandSchaefer:2013}, I find it
very hard to reconstruct the coding of some of the metonymical
shifts. Coding
\emph{cocktail} in \emph{cocktail dress} as metonomy seems
straightforward to me: the
whole compound refers to a dress worn at cocktail parties, and
cocktails belong to cocktail parties (note that this holds independently
of whether one knows the exact literal meaning of `cocktail').
% In contrast, other codings choices are, in retrospect, not clear to me:
But why did we classify \emph{cash} in \emph{cash cow} and \emph{wedding}
in \emph{diamond wedding} as a metonymic
shifts? Likewise, why did we classify \emph{silver
  spoon} as whole compound metonomy? Constructing metonymical analyses is not impossible, but the analyses do
not seem to be very compelling. Thus, the image associated with
\emph{cash cow}, at least for me, is of a cow that gives coins instead
of milk, and since cash consists of banknotes and coins, the
definition of metonymy is fulfilled. However, on reflection, this
seems to be a rather idiosyncratic interpretation, and other interpretations are
equally plausible. 
\is{metonymy!{coding metonymic shifts}|)}

\subsubsection{Coding metaphoric shifts}
\label{sec:bellschaefer2013-coding-metaphorical}

\is{metaphor!{coding metaphoric shifts}|(}
At first sight, the coding of the metaphorical variables seems much
more straightforward than the coding of metonymy, consider e.g. \emph{head} in \emph{head
  teacher}, \emph{aunt} in \emph{agony aunt}, and the whole compound
shift assumed for \emph{swan song}, with representative usages given
below:

\pagebreak[4]
\ex.  At the beginning of the school year, Mr Bailey, the \textbf{head teacher}, would remind the staff about various rules at the school and he would also give us his view about clothes. BNC/A6V 2190 	

\ex. I am still friends with my ex-husband who takes it on himself to be my personal \textbf{agony aunt}. BNC/CH1 6758 	

\ex. Gazing out into the blue, he asked himself if this assignment was his \textbf{swan song}. BNC/AC2 496 	

Head in \emph{head teacher} is clearly used metaphorically, indicating
that the referent is the person whose role with respect to whichever institution the person is
head teacher of resembles the role of the head with respect to the body, i.e., that part
that makes decisions for and guides the whole. Similarly clearly, \emph{aunt} in \emph{agony aunt}
clearly does not refer to the speaker's real aunt, but to her
ex-husband taking over a role that resembles the role and status of an agony aunt. In both cases, the metaphorically shifted elements are, to quote 
 Löbner's definition from \ref{def:metaphor-loebner-2013} above, ``in crucial aspects
similar" to the meaning of \emph{aunt} as caring and trustworthy female relative and head as the body part.
And finally, the whole
compound shift of \emph{swan song} is equally obvious, as here, although the
expression refers to an assignment executed by a human, not a swan,
the similarity lies in the metaphor being used to indicate one final,
substantive effort.
 
Other decisions are not so clear, but for different reasons (cf. also the discussion in \citet{BellandSchaefer:2016}.
However, in one way or the other all of the decisions are linked to the notion of
\isi{literal meaning}. Here, I will first focus on compounds where it is unclear whether
shifts are involved and if so, which. Secondly, I will discuss the more fundamental aspect of the
availability of a given \isi{literal meaning}.

I already reported in Section \ref{sec:bell-schaefer-annotation-results} that 2 items, \emph{kangaroo court} and
\emph{flea market}, had been excluded from the semantic annotation,
because we could not agree on an annotation, and pointed to their
murky etymology as a likely reason for this disagreement. However,
similar points can be made with regard to some of the other compounds
in the dataset. I will illustrate this here with the help of
\emph{grandfather clock} and \emph{gravy train}. 

\emph{Grandfather} in \emph{grandfather clock}
is coded as being metaphorically shifted. We identified \textsc{be} and \textsc{have2}
as possible semantic relations, which is already a first indicator
that we had trouble coding this item, since no other compound reading
is coded with 2 different relations, and, according to the logic of
the coding, the 2 relations cannot refer to the same construal of
the compound meaning. Construing the compound with the \textsc{be} relation, \emph{grandfather}
clearly requires a metaphoric shift. Note, though, that it is not at all clear which metaphorical shift this should be, it could be from grandfather to something as old or
old-fashioned as a grandfather, or perhaps to something as big as a
grandfather. This is quite different from other items coded as
containing a metaphoric shift in the first constituent, cf. the
above-mentioned \emph{head teacher} or items like
\emph{panda car} or \emph{snail mail}, where in both cases the crucial
aspect involved in the shift, for \emph{panda} the white-black
pattern, for \emph{snail} the speed of movement, is very
straightforward.
The construal with the \textsc{have2} relation, that is, a clock that
grandfathers have, does not necessarily
require a meaning shift of the constituent, although a widening from
biological grandfather to all kinds of old people seems likely, that
is, a clock that old people have. Thus, depending on the construal,
\emph{grandfather} is either shifted or unshifted, and if shifted,
different crucial aspects can be selected, partly depending on the
construal. All of the shifts involve considerable interpretational
work and are not immediately obvious. Etymologically, all appear to be wrong:
According to the OED, the name \emph{grandfather clock} for a tall,
floor-standing clock, originates from the song, \emph{My Grandfather’s
Clock}, and not from a shift in the meaning of \emph{grandfather}. 
% Without
% that etymological knowledge, the raters would have had to try to infer
% some relation between the concepts \textsc{Grandfather} ,
% \textsc{Clock} and \textsc{Grandfather clock} , which may well have proved more difficult than the
% straightforward shift for \emph{eye candy}.

\emph{Gravy} in \emph{gravy train}, a compound which was already mentioned in
 Section \ref{sec:bs2013_mixed-effects-for-constituents} in the
 discussion of mixed
 effect models for constituent transparency, likewise is annotated as
 containing a metaphorically shifted first constituent. Again, though, it is
 quite unclear what the exact nature of the shift is supposed to
 be. The OED lists the whole compound under a word sense of
 \emph{gravy} that comes from U.S. slang usage:
 2. d. ``Money easily acquired; an
 unearned or unexpected bonus; a tip. Hence \textbf{\emph{to ride (board) the gravy
 train (}or \emph{boat)}}, to obtain easy financial success."
%   slang (orig. U.S.). 
Is this a metaphor for any other sense of \emph{gravy}? It is
certainly not very straightforward, and it is not helping that the
role of trains in all of this is unclear (\emph{gravy train} is the
topic of numerous blog entries, cf. Quinion (n.d.) for a good overview).\nocite{Quinion:web}

\is{literal meaning|(}
I now turn to the second issue, the necessity of having a
\isi{literal meaning} to start with: in order to classify something as
metaphorically shifted, it has to be clear what the literal meaning is
supposed to be. Thus, we rated \emph{card} in \emph{credit card} as
metaphorical shifted. Our reasoning was that a \emph{card} is made
from cardboard and not from plastic like credit cards. Therefore,
\emph{card} needs to be shifted. Likewise, we coded \emph{web} in
\emph{website} as metaphoric, reasoning that it does not refers to a
real web, that is, a spider's web or anything tangible resembling
one. These decisions were based on our intuitions about these words;
the average ratings of 2.7 for \emph{web} and \emph{4.9} for
\emph{card} show that the raters saw medium and almost no deviation
from the literal meaning for the 2 constituents. How can this be?
First, as the discussion in Chapter \ref{cha:theo}, Section
\ref{sec:literality} has already shown, literal meaning is not a
well-defined notion. Second, neither were the raters instructed to
make decisions based on etymology, nor were our own annotations meant
as exercises in etymology. What we annotated was whether we
intuitively thought that something was metaphorically shifted or
not. There are a number of factors that influence one's perception of
words as shifted. Recall the reasoning by \citet{Jaszczolt:2016} from
the earlier discussion that being able to easily come up with a
meaning in isolation is linked to being able to envision contexts for
the respective meaning. In other words, if a word sense requires a
very specific context, we might perceive it as somehow shifted from
the original.\is{literal meaning} Also, in the same section, I pointed to the role of
contrasting pairs as driving such perceptions. In the case of
\emph{credit card}, once you start considering the card made from
cardboard against the plastic version it seem plausible to consider
the latter as somehow derivative. However, in many cases it is unclear
when an additional contrast with another meaning is considered. Among
other things, the frequencies of specific senses alone and in other
compounds are likely to play a role. Further, specific properties of
the referents might play a role, so that for example animal names
(\emph{swan}, \emph{crocodile} etc.), which refer to concrete and
specific living entities, are more likely to give rise to senses that
are seen as derived even if this does not necessarily correspond to
frequency of usage of that specific word sense (in this context,
recall that of the 5 lowest rated first constituents in the Reddy et
al. dataset, 4 are animal terms, cf.
\tabref{tab:constituent1-ratings} in Section
\ref{sec:descriptive-statistics}).\is{literal meaning|)}
\is{meaning shifts|)}
\is{metaphor!{coding metaphoric shifts}|)}

\section{Conclusion and consequences }
\label{sec:con&con}

This chapter started with the idea to model the semantic transparency
of compounds by
including predictors that represent core aspects of their semantics: meaning shifts and the relations holding between a compound's
constituents.
% , were used to predict the semantic transparency of the
% respective compounds.
After introducing the
dataset from which the dependent variables, the transparency ratings
for compounds and their constituents, were drawn, I introduced the
annotation scheme used in \citet{BellandSchaefer:2013}, as well as the
results of their annotation. Section
\ref{sec:bell-and-schaefer-models} presented the models from
\citet{BellandSchaefer:2013}. The central part of this chapter,
however, is Section \ref{sec:bell-and-schaefer-2013-revisited}. In
Section \ref{sec:bell-schaefer-lmer}, I first explain why the nature
of the data requires one to use mixed effects models. Secondly, using mixed effects models
shows that semantic relations, when considered as predictors
independent of particular constituents, do not play a role in models
of compound
transparency. In contrast, meaning shifts as coded in
\citet{BellandSchaefer:2013}, play a role. However, I argue in Section \ref{sec:bell&schaefer2013_shifts}
that the way in which meaning shifts were coded throws
doubt on the meaningfulness of the results. 
All in all, this chapter has thus shown that the goal behind
the paper by \citet{BellandSchaefer:2013}, namely to show that the internal semantic structure of compounds plays a role
for their perceived transparency, turns out not to have been achieved.

In the next chapter, I
will therefore report on work that takes a different, expectancy-based
approach on the role of semantic relations as well as on the role of
meaning shifts.

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "habil-master_rev-1"
%%% End: 
