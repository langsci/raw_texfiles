\chapter[Compound family based models]{Modeling the semantic transparency of  English compounds: compound family based models}
\label{cha:empirical-2}
% all includegraphics commands changed to ./figures/
% When no further information is given, these were previously located in:
% /home/martin/Dropbox/statistics/habil-stat/
What other ways are there to exploit the underlying semantic structure
of compounds in modeling their semantic transparency? And, more
crucially, how can the problems and pitfalls encountered in the
previous chapter be avoided? This chapter presents a new, alternative approach using semantic features of
compounds in models of semantic transparency. In contrast to the
method presented in the previous chapter, in which all semantic
predictors were based on features of the target compounds alone, the
approach presented here is based on semantic features of the constituents
and the whole compound relative to the patterns found in the
respective compound's constituent families. This chapter includes a
detailed introduction to the approach and the models presented in \citet{BellandSchaefer:2016}. 
The choice of semantic explanatory variables for the models presented in this chapter is a result
of the conclusions drawn from the models discussed in the
previous chapter. % , chapter \ref{cha:empirical-1}. 
In the mixed effects
models presented there, the semantic relations used in the individual
compounds did not emerge as significant predictors (except for
\textsc{in} in the model for N1 transparency). Furthermore, I have
argued that the coding of meaning shifts is not empirically sound.
The dependent variables in the statistical models are again
the semantic transparency ratings collected in \citet{Reddyetal:2011}
which have been introduced earlier.

% Instead of just coding the individual
% word senses, the semantic predictors are now based on the constituent
% families of the individual compounds. 
In order to make use of constituent family information, I annotated a
large set of compounds with information on semantic relations as well
as constituent senses. Since this dataset constitutes a unique
resource that can be used independently, its creation is described in
detail. 

This chapter is structured as follows: Section
\ref{sec:operationalization-sem-rel} discusses previous studies
using semantic relations relative to compound families and motivates
the procedure used to derive the corresponding explanatory variables
for the models to be discussed in this chapter. Section
\ref{sec:meaningShiftsInFamilies} extends the expectancy-based
approach used for the semantic relations to the coding of constituent
senses. Section \ref{sec:methods1} describes the methods used by
Melanie Bell and me to arrive
at a representative set of compound families for the
Reddy et al. items. My subsequent semantic coding of the compounds in
these families is described in Section \ref{sec:methodsSemCoding}. Section \ref{sec:bellschaefer2016_further-and-predictions} introduces the explanatory variables
and the predictions from \citet{BellandSchaefer:2016}. The models
from \citet{BellandSchaefer:2016} are presented and discussed in
Section \ref{sec:bellandschaefer2016models}. Section
\ref{sec:bellandschaefer2016_new_models} starts from the inspection of
the residuals of the models introduced in the previous section and shows
the results of running models on the data after cleaning it using a
more consistent outlier removal algorithm. 
% Section \ref{sec:spelling-ratio} discusses reasons for the different role of
% the variable spelling ratio in the models discussed in this chapter as
% opposed to its role in the models discussed in chapter
% \ref{cha:empirical-1}. 
Section \ref{sec:emp2-conclusion} concludes.

\section[Semantic relations relative to constituent families]{Measuring semantic relations relative to constituent families}
\label{sec:operationalization-sem-rel}

\is{compound!{constituent family}!{assessing distribution of semantic relations}|(}
While in works like \citet{Plagetal:2007}, \citet{Plagetal:2008}, and \citet{BellandSchaefer:2013} the different semantic relations
between compound constituents were treated as predictors across the
whole set of data considered, works within the framework of conceptual
combination
% , that is, ``the process by which existing concepts are
% combined to generate new concepts'' \citet[283]{Spaldingetal:2010}, 
offer a very different perspective on the nature of the
relational information in compound processing. 
Central to this understanding is the following quote: 
% 
% More generally, our view is that 
``[\dots] the difficulty of any particular
combination is a function neither of its frequency in the language nor
of the complexity of the relation. Instead, we contend that the
difficulty is a function of the likelihood of the thematic relation
for the particular constituents'' \citep[73]{GagneandShoben:1997}. 
% In this paper, they present initial evidence for their view. 
If one wants to test whether this constituent-centric view of semantic
roles can explain the role of semantic relations in rating semantic
transparency, then 2 core issues need to be decided:\is{semantic relations!{constituent specific}}
\begin{inparaenum}[(1)]
\item What should be
used as the basis for the distribution of the semantic relations for a
specific constituent?
\item How should the place of a particular compound in this
distribution be represented, that is, what measure should be used to
capture the distribution of relations as it pertains to a specific
compound and its constituents. 
\end{inparaenum}

% This section begins by introducing the methods used in \citet{GagneandShoben:1997} in section \ref{sec:gagneshoben-rel}. 
% Section \ref{sec:relationalFamilies2} discusses some criticism brought
% against this approach, including the attempt by
% \citet{Maguireetal:2007} to compare the results of Gagné and Shobens
% method to an alternative way of establishing the relational
% distributions. Finally, section
% \ref{sec:relations-other-studies} summarizes how relations were
% treated in \citet{PhamandBaayen:2013}. 

After introducing the methods used in \citet{GagneandShoben:1997} to
assess the distribution of semantic relations, I will  discuss some criticism brought
against their approach, including the attempt by
\citet{Maguireetal:2007} to compare the results of Gagné and Shoben's
method to an alternative way of establishing the relational
distributions. Finally, the way semantic relations were
treated in \citet{PhamandBaayen:2013} is summarized, and conclusions
for the procedure to assess the distribution of semantic relations for
the target data used in this chapter are drawn.


% In order to assess the likelihood of a particular thematic relation, they
% used the number of occurences of specific relations within the
% constituent families of the respective compounds. These frequencies
% were drawn from their own artificial corpus, being derived from
% combinations in the appendix of \citet{Levi:1978} and permissible permutations thereof
% (cf. \citet[854--855]{StormsandWisniewski:2005},
% \citet{WisniewskiandMurphy:2005}, \citet{Maguireetal:2007}
% \citet{SpaldingandGagne:2008} for discussion of their procedure).

\subsection{Gagné and Shoben}
\label{sec:gagneshoben-rel}

The \isi{CARIN model}, the \textbf{C}ompetition \textbf{A}mong
\textbf{R}elations \textbf{I}n \textbf{N}ominals models introduced in
\citet{GagneandShoben:1997}, was already discussed in Chapter
\ref{cha:semTranPsycho}, Section \ref{sec:carin}, and along with it
also one specific measure they used to assess the distributions of
semantic relations over a constituent family, the strength
ratio. Here, I will describe in more detail which data they used to
establish the distribution of the relations over a compound's
constituent family, and which measures they used to operationalize
these distributions.

\subsubsection{Establishing the distributions of the relations}
\label{sec:gagneShobenEstabRelDistro}

% Here, I want to look in somewhat more detail at the basis
% How did \citet{GagneandShoben:1997} used
% for establishing . 
As mentioned in Chapter \ref{cha:semTranPsycho}, Section
\ref{sec:carin}, the distribution of relations within a constituent
compound family
were drawn from Gagné and Shoben's own artificial corpus, which was derived from
combinations in the appendix of \citet{Levi:1978} and permissible
permutations thereof. What exactly does this mean? 
\citet[74]{GagneandShoben:1997} report that they
started with the 91 modifiers and 91 heads taken from the Shoben and Medin corpus
which was created by sampling
100 combinations from the appendix of \citet{Levi:1978} and removing
duplicates (they refer to \citealt{Shoben:1991} but there the
corpus is described only vaguely). % this paper is not at all clear on
                                % what the people did! strange! on
                                % page 127 it says they sampled all
                                % combinations. 
The appendix of \citet{Levi:1978} is not very
large and contains 3 pages listing examples of all of her proposed
derivations, ranging from just 8 types of complex nominals for the
\textsc{make1} category to larger groups, e.g. \textsc{have2} with 26
compound types. There is no information concerning the sources of
these examples in her appendix. 
From these 2 sets of modifiers and heads, \citet[74]{GagneandShoben:1997} created all possible permutations (91
x 91 = 8,281). They selected only those permutations which were
sensible, yielding a set of 3,239 sensible permutations. This
procedure is the reason for my labeling of this corpus as artificial:
while it is still very likely to contain the original sample of
 compounds from the Levi appendix whose constituents were used to
generate the permutations, the permutations might or might not be
attested in English. These 3,239
sensible combinations were
then 
classified into 15 categories by both authors (the Levi categories
plus some additions, cf. Chapter \ref{cha:semTranPsycho}, Section \ref{sec:carin} for the details).
% , essentially resembling the
% Levi categories, except that both USE and IN (here: located) also
% occurred in two relational versions, e.g. instead of just USE they had
% two relations, one for `noun uses modifier' \emph{gas antiques},
% % antiques relating to gas/gas station memorabilia?   
% one `noun used by modifier' \emph{servant language}
% (these revisions to Levi's categories stem from Shoben and Medin). In
% addition, the category `noun during modifier' was used (for
% e.g. \emph{summer cloud}).
The resulting counts yielded the distribution of semantic relations across constituent
families in their corpus.
% BEGIN: \citet[74]{GagneandShoben:1974}
% In this experiment, we examined whether the availability
% of a thematic relation influences the ease with which a
% combined concept can be interpreted We used combined
% concepts that instantiate a subset of the thematic relations
% described by Levi (1978) and Downing (1977). We defined
% the availability of a thematic relation for a constituent
% concept as the frequency with which combinations contain-
% ing that concept were interpreted as having the relation in
% question. To determine the frequency of various combina-
% tions, we reexamined Shoben and Medin's (Shoben, 1991)
% corpus. They sampled 100 combinations from the appendix
% of Levi's (1978) book. Deleting duplications left them with
% 91 head nouns and 91 modifiers. We examined all possible
% combinations and determined which were sensible. Each of
% us subsequently classified all 3,239 sensible combinations
% into 15 categories: the 14 identified by Medin and Shoben
% (1991; see Table 1 in the present article) plus the category
% "noun during modifier" (e*g., summer cloud).
% Subsequently, we determined the frequency with which
% each relation occurred for each modifier and each head noun.
% For example, the head noun cloud appeared in 16 sensible
% combinations in the corpus. Of these, 2 were locatives, and
% thus locatives constituted 13% of the total.
% END: \citet[74]{GagneandShoben:1974}


\subsubsection{Measuring a relation's place}
\label{sec:gagneShobenMeasuringARelationsPlace}


As already discussed in Chapter \ref{cha:semTranPsycho}, Section
\ref{sec:carin}, \citet{GagneandShoben:1997} introduce the 
strength ratio, repeated in \Next for convenience, as a measure to capture the competition between the
relation relevant for a specific compound and the other relations
occurring in the compound's constituent families.\is{compound measures!{strength ratio}}  
\is{semantic relations!{measuring the distribution}|(}
\is{frequency!{distribution of semantic relations}|(}

\ex. % \label{ex:strength-ratio}
\label{ex:strength-ratio-rep}
\( \displaystyle \text{strength} = \frac{e^{-ap_{\text{selected}}}}{e^{-ap_{\text{selected}}}\; + \;
e^{-ap_{1}} \; + \; e^{-ap_{2}}\; +\; e^{-ap_{3}}} \)
% \\ 
% $p_1$ proportion of most freqent relation (for a specific item) in corpus\\
% e exponential decay function [etwas irreführend, vielleicht Abnahme der Stärke
% via eulersche Zahl genug]\\
% a constant

The way this formula works and the reason why the later renaming of strength
ratio to
\emph{competition} is conceptually preferable were also already
discussed in Section
\ref{sec:carin}. 

\citet{GagneandShoben:1997} introduced the above measure
in a post-hoc analysis; throughout the paper, they use the distributional data in 2 other ways:
\begin{inparaenum}[(1)]
\item in the preparation of the experimental materials, they used an
  arbitrary 60\% cutoff point to distinguish between constituents
  occurring with high relational frequency and those occurring with low
  relational frequency. In other words, any
relation within a constituent family that accounted for 60\% of the
combinations was considered a high frequency relation for that
constituent family. If no single relation accounted for 60\%, all
relations that occurred within the 60\% bracket were taken as high
frequency relations. This classification was used to construct
3 classes of experimental items: a combination High-High
frequency, e.g. \emph{mountain bird}, a combination Low-High frequency, e.g.
\emph{mountain magazine}, and a combination
High-Low frequency, e.g. \emph{mountain cloud}.
\item In the regression analyses for their experiments, they used 
the rank of the relation in the constituent family as well as the
number of high-frequency relations in a constituent family as
predictors.
\end{inparaenum}


% families in their corpus. They
% used the constituent families to establish high and low frequently relations for a given


\subsection{Criticism and a corpus-based re-implementation}
\label{sec:relationalFamilies2}

% The way that \citet{GagneandShoben:1997} came to their distribution of
% relations drew
\is{semantic relations!{measuring the distribution}}
\citet[854--855]{StormsandWisniewski:2005} point out 3 areas of
concern with regard to the distributional frequencies established by \citet{GagneandShoben:1997}:
Firstly, the relational frequencies should ideally reflect how often
these relations occur in combinations that people are familiar with
(through reading or hearing). The way in which Gagné and Shoben constructed their corpus does not
guarantee this, as they arbitrarily paired modifiers and heads and did
not take familiarity of the combinations into account. Secondly, \citet{StormsandWisniewski:2005} wonder whether
the restriction to just 91 heads and modifiers actually resulted
in a broad enough sample to accurately reflect the relation
frequencies for the nouns. In particular, they point to their
intuition that specific modifiers have a preference for certain types
of heads and vice versa, which, if true, would require a much larger
sample to accurately reflect distributional differences. Thirdly, they
criticize that the sampling procedure did not take token frequencies
into account, a point first made in \citet{WisniewskiandMurphy:2005},
who in turn also take up the 2 other points. 

\citet{Maguireetal:2007} present a corpus study trying
to test the representativity of the original Gagné and
Shoben corpus. In particular, they tried to derive measures for 38
words, namely the 19
heads and 19 modifiers used in Experiment 1 in
\citet{GagneandShoben:1997}, from the \isi{BNC} (in the process, they
replaced the adjective modifier \emph{musical} by \emph{music} and using
\emph{flower} in addition to the original \emph{floral}). 
% For each of the 38 items
% they randomly sampled 100 noun noun combinations from the BNC,
% replacing. 
For the compound heads,
singulars and plurals where considered, leaving 4 heads with smaller
samples. All in all, they extracted 1,832 compounds sharing the
respective compound modifier constituent and 1,669 compounds sharing
the respective head constituent. These were classified into the 15 relations used in
\citet{GagneandShoben:1997}, with one of the authors each classifying
half of the compounds, using the actual \isi{BNC} context sentence in order
to determine the appropriate relation. Inter-rater agreement was
checked on a
sample of 10 combinations for each noun, with the authors reporting
agreement at the  68\% level.  
% Sampling was done by looking for NN separated by spaces;
% non-legitimate combinations were manually rejected (including verbs
% incorrectly tagged as nouns and N N cooccurences (last \emph{year
% albums} were cheaper))
In coding, noun ambiguities were ignored (that is, usages of
e.g. \emph{plant} as standing either for the organism or for a factory
were not differentiated). \citet[813]{Maguireetal:2007} point out that
in doing so they follow the procedure in the original
paper (as evidenced by e.g. the experimental items). At the same time,
\citet[813]{Maguireetal:2007} note that  according to
the CARIN theory, the different distributions should be calculated individually for each
unique concept associated with a given string, since, according to the theory, the frequencies
of the different relations are stored with the concepts.\is{CARIN model}

Furthermore, the authors observed that in many cases more than one
relation could reasonably be chosen, citing \emph{family activities}
and \emph{storm cloud} as examples, where the former could be
classified with either \textsc{has}, \textsc{located}, \textsc{for},
\textsc{causes} or \textsc{by}, and the latter by either \textsc{causes},
\textsc{located}, \textsc{during}, or \textsc{has}. Nevertheless, only
a single relation was selected even in those cases. While the 2
examples might be extreme cases, note that this problem of multiple
possible relations for one and the same compound is in fact the norm
and not the exception (see also the discussion in Section
\ref{sec:methodsSemCoding}), calling any absolute comparability of
these labels across different modifiers and heads into question.  For
7.5\% of the modifier compounds and 4.3 \% of the head compounds,
thematic relations did not `realistically' fit the combinations (their
examples are \emph{chocolate eater, water supply, family commitments} and
  \emph{music journalist}). It is not clear how these combinations were
treated.

When comparing their data to the data of \citet{GagneandShoben:1997},
\citet{Maguireetal:2007} noted the following differences:
\begin{inparaenum}[(1)]
\item The compound types identified for the
respective heads and modifiers are very different. Only 5\% of the
compound types in Gagné \& Shoben's modifier families and 7\% of the
head families also  occur in the \isi{BNC} sample.
\item Spearman's $\rho$ for the correlation between the relational frequencies of the heads and modifiers
in the 2 datasets was on average 0.64 and 0.63 for the modifiers and
the heads respectively, with 10 of the modifier distributions and 9
of the head distributions significantly correlated at the 0.01
level. 
\end{inparaenum}
\citet{Maguireetal:2007} contrast the correlation between the 2
datasets to the correlation that results when randomly splitting their
\isi{BNC} data in 2 halves. For their split dataset, the
correlation is much better, with 0.83 and 0.88 as average values for
modifiers and heads respectively, and a correlation at the 0.01 level
for 17 of the modifier and 18 of the head
distributions. \citet{SpaldingandGagne:2008} point out that the
sampling procedure used by \citet{Maguireetal:2007} resulted in
non-unique modifier-head combinations, with items like \emph{chocolate biscuit(s)} appearing 12 times, and \emph{chocolate cake} and \emph{chocolate bar} each appearing 8
times. Based on the numbers of unique modifier-head
combinations, that is, compound types, the
sample used by \citet{Maguireetal:2007} is only roughly 20\% larger %bigger
than the original \citet{GagneandShoben:1997}
sample \citep[1576]{SpaldingandGagne:2008}.
\citet{SpaldingandGagne:2008} further point out that if only the
compound types are considered, the artificial corpus used in
\citet{GagneandShoben:1997} yields relational distributions very
similar to those of the random sample from the \isi{BNC} used by
\citet{Maguireetal:2007}. 

Should only compound types be considered? \is{compound!{types vs. tokens}}
% BEGIN Spalding and Gange 2008 page 1577
% Indeed, research on
% compound-word processing sometimes finds that type frequencies
% are more appropriate and might reflect more central semantic
% levels of processing (see, for example, deJong, Schreuder, &
% Baayen, 2000, for discussion of the use of family size vs. family
% frequencies of compounds).
% END Spalding and Gange 2008 page 1577
\citet[1577]{SpaldingandGagne:2008} argue that ``research on
compound-word processing sometimes finds that type frequencies
are more appropriate and might reflect more central semantic
levels of processing" and cite the comparison between family size
vs. family frequencies of compounds in \citet{deJongetal:2000} as
evidence to this effect. 

\citet{Maguireetal:2007} also critically discuss the mathematical
features of the strength ratio, pointing especially to the results of
using negative exponentials. \is{compound measures!{strength ratio}}
Their first point concerns the fact
mentioned earlier that a high strength ratio does
stand for a high degree of competition (hence the renaming of strength
ratio to competition
in \citealt[1574]{SpaldingandGagne:2008}). Their second point is more
interesting: given the way the strength ratio is calculated, the term
standing for the relation with the lowest relation frequency will always have the largest
influence on the strength ratio. To see why this must be so, cf. the
plot in \figref{fig:expenonential}.

\begin{figure}[!htb]
  \centering
% \includegraphics[scale=.75,clip, trim= 0mm 0mm 0mm 0mm]{/home/martin/Dropbox/statistics/habil-stat/negative-exponentials.png} 
% \includegraphics[scale=.65,clip, trim= 0mm 0mm 0mm 0mm]{/home/martin/Dropbox/statistics/habil-stat/negative-exponentials.pdf} 
\includegraphics[scale=.65,clip, trim= 0mm 0mm 0mm 0mm]{./figures/negative-exponentials.pdf} 
  
  \caption{Relational proportion, ranging from 0 to 1, plotted against
  its negative exponentials}
\label{fig:expenonential}
\end{figure}

\enlargethispage{1\baselineskip}
As the plot shows, the result of using negative exponentials of the
relation proportion in effect reverses the values associated with the
different proportions. The lowest relation proportion possible is 0,
the highest 1. The negative exponential, that is, Euler's number to
the power of the negative relations proportion, reverses the situation,
with the highest possible relation proportion resulting in the lowest
possible value, and the lowest proportion in the highest value,
cf. \Next.

\ex. \a.  $e^{-0} = 1$
\b. $e^{-1} = 0.368$
% exp(-1)
% [1] 0.3678794

\citet[1574]{SpaldingandGagne:2008} point out that ``this pattern is actually
a natural consequence of the RT [reaction time] data and of a particular kind of
competition among the relations", and report similar patterns when
modeling the influence of the 3 highest ranked competitors via
individual weights. 

%  (cf. \citet[854-855]{StormsandWisniewski:2005},
% \citet{WisniewskiandMurphy:2005}, \citet{Maguireetal:2007}, and
% \citet{SpaldingandGagne:2008} for a critical discussion of this procedure).
% They
% started with the 91 modifiers and 91 heads taken from the Shoben and Medin corpus
% (they refer to \citet{Shoben:1991}, though there the corpus is described only vaguely), % this paper is not at all clear on what the people did! strange! on page 127 it says they sampled all combinations
% which was created by sampling
% 100 combinations from the appendix of \citet{Levi:1978} and removing
% duplications. For this set, they created all possible permutations (91
% x 91 = 8281). Of these permutations, they determined which were
% sensible, yielding a set of 3239 sensible permutations. These were
% classified into 15 categories, essentially resembling the
% Levi categories, except that both USE and IN (here: located) also
% occurred in two relational versions, e.g. instead of just USE they had
% two relations, one for `noun uses modifier' \emph{gas antiques},
% % antiques relating to gas/gas station memorabilia?   
% one `noun used by modifier' \emph{servant language}
% (these revisions to Levi's categories stem from Shoben and Medin). In
% addition, the category `noun during modifier' was used (for
% e.g. \emph{summer cloud}). As a result, they had available the
% frequency with which relation occurred with either constituent, that
% is, the distribution of semantic relations across constituent
% families in their corpus. They
% used the constituent families to establish high and low frequently relations for a given
% constituent, using an arbitrary 60\% cutoff point. In other words, any
% relation within a constituent family that accounted for 60\% of the
% combinations was considered a high frequency relation for that
% constituent family. If no single relation accounted for 60\%, all
% relations that occurred within the 60\% bracket were taken as high
% frequency relations. This classification was used to construct
% three classes of experimental items: a combination High-High
% frequency, cf. \emph{mountain bird}, a combination Low-High frequency, cf.
% \emph{mountain magazine}, and a combination
% High-Low frequency\ cf. \emph{mountain cloud}. The subsequent regression analyses used
% the rank of the relation in the constituent family as well as the
% number of high-frequency relations in a constituent family as
% predictors.
% Testing the influence of constituent-family based
% relational information with a sense/nonsense judgement, they find 
% % . That is,
% % subjects had to indicate whether a given word pair makes sense, either
% % within a sentence frame (experiment 1), or when presented in isolation
% % (experiment 3). They conclude 
% that the frequency of the modifier's 
% thematic role is a determiner of response time, while the frequency of
% the head's thematic role is not a determiner of response
% time. \citet{GagneandShoben:1997} account for this observed assymetry
% between modifier and head by the
% competition among relations in nominals (CARIN) model, which holds
% that relational information is already stored with the modifiers and claims
% that ``the ease with which the appropriate relation can be found
% depends on both the strength of the to-be-selected relation and on the
% strength of the alternatives'' \citet[81]{GagneandShoben:1997}. In
% their mathematical implementation of the CARIN model, they use a
% strength ratio ranging from 0 to 1 and being derived from the equation
% in \Next, which uses an exponential decay function (in
% \citet{SpaldingandGagne:2008}, this strength ratio is renamed `competition').

% \ex. \label{ex:strength-ratio}
% strength = 
% $\frac{e^{-ap_{selected}}}{e^{-ap_{selected}} +
% e^{-ap_{1}} +e^{-ap_{2}} +e^{-ap_{2}}}$
% % \\ 
% % $p_1$ proportion of most freqent relation (for a specific item) in corpus\\
% % e exponential decay function [etwas irreführend, vielleicht Abnahme der Stärke
% % via eulersche Zahl genug]\\
% % a constant

% In this equation, \emph{a} is a free parameter, and
% $p_{\mathrm{relation}}$ stands for the proportion of a specific
% relation for a specific item in the corpus, with $p_1$ standing for
% the proportion of most freqent relation, and $p_2$ and $p_3$ standing
% for the second and third most frequent relation. 

% \citet{Gagne:2001}, sampling from the combinations created for
% \citet{GagneandShoben:1997}, combined the sense/nonsense task with
% priming, 
% % That is, subjects first performed a sense/nonsense judgment on
% % a noun noun combination serving as the prime, and then on the target
% % combination. She found 
% finding relational priming when prime and target shared
% the same modifier.
% % , contrasting two conditions, same and different
% % semantic relations (e.g., the target combination \emph{oil
% %   treatment} was preceded either by \emph{oil moisturizer} or
% % \emph{oil accident}). 
% \citet{Gagne:2002}, using the same sampling
% procedure, shows that relational priming can be obtained for
% semantically similar modifiers.
% %  (e.g., the target
% % combination \emph{student vote} was preceded either by \emph{scholar
% %   accusation} or \emph{scholar car}). 
% \citet{Estes:2003} and
% \citet{EstesandJones:2006} likewise
% report relational priming in the absence of shared constituents. 
% \citet{Jonesetal:2008} showed
% that the same relation facilitated later recognition of the
% modifier. For Indonesian, where the order is head-modifier, \citet{StormsandWisniewski:2005} replicated the finding from
% \citet{GagneandShoben:1997} that the modifiers relational frequency is
% a significant predictor of response time in sensibility judgement for
% Indonesian. 
% % They used a different procedure in selecting the
% % material, trying to address concerns voiced in
% % \citet{WisniewskiandMurphy:2005} concerning a possible confound of
% % familiarity and plausibility of the combinations in the material used
% % in \citet{GagneandShoben:1997} (for this point, cf. \citet{GagneandSpalding:2006}). 

% Finally, \citet{Spaldingetal:2010} is of particular interest, as they address
% in detail the question of the role of the head noun, and also
% re-model some of the data from the experiments presented in
% \citet{GagneandShoben:1997}. Using a verification task, they found
% relational priming for the head.
% % Their experiment 1 uses the
% % sense/nonsense task on primes and targets, replicating the effect of
% % relational priming when the modifier is repeated
% % (cf. \citet{Gagne:2001} discussed above)
% % % (p. 288 AS SHOWN BYGagne 2001,2002 and Maguire and Cater 2004). 
% % Experiment 2 introduces a relation verification task where both prime as well as target were
% % embedded in a verification frame of the general form XY = Y RELATION
% % X, e.g. \emph{knitting blog} = \emph{blog about knitting}, and the task of the subjects was to
% % judge the acceptability of the interpretation suggested by the
% % verification frame. Here, they found a very robust relational priming
% % effect when the head was repeated. Experiment 3 used the same
% % procedure as experiment 2, but the prime items were not presented in
% % the verification frame but embedded in
% % sentences consistent with only one analysis (e.g., \emph{Will's family
% %   garden doesn't have any carrots growing this year}). The robust
% % relational priming effect for the head was replicated. Thus, whether
% % or not there is a relational priming effect for the head seems to be
% % task dependent.
% \citet[286-287]{Spaldingetal:2010} argue that
% the design of the experiments reported in \citet{GagneandShoben:1997}
% is prone to hide any relational effects due to the head. Thus, the
% modifiers typically suggest multiple relations, but the the head's
% relational frequency was determined independent of any specific
% interpretation, being based on the frequencies of the relations in the
% constituent family. In contrast, they argue that in the verification
% task, the ``effect of the modifier should be decreased relative to the
% sense/nonsense task, as it is not required to suggest a set of
% relations. In contrast, the head should be highly involved in
% determining whether the suggested relation is acceptable, and because
% no other relations have been suggested, relational effects associated
% with the head should be evident'' \citet[288]{Spaldingetal:2010}. 
% In
% their final experiment 4, they use the material and design from experiment 3 from
% They also use the relation verification task to re-run one of the
% experiments reported in \citet{GagneandShoben:1997}, 
% % but again use the relation verification
% % task (only this time without any priming, as the original task also
% % did not involve priming). 
% % They 
% this time finding effects due to the relational
% structure of the head as well as due to the relational structure of
% the modifier. 
% % And while the effects found in the priming task might be
% % due to short term effects, the effects in this task are long-term
% % effects, because no priming takes place. 
% Intriguingly, the modifier
% effect is different in nature from the effect found in the
% sense/nonsense task in \citet{GagneandShoben:1997}, which they explain
% again via the nature of the task involved. The model they propose, the
% relatianal interpretation competitive evalation (RICE) theory of
% conceptual combination, assume a suggest-evaluate framework: First, a
% number of different relations is suggested by the modifier. Secondly,
% these relations are evaluated by the head. Finally, the specific
% nature of the relations needs to be elaborated with the help of
% pragmatics and world knowledge. While the material in the papers mentioned so far mainly concerned
% novel combinations, relational effects have also been found in
% established combinations, cf. \citet{GagneandSpalding:2004},
% \citet{GagneandSpalding:2009} and \citet{SpaldingandGagne:2011}. 


% % The only attempt at a mathematical implementation of a
% % theory of conceptual combination has been the strength ratio or
% % competition index developed within the CARIN framework, cf. the
% % equation \ref{ex:strength-ratio}. Because the equation needs frequency
% % data for the number of different relations occurring for a given
% % consituent family, the way that this data was arrived at by
% % \citet{GagneandShoben:1997} has been discussed in some
% % detail. 




% Note that not all work within the framework of conceptual combination
% assumes that the
% relations are always part of either the modifier or head concept, 
% \citet{Estes:2003}
%  and \citet{EstesandJones:2006} argue that relations are representational units  independent of specific concepts
% (cf. also \citet{SpaldingandGagne:2011} for discussion). Regardless of the question whether relations are representational
% units of their own or not, the research discussed above suggests that
% specific relations are tied to specific compound constituent. If
% \citet{BellandSchaefer:2013} are right in assuming that the semantic
% relations play a role in compound transparency, testing the effect of a measure that
% captures constituent-specific relational preferences on semantic
% transparency seems like a worthwhile enterprise. Note, though, that it could even be the case that both a
% constituent-sensitive measure for semantic relations as well as the
% frequency of a relations across all compounds could play a role, e.g.,
% due to analogy. 


\subsection{Relational distributions in other studies}
\label{sec:relations-other-studies}

\citet{PhamandBaayen:2013} also use a
database of semantic relations and 3 measures derived from this database. I discussed their
approach in detail in Chapter
\ref{cha:modPrevious}, Section \ref{sec:phambaayen2013}. In contrast
to the previous 2 approaches, the main differences in establishing the
relational distributions are:
\begin{inparaenum}[(1)]
\item they started with a much larger initial set of compounds (783 compounds).
\item they drew the compound families from the \isi{CELEX}
  database, which contains only compounds drawn from dictionaries and
  is relatively small (see Section \ref{sec:celex} below for
  additional discussion), resulting in
  3,455 compounds.
\end{inparaenum}
% The \isi{CELEX} database is rel on a 17.9 million word version of the COBUILD
% corpus and thus a relatively small corpus. The morphological dictionary distinguishes 52447 wordtypes. In
% turn, this dictionary contains 12130 items marked as compounds. 
Using the \isi{CELEX} database, \citet{PhamandBaayen:2013} calculated 3
measures based on the CARIN model of \citet{GagneandShoben:1997}: the strength measure C, the generalized
strength measure gC, and the relative entropy measure reC. \is{compound measures!{strength measure C}}
\is{compound measures!{generalized strength measure gC}}
\is{compound measures!{relative entropy measure reC}}
Their strength measure C is based on \citeauthor{GagneandShoben:1997}'s strength ratio, but
differs in (1) not being restricted to just 3 relations and (2) using
proportions (instead of the exponential decay function).  The
generalized strength measure is based on the relational proportions
across the full database (note that this measure is therefore a departure from the constituent-centred view of the
CARIN model), and the relative entropy measure posits the
probability of a relation in its modifier family against its
probability across all modifier families (for the exact definitions of
these measures, see the discussion in Chapter
\ref{cha:modPrevious}, Section \ref{sec:phambaayen2013}).

\subsection[Conclusion: relations relative to families]{Conclusion: semantic relations relative to constituent families}

In exploring measures of semantic
relations relative to constituent families, I discussed the original approach by
\citet{GagneandShoben:1997}, in which they constructed an artificial
corpus and proposed the strength ratio to best capture the role the
relational distributions relative to a given
compound. \citet{Maguireetal:2007} compare the result of sampling from
the \isi{BNC} with the distributions in the artificial
corpus. Importantly, if one only considers compound types, the 2 
corpora are very comparable. 
\citet{PhamandBaayen:2013} show yet another
way of constructing a relational database, starting with a random
compound sample and then using the \isi{CELEX} database. In contrast to the
\isi{BNC}, the \isi{CELEX} database is very small and all lemmata are derived from
dictionaries, that is, lexicalized in the very sense of the word. \is{CELEX!{and lexicalized compounds}}\is{lexicalized compounds}
% However, among the
% three approaches, this one is bound to be most heavily influenced by
% lexicalized compounds, given that \isi{CELEX} is a database drawn
% dictionaries. 

For the specific task set in this chapter, that is, establishing
constituent families for a given set of compounds, the procedure
chosen by \citet{GagneandShoben:1997} does not seem very promising for
the simple reason that the starting point for an artificially
constructed dataset, the Reddy et al. dataset, was not designed to
reflect a variety of semantic relations. In contrast, this was the
main concern of the appendix
in \citet{Levi:1978}. In addition, it seems plausible that the second
selection step, judging all the combination for whether or not they
make sense, is by itself heavily influenced by the frequencies of
occurrence of the corresponding constituents and their preferred
combinations.  And finally, data from an actual corpus makes it
possible to explore a fuller range of factors, for example the
above-mentioned issue of type- vs. token-based measures for compounds.

When it comes to a decision between the \isi{BNC} and \isi{CELEX}, using the \isi{BNC}
has the advantage of not being restricted to lexicalized
compounds. \is{lexicalized compounds}
In addition, the \isi{CELEX} database does not contain
frequencies for compounds that are not written as one word. 
The construction
of the database
to be introduced below therefore will start from compound families
drawn from the \isi{BNC} (although \isi{CELEX} data will also be used).

There are several proposals for measures
assessing the role of the
relational distribution for a particular compound. Once a
 database is available, these different measures can be compared and which measure works best in predicting compound
 transparency is an empirical question. 
\is{semantic relations!{measuring the distribution}|)}
\is{frequency!{distribution of semantic relations}|)}
\is{compound!{constituent family}!{assessing distribution of semantic relations}|)}

\section{Assessing the role of constituent meanings}
\label{sec:meaningShiftsInFamilies}

After concluding that the coding of the constituents and the whole
compounds for meaning shifts as done in
\citet{BellandSchaefer:2013} is problematic for a number of reasons (cf. the
discussion in Chapter \ref{cha:empirical-1}, Section \ref{sec:bell&schaefer2013_shifts}), an
alternative to assess the role of meaning shifts for
semantic transparency is needed. Here, an approach that closely
mirrors the procedure for semantic relations is chosen. Recall that
in order to be able to assess, for the individual constituents of a
compound, how closely these constituents are associated with a
specific relation, the distribution of relations in the individual constituent
families is used. Transferring this idea to constituent senses, the distribution of different constituent senses across the
constituent families can be used. This allows one to determine, for the specific
constituent meaning used in a compound, how expected that meaning is
in the given construction. This seems to me to be a very adequate way
to encode uses of compound constituents that do not seem to be
transparent. In this context, recall an important point from 
\citeauthor{Jaszczolt:2016} (discussed in more detail in Chapter
\ref{cha:theo}, Section \ref{sec:literality}): Nothing is ever
interpreted in isolation; rather, ``[t]he plausibility and the
intuitions all depend on the accessibility of a default, `made-up'
context" \citet[58]{Jaszczolt:2016} (cf. the previous discussion for
the quote in context). While she makes this point for sentences, it
plausibly applies in a 
similar way to lower level construction such as, in this case,
compounds. And arguably, for compound constituents, the constituent's
compound families are the next place to look if one wants to emulate
what language users will take to be a default context to be used as a
guide in interpretation.

How, then, should one determine the distribution of constituent
meanings in a compound family? One straightforward idea is to exploit
the meaning differentiations made in
existing lexical databases for this purpose. \is{compound!{constituent meanings}!{distribution of}}
Here, the \isi{WordNet} lexical
database \citep{Fellbaum:1998} is chosen, and I will introduce this resource in detail in
Section \ref{sec:wordnet}.

An open question is what to use instead of manually coded meaning
shifts of the whole compound. 
Recall that \citet{BellandSchaefer:2013}
also used spelling ratio, that is, the ratio of unspaced and hyphenated
occurrences to spaced occurrences, which has been hypothesized to be a
correlate of lexicalization (cf. \citealt[496]{BellandPlag:2012}). 
% For want of an alternative, 
This variable will also be used here, on the assumption that it is
positively correlated with whole compound meaning shifts (but compare the discussion of spelling ratio in Chapter \ref{cha:empirical-1}, Section \ref{sec:results-of-mixed-effect-models}). \is{meaning shifts!{spelling ratio and}}\is{compound measures!{spelling ratio}!{meaning shifts and}}

% (note that \citet[495-496]{BellandPlag:2012} also hypothesizes that,
% besides spelling ratio, listedness and compound frequency are
% correlates of lexicalization). 
% \textbf{TODO SHOULD I COME BACK TO THIS  POINT? CHECK FOR AB Metaphor/correlation?} 

\subsection*{WordNet and WordNet definitions}
\label{sec:wordnet}

\is{WordNet!{general organization}|(}
Data from WordNet already played a considerable role in the selection
of the original items in the Reddy et
al. study (cf. the discussion in Chapter \ref{cha:modPrevious},
Section \ref{sec:Reddy-selection}). Since it also forms the basis for
coding the constituent meanings, this section introduces WordNet's general
organization. Essentially, WordNet is a lexical database for
English. Some of its distinguishing features can be seen when looking
at an exemplary entry, cf. the entry for \emph{rock} reproduced in \Next. 

\ex. WordNet entry for \emph{rock}
\a. Noun
\a. \label{ex:rock-stone}
S: (n) rock, stone (a lump or mass of hard consolidated mineral matter) ``he threw a rock at me"
\b. \label{ex:rock-material}
S: (n) rock, stone (material consisting of the aggregate of minerals like those making up the Earth's crust) ``that mountain is solid rock"; ``stone is abundant in New England and there are many quarries"   
\c. S: (n) Rock, John Rock (United States gynecologist and devout Catholic who conducted the first clinical trials of the oral contraceptive pill (1890-1984))
\d. \label{ex:rock-person}
S: (n) rock ((figurative) someone who is strong and stable and dependable) ``he was her rock during the crisis"; ``Thou art Peter, and upon this rock I will build my church"--Gospel According to Matthew
   \d. \label{ex:rock-candy}
S: (n) rock candy, rock (hard bright-colored stick candy (typically flavored with peppermint))
    \d. \label{ex:rock-music}
S: (n) rock 'n' roll, rock'n'roll, rock-and-roll, rock and roll, rock, rock music (a genre of popular music originating in the 1950s; a blend of black rhythm-and-blues with white country-and-west\-ern) ``rock is a generic term for the range of styles that evolved out of rock'n'roll."
    \d.S: (n) rock, careen, sway, tilt (pitching dangerously to one side)
\z.
\b. Verb
\a. S: (v) rock, sway, shake (move back and forth or sideways) ``the ship was rocking"; ``the tall building swayed"; ``She rocked back and forth on her feet"
\b. S: (v) rock, sway (cause to move back and forth) ``rock the cradle"; ``rock the baby"; ``the wind swayed the trees gently''
\z. Results of searching for \emph{rock} on WordNet (WordNet Search 3.1, accessed 27.12.2014, \url{http://wordnetweb.princeton.edu/perl/webwn})

The WordNet entry for \emph{rock} is divided into 9 sub-entries, which
are classified as either nouns or verbs. Each sub-entry constitutes a
synset, a set of synonyms. These synonyms are interchangeable in some
contexts (cf. \citealt[24]{Miller:1998}). As \citealt[24]{Miller:1998}
points out, ``[i]t is convenient to think of a synset as representing
a lexicalized concept of English.'' The resulting synsets
might be connected by meaning shifts, and are thus etymologically related, cf. the synsets
\ref{ex:rock-stone}, \ref{ex:rock-material} and \ref{ex:rock-person},
or they might be unrelated, as the stone-sense underlying the 3
synsets just mentioned and the music-sense of \emph{rock} in
\ref{ex:rock-music}. Unsurprisingly, these cases are typically
etymologically unrelated, in this case with the stone-sense being
derived from a Romance noun and the music-sense being derived from a
Germanic verb. WordNet incorporates a number of various
sources, including large amounts of manual annotation, but also the results of automatic tagging based on a earlier
versions of WordNet (cf. \citealt[xviii-xxi]{Miller:1998a}). Note in
particular that the explanatory glosses and the illustrative
quotations were added manually, and that the unsystematic coverage of
proper nouns in the set of synsets is due to the nature of the sources
used in building WordNet. As Miller puts it: ``No special attempt has
been made to include proper nouns; on the other hand, since many
common nouns once were names, no serious attempt has been made to
exclude them.''  \citet[23]{Miller:1998}. While the basic unit for
WordNet are words, \citet[5--6]{Fellbaum:1998} points out that WordNet also
contains short phrases (her example is \emph{bad person}) if these
cannot be paraphrased by a single word. Technically, these short
phrases seem to be non-distinct from compounds written as two
words. All synsets are categorized as either nouns, adjectives, verbs
or adverbs, and relations between synsets are always within their
categorical boundaries (cf. \citealt[5]{Fellbaum:1998}).
\is{WordNet!{general organization}|)}

\section{A database of compound families}
\label{sec:methods1}

In this section, I describe the way in which Melanie Bell and I
selected the items for the compound database used in
\citet{BellandSchaefer:2016}. 
% Second, I describe how I coded the
% compounds for semantic relations and constituent meanings.
% \subsection{Selection of constituent families}
% \label{sec:methodsSample}
The selection of constituent families involved 4 steps:
\begin{inparaenum}[(1)]
\item Using the \isi{BNC} to establish an initial set of families.
\item Adding items from \isi{CELEX}.
\item Getting frequencies from USENET.
 % and determining a low-frequency cut-off point
 %  using 
\item Further post-processing.
\end{inparaenum}
I will describe and explain the rationale of the 4 steps in the
following 4 sections.
% , closing this section with a few remarks on
% further postprocessing of the data.

\subsection{Initial families from the BNC}
\label{sec:initial}

We used the \nocite{BNCxml} BNC XML edition to select all noun noun compounds
from the \isi{BNC}. \is{BNC!{characterization of}}
The \isi{BNC}, the British national corpus, is a 100 million
word corpus, sampling written (90\% of
the total corpus) as well as spoken texts (10\% of
the total corpus). The spoken part comes from transcriptions of
informal conversations and more contextualized spoken language (e.g.
government meetings) dating from 1991 to 1994, that is, the time the corpus was built. The written part is mainly (92\%) drawn from
publications from 1985 to 1993, with the earliest publications dating from the 1960s. We accessed the \isi{BNC} via the web interface provided by
Lancaster University: the CQP-edition (Version 4.3) of BNCweb
developed by Sebastian Hoffmann and Stefan Evert
(cf. \citealt{Hoffmannetal:2008}; BNCweb is accessible via
\url{http://bncweb.lancs.ac.uk/}). We used the CQP
query syntax to extract all strings of 2 nouns from the \isi{BNC}, both
the written and the spoken part. In order to minimalize manual
corrections, the search was restricted to strings following the definite
article, and excluded all strings that were themselves followed by a
noun, an adjective, or a possessive marker. Since we also used the
spoken part of the \isi{BNC}, any strings containing pauses or interruptions or other additional
material, be it linguistic or non-linguistic, were excluded. The exact query is
reproduced in \Next.
\ex. 
 \url{([type="w"&word="the"][type="w"&pos="N.*"&}\\\url{flags_before not contains"pause.*|vocal.*|event.*|shift.*|}\\\url{trunk.*|unclear.*"][type="w"&pos="N.*"&}\\\url{flags_before not contains"pause.*|vocal.*|event.*|shift.*|}\\\url{trunk.*|unclear.*"][:pos!="N.*|AJ.*|POS":])within s}

% OK: this works on lancaster bnc-web interface, using CQP syntax switch
% What does it mean: 
% 1. we search for strings within a sentence
% 2. strings are of type "the'' + any noun + any noun, not followed by a noun, and not followed by anything that is any noun, adjective, or possessive marker
% 3. in addition, the flags before could not contain: (the flags are only relevant for the spoken part)
% pause. a pause either between or within utterances.
% vocal. (Vocalized semi-lexical) any vocalized but not necessarily lexical phenomenon, for example voiced pauses, non-lexical backchannels, etc.
% event.  used in spoken texts for non-linguistic but significant event (e.g. ringing phone)
% shift. marks the point at which some paralinguistic feature of a series of utterances by any one speaker changes.
% trunk. contains one or more truncated words in transcribed speech.
% unclear. contains a word, phrase, or passage which cannot be transcribed with certainty because it is illegible or inaudible in the source.
%
We then used the constituents from the 90 compounds in the Reddy et al. dataset to extract
those noun noun sequences from the \isi{BNC} dataset that shared a constituent with any of those items. In
doing so, we matched all items lemma-based, that is, regardless of whether they occurred in
their singular or plural form. We decided to be as inclusive as
possible with regard to regular spelling variants, searching for items
regardless of whether they occurred with British or
American spelling (for the 90 compounds from the Reddy et al. dataset,
this concerns only the variation between \emph{centre} and \emph{center}). 
We created 2 sets of compound families: positional constituent families,
that is, constituent families in which the constituent occurs in the
same position as its position in the dataset, and reverse constituent
families, that is, families where the constituent occurred in the
opposite position. While the reverse families did not play a role in
the creation of the semantically annotated database, they are needed
for the calculation of the family size ratios, cf. the description and
further explanation in
section \ref{sec:methodsFurtherExplanatory}.

Note that at no point did we make any efforts to exclude proper
nouns. Their inclusion is warranted for at least 3 reasons:
\begin{inparaenum}[(1)]
\item As far as we know, proper nouns are processed in the same way as
  other nouns
\item English does not have a clear formal distinction between nouns
  that are proper
  names and those that are not; in fact, conversions
  from and to proper names lead to the existence of 
  doublettes (cf. \citealt[516]{HuddlestonandPullum:2002})
\item The well-known variation in compound realizations between left
  and right-stress is among other things influenced by the proper
  name/proper noun status of the elements involved. \citet[779]{Plagetal:2008} find both N1 and N2
  forming a proper noun as well as N1 itself being a proper noun to be
  significant predictors of rightward stress in English noun noun compounds.
\end{inparaenum}

 
\subsection{Adding items from CELEX}
\label{sec:celex}
\is{CELEX|(}
The search pattern described above is not able to find noun noun
compounds that are written as one word, be it with or without
hyphens. In general, it is not possible to search for these items in
the \isi{BNC} when using the tagging provided by the \isi{BNC}, since it does not
include compounds as a dedicated category. In order to also include
those compounds that are always written as one word, we used \isi{CELEX},
the database from the Dutch Centre for Lexical Information, cf. \citet{Baayenetal:1995}. 
\is{CELEX!{characterization of}}
The English part of the \isi{CELEX}
database is compiled from two dictionaries, the 1974 edition of the
Oxford Advanced Learner's Dictionary (41,000 lemmata) and the 1978
edition of the Longman Dictionary of Contemporary English (53,000
lemmata, with an overlap of approximately 30,000 lemmata with the other
dictionary). Due to its origin, \isi{CELEX} only contains lexicalized
compounds (note that even though \isi{CELEX} derives frequency information from
the 17.9 million token COBUILD/Birmingham corpus, this corpus was not
used to add new lemmata).
% This info comes from the CELEX readme file
The English morphological
database distinguishes 52,447 word types.  All in all, \isi{CELEX}'s morphological database contains 12,130 items marked as compounds. From
these, all concatenated noun noun compounds sharing either the first
or the second constituent with a compound from the Reddy et al. dataset were added to the
respective constituent families (that is, to both the positional and
the reverse families).

% , and added all compounds that shared any
% constituent with the Reddy et al. set to both the reverse and
% positional constituent families.
\is{CELEX|)}
\subsection{Usenet frequencies}
\label{sec:freqUsenet}
\is{USENET|(}
Compounds have a comparatively low textual frequency
(cf. \citealt[776]{Plagetal:2008}). For English noun noun compounds, \citet{Baldwin_and_Tanaka:2004}
report that between 2.6\% (spoken part of the BNC) and 3.9\% (Reuters
corpus) of
the respective corpus' tokens occur as part of a noun noun compound.
% Plag et al. 2008: 776
% ``The problem with frequency is that compounds in general are
% comparatively rare." Plag et al. 2008:776
Using a small corpus like the \isi{BNC} to retrieve compound frequencies
means that there is only limited insight into the distribution of
low-frequency compounds. There are very many compounds that
occur only once in the \isi{BNC} (in the study by
\citealt{LapataandLascarides:2003}, 70\% of the candidate set of noun noun
compounds drawn from the \isi{BNC} are hapaxes, 60\% of which are valid compounds), but within this group no further frequency
distinction is possible. In order to get better insight into these
lower frequency realms, we decided to use a much larger corpus as an
additional filter, settling on the reduced redundancy USENET corpus
(\citealt{ShaoulandWestbury:2013}). This corpus contains over 7
billion tokens. The corpus is a collection of public USENET postings
collected between October 2005 and January 2011. The reduced
redundancy version of the USENET corpus is the result of applying
algorithms for the removal of text redundancy to the original
collection of postings, shrinking the corpus to just over 7 billion tokens
from originally 30 billion tokens. However, the shrunk corpus is still 700 times
bigger than the \isi{BNC}.\is{USENET!{characterization of}}
Using this corpus has 2 side effects: (1) any highly
context-bound ad-hoc formations are likely to be removed (2) the level
of noise in the data might get slightly reduced, since noun noun
combinations found in the \isi{BNC} that are not compounds but are adjacent
nonetheless might not occur adjacent in the USENET corpus.

The USENET corpus is not lemmatized. In order to get lemma
frequencies, we searched for all inflectional variants of the
compounds in question, as well as all spelling variants (spaced,
hyphenated, and unspaced in British and American English). This was
done via an R-script written by me. For the pluralization and
singularization of words, I relied
heavily on \citet{Conway}. We obtained frequencies for all the
word forms from USENET. The actual extraction of these frequencies was kindly done for us by Cyrus Shaoul and Gero Kunter.
% using Python scripts. 
We summed
over these word form frequencies to get the lemma frequencies. 
\is{USENET|)}



% Despite the care taken with the corpus search, the resulting set of noun–noun strings included many that were not in fact compounds. In an attempt to reduce this noise in our data, as well as to keep the dataset to a manageable size, we decided to exclude types with very low frequencies. However, because of the low textual frequencies of compounds in general (Plag et al. 2008: 776), a comparatively small corpus like the BNC contains a very large number of compounds that occur only once, and it is difficult to distinguish between those with relatively high and low frequencies. In order to address these points, we decided to get frequencies for the compounds in our constituent families from a much larger corpus, and for this we used the reduced redundancy USENET corpus (Shaoul and Westbury 2013), containing over 7 billion tokens. Because this corpus is not lemmatized, we searched for all inflectional variants of the compounds in question, as well as all spelling variants (spaced, hyphenated and unspaced in British and American English), and summed these frequencies to get the lemma frequencies. We then restricted our constituent families to only those items that occurred with a lemma frequency of at least 5. This left a total of 2893 compound lemmas in the N1 positional constituent families and 6425 compound lemmas in the N2 positional constituent families.

\subsection{Further post-processing}
\label{sec:postData}

Recall that we added items from \isi{CELEX} because we could not search in
the \isi{BNC} for compounds written as one word. This, in turn, means that
we also could not exclude the possibility that the items that were selected from the
BNC included constituents that were themselves compounds written as
one word. Because it is unclear
in how far these 3 or 4 constituent compounds behave
similarly to 2 constituent compounds, and because the current dataset
can only contain those complex compounds as constituents that were
written as one word, we decided to eliminate the 3 and more constituent
compounds altogether. To achieve this, we proceeded as follows:
\begin{inparaenum}[(1)]
\item We filtered our search results
against all English compounds and simplex words in the English part of
the \isi{CELEX}.
\item All compounds that consisted only of simplex words were left in
  the dataset, but all compounds with one or more constituents that were itself compounds
  were excluded.
\item Compounds with constituents not occurring in \isi{CELEX} were checked
manually, at which point we also excluded compounds in which either
constituent consisted of an abbreviation. 
\end{inparaenum}

We then restricted our constituent families to only those items that
occurred with a lemma frequency of at least 5. We selected this
cut-off point for 2 reasons:
\begin{inparaenum}[(1)]
\item to reduce the amount of noise,
mishits, and ad-hoc formations and 
\item to keep the data to be coded within
manageable limits.
\end{inparaenum}
This left a total of 2,893 compound lemmas in the
N1 positional constituent families and 6,425 compound lemmas in the N2
positional constituent families. 


%% Start Bell Schäfer 2016 175
% In order to calculate the expectedness of particular word senses and semantic relations for our compounds, we first needed to access their constituent families. For this, we used the British National Corpus (BNC XML Edition 2007). The BNC is a 100 million-word corpus containing 90% written and 10% spoken data, representing a cross-section of British English from the late 20th century. We accessed the BNC via the web-interface provided by Lancaster University: the CQP-edition (Version 4.3) of BNCweb7 developed by Sebastian Hoffmann and Stefan Evert (cf. Hoffmann et al. 2008). We used the CQP query syntax to extract all strings of two nouns that followed a definite article and were not themselves followed by another noun, an adjective, or a possessive marker. In this way, we excluded noun–noun strings that were part of larger complex nominal constructions. We used both the spoken and written parts of the BNC, but excluded any strings from the spoken part that contained pauses, unclear portions or other paralinguistic events. From the resulting set of NN strings, we selected those that shared a constituent lemma with a compound in our dataset. In doing this, we took into account both the position of the constituent in the original item, and whether it occurred in the same position in the family member. In this way, we produced a positional constituent family and a reverse constituent family for both constituents of every item in the dataset. Note that we did not make any attempt to exclude proper names. First of all, we do not assume that proper names are processed by humans in a principally different way from common nouns. Secondly, there is no clear formal distinction between proper names and their complement in English, and in fact many doublets exist due to conversion in either direction (Huddleston et al. 2002: 516). Thirdly, and most importantly, it is well known that proper names interact in notable compound patterns, e.g. the classic stress contrast observed for NN combinations headed by either avenue or street, where the relevant constituent families include a considerable number of proper names (Plag et al. 2008).

%% END Bell Schäfer 2016 175

% It is not possible to search the BNC for NN combinations written as one word, since these items are tagged as single nouns. This had two significant implications for the creation of our dataset. Firstly, NN strings extracted as described in the preceding paragraph might actually turn out to have more than two nominal constituents, if at least one of the nouns in the string was itself an unspaced compound. Secondly, our search algorithm would not detect compounds that occur only unspaced in the BNC. To address the first of these issues, we filtered our search results against all English compounds and simplex words in the English part of the CELEX lexical database (Baayen et al. 1995). We left in our dataset all compounds that consisted only of simplex words, but excluded those with one or more compound constituents. Compounds with constituents not occurring in CELEX were checked manually, at which point we also excluded compounds in which either constituent consisted of an abbreviation. To address the second issue, we added to our constituent families all the unspaced compounds in CELEX that shared a constituent with any of the 81 compounds in our core data.

% Despite the care taken with the corpus search, the resulting set of noun–noun strings included many that were not in fact compounds. In an attempt to reduce this noise in our data, as well as to keep the dataset to a manageable size, we decided to exclude types with very low frequencies. However, because of the low textual frequencies of compounds in general (Plag et al. 2008: 776), a comparatively small corpus like the BNC contains a very large number of compounds that occur only once, and it is difficult to distinguish between those with relatively high and low frequencies. In order to address these points, we decided to get frequencies for the compounds in our constituent families from a much larger corpus, and for this we used the reduced redundancy USENET corpus (Shaoul and Westbury 2013), containing over 7 billion tokens. Because this corpus is not lemmatized, we searched for all inflectional variants of the compounds in question, as well as all spelling variants (spaced, hyphenated and unspaced in British and American English), and summed these frequencies to get the lemma frequencies. We then restricted our constituent families to only those items that occurred with a lemma frequency of at least 5. This left a total of 2893 compound lemmas in the N1 positional constituent families and 6425 compound lemmas in the N2 positional constituent families.
%%%%%%%55
%%
%%
%% END Bell Schäfer 2016 176
%%
%%
%%%%%%%%%
\section{Semantic coding}
\label{sec:methodsSemCoding}

The semantic coding for the constituent families involved 2 steps: assigning a \isi{WordNet} synset to
the usage of the constituent in the respective families, and assigning
a relation to the compound under consideration. In contrast to the
coding in \citet{BellandSchaefer:2013}, only a single rater, me,
annotated the data. The main reason why we opted for a
single-rater based procedure is that inter-annotator agreement for
coding compound relations is usually quite poor. Recall that
\citet{Maguireetal:2007} reported an inter-rater agreement of 68\% for
the test items in their study. Similarly, \citet[44--45]{Oseaghdha:2008}, who
worked out a very carefully worded annotation guideline based on an extension of the Levi-system, reports 66.2\% agreement on a 500 item test set between
himself and a second annotator experienced in lexicography who had
been trained on two 100-compound batches previously. In case of
disagreement, the corresponding items can either be discarded, or the
disagreement can be resolved. Neither of these 2 options seemed
desirable to us. The first option might lead to loss of predictive
power due to loss of data as well as to a bias towards the more
clear examples. The second option brings with it the danger of leading
to an overall inconsistency  in the annotations, depending on which
annotation wins in the respective cases.

This section describes the coding of the semantic relations and the
synsets. Appendix B  %\ref{sec:appendix_semantic-coding-2016} 
contains a detailed  overview of the coding results, especially focusing
on the synset coding, but also containing notes on the relation coding.

\subsection{Coding the semantic relations}
\label{sec:coding-the-relations}

In coding the semantic relations within a constituent family, I
used the Levi classification system. In addition to Levi’s (1978)
categories, I used the relation VERB for deverbal heads with an
argument in N1 position, and the category IDIOM for cases that did not
fit any of the other relations. \is{semantic relations!{set used in Bell \& Schäfer (2016)}}
Coding examples from our positional families are shown in table \Next.

\begin{table}[htb]
  \begin{tabularx}{0.8\textwidth}{lll}\lsptoprule
&relation&examples \\\midrule  
1&\textsc{cause1}&\emph{cost centre}, \emph{result centre},
\emph{collision course} \\  
2&\textsc{cause2}&\emph{guilt feeling}, \emph{night blindness}, \emph{snake bite}\\  
3&\textsc{have1}&\emph{ruby ring}, \emph{coal mine}, \emph{metal site}\\  
4&\textsc{have2}&\emph{factory wall}, \emph{death rate}, \emph{staff reaction}\\  
5&\textsc{make1}&\emph{cash cow}, \emph{engine plant}, \emph{law maker}\\  
6&\textsc{make2}&\emph{copper plate}, \emph{plastic clock},
\emph{concrete floor}\\  
7&\textsc{use}&\emph{video game}, \emph{number lock}, \emph{radio conference}\\  
8&\textsc{be}&\emph{head man}, \emph{gold grain}, \emph{acid solution}\\  
9&\textsc{in}&\emph{rock fissure}, \emph{night class}, \emph{bank teller}\\  
10&\textsc{for}&\emph{swimming club}, \emph{rock station},
\emph{fashion model}\\  
11&\textsc{from}&\emph{ground missile}, \emph{interest charge},
\emph{health advantage}\\  
12&\textsc{about}&\emph{fashion magazine}, \emph{bank dispute},
\emph{case study}\\  
13&\textsc{verb}&\emph{credit granter}, \emph{speed increase},
\emph{video edit}\\  
14&\textsc{idiom} &\emph{monkey wrench}, \emph{eye tooth}, \emph{swann
inn}\\  \lspbottomrule
  \end{tabularx}
  \caption{Examples of the coding of the semantic relations in the annotated dataset}
  \label{tab:bs2016_relation-coding}
\end{table}
 % [1] BE     USE    ABOUT  CAUSE2 FOR    HAVE1  HAVE2  <NA>   IN     FROM  
% [11] MAKE2  VERB   IDIOM  MAKE1  NONE   MAKE  
 
% Note: cause 1 only in N2, only a few.
%
The main idea behind the current approach is to investigate whether
preferences of an individual constituent for a specific semantic
relation 
% as expressed via the distribution of relations in that
% constituent's compound family 
play a role for the perception of
semantic transparency. Therefore, all the semantic annotation was strictly compound family
based. That is, all the compounds in the compound database were
annotated twice, once in the N1 compound family, and once in the N2
compound family.  In some cases, this resulted in different relational
labels being assigned to the same compound in the N1 and N2
families. An example is \emph{face value}, which in the N1 family was
coded with the relation \textsc{have2} (value that the face has),
along with e.g. \emph{face price} and \emph{face validity}, and in
contrast to \textsc{in}, which was used for e.g. \emph{face
  ache}. % and \emph{face wound}.
On the other hand, in the N2 family \emph{face value} was coded as
\textsc{in} (value on the face), as was e.g. \emph{market value},
\emph{cash value}, or \emph{street value}, while examples for
\textsc{have2} are e.g. \emph{credit value}, \emph{pixel value} and
\emph{probability value}. Note that when one is interested in
the distribution of relations within a constituent family, the
specific labels are irrelevant, as long as the coding scheme within
the families is consistent and the overall level of granularity
remains constant. \enlargethispage{\baselineskip}
On the other hand, this family specific way of
coding the relations makes it impossible to compare their distribution across families.

The compounds were annotated in isolation, that is, by inspecting them
outside of their 
sentential context. However, when I could not
decide on an annotation in isolation, I checked the sentential context in
the \isi{BNC}. Often, this led to the discovery of combinations that were in
fact not compounds, either because they were part of 2 syntactic constituents or
because they were hits that resulted from tagging errors. There were also cases where the
compounds did not fit our
original search query, usually because they were part of bigger
complex expressions. All these cases were excluded.


\subsection{Coding the constituent senses}
\label{sec:coding-the-senses}

The constituents were annotated with their respective \isi{WordNet}
synsets. This was done together with the coding of the semantic
relations. 

Table \ref{tab:bank-n1-synsets} shows some example codings from the constituent family of
\emph{bank} in N1 position, along with the number of compound types sharing the respective \isi{WordNet} sense. For similar overviews of the synset coding
decisions for all constituents, cf. Appendix B.% \ref{sec:appendix_semantic-coding-2016}.

\begin{table}[H]
\begin{tabularx}{\textwidth}{cp{5cm}lll}\lsptoprule
{\small wnSense}&WordNet description&types&class&example\\\midrule
1&sloping land (especially the slope beside a body of water)&5&n&bank barn\\\midrule
2&a financial institution that accepts deposits and channels the money into lending activities&52&n&bank job\\\midrule
4&an arrangement of similar objects in a row or in tiers&2&n&bank switch\\\midrule
5&a supply or stock held in reserve for future use (especially in emergencies)&1&n&bank nurse\\\midrule
10&a flight maneuver; aircraft tips laterally about its longitudinal axis (especially in turning)&1&n&bank angle\\\lspbottomrule
\end{tabularx}
  \caption{Synset coding for bank in N1 position}
  \label{tab:bank-n1-synsets}
\end{table}

As described in Section \ref{sec:wordnet}, \isi{WordNet} does not differentiate
between related or unrelated synsets, and the synset coding therefore
simply shows the distribution of different senses across homonyms. In
some cases, this distribution corresponds to the distribution of different senses
related via meaning shifts, but this is not necessarily the case.

The specific word sense applicable to a given compound
is usually clear, e.g. \emph{rock music} vs. \emph{rock arch}. In
cases were the ambiguity persisted, e.g. \emph{rock mix}, which could in principle mean a mix of
different kinds of stones or a musical mix in the rock style, the
meaning occurring in the \isi{BNC} was used. If both meanings occurred in
the \isi{BNC}, the meaning that occurred most frequently was chosen. 


A second difficulty I encountered were WordNet senses I could not distinguish, either conceptually or in application to
the data. In these cases, the senses were collapsed into one
sense. Finally, some compounds involved constituent senses that did
not occur in \isi{WordNet}, in which case I added the missing senses manually.
Often, these missing senses involved proper names, e.g. \emph{Ring} referring
to the set of 4 operas by Richard Wagner. 

\enlargethispage{1\baselineskip}
The constituents were coded based on the compounds in
isolation, similar to the way the semantic relations were coded. Whenever necessary for clarification, the sentential context in the \isi{BNC} was
checked. Any combination that turned out to be not a compound or part
of a more complex compound was discarded.  

The numbers of unique compound types accepted for further processing
were 2,629 in the N1 families and 6,172 in the N2 families.

\section[Variables and predictions]{Bell \& Schäfer (2016): explanatory variables and predictions}
\label{sec:bellschaefer2016_further-and-predictions}

This section describes the explanatory variables used in the models
described in this chapter. In Section \ref{sec:semcoding}, I describe
the variables derived from the semantic annotations in our compound
database. Section \ref{sec:methodsFurtherExplanatory} explains the
other variables used.

\subsection{Variables derived from the semantic coding}
\label{sec:semcoding}

To assess the place of a given compound in its constituent families relative to the distribution of relations and sysnsets in those families, we decided to use proportions
and ranks as explanatory variables. Using these 2 types of variables
allows one to bring the greatest amount of distributional information
into the models. While we did not explore all other measures, initial
exploration had shown that expressing the relations in terms of
proportions explained more of the variation than using the 
strength ratio from \citet{GagneandShoben:1997}.

The explanatory variables derived from the relation coding in the
dataset are shown in \Next.

\ex. 
\a. relation proportion:\\
the proportion of positional family members that share a con\-stit\-u\-ent’s semantic relation
\b. relation rank:\\ % \enlargethispage{1\baselineskip}
the frequency-based ranking of a constituent’s semantic relation in its positional family
 
The corresponding 2 explanatory variables encoding the synsets are
given in \Next.

\ex.
\a. synset proportion:\\
    the proportion of positional family members that share a con\-stit\-u\-ent’s WordNet sense
\b. synset rank:\\
    the frequency-based ranking of a constituent’s WordNet sense in its positional family

I will use the compound \emph{application form} to illustrate how
these variables are derived. The calculations for the 4 variables
pertaining to the N1 constituent family are shown in \Next, while
\NNext shows the calculation of the 4 variables for the N2 family. 

\ex. \emph{application form}, N1 family\\
relation: \textsc{for}\\
synset: WordNet sense 2 ({a verbal or written request for assistance or employment or admission to a school})
\a. N1 relation proportion:\\[.5em] 
\( \displaystyle \frac{\text{number of compound types coded with
\textsc{for} in N1 family}}{\text{total number of compound types in
N1 family}}\\[.1em] = \frac{28}{42} = 0.67 \) \vspace*{.3em}
\b. N1 relation rank: 1
\c. N1 synset proportion:\\[.5em]
\( \displaystyle \frac{\text{number of compound types with WordNet sense 2 in N1 family}}{\text{total number of compound types in
N1 family}}\\[.1em] = \frac{20}{42} = 0.48 \)  \vspace*{.3em}
\d. N1 synset rank: 1 (no other synset occurs in more
compound types)

% An example will help to make this coding clear. \emph{Application} in \emph{application
% form} is coded with the relation \textsc{for}, and there are 27 further types in
% the application N1 family with this relation. Since the family itself
% has 42 members, \textsc{for} occupies the first rank, occurring in
% 28/42=67\% of family members. 
% Hence, \emph{application form} is coded with an N1 relation proportion
% of 0.67 and an N1 relation rank of 1. 
%
%     
% For example, \emph{application} in \emph{application form} is coded
% with WordNet sense 2, and there are 19 other types with this WordNet
% sense in a family of 42 members. Hence the N1 synset proportion for
% \emph{application form} is 20/42= 0.48. There are in total 4 WordNet
% senses of application in this constituent family, of which sense 2 is
% the most frequent, hence \emph{application form} gets an N1 synset rank of 1.

\ex. \emph{application form}, N2 family\\
relation: \textsc{for}\\
synset: WordNet sense 8 ({a printed document with spaces in which to write})
\a. N2 relation proportion:\\[.5em] 
\( \displaystyle \frac{\textrm{number of compound types coded with
\textsc{for} in N2 family}}{\text{total number of compound types in
N2 family}}\\[.1em] = \frac{77}{163} = 0.47 \)  \vspace*{.3em}
\b. N2 relation rank: 1
\c. N2 synset proportion:\\[.5em]
\( \displaystyle \frac{\text{number of compound types with WordNet sense 2 in N2 family}}{\text{total number of compound types in
N2 family}}\\[.1em] = \frac{76}{163} = 0.46 \)  \vspace*{.3em}
\d. N2 synset rank: 1 (no other synset occurs in more
compound types)



\subsection{Further explanatory variables}
\label{sec:methodsFurtherExplanatory}
\is{frequency!{based variables in Bell \& Schäfer (2016)}|(}

\subsubsection{Constituent frequencies and spelling ratio}
\label{sec:freqandspell}
% \is{frequency!{constituent}}
Just as in the models discussed in Chapter \ref{cha:empirical-1}, %\citet{BellandSchaefer:2013}, 
we use the constituent
frequencies as predictors. Constituent frequencies are clearly not
semantic predictors. However, they fit the general idea of modeling
transparency in terms of expectedness: The more frequent the
occurrence of a constituent in the language as a whole, the more
expected it is. 

As explained above in Section \ref{sec:meaningShiftsInFamilies}, we used the spelling ratio of a compound as a
replacement of the coding of whole compound shifts used in the models
described in Chapter \ref{cha:empirical-1}. Spelling ratio was calculated as shown in \Next:\is{compound measures!{spelling ratio}}

\ex. \( \displaystyle \text{spelling ratio} =  \frac{\text{unspaced frequency} + \text{hyphenated frequency})}{\text{spaced frequency}}\)

For an example of calculating the spelling ratio, cf. Chapter \ref{cha:empirical-1}, Section \ref{sec:bell-schaefer-freq}.
\subsubsection{Family size ratios}
\label{sec:famsizeratios}

\is{compound measures!{family size ratio}}
Besides the expectedness of the individual constituents themselves as
measured via their overall frequency in the language, we added 2
 variables assessing the expectedness of a constituent as
either head or modifier of a compound, the family size ratios of N1
and N2 respectively. \citet{BellandPlag:2012} introduced this measure
to indicate the tendency of a given constituent to appear as a head or
as a modifier in a compound. It is operationalized as the log of the
positional family size divided by the reverse family size, cf. \Next.

\ex. \( \displaystyle \text{family size ratio} = \frac{\textrm{positional family size}}{\textrm{reverse family size}} \)

As described in Section \ref{sec:initial} above, the positional family of a
constituent is the set of compounds in which a given constituent
appears in the same position. In contrast, the reverse family is the
set of compounds in which that constituent occurs in the alternative
position. Take the compound \emph{bank account}. The first constituent
is \emph{bank}, and its positional constituent family includes
e.g. \emph{bank emergency}, \emph{bank fraud}, and \emph{bank
  index}. The positional family of the second constituent, \emph{account},
includes e.g. \emph{summary account}, \emph{insider account}, and
\emph{police account}. The N1 reverse family collects the compounds in
which \emph{bank} occurs as the second constituent, e.g. \emph{asset
  bank}, \emph{Beirut bank}, and \emph{blood bank}.  The N2 reverse
family, correspondingly, collects the compounds in which
\emph{account} occurs as the first constituent,  e.g. \emph{account
  balance}, \emph{account handler}, and \emph{account number}. Again,
the family size ratio is constituent specific. The calculation for the
2 constituents of \emph{bank account} is shown in \Next.

\ex. \emph{bank account}
\a. N1 family size ratio = 
\( \displaystyle \frac{\textrm{positional family size N1}}{\textrm{reverse
family size N1}} =\frac{75}{101} = 0.74 \) \vspace*{.5em}
% $log(\frac{\textrm{positional family size N1}}{\textrm{reverse
% family size N1}}) = log(\frac{75}{101}) = log(0.74) = -0.30$
\b. N2 family size ratio = 
\( \displaystyle \frac{\textrm{positional family size N2}}{\textrm{reverse family size N2}} = \frac{92}{33} = 2.79 \)
% $log(\frac{\textrm{positional family size
%   N2}}{\textrm{reverse family size N2}}) = log(\frac{92}{33}) = log(2.79) = 1.03$

% head(allData[allData$singBrUnderscore == "bank_account",c("positionalFamilySizeN1AboveFour","positionalFamilySizeN2AboveFour","reversedFamilySizeN1AboveFour","reversedFamilySizeN2AboveFour","famSizeRatioN1AboveFour","famSizeRatioN2AboveFour")],n=1)                
%     positionalFamilySizeN1AboveFour positionalFamilySizeN2AboveFour
% 348                              75                              92
%     reversedFamilySizeN1AboveFour reversedFamilySizeN2AboveFour
% 348                           101                            33
%     famSizeRatioN1AboveFour famSizeRatioN2AboveFour
% 348              -0.2942395                1.006239
\is{frequency!{based variables in Bell \& Schäfer (2016)}|)}




% This expectedness can be assessed using the notion of constituent family sizes. Every noun–noun (NN) compound has two positional constituent families. The modifier positional family consists of all other NN compounds that share the same modifier, and the head positional family consists of all other NN compounds that share the same head. These two constituent families are the positional families since the nouns used to create them occur in the same position in the target compound as they do in all other members of the family. It is also possible to create reverse families, in which the constituent in question occurs in the alternative position compared with the target compound. For example, the N1 positional family for bank account includes  The respective family sizes are the numbers of different compound types in each of these families. To measure the tendency of constituents to occur as either compound heads or modifiers, it is possible to use family size ratios (Bell and Plag 2013). Family size ratio is the log of the positional family size divided by reverse family size; it therefore indicates the preference of a constituent to appear either in its current or in the alternative position, and hence its expectedness in either position.


% Lemmatized constituent frequencies were calculated by summing the frequencies of all inflectional variants of the constituents in the USENET corpus.
% Family size ratios were calculated as shown in (3):

%     (3)

%     family size ratio = log(positional family size/reverse family size)
     

% Family size ratio is the log of the positional family size divided by
% reverse family size and therefore indicates the preference of a
% constituent to appear either in its current or in the alternative
% position. We calculated family size ratios both on the basis of the
% entire corpus, and using a lemmatized frequency baseline of at least 5
% occurrences, the same frequency baseline we used for relation and
% sense proportions. The latter values were found to be better
% predictors of perceived transparency and are therefore used in the
% models reported here.

% Constituent family size
% e.g. bank account
% positional families
% bank emergency, bank fraud, bank index etc.
% summary account, insider account, police account etc.
% reverse families
% asset bank, beirut bank, blood bank etc.
% account balance, account handler, account number etc.

% \textbf{TODO: plot the tendencies? y-axis the constituents, x-axis the
% ratios}

\subsection{Tabular overview of the explanatory variables}
\label{sec:overviewExplanatoryVariables}

The explanatory variables used in the modeling are listed in table \ref{tab:bs2016explanatory.variables}
\begin{table}[!htb]
  \small
  \begin{tabularx}{\textwidth}{l>{\raggedright\arraybackslash}p{3cm}>{\raggedright\arraybackslash}p{8cm}}
\lsptoprule
\multicolumn{3}{l}{{semantic explanatory variables}}\\\midrule
1.&N1 relationship proportion&proportion of compound types sharing the
target compound's semantic relation in the N1 constituent family\\                    
2.&N2 relationship proportion&proportion of compound types sharing the
target compound's semantic relation in the N2 constituent family\\
3.&N1 synset proportion&proportion of compound types sharing the
N1 synset of the target compound in the compound's N1 constituent family \\                
4&N2 synset proportion&proportion of compound types sharing the
N2 synset of the target compound in the compound's N2 constituent family      \\\tablevspace               
\multicolumn{3}{l}{{non-semantic explanatory variables}}\\\midrule
4.&N1 frequency &summed occurrences of all forms of the N1 lemma\\
5.&N2 frequency &summed occurrences of all forms of the N2 lemma\\
6.&spelling ratio&sum of the unspaced and hyphenated frequency of the
compound divided by the spaced frequency\\
7.&N1 family size ratio &number of compound types in the N1 positional
family size divided by the number of items in the N1 reverse family\\
8.&N2 family size ratio&number of compound types in the N2 positional
family size divided by the number of items in the N2 reverse family\\\lspbottomrule
  \end{tabularx}
  \caption{Explanatory variables in the models from
    \citet{BellandSchaefer:2016}. All variables are logarithmized.}
\label{tab:bs2016explanatory.variables}
\end{table}



\subsection{Restricting the target dataset}
\label{sec:restricted-target}

The compound dataset provided by \citet{Reddyetal:2011} consists of 90
compounds. In the discussion of the linguistic properties of these
compounds in Chapter \ref{cha:empirical-1}, Section \ref{sec:linguistic-characeterization}, it
already emerged that these compounds are not fully
homogeneous. Some aspects turned out to be problematic for the
approach taken in this chapter and the corresponding items were
 excluded.

As mentioned in Section \ref{sec:postData}, we used CELEX to prune the compound
data\-base, removing all compounds with 3 or more constituents. Following on the decision to exclude these items from the
database, we also excluded the 3 Reddy et al. items that are
internally complex, namely \emph{grandfather clock}, \emph{cocktail dress}, and \emph{gaveyard shift}, from our analysis.\is{CELEX}
 
% # #                   x freq
% # # 1    cocktail_dress   84
% # # 2         fine_line   88
% # # 3 grandfather_clock   85
% # # 4   graveyard_shift   86
% # # 5  number_crunching   85
% # # 6        sacred_cow   83
% # # 7  shrinking_violet   88
% # # 8      sitting_duck   83
% # # 9       smoking_gun   83

Because the construction of the compound database is based on noun
noun patterns, we also excluded the adjective noun combinations \emph{fine line} and
\emph{sacred cow} from our analysis. For the same reason, we excluded the
3 combinations that contained attributively used gerund-participles as modifiers:
\emph{shrinking violet}, \emph{sitting duck}, and \emph{smoking
  gun}. Finally, we excluded \emph{number crunching} because
\emph{crunching} is exclusively classified as a verb in \isi{WordNet}. This
left 81 compound types in the analysis. 

\enlargethispage{1\baselineskip}
Note that since we did not intend to model compound transparency with
the help of constituent transparency, we used the full set of ratings
in the Reddy et al. dataset, accepting all ratings accepted in
\citet{Reddyetal:2011}. This left us with a total of 6,952 ratings for
the 81 compounds: 2,307 ratings of whole compound transparency, 2,317
ratings of N1 transparency and 2,328 ratings of N2 transparency. 

\subsection[Predicting semantic transparency]{Transparency in terms of expectancy: the predictions of
  Bell \& Schäfer (2016)}
\label{sec:bellschaefer2016_predictions}

% \enlargethispage{2\baselineskip}
The main hypothesis in \citet{BellandSchaefer:2016} was that
expectedness is the main explanation of perceived semantic
transparency. We translated this into 14 explicit predictions, cf. \citet[172--174]{BellandSchaefer:2016},
distinguishing between effects of properties of the individual
constituent on the 2 constituent transparencies and the whole compound
transparency, and effects of properties of the whole compound on
constituent as well as compound transparency. These predictions are 
 reproduced in Tables \ref{tab:predictions-AB} and \ref{tab:predictions-CD}.

\begin{table}[p]
% \begin{longtable}[!htb]{lp{9cm}}
% \begin{tabularx}{\textwidth}{l>{\raggedright\arraybackslash}p{11cm}}
\small
\begin{tabularx}{\textwidth}{lQ}
\lsptoprule
{set A}&{effects of a constituent's properties on that constituent's transparency}\\ \midrule % \cmidrule{2-2}
A1.& A constituent will be perceived as more transparent the more frequent it is, i.e. the more expected it is in the language in general.\\
A2.&A constituent will be perceived as more transparent, the more expected its particular sense within the positional family, i.e. the more likely it is to occur with that sense as the head (for N2) or modifier (for N1) of a compound.\\
A3.&A constituent will be perceived as more transparent, the more expected it is as the head (for N2) or modifier (for N1) of compounds in general, i.e. the more characteristic the relevant role for the constituent in question.\\
A4.&A constituent will be perceived as more transparent, the greater
    the proportion of compounds in its positional family that share
    the same semantic relation as the compound in question, i.e. the
    more expected the relevant semantic relation with that
    constituent.\\ \tablevspace % \lspbottomrule %\pagebreak
{set B}&{effects of a constituent’s properties on the perceived transparency of the other constituent}\\\midrule % \cmidrule{2-2}
B5.&A constituent will be perceived as more transparent the more frequent the other constituent, i.e. the more expected it is in the language in general. This is what we found in the study reported in Bell and Schäfer (2013); we expect to replicate this result.\\
B6.&A constituent will be perceived as more transparent, the less expected the relevant sense of the other constituent within its positional constituent family. In Bell and Schäfer (2013) we reported that a semantic shift in either constituent was associated with greater perceived transparency of the other constituent. If, as we hypothesize, sense frequencies can be used to estimate semantic shiftedness, then we would expect to find the same effect.\\
B7.&A constituent will be perceived as more transparent, the more expected the other constituent as the head (for N2) or modifier (for N1) of compounds in general, i.e. the more characteristic the relevant role for the other constituent. This is because we hypothesize that a more readily available semantic structure will lead to an increased perception of transparency all round.\\
B8.&A constituent will be perceived as more transparent, the greater the proportion of the other constituent’s positional family that shares the same semantic relation as the compound in question, i.e. the more expected is the other constituent with the relevant semantic relation. This is because we hypothesis that the more easily accessible the semantic relation, the greater the perceived transparency all round.\\\lspbottomrule\end{tabularx}
% \caption[Predictions]{Predictions from \citet{BellandSchaefer:2016}, set A: effects of a constituent's properties on that constituent's transparency}
% \caption[Predictions]{Predictions from \citet{BellandSchaefer:2016}, set A}
% \label{tab:predictions-A}
\caption[Predictions]{Predictions from \citet{BellandSchaefer:2016}, set A and B}
\label{tab:predictions-AB}
% \end{longtable}
\end{table}
% \afterpage{\clearpage}
% \begin{table}[!htb]
% \small
% \begin{tabularx}{\textwidth}{lQ}
% % \begin{tabularx}{\textwidth}{l>{\raggedright\arraybackslash}p{11cm}}
% \lsptoprule
% {set B}&{effects of a constituent’s properties on the perceived transparency of the other constituent}\\\midrule % \cmidrule{2-2}
% B5.&A constituent will be perceived as more transparent the more frequent the other constituent, i.e. the more expected it is in the language in general. This is what we found in the study reported in Bell and Schäfer (2013); we expect to replicate this result.\\
% B6.&A constituent will be perceived as more transparent, the less expected the relevant sense of the other constituent within its positional constituent family. In Bell and Schäfer (2013) we reported that a semantic shift in either constituent was associated with greater perceived transparency of the other constituent. If, as we hypothesize, sense frequencies can be used to estimate semantic shiftedness, then we would expect to find the same effect.\\
% B7.&A constituent will be perceived as more transparent, the more expected the other constituent as the head (for N2) or modifier (for N1) of compounds in general, i.e. the more characteristic the relevant role for the other constituent. This is because we hypothesize that a more readily available semantic structure will lead to an increased perception of transparency all round.\\
% B8.&A constituent will be perceived as more transparent, the greater the proportion of the other constituent’s positional family that shares the same semantic relation as the compound in question, i.e. the more expected is the other constituent with the relevant semantic relation. This is because we hypothesis that the more easily accessible the semantic relation, the greater the perceived transparency all round.\\\lspbottomrule
% \end{tabularx}
% % \caption[Predictions]{Predictions from \citet{BellandSchaefer:2016}, set B: effects of a constituent’s properties on the perceived transparency of the other constituent}
% \caption[Predictions]{Predictions from \citet{BellandSchaefer:2016}, set B}
% \label{tab:predictions-B}
% % \end{longtable}
% \end{table}

\begin{table}[p]
\small
\begin{tabularx}{\textwidth}{lQ}
% \begin{tabularx}{\textwidth}{lp{11cm}}
\lsptoprule
{set C}&{effects of constituent properties on the perceived transparency of the whole compound}\\ \midrule % \cmidrule{2-2}
C9.&A compound will be perceived as more transparent the more frequent either constituent, i.e. the more expected it is in the language in general. Greatest perceived transparency will occur when both constituents are frequent.\\
C10.&A compound will be perceived as more transparent, the more expected either constituent in the relevant role, i.e. as the head (for N2) or modifier (for N1) of compounds in general. Greatest perceived transparency will occur when both constituents occur in their characteristic roles.\\
C11.&A compound will be perceived as more transparent, the greater the proportion of either constituent’s positional family that shares the same semantic relation as the compound in question, i.e. the more expected is either constituent with the relevant semantic relation. Greatest perceived transparency will occur when the relation occurs in a high proportion of both families.\\
C12.&The effect of constituent senses on whole compound transparency will be less pronounced than the effects on individual constituents, and less pronounced than the effects of the other predictors on whole compound transparency. This follows from our hypotheses that compound transparency is a function of constituent transparencies, and that a high sense proportion of a given constituent increases the perceived transparency of that constituent while decreasing the perceived transparency of the other.\\ \tablevspace % \lspbottomrule
{set D}&{effects of properties of the whole compound}\\\midrule %  \cmidrule{2-2}
D13.&Both constituents will be perceived as less transparent, the greater the spelling ratio of the compound, i.e. the more frequently it occurs with non-spaced orthography relative to its frequency with spaced orthography. Bell and Schäfer (2013) found that semantic shifts of the compound as a whole were associated with lower perceived transparency of both constituents. We take spelling ratio to be a measure of the degree of semantic lexicalisation of a compound (after Bell and Plag 2012, 2013) and hypothesize that it can therefore be used to replicate the effect of whole-compound semantic shift.\\
D14.&The compound will be perceived as less transparent, the greater its spelling ratio, i.e. the more frequently it occurs with non-spaced orthography relative to its frequency with spaced orthography. As described above, we hypothesize that high spelling ratio is a correlate of whole-compound semantic shift.\\\lspbottomrule
\end{tabularx}
% \caption[Predictions]{Predictions from \citet{BellandSchaefer:2016}, set C: effects of constituent properties on the perceived transparency of the whole compound}
\caption[Predictions]{Predictions from \citet{BellandSchaefer:2016}, set C and D}
\label{tab:predictions-CD}
% \caption[Predictions]{Predictions from \citet{BellandSchaefer:2016}, set C}
% \label{tab:predictions-C}
% \end{longtable}
\end{table}

% \begin{table}[!htb]
%   \small
%   \begin{tabularx}{\textwidth}{lQ}
% % \begin{tabularx}{\textwidth}{lp{11cm}}
% \lsptoprule
% {set D}&{effects of properties of the whole compound}\\\midrule %  \cmidrule{2-2}
% D13.&Both constituents will be perceived as less transparent, the greater the spelling ratio of the compound, i.e. the more frequently it occurs with non-spaced orthography relative to its frequency with spaced orthography. Bell and Schäfer (2013) found that semantic shifts of the compound as a whole were associated with lower perceived transparency of both constituents. We take spelling ratio to be a measure of the degree of semantic lexicalisation of a compound (after Bell and Plag 2012, 2013) and hypothesize that it can therefore be used to replicate the effect of whole-compound semantic shift.\\
% D14.&The compound will be perceived as less transparent, the greater its spelling ratio, i.e. the more frequently it occurs with non-spaced orthography relative to its frequency with spaced orthography. As described above, we hypothesize that high spelling ratio is a correlate of whole-compound semantic shift.\\\lspbottomrule
% \end{tabularx}

% % \caption[Predictions]{Predictions from \citet{BellandSchaefer:2016}, set D: effects of properties of the whole compound}
% \caption[Predictions]{Predictions from \citet{BellandSchaefer:2016}, set D}
% \label{tab:predictions-D}
% % \end{longtable}
% \end{table}
\clearpage
I will use these predictions to discuss the models from
\citet{BellandSchaefer:2016} in the next section. However, note that
some of the predictions are based on the findings in the models
presented in \citet{BellandSchaefer:2013},
% that I argued used regression models that should not have been used
 cf. the discussion in Chapter \ref{cha:empirical-1}, Section \ref{sec:bell-schaefer-lmer}. In the mixed effects
regression models presented there, some of the predictors mentioned in Tables
 \ref{tab:predictions-AB}--\ref{tab:predictions-CD} are not significant. Thus, the finding
underlying prediction B5, the positive correlation of the other
constituent's frequency with perceived constituent transparency, occurs
only in the mixed effects model for the second constituent. In contrast,
the finding underlying prediction B6, a shifted other constituent as a
foil for constituent transparency, occurs only in the mixed effects
model for the first constituent. 

% Also, recall that spelling ratio, the only variable encoding
% properties of the whole compound, did not emerge as significant in any
% of the mixed effects models discussed in chapter \ref{cha:empirical-1}, section \ref{sec:bell-schaefer-lmer}. 

\section{The models from Bell \& Schäfer 2016}
\label{sec:bellandschaefer2016models}

\enlargethispage{1\baselineskip}
We used mixed effects regression models with crossed random effects for the raters and the items.
For the justification of why we used these
kinds of models and the R-packages used, cf. the
remarks in Chapter \ref{cha:empirical-1}, Section
\ref{sec:bell-schaefer-lmer}.  

All numerical variables were logarithmatized (cf. the remarks in
Chapter \ref{cha:empirical-1}, Section \ref{sec:bell-schaefer-freq}
for the reasons). In addition, the resulting
variables were centred on their means. \citet[254--255]{Baayen:2008a} explicitly
recommends \isi{centering} in his discussion of the random effect structure
of mixed models, because centering allows to vary intercepts and
slopes independently (see also the points on the advantages of
centering in Chapter \ref{cha:semTranPsycho}, Section
\ref{sec:marelliluzuatti2012}).   

We checked the set of explanatory variables for collinearity (as
indicated by the condition number provided by the function
\texttt{collin.fnc()} from \citealt{languageR}, cf. the remarks in Chapter
\ref{cha:empirical-1}, Section
\ref{sec:bell-and-schaefer-models}). \is{r-packages!\texttt{languageR}}
Because including the proportions
as well as the ranks for the synset and relation coding led to
unacceptable levels of \isi{collinearity}, we dropped the ranks from the
analysis. We opted for the ranks because the proportions produce more
fine-grained distinctions. The resulting set of predictors had very
low condition numbers for the 3 different datasets used, ranging from
2.25 to 2.27. Note that these very low values are a side effect of
centering the data. The possible influence of column scaling on the
results of applying collinearity diagnostics is already mentioned in
\citet[183]{Belsleyetal:1980}.\is{centering!effect on collinearity measures}\is{collinearity!centering and}

As well as the predictors individually, we also included
an interaction between the relation proportions of N1 and N2: if the
RICE theory of conceptual combination \citep{Spaldingetal:2010} is
correct, then we might expect some interaction between the strength of
association of the relation with N1 and the strength of its
association with N2.\is{RICE theory} 

\enlargethispage{1\baselineskip}
The random effects structure was selected by comparing sequences of
models with increasingly complex random effects structures using
likelihood ratio tests. Note that this procedure differs from the
approach chosen in Chapter \ref{cha:empirical-1}, where I started by
using the maximal random effects structure. There is no agreement on
the best way to approach this issue. For example, the procedures
described in \citet[cf. especially the remark
on page 393]{Baayenetal:2008} % \citet[393]{Baayenetal:2008}) 
and \citet[Section 7.1]{Baayen:2008a} are hypothesis-driven: factors hypothesized to vary
randomly are included in the
random effect component. 
Regardless of
the chosen procedure, the resulting models are compared using
likelihood ratio tests, and only those random components are kept
respectively added that yield significantly better fits. 

The non-significant fixed effects were
progressively removed from the models by stepwise elimination. The
manual analysis was checked against the results of the step function
in lmerTest, which performs automatic backward elimination on random
and fixed effects in a linear mixed effects model.\is{r-packages!\texttt{lmerTest}}
 % Marginal and conditional R2 values were calculated using the r.squaredGLMM function in the MuMIn package (Bartoń 2016). For mixed effects models, marginal R2 values are those associated with the fixed effects, and conditional R2 values are those associated with the fixed effects plus the random effects (Nakagawa and Schielzeth 2013).

\subsection{N1 transparency}
\label{sec:bellschaefer2016n1}


The final model for N1 transparency is presented in
\tabref{tab:bellschaefer2016mixed-revised-N1}. Note that this model
deviates slightly in its random effects structure from the N1 model
presented in \citet{BellandSchaefer:2016}. However, this difference
does not affect anything outside of the random effects structure to
any noticeable degree. The fixed effects are presented graphically in \figref{fig:bellschaefer2016_model_N1}.
% \begin{table}[!htb]
% %% Article version of the model for N1 transparency
% % summary(step.cord.n1.lmer)
% % Linear mixed model fit by REML t-tests use Satterthwaite approximations to
% %   degrees of freedom [lmerMod]
% % Formula: 
% % litScoreN1 ~ spellingRatioCentred + logN1FreqCentred + logN2FreqCentred +  
% %     logSynsetPropInN2FamCentred + logRelPropInN1FamCentred +  
% %     (1 + spellingRatioCentred | workerID) + (1 + logN1FreqCentred |  
% %     workerID) + (1 | singBrUnderscore)
% %    Data: t1
% % Control: lmerControl(optimizer = "bobyqa")

% % REML criterion at convergence: 6947.5

% % Scaled residuals: 
% %     Min      1Q  Median      3Q     Max 
% % -4.6279 -0.5353  0.0846  0.4152  4.5348 

% % random effects:
% %  groups           name                 variance std. dev. Corr 
% %  workerID         (intercept)          0.046443 0.21551       
% %                   spellingRatioCentred 0.003116 0.05582  1.00 
% %  workerID.1       (intercept)          0.018355 0.13548       
% %                   logN1FreqCentred     0.003735 0.06111  -1.00
% %  singBrUnderscore (intercept)          1.627958 1.27591       
% %  residual                              0.978290 0.98909       
% % number of obs. 2317, groups:  workerID, 114; singBrUnderscore, 81

% % fixed effects:
% %                             estimate std. error       df t value pr(>|t|)    
% % (intercept)                  2.84159    0.14830 81.75000  19.161  < 2e-16 ***
% % spellingRatioCentred        -0.30717    0.08391 76.04000  -3.661 0.000462 ***
% % logN1FreqCentred             0.69523    0.08641 76.32000   8.046 8.78e-12 ***
% % logN2FreqCentred            -0.32067    0.13186 75.00000  -2.432 0.017407 *  
% % logSynsetPropInN2FamCentred -0.29082    0.14541 75.00000  -2.000 0.049126 *  
% % logRelPropInN1FamCentred     0.37687    0.15973 75.02000   2.359 0.020904 *  
% % ---
% % Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

% % Correlation of Fixed Effects:
% %             (Intr) spllRC lgN1FC lgN2FC lSPIN2
% % spllngRtCnt -0.063                            
% % lgN1FrqCntr -0.014 -0.098                     
% % lgN2FrqCntr -0.127  0.335 -0.185              
% % lgSynPIN2FC -0.003  0.250 -0.089  0.176       
% % lgRlPrIN1FC  0.048  0.042  0.096  0.036  0.029
% \begin{tabular}{lllll}
% \multicolumn{4}{l}{\textbf{random effects:}}\\
%  \textbf{groups}     &\textbf{name}       &\textbf{variance}&\textbf{std. dev.} \\%&Corr\\ 
%  workerID        &(intercept)         &0.046443&0.21551\\       
%                  &spellingRatioCentred&0.003116&0.05582\\  %1.00 
%  workerID.1      &(intercept)         &0.018355&0.13548\\       
%                  &logN1FreqCentred    &0.003735&0.06111\\  %-1.00
%  singBrUnderscore&(intercept)         &1.627958&1.27591\\       
%  residual        &                    &0.978290&0.98909\\       
% \multicolumn{4}{l}{number of obs. 2317, groups:  workerID, 114; singBrUnderscore, 81}
  
% \end{tabular}
% \vspace*{1ex}

% \begin{tabular}[h]{lllllll}
% \multicolumn{7}{l}{\textbf{fixed effects:}}\\
% % &&&&&\\
%               &estimate& std. error   &    df& t value &pr($>|t|$)\\    
% (intercept)                & 2.84159 &  0.14830&81.75000& 19.161& $<$ 2e-16\\
% logRelPropInN1FamCentred   & 0.37687 &  0.15973&75.02000&  2.359&0.020904 \\
% logSynsetPropInN2FamCentred&-0.29082 &  0.14541&75.00000& -2.000&0.049126 \\
% logN1FreqCentred           & 0.69523 &  0.08641&76.32000&  8.046&8.78e-12 \\
% logN2FreqCentred           &-0.32067 &  0.13186&75.00000& -2.432&0.017407 \\
% spellingRatioCentred       &-0.30717 &  0.08391&76.04000& -3.661&0.000462 
  
% \end{tabular}
%   \caption{Final mixed effects model for constituent 1 transparency,
%     marginal R$^2$= 0.37, conditional R$^2$= 0.77}
%   \label{tab:bellschaefer2016mixed-constituent-1}
% \end{table}

% \begin{figure}[!htb]
% % \begin{figure}[H]
%   \centering
% \includegraphics[scale=.8,trim=40 90 60 120, clip]{/home/martin/Dropbox/statistics/habil-stat/bell-schaefer-2016_allEffects_modelN1_gridlayout.pdf}
%  % trim left lower right upper
%   \caption{Partial effects in the final model for N1 transparency}
% \label{fig:bellschaefer2016_model_N1}
% \end{figure}

\begin{table}[htb]
% habil.bs2016.n1.lmer <- lmer(formula = litScoreN1 ~
%                                  logRelPropInN1FamCentred + logSynsetPropInN2FamCentred  + logN1FreqCentred + logN2FreqCentred + spellingRatioCentred  + (1 + spellingRatioCentred + logN1FreqCentred | workerID) + (1 | singBrUnderscore), data = t1, control = lmerControl(optimizer = "bobyqa"))
% summary(habil.bs2016.n1.lmer)
% Linear mixed model fit by REML t-tests use Satterthwaite approximations to
%   degrees of freedom [lmerMod]
% Formula: litScoreN1 ~ logRelPropInN1FamCentred + logSynsetPropInN2FamCentred +  
%     logN1FreqCentred + logN2FreqCentred + spellingRatioCentred +  
%     (1 + spellingRatioCentred + logN1FreqCentred | workerID) +  
%     (1 | singBrUnderscore)
%    Data: t1
% Control: lmerControl(optimizer = "bobyqa")

% REML criterion at convergence: 6946.8

% Scaled residuals: 
%     Min      1Q  Median      3Q     Max 
% -4.6320 -0.5408  0.0835  0.4129  4.5269 

% random effects:
%  groups           name                 variance std. dev. Corr       
%  workerID         (intercept)          0.067673 0.26014             
%                   spellingRatioCentred 0.003092 0.05561   0.93      
%                   logN1FreqCentred     0.003479 0.05898  -0.66 -0.34
%  singBrUnderscore (intercept)          1.627977 1.27592             
%  residual                              0.979093 0.98949             
% number of obs. 2317, groups:  workerID, 114; singBrUnderscore, 81

% fixed effects:
%                             estimate std. error       df t value pr(>|t|)    
% (intercept)                  2.84124    0.14840 81.94000  19.146  < 2e-16 ***
% logRelPropInN1FamCentred     0.37687    0.15973 75.02000   2.359 0.020904 *  
% logSynsetPropInN2FamCentred -0.29064    0.14542 75.00000  -1.999 0.049265 *  
% logN1FreqCentred             0.69511    0.08637 76.17000   8.048 8.79e-12 ***
% logN2FreqCentred            -0.32050    0.13186 75.01000  -2.431 0.017466 *  
% spellingRatioCentred        -0.30710    0.08389 75.98000  -3.661 0.000462 ***
% ---
% Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

% Correlation of Fixed Effects:
%             (Intr) lRPIN1 lSPIN2 lgN1FC lgN2FC
% lgRlPrIN1FC  0.048                            
% lgSynPIN2FC -0.003  0.029                     
% lgN1FrqCntr -0.016  0.096 -0.089              
% lgN2FrqCntr -0.127  0.036  0.176 -0.186       
% spllngRtCnt -0.061  0.042  0.250 -0.101  0.335

% \centering

\small
\begin{tabularx}{.95\textwidth}{llrrrrr}\lsptoprule
\multicolumn{7}{l}{\textbf{random effects:}}\\
% \hspace*{-1.8cm}\begin{tabular}{lllll}
% \multicolumn{4}{l}{\textbf{random effects:}}\\
 {groups}     &{name}       &{variance}&\multicolumn{2}{l}{{std. dev.}}&& \\ \midrule %&Corr\\ 
 workerID        &(intercept)         &0.067673&\multicolumn{2}{l}{0.26014}&&\\%            
                 &spelling ratio&0.003092&\multicolumn{2}{l}{0.05561}&&\\%  0.93      
                 &N1 frequency    &0.003479&\multicolumn{2}{l}{0.05898}&&\\% -0.66 -0.34
 singBrUnderscore&(intercept)         &1.627977&\multicolumn{2}{l}{1.27592}&&\\%            
 residual        &                    &0.979093&\multicolumn{2}{l}{0.98949}&&\\\tablevspace  %            
\multicolumn{7}{l}{number of obs.: 2317, groups:  workerID, 114; singBrUnderscore, 81}\\[1ex]
%   
% \end{tabular}
% \vspace*{1ex}
% 
% 
% \hspace*{-10cm}\begin{tabular}[h]{lllllll}
\multicolumn{7}{l}{\textbf{fixed effects:}}\\
              &{estimate}& {std. error}   &    {df}& {t value} &{pr($>|t|$)}\\\midrule    
(intercept)                & 2.84124&   0.14840&81.94& 19.146& $<$ 2e-16\\%***
N1 relation proportion   & 0.37687&   0.15973&75.02&  2.359&0.020904\\%*  
N2 synset proportion&-0.29064&   0.14542&75.00& -1.999&0.049265\\%*  
N1 frequency           & 0.69511&   0.08637&76.17&  8.048&8.79e-12\\%***
N2 frequency           &-0.32050&   0.13186&75.01& -2.431&0.017466\\%*  
spelling ratio       &-0.30710&   0.08389&75.98& -3.661&0.000462\\\lspbottomrule %***
% (intercept)                & 2.84124&   0.14840&81.94000& 19.146& $<$ 2e-16\\%***
% N1 relation proportion   & 0.37687&   0.15973&75.02000&  2.359&0.020904\\%*  
% N2 synset proportion&-0.29064&   0.14542&75.00000& -1.999&0.049265\\%*  
% N1 frequency           & 0.69511&   0.08637&76.17000&  8.048&8.79e-12\\%***
% N2 frequency           &-0.32050&   0.13186&75.01000& -2.431&0.017466\\%*  
% spelling ratio       &-0.30710&   0.08389&75.98000& -3.661&0.000462\\\lspbottomrule %***
\end{tabularx}
\caption{Final mixed effects model for constituent 1 transparency, marginal R$^2$= 0.37, conditional R$^2$= 0.77}
\label{tab:bellschaefer2016mixed-revised-N1}
% r.squaredGLMM(habil.bs2016.n1.lmer)
%       R2m       R2c 
% 0.3709319 0.7715259 

\end{table}
\begin{figure}[!htb]
% \begin{figure}[H]
  \centering
% \includegraphics[scale=.6,trim=40 90 60 120, clip]{/home/martin/Dropbox/statistics/habil-stat/bell-schaefer-2016_allEffects_modelN1revised.pdf}
\includegraphics[scale=.6,trim=40 90 60 120, clip]{./figures/bell-schaefer-2016_allEffects_modelN1revised.pdf}
 % trim left lower right upper
  \caption{Partial effects in the final model for N1 transparency}
\label{fig:bellschaefer2016_model_N1}
\end{figure}

The random effects of the model are shown in the top section of
\tabref{tab:bellschaefer2016mixed-revised-N1}, the fixed effects are
shown in its bottom section. The random effects are grouped by item
and rater. The model includes random intercepts for
items. In addition, it contains random intercepts for the raters, and random slopes for the
effects of spelling ratio and N1 frequency. These 3 random components
are paired, and are allowed to correlate. This correlation makes
sense conceptually, as the choice of one's personal rating range on
the Likert scale influences both the intercept as well as the possible
magnitude of the predictors at the same time. Note that the low variance
indicates that the slope adjustments are in both cases rather
small. For the adjustments of the intercepts we can observe that the
items come with much more variance than the raters, that is, the
adjustments to the intercepts for the individual items are greater
than the adjustments due to peculiarities of the individual subjects.  

Of the set of explanatory
variables, 5 predictors are significant in the model. Of the semantic predictors,
the proportion of a compound's relationship in the N1 family is
positively correlated with the perceived transparency of N1. In
contrast, the proportion of the synset of the compound's second
constituent in the N2 constituent family is negatively correlated with
semantic transparency. Of the 3 non-semantic predictors, only N1
frequency is positively correlated with the perceived transparency of
N1, while both N2 frequency as well as spelling ratio are negatively correlated. 

\figref{fig:bellschaefer2016_model_N1} shows plots of the 5
significant predictors. In all cases,
the vertical axis represents the semantic transparency of the first
constituent as given by the human raters. Since all predictors are continuous
variables, the graphs show regression lines. In addition, the rug plot on the horizontal axis gives the marginal distribution of the
predictor, in other words, it shows the actual distribution of the
values of that predictor in the data. Confidence bounds are indicated
by confidence bands using 95\% confidence limits. 
To show the effect of
each predictor in turn, the other predictors are adjusted to their
 means. The predictors are presented in the same order as in the table
 with the semantic predictors first and the other predictors following.

How do the predictors fare with respect to our predictions? The top
left-hand plot shows that the more frequent the relation of the target
compound occurs within all the compounds in the N1 family, the more
transparent is the first constituent rated. This corresponds to
prediction A4. The top right-hand plot shows that the more frequent
the synset associated with the second constituent is used in the N2
family, the less transparent the first constituent is perceived. This
corresponds to the prediction B6 and replicates the effect associated
with metaphoric constituent shifts in
\citet{BellandSchaefer:2013} with the help of synset proportions. The
next row shows the constituent frequency effects, with the effect
associated with N1 frequency in the middle left-hand plot and the
effect associated with N2 frequency in the middle right-hand
plot. Again, the effect stemming from the same constituent is
positively correlated with N1 transparency, while the effect stemming from the other constituent, in this case
N2, is negatively correlated with N1 transparency. The positive
correlation corresponds to our prediction A1. The negative correlation
is exactly the opposite of our prediction B5. This prediction was
again driven by a finding from \citet{BellandSchaefer:2013}. However,
at least for N1, this finding disappeared when using random
effects. One possible explanation for this finding is the same that we
already used for the effects of metaphoric shifts and synset
proportion of the other constituent: using the other constituent as a
foil might lead to relative judgements. If the other constituent is
very frequent, hence very expected, the constituent to be rated might
appear to be less expected and hence less transparent relative to the
other constituent. Finally, the bottom row shows the negative
correlation of N1 transparency with spelling ratio. This corresponds
to prediction D13. 
% Note, by the way, that spelling ratio never reached
% significance in the mixed effects models introduced in chapter
% \ref{cha:empirical-1}. I will return to this issue in section \ref{sec:spelling-ratio}.  


\subsection{N2 transparency}
\label{sec:bellschaefer2016n2}

The final model for N2 transparency is presented in
\tabref{tab:bellschaefer2016mixed_revisedN2}. Again, it departs
slightly from the random effects structure used in
\citet{BellandSchaefer:2016}, without in any way affecting the main
findings. The fixed effects are
presented graphically in \figref{fig:bellschaefer2016_model_N2}. 

% \begin{table}
% % # Model for N2 ARTICLE VERSION
% % step.cord.n2.lmer <- lmer (formula = litScoreN2 ~ spellingRatioCentred + logN2FreqCentred + logRelPropInN1FamCentred + (1 + spellingRatioCentred | workerID) +  (1 + logN2FreqCentred | workerID) + (1 | singBrUnderscore),  data = t2, REML = reml.lmerTest.private, control = lmerControl(optimizer = "Nelder_Mead"))
% % Fehler in lme4::lFormula(formula = litScoreN2 ~ spellingRatioCentred +  : 
% %   Objekt 'reml.lmerTest.private' nicht gefunden
% % step.cord.n2.lmer <- lmer (formula = litScoreN2 ~ spellingRatioCentred + logN2FreqCentred + logRelPropInN1FamCentred + (1 + spellingRatioCentred | workerID) +  (1 + logN2FreqCentred | workerID) + (1 | singBrUnderscore),  data = t2, control = lmerControl(optimizer = "Nelder_Mead"))
% % summary(step.cord.n2.lmer)
% % Linear mixed model fit by REML t-tests use Satterthwaite approximations to
% %   degrees of freedom [lmerMod]
% % Formula: 
% % litScoreN2 ~ spellingRatioCentred + logN2FreqCentred + logRelPropInN1FamCentred +  
% %     (1 + spellingRatioCentred | workerID) + (1 + logN2FreqCentred |  
% %     workerID) + (1 | singBrUnderscore)
% %    Data: t2
% % Control: lmerControl(optimizer = "Nelder_Mead")

% % REML criterion at convergence: 6941.7

% % Scaled residuals: 
% %     Min      1Q  Median      3Q     Max 
% % -4.2941 -0.4710  0.0683  0.4841  4.4891 

% % random effects:
% %  groups           name                 variance std. dev. Corr
% %  workerID         (intercept)          0.056162 0.23699      
% %                   spellingRatioCentred 0.002847 0.05336  1.00
% %  workerID.1       (intercept)          0.003501 0.05917      
% %                   logN2FreqCentred     0.012510 0.11185  1.00
% %  singBrUnderscore (intercept)          2.009099 1.41743      
% %  residual                              0.953022 0.97623      
% % number of obs. 2328, groups:  workerID, 108; singBrUnderscore, 81

% % fixed effects:
% %                          estimate std. error       df t value pr(>|t|)    
% % (intercept)               3.09783    0.16357 82.40000  18.938  < 2e-16 ***
% % spellingRatioCentred     -0.18680    0.08969 77.86000  -2.083   0.0406 *  
% % logN2FreqCentred          0.68191    0.14249 78.74000   4.786 7.83e-06 ***
% % logRelPropInN1FamCentred  0.45301    0.17608 77.00000   2.573   0.0120 *  
% % ---
% % Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

% % Correlation of Fixed Effects:
% %             (Intr) spllRC lgN2FC
% % spllngRtCnt -0.067              
% % lgN2FrqCntr -0.127  0.294       
% % lgRlPrIN1FC  0.049  0.044  0.050

% \begin{tabular}{lllll}
% \multicolumn{4}{l}{\textbf{random effects:}}\\
%  \textbf{groups}     &\textbf{name}       &\textbf{variance}&\textbf{std. dev.} \\%&Corr\\ 
%  workerID        &(intercept)         &0.056162&0.23699\\      
%                  &spellingRatioCentred&0.002847&0.05336\\  %1.00
%  workerID.1      &(intercept)         &0.003501&0.05917\\      
%                  &logN2FreqCentred    &0.012510&0.11185\\  %1.00
%  singBrUnderscore&(intercept)         &2.009099&1.41743\\      
%  residual        &                    &0.953022&0.97623 \\     
% \multicolumn{4}{l}{number of obs. 2328, groups:  workerID, 108; singBrUnderscore, 81}
  
% \end{tabular}
% \vspace*{1ex}

% \begin{tabular}[h]{lllllll}
% \multicolumn{7}{l}{\textbf{fixed effects:}}\\
% % &&&&&\\
%               &estimate& std. error   &    df& t value &pr($>|t|$)\\    
% (intercept)             & 3.09783&   0.16357&82.40000& 18.938& $<$2e-16\\
% logRelPropInN1FamCentred& 0.45301&   0.17608&77.00000&  2.573&  0.0120\\
% logN2FreqCentred        & 0.68191&   0.14249&78.74000&  4.786&7.83e-06\\
% spellingRatioCentred    &-0.18680&   0.08969&77.86000& -2.083&  0.0406
% \end{tabular}
%   \caption{Final mixed effects model for transparency of the second constituent,
%     marginal R$^2$= 0.26, conditional R$^2$= 0.77}
%   \label{tab:bellschaefer2016mixed-constituent-2}
% \end{table}


% \begin{figure}[!htb]
% % \begin{figure}[H]
%   \centering
% \includegraphics[scale=.8,trim=40 50 60 70, clip]{/home/martin/Dropbox/statistics/habil-stat/bell-schaefer-2016_allEffects_modelN2_gridlayout.pdf}
%  % trim left lower right upper
%   \caption{Partial effects in the final model for N2 transparency}
% \label{fig:bellschaefer2016_model_N2}
% \end{figure}

\begin{table}[htb]
% N2 transparency bs2016 version with revised random effects structure
% habil.bs2016.n2.lmer <- lmer (formula = litScoreN2 ~ logRelPropInN1FamCentred + logN2FreqCentred + spellingRatioCentred +  (1 + spellingRatioCentred+ logN2FreqCentred | workerID) + (1 | singBrUnderscore),  data = t2, control = lmerControl(optimizer = "bobyqa"))
% summary(habil.bs2016.n2.lmer)
% Linear mixed model fit by REML t-tests use Satterthwaite approximations to
%   degrees of freedom [lmerMod]
% Formula: 
% litScoreN2 ~ logRelPropInN1FamCentred + logN2FreqCentred + spellingRatioCentred +  
%     (1 + spellingRatioCentred + logN2FreqCentred | workerID) +  
%     (1 | singBrUnderscore)
%    Data: t2
% Control: lmerControl(optimizer = "bobyqa")

% REML criterion at convergence: 6941.7

% Scaled residuals: 
%     Min      1Q  Median      3Q     Max 
% -4.2947 -0.4711  0.0694  0.4841  4.4890 

% random effects:
%  groups           name                 variance std. dev. Corr     
%  workerID         (intercept)          0.059691 0.24432           
%                   spellingRatioCentred 0.002849 0.05337  0.97     
%                   logN2FreqCentred     0.012532 0.11195  0.25 0.02
%  singBrUnderscore (intercept)          2.009065 1.41741           
%  residual                              0.953068 0.97625           
% number of obs. 2328, groups:  workerID, 108; singBrUnderscore, 81

% fixed effects:
%                          estimate std. error       df t value pr(>|t|)    
% (intercept)               3.09784    0.16357 82.40000  18.939  < 2e-16 ***
% logRelPropInN1FamCentred  0.45302    0.17608 77.01000   2.573   0.0120 *  
% logN2FreqCentred          0.68191    0.14249 78.74000   4.786 7.83e-06 ***
% spellingRatioCentred     -0.18673    0.08969 77.86000  -2.082   0.0406 *  
% ---
% Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

% Correlation of Fixed Effects:
%             (Intr) lRPIN1 lgN2FC
% lgRlPrIN1FC  0.049              
% lgN2FrqCntr -0.127  0.050       
% spllngRtCnt -0.067  0.044  0.294
\small
\begin{tabularx}{1\textwidth}{llrrrrr}\lsptoprule
\multicolumn{7}{l}{\textbf{random effects:}}\\
% \hspace*{-1.8cm}\begin{tabular}{lllll}
% \multicolumn{4}{l}{\textbf{random effects:}}\\
 {groups}     &{name}       &{variance}&\multicolumn{2}{l}{{std. dev.}}&& \\ \midrule %&Corr\\ 
 workerID        &(intercept)         &0.059691&\multicolumn{2}{l}{0.24432}&& \\%         
                 &spelling ratio&0.002849&\multicolumn{2}{l}{0.05337}&& \\%0.97     
                 &N2 frequency    &0.012532&\multicolumn{2}{l}{0.11195} &&\\%0.25 0.02
 singBrUnderscore&(intercept)         &2.009065&\multicolumn{2}{l}{1.41741}&& \\%         
 residual        &                    &0.953068&\multicolumn{2}{l}{0.97625} &&\\\tablevspace %         
\multicolumn{7}{l}{number of obs.: 2328, groups:  workerID, 108; singBrUnderscore, 81}\\[1ex]
%   
% \end{tabular}
% \vspace*{1ex}
% 
% \hspace*{-10cm}\begin{tabular}[h]{lllllll}
\multicolumn{7}{l}{\textbf{fixed effects:}}\\
% &&&&&\\
              &{estimate}& {std. error}   &    {df}& {t value} &{pr($>|t|$)}\\    
(intercept)             & 3.09784   &0.16357&82.40& 18.939& $<$ 2e-16\\
N1 relation proportion& 0.45302   &0.17608&77.01&  2.573&  0.0120\\
N2 frequency        & 0.68191   &0.14249&78.74&  4.786&7.83e-06\\
spelling ratio    &-0.18673   &0.08969&77.86& -2.082&  0.0406\\\lspbottomrule
\end{tabularx}
  \caption{Final mixed effects model for transparency of the second constituent,
    marginal R$^2$= 0.26, conditional R$^2$= 0.77}
  \label{tab:bellschaefer2016mixed_revisedN2}
% 0.2602486 0.7690760 
\end{table}

\begin{figure}[!htb]
% \begin{figure}[H]
  \centering
\includegraphics[scale=.6,trim=40 50 60 70, clip]{./figures/bell-schaefer-2016_allEffects_modelN2revised.pdf}
 % trim left lower right upper
  \caption{Partial effects in the final model for N2 transparency}
\label{fig:bellschaefer2016_model_N2}
\end{figure}


Table \ref{tab:bellschaefer2016mixed_revisedN2} is again divided
into a top half showing the random effects structure and a bottom half
showing the fixed effects. The random components are again grouped by
items and raters. And just as in the previous model, this model has random intercepts
for items. The random effects structure associated with the raters is different
than the one used in the previous model: while the intercept is
allowed to vary and the slopes are adjusted for the effects of
spelling ratio, the random slopes for the effect of N1 frequency are replaced by  random
slopes for the effect of N2 frequency. While this is the
 justified result of our model selection procedure, it is not totally
 straightforward in its interpretation. After all, N2 effects played a
 role in the model for N1, too, and if the influence of the N2
 frequency is adjusted by rater for this model, why should this not
 be the case for the first model? There are at least 2 possible
 reasons. On the one hand, since rating transparency is a
 metalinguistic task, conscious focusing is involved, which might
 give more prominence to subtle aspects of the constituent that is being
 coded, resulting in adjusted slopes for N1 frequency when rating N1
 transparency and similarly effects for N2. On the other hand, recall
 that, different from the models discussed in the previous chapter,
 the ratings on N1 and N2 transparency used here include all ratings,
 not just those from raters who rated N1, N2, and the whole compound
 for a given item. Thus, the set of raters differs, and, given the
 very small adjustments, this difference alone could be responsible
 for the differences in the random effects structure.

The top left-hand plot in \figref{fig:bellschaefer2016_model_N2}
shows that the relation proportion in the N1 constituent family, that
is, the number of compound types in the N1 family that share the
relation encoded in the target compound, is positively correlated with
N2 transparency. This corresponds to our prediction B8, that is, the
more accessible the relation in the target compound, the greater the
overall transparency, including the transparency of the other
constituent. The 2 non-semantic predictors presented in the second
row, N2 frequency on the left-hand side and spelling ratio on the
right-hand side, both point in the expected directions: N2 frequency is positively correlated with N2 transparency, and spelling ratio is negatively correlated with N2 transparency, again conforming
to predictions A1 and D13 respectively.     

\subsection{Whole compound transparency}
\label{sec:bellschaefer2016wholecompound}

This section presents 2 models of whole compound transparency. The
first model for N2 transparency, the final model including N2 synset proportion, is presented in
\tabref{tab:bellschaefer2016mixed-whole-1}. The fixed effects are
presented graphically in
\figref{fig:bellschaefer2016_model_compound1}. The random effects include
the random effects for items, as well as by-rater random
intercepts and random slopes for the effect of spelling ratio.
\begin{table}
% # Compound Transparency: two models
% # table 5 model
% step.cord.nn.lmer <- lmer(formula = litScoreN1N2 ~ spellingRatioCentred + logN1FreqCentred + logSynsetPropInN2FamCentred + logRelPropInN1FamCentred +  (1 + spellingRatioCentred | workerID) + (1 | singBrUnderscore), data = ttot, REML = reml.lmerTest.private, control = lmerControl(optimizer = "bobyqa"))
% Fehler in lme4::lFormula(formula = litScoreN1N2 ~ spellingRatioCentred +  : 
%   Objekt 'reml.lmerTest.private' nicht gefunden
% step.cord.nn.lmer <- lmer(formula = litScoreN1N2 ~ spellingRatioCentred + logN1FreqCentred + logSynsetPropInN2FamCentred + logRelPropInN1FamCentred +  (1 + spellingRatioCentred | workerID) + (1 | singBrUnderscore), data = ttot, control = lmerControl(optimizer = "bobyqa"))
% summary(step.cord.nn.lmer)
% Linear mixed model fit by REML t-tests use Satterthwaite approximations to
%   degrees of freedom [lmerMod]
% Formula: 
% litScoreN1N2 ~ spellingRatioCentred + logN1FreqCentred + logSynsetPropInN2FamCentred +  
%     logRelPropInN1FamCentred + (1 + spellingRatioCentred | workerID) +  
%     (1 | singBrUnderscore)
%    Data: ttot
% Control: lmerControl(optimizer = "bobyqa")

% REML criterion at convergence: 6810.6

% Scaled residuals: 
%     Min      1Q  Median      3Q     Max 
% -3.8861 -0.6040  0.0733  0.5925  4.3873 

% random effects:
%  groups           name                 variance std. dev. Corr
%  workerID         (intercept)          0.150915 0.38848      
%                   spelling ratio 0.004018 0.06339  0.91
%  singBrUnderscore (intercept)          1.145611 1.07033      
%  residual                              0.930349 0.96455      
% number of obs. 2307, groups:  workerID, 119; singBrUnderscore, 81

% fixed effects:
%                             estimate std. error       df t value pr(>|t|)    
% (intercept)                  2.83314    0.12886 95.57000  21.986  < 2e-16 ***
% spellingRatioCentred        -0.27239    0.06674 77.83000  -4.081 0.000108 ***
% logN1FreqCentred             0.52198    0.07116 75.97000   7.336 2.04e-10 ***
% logSynsetPropInN2FamCentred -0.25046    0.12056 76.10000  -2.077 0.041134 *  
% logRelPropInN1FamCentred     0.41104    0.13442 76.04000   3.058 0.003076 ** 
% ---
% Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

% Correlation of Fixed Effects:
%             (Intr) spllRC lgN1FC lSPIN2
% spllngRtCnt -0.002                     
% lgN1FrqCntr -0.028 -0.040              
% lgSynPIN2FC  0.019  0.205 -0.058       
% lgRlPrIN1FC  0.051  0.031  0.105  0.023
\small
\begin{tabularx}{.95\textwidth}{llrrrrr}\lsptoprule
\multicolumn{7}{l}{\textbf{random effects:}}\\
% \hspace*{-1.8cm}\begin{tabular}{lllll}
% \multicolumn{4}{l}{\textbf{random effects:}}\\
 {groups}     &{name}       &{variance}&\multicolumn{2}{l}{{std. dev.}}&& \\\midrule %&Corr\\ 
 workerID        & (intercept)         & 0.150915& \multicolumn{2}{l}{0.38848}&&\\      
                 & spelling ratio& 0.004018& \multicolumn{2}{l}{0.06339}&&\\  % 0.91
 singBrUnderscore& (intercept)         & 1.145611& \multicolumn{2}{l}{1.07033}&&\\      
 residual        &                     & 0.930349& \multicolumn{2}{l}{0.96455}&&\\\tablevspace      
\multicolumn{7}{l}{number of obs.: 2307, groups:  workerID, 119; singBrUnderscore, 81}\\[1ex]
%   
% \end{tabular}
% \vspace*{1ex}
% 
% \hspace*{-10cm}\begin{tabular}[h]{lllllll}
\multicolumn{7}{l}{\textbf{fixed effects:}}\\
% &&&&&\\
              &{estimate}& {std. error}   &    {df}& {t value} &{pr($>|t|$)}\\\midrule    
(intercept)                & 2.83314&   0.12886&95.57& 21.986& $<$ 2e-16\\
N1 relation proportion   & 0.41104&   0.13442&76.04&  3.058&0.003076\\
N2 synset proportion&-0.25046&   0.12056&76.10& -2.077&0.041134\\
N1 frequency           & 0.52198&   0.07116&75.97&  7.336&2.04e-10\\
spelling ratio       &-0.27239&   0.06674&77.83& -4.081&0.000108\\\lspbottomrule
\end{tabularx}
  \caption{Final mixed effects model for compound transparency,
    marginal R$^2$= 0.33, conditional R$^2$= 0.72}
  \label{tab:bellschaefer2016mixed-whole-1}
\end{table}

\begin{figure}[!htb]
% \begin{figure}[H]
  \centering
\includegraphics[scale=.6,trim=40 50 60 70, clip]{./figures/bell-schaefer-2016_allEffects_modelCompound_gridlayout.pdf}
 % trim left lower right upper
  \caption{Partial effects in the final model for compound transparency}
\label{fig:bellschaefer2016_model_compound1}
\end{figure}

The 4 significant fixed effects are shown in
\figref{fig:bellschaefer2016_model_compound1}. In accordance with our
prediction D11, the greater the N1 relation proportion, the more
transparent the whole compound is perceived to be. Note, however, that
N2 relation proportion is not a significant predictor in this
model. The second plot in the top row shows that the N2 synset
proportion is negatively correlated with perceived compound
transparency. This is unexpected, and I will come back to this point
below. The two plots in the bottom row show the non-semantic
predictors. N1 frequency is positively correlated with perceived
compound transparency, validating part of our prediction C9. Again,
the predicted effect of N2 frequency is not significant in our
model. Finally, in accordance with prediction D14, spelling ratio is
negatively correlated with perceived compound transparency.

How can the unpredicted behavior of N2 synset
proportion be explained? Recall that we predicted that both constituents' synset
proportions individually are 
positively correlated with the respective constituent's perceived
transparency (prediction A2) but negatively correlated with the
perceived transparency of the respective other constituent (prediction
A6). A likely explanation for the behavior with respect to the other
constituent is that the other constituent is used as a foil in judging
the transparency of the constituent under consideration, and we
already explained the findings concerning the metaphoric shifts in the
models described in the previous chapter this way. Based on this
finding and the constituent transparency related predictions, we
already predicted that the effect of synset proportion on whole
compound transparency is more muted (prediction D12). In the
constituent transparency models, we have only found an effect of N2
synset proportion on the perceived transparency of N1. While there is
the predicted negative correlation, I already pointed out that this effect is not found for N1 
when
re-running the models of \citet{BellandSchaefer:2013} with mixed
effects regression models. \enlargethispage{1\baselineskip}
All in
all it is surprising that sysnset proportion only occurs as a negative
predictor. This led us to consider whether or not this effect might
not be due to some other underlying factor not considered in our
model, and warrants a closer look at the N2 synset proportion
variable.

In our dataset, a high N2 synset proportion often arises in small N2
families. These families often  only have a single synset to
begin with, therefore the N2 synset proportion is maximally high, that
is, one. \is{compound measures!{family size}}
In contrast,
in large families the synset proportions are more varied, and the
families are rarely restricted to just one synset. Note also that the
family size puts a limit on how low the synset proportion can actually
get. Since the synset proportion is calculated by dividing the number
of compound types sharing the target synset by the number of compound
types in the constituent family, the family size determines how small
the proportion can possibly be. For example, if the family has 8 members, the lowest possible synset
proportion is 0.125. Contrast this with the lowest
synset proportion in our dataset, 0.006993007 for \emph{model} from
\emph{role model}, with an N2 family with 143 members. 
% cor.test(uniqueSynsetsSizes$synsetPropInN2Fam,uniqueSynsetsSizes$n2FamSize)

% 	Pearson's product-moment correlation

% data:  uniqueSynsetsSizes$synsetPropInN2Fam and uniqueSynsetsSizes$n2FamSize
% t = -1.8174, df = 79, p-value = 0.07295
% alternative hypothesis: true correlation is not equal to 0
% 95 percent confidence interval:
%  -0.40113146  0.01884558
% sample estimates:
%        cor 
% -0.2003282 
Because of the slight negative correlation between N2 family size and N2
synset proportion (the higher the family size, the lower the synset
ratio), we decided to test the effect of adding positional family sizes as
additional explanatory variables to the set of variables used in our
models (this slightly increases collinearity, c-number = 3.777). The
result is a model in which N2 family size in effect replaces N2 synset proportion. 
% EMAIL TO MELANIE (9.2.2016)
% Hi Mel, have to teach, here are my thoughts on the predictors, synset
% n2 at the bottom, talk to you in 2 hrs

% N1 predictors
% spelling ratio: the more lexicalized a compound is, the more opaque is
% N1. Expected, since lexicalization goes together with meaning
% specializations and meaning shifts that a) might make the meaning of
% N1 idiosyncratically specific in the contexts of compounds and b)
% might involve shifting the meaning of N1 to arrive at the meaning of
% the compound. Both often occur in the contexts of whole-compound
% shifts, for which we introduced the
% spelling ratio as a stand-in.

% frequency n1: the more frequent N1, the more transparent it is judged
% to be. Viewing frequency as one aspect of expectedness, this is full
% in line with our hypothesis that transparency corresponds to
% expectedness.

% relation proportion n1: the higher the proportion of the compound's
% relation in the modifiers family, the more transparent the
% constituent. This is expected, and shows that the compound context
% itself influences transparency judgements on the constituents. If
% Gagne & Spalding and Marelli and Luzatti are correct, then
% interpreting a compound always involves trying to compose its
% meaning. For this, the modifier is the starting point, leading to the
% selection of the most frequent relation for the modifier. If it turns
% out that a less frequent relation needs to be selected, the original
% assignment must be rejected. The expectations with regard to the
% semantic relation raised by the modifier are not met, and the modifier
% is consequently judged to be less transparent.

% frequency n2: the higher the frequency of n2, the less transparent
% n1. This is in contrast to Bell & Schäfer 2013, and we did not expect
% this result. One possible explanation is that when judging the
% transparency of one constituent, it is always implicitly compared to
% the other constituent. Thus, if the other constituent, in this case
% N2, is very frequent, and constituent frequency itself is connected to
% a constituent's perceived transparency, and N2 serves as a foil for
% judging N1, then the perceived transparency of N1 might be lower since
% the bar set by N2 is so high.

% synset proportion n2: the higher the synset proportion in n2, the less
% transparent n1 is judged. This is not expected, a similar explanation
% as for the frequency n2 effect might be possible, but see below for
% more discussion of the synset issue.

% N2 predictors

% frequency n2, spelling ratio: expected, in parallel to what we found
% for N1

% interaction between family size ratio N1 and relationship proporion N1
% this is in so far contrary to our expectations, as we hypothesized
% that both family size ratio N1 and the relationship proportion N1 in
% isolation would lead to higher perceived transparency of N2, the idea
% being that a more readily available semantic structure leads to
% seamless integration of the constituents, and thus to higher perceived
% semantic transparency. What the interaction shows is that relation
% proportion of N1 is only beneficial for the transparency of N2 if N1
% is a typical modifier, that is, if its family size ratio is high. In
% contrast, when N1 is an atypical modifier, the effect of relation
% proportion in N1 is not beneficial, in fact, it is slightly going in
% the other direction. One possible interpretation for this pattern
% could be that the relation proportion in the N1 modifier family is
% given more weight in calculating a compositional interpretation of the
% whole compound, involving integration of the meaning of the second
% constituent, when N1 is a typical modifier, reflecting a higher degree
% of confidence in the usefullness of the semantic relations associated
% with this noun in modifier position.

% no effect of frequency n1: unexpected; we hypothesized a positive
% effect; parallel to n1 transparency would be a negative effect. Points
% to a difference in the role of modifier and head.

% N1N2 predictors

% spelling ratio: the more lexicalized, the less transparent. This is
% fully expected, since we expect that lexicalization typically involves
% meaning shifts and meaning specializations, and that whole compound
% shifts are typically associated with a higher spelling ratio.

% interaction frequency N1 relation proportion N1
% That both predictors play a role for compound transparency is
% expected, since we assume that anything that makes a constituent more
% transparent should also make the whole compound more transparent. The
% interaction itself is not expected. What the interaction shows is that
% n1 frequency by itself leads already to high compound transparency.

% no effect of N2 frequency: not hypothesized, but apparently the
% beneficial effect of n2 frequency on n2 transparency and the
% detrimental effect of n2 frequency on n1 transparency cancel each
% other out in terms of whole compound transparency

% no effect of family size ratio N1: not hypothesized, but apparently
% the interaction of relation proportion N1 with frequency N1 is a
% better reflects whole compound transparency then the interaction of
% relation proportion N1 with family size ratio N1 which only plays a
% role for N2 transparency.

% synset propoartion in n2 family: the higher the synset proportion in
% the n2 family, the less transparent the compound is judged. Expected
% in so far as we expect the same effects that play a role for the
% constituents to play a role for whole compound transparency. However,
% the relative expectedness explanation given for n2 frequency on n1
% transparency does not seem plausible with regard to whole comound
% transparency.

% High synset proportions in our dataset reflect to quite different
% constellations: in our 22 compounds with only one single synset in the
% whole family, quite a number of the families is rather small (12 have
% 10 or less members, 9 5 or less, 14 have less then 15), or the family
% size is bigger, up to
% 146 items for mailing list. Ok, why should this matter?

% What is notable in the small families (below 15 items) with the single
% synsets is that
% 6(8) of them contains an n2 constituent that clearly seems to be
% metaphorically shifted or otherwise used differently then one would
% use them in isolation:
% agony_aunt  (cloud_nine)    spinning_jenny
%    night_owl         eye_candy
%  (silver_spoon)     cash_cow
%  nest_egg

% So, while not an explanation for the observed effect, we can at least
% note that capturing constituent shifts via wordnet senses within the
% compound families did not work out in these cases.

% Why is this effect detrimental to n1 transparency?

% For the low frequency cases:
% Note that in some cases (agony, spinning, eye, cash), the modifier
% alone suffices to induce/signal the shift of the following
% constituent, while n1 seems not to be shifted. Thus, metaphorically
% speaking, the modifier takes the blame for the shift and is demoted in
% transparency.

% For the high frequency cases (e.g. shirt, science, tower, student,
% teacher, firm, project, list): Here the foil idea makes sense: that
% is, these are large classes with one dominant synset, and very clear
% superset-subset relationships (every shirt is a shirt etc.). N1 can
% only loose in contrast.


% Why not an effect on n2 transparency?
% No effect on n2, because in the small families, high n2synset is
% detrimental, in the large it is benificial, so they cancel each other
% out.

% Why does synset n1 not play a role?
% The n1 families are in general much smaller, and the proportion of
% families with only one synset is much higher. In fact, half of the
% families (42 of 85) have only one synset, making it a quite useless
% predictor.

% EMAIL ENDE


This second model for compound transparency is shown in 
\tabref{tab:bellschaefer2016mixed-whole-2}, and its significant
predictors are graphically presented in 
\figref{fig:bellschaefer2016_model_compound-family-size}. Comparing the
fit of the previous model with this model via R's anova function
reveals that it is a significantly better model. However, the
difference is small: the second model explains one percentage point more
of the variance via its fixed effects. 

\begin{table}[htb]
% # table 6 model

% cord.nn.2.step <- lmer(formula = litScoreN1N2 ~ spellingRatioCentred + logN1FreqCentred +logRelPropInN1FamCentred + logPositionalFamilySizeN2AboveFourCentred + (1 + spellingRatioCentred | workerID) + (1 | singBrUnderscore),data = ttot,  control = lmerControl(optimizer = "bobyqa"))
% summary(cord.nn.2.step)
% Linear mixed model fit by REML t-tests use Satterthwaite approximations to
%   degrees of freedom [lmerMod]
% Formula: 
% litScoreN1N2 ~ spellingRatioCentred + logN1FreqCentred + logRelPropInN1FamCentred +  
%     logPositionalFamilySizeN2AboveFourCentred + (1 + spellingRatioCentred |  
%     workerID) + (1 | singBrUnderscore)
%    Data: ttot
% Control: lmerControl(optimizer = "bobyqa")

% REML criterion at convergence: 6808.4

% Scaled residuals: 
%     Min      1Q  Median      3Q     Max 
% -3.8706 -0.6030  0.0662  0.5903  4.3956 

% random effects:
%  groups           name                 variance std. dev. Corr
%  workerID         (intercept)          0.150796 0.38832      
%                   spellingRatioCentred 0.004011 0.06333  0.91
%  singBrUnderscore (intercept)          1.107061 1.05217      
%  residual                              0.930388 0.96457      
% number of obs. 2307, groups:  workerID, 119; singBrUnderscore, 81

% fixed effects:
%                                           estimate std. error       df t value
% (intercept)                                2.81222    0.12734 96.06000  22.084
% spellingRatioCentred                      -0.21449    0.06521 77.87000  -3.289
% logN1FreqCentred                           0.47065    0.07170 75.97000   6.564
% logRelPropInN1FamCentred                   0.38949    0.13259 76.04000   2.938
% logPositionalFamilySizeN2AboveFourCentred  0.25964    0.09793 76.01000   2.651
%                                           pr(>|t|)    
% (intercept)                                < 2e-16 ***
% spellingRatioCentred                       0.00151 ** 
% logN1FreqCentred                          5.75e-09 ***
% logRelPropInN1FamCentred                   0.00438 ** 
% logPositionalFamilySizeN2AboveFourCentred  0.00976 ** 
% ---
% Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

% Correlation of Fixed Effects:
%             (Intr) spllRC lgN1FC lRPIN1
% spllngRtCnt -0.018                     
% lgN1FrqCntr -0.009 -0.066              
% lgRlPrIN1FC  0.056  0.013  0.122       
% lgPsFSN2AFC -0.077  0.170 -0.225 -0.079
% >
\small
\begin{tabularx}{.95\textwidth}{llrrrrr}\lsptoprule
\multicolumn{7}{l}{\textbf{random effects:}}\\
% \hspace*{-1.8cm}\begin{tabular}{lllll}
% \multicolumn{4}{l}{\textbf{random effects:}}\\
 {groups}     &{name}       &{variance}&\multicolumn{2}{l}{{std. dev.}}&& \\\midrule   %&Corr\\ 
 workerID         &(intercept)          &0.150796& \multicolumn{2}{l}{0.38832}&&\\      
                  &spelling ratio &0.004011& \multicolumn{2}{l}{0.06333}&&\\  %0.91
 singBrUnderscore &(intercept)          &1.107061& \multicolumn{2}{l}{1.05217}&&\\      
 residual         &                     &0.930388& \multicolumn{2}{l}{0.96457}&&\\\tablevspace      
\multicolumn{7}{l}{number of obs.: 2307, groups:  workerID, 119; singBrUnderscore, 81}\\[1ex]
% \end{tabular}
% \vspace*{1ex}
% 
% \hspace*{-10cm}\begin{tabular}[h]{lllllll}
% \multicolumn{7}{l}{\textbf{fixed effects:}}\\
% &&&&&\\
              &{estimate}& {std. error}   &    {df}& {t value} &{pr($>|t|$)}\\\midrule    
(intercept)                              & 2.81222 &  0.12734&96.06& 22.084&$<$ 2e-16\\
N1 relation proportion                 & 0.38949 &  0.13259&76.04&  2.938&0.00438\\
N2 family size& 0.25964 &  0.09793&76.01&  2.651&0.00976\\
N1 frequency                         & 0.47065 &  0.07170&75.97&  6.564&5.75e-09\\
spelling ratio                     &-0.21449 &  0.06521&77.87& -3.289&0.00151\\\lspbottomrule
\end{tabularx}
  \caption{Final mixed effects model for compound transparency,
    including N2 positional family size as a predictor,
    marginal R$^2$= 0.34, conditional R$^2$= 0.72}
  \label{tab:bellschaefer2016mixed-whole-2}
\end{table}

\begin{figure}[htb]
% \begin{figure}[H]
  \centering
\includegraphics[scale=.6,trim=40 50 60 70, clip]{./figures/bell-schaefer-2016_allEffects_modelCompound2_gridlayout.pdf}
 % trim left lower right upper
  \caption{Partial effects in the final model for compound transparency, including N2 positional family size as a predictor}
\label{fig:bellschaefer2016_model_compound-family-size}
\end{figure}

The 3 predictors that reoccur in this model, N1 relation proportion,
N1 frequency, and spelling ratio, remain largely unchanged, differing
only very slightly in their magnitudes from the magnitudes of the
effects in the first compound transparency model. The effect of N2
family size is depicted in the top right-hand plot of 
\figref{fig:bellschaefer2016_model_compound-family-size}. In contrast to
N2 synset proportion, N2 family size is positively correlated with
perceived compound transparency. While we did not predict any effects
for family size per se, it is in line with the general logic of our
predictions in that a large N2 family raises the expectedness of a given
constituent to occur as the head of a compound. Note that the finding
that the other predictors remain largely unchanged is a first sign
that N2 family size and N2 synset proportion explain the same portion
of the variance. This will be confirmed below in Section
\ref{sec:bellandschaefer2016models}, when we look at the residuals of
the models in detail.

Note that we consequently also re-ran the model for N1 transparency
to check whether the N2 synset proportion effect would be replaced by
the effect of N2 family size. However, this is not the case. One
possible explanation for this is that the 2 variables in effect
compete for significance in our models, and that, given that they
explain a roughly similar part of the variation, small changes
might lead to one predictor being chosen instead of the other predictor. Since
the datasets are only partially produced by the same raters, this
alone might make a decisive difference. Another explanation is
that N2 synset proportion combines different underlying factors one of
which might play a role for N1 transparency. Note incidentally that at
least for small families synset proportion does not necessarily pick up anything
related to semantic shifts per se. Thus, \emph{agony aunt} is the only
member of its N2 family. Therefore the synset proportion is 1, although
\emph{agony} would count as metaphorically shifted in the coding
employed in Chapter \ref{cha:empirical-1}.

\subsection{The 2016 models: discussion and conclusion}
\label{sec:bs2016discussionandconclusion}

This section presented the models from
\citet{BellandSchaefer:2016}. Looking at all the 4 models, one can
first of all observe that out of the set of explanatory variables
considered (cf. Table \ref{tab:bs2016explanatory.variables}), the 2
measures assessing the likelihood of a given constituent to occur as
either the modifier or the head of the compound, family size ratio N1
and family size ratio N2, are not significant in any of the 4 models. For those explanatory variables
that are significant, it is noticeable that the variables that are
constituent specific usually only reach significance for either their
N1 or their N2 version, with the exception of the role of N1 and N2
constituent frequency for N1 transparency. 

As far as the general idea of compound transparency as a function of
the 2 constituent transparencies is concerned, we can note that the
first model for compound transparency looks like a combination of the
effects observed for N1 and N2 transparency. 
The 2 predictors that correlate with both the N1 and the N2
constituent transparency ratings in the
same direction, N1 relation proportion and spelling ratio, both re-appear in the
first (and also in the second) model for whole compound
transparency. In all models, N1 relation proportion is positively correlated
with transparency, and spelling ratio is negatively correlated with
semantic transparency. N2 frequency also emerges as a significant
predictor in both constituent transparency models. However, in the
model for N1 transparency it is negatively correlated with semantic
transparency, while in the model for N2 transparency it is positively
correlated with transparency. When it comes to whole compound
transparency, these opposing tendencies seem to cancel each other out and
N2 frequency does not emerge as a significant predictor. Finally, N2
synset proportion occurs only in the N1 but not in the N2 constituent transparency
model, correlating negatively with N1 transparency. This negative
correlation with transparency reoccurs in the model for whole
compound transparency. Note, however, that at least for the whole
compound, this predictor can be successfully replaced by N2 family
size, again a positively correlating predictor in line with the
general view of transparency as an expectancy driven phenomenon.

Going through the original list of predictions spelling out the
hypotheses for all of the variables used, it can be observed that 8 of them are,
albeit sometimes only partially, borne out by our models. In
particular, the role of N1 relation proportion as a positive correlate
of transparency in all 4 models shows that the attempt to reassess
the role of semantic relations in terms of constituent family based
expectancy payed off. In contrast, the synset proportions played a
role in only 2 of the 4 models, namely the model for N1 transparency and the first
model for compound transparency. However, N2 family
size is a better predictor for compound transparency,
apparently explaining the same portion (and a bit more) of the
variation. There are at least 3 factors that might explain why synset
proportion played such a small role in
our models. Firstly, in contrast to the semantic relations in
compounds which are bound to this specific construction type, the
constituents also occur with different usages, that is, different
synsets, outside of compounds. This distribution might play an
important role for perceived transparency. Unfortunately, we had no way of
assessing this distribution. Secondly, the number of synsets
does not differentiate between the constituent families as
much as the relation proportions do. Thus, for the 81 compound types
from the Reddy et al. dataset, relation proportion yields 56 and 72
distinct proportions for the N1 and the N2 families respectively,
compared to 41 and 56 for the N1 and N2 synset proportions. Thirdly,
the synsets available for the constituents might have been too
idiosyncratic in the way in which they distinguished between different meanings
for the constituents (see the description of the WordNet
senses in Section \ref{sec:wordnet} and also my remarks on cases were
it was difficult to understand or apply the WordNet distinctions in
Section \ref{sec:coding-the-senses}).  

% And a final remark: note that spelling ratio played the predicted role
% in all of the 4 models, although it did not become a significant
% predictor in the mixed effects models presented in chapter
% \ref{empirical-2}. After re-modeling the models discussed in this
% section with a cleaned dataset in section
% \ref{sec:bellandschaefer2016models}, I will come back to this issue in
% section \ref{sec:spelling-ratio}.

\section{Re-modeling \citet{BellandSchaefer:2016}}
\label{sec:bellandschaefer2016_new_models}

If we re-examine the models proposed in \citet{BellandSchaefer:2016},
one particular issue that signals room for improvement is the
distribution of the residuals. 
Below, the standardized residuals for all 4 models discussed in the previous section are visualized in 2 ways: plotted against the fitted
values and in Q-Q plots.
\figref{fig:bellschaefer2016_model_constituent_residuals}
shows the plots for the 2 models for constituent transparency. 

\begin{figure}[!htb]
% \begin{figure}[H]
  \centering
\includegraphics[scale=.55,trim=10 15 0 10, clip]{./figures/bell-schaefer-2016_constituent-residuals.pdf}
 % trim left lower right upper
  \caption{Standardized residuals of the models for constituent transparency. The plots for
the N1 transparency model are shown on the left-hand side, the
plots for the N2 transparency model on the right-hand
side.}
\label{fig:bellschaefer2016_model_constituent_residuals}
\end{figure}

\pagebreak[4]
The top row shows plots of the standardized residuals against the
fitted values. The 2 horizontal lines mark the $\pm$ 2.5 region. The bottom row shows Q-Q plots of the
standardized residuals against the normal distribution. The plots for
the N1 transparency model are shown on the left-hand side, while the
plots for the N2 transparency model are shown on the right-hand
side. The plots show very clear departures of the residuals
from the normal distribution. Both models have problems predicting the
high and the low ratings on the Likert scale. 

% \enlargethispage{1\baselineskip}
\pagebreak[4]
\figref{fig:bellschaefer2016_model_compound_residuals}
shows plots for the residuals of the 2 models for compound
transparency. Again, the top row shows the fitted values against the
standardized residuals, and the bottom row shows the Q-Q plots. On the
left-hand side are the plots for the first model for compound
transparency which includes N2 synset proportion as a predictor. On
the right-hand side are the plots for the second model of compound
transparency, in which N2 synset proportion was replaced by N2 family size.

\begin{figure}[!htb]
% \begin{figure}[H]
  \centering
\includegraphics[scale=.55,trim=10 15 0 10, clip]{./figures/bell-schaefer-2016_compounds-residuals.pdf}
 % trim left lower right upper
  \caption{Standardized residuals in the models for compound transparency. The plots for
the compound transparency model including N2 synset proportion are shown on the left-hand side. The
plots for the compound transparency model including N2 family size instead are shown on the right-hand
side.}
\label{fig:bellschaefer2016_model_compound_residuals}
\end{figure}

\pagebreak[4]
Note that the distribution of the residuals is extremely similar in
both models. Apart from that, the residuals depart less from normality
than those for the constituent transparency models, but still
noticeably so, again showing difficulties of the models in predicting
the high and low ratings respectively.

In all 4 cases, the break in continuity 
outside of the $\pm$ 2.5 range points to outliers in the data. 
The existence of outliers in the data is not surprising, given that the outlier trimming procedure used by \citet{Reddyetal:2011} applied trimming only to the contributions of a
subset of raters (see Chapter \ref{cha:modPrevious}, Section
\ref{sec:Reddyetal2011sum}). Using the same $\pm$1.5 deviation from the mean cut-off point as
previously for the models run on cleaned data in Chapter
\ref{cha:empirical-1} (see Section \ref{sec:bell-schaefer-2013-model1-diagnostics:Model1}), the distribution of the residuals changes as
shown in \figref{fig:bellschaefer2016_clean_models_residuals}.

\begin{figure}[!htb]
% \begin{figure}[H]
  \centering
\includegraphics[scale=.5,trim=10 15 0 10, clip]{./figures/bell-schaefer-2016_cleaned-residuals-Q-Q.pdf}
 % trim left lower right upper
  \caption{Standardized residuals for the 4 models in \citet{BellandSchaefer:2016} run on trimmed data}
\label{fig:bellschaefer2016_clean_models_residuals}
\end{figure}
\pagebreak[3]
\figref{fig:bellschaefer2016_clean_models_residuals} shows the Q-Q
plots of the standardized residuals against the normal distribution,
with the plots for the constituent transparency models in the top row
and the plots for the compound transparency models in the bottom
row. Within the first row, the residuals for the model of N1 transparency are shown on the left-hand
side, those for the N2 model on the right-hand side. At the bottom,
the residuals for the model including the N2 synsets are shown on the
left. The residuals for the model including the N2 family size are
shown on the right-hand side. 
As the 4 plots show, trimming the data by using the word sense
specific means results in residuals that are, in their majority,
closer to the normal distribution than before. At the same
time, there are in all plots, most noticeably in the plots of the
residuals from the constituent transparency models,
several strings of standardized residuals that are cut off from the main trend,
exhibiting very large values. What caused this? Careful inspection of
the residuals reveals that in almost all cases the existence of
ratings on either of the 2 senses of a given compound is responsible
for the outliers. Recall that whereas the models discussed in Chapter
\ref{cha:empirical-1} are all word-sense specific, the models
discussed here are item specific. That is, the semantic annotation did
not take different interpretations of the same compound into
account, but in all cases was based on what I believed to be the
standard interpretation of the compound. Due to this procedure, the
models cannot do justice to differences in the ratings that result
from the raters actually rating different word senses of one and the
same item. The effect of the trimming of the data was to bring out
this difference more clearly, since the trimming was done on the
individual compound senses, not on the items. For the final set of
models to be discussed, I reduced the dataset again by taking out all ratings that yield standardized residuals
exceeding the $\pm$2.5 range. This procedure eliminates many of those ratings which
depart from the models' predictions because the raters apparently used different
meanings of the compounds than the meanings used by me in annotating
the data and by other raters in rating the data. Quite
expectedly, this results in models with standardized residuals closer to
the normal distribution, cf. \figref{fig:bellschaefer2016_clean_models_noOutliers_residuals}.   
However, not only the standardized residuals, also the models
themselves change, particular those for constituent transparency. 


\begin{figure}[p]
  \centering
%   \includegraphics[scale=.4,trim=15 10 0 20, clip]{./figures/bell-schaefer-2016_noOutliers-cleaned-residuals-Q-Q.pdf}
\includegraphics[scale=.55,trim=10 15 0 10, clip]{./figures/bell-schaefer-2016_noOutliers-cleaned-residuals-Q-Q.pdf}
 % trim left lower right upper
  \caption{Standardized residuals in the models run on the datasets that were cleaned in a 2-step process. First, the datasets were
    trimmed using deviations from the mean ratings. Second, remaining outliers were removed by excluding those ratings that yielded standardized residuals
exceeding the $\pm$2.5 range in the models run on the trimmed dataset.}
\label{fig:bellschaefer2016_clean_models_noOutliers_residuals}
\end{figure}
% \clearpage
% \afterpage{\clearpage}
\pagebreak[4]
\subsection{New models for constituent transparency }
\label{sec:new-constituent-transparency}

Using the same random effect structure and the same fixed effects in
the model specification for the cleaned data leads to one of the
originally 5 fixed effects to become insignificant. Eliminating this
predictor, N2 synset proportion, leads to the model shown in \tabref{tab:bs2016_N1_clean_final}. The fixed effects are presented graphically in \figref{fig:bs2016_N1_final}.
\begin{table}[!htb]
% # Linear mixed model fit by REML t-tests use Satterthwaite approximations to
% #   degrees of freedom [lmerMod]
% # Formula: 
% # litScoreN1 ~ logRelPropInN1FamCentred + logN1FreqCentred + logN2FreqCentred +  
% #     spellingRatioCentred + (1 + spellingRatioCentred + logN1FreqCentred |  
% #     workerID) + (1 | singBrUnderscore)
% #    Data: clean.test.noOutliers
% # Control: lmerControl(optimizer = "optimx", optCtrl = list(method = "nlminb"))
% # 
% # REML criterion at convergence: 3928
% # 
% # Scaled residuals: 
% #     Min      1Q  Median      3Q     Max 
% # -3.5031 -0.6738  0.1492  0.5288  4.0220 
% # 
% # random effects:
% #  groups           name                 variance  std. dev. Corr       
% #  workerID         (intercept)          0.0231369 0.15211             
% #                   spellingRatioCentred 0.0003234 0.01798   0.90      
% #                   logN1FreqCentred     0.0044793 0.06693  -0.40  0.05
% #  singBrUnderscore (intercept)          2.2179216 1.48927             
% #  residual                              0.3101274 0.55689             
% # number of obs. 2030, groups:  workerID, 112; singBrUnderscore, 81
% # 
% # fixed effects:
% #                          estimate std. error       df t value pr(>|t|)    
% # (intercept)               2.83970    0.16900 77.81000  16.803  < 2e-16 ***
% # logRelPropInN1FamCentred  0.43872    0.18492 75.89000   2.372  0.02020 *  
% # logN1FreqCentred          0.70623    0.09962 77.04000   7.090 5.61e-10 ***
% # logN2FreqCentred         -0.31424    0.15035 75.94000  -2.090  0.03997 *  
% # spellingRatioCentred     -0.27024    0.09380 76.01000  -2.881  0.00515 ** 
% # ---
% # Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
% # 
% # Correlation of Fixed Effects:
% #             (Intr) lRPIN1 lgN1FC lgN2FC
% # lgRlPrIN1FC  0.049                     
% # lgN1FrqCntr -0.008  0.099              
% # lgN2FrqCntr -0.131  0.032 -0.173       
% # spllngRtCnt -0.078  0.036 -0.080  0.306
% r.squaredGLMM(habil.bs2016.n1.noOutliers.noSynset.clean.lmer)
% #       R2m       R2c 
% # 0.4024075 0.9277412 
% anova(habil.bs2016.n1.noOutliers.noSynset.clean.lmer,habil.bs2016.n1.noOutliers.clean.lmer)
% #        Df    AIC    BIC  logLik deviance  Chisq Chi Df pr(>Chisq)  
% # object 13 3942.8 4015.8 -1958.4   3916.8                           
% # ..1    14 3941.1 4019.7 -1956.5   3913.1 3.7292      1    0.05347 .
% # ---
% # Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
\small
\begin{tabularx}{.95\textwidth}{llrrrrr}\lsptoprule
\multicolumn{7}{l}{\textbf{random effects:}}\\
% \hspace*{-2.3cm}\begin{tabular}{lllll}
% \multicolumn{4}{l}{\textbf{random effects:}}\\
 {groups}     &{name}       &{variance}&\multicolumn{2}{l}{{std. dev.}}&& \\\midrule   %&Corr\\ 
workerID        &(intercept)         &0.0231369&\multicolumn{2}{l}{0.15211}&&\\%            
                &spelling ratio&0.0003234&\multicolumn{2}{l}{0.01798}&&\\%  0.90      
                &N1 frequency    &0.0044793&\multicolumn{2}{l}{0.06693}&&\\% -0.40  0.05
singBrUnderscore&(intercept)         &2.2179216&\multicolumn{2}{l}{1.48927}&&\\%            
residual        &                    &0.3101274&\multicolumn{2}{l}{0.55689}&&\\\tablevspace  %            
\multicolumn{7}{l}{number of obs.: 2030, groups:  workerID, 112; singBrUnderscore, 81}\\[1ex]
% \end{tabular}
% \vspace*{1ex}
% 
% \hspace*{-10cm}\begin{tabular}[h]{lllllll}
\multicolumn{7}{l}{\textbf{fixed effects:}}\\
              &{estimate}& {std. error}  &    {df}& {t value} &{pr($>|t|$)}\\\midrule    
(intercept)             & 2.83970  & 0.16900&77.81& 16.803& $<$ 2e-16\\%***
N1 relation proportion& 0.43872  & 0.18492&75.89&  2.372& 0.02020\\%*  
N1 frequency        & 0.70623  & 0.09962&77.04&  7.090&5.61e-10\\%***
N2 frequency        &-0.31424  & 0.15035&75.94& -2.090& 0.03997\\%*  
spelling ratio    &-0.27024  & 0.09380&76.01& -2.881& 0.00515\\\lspbottomrule%** 
\end{tabularx}

  \caption{Model for N1 transparency, using the cleaned dataset with
    outliers removed. Marginal R$^2$ = 0.40, conditional R$^2$ = 0.93}
  \label{tab:bs2016_N1_clean_final}
\end{table}

\begin{figure}[p]
% \begin{figure}[H]
  \centering
\includegraphics[scale=.55,trim=-20 110 50 110, clip]{./figures/bell-schaefer-2016_modelN1_clean_noOutliers.pdf}
 % trim left lower right upper
  \caption{Fixed effects in the final model for N1 transparency, using the trimmed dataset with outliers removed}
\label{fig:bs2016_N1_final}
\end{figure}

Besides the missing predictor N2 synset proportion, the fixed effects
are very similar to those in the original model,
cf. \tabref{tab:bellschaefer2016mixed-revised-N1}. The magnitude of
the positive correlation of N1 relation proportion is slightly higher,
whereas the magnitude of the negative correlation due to the spelling
ratio is slightly lower. The other 2 effects remain almost
unchanged. Note that the higher R$^2$ values are to be expected given
that I removed the outliers from the data.

\pagebreak[4]
The result of using the same model specification but the cleaned data
in modeling N2 transparency is shown in \tabref{tab:bs2016_N2_clean_final}. The fixed effects
are graphically presented in \figref{fig:bs2016_N2_final}.

\begin{table}[htb]
% Linear mixed model fit by REML t-tests use Satterthwaite approximations to
%   degrees of freedom [lmerMod]
% Formula: litScoreN2 ~ logRelPropInN1FamCentred + logN2FreqCentred + (1 +  
%     logN2FreqCentred | workerID) + (1 | singBrUnderscore)
%    Data: clean.N2.NoOutliers
% Control: lmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e+06))

% REML criterion at convergence: 3980.8

% Scaled residuals: 
%      Min       1Q   Median       3Q      Max 
% -2.99650 -0.52777  0.09861  0.50866  3.12627 

% random effects:
%  groups           name             variance std. dev. Corr 
%  workerID         (intercept)      0.012835 0.11329       
%                   logN2FreqCentred 0.008178 0.09043  -0.20
%  singBrUnderscore (intercept)      2.586534 1.60827       
%  residual                          0.308966 0.55585       
% number of obs. 2075, groups:  workerID, 108; singBrUnderscore, 81

% Fixed effects:
%                          estimate std. error      df t value pr(>|t|)    
% (intercept)                3.1158     0.1813 79.0300  17.188  < 2e-16 ***
% logRelPropInN1FamCentred   0.5154     0.1984 77.9500   2.598   0.0112 *  
% logN2FreqCentred           0.8103     0.1530 78.9200   5.295 1.04e-06 ***
% ---
% Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

% Correlation of Fixed Effects:
%             (Intr) lRPIN1
% lgRlPrIN1FC  0.054       
% lgN2FrqCntr -0.116  0.038
% r.squaredGLMM(habil.bs2016.n2.noSpelling.noOutliers.clean.lmer)
% #       R2m       R2c 
% # 0.2751319 0.9232848 
\small
\begin{tabularx}{.95\textwidth}{llrrrrr}\lsptoprule
\multicolumn{7}{l}{\textbf{random effects:}}\\
% \hspace*{-2.3cm}\begin{tabular}{lllll}
% \multicolumn{4}{l}{\textbf{random effects:}}\\
 {groups}     &{name}       &{variance}&\multicolumn{2}{l}{{std. dev.}}&& \\\midrule   %&Corr\\ 
 workerID        &(intercept)     &0.012835&\multicolumn{2}{l}{0.11329}&&\\      
                 &N2 frequency&0.008178&\multicolumn{2}{l}{0.09043}&&\\ % -0.20
 singBrUnderscore&(intercept)     &2.586534&\multicolumn{2}{l}{1.60827}&&\\      
 residual        &                &0.308966&\multicolumn{2}{l}{0.55585}&&\\\tablevspace      
\multicolumn{7}{l}{number of obs.: 2075, groups:  workerID, 108; singBrUnderscore, 81}\\[1ex]
% \end{tabular}
% \vspace*{1ex}
% 
% \hspace*{-10cm}\begin{tabular}[h]{lllllll}
\multicolumn{7}{l}{\textbf{fixed effects:}}\\
              &{estimate}& {std. error}   &    {df}& {t value} &{pr($>|t|$)}\\\midrule    
(intercept)              & 3.1158   & 0.1813&79.03& 17.188& $<$ 2e-16\\
N1 relation proportion & 0.5154   & 0.1984&77.95&  2.598&  0.0112\\
N2 frequency         & 0.8103   & 0.1530&78.92&  5.295&1.04e-06\\\lspbottomrule
\end{tabularx}

  \caption{Model for N2 transparency, using the cleaned dataset with
    outliers removed. Marginal R$^2$ = 0.28, conditional R$^2$ = 0.92}
  \label{tab:bs2016_N2_clean_final}
\end{table}
% \pagebreak[4]
Just as in the new N1 transparency model, the new model for N2
transparency reduces the number of significant
predictors: spelling ratio is not significant anymore, leaving the 2
predictors N1 relation proportion and N1 frequency.  Note that since
spelling ratio is not a significant fixed effect anymore, I also
removed the corresponding random slope specification from the random
part of the model specification.

% The fixed effects are presented graphically in \figref{fig:bs2016_N2_final}.
\begin{figure}[htb]
% \begin{figure}[H]
  \centering
\includegraphics[scale=.45,trim=20 30 50 30, clip]{./figures/bell-schaefer-2016_modelN2_clean_noOutliers.pdf}
 % trim left lower right upper
  \caption{Fixed effects in the final model for N2 transparency, using the trimmed dataset with outliers removed}
\label{fig:bs2016_N2_final}
\end{figure}

Just as in the previous model for N2 transparency, both remaining
fixed effects are positively correlated with N2 transparency. In both
cases, the magnitudes of the effects are slightly boosted.

% \pagebreak[4]
\subsection{New models for compound transparency}
\label{sec:new-compound-transparency}

The 2 new models for compound transparency are shown in \tabref{tab:bellschaefer2016whole_clean-1}
and \tabref{tab:bellschaefer2016whole_clean-2}. Both models are
very similar to the original models.
In contrast to the models for constituent transparency, the fixed
effects in both models remain the same as before.

\begin{table}[htb]
% summary(bs2016.n1n2.N2synset.noOutliers.clean.lmer)
% Linear mixed model fit by REML t-tests use Satterthwaite approximations to
%   degrees of freedom [lmerMod]
% Formula: 
% litScoreN1N2 ~ logRelPropInN1FamCentred + logSynsetPropInN2FamCentred +  
%     logN1FreqCentred + spellingRatioCentred + (1 + spellingRatioCentred |  
%     workerID) + (1 | singBrUnderscore)
%    Data: clean.N1N2.No.Outliers
% Control: lmerControl(optimizer = "bobyqa")

% REML criterion at convergence: 4422.1

% Scaled residuals: 
%     Min      1Q  Median      3Q     Max 
% -3.4666 -0.7410  0.1228  0.6596  3.4575 

% random effects:
%  groups           name                 variance std. dev. Corr
%  workerID         (intercept)          0.043502 0.20857      
%                   spellingRatioCentred 0.001939 0.04404  0.84
%  singBrUnderscore (intercept)          1.506764 1.22750      
%  residual                              0.420064 0.64812      
% number of obs. 2005, groups:  workerID, 116; singBrUnderscore, 81

% fixed effects:
%                             estimate std. error       df t value pr(>|t|)    
% (intercept)                  2.80437    0.13991 80.92000  20.045  < 2e-16 ***
% logRelPropInN1FamCentred     0.44567    0.15283 75.95000   2.916 0.004656 ** 
% logSynsetPropInN2FamCentred -0.27853    0.13709 76.04000  -2.032 0.045671 *  
% logN1FreqCentred             0.56859    0.08091 75.90000   7.028 7.83e-10 ***
% spellingRatioCentred        -0.27261    0.07560 76.69000  -3.606 0.000551 ***
% ---
% Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

% Correlation of Fixed Effects:
%             (Intr) lRPIN1 lSPIN2 lgN1FC
% lgRlPrIN1FC  0.054                     
% lgSynPIN2FC  0.020  0.023              
% lgN1FrqCntr -0.030  0.105 -0.058       
% spllngRtCnt -0.027  0.031  0.206 -0.040
% r.squaredGLMM(bs2016.n1n2.N2synset.noOutliers.clean.lmer)
% #       R2m       R2c 
% # 0.3976001 0.8720364 

\small
\begin{tabularx}{1\textwidth}{llrrrrr}\lsptoprule
\multicolumn{7}{l}{\textbf{random effects:}}\\
% \hspace*{-1.8cm}\begin{tabular}{lllll}
% \multicolumn{4}{l}{\textbf{random effects:}}\\
 {groups}     &{name}&{variance}&\multicolumn{2}{l}{{std. dev.}}&& \\\midrule  %&Corr 
workerID         &(intercept)         &0.043502&\multicolumn{2}{l}{0.20857}&&\\      
                 &spelling ratio&0.001939&\multicolumn{2}{l}{0.04404}&&\\  %0.84
 singBrUnderscore&(intercept)         &1.506764&\multicolumn{2}{l}{1.22750}&&\\      
 residual        &                    &0.420064&\multicolumn{2}{l}{0.64812}&&\\\tablevspace      
 \multicolumn{7}{l}{number of obs.: 2005, groups:  workerID, 116; singBrUnderscore, 81}\\[1ex]
% \end{tabular}
% \vspace*{1ex}
% 
% \hspace*{-10cm}\begin{tabular}[h]{lllllll}
\multicolumn{7}{l}{\textbf{fixed effects:}}\\
% &&&&&\\
              &{estimate}& {std. error}   &    {df}& {t value} &{pr($>|t|$)}\\\midrule    
(intercept)                 & 2.80437 &  0.13991&80.92& 20.045& $<$ 2e-16\\
N1 relation proportion    & 0.44567 &  0.15283&75.95&  2.916&0.004656\\
N2 synset proportion &-0.27853 &  0.13709&76.04& -2.032&0.045671\\
N1 frequency            & 0.56859 &  0.08091&75.90&  7.028&7.83e-10\\
spelling ratio        &-0.27261 &  0.07560&76.69& -3.606&0.000551\\\lspbottomrule
\end{tabularx}
  \caption{Final mixed effects model for compound transparency,
    including N2 synset proportion as a predictor,
    marginal R$^2$= 0.40, conditional R$^2$= 0.87}
  \label{tab:bellschaefer2016whole_clean-1}
\end{table}
% \pagebreak[4]
In the compound transparency model including the N2 synset proportion, cf.
\tabref{tab:bellschaefer2016whole_clean-1}, the 2 semantic predictors, N1
relation proportion and N2 synset proportion, are again correlated with
compound transparency. And just as before, N1
relation proportion is positively correlated with compound
transparency, and N2 synset proportion is
negatively correlated with compound transparency. Both are slightly
larger in magnitude than in the original model.
% \enlargethispage{1\baselineskip}
In contrast, both
non-semantic predictors, namely the positively correlated N1 frequency and
the negatively correlated spelling ratio, are smaller in
magnitude, although the former only slightly so.

\begin{table}[htb]
% summary(bs2016.n1n2.N2famsize.noOutliers.clean.lmer)
% Linear mixed model fit by REML t-tests use Satterthwaite approximations to
%   degrees of freedom [lmerMod]
% Formula: 
% litScoreN1N2 ~ logRelPropInN1FamCentred + logPositionalFamilySizeN2AboveFourCentred +  
%     logN1FreqCentred + spellingRatioCentred + (1 + spellingRatioCentred |  
%     workerID) + (1 | singBrUnderscore)
%    Data: clean.N1N2.No.Outliers
% Control: lmerControl(optimizer = "bobyqa")

% REML criterion at convergence: 4420

% Scaled residuals: 
%     Min      1Q  Median      3Q     Max 
% -3.4777 -0.7420  0.1240  0.6584  3.4686 

% random effects:
%  groups           name                 variance std. dev. Corr
%  workerID         (intercept)          0.043520 0.20861      
%                   spellingRatioCentred 0.001941 0.04405  0.84
%  singBrUnderscore (intercept)          1.457949 1.20746      
%  residual                              0.420060 0.64812      
% number of obs. 2005, groups:  workerID, 116; singBrUnderscore, 81

% fixed effects:
%                                           estimate std. error       df t value
% (intercept)                                2.78103    0.13814 81.08000  20.131
% logRelPropInN1FamCentred                   0.42157    0.15080 75.96000   2.796
% logPositionalFamilySizeN2AboveFourCentred  0.29016    0.11140 75.97000   2.605
% logN1FreqCentred                           0.51130    0.08155 75.92000   6.269
% spellingRatioCentred                      -0.20806    0.07388 76.72000  -2.816
%                                           pr(>|t|)    
% (intercept)                                < 2e-16 ***
% logRelPropInN1FamCentred                   0.00656 ** 
% logPositionalFamilySizeN2AboveFourCentred  0.01106 *  
% logN1FreqCentred                          2.02e-08 ***
% spellingRatioCentred                       0.00618 ** 
% ---
% Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

% Correlation of Fixed Effects:
%             (Intr) lRPIN1 lPFSN2 lgN1FC
% lgRlPrIN1FC  0.059                     
% lgPsFSN2AFC -0.081 -0.079              
% lgN1FrqCntr -0.010  0.122 -0.225       
% spllngRtCnt -0.045  0.013  0.171 -0.066
% r.squaredGLMM(bs2016.n1n2.N2famsize.noOutliers.clean.lmer)
% #       R2m       R2c 
% # 0.4140953 0.8723927 
\small
\begin{tabularx}{.95\textwidth}{llrrrrr}\lsptoprule
\multicolumn{7}{l}{\textbf{random effects:}}\\
% \hspace*{-1.2cm}\begin{tabular}{lllll}
% \multicolumn{4}{l}{\textbf{random effects:}}\\
 {groups}     &{name}&{variance}&\multicolumn{2}{l}{{std. dev.}}&& \\\midrule %&Corr
workerID        &(intercept)         &0.043520&\multicolumn{2}{l}{0.20861}&&\\      
                &spelling ratio&0.001941&\multicolumn{2}{l}{0.04405}&&\\ % 0.84
singBrUnderscore&(intercept)         &1.457949&\multicolumn{2}{l}{1.20746}&&\\      
residual        &                    &0.420060&\multicolumn{2}{l}{0.64812}&&\\\tablevspace      
\multicolumn{7}{l}{number of obs.: 2005, groups:  workerID, 116; singBrUnderscore, 81}\\[1ex]
% \end{tabular}
% \vspace*{1ex}
% % 
% % fixed effects:
% %                                           estimate std. error       df t value
% 
% \hspace*{-8cm}\begin{tabular}[h]{lllllll}
% \multicolumn{7}{l}{\textbf{fixed effects:}}\\
% % &&&&&\\
              &{estimate}& {std. error}   &    {df}& {t value} &{pr($>|t|$)}\\\midrule    
(intercept)                              & 2.78103 &  0.13814&81.08& 20.131&$<$ 2e-16    \\
N1 relation proportion                 & 0.42157 &  0.15080&75.96&  2.796&0.00656\\
N2 family size& 0.29016 &  0.11140&75.97&  2.605&0.01106\\
N1 frequency                         & 0.51130 &  0.08155&75.92&  6.269&2.02e-08\\
spelling ratio                     &-0.20806 &  0.07388&76.72& -2.816&0.00618\\\lspbottomrule
\end{tabularx}
  \caption{Final mixed effects model for compound transparency,
    including N2 positional family size as a predictor,
    marginal R$^2$= 0.41, conditional R$^2$= 0.87}
  \label{tab:bellschaefer2016whole_clean-2}
\end{table}

In the compound transparency model including the N2 family size, cf. 
\tabref{tab:bellschaefer2016whole_clean-2}, the semantic predictor N1
relation proportion is also larger in magnitude, as is the replacement
for N2 synset proportion, N2 family size. The positively correlated N1
frequency is larger in magnitude. The negatively correlated spelling
ratio is slightly smaller in
magnitude. The model including the N2 family size still fits the data
better, but there is no significant difference between the 2
models anymore when comparing them via log likelihood testing.



\subsection{Conclusion: re-modeling \citet{BellandSchaefer:2016}}
\label{sec:con-remod-bs2016}

Starting from the observation of large residuals in the models from
\citet{BellandSchaefer:2016}, this section showed that using a single
consistent criterion to eliminate outliers across all ratings
led to residuals containing even larger outliers, and also, and more
conspicuously, bands of large outliers. Closer inspection revealed
that these outliers were caused by ratings on compounds for which
both meanings where selected by raters. Divergent ratings driven by different
meanings of one and the same compound cannot be modeled by the
predictor variables used in this chapter, because they were all bound
to compound types, not compound senses. I therefore eliminated the
entries causing the high residuals from the data, and presented the
resulting 4 models. % in section \label{sec:new-compound-transparency}.

The most notable changes occurred for the models of N1 and N2
transparency, resulting in more parsimonious models. In the model for
N1 transparency, N2 synset proportion did not become significant; in
the model for N2 transparency, spelling ratio did not become
significant. Idiosyncratic properties of N2 synset proportion were already discussed at length
earlier (cf. Section \ref{sec:bs2016discussionandconclusion}). Its
diminished role in a model ran on cleaner data is thus
reassuring. Why spelling ratio did not become significant in the model
for N2 transparency is less clear. However, note that in the mixed
effects models presented in Chapter \ref{cha:empirical-1}, the model
for N2 transparency was the only model that retained only 2 of the 3
predictors capturing meaning shifts. If spelling ratio, intended 
primarily as a replacement for whole compound shifts, also captures
some part of the variation captured in the earlier models by constituent shifts, its
smaller effect on N2 transparency is expected.

For compound transparency, the models remained unchanged as far as
there significant predictors are concerned. Across all models, the
remaining predictors exhibited the same direction and by and large
similar magnitudes.

% \section{The role of spelling ratio}
% \label{sec:spelling-ratio}
% TODO man. TODO

\section{Conclusion}
\label{sec:emp2-conclusion}

The aim of this chapter was to model semantic transparency based on information
drawn from compound families. In particular, its aim was to explore
whether the semantic predictors that emerged either as insignificant
or as conceptually unsatisfactory in Chapter \ref{cha:empirical-1}
could be turned into measures capturing the expectedness of a semantic
configuration in view of a compound's constituent families. 

Section \ref{sec:operationalization-sem-rel} focused on previous
attempts to assess semantic
relations within compounds relative to their constituent
families, extensively discussing the approach of using an artificial corpus by
\citet{GagneandShoben:1997} and the BNC-based re-implementation by
\citet{Maguireetal:2007}, and concluding that for the task at hand a
BNC-based procedure is most promising.  Section
\ref{sec:meaningShiftsInFamilies} extends the expectancy-based
approach used for the semantic relations to the coding of constituent
senses, proposing to use the distribution of \isi{WordNet} synsets across
constituent families instead of the coding of meaning shifts. In addition, it argues that spelling ratio, a variable already
used in the models presented in Chapter \ref{cha:empirical-2}, can be
used as a stand-in for whole compound shifts. In addition, this
section introduced \isi{WordNet}, the lexical resource used to code the
constituent senses.

Section \ref{sec:methods1} described the methods used by
Melanie Bell and me to arrive
at a representative set of compound families for the
Reddy et al. items. Starting from the \isi{BNC}, and adding items from
\isi{CELEX}, we used the USENET corpus in order to have more insight into
the occurrences of low frequency items. In addition, we used \isi{CELEX} to
filter out compounds that themselves consisted of complex
constituents. 
My subsequent semantic coding of the compounds in
these families is described in Section \ref{sec:methodsSemCoding}.

Section \ref{sec:bellschaefer2016_further-and-predictions} introduced the explanatory variables
and the predictions from \citet{BellandSchaefer:2016}. The models
from \citet{BellandSchaefer:2016} were presented and discussed in
Section \ref{sec:bellandschaefer2016models}. Core findings were an
 imbalance in the distribution of the contributions due to N1
and N2 predictors and the observation that the models for compound
transparency can be seen as combinations of the predictors playing a
role for the constituent transparency models. The majority of our
predictions was at least partially borne out, and with the N1 relation
proportion there was one predictor based on the semantic annotation that reoccurred in all models,
always positively correlating with semantic transparency. Spelling
ratio, in contrast, occurred in all but one model and was always
negatively correlated with semantic transparency. However, while we motivated
its inclusion with the assumption that it is positively correlated
with whole compound meaning shifts, it is actually not so clear
what exactly this variable represents in all individual cases,
cf. again the pertinent remarks in Chapter \ref{cha:empirical-1},
Section \ref{sec:results-of-mixed-effect-models}.

Section \ref{sec:bellandschaefer2016_new_models} showed that the dataset used
so far still contained many outliers. After removing the outliers in a
2-step process, I presented the final models for semantic
transparency. This resulted in more parsimonious models for N1 and N2
transparency, while the models for whole compound transparency
remained essentially unchanged.

While thus only one predictor derived from the semantic annotation
reoccurred in all models with a correlation in the expected direction,
this is actually a very promising result, showing that viewing semantic
relations as constituent-specific was a step in the right
direction. Note also that in the 2 theoretical frameworks that argue
for this view, the CARIN and RICE theories of conceptual combination,
an imbalance in the contribution of the modifier and the head is
expected.

% Instead of just coding the individual
% word senses, the semantic predictors are now based on the constituent
% families of the individual compounds. 



% \section{open ends}

% add: advantage/disadvantage that homonyms are now also coded even though they do
% not represent meaning shifts

% why not use whether it occurs as its own entry in wordnet? Or occurs
% in celex?


% What about the collinearity? Confer this paper: \citet{EchambadiandHess:2007}. What I should do: See what happens without centering in terms of the model.

%  5
% down vote
	

% When the model is additive and linear, centering has nothing to do with collinearity. Centering can only help when there are multiple terms per variable such as square or interaction terms. Even then, centering only helps in a way that doesn't matter to us, because centering does not impact the pooled multiple degree of freedom tests that are most relevant when there are multiple connected variables present in the model. For example, if a model contains X
% and X2, the most relevant test is the 2 d.f. test of association, which is completely unaffected by centering X. The next most relevant test is that of the effect of X2

% which again is completely unaffected by centering.
% shareimprove this answer
	
% answered Apr 27 '14 at 16:08
% Frank Harrell
% 39.9k173161
	
% add a comment
% http://stats.stackexchange.com/questions/95404/is-centering-a-valid-solution-for-multicollinearity


% point out: what about constituent frequency, strength ratio, other measures?


%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "habil-master_rev-1"
%%% End: 
