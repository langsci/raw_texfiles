\chapter{Situated games}

%\hfill \begin{minipage}{2.8in}
%
%       \small
%
%Though this be madness, yet there is method in 't.
%       
%
%       \setlength{\parindent}{.8em} % this will indent subsequent paragraphs
%
%\vspace{1ex}
%
%       \hfill --- William Shakespeare, \emph{Hamlet}\ia{Shakespeare, William}
%
%       \end{minipage}
%
%\bigskip

The basic task of this Appendix is to derive the locutionary semantic map $g_u: {\cal L} \functionarrow {\cal G}$ introduced in \partref{part:III} from first principles. This derivation will provide the mathematical foundation for our informal discussion of situated games of partial information. It will also enable readers to see how all the other games such as syntactic games of partial information, illocutionary games of partial information, locutionary and illocutionary global games, Setting Games, Content Selection Games, Generation Games, Interpretation Games, Communication Games, and Language Games can be defined either analogously or by further construction. 

%\footnote{Much of what follows echoes and quotes liberally from Appendix~A in \emph{Language and Equilibrium}, updating definitions when required especially to take account of the new models of partial information games in this book as contrasted with the old models. See the comparison in \sectref{sec:old partial information game}.}

Recall that the elements of situation theory have already been spelled out as fully as required for the purposes of this book in \sectref{sec:information}. Certain basic facts relating to agents and language were also identified in \sectref{sec:agents} and \chapref{ch:language and structure}. I will take this material as given here. 

The key innovation in my presentation, based on \citet{parikh:diss,parikh:sga,parikh:ul,parikh:le}, is that games are constructed from situation-theoretic objects just as numbers can be constructed from sets. The motivation for preferring such an embedding of game theory in situation theory is discussed in Appendix~A of \emph{Language and Equilibrium} and so will not be repeated here.

%First, situation theory is a foundational theory of information -- philosophically\is{information} as we have already seen, but also mathematically, computationally, and empirically -- and if games, which provide a framework for choice and action, are constructed from situations then these more complex objects are explicitly related to their simpler, more basic building blocks, thereby making their ontological status clear. This is useful not just for semantics but for any application of game theory. 
%
%In pure mathematics, when one type of entity (e.g.\ numbers or games) is constructed from a simpler type of entity (e.g.\ sets or situations), then this construction has a \emph{logical} character. However, when the same piece of mathematics is applied to some part of the real world, then such a construction additionally takes on the character of an \emph{explanation}. Since situations and games are very much part of the world, my construction serves as an explanation of how games arise in communicative situations. The alternative is simply to assume that there is a game that models some flow of information and then show that its solution matches our intuitions. My construction goes a step further: instead of assuming a game to start with as an article of faith, I assume a more basic ontology, one whose objects are prima facie easier to accept, and show how a game naturally emerges in communication. This is a common feature in science where relatively complex objects whose existence is assumed in a theory that is more at the surface of things get accounted for by more fundamental objects in a deeper theory (e.g.\ explaining certain objects of particle physics -- like hadrons -- by\is{particle physics} using string theory\is{string theory} or explaining diseases via genetics\is{genetics} and epigenetics).\is{epigenetics} In this sense, I take games to be real objects out there in the world just like individuals, properties, relations, infons, situations, constraints, and all the rest of the objects in the ontology $\cal O$. Indeed, situation theory provides a finer-grained universe of objects that even facilitates a natural derivation of more general choice-theoretic structures called strategic interactions\is{strategic interaction} discussed in \citet[Chapters~5 and 6]{parikh:ul} and \citet[Sections~3.3.4, 5.3, 5.10]{parikh:le} that permit weaker conditions than common knowledge. This is precisely the kind of consequence that one should expect from using a more general framework.
%
%A third and related reason is that the elements of situation theory\is{situation theory} actually make certain aspects of the game theory\is{game theory} clearer. For example, the information that agents possess at each stage of a game can be made explicit in a natural way since the progression marked by a path in a game tree is nothing but a progression of evolving situations that support different infons based on the action chosen by an agent. Likewise, the basis for the particular payoffs and probabilities in a game can be represented in the initial situations of a game. The definition of a product of two games also becomes easier to address because the information at each node of the product is readily expressible via set-theoretic operations on the situations at the nodes in the multiplicands. The circular and nonwellfounded aspects of strategic inference\is{strategic inference} also become transparent, something I have referred to at various points in this book.
%
%A fourth reason is that, in my view, \emph{all} choice is fundamentally \emph{situated}. For example, an agent in a certain situation may prefer a scoop of ice-cream to a glass of water. After he chooses the ice-cream and eats it, he may face exactly the same choice in the ensuing new situation. Though his options are the same the second time around, his preferences in this new situation may be different: he may now prefer a glass of water to the ice-cream and may act accordingly. This is something economists and others using game theory have seldom tried to capture explicitly. Games and decision problems\is{decision problem} become \emph{actual} only with respect to a \emph{setting} or situation. And real situations, being what they are, can seldom be enumerated exhaustively. This means real games themselves are \emph{partial} objects -- just like infons and situations -- which can be more or less fully captured by the game-theoretic models we build. Sometimes, as we have seen, the agents in a situation may model the choices available to them differently, either because of their different epistemic constraints or because of their different preferences. The solutions to a game also sometimes depend on the ambient situation as not all the information required for a solution may be located in the model of the game itself but may remain ``outside,'' as it were, in the setting for the game. It is worth amplifying on this situatedness of choice and action despite the slight digression it entails.
%
%In this book, I have relied largely on the Pareto-Nash equilibrium\is{equilibrium!Pareto Nash} as a solution concept. This isn't because I believe it is the one and only correct solution concept but because it made it possible for me to be concrete in considering the solutions to games of partial information. Additionally, as discussed briefly in footnote~\ref{foot:Pareto criterion} in \sectref{sec:solving locutionary global games} and also more extensively in my earlier books, it does seem that most other solution concepts are likely to yield results that are the same as the Nash\is{equilibrium!Nash} or Pareto-Nash equilibria in the contexts of interest to us. Suffice it to say here that the universality\is{universality} result of \sectref{sec:universality} does guarantee that a unique solution exists for all games of partial information. 
%
%In any case, often too much attention is given to solution concepts. Important as they are for completing the analysis, it is the games themselves and their various representations that are more fundamental, and I have tried to show throughout that they can model a very wide range of phenomena. In general, there are many different approaches to solving essentially the same game, some giving similar predictions and others that are not equivalent. Once one has the basic setup one can explore multiple approaches to analyzing it without committing oneself to one or another approach. This is an ongoing task. Thus, a clear distinction needs to be made between the choice situation being modeled, the game one uses to model that situation, and finally, the analysis of the model with some solution concept. 
%
%Indeed, once this kind of separation is made, a very different view of game theory emerges, a view that does not seem to have been explored in the game-theoretic literature, at least as far as I know. This view was discussed in \citet{parikh:pgpi,parikh:le} and I revisit it here. To introduce this perspective of what I have called \emph{situated game theory},\is{game theory} let us consider an analogy.
%
%As mentioned in \sectref{sec:information}, it has taken a while to give full recognition to the context of utterance as an integral factor in the determination of content and even today the dominant position gives it a second-class status in semantics. But there should no longer be any doubt that it is only the sentence together with a context that can have a content. The proliferation of analysis strategies for games suggests that games may well be like sentences in this regard. Indeed, Theorem~\ref{thm:isomorphism} that ${\cal L} \cong {\cal G}$, that is, that ${\cal L}$ and ${\cal G}$ are isomorphic, puts this analogy on a formal footing. Just as the same sentence can be used in a variety of ways in different situations to make different statements, so the same game can be solved in a variety of ways in different situations to yield different solutions. The same game in an economic context may be best analyzed in one way but in a political or communicative context in other ways. It is only the game together with a context that can have a solution (or ``content'').
%
%Now games already incorporate a number of contextual factors internally -- through the payoffs and probabilities and game tree -- so what remains of relevance in the context after this has been done? Indeed, games are themselves models of situations so why leave anything relevant out in the situation being modeled? This is a moot point because if something does remain, we could always try to enrich the model and incorporate it. This would be similar to the familiar move in the case of language of enriching the sentence itself or the sentence's logical form. While this is an ad hoc and therefore bad strategy for the analysis of utterances, it may be partially acceptable in the case of games: we can sometimes enrich the game model and sometimes leave things in an external context. Perhaps there are higher level things about the concerns of the players that are best left out of the game model and used externally to determine how the game should be analyzed, whether statically or behaviorally\is{game theory!behavioral} or evolutionarily,\is{game theory!evolutionary} or given one of these choices, what solution concept should be employed, and further, which of multiple possible equilibria should be selected. Perhaps there are external things about the behavioral or architectural configurations of the agents involved: they may have all kinds of computational limitations for example that may vary from situation to situation and agent to agent.

%%In Section~3.1, the protagonists faced multiple equilibria in $G$ regarding their choices for how to spend the evening, and it was suggested there that the setting of the game that made it actual could contain further information about its solution. Different assumptions and different corresponding analyses would be germane for other settings and the behavior of the players would then be different. That is, just as the variation of context leads to different contents for utterances, so this variation can also lead to different solutions for games.

%So the ambient situation is responsible not just for giving rise to the game model itself but also partially for its solution. There is a kind of trade-off and indeterminacy\is{indeterminacy} between how much information is absorbed explicitly into the game and how much is left in the ambient situation, just as in \sectref{sec:setting game again} there was an indeterminacy between how much of the content of an utterance should be inscribed on the side of the described situation and how much on the side of the infons. In one, we have the form $u \vDash G$ and, in the other, we have the similar form $c \vDash \sigma$, and the indeterminacy concerns which side of the turnstile the information in question is placed.
%
%Since there are often additional facts in $u$ that have been left out of the game (e.g.\ a preference for certain equilibria\is{equilibrium} or a certain kind of mixed strategy equilibrium\is{equilibrium!mixed strategy} in a game of partial information), why not use a second higher-order game to model these additional facts? This would be an adaptation of the  strategy of leaving certain facts external to the initial game model in the context $u$, and then using a second game to model these external facts. This move can be made clearer by recognizing what has been done for content:
%
%\[ \hbox{phrase} \oplus \hbox{utterance situation} = \hbox{content of utterance}\ \ \ (\hbox{i.e.}\ {\cal C}_u(\alpha) = \sigma) \]
%
%\noindent Here, games of partial information were introduced to model the utterance situation.  A similar equation can be expressed for games:
%
%\[ \hbox{game} \oplus \hbox{game situation or setting} = \hbox{solution of game}\ \ \ (\hbox{i.e.}\ {\cal C}_u(G) = \hbox{solution}) \]
%
%\noindent If games of some kind were relevant for utterance situations, then it is plausible that games can be deployed to model ``game situations'' or settings. This is precisely the second higher-order game mentioned above. In the special case of communication, the game situation is nothing but the utterance situation. But for other settings, say in economics or political science or biology, there is no prior phrase or utterance.
%
%This idea suggests that given a general situation $u$ containing one or more agents, it is possible to model it as a sequence of games (or decision problems)\is{decision problem} $\tuple{G_0,G_1,G_2,\ldots}$, $G_0$ being the initial model $G$, and each subsequent game being at a higher level than the one before it in a way that each successive game in the sequence captures some of the residual information in the initial (game) situation $u$. So $G_1$ might encode information about a preference the players may have for a certain type of solution concept in $G_0$, $G_2$ in $G_1$, and so on. Even though the information in a real situation is seldom fully exhausted, one can imagine situations where such a sequence ``converges'' so that in some $G_n$ for finite $n$ or possibly in the limit as $n \rightarrow \infty$, the solution is obvious. Then this would presumably cascade all the way back to $G_0$, yielding the solution to the original game. 
%
%And when an utterance of $\alpha$ is being considered, not an arbitrary game or decision problem $G$, then the relevant sequence $\tuple{g^0,g^1,g^2,\ldots}$ would start with the phrase or sentence $\alpha$ itself and go on to a game of partial information $g_u(\alpha)$ followed by other games. That is, $g^0 = \alpha$ is the phrase or sentence uttered in $u$ and $g^1 = g_u(\alpha)$ is the partial information game of equilibrium semantics. Each game helps to solve the one preceding it: $g^1$ enables the solution to $g^0$, $g^2$ to $g^1$, and so on, ad infinitum if necessary.
%
%In the case of general games as well as the case of utterances, the setting $u$ is the source of the entire sequence: $u$ supports $G$ and $\alpha$, $u$ supports $G_1$ and $g_u(\alpha)$, and so on.
%
%Admittedly, this suggestion is a bit speculative, but there seems to be no immediate problem in carrying it out. Certainly, there may often be additional information in $u$ that has not been exhausted by $G_0$ and this leftover information may be relevant for the solution of $G_0$. If this suggestion turns out to be valid, it would have interesting consequences for the use of game theory in wider contexts too, whether they are economic, political, or biological. And, of course, it would apply to games of partial information. We may also be forced to accept that if contextual information relevant for solving a game is not always fully exhaustible through the sequence of games above, then there may well remain a non-formal residue in our attempts to solve games satisfactorily. This may happen also because the initial situation $u$ is simply not given clearly or differs for the agents involved, as mentioned in connection with indeterminacy in \sectref{sec:indeterminacy} and elsewhere. Just as there is an element of creativity involved in coming up with a suitable context for the interpretation of a text, so there is an element of creativity involved in identifying the context for a game, as can be seen when two sides are involved in a difficult negotiation. This observation pretty much dashes all hopes for a fully formal theory for the  determination of unique equilibria for games just as new readings for existing texts will always be possible by changing their context.
%
%Incidentally, all of the foregoing refers to the situatedness of \emph{choice}, not of action.\is{action} In this book, the primary actions of interest have been utterances and interpretations. It is easy to separate an utterance into a sentence and a situation in which it is uttered and, likewise, it is easy to separate an interpretation into an infon and a situation. A point I have not pursued here but mention in passing is that \emph{all} actions are situated and require reference to a situation, just as utterances and interpretations do. This observation makes it possible to develop an entire theory of action based on situation theory, something clearly outside our scope.
%
%To return from the brief detour, a fifth and final reason for constructing games from situations is that I have already done it informally starting with \sectref{sec:agents} and \partref{part:III}. All that needs to be done is to spell it out more formally here.
%
%Quite apart from the applications to semantics, it is likely that such an integration of situation and game theory\is{situation theory}\is{game theory} will have many uses in the wider domain of action, especially as it is studied in philosophy\is{philosophy} and artificial intelligence.\is{artificial intelligence} For example, it could well be of interest in robotics.\is{robotics}

%Generally, if there are results that are relatively hard to prove they are called theorems,
%whereas simpler results of this sort are called propositions. Because the proofs here are all
%quite simple, I have used ``theorem'' and ``proposition'' differently, to mark the importance of the result for Equilibrium Semantics.


\section{The background}\label{sec:A.1}

Let the sets of infons, situations, and propositions be $\cal I$, $\cal S$, and $\mathbf{PROP}$ respectively. These sets are assumed to be finite and represent the range of infons, situations, and propositions of interest relative to a small part of reality called the environment $\cal E$ within the overall informational space or ontology $\cal O$. There are various operations on these entities partially described in \sectref{sec:information} and these should be borne in mind as well.

%Agents were introduced in \sectref{sec:agents} and elaborated on in later chapters. The language $\cal L$ and its structure were introduced in \chapref{ch:language and structure}. 

While any action can be communicative in the right context, I restrict my focus to linguistic communication. The Conventional sub-Constraint \textbf{C} and the Referential sub-Constraint \textbf{R} originate in communication as discussed in \partref{part:V} and together provide the set of possible (semantic) contents of an utterance. Another way of describing the task of the Appendix is to say that the Flow Constraint \textbf{F} will be developed mathematically assuming \textbf{C} and \textbf{R} are given.


%\subsection{Language}

%
%$m: \cal L \functionarrow \powset(P\!RO\!P)$ and 
%cost $cost: \cal L \functionarrow \Re^+$. For all $\varphi \in \cal L$ we
%assume that $m(\varphi)$ is finite.

%%\begin{aA} \hspace{.1pc} {} \end{aA}

%\begin{definition} \begin{tabular}[t]{l} {$E\!P\!RO\!P$ is the set of all 
%expressible propositions.}\\ {$E\!P\!RO\!P =_{df} \bigcup\__{\varphi} 
%m(\varphi)$.} \end{tabular} \end{definition}

%\begin{definition} \begin{tabular}[t]{l} {${\cal L}_{p} = 
%\{ \varphi \in \cal L : \hbox{$m$}(\varphi) = \{\hbox{$p$}\}\,\}$.} 
%\end{tabular} \end{definition}

%
%\noindent We assume that ${\cal L}_{p}$ is nonempty and finite.  This
%property is called  expressivity.  It  implies that every expressible
%proposition can be expressed unambiguously.\is{ambiguity} 
% 

%\begin{definition} \begin{tabular}[t]{l} {$\mu: E\!P\!RO\!P 
%\functionarrow \powset(\cal L)$}\\ {$\mu(p) =
%[cost^{-1}\min\{cost(\varphi) :
%\varphi\in {\cal L}_{p}\}]
%\cap \hbox{\LL}_p$.} \end{tabular} \end{definition}

%\noindent Expressivity guarantees that the set of minimal cost 
%unambiguous\is{ambiguity} sentences that express $p$ is not empty.

%\begin{pr} \hspace{.1pc} $\forall p \in E\!P\!RO\!P$, $\mu(p)$ 
%is not empty. \end{pr}

%\begin{pf} \hspace{.1pc} {\rm ${\cal L}_{p}$ is nonempty and finite and so
%a minimum exists and will be in ${\cal L}_{p}$. The intersection
%with ${\cal L}_{p}$ will eliminate all unwanted minima. \hspace{.2pc}
%$\Box$}
%\end{pf}\\


Since $\cal A$'s actions are utterances of sentences, they can be modeled by ordered pairs $\tuple{\varphi,u}$, where $\varphi$ is a sentence in $\cal L$. As the utterance situation $u$ is a parameter, it is convenient to simplify the notation by specifying utterances by their sentences alone.

$\cal B$'s actions are interpretations of $\cal A$'s utterances, and can be 
modeled as pairs $\tuple{\sigma,c}$, where $\sigma$ is an infon and $c$ the situation described partially by the infon. Once again, this can be simplified to just $\sigma$, because $c$ is held fixed for all the infons that serve as interpretations relative to the utterance situation $u$. I have taken infons rather than propositions as the relevant contents. Clearly, both are transmitted in an utterance.

Initially, lexical games $g_u(\varphi_i)$ will be constructed, where $\varphi_i$ is a word in the sentence $\varphi$. The corresponding possible contents of $\varphi_i$ obtained from \textbf{C} and \textbf{R} will be denoted by $\sigma_i^{y}$ where $y$ stands for zero or more primes. To avoid the proliferation of generic indices, I choose to replace $i$ with just the number $1$ with the understanding that the same construction would apply mutatis mutandis to all the words in the sentence uttered. Thus, $\varphi_i$ is replaced by $\varphi_1$ and $\sigma_i^{y}$ by $\sigma_1^{y}$.

It is convenient to define a function $m_u$ that maps elements of $\cal L$ into their possible contents $\sigma_1^{y}$ relative to $u$. $m_u(\varphi_1) = \{ \sigma_1^{y} \mid y = 0, 1, 2, \ldots \hbox{primes} \}$ is assumed to be finite and generated via \textbf{C} and \textbf{R}. Indeed, $m_u$ is just the composition of the conventional and referential maps suitably defined. An added advantage of using this composed function is that the construction of $g_u(\varphi_1)$ can be applied beyond language to other symbol systems and other domains like social systems if $m_u$ is reinterpreted for those other contexts. In other words, \textbf{C} and \textbf{R} and their corresponding maps may be viewed as just the \emph{theory} of $m_u$ for the case of language. Further, different parts of language such as nouns and verbs require different theories for each corresponding part of the Referential Constraint \textbf{R}, something that was considered in greater detail in my previous book. A similar function $m'_u$ that maps elements of $\cal L$ into their possible parse trees based on the Syntactic Constraint may be assumed if we wish to consider syntax but I will just abstract from it here.

%This way of accounting for the possible contents of an expression suffices for \emph{locutionary}\is{meaning!locutionary} meanings because they are generated by the expressions themselves via \textbf{C} and \textbf{R}. As we saw in Section~4.4, the possible contents that arise in connection with the illocutionary meanings of an utterance are based not on any expression in the sentence but on the resolution of \emph{issues} that are raised. Crucially, as was pointed out in Section~4.4.2, these issues have what was called a \emph{support} in the sentence, which may be a single word or phrase or the entire sentence. So it is possible to extend the function $m_u(\alpha)$ to illocutionary meanings\is{meaning!illocutionary} as well by identifying its argument $\alpha$ as the support of the possible illocutionary meanings of the utterance. This makes the function $m_u(\alpha)$ not a function but a correspondence since it would yield the set of possible locutionary contents of $\alpha$ as well as the set of possible illocutionary contents whose support is $\alpha$. We could easily separate this into two functions $m_u^{\ell}$ and $m_u^{\imath}$, one for locutionary meanings and the other for illocutionary meanings, just as was done with the actual equilibrium contents ${\cal C}_u^{\ell}(\alpha)$ and ${\cal C}_u^{\imath}(\alpha)$, but this merely adds clutter so I will avoid it. 

%In any event, it should be kept in mind that the function $m_u$ is nothing but a notational stand-in for the constraints \textbf{C} and \textbf{I} and represents the composition of the conventional and informational maps. It is to them one has to turn in order to actually know what the \emph{possible} locutionary and illocutionary meanings are when considering linguistic communication.

The way the game-theoretic model works is that given an utterance situation $u$, the speaker $\cal A$ forms  an intention to convey a (partial) content $\sigma_1$ (like \emph{Bill Smith}) as part of a full utterance and chooses a possibly ambiguous locution $\varphi_1$ (like ``Bill'') such that $\sigma_1 \in m_u(\varphi_1)$. If $\sigma_1$ is the only member of $m_u(\varphi_1)$, a trivial game ensues. If $\varphi_1$ is ambiguous then a nontrivial game results. In either case, the number of initial situations in the game equals the number of possible contents of $\varphi_1$. 

%In the construction below, it is assumed that these starting points are given.



\section{Some prior basic elements}\label{sec:A.2}

Some basic relations, infons, situations, and functions pertaining to communication are now defined.

The first is the relation $itc$ of intending to convey something. This is a three-place relation with a speaker who does the intending, an infon the speaker intends to convey, and an addressee to whom the content is addressed. Such intentions can be either explicit or implicit. The second relation $hu$ is the relation of having uttered something. Its first argument is a speaker and its second argument is a parameter that is anchored to an expression. However, instead of writing $\soa{hu;\ {\cal A};\ \dot{\varphi}}$ with $f(\dot{\varphi}) = \varphi_1$, I will write simply $\soa{hu;\ {\cal A};\ \varphi_1}$ to keep the notation uncluttered.  The third relation is the relation $hi$ of an addressee's having interpreted an utterance as communicating something. This is a three-place relation with arguments an  addressee, an utterance, and an infon. From these three relations, corresponding infons and situations can be constructed.


%\begin{definition} \begin{tabular}[t]{l} {$c: {\cal I} 
%\functionarrow {\cal S}$}\\ {$c(\sigma_i) = \{ \soa{itc,{\cal 
%A},\sigma_i,{\cal B}} \} .$} \end{tabular} \end{definition}

%\begin{definition} \begin{tabular}[t]{l} {$s_{1^y} = u \cup \{ \soa{itc, {\cal A}, \sigma_{1}^{y}, {\cal B}} \}$ where $y$ stands for zero or more primes depending on how many possible contents of $\varphi_1$ are generated by the constraints \textbf{C} and \textbf{I}.} \end{tabular} 
%\end{definition}

We start with a specification of the possible initial situations in a game of partial information.

\begin{definition}  $s_{1^y} \subset u$ and $s_{1^y} \vDash \{ \soa{itc, {\cal A}, \sigma_{1}^{y}, {\cal B}} \}$, where $\sigma_1^{y} \in m_u(\varphi_1)$.\label{def:A.1}\end{definition}



\noindent This says simply that the initial situation $s_{1^y}$ is a subset of the utterance situation $u$ and supports an infon representing the appropriate intention $\cal A$ would have to convey $\sigma_{1}^{y}$ to $\cal B$.

I had earlier used $t$ to refer to various parse trees but I will be abstracting from syntax here so I will use it instead for situations that result from an initial situation after $\cal A$ has uttered something.

%In my previous book with the old partial information games, this definition and the basic relations above were then used to specify the alternatives to $\varphi_1$ that $\cal A$ might consider and the consequences of $\cal A$'s and $\cal B$'s possible actions.


%\begin{definition} $alt_u: {\cal L} \times {\cal I} \functionarrow {\cal L}$ with $alt_u(\varphi_1, \sigma_{1}^{y}) = \varphi_{1}^{y+1}$ where $\varphi_{1}^{y+1} \in {\cal L}$ is a minimal cost alternative to $\varphi_1$ such that its unique possible content in $u$ is $\sigma_{1}^{y}$. That is, $m_u(\varphi_{1}^{y+1}) = \{ \sigma_{1}^{y} \}$. Moreover, the cost of $\varphi_{1}^{y+1}$ is always greater than the cost of $\varphi_{1}$ for all $y$. In the special case when $m_u(\varphi_{1}) = \{ \sigma_{1} \}$ is a singleton, then $alt_u(\varphi_1, \sigma_{1}) = \varphi_{1}$.
%\end{definition}

%\noindent For the purposes of the model, the cost\is{costs} of uttering an expression and perceiving and interpreting it are taken as given. To keep things simple, the definition above refers just to ``cost'' without specifying whether it is the cost for $\cal A$ or $\cal B$ and whether these costs are identical. A whole \emph{theory} of cost would be required to do justice to this aspect of payoffs and is obviously beyond our scope here. If there is more than one minimal cost alternative, one can be picked arbitrarily. 
%
%As we have seen, defining $alt_u$ to yield just one alternative is \emph{not} required. It could quite easily be defined as a \emph{set} of alternatives that moreover do not necessarily have unique contents in $u$. But this needlessly complicates the model and we would lose sight of the forest for the trees!\footnote{Pun intended.}


\begin{definition}\label{def:A.2}\begin{tabular}[t]{l} 
{$act_{\cal A}: {\cal S} \times {\cal L} \functionarrow {\cal S}$}\\
\vspace{0.075in}%
{$act_{\cal A}(s,\varphi_1) = s \cup \{ \soa{hu,{\cal A},\varphi_1} \}$.}\\
%{}\\ 
%\vspace{0.5in}
{$act_{\cal B} : \hbox{ran}(act_{\cal A}) \times {\cal I} \functionarrow {\cal S}$}\\
{$act_{\cal B}(t,\tau) = t \cup \{ \soa{hi,{\cal B},\varphi_1,\tau} \}$ where $\varphi_1 = 2^{nd}[act_{\cal A}^{-1}(t)]$.}
\end{tabular} \end{definition}

\noindent Here $\hbox{ran}(act_{\cal A})$ is just the range of the function $act_{\cal A}$. These two functions give general descriptions of the consequences of $\cal A$'s uttering something in a situation and of $\cal B$'s subsequently interpreting it. All that happens is that the initial situations $s$ get augmented first with $\cal A$'s utterance and next with $\cal B$'s interpretation. It should be easy to see that if $s$ were taken to be one of the initial situations $s_{1^y}$ above and if appropriate utterances and interpretations were specified, then we would have the basic mechanism for generating the game tree via the updates given by $act_{\cal A}$ and $act_{\cal B}$. Thus, having started with the elements of situation theory and with some basic relations pertaining to communication, games of partial information will naturally follow.

This is partly where using situation theory enables us to make the information available to each agent at each stage explicit. Uttering $\varphi_1$ in $s$ has the consequence that $\soa{hu,{\cal A},\varphi_1}$ gets added to $s$, a fact that is explicitly available to both agents. Without this kind of underlying construction, this fact would remain implicit. This kind of articulation is especially useful in contexts where artificial agents that communicate have to be designed because such information can then be used in making situated and strategic inferences.

We first remind ourselves of the form of games of incomplete information which will be the approximate target of our construction.


\section{Games of incomplete information}\label{sec:A.3}

As I have said, traditionally, games are approached directly. Although \citet{harsanyi:bayes} was the first person to define games of incomplete information, he did so in normal or strategic form.\is{game!normal form} What we need is their extensive form\is{game!extensive form} definition because that is where various aspects of the choice structure are made transparent. This was made clear by \citet{kuhn:egpi} who was the first to define extensive form games for games of perfect\is{game!perfect information} and imperfect\is{game!imperfect information} information. \citet{kw:se} extended Kuhn's definition to games of incomplete information. We use their formulation of a game of incomplete information as a tuple\is{game!incomplete information} of sets and functions as the approximate goal of 
the situation-theoretic construction. This goal is approximate because games of partial information\is{game!partial information} are different in certain respects from incomplete information games. 

%Incidentally, \citet{lewis:c}\ia{Lewis, David} who based his signaling games\is{game!signaling} on \citegen{schelling:sc}\ia{Schelling, Thomas} normal form games implicitly used imperfect information games, although the informational aspects of such games were never made explicit. Later, they were generalized by game theorists to incomplete information games.

Kreps and Wilson \cite{kw:se} define a game of incomplete 
information\is{game!incomplete
information} directly as an extended tuple \hbox{$\tuple{T,\prec \sep ACT, act
\sep N,\eta \sep 
P \sep H \sep v}$}.  $T$ is a set of nodes and $\prec$ is a partial 
ordering on $T$ that makes the pair $\tuple{T,\prec}$ a tree (more
precisely, a forest). 
$ACT$ is a  set of actions and $act$ is a function that maps every
noninitial  node of 
$\tuple{T,\prec}$ into some action in $ACT$. This is intended to be the 
action that leads to this node. $N$ is a set of agents (or players) and
$\eta$  is a mapping from the set of nonterminal nodes onto $N$. $\eta$ 
establishes whose turn it is to act. $P$ is a vector of probabilities on
the  set of initial nodes. This much of the tuple gives a tree with decision
nodes  connected by actions with an agent identified for each decision
node. $H$ is  a partition on $T$ that consists of subpartitions, one for each
player. It is  meant to capture the information sets of each agent, the sets
of decision  nodes of an agent that cannot be distinguished by the agent.
Accordingly,  each agent's subpartition is a collection of those sets of
nodes that are his or her  information sets. Finally, $v$ is the payoff function,
a mapping from the  terminal nodes into the set $\mathbb{R}$ of real numbers.
%This is an informal  description of the tuple constructed below and the reader is 
%referred to Kreps and Wilson's paper for the formal definitions.


\section{Games of partial information}\label{sec:A.4}

I now construct locutionary semantic partial information games as described in \chapref{ch:defining communication games}. This is a straightforward matter of defining the elements of the tuple above one by one.




%Let $p^{\ast}$ be the unique proposition such that 
%$d \vDash \soa{itc,{\cal A},p^{\ast},{\cal B}}$.  Let $C$, $\cal A$'s choice
%set, be a finite nonempty subset of $\cal L$.  For all $\varphi$ in $C$,
%$p^{\ast} \in  m(\varphi)$.\footnote{This would not be true if we were
%considering implicatures.}  This assumption constrains $\cal A$'s choice
%set to be relevant to the communication.


%\subsection{Local Games}

\subsection{Situations and choices}\label{sec:A.4.1}

As was said above in \sectref{sec:A.1}, given an utterance situation $u$, the speaker $\cal A$ forms  an intention to convey a (partial) content $\sigma_1$ (like \emph{Bill Smith}) as part of a full utterance and chooses a possibly ambiguous locution $\varphi_1$ (like ``Bill'') such that $\sigma_1 \in m_u(\varphi_1)$. The first element of the tuple that has to be constructed is the tree of possible situations and to do this we start with the initial situations identified in Definition~\ref{def:A.1} in \sectref{sec:A.2}. Then we define $\cal A$'s choice sets in each of these initial situations which just contain $\varphi_1$. Next, we generate the intermediate situations that result from $\varphi_1$ based on $act_{\cal A}$ from Definition~\ref{def:A.2} and then identify $\cal B$'s choices in these situations. Finally, we define the terminal situations that follow from $\cal B$'s interpretive  actions based on $act_{\cal B}$. This collection of situations forms a tree under the subset ordering.

\begin{definition} \begin{tabular}[t]{l} 

\vspace{0.075in}
{$T\subnum{0} = \{ s_{1^y}  \mid  \sigma_1^{y} \in m_u(\varphi_1) \} $}\\

%{$T\subnum{0}: \{ \varphi_1 \} \functionarrow \powset({\cal S})$}\\  {$T\subnum{0}(\varphi_1) = \{ s_{1^y}  \mid  \sigma_1^{y} \in m_u(\varphi_1) \} $}

%{$T\subnum{0}: C \functionarrow
%P\!RO\!P$}\\  {$T\subnum{0}(\varphi) = \{ c(p) : p \in m(\varphi) \} .$}
%{}\\

%~\\
{$C_{\cal A}:  T\subnum{0} \functionarrow \powset({\cal L})$}\\
\vspace{0.075in} 
{$C_{\cal A}(s_{1^y}) = \{ \varphi_1 \}$}\\ 
%{}\\ 

%{$T\subnum{1} : \{ \varphi_1 \} \functionarrow \powset({\cal S})$}\\ 

\vspace{0.075in}
{$T\subnum{1} = \{ act_{\cal A}(s_{1^y},\varphi_1) \mid s_{1^y} \in T\subnum{0} \}$}\\ %{}\\ 



%{$T\subnum{1} = \{ t \mid \exists s_{1^y} \in T\subnum{0},\ \exists 
%\alpha \in C(s_{1^y})$}\\
%{\phantom{$T\subnum{1} = \{ $}such that $act_{\cal A}(s_{1^y},\alpha) = t \}$}\\ {}\\ 

{$C_{\cal B}: T\subnum{1} \functionarrow \powset({\cal I})$}\\
\vspace{0.075in} 
{$C_{\cal B}(t) = m_u(\varphi_1)$} \\
%{}\\  
\vspace{0.075in}
{$T\subnum{2} = \{ act_{\cal B}(t, \tau) \mid t \in T\subnum{1},\ \tau \in C_{\cal B}(t) \}$}\\ 

%{}\\ 


%{$T\subnum{2}: C \functionarrow P\!RO\!P$}\\
%{$T\subnum{2}(\varphi) = \{ t : \exists  t' \in T\subnum{1}(\varphi),\ \exists p
%\in D\__{\varphi}(t')$}\\
%\phantom{$T\subnum{2}(\varphi) = \{$}{such that $g(t',p) = t 
%\}.$}\\ {}\\ 

{$T = \bigcup\__i T\__{i}$} \end{tabular}\label{def:A.3}\end{definition}


\noindent Each $C_{\cal A}(s)$ and $C_{\cal B}(t)$ are the same and are $\cal A$'s and $\cal B$'s choice sets in the relevant situations.

%This is one place where games of partial information\is{game!partial information} differ from games of incomplete\is{game!incomplete information} information because the usual definition of the latter requires that all the choice sets $C_{\cal A}(s)$ be equal and correspondingly that all the choice sets $C_{\cal B}(t)$ also be equal. This goes back to \citegen{harsanyi:bayes} original definition of incomplete information games. Games of partial information relax this requirement.

\begin{proposition} \hspace{.1pc} $\tuple{T,\subset}$ is a ``tree'' (more accurately, forest). \end{proposition}


\noindent Since the more basic building blocks of situations and actions have been strung together piece by piece, the fact that $\tuple{T,\subset}$ is a tree is something that can now be \emph{proved} rather than simply assumed.


%\begin{definition} \begin{tabular}[t]{l} {$\forall t,t' \in T$, $t
%\equiv\!\!\__{\cal A}\,\, t'$ iff 
%$t = t'$.}\\ \noindent {$\forall t,t' \in T$,  $t \equiv\!\!\__{\cal
%B}\,\, t'$ iff either (1) $t,t' \in T\subnum{0}$}\\ {or (2)
%there exist $s,s' \in  T\subnum{0}$ such that $t = act_{\cal A}(s,\alpha)$}\\
%{and $t' = act_{\cal A}(s',\alpha)$ for  some $\alpha$ in both $C_{\cal A}(s)$ and
%$C_{\cal A}(s')$}\\ {or (3) $t=t'$.} \end{tabular} \end{definition}


\begin{definition}\label{def:A.4}\begin{tabular}[t]{l} 
{$\forall t,t' \in T\subnum{0}$, $t \equiv\!\!\__{\cal A}\,\, t'$ iff $t = t'$}\\ 
\noindent {$\forall t,t' \in T\subnum{1}$,  $t \equiv\!\!\__{\cal B}\,\, t'$ 
%iff $t = t'$}\\ {or for  some $\alpha$ in both $C_{\cal A}(s)$ and $C_{\cal A}(s')$}\\ {there exist $s,s' \in  T\subnum{0}$}\\ 
%{such that $t = act_{\cal A}(s,\alpha)$ and $t' = act_{\cal A}(s',\alpha)$
}
 \end{tabular} \end{definition}




\begin{proposition} \label{prop:A.2}\hspace{.1pc} $\equiv\!\!\__{\cal A}$, $\equiv\!\!\__{\cal
B}$ are equivalence relations. \end{proposition}


\noindent These equivalence relations capture the 
relevant epistemic properties of the two agents as follows.

\begin{proposition}\label{prop:A.3} \hspace{.1pc}
\begin{itemize} \item {For all $t,t' \in 
T\subnum{1}$, $t \equiv\!\!\__{\cal B}\,\, t'$ implies 
$C_{\cal B}(t) = C_{\cal B}(t')$.}

\item {For all $t,t' \in T\subnum{1}$, $t \equiv\!\!\__{\cal B}\,\, t'$ 
implies $t \not\subset t'$.}

\item {For all $t,t' \in T\subnum{1}$, $t \equiv\!\!\__{\cal
B}\,\, t'$ implies $\eta(t) = \eta(t')$.} 
\end{itemize}
\end{proposition}

\noindent The first statement says that $\cal B$ has the same choices at each of various equivalent situations. This is important because if the choices weren't the same the agent could use that information to distinguish between epistemically equivalent situations, a contradiction. The second statement says that of two equivalent situations one cannot precede the other. This again makes intuitive sense because if such precedence were possible, the agent would know it, and it would make the situations epistemically distinguishable. The last statement requires Definition~\ref{def:A.8} made below and says simply that the same agent has to act in all equivalent situations. The corresponding properties for ${\cal A}$ are even more trivially true. The key thing to note is that all these properties can now be \emph{proved} from more basic assumptions.


\subsection{Actions}\label{sec:A.4.2}

The third element of the game tuple above, the 
set of actions in the game, is nothing but the union of all the choice sets 
in Definition~\ref{def:A.3}. This gathering of all the actions into a single set is just to maintain conformity with Kreps and Wilson's tuple, so that the game is rendered in a familiar form.

\begin{definition} $ACT = [\bigcup\__{s \in T\subnum{0}} 
C_{\cal A}(s) ] \cup [\bigcup\__{t \in T\subnum{1}} C_{\cal B}(t) ] = \{\varphi_1\} \cup m_u(\varphi_1)$
\end{definition}

The map $act$ assigns an appropriate set of actions in $ACT$ to each noninitial situation in $T$.

\begin{definition}\label{def:A.6}\begin{tabular}[t]{l} 
{$act: T\subnum{1} \cup T\subnum{2} \functionarrow ACT$}\\
{\hspace{0pc}\vtop{\halign{$#$\ &\ $#$\ &\ $#$\ &\ $#$\hfil\cr 
act(t)&\!\!\! = 2^{nd}[act_{\cal A}^{-1}(t)] &\! = \ \varphi_1 & \hbox{ if } t \in T\subnum{1}\cr
&\!\!\! = 2^{nd}[act_{\cal B}^{-1}(t)] &\!  = \ \sigma_{1}^{y} & \hbox{ if } t \in T\subnum{2} \ \hbox{for some appropriate $y$}\cr
}}} 
\end{tabular}
\end{definition}

\noindent $act$ maps a situation into the action that brings it about. The reason for labeling situations or nodes in the game tree with actions in this manner is because $\tuple{T,\subset}$ is a tree and this means that each noninitial situation has a single action that generates it.


\subsection{Agents}\label{sec:A.4.3}

\begin{definition} $N = \{{\cal A}, {\cal B}\}$ is the set of agents.
\end{definition}


The function $\eta$ below determines whose turn it is to act.

\begin{definition}\label{def:A.8}\begin{tabular}[t]{l} {$\eta: T\subnum{0} \cup T\subnum{1} \functionarrow N$}\\
{\hspace{0pc}\vtop{\halign{$#$\ &\ $#$\ &\ $#$\hfil\cr 
\eta(t)&\!\!\! =
{\cal A} & \hbox{ if } t \in T\subnum{0} \cr &\!\!\! = {\cal B} & 
\hbox{ if } t \in T\subnum{1}\cr
}}} 
\end{tabular} \end{definition}

\noindent This is just a formal way of saying that $\cal A$ is the speaker and $\cal B$ the addressee.



\subsection{Prior probabilities}\label{sec:A.4.4}

The next item in the tuple is the prior probabilities. As we have seen, they are the most complex part of the game-theoretic structure because it is through them that each local game is connected with all the other local games, both locutionary and illocutionary, that materialize when a sentence is uttered. To enable the definition below, assume that the whole sentence uttered is $\varphi = \varphi_1\varphi_2\ldots\varphi_n$ for some $n$, as was done in \sectref{sec:solving locutionary global games}. In addition, remember that $x_{-1}$ is a variable that stands for any of the vectors formed by taking all the combinations of the possible semantic contents of locutions other than $\varphi_1$. As I am abstracting from syntax here, we do not consider the vector of possible syntactic contents $y$.

\begin{definition} $P: m_u(\varphi_1) \times m_u(\varphi_2) \times \ldots \times m_u(\varphi_n) \times \{u\} \functionarrow [0,1]$ such that $\sum_y\, P(\sigma_1^{y} \cond x_{-1}; u) = 1$ with $\sigma_1^{y} \in m_u(\varphi_1)$ and $x_{-1} \in m_u(\varphi_2) \times \ldots \times m_u(\varphi_n)$.
\end{definition}

%\noindent Each $m_u$ can cover either just the locutionary possibilities or both locutionary and illocutionary possibilities depending on whether we want locutionary and illocutionary contents to influence each other or not. 

%The second is that only lexical contents have been mentioned in the domain of $P$. To be complete, it would be necessary to include \emph{all} the constituents $\alpha$ of the sentence, words and phrases, but this would require looking at the Syntactic Constraint and would involve more encumbrances, so I avoid spelling out this more fully. The basic idea is clear enough and this is all I am after here. Besides, phrasal and sentential games can be built up from the corresponding lexical games through taking products.

This is a key reason why games of partial information differ from games of incomplete information.\is{game!incomplete information} Incomplete information games have a single pre-given probability distribution; as was first explained in \sectref{sec:generation game}, partial information games have multiple probability distributions for each local game. These form a \emph{third} set of \emph{strategic} choice variables along with the choice of utterance and interpretation from each $C_{\cal A}(s)$ and $C_{\cal B}(t)$. This strategic characteristic is made possible by the presence of the conditioning variables $x_{-1}$ because each different instantiation of these variables creates a different probability distribution $P(\sigma_1^{y} \mid x_{-1}; u)$ and the agents have to \emph{choose} one distribution from among many based on whether all such choices are in \emph{global} equilibrium\is{equilibrium!global} or not, the latter just being the equilibrium of the global game.


\subsection{Information sets}\label{sec:A.4.5}

Definition~\ref{def:A.4} and Propositions~\ref{prop:A.2} and \ref{prop:A.3} allow us to specify the information sets\is{information set} of each agent. They are \emph{information} sets precisely because they have been shown to have the appropriate epistemic properties.

\begin{definition} \begin{tabular}[t]{l} {$h_{\cal A}: T\subnum{0} \functionarrow \powset(T)$}\\ 
{$ h_{\cal A}(t) = \{ t' \in T\subnum{0} \mid
t' \equiv\!\!\__{\cal A}\,\, t \} = \{ t \} $}\\ 
\vspace{0.075in}
{$ H_{\cal A} = \{ h_{\cal A}(t) \mid t \in T\subnum{0} \} $} \\

%{}\\ 


{$h_{\cal B}: T\subnum{1} \functionarrow \powset(T)$}\\ 
{$ h_{\cal B}(t) = \{ t' \in T\subnum{1} \mid
t' \equiv\!\!\__{\cal B}\,\, t \} = T\subnum{1} $}\\ 
\vspace{0.075in}
{$ H_{\cal B} = \{ h_{\cal B}(t) \mid t \in T\subnum{1} \} $} \\

%{}\\ 


%{$h^{\cal B}\!\!\__{\varphi}: T(\varphi)
%\functionarrow 
%\powset(T(\varphi))$}\\ {$ h^{\cal B}\!\!\__{\varphi}(t) = \{ t' \in T(\varphi) :
%t' \equiv\!\!\__{\cal B}\,\, t \} $}\\
%{$ H^{\cal B}\!\!\__{\varphi} = \{ h^{\cal B}\!\!\__{\varphi}(t) : t \in T\subnum{1}(\varphi) 
%\} = T\subnum{1}(\varphi)/\!\!\equiv\!\!\__{\cal B}$.}\\ {}\\

{$H = H_{\cal A} \cup H_{\cal B}$}

\end{tabular} 
\end{definition}

\noindent Again, I observe that the situation-theoretic construction makes it possible to build information sets from the simpler objects $\equiv\!\!\__{\cal A}$ and $\equiv\!\!\__{\cal B}$ rather than just defining and imposing them outright. It provides an explanation of why they arise from the more basic epistemic properties of the game.



\subsection{Payoffs}\label{sec:A.4.6}\largerpage[1]

At one level, the payoffs\is{payoffs} are the easiest elements to define as all that is needed is two real-valued functions defined on the terminal situations in $T\subnum{2}$, with the understanding that each function encodes the same underlying preferences up to positive affine transformations. This would be the most general case. However, it is desirable to constrain these functions to respect the inequalities introduced in \sectref{sec:generation game}.
%~\\
\[ a_{\cal A} > c_{\cal A};\ \ a'_{\cal A} > c'_{\cal A};\ \ a_{\cal B} > c_{\cal B};\ \ a'_{\cal B} > c'_{\cal B} \] 

%\[ a'_{\cal A} > c'_{\cal A} \] 
%
%\[ a_{\cal B} > c_{\cal B} \] 
%
%\[ a'_{\cal B} > c'_{\cal B} \] 
%~\\
\noindent These inequalities pertain to games where there are only two initial situations. For games with more initial situations, note that the additional terminal situations that result all belong with instances where $\cal B$ has erred in her interpretation. All such situations are mapped into the lowest level of payoffs $c_{\cal A}$ or its cognates.

These inequalities were derived from the underlying preferences agents have for successful communication on the one hand and for minimizing effort or cost on the other. This is why it makes sense to constrain the payoff functions we define to obey these inequalities.

A little manipulation of prior constructs is required to express the condition that a terminal situation represents a correct interpretation or an incorrect one. This is not difficult to do but I rehearse it a bit to make it more readable.

To identify terminal situations where the interpretation is correct, we require that the situation $t \in T\subnum{2}$ satisfies:
%~\\
\[ 1^{st}[act_{\cal A}^{-1}(1^{st}[act_{\cal B}^{-1}(t)])] = s_{1^y} \in T\subnum{0} \]

%\[ 2^{nd}[act_{\cal A}^{-1}([1^{st}[act_{\cal B}^{-1}(t)])] = \varphi_1 \]

\[ 2^{nd}[act_{\cal B}^{-1}(t)] = \sigma_1^y \]
%~\\
\noindent\largerpage Both these conditions flow from Definitions~\ref{def:A.1}, \ref{def:A.1}, and~\ref{def:A.6}. The first condition simply traces the path back from the terminal situation $t$ to the initial situation $s_{1^y}$ in $T\subnum{0}$ by Definition~\ref{def:A.2} and the second condition requires that the interpretation leading to the terminal situation be $\sigma_1^y$, which is the content intended in $s_{1^y}$ by Definition~\ref{def:A.1}, thereby ensuring that the interpretation is the right one. These two conditions jointly capture the requirements for the highest payoffs like  $a_{\cal A}$ and its cognates. Similar conditions with suitable modifications are required to identify payoffs like $c_{\cal A}$ and its cognates.

\begin{definition} \begin{tabular}[t]{l} {$v_{\cal A}: T\subnum{2} \functionarrow \mathbb{R}$}\\
{$v_{\cal B}: T\subnum{2} \functionarrow \mathbb{R}$}\\
~\\
{such that $\forall t$, $t' \in T\subnum{2}$}\\
~\\
{if}\\
~\\
%{$t$ is such that}\\
{$1^{st}[act_{\cal A}^{-1}(1^{st}[act_{\cal B}^{-1}(t)])] = s_{1^y} \in T\subnum{0}$,}\\
%{$2^{nd}[act_{\cal A}^{-1}([1^{st}[act_{\cal B}^{-1}(t)])] = \varphi_1$,}\\
{$2^{nd}[act_{\cal B}^{-1}(t)] = \sigma_1^y$,}\\
~\\
{and}\\
~\\
%{$t'$ is such that}\\
%{$1^{st}[act_{\cal A}^{-1}([1^{st}[act_{\cal B}^{-1}(t')])] = s_{1^y} \in T\subnum{0}$,}\\
%{$2^{nd}[act_{\cal A}^{-1}([1^{st}[act_{\cal B}^{-1}(t')])] = \varphi_1^{y + 1}$,}\\
%{$2^{nd}[act_{\cal B}^{-1}(t')] = \sigma_1^y$,}\\
%~\\
%{and}\\
%~\\
%{$t''$ is such that}\\
{$1^{st}[act_{\cal A}^{-1}(1^{st}[act_{\cal B}^{-1}(t')])] = s_{1^y} \in T\subnum{0}$,}\\
%{$2^{nd}[act_{\cal A}^{-1}([1^{st}[act_{\cal B}^{-1}(t')])] = \varphi_1$,}\\
{$2^{nd}[act_{\cal B}^{-1}(t')] \neq \sigma_1^y$}\\
~\\
{then}\\
~\\
{$v_{\cal A}(t) > v_{\cal A}(t')$}\ {and}\ {$v_{\cal B}(t) > v_{\cal B}(t')$}\\
~\\
{$v = (v_{\cal A}, v_{\cal B})$}

\end{tabular} \end{definition}
~\\
\noindent The terminal situations $t'$ are those where the interpretation is incorrect. In general, there will be many terminal situations $t'$ when the number of initial situations in the game is greater than two. 

Both $v_{\cal A}$ and $v_{\cal B}$ obey the same constraints although the actual payoff numbers may be different for the two agents. $v$ collects both these functions in an ordered pair.

%I have deliberately not imposed any further conditions like the Pareto-Nash Inequalities or the Mixed Strategy Equilibria conditions first introduced in Section~3.2, or the risk dominance condition of Equation~\ref{eq:risk dominance condition} in Section~3.3.5.
%
%If a theory of costs\is{costs} and benefits\is{benefits} were available, it would have been possible to break down the payoff functions above into cost and benefit functions. Such costs and benefits depend on $u$ and $\cal L$. Making this dependence explicit would reinforce the situatedness of choice and game theory.


\subsection{The game tuple}\label{sec:A.4.7}

All the elements required for a local game are now at hand. 


\begin{definition} $g_u(\varphi_1) = \tuple{T,\subset \sep ACT,act \sep N,\eta \sep P \sep H \sep v}$ \end{definition}


\noindent The full local game is of course $\tuple{g_u(\varphi_1), {\cal I}_g}$, where ${\cal I}_g$ represents common knowledge between $\cal A$ and $\cal B$ of $g_u(\varphi_1)$.\is{game!partial information} In general, ${\cal I}_g$ represents the \emph{information structure} of the \emph{strategic interaction} and it may range from no shared information to full common knowledge.\footnote{See \citet[Section~3.3.4]{parikh:le} for further discussion.} This is part of the advantage gained by the situation-theoretic construction because it permits a natural extension of games where common knowledge obtains to more general strategic interactions where common knowledge may not obtain.

Earlier, in \sectref{sec:A.1}, I chose to avoid undue generality by fixing the utterance to be 
$\varphi_1$. It is now time to relax this constraint by letting the utterance vary freely over  $\cal L$.\footnote{Remember that $\cal L$ is the free monoid generated from the vocabulary $\cal W$ by the special concatenation operation $\circ_G$ together with the empty string $e$ and the zero element $0$ as mentioned in \sectref{sec:language definition}. Needless to say, $m_u(e) = \{\mathbf{1}\}$, $m_u(0) = \{\mathbf{0}\}$, and $m_u(\alpha) = \{\mathbf{0}\}$ when $\alpha \in {\cal L}$ is a grammatical but meaningless expression.}

\begin{definition} $g_u(\alpha)$ where $\alpha \in {\cal L}$ is defined analogously by replacing 
$\varphi_1$ with $\alpha$ and making all other corresponding changes in each component of the game tuple above. $g_u(e) = g_e$  and $g_u(0) = g_0$.\footnote{See \sectref{sec:universality}.} ${\cal G}$ is defined to be just the collection of all the tuples so obtained. This gives us the map $g_u: {\cal L} \functionarrow {\cal G}$.\footnote{I have already specified in \sectref{sec:A.2} that we have an anchor $f$ such that $f(\dot{\varphi}) = \alpha$ in order to secure that $\alpha$ is uttered in $u$. It is necessary to make the game map a total function. We can do this as follows: 

\begin{equation*}
g_{u[f]}(\alpha) = \left\{ \begin{array}{ll}
g & \mbox{if $f(\dot{\varphi}) = \alpha$} \\
g_{\alpha} & \mbox{otherwise}
			\end{array}
		\right. \label{eq:game map}
\end{equation*}
~\\
where $g$ is the game defined above when $\alpha$ is uttered in $u$ and where $g_{\alpha}$ is the game below:

%Figure 5
\begin{picture}(450,40)(65,15)
%\begin{picture} (450,140)(15,0)
%\begin{picture} (450,70)(0,0)
% Upper Tree

%\put(171,50){\input{unit1}}
\put(171,0){\input{figures/unit1}}

%\put(224,60)
\put(171,0)
{\begin{picture}(120,54)
%{\begin{picture}(120,15)
\put(108,27){\circle*{3}}
\put(54,27){\vector(1,0){54}}
\end{picture}}
% End of Upper Tree
%--------------------------------
% Upper Labels
\put(171,0)
{\begin{picture}(120,54)
%{\begin{picture}(120,15)
\put(0,18){\makebox(0,0){$\rho_{\alpha} = 1$}}
\put(0,36){\makebox(0,0){$s_{\alpha}$}}
\put(54,36){\makebox(0,0){$t_{\alpha}$}}
\put(27,33){\makebox(0,0){$\alpha$}}
\put(81,33){\makebox(0,0){$\mathbf{1}$}}
\put(126,27){\makebox(0,0){$0,0$}}
\end{picture}}
% End of Upper Labels
%--------------------------------------
% End of Figure 5
%-----------------------------------
\end{picture}}

\end{definition}

\noindent This completes the construction of the local game map $g_u$, the primary goal of the Appendix. 

%The theorem below then follows.


%\hspace{.1pc}

\begin{theorem} {$g_u(\alpha)$ where $\alpha \in {\cal L}$ is a local game of partial information.}\end{theorem}

\noindent As observed above, instead of simply \emph{defining} or legislating that the tuple above is a game, the situation-theoretic construction makes this fact a \emph{consequence} derived from more basic assumptions. It is possible to \emph{prove} that the tuple is a local game of partial information.

Games of partial information are in many ways similar to but slightly more general than games of incomplete information.\is{game!incomplete information} The particular subclass of partial information games we are concerned with -- those that apply to communication -- are in fact similar to but again slightly more general than the subclass of incomplete information games known in economics as signaling games.\is{game!signaling}

We can now introduce syntactic contents into these games and define syntactic local games by using a similar function $m'_u$ that maps elements of $\cal L$ into their possible parse trees based on the Syntactic Constraint.

%The two types of game models of partial and incomplete information are predictively identical.
%
%A signaling game starts with a move of Nature that reveals some private information to one  player. This private information is called the type of the player and is known only to that player and not to the other player. The other player knows only the range of possible values of this type, that is, the other possible moves of Nature, but does not know which particular value was instantiated. Then the same extensive form, consisting of some actions (signals) by the first player followed by some actions (responses) by the second player, is appended to each of these types. Since the same extensive forms are attached, there are often many nodes between which the second player cannot distinguish and these are collected into appropriate information sets. The first signaling games were invented by David \citet{lewis:c}\ia{Lewis, David}  who represented them in normal or strategic form, as mentioned in Sections~1.4.4 and 3.2. They were later studied by Michael \citet{spence:jms}\ia{Spence, Michael}, \citet{cs:sit}\ia{Crawford, V. P.}\ia{Sobel, J.}, and David \citet{kreps:oeb}\ia{Kreps, David} who represented them in extensive form which is now the standard form in economics for signaling games.\footnote{Games of partial information were first invented by the author in 1985.} 
%
%This form, defined for incomplete information games by \citet{kw:se}\ia{Wilson, Robert} and introduced in Section~A.3, is what we have used as the approximate target of our construction.
%
%What are the precise differences between signaling games and the relevant subclass of partial information games we have constructed?
%
%\begin{enumerate}
%
%\item In incomplete information signaling games, the same extensive form is always attached to each type (see for example Myerson~\citeyear{myerson:gt}, \citealt{or:cgt}, Watson~\citeyear{watson:s}; see \citealt{ks:s} for a parenthetically expressed relaxation of this requirement). In partial information games, this is not necessarily true: in general, $C_{\cal A}(s) \neq C_{\cal A}(s')$ where both $s$ and $s'$ belong to $T\subnum{0}$. Similar considerations apply, mutatis mutandis, to the sets of interpretive actions $C_{\cal B}(t)$ by $\cal B$.\footnote{See Parikh~\cite{parikh:pgpi} for more details.}
%
%\item Another difference is that, in partial information games involving communication, the interpretive act -- what Austin~\cite{austin:htdtww}\ia{Austin, J. L.@Austin, J. L.} called an act of understanding -- is always made explicit. In signaling games, there is usually an action the ``Receiver'' takes, and the interpretive act remains implicit and part of the solution process. Of course, since the action the Receiver can take is completely general, it can always be defined to be an interpretive action in purely formal terms. But it is in natural language communicative situations (e.g.\ with ambiguity) that the need for an explicit representation of this interpretive act becomes fully visible. Of course, if a further action is required after the interpretive act -- like the acceptance or rejection of a statement, or the carrying out of a request or command, or an answer in response to a question -- then that act is appended to the interpretive act.\footnote{See Parikh~\cite{parikh:ul}, Chapter 8.} The interested reader is referred to Parikh~\cite{parikh:gtm} for a generalization of this idea to \emph{all} games, even those that do not involve communication.
%
%\item A third difference, mentioned in Section~3.3.5, is that $\cal B$ constructs the game $g_u(\alpha)$ only after $\cal A$ has uttered $\alpha$, and similarly the game becomes common knowledge -- when common knowledge is warranted -- only after $\cal A$'s action. In signaling games, the entire game is common knowledge to both players before the start of the game.
%
%\item A related difference is that $g_u(\alpha)$ need not be common knowledge for both players in games of partial information. As was made clear in Section~3.3.4, it is generally enough to simply have each agent \emph{believe} that a certain extensive form and payoff structure is common knowledge. When these beliefs are false, more general strategic interactions result.
%
%\item Fifth, the initial probabilities are \emph{strategic} choice variables, just like the utterance and interpretation, as a result of the interconnectedness of the various local games associated with an utterance. No game of partial information -- in the context of communication -- is an isolated and independent entity but is interdependent with other related games. They always exist as a family.
%
%\item Lastly, this so-called \emph{local} game is embedded in a larger \emph{glocal} game described in Section~3.3.5. Incidentally, it is now easy to construct glocal games situation-theoretically and I leave this to the reader.
%
%
%\end{enumerate}
%
%
%To summarize the above, games of partial information generalize games of incomplete information (and their corresponding subclass of signaling games) but are predictively identical to them when they are analyzed in the same way. In some sense, the underlying game model is more important than the subsequent analysis through solution concepts, as there are usually several solution concepts that can be applied to a game model, most of which turn out to be equivalent for the simpler classes of games involved here.\footnote{I quote from Parikh~\cite{parikh:pgpi}:
%
%\begin{quote}
%
%In his paper, van Rooij~\cite{vanrooy:sgshs}\is{van Rooij, Robert} has the unfortunate title ``Signaling games select Horn strategies'' -- the game model, whether it is a game of partial information or a signaling game (of incomplete information), can never select anything as such; it is only the analysis of a game model based on a solution concept that results in some strategy being selected. He contrasts games of partial information with signaling games implying that, in a certain context, the latter give the expected result whereas the former don't, but this is impossible because the two models are predictively identical when analyzed identically. In addition, because both types of models have relatively simple structures, it will turn out that most solution concepts will yield identical predictions. This means that even if the two types of games are analyzed differently, they are still likely to yield the same outcomes, though of course this would be an incorrect comparative procedure. 
%
%The particular difference in prediction in van Rooij's paper cited above arose from two faulty sources. One is whether one uses mixed strategies or behavioral strategies to do the analysis; however, it is a well known result -- I believe going back to Kuhn~\cite{kuhn:egpi} -- that\ia{Kuhn, Harold} the two modes of analysis are predictively identical. So this cannot be a source of difference, even though van Rooij wrongly believed that he was using a different solution concept. As regards the real source, van Rooij has clarified in an email that he inadvertently used certain incorrect numbers which resulted in the different predictions. My thanks to him for pointing this out.
%
%\end{quote}
%}
%\is{game!signaling|)}


\section{The product of two games}\label{sec:A.5}

Now that games of partial information have been built and their collection $\cal G$ identified, it is possible to define their product $\otimes$. What has to be done is to start with two tuples, one for each multiplicand, and then construct the tuple for their product, building each component one by one from the components of the multiplicands. Along the way, it is necessary to prove that each component does in fact have all the required properties. For example, the payoff inequalities have to be preserved in the product when they are defined to be the sum of the corresponding payoffs in the multiplicands. 

%This would have to be proved to establish that the product game really is a game of partial information.

%that plays a central role in Equilibrium Semantics. It is straightforward but time-consuming to carry this out.

Once this is done, it becomes easy to show that $({\cal G}, \otimes)$ is a monoid and that $g_u(\alpha_1 \circ \alpha_2) = g_u(\alpha_1) \otimes g_u(\alpha_2)$, facts that are required in \sectref{sec:universality} to prove that $g_u: {\cal L} \functionarrow {\cal G}$ is an isomorphism in order to establish the universality\is{universality} of games of partial information in semantics.

%To define the product, start with two games $g_u(\omega_1) = \tuple{T_1,\subset \sep ACT_1,act_1 \sep N,\eta_1 \sep P_1 \sep \allowbreak H_1 \sep v_1}$ and $g_u(\omega_2) = \tuple{T_2,\subset \sep ACT_2,act_2 \sep N,\eta_2 \sep P_2 \sep H_2 \sep v_2}$ where $\omega_1$ and $\omega_2$ form a syntactic constituent like \Expression{the waiter}.

%
%\subsection{Situations and Choices}

%Given an utterance situation $u$, the speaker $\cal A$ forms an intention to convey a (partial) content $\sigma_1$ (like the referential content of \Expression{the}) and forms an intention to convey a (partial) content $\sigma_2$ (like the predicative content of \Expression{waiter}) as part of a full utterance and chooses a possibly ambiguous locution $\omega_1$ (like \Expression{the}) such that $\sigma_1 \in m_u(\omega_1)$ and a possibly ambiguous locution $\omega_2$ (like \Expression{waiter}) such that $\sigma_2 \in m_u(\omega_2)$. 

%%In the product situation (represented as $u_1 \times u_2$ where $u_1$ and $u_2$ are the relevant subsituations of $u$), $\cal A$ forms the product intention to convey the phrasal content $\sigma_1 \odot_u \sigma_2$ by uttering $\omega_1 \circ \omega_2$.

%The first element of the product tuple that has to be constructed is the tree of situations and to do this we start with the initial situations in $T_1$ and $T_2$ and construct their . Then we define $\cal A$'s choice sets in each of 
%these initial situations based on the function $alt_u$ from Definition~2. Next, we generate the situations that result from these possible actions based on $act_{\cal A}$ from Definition~3 and then identify $\cal B$'s choices in these resulting
%situations.  Finally,  we define the terminal situations that follow from $\cal B$'s interpretive  actions based on $act_{\cal B}$.  This collection of situations forms a tree under the subset ordering.

%\begin{definition} \begin{tabular}[t]{l} 

%{$T\subnum{0} = \{ s_{1^y}  \mid  \sigma_1^{y} \in m_u(\varphi_1) \} $}

%
%%{$T\subnum{0}: \{ \varphi_1 \} \functionarrow \powset({\cal S})$}\\  {$T\subnum{0}(\varphi_1) = \{ s_{1^y}  \mid  \sigma_1^{y} \in m_u(\varphi_1) \} $}

%%{$T\subnum{0}: C \functionarrow
%%P\!RO\!P$}\\  {$T\subnum{0}(\varphi) = \{ c(p) : p \in m(\varphi) \} .$}
%\\ {}\\

%{$C_{\cal A}:  T\subnum{0} \functionarrow \powset({\cal L})$}\\ {$C_{\cal A}(s_{1^y}) = \{ \varphi_1, alt_u(\varphi_1, \sigma_{1}^{y}) \} = \{ \varphi_1, \varphi_{1}^{y+1} \}$}\\ {}\\ 

%%{$T\subnum{1} : \{ \varphi_1 \} \functionarrow \powset({\cal S})$}\\ 

%
%{$T\subnum{1} = \{ act_{\cal A}(s_{1^y},\alpha) \mid s_{1^y} \in T\subnum{0},\ \alpha \in C(s_{1^y}) \}$}\\ {}\\ 

%

%%{$T\subnum{1} = \{ t \mid \exists s_{1^y} \in T\subnum{0},\ \exists 
%%\alpha \in C(s_{1^y})$}\\
%%{\phantom{$T\subnum{1} = \{ $}such that $act_{\cal A}(s_{1^y},\alpha) = t \}$}\\ {}\\ 

%{$C_{\cal B}: T\subnum{1} \functionarrow \powset({\cal I})$}\\ 
%{$C_{\cal B}(t) = m_u(\alpha)$ where $\alpha = 2^{nd}[act_{\cal A}^{-1}(t)]$}\\
%{}\\  

%{$T\subnum{2} = \{ act_{\cal B}(t, \tau) \mid t \in T\subnum{1},\ \tau \in D(t) \}$}\\ {}\\ 

%
%%{$T\subnum{2}: C \functionarrow P\!RO\!P$}\\
%%{$T\subnum{2}(\varphi) = \{ t : \exists  t' \in T\subnum{1}(\varphi),\ \exists p
%%\in D\__{\varphi}(t')$}\\
%%\phantom{$T\subnum{2}(\varphi) = \{$}{such that $g(t',p) = t 
%%\}.$}\\ {}\\ 

%{$T = \bigcup\__i T\__{i}$} \end{tabular} \end{definition}

%\noindent Each $C_{\cal A}(s)$ and $C_{\cal B}(t)$ are $\cal A$'s and $\cal B$'s choice sets in the relevant situations.

%This is one place where games of partial information differ from games of incomplete information because the usual definition of the latter requires that all the choice sets $C_{\cal A}(s)$ be equal and correspondingly that all the choice sets $C_{\cal B}(t)$ also be equal. This goes back to Harsanyi's~\cite{harsanyi:bayes} original definition of incomplete information games. Games of partial information relax this requirement.

%\begin{pr} \hspace{.1pc} $\tuple{T,\subset}$ is a ``tree'' (more accurately, forest). \end{pr}

%
%\noindent Since the more basic building blocks of situations and actions have been strung together piece by piece, the fact that $\tuple{T,\subset}$ is a tree is something that can now be \emph{proved} rather than simply assumed as is conventionally done. The nodes of the tree can in general represent situations or \emph{types} of situations.

%
%%\begin{definition} \begin{tabular}[t]{l} {$\forall t,t' \in T$, $t
%%\equiv\!\!\__{\cal A}\,\, t'$ iff 
%%$t = t'$.}\\ \noindent {$\forall t,t' \in T$,  $t \equiv\!\!\__{\cal
%%B}\,\, t'$ iff either (1) $t,t' \in T\subnum{0}$}\\ {or (2)
%%there exist $s,s' \in  T\subnum{0}$ such that $t = act_{\cal A}(s,\alpha)$}\\
%%{and $t' = act_{\cal A}(s',\alpha)$ for  some $\alpha$ in both $C_{\cal A}(s)$ and
%%$C_{\cal A}(s')$}\\ {or (3) $t=t'$.} \end{tabular} \end{definition}

%
%\begin{definition} \begin{tabular}[t]{l} {$\forall t,t' \in T\subnum{0}$, $t
%\equiv\!\!\__{\cal A}\,\, t'$ iff 
%$t = t'$.}\\ \noindent {$\forall t,t' \in T\subnum{1}$,  $t \equiv\!\!\__{\cal
%B}\,\, t'$ iff $t = t'$}\\ {or for  some $\alpha$ in both $C_{\cal A}(s)$ and $C_{\cal A}(s')$}\\ {there exist $s,s' \in  T\subnum{0}$}\\ 
%{such that $t = act_{\cal A}(s,\alpha)$ and $t' = act_{\cal A}(s',\alpha)$}.
% \end{tabular} \end{definition}

%

%
%\begin{pr} \hspace{.1pc} $\equiv\!\!\__{\cal A}$, $\equiv\!\!\__{\cal
%B}$ are equivalence relations. \end{pr}

%
%\noindent These equivalence relations capture the 
%relevant epistemic properties of the two agents because they have 
%the following consequences.

%\begin{pr} \hspace{.1pc}
%\begin{itemize} \item {For all $t,t' \in 
%T\subnum{1}$, $t \equiv\!\!\__{\cal B}\,\, t'$ implies 
%$C_{\cal B}(t) = C_{\cal B}(t')$.}

%\item {For all $t,t' \in T\subnum{1}$, $t \equiv\!\!\__{\cal B}\,\, t'$ 
%implies $t \not\subset t'$.}

%\item {For all $t,t' \in T\subnum{1}$, $t \equiv\!\!\__{\cal
%B}\,\, t'$ implies $\eta(t) = \eta(t')$.} 
%\end{itemize}
%\end{pr}

%\noindent The first statement says that $\cal B$ has the same choices at each of various equivalent situations. This is important because if the choices weren't the same the agent could use that information to distinguish between epistemically equivalent situations, a contradiction. The second statement says that of two equivalent situations one cannot precede the other. This again makes intuitive sense because if such precedence were possible, the agent would know it, and it would make the situations epistemically distinguishable. The last statement requires Definition~9 made below and says simply that the same agent has to act in all equivalent situations. The corresponding properties for ${\cal A}$ are trivially true. The key thing to note is that all these properties can now be \emph{proved} from more basic assumptions.

%
%\subsection{Actions}

%The third element of the game tuple above, the 
%set of actions in the game, is nothing but the union of all the choice sets 
%in Definition~4. This gathering of all the actions into a single set is just to maintain conformity with Kreps and Wilson's tuple, so that the game is rendered in a familiar form.

%\begin{definition} $ACT = [\bigcup\__{s \in T\subnum{0}} 
%C_{\cal A}(s) ] \cup [\bigcup\__{t \in T\subnum{1}} C_{\cal B}(t) ]$
%\end{definition}

%The map $act$ assigns an appropriate set of actions in $ACT$ to each noninitial situation in $T$.

%\begin{definition} \begin{tabular}[t]{l} {$act: T\subnum{1} \cup T\subnum{2} \functionarrow ACT$}\\
%{\hspace{0pc}\vtop{\halign{$#$\ &\ $#$\ &\ $#$\hfil\cr 
%act(t)&\!\!\! = 2^{nd}[act_{\cal A}^{-1}(t)] & \hbox{ if } t \in
%T\subnum{1} \cr
%&\!\!\! = 2^{nd}[act_{\cal B}^{-1}(t)] & \hbox{ if } t \in T\subnum{2}\cr
%}}} 
%\end{tabular}
%\end{definition}

%\noindent $act$ maps a situation into the action that brings it about. The reason for labeling situations or nodes in the game tree with actions in this manner is because $\tuple{T,\subset}$ is a tree and this means that each noninitial situation has a single action that generates it.

%
%\subsection{Agents}

%\begin{definition} $N = \{{\cal A}, {\cal B}\}$ is the set of agents.
%\end{definition}

%
%The function $\eta$ below determines whose turn it is to act.

%\begin{definition} \begin{tabular}[t]{l} {$\eta: T\subnum{0} \cup T\subnum{1} \functionarrow N$}\\
%{\hspace{0pc}\vtop{\halign{$#$\ &\ $#$\ &\ $#$\hfil\cr 
%\eta(t)&\!\!\! =
%{\cal A} & \hbox{ if } t \in T\subnum{0} \cr &\!\!\! = {\cal B} & 
%\hbox{ if } t \in T\subnum{1}\cr
%}}} 
%\end{tabular} \end{definition}

%\noindent This just offers a formal way of saying that $\cal A$ is the speaker and $\cal B$ the addressee.

%

%\subsection{Initial Probabilities}

%The next item in the tuple is the initial probabilities. As we have seen, they are, in a sense, the most complicated part of the game-theoretic structure because it is through them that each local game is connected with all the other local games, both locutionary and illocutionary, that materialize when a sentence is uttered. To enable the definition below, assume that the whole sentence uttered is $\varphi = \varphi_1\varphi_2\ldots\varphi_n$ for some $n$, as was done in Section~2.6. In addition, remember that $x_{-1}$ is a variable that stands for any of the vectors formed by taking all the combinations of the possible contents of locutions other than $\varphi_1$.

%\begin{definition} $P: m_u(\varphi_1) \times m_u(\varphi_2) \times \ldots \times m_u(\varphi_n) \functionarrow [0,1]$ such that $\sum\, P(\sigma_1^{y} \mid x_{-1}, u) = 1$ with $\sigma_1^{y} \in m_u(\varphi_1)$ and $x_{-1} \in m_u(\varphi_2) \times \ldots \times m_u(\varphi_n)$.
%\end{definition}

%\noindent There are two things to note in the above definition. The first is that each $m_u$ is intended to cover both locutionary and illocutionary possibilities as was clarified in Section~A.1. The second is that only lexical contents have been mentioned in the domain of 
%$P$. To be complete, it would be necessary to include \emph{all} the constituents $\alpha$ of the sentence, words and phrases, but this would require looking at the Syntactic Constraint \textbf{S} and would involve more encumbrances, so I avoid spelling out this more fully. The basic idea is clear enough and this is all I am after here.

%This is another area where games of partial information differ from games of incomplete information. Incomplete information games have a single pre-given probability distribution; as was first explained in Chapter~4, partial information games have multiple probability distributions for each local game. These form a \emph{third} set of \emph{strategic} choice variables along with the choice of utterance and interpretation from each $C_{\cal A}(s)$ and $C_{\cal B}(t)$. This strategic characteristic is made possible by the presence of the conditioning variables $x_{-1}$ because each different instantiation of these variables creates a different probability distribution $P(\sigma_1^{y} \mid x_{-1}, u)$ and the agents have to \emph{choose} one distribution from among many based on whether all such choices are in \emph{global} equilibrium or not.

%
%\subsection{Information Sets}

%
%Definition~5 and the corresponding Propositions~2 and 3 allow us to specify the information sets of each agent. They are \emph{information} sets precisely because they have been shown to have the appropriate epistemic properties.

%\begin{definition} \begin{tabular}[t]{l} {$h_{\cal A}: T\subnum{0} \functionarrow \powset(T)$}\\ 
%{$ h_{\cal A}(t) = \{ t' \in T\subnum{0} \mid
%t' \equiv\!\!\__{\cal A}\,\, t \} = \{ t \} $}\\ 
%{$ H_{\cal A} = \{ h_{\cal A}(t) \mid t \in T\subnum{0} \} $} \\{}\\ 

%
%{$h_{\cal B}: T\subnum{1} \functionarrow \powset(T)$}\\ 
%{$ h_{\cal B}(t) = \{ t' \in T\subnum{1} \mid
%t' \equiv\!\!\__{\cal B}\,\, t \} $}\\ 
%{$ H_{\cal B} = \{ h_{\cal B}(t) \mid t \in T\subnum{1} \} $} \\{}\\ 

%
%%{$h^{\cal B}\!\!\__{\varphi}: T(\varphi)
%%\functionarrow 
%%\powset(T(\varphi))$}\\ {$ h^{\cal B}\!\!\__{\varphi}(t) = \{ t' \in T(\varphi) :
%%t' \equiv\!\!\__{\cal B}\,\, t \} $}\\
%%{$ H^{\cal B}\!\!\__{\varphi} = \{ h^{\cal B}\!\!\__{\varphi}(t) : t \in T\subnum{1}(\varphi) 
%%\} = T\subnum{1}(\varphi)/\!\!\equiv\!\!\__{\cal B}$.}\\ {}\\

%{$H = H_{\cal A} \cup H_{\cal B}$}

%\end{tabular} 
%\end{definition}

%\noindent Again, I observe that the situation-theoretic construction makes it possible to build information sets from the simpler objects $\equiv\!\!\__{\cal A}$ and $\equiv\!\!\__{\cal B}$ rather than just defining and imposing them outright. It provides an explanation of why they arise from the more basic epistemic properties of the game.

%

%\subsection{Payoffs}

%At one level, the payoffs are the easiest elements to define as all that is needed is two real-valed functions defined on the terminal situations in $T\subnum{2}$, with the understanding that each function encodes the same underlying preferences up to positive affine transformations. This would be the most general case. However, it is desirable to constrain these functions to respect the inequalities introduced in Chapter~3.
%~\\
%\[ a_{\cal A} > b_{\cal A} > c_{\cal A} \] 

%\[ a'_{\cal A} > b'_{\cal A} > c'_{\cal A} \] 

%\[ a_{\cal B} > b_{\cal B} > c_{\cal B} \] 

%\[ a'_{\cal B} > b'_{\cal B} > c'_{\cal B} \] 
%~\\
%These inequalities pertain to games where there are only two initial situations. To consider games with more (or less) initial situations, all that needs to be noted is that the additional terminal situations that result all belong with instances where $\cal B$ has erred in interpreting the utterance. All such situations need to be mapped into the lowest level of payoffs $c_{\cal A}$ or its cognates.

%Keep in mind that these inequalities were derived from the underlying preferences agents have for successful communication on the one hand and for minimizing effort or cost on the other. This is why it makes sense to constrain the payoff functions we define to obey these inequalities.

%A little manipulation of prior constructs is required to express the condition that a terminal situation represents a correct interpretation or an incorrect one or the intermediate case where the interpretation is correct but the path to it involves a greater cost. This is not difficult to do but I rehearse it a bit to make it more readable.

%To identify terminal situations where the interpretation is correct and is realized with the lowest cost, we require that the situation $t \in T\subnum{2}$ satisfies:
%~\\
%\[ 1^{st}[act_{\cal A}^{-1}([1^{st}[act_{\cal B}^{-1}(t)])] = s_{1^y} \in T\subnum{0} \]

%\[ 2^{nd}[act_{\cal A}^{-1}([1^{st}[act_{\cal B}^{-1}(t)])] = \varphi_1 \]

%\[ 2^{nd}[act_{\cal B}^{-1}(t)] = \sigma_1^y \]
%~\\
%\noindent All of these conditions flow from Definitions~1, 2, and 3. The first condition simply traces the path back from the terminal situation $t$ to the initial situation $s_{1^y}$ in $T\subnum{0}$ by Definition~3; the second condition states that the utterance that led to the terminal situation be $\varphi_1$, which implies that it is the lowest cost action by Definition~2; and the last condition requires that the interpretation leading to the terminal situation be $\sigma_1^y$, which is the content intended in $s_{1^y}$ by Definition~1, thereby ensuring that the interpretation is the right one. These three conditions jointly capture the requirements for the highest payoffs like  $a_{\cal A}$ and its cognates.

%Similar conditions with suitable modifications are required to identify payoffs like $b_{\cal A}$ and its cognates and $c_{\cal A}$ and its cognates.

%
%\begin{definition} \begin{tabular}[t]{l} {$v_{\cal A}: T\subnum{2} \functionarrow \mathbb{R}$}\\
%{$v_{\cal B}: T\subnum{2} \functionarrow \mathbb{R}$}\\
%~\\
%{such that $\forall t$, $t'$, $t'' \in T\subnum{2}$}\\
%~\\
%{if}\\
%~\\
%%{$t$ is such that}\\
%{$1^{st}[act_{\cal A}^{-1}([1^{st}[act_{\cal B}^{-1}(t)])] = s_{1^y} \in T\subnum{0}$,}\\
%{$2^{nd}[act_{\cal A}^{-1}([1^{st}[act_{\cal B}^{-1}(t)])] = \varphi_1$,}\\
%{$2^{nd}[act_{\cal B}^{-1}(t)] = \sigma_1^y$,}\\
%~\\
%{and}\\
%~\\
%%{$t'$ is such that}\\
%{$1^{st}[act_{\cal A}^{-1}([1^{st}[act_{\cal B}^{-1}(t')])] = s_{1^y} \in T\subnum{0}$,}\\
%{$2^{nd}[act_{\cal A}^{-1}([1^{st}[act_{\cal B}^{-1}(t')])] = \varphi_1^{y + 1}$,}\\
%{$2^{nd}[act_{\cal B}^{-1}(t')] = \sigma_1^y$,}\\
%~\\
%{and}\\
%~\\
%%{$t''$ is such that}\\
%{$1^{st}[act_{\cal A}^{-1}([1^{st}[act_{\cal B}^{-1}(t'')])] = s_{1^y} \in T\subnum{0}$,}\\
%{$2^{nd}[act_{\cal A}^{-1}([1^{st}[act_{\cal B}^{-1}(t'')])] = \varphi_1$,}\\
%{$2^{nd}[act_{\cal B}^{-1}(t'')] \neq \sigma_1^y$}\\
%~\\
%{then}\\
%~\\
%{$v_{\cal A}(t) > v_{\cal A}(t') > v_{\cal A}(t'')$}\\
%~\\
%{and}\\
%~\\
%{$v_{\cal B}(t) > v_{\cal B}(t') > v_{\cal B}(t'')$}\\
%~\\
%{$v = (v_{\cal A}, v_{\cal B})$}

%\end{tabular} \end{definition}
%~\\
%\noindent The terminal situations $t'$ are those where the interpretation is correct but the utterance is not the cheapest, and so lead to the intermediate payoffs $v_{\cal A}(t')$ and $v_{\cal B}(t')$ akin to $b_{\cal A}$ and $b_{\cal B}$. Likewise, the terminal situations $t''$ are those where the interpretation is incorrect but the utterance is the lowest cost one and so lead to the lowest payoffs $v_{\cal A}(t'')$ and $v_{\cal B}(t'')$ akin to $c_{\cal A}$ and $c_{\cal B}$. In general, there will be many terminal situations $t''$ when the number of initial situations in the game is greater than two. 

%Both $v_{\cal A}$ and $v_{\cal B}$ obey the same constraints although the actual payoff numbers may be different for the two agents. $v$ collects both these functions in an ordered pair.

%I have deliberately not imposed any further conditions like the Pareto-Nash Inequalities or the Mixed Strategy Equilibria conditions first introduced in Section~3.2.

%If a theory of costs and benefits were available, it would have been possible to break down the payoff functions above into cost and benefit functions. Such costs and benefits depend on $u$ and $\cal L$. Making this dependence explicit would reinforce the situatedness of choice and game theory.

%
%\subsection{The Game Tuple}

%All the elements required for a local game are now at hand. 

%
%\begin{definition} $g_u(\varphi_1) = \tuple{T,\subset \sep ACT,act \sep N,\eta \sep P \sep H \sep v}$ 
%\end{definition}

%
%\noindent The full local game is of course $\tuple{g_u(\varphi_1), {\cal I}_g}$, where
%${\cal I}_g$ represents common knowledge between
%$\cal A$ and $\cal B$ of $g_u(\varphi_1)$.\is{game!of partial information} In general, as was said in Section~3.3.4, ${\cal I}_g$ represents the \emph{information structure} of the \emph{strategic interaction} and it may range from no shared information to full common knowledge. This is part of the advantage gained by the situation-theoretic construction because it permits a natural extension of games where common knowledge obtains to more general strategic interactions where common knowledge may not obtain.

%Earlier, in Section~A.1, I chose to avoid undue generality by fixing the utterance to be 
%$\varphi_1$. It is now time to relax this constraint by letting the utterance vary freely over  $\cal L$.\footnote{Remember that $\cal L$ is the free monoid generated from the vocabulary $\cal V$ by the special concatenation operation $\circ$ together with the empty string $e$ and the zero element $0$ as mentioned in Section~2.6. Needless to say, $m_u(0) = \{\mathbf{0}\}$ and $m_u(\alpha) = \{\mathbf{0}\}$ when $\alpha \in {\cal L}$ is a grammatical but meaningless expression.}

%\begin{definition} $g_u(\alpha)$ where $\alpha \in {\cal L}$ is defined analogously by replacing 
%$\varphi_1$ with $\alpha$ and making all other corresponding changes in each component of the game tuple above. $g_u(e) = g_e$ where $g_e$ is the trivial game with a single initial node, a single branch labeled $e$, and a further single branch labeled $\mathbf{1}$ issuing from the node ending the first branch with any payoff at the terminal node, and $g_u(0) = g_0$ where $g_0$ is the the trivial game with a single initial node, a single branch labeled $0$, and a further single branch labeled $\mathbf{0}$ issuing from the node ending the first branch with any payoff at the terminal node. ${\cal G}$ is defined to be just the collection of all the tuples so obtained. This gives us the map $g_u: {\cal L} \functionarrow {\cal G}$.  
%\end{definition}

%\noindent This completes the construction of the local game map $g_u$, the primary goal of the Appendix. The theorem below then follows.

%
%%\hspace{.1pc}

%\begin{thm} {$g_u(\alpha)$ where $\alpha \in {\cal L}$ is a local game of partial
%information.}
%\end{thm}

%\noindent As observed above, instead of simply \emph{defining} or legislating that the tuple above is a game, the situation-theoretic construction makes this fact a \emph{consequence} derived from more basic assumptions. It is possible to \emph{prove} that the tuple is a local game of partial information.

%


I leave this construction and the proofs of the corresponding facts as an exercise for the reader. 

%Instead of defining $\cal G$ directly as was done in Definition~13, it could be freely generated from just the lexical games\is{game!lexical} via the product. Both approaches yield the same set.

\section{The compact form}\label{sec:A.6}

%It is straightforward to collect all the local games generated by an utterance into a locutionary global game. 

A compact form for the locutionary global game can now be defined as discussed in \sectref{sec:solving locutionary global games}. This is straightforward to do as all its components have already been constructed.


\section{Solution concepts}\label{sec:A.7}

The next step would be to define the notion of a strategy for such games and examine various solution concepts. Because all the local games generated by an utterance are interconnected through the prior probabilities, it becomes necessary to extend the standard definitions of a strategy and the corresponding equilibria. This involves \emph{two} things: one is to provide for the strategic nature of the prior probability distributions and the other is to build a definition of \emph{global} equilibrium\is{equilibrium!global} based on the solution concept one starts with, presumably Pareto-Nash equilibrium. I have shown how to do this informally in \sectref{sec:solving locutionary global games} and the definitions do not pose any special obstacles.

Whatever solution concepts we employ, they make possible the construction of the second basic map of Equilibrium Semantics $f_u: {\cal G} \functionarrow {\cal I}$, whose existence and uniqueness were established by the universality result of \sectref{sec:universality}.\is{universality} Once we have both maps $g_u$ and $f_u$, we have essentially derived our fundamental global fixed point equations: Equations~\ref{eq:simple} and \ref{eq:simple with payoffs} from Theorems~\ref{thm:simple equation} and~\ref{thm:compatibility with payoffs}.

%\[ {\cal C}_u(\alpha,  P(x \mid u)) = f_u[g_u(\alpha, P(x \mid u))] = x \]
%~\\
This completes a mathematical rendering of the core framework of Equilibrium Semantics from first principles. It can be extended to all the other games mentioned at the start of the Appendix in a natural way.
