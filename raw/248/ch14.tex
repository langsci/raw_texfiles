\chapter{Distance} \label{ch:distance}

It is reasonable to suppose that just as people form intuitive judgments about physical distance which may be more or less accurate, so people routinely form intuitive and subpersonal judgments about the distance between two infons. This judgment about informational distance is always relative to the situation in\linebreak which it is made and also relative to the goals of the agents in that situation. It is a subjective assessment that sometimes becomes conventionalized.

Just as one thinks of physical distance in terms of the path that takes one from here to there, one can think of informational distance in terms of the steps that take one from one infon to another, so perhaps the best way to fix this notion is through human reasoning. Agents attempt to derive information that enables them to fulfill their goals. Such inferences involve a variety of modes of reasoning including especially abduction,\is{abduction} but also deduction, induction, probabilistic (e.g.\ Bayesian) and plausible reasoning, and so on.\footnote{\citet{ar:r} is a large collection of papers that discuss a variety of modes of reasoning.}

To start with, there is a situation $u$ and a corresponding Communication Game $\Gamma_u$. $\Gamma_u$ contains a Setting Game $SG_u$ which has information about the setting with respect to which some communication takes place. Either because of prior utterances or because of the interaction between the agents, both of which are housed within $SG_u$, some information about the agents' explicit or implicit goals may become public. If the goals are not already common knowledge, the agents invoke the Cooperative Principle to assume that their goals are shared. For example, $\cal A$ and $\cal B$ may be discussing where to eat, in which case their (implicit) goal would be to eat out together. This goal is common knowledge so the Cooperative Principle is already satisfied.

Next, an agent may utter a sentence $\varphi$ based on a Generation Game $GG_u$ induced by a Content Selection Game $CSG_u$ which in turn is induced by $SG_u$. This utterance is evaluated by $\cal B$ in the Interpretation Game $UG_u$ and will have some locutionary content $\sigma^{\ell}$ determined via the locutionary game $LG_u(\varphi)$ as discussed in \partref{part:III}. Recall that the Setting Game or conversational goals influenced the formation of preferences and prior probabilities in $LG_u(\varphi)$ which helped determine locutionary meaning. Now we will see how they help in identifying illocutionary meaning.

Once $\cal B$ derives $\sigma^{\ell}$ he checks if it fulfills their shared goal, shared either by virtue of it being common knowledge or by being assumed via the Cooperative Principle. If it fulfills the goal, there is nothing more to be done. In this event the whole intended meaning of the utterance is just $\sigma^{\ell}$. If it falls short of the goal, then a search for one or more illocutionary meanings is \emph{triggered}.

It is in the course of this search that distance and relevance play a role in generating the possibilities for illocutionary meaning that are later disambiguated by the illocutionary Flow Constraint which is made up of the illocutionary global game $IG^{\cal B}_u(\varphi)$. There are no conventional meanings to generate the possibilities as there were for locutionary meaning. So the illocutionary Semantic Constraint can no longer rely on the Conventional and Referential sub-Constraints. Instead, it must use the Relevance and Distance sub-Constraints to generate the possibilities. The search for illocutionary possibilities takes place within the infon space $\cal I$ and involves a \emph{derivation} of one or more contents from the locutionary content relative to $u$. This derivation involves a sequence of steps from initial premises to conclusions and has a length.

In general, the situated distance $d^{\cal B}_u(\sigma, \tau)$ between two infons $\sigma$ and $\tau$ for $\cal B$ with respect to $u$ can be defined as the length of the derivation from $\sigma$ to $\tau$ that $\cal B$ actually undertakes in $u$ relative to $\cal B$'s goals in $SG_u$ (that are assumed to be shared with $\cal A$) and relative to other infons in $u$. These other infons in $u$ may be part of the agent's explicit beliefs, they may come from what she is perceiving, they may come from the common ground of the dialogue taking place, and so on. In any event, they constitute a \emph{finite} set.\footnote{It is not clear how the underlying space of infons through which the agent searches is structured but it may be thought of as a graph of some kind. A graph is a set of vertices representing the infons in the space together with directed or undirected edges linking them that represent various kinds of inferential steps. This notion of distance is not a metric as the symmetry condition $d^{\cal A}_u(\sigma, \tau) = d^{\cal A}_u(\tau, \sigma)$ for all $\sigma$ and $\tau$ may not be satisfied. In any case, this condition is not required for the idea to work. See \citet[Section~3]{be:iii} for a partial implementation of such a graph.}

To clarify what is meant in the above definition of distance by ``relative to $\cal B$'s (shared) goals in $SG_u$,'' there is always a step in the reasoning involving an implication such as $\tau' \rightarrow \hbox{Goal}$ where $\hbox{Goal}$ is an infon representing a conversational goal. Then, either because $\hbox{Goal}$ is common knowledge or because it can be assumed via the Cooperative Principle, $\cal B$ can infer $\tau'$ by abduction.\is{abduction} Usually, $\tau' = \tau$, the end state of the derivation, but occasionally there may be one or more steps beyond $\tau'$ to $\tau$. Also, there may be other such implications like, for example, $\tau'' \rightarrow \hbox{Goal}$, in which case $\tau''$ could be another conclusion reached by the search. This will become clearer when I discuss concrete examples below. As I will also show, because human reasoning is extremely broad and versatile, employing all kinds of inferential steps, it is probably not possible to capture it in any logical calculus or pin down the definition of distance more precisely.

There will be a corresponding distance $d^{\cal A}_u(\sigma, \tau)$ for $\cal A$ as both agents have to reason from $\sigma$ to $\tau$, one in the Generation Game and the other in the Interpretation Game. This is what would make the final result $\tau$ common knowledge if it survives all the other requirements for being an illocutionary meaning. But the precise derivations for the two agents may differ and so $d^{\cal A}_u(\sigma, \tau)$ may not equal $d^{\cal B}_u(\sigma, \tau)$. 

This idea of distance constitutes the second sub-Constraint of the Semantic Constraint for illocutionary meaning. The way the two sub-Constraints of Relevance and Distance are meant to work together once a search is triggered is as follows. Assume for the moment that the only indirect meaning being considered is an implicature.\footnote{In earlier chapters, I have used the terms \emph{locutionary} and \emph{illocutionary} for direct and indirect contents. Here, I will use the two pairs of terms interchangeably to make the writing and reading smoother. The first terms of each pair correspond to the content that results primarily from the conventional meanings of the uttered words whereas the second terms of each pair correspond to the content that arises primarily from the context. This is not meant to be a black-and-white distinction.} Essentially, the infon $\sigma$ and other infons present through $u$ and through $\cal B$'s goals provide a space through which $\cal B$ searches either consciously or nonconsciously for derivations to a sufficiently \emph{relevant} set of conclusions. When the distance, that is, the length of these derivations, is also sufficiently small, they become possible candidates for the Flow Constraint. In other words, distance and relevance have to be compared with situated thresholds. Crucially, one does not have to check each infon in $\cal I$ to find the candidates, which is an infinite task. One starts from the locutionary content or its proper parts and then proceeds \emph{locally} until one reaches a relevant conclusion that fulfills one's goal within a specified radius.

Suppose the distance and relevance thresholds are $\epsilon_{d,u}$ and $\epsilon_{R,u}$ respectively. I have omitted the agent superscripts on these thresholds to avoid clutter but different agents will, in general, have different thresholds. One can now identify an ``open ball'' $\hbox{Ball}^{\cal B}_u(\sigma^{\ell}, \epsilon_{d,u}) = \{ x \in {\cal I} \mid d^{\cal B}_u(\sigma^{\ell}, x) < \epsilon_{d,u} \}$ inside which all distances from $\sigma^{\ell}$ to $x$ must lie.\footnote{I have borrowed the term ``open ball'' from the context of metric spaces.} Further, only those $x$ that also have $\hbox{Relevance}_u(x) > \epsilon_{R,u}$ qualify as possible implicatures. Thus, the set of possible implicatures is given by $\{ x \in \hbox{Ball}^{\cal B}_u(\sigma^{\ell}, \epsilon_{d,u}) \mid  \hbox{Relevance}_u(x) > \epsilon_{R,u} \}$. Because agents are finite, the space searched is finite. So it becomes possible to search locally in a computationally tractable way within the ball for sufficiently relevant candidate implicatures. \citet[Section~1.3]{jm:slp2} discuss a variety of algorithms (e.g.\ graph algorithms such as depth-first search) for such tasks when they have to be performed by artificial agents. These candidate implicatures can then be supplied to the illocutionary Flow Constraint which disambiguates among them and chooses the best ones.

The reason why the two thresholds above are subscripted with $u$ is that they may be different for different kinds of communication. When interpreting a novel or a poem, for example, it is reasonable to form extended derivational chains consciously. In such cases, the open ball will be much larger than it would be for ordinary face-to-face communication. In the case of Relevance, too, different kinds of conclusions might be found relevant depending on what is being interpreted, whether some immediate communication or some remote text. In the latter case, an addressee's tolerance may be greater, making the corresponding threshold lower.

I repeat that the local search for implicatures and other indirect meanings is triggered by the locutionary content or its proper parts falling short of the agent's goals in one way or another. If such a content is adequate, there will be no need to search for further meanings. This means there are three steps in eliciting indirect meanings: first check if the locutionary content or its proper part fulfills the conversational goal appropriately and, if not, then search locally via the illocutionary Semantic Constraint consisting of Relevance and Distance to produce candidate implicatures or other indirect meanings, and, last, submit these candidates to the illocutionary Flow Constraint for disambiguation.

The procedure sketched above provides a more or less complete description of the task of computing the implicatures of an utterance, when to look for them and how to find the possibilities and how to identify the best ones. In implementing such an idea computationally it would be necessary to set up an actual search space of infons and various inferential modes of traversing this space. Needless to say, this is nontrivial to do. To make things more concrete, reconsider Grice's\ia{Grice, Paul@Grice, Paul} example of the stranded motorist I discussed in \sectref{sec:theory of conversation}. Let the sentence uttered by the passerby in response to the motorist saying ``I am out of gas'' be:

\begin{exe}
\ex There is a garage around the corner. ($\psi$)
\end{exe}

\noindent As I noted earlier, an utterance of $\psi$ in the context described has been generally taken to have the implicature that the speaker thinks the garage might be open. How would such an implicature be derived in a rigorous and complete way given just the locutionary content of the utterance and $u$?

First, note that the prior utterance, ``I am out of gas,'' makes the goal of the motorist public in the Setting Game for the utterance of $\psi$ in $u$. Since it is not common knowledge this goal is \emph{shared} by the passerby, this is assumed by invoking the Cooperative Principle. The locutionary content $\sigma^\ell$ of $\psi$ in $u$ does not, by itself, fully meet this goal of getting gas. So a local search for one or more implicatures is triggered.

If the implicature referred to above is denoted by $\tau$, then it is plausible to say that in the utterance situation $u$ the two infons $\sigma^\ell$ and $\tau$ are relatively \emph{near} each other, that is, $d_u(\sigma^\ell, \tau)$ is within the threshold $\epsilon_{d,u}$ or, equivalently, $\tau$ lies inside the corresponding open ball. This is because the chain of reasoning from $\sigma^\ell$ to $\tau$ is quite short and the distance may even be just $3$ or $4$ units depending on how one counts the steps, which depends on how the search space is set up in the agent's head. For example, the addressee may start with common knowledge of $\sigma^\ell$ that the garage is around the corner and common knowledge that $\sigma^\ell$ falls short of his goal. Then he may observe that the speaker has uttered the sentence $\psi$ in response to his goal. If the speaker's cooperation is assumed, it follows that the speaker would not have said this if he knew the garage was closed. Indeed, it is plausible to conclude that the speaker thinks it is open because this fulfills the addressee's goal. This is about $3$ or $4$ steps to $\tau$ and all of them are common knowledge. So the distance from $\sigma^{\ell}$ to $\tau$ is about $3$ or $4$ units as undertaken in $u$ and would certainly be contained within the open ball. So the first requirement of Distance has been met. 

Since clearly $\hbox{Relevance}_u(\tau) > \epsilon_{R,u}$ as well because the motorist is out of gas and needs to fill up (i.e.\ this value of information is also related to the interlocutor's goal), one strand of the local search stops with $\tau$ and we can conclude that $\tau$ qualifies as a \emph{candidate} implicature. Crucially, it is not necessary to pull $\tau$ out of thin air and then evaluate its distance and relevance. On the contrary, $\tau$ is \emph{discovered} by the agent as he searches locally through the associated space. This candidate implicature then becomes one \emph{possible} interpretation in the relevant illocutionary partial information game. As will be shown in the next chapter, such an implicature would be derived with some probability as a solution to this game so that its being an implicature is \emph{seldom} certain. This is because it is possible that the passerby does not give any thought to whether the garage is open or not.

Both the Distance and Relevance sub-Constraints are evaluated relative to the agent's goals. But the nature of the computation in each case is quite different. In the former, a derivation is constructed, and in the latter, the \emph{value} of the information is computed. It may happen that there is no derivation that fulfills the goals and then a suitable conclusion has to be drawn (e.g.\ that the speaker does not know the required information or is cooperating only partially or not at all). I will look at such an example in \chapref{ch:implicature}.

How does the search algorithm know where to stop as it reasons along the search space starting from $\sigma^\ell$? With each step it takes to some $x \in {\cal I}$, it tests whether $\hbox{Relevance}_u(x) > \epsilon_{R,u}$ and whether the goal is fulfilled. If not, it keeps going. For example, the intermediate steps in the three- or four-step reasoning above were not sufficiently relevant. Finally, it either reaches an infon like $\tau$ which \emph{is} sufficiently relevant and which fulfills the goal or it goes outside the ball. If the former, $\tau$ is accepted as a candidate; if the latter, it returns empty-handed to $\sigma^\ell$. In either case, a new local search begins.

If we assume both interlocutors are aware of a few gas stations nearby then such a new search might lead to another \emph{possible} implicature $\tau'$ that the gas available at the garage around the corner is inexpensive as the passerby may be offering the best option among the available ones. This is because $\tau'$ is also near $\sigma^\ell$ as $\tau$ was and is discovered in the same way. It is possible that $d_u(\sigma^\ell, \tau) < d_u(\sigma^\ell, \tau')$ even though $\tau'$ may also lie within the open ball. Its relevance is also sufficiently high in $u$ though, again, it is likely that $\hbox{Relevance}_u(\tau) > \hbox{Relevance}_u(\tau')$. So $\tau'$ could also become a candidate implicature. It is hard to be sure whether the speaker is possibly conveying $\tau'$ or not because goals such as a general preference for inexpensive gas can be implicitly shared. Most likely, it can be taken to be an implicature by the Flow Constraint with an even lower probability than $\tau$. Such considerations show how much indeterminacy can be present at the level of both the Semantic and Flow Constraints.

%But the fact that the desirability of inexpensive gas was not an \emph{explicit} goal expressed in the motorist's prior utterance might also mean that such a goal was not common knowledge and so $\tau'$ may, in fact, not be derivable within the open ball. This might rule it out even as a candidate implicature.

A possibility I have never seen addressed is why the passerby might not be implying that he would fetch the gas from the garage for the motorist. Call this $\tau''$. It is assumed because Grice assumed it that the implicature is $\tau$ and not $\tau''$. The latter certainly fulfills the motorist's goal and is certainly relevant: indeed, its value may be potentially higher even if its probability may be lower. But, in most circumstances, $\tau''$ would be ruled out by everyone. It would \emph{not} be near $\sigma^\ell$ as even though $\tau'' \rightarrow \hbox{Goal}$, the abductive inference to $\tau''$ \is{abduction} would be blocked because it is not the \emph{best} explanation. So even though it is relevant, its distance is infinite or at least beyond the open ball. Practically every method of deriving implicatures (e.g. Gricean \ia{Grice, Paul@Grice, Paul} or Relevance-Theoretic \is{Relevance Theory} or \citealt{benz:i}) \ia{Benz, Anton@Benz, Anton} fails to disqualify such possibilities. As such examples are omnipresent, this shows their account of implicature is seriously inadequate.

%This is because of shared but implicit background information that it is reasonable to help up to a point in such circumstances. If the motorist had been disabled then, maybe, such an implicature could be derived but, generally, the passerby would then choose to convey the information explicitly so as to remove any doubt in the motorist's mind. 

%A second way it would be eliminated is by the illocutionary Flow Constraint. Even if it did somehow manage to make it as a candidate, the relevant game of partial information would rule it out because its prior probability would be far too low and it would never be a solution to the game in such situations.



Finally, as mentioned in \sectref{sec:semantics and pragmatics}, there is a certain indeterminacy between whether the illocutionary meaning in question is the implicature $\tau$ or is the modulated meaning $\tau'''$, the content that there is a \emph{possibly open} garage around the corner. That is, the distance $d_u(\sigma^\ell, \tau''')$ is also small. 

%This shows informally how we may get candidate implicatures and candidate modulations in roughly the same way using the twin ideas of Relevance and Distance.

The search algorithm terminates its search when no new steps can be taken from $\sigma^\ell$. Note that I have informally described one version of depth-first search and it is not the only way that this search might be organized. The goal of any algorithm is to locate all the infons in $\{ x \in \hbox{Ball}^{\cal B}_u(\sigma^{\ell}, \epsilon_{d,u}) \mid  \hbox{Relevance}_u(x) > \epsilon_{R,u} \}$, the set of possible indirect meanings starting from $\sigma^\ell$. 

%The algorithm I have just outlined may miss sufficiently relevant infons that lie beyond $\tau$ but inside the ball. But I am not concerned with actually furnishing a detailed algorithm, just a suggestion of one for illustrative purposes. 

In principle, there could be other sets of possible indirect meanings  issuing from the proper \emph{parts} of $\sigma^\ell$ as well. The distance to $\tau'''$ that I took to be $d_u(\sigma^\ell, \tau''')$ would actually be $d_u(\soa{\hbox{garage}}, \tau''')$ where $\soa{\hbox{garage}}$ is the proper part of $\sigma^\ell$ that corresponds to the word \Expression{garage} in $\psi$. Such examples arise not just with modulated meanings but also with implicatures and free enrichments and other indirect meanings triggered by subsentential expressions.

%like $\{ x \in \hbox{Ball}^{\cal B}_u(\sigma^{\ell}, \epsilon_{d,u}) \mid  \hbox{Relevance}_u(x)\break > \epsilon_{R,u} \}$

In the discussion of this example I have throughout used distances without any agent superscript. In fact, similar computations have to be undertaken by both agents, the speaker in the Generation Game and the addressee in the Interpretation Game. Even though the details of the calculations are private, each agent has common knowledge that such calculations exist in the other's mind. This is what results in common knowledge of the implicature once it passes the further requirement of the illocutionary Flow Constraint.

I have given a fairly detailed analysis of this example but it is not, in fact, detailed enough. I have focused mainly on the addressee's goal which is assumed to be shared via the Cooperative Principle. But the speaker's goals also play a role as they are also implicitly shared. For instance, the inference to $\tau''$ is blocked in most circumstances because it is implicitly shared that the passerby has other goals of his own and would not want to fetch the gas for the motorist. Thus, there is generally a mutual sharing of both agents' explicit and implicit goals that permit some candidates to be licensed while others are eliminated. This implies that cooperation is almost always \emph{partial}, a nuance that is missing from Grice's Cooperative Principle.
\ia{Grice, Paul@Grice, Paul}
%This example suggests one way to improve the informal definition of distance I have provided. 

I have implicitly assumed that each step of a derivation is equally easy for the agent. But this may not be true. For example, the steps involved in reaching $\tau'$ may be harder than those involved in reaching $\tau$  as $\tau'$ is less related to the agent's immediate need. So one can assume that each step comes with a weight or cost and the distance then is not the length of a derivation but its cost. If the search space is a graph, then its edges would have weights. This idea of a weighted graph could model the more imaginative kinds of reasoning involved in interpreting the indirect meanings of a poem or novel. There is a certain creativity involved in such interpretations and the task of the literary critic is a costly one.

%How might the weights or costs be determined? One can speculate that they might have to do with proximity to the agent's goals, some being more important than others, and some being less explicit than others, as well as other factors. Sometimes when an implicature pertains to an implicit goal of the speaker, the addressee may not get it if the goal is not common knowledge. This would be explained by the fact that the inference was too difficult as the costs to the relevant conclusion were too high.

The conception of distance I have offered does not yet tell us how the implicature of an utterance of \Expression{He is a fine friend} might be derived because the implicature is precisely the negation of the locutionary content as discussed in \sectref{sec:theory of conversation}. How can the agent start from a content and arrive at its negation? For this, a slight adjustment in the procedure is required. Recall that the distance between two infons $\sigma$ and $\tau$ is to be calculated relative to other infons present in $u$. Such other infons include background knowledge that the agents share or are perceiving as well as the common ground of the dialogue taking place. So the procedure has to start with a whole \emph{set} of premises, not just a single infon $\sigma$. This set could be internally inconsistent -- the speaker could not be conveying the locutionary meaning because it contradicts the common knowledge the agents have that the person is question has cheated the speaker -- and so the reasoning process must include cases where such a set of infons may need some revision, just as happens in situations where our beliefs have to be revised sometimes in the light of new knowledge or because they are internally inconsistent. This kind of revision may result in rejecting $\sigma$, the starting point, or one of the other premises, depending on which of these are potentially alterable. In our example, only the locutionary content can be negated as the other situational infons are taken as true. This broader conception of reasoning that includes such revision is therefore required to account for all cases of illocutionary meaning.

In general, then, the locutionary meaning $\sigma^\ell$ or its proper parts serve as the baseline relative to which distances for various types of potential illocutionary meanings are measured. I will assume henceforth that people are able to form such intuitive judgments (either consciously or nonconsciously) about the magnitude of distances like $d_u(\sigma^\ell, x)$ for various $x$ in $\cal I$. If one wishes, one can call the Distance sub-Constraint a \emph{theory} of ``accessibility,'' recalling that this was precisely one of the questions \isi{Relevance Theory} had simply begged. 

%When conjoined with Relevance, it provides the set of illocutionary candidates for disambiguation by the illocutionary Flow Constraint. 

In Relevance Theory, relevance and accessibility are more or less equated because the most accessible meaning always turns out to be the most relevant. In Equilibrium Semantics, Relevance is the \emph{value} of information which is completely distinct from Distance or the derivational accessibility of information, and both of these sub-Constraints are quite different from the Flow Constraint. It is the three constraints together that lead one to a complete theory of illocutionary meaning. And, moreover, in Equilibrium Linguistics, the goals and preferences of the interlocutors present in the Setting Game always enter all three constraints, the calculation of relevance and distance, and the calculation of equilibria of partial illocutionary games.

Why are illocutionary partial information games required? Isn't it enough to identify the maximally relevant meanings inside the open ball? Unfortunately, \emph{all} such nearby relevant meanings may not be compatible with the speaker's and addressee's viewpoints. They also have to satisfy the requirement of ``optimality'' based on the agents' preferences. Otherwise, for instance, an addressee could infer a very valuable proposition that is easy to access derivationally but that was not intended by the speaker. This kind of miscommunication occurs quite frequently, in fact. For instance, in the garage example, as I just noted, the passerby may not have given any thought to whether the garage is open or not. In such a case, the motorist would be wrong to infer $\tau$ as an implicature even though it is both relevant and near. But this ties in with the general fact of the indeterminacy of indirect meanings.

%Only when this third constraint is satisfied will there be a guarantee that the selected illocutionary meanings are attuned to the communication at hand.

To the best of my knowledge, neither Grice\ia{Grice, Paul@Grice, Paul} nor any of his followers have ever shown a way to \emph{find} candidate implicatures or other candidate illocutionary meanings such as free enrichments and modulations. They have, at best, provided more or less convincing ways -- usually less convincing, as I have argued in \sectref{sec:theory of conversation} and in this chapter -- to determine if a candidate is actually an implicature, say, \emph{given} that it is a candidate. But the candidate itself is always pulled out of thin air. It is to the credit of my first book, \emph{The Use of Language} (\citeyear[Chapter~7]{parikh:ul}), that this problem was first considered partially, and to the credit of Equilibrium Semantics that it now offers a \emph{complete} and \emph{computationally tractable} solution to the problem, at least in principle. If suitable assumptions are made about the search space, it may become possible to put the theory of implicature and other indirect meanings on a solid scientific footing and explain how it applies to humans at a psycholinguistic level. It may also make it feasible for robots to communicate effectively with indirect meanings, maybe for limited purposes rather than for open-ended conversations, as they can be endowed with appropriate search spaces. Texts such as \citet{ms:fsnlp} and \citet{jm:slp, jm:slp2} are largely silent about how indirect meanings may be derived. \citet{jurafsky:pcl} does compare and contrast the logical Plan Inference (or Belief-Desire-Intention) Model developed mainly by Allen, Cohen, and Perrault (see \citealt{allen:nlu}) with his probabilistic Cue-based Model in the context of speech act interpretation and similar tasks like reference resolution and discourse structure interpretation. As will be seen below, the approach of Equilibrium Semantics integrates the two methods in some sense, as it provides the depth of the first and the breadth of the second. 

I now consider an example in greater detail to show how the sub-Constraints of Relevance and Distance work together in enabling the identification of candidate illocutionary meanings, that is, the illocutionary possibilities, that would then be disambiguated by the Flow Constraint, that is, by $IG_u(\varphi)$, the global set of local illocutionary games. I discuss this in the context of free enrichment so it also shows how the same method applies to other types of indirect meaning.





%A non-empty subset $\cal F$ of $\cal I$ is called a filter if
%
%\begin{itemize}
%
%\item[a.] $\sigma, \tau \in {\cal F}$ implies $\sigma \wedge \tau \in {\cal F}$,
%
%\item[b.] $\sigma \in {\cal F}$, $\tau \in {\cal I}$ and $\sigma \Rightarrow_\ell \tau$ imply $\tau \in {\cal F}$. 
%
%\end{itemize}
%
%A subset $F$ of $\cal I$ is called an \emph{up-set} if, whenever $\sigma \in F$, $\tau \in {\cal I}$ and $\sigma \Rightarrow_\ell \tau$, we have $\tau \in F$. With this in mind, a filter on $\cal I$ can be more compactly described as a non-empty up-set closed under meet. The set of filters on $\cal I$ is ordered by inclusion.
%
%As I said above, situations are just collections of infons. The relation between a situation $s$ and an infon $\sigma$ that holds in it is written $s \vDash \sigma$  or $\sigma \in s$, and is described by saying $s$ supports $\sigma$ or $\sigma$ holds in $s$. The information expressed by the relation $\vDash$ is special and $s \vDash \sigma$ is called a proposition. Only propositions are true or false; infons by themselves do not admit of truth values. Utterances typically convey multiple propositions, although these are usually just multiple infons relative to some common described situation.
%
%For all situations $s$ and all infons $\sigma$ and $\tau$, the following facts hold:
%
%\begin{enumerate}
%
%\item $s 
%vDash \mathbf{0}$ and $s \vDash \mathbf{1}$.
%
%\item If $s \vDash \sigma$ and $\sigma \Rightarrow_\ell \tau$ then $s \vDash \tau$.
%
%\item $s \vDash \sigma \wedge \tau$ if and only if $s \vDash \sigma$ and $s \vDash \tau$. 
%
%\item $s \vDash \sigma \vee \tau$ if and only if $s \vDash \sigma$ or $s \vDash \tau$.
%
%\end{enumerate}
%
%We can now begin to explore the range of meanings evoked by an utterance.


