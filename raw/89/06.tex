\chapter{Theoretical and Methodological Implications}\label{sec:6}

\epigraph{\itshape What sort of process underlies the formation of a grammaticality judgment? The only way to approach this question is to ignore all \emph{a priori} linguistic restrictions and to regard it as a problem in human information processing.\\[-2\baselineskip]}{\citep{LeveltEtAl1977}}

\section{Introduction}\label{sec:6.1}

The purpose of this chapter is to bring together many of the issues raised and results reviewed in the preceding chapters to consider what we can learn from them. I entertain two particular angles on that question, namely, what we can learn about what goes on in the mind to allow grammaticality judgments to be made, and what \textit{should} go on in linguistic experimentation in order for those judgments to be useful.

In \sectref{sec:6.2}, I take up the idea proposed in \chapref{sec:1} that a useful way to make sense of a large collection of diverse experimental results is to try to fit them into a single coherent model of the mental structures that underlie the behavior. That is, following the advice of the epigraph above, we should treat this like any other problem in human information processing. In \sectref{sec:6.2.1}, I review what very little previous work of this sort has been done. In \sectref{sec:6.2.2}, I propose a 
preliminary model  that provides a way of picturing how the many mental components discussed so far might be brought together in the judgment process. \sectref{sec:6.2.3} presents some examples of ways in which such a model, in conjunction with specific assumptions about how the underlying cognitive processes work, could account for some major findings. In \sectref{sec:6.3}, I move on to the applied issues. In light of the demonstration in \sectref{sec:2.3} of the apparent necessity of using complex and fine-grained judgments in current theoretical argumentation, and the dismal record of ``insufficient reporting of results or data, poorly elaborated stimulus materials, or ... lack of adequate controls'' \citep[367]{Chaudron1983}
% 170
% Theoretical and Methodological Implications  171
evinced in experimental work to date, it should be obvious that considerable care and effort must be put into the elicitation of grammaticality judgments if we are to stand a chance of getting consistent, meaningful, and accurate results. This is not being done. I therefore make specific recommendations on how to improve almost every phase of the experimental process. I first examine the stimulus materials (\sectref{sec:6.3.1}), then the elicitation procedures themselves (\sectref{sec:6.3.2}), and finally the statistical analysis and interpretation of the results (\sectref{sec:6.3.3}). I conclude in \sectref{sec:6.4} by exploring the potential benefits of the theoretical hypotheses and methodological proposals put forth in the chapter.

\section{Modeling Grammaticality Judgments}\label{sec:6.2}
\subsection{Previous Work}\label{sec:6.2.1}

Almost no work has been done to date by way of modeling the psychological representations and processes involved in making grammaticality judgments, despite the proliferation of models of other language behaviors, most notably sentence processing. The first attempt in this area that I am aware of was the work of \citet{BialystokEtAl1985}, described in \sectref{sec:3.4}. From my earlier description, it should be clear that this is a very high-level model, whose constructs are so abstract as to have almost no concrete content. This is not to say that they do not exhibit useful insights, but the details are left for others to work out. While the authors claim that the dimensions of analyzed knowledge\is{analyzed knowledge, as component of language skill} and cognitive control\is{cognitive control, as component of language skill} underlie many of the more specific properties on which people differ (e.g., field dependence) nothing more specific is said. At the level of detail I wish to work at, they do not have much to offer. The same is unfortunately true of \citegen{VanKleeck1982} proposed model. \citet{Gombert1992} proposes a model of metalinguistic development whose goals are rather different from mine.

Another line of work that could be considered a model of certain aspects of  the grammaticality judgment  process is that of Catt (\citeyear{Catt1988}; \citealt{CattEtAl1990}),\linebreak 
although this was not his main goal. Catt created a computer program for com\-puter-assisted language instruction\is{computer-assisted language instruction} that was designed to perform automatic error diagnosis and correction\is{ungrammatical sentence, correction of} of ungrammaticalities produced by second-language learners. In effect, the system was a model of a foreign-language instructor. It would classify the errors in a sentence as being due to phrase structure, transformations, morphology, verb subcategorization, or certain direct translations from the learner's native language. The heart of the system was a parser made up of
constraints that could be selectively relaxed\is{constraint relaxation} when an initial parse failed. Once a parse was eventually found in this way, the constraint(s) that had been relaxed indicated the nature and location of the ungrammaticality. (I will return to the idea of constraint relaxation in \sectref{sec:6.2.3}.) It is possible that people do something similar when they encounter ungrammaticality, and, if so, the nature and degree of constraint relaxation might be reflected in their grammaticality ratings. There is some evidence that people behave systematically and quite uniformly in interpreting and correcting ungrammatical sentences,\is{metalinguistic tasks!correcting ungrammatical sentences} e.g., \citegen{Shanon1973} work on agreement rules in Hebrew. Unfortunately for us, Catt was not concerned with extragrammatical factors that could enter into this process, and Shanon's scope was very limited, so we shall have to go the rest of the way alone.

\subsection{The Outlines of a Preliminary Model}\label{sec:6.2.2}
\epigraph{\itshape If we take just a moment to reflect just a bit on our own linguistic performance, how \emph{implausible} this whole ``underlying generative grammar'' concept seems in the first place. (Surely nobody but a linguist would ever have dreamed of such a thing!)\\[-2\baselineskip]}{\citep{Derwing1979}}

\noindent In this subsection I propose some high-level accounts of the phenomena discussed so far in this work, culminating in suggestions for what the relevant cognitive representations might be and what the steps in the grammaticality judgment process might be. The motivations for modeling this process are given in Chapters \ref{sec:1} and \ref{sec:2} and will not be repeated here. At this point it is important to stress the preliminary and speculative nature of these proposals. Much more experimental work is needed before we can begin to have any real confidence in our knowledge about the way the mind works in this regard. In addition, what the model should look like will depend in large measure on many larger unanswered questions in language processing that also display a lack of well-articulated, well-motivated models, since a major issue of interest to me is the interface between metalinguistic components and those related to regular processing. In these cases I can only adopt some fairly well-accepted assumptions and proceed.

To begin, I ask whether there is in fact a static\is{grammar!as static representation (independent of processing)} representation of grammatical knowledge independent of production and comprehension mechanisms. Bever (\citet{Bever1975b}; \citet{LachterEtAl1988}), among many others, has argued for such a psychogrammar, ``an internalized representation of the language, that is not necessarily a model of such behaviors as speech perception or production, but a representation of the structure used in those and other language behaviors'' (p. 221). Bever's\ia{Bever, Thomas G.} strongest argument for his position is based on the existence of two types of sentence that seem to presuppose mismatches between (psycho)grammatical status and processing status. Some sentences are unusable yet intuitively well-formed (e.g., multiply center-embedded\is{center-embedding, multiple} ones), while others are usable\is{grammaticality!versus usability}\is{usability versus grammaticality} or comprehensible but intuitively ill-formed. While acknowledging that psychogrammar is redundant for adults, since the production and perception mechanisms are fully capable of performing the mapping between ideas and utterances, Bever\ia{Bever, Thomas G.} argues that the psychogrammar plays an important role in acquisition,\is{grammar!role in acquisition} namely to bootstrap the two performance systems, to keep them roughly consistent, and to record accumulated knowledge until it is incorporated in the processing procedures. When acquisition is far enough advanced, the psychogrammar may uncouple from everyday linguistic performance altogether, leading to the mismatches mentioned above.\is{grammaticality judgments!versus language use} Although I do not find the arguments particularly convincing, I will adopt this assumption, in part for clarity of exposition, in part because it is such a deep-seated feature of the generative approach. At the same time we should accept that our concept of the grammar as a separable black box of static knowledge might eventually have to change. The next question is, what does the grammar look like? Here I assume a principles-and-parameters model of \isi{Universal Grammar} (UG), only because it is the theory I am most familiar with. Now, what is the relationship between the principles and parameters, the grammar as a whole (including areas not covered by UG), and the parsing and processing mechanisms?\is{parsing!versus grammar} Again mostly for expository ease, I shall assume that UG is part of the grammar that is separate from processing mechanisms, which are based on it in some unspecified way, but function independently. (See \citet{GerkenEtAl1986} for discussion of the possible relations between linguistic universals, language-specific structures, and perceptual mechanisms.)

The major question we are attempting to answer by way of a psychological model is summed up by \citet{Klein1979}: ``How much of acceptability, or what kind of acceptability, falls within the scope of grammar, and how much is to be accounted for by other parts of the linguistic description or by disciplines outside linguistics'' (p. 8). This brings us back to two major issues touched on in \chapref{sec:3}: how does linguistic judgment differ from language use, and are any of the manipulations to which judgment is susceptible particular to language? In \sectref{sec:3.4}, I discuss the conceivable extremes in response to the first question: judgment involves all of the same components as conversation, or the two processes are entirely separate. Under either of these scenarios, the answer to the second question would be fairly uninteresting. If the mechanisms are identical, the only possible source of influence on judgments is the comprehension mechanism, so whatever we cannot attribute to that (linguistic) faculty cannot be accounted for. On that basis, we can probably rule out this model immediately. If the mechanisms are completely separate, there is no potential for normal language mechanisms to contribute to linguistic judgments, but since no other process relies on the judgment module, it can be a black box with arbitrary properties. Whatever effects we find can be dumped in there. However, if we make the reasonable assumption that reality lies somewhere between these extremes, then the question of how the various components contribute to the total process becomes more interesting. \figref{fig:1} represents a first attempt at modeling this scenario. I explain below what I have in mind with the various pieces of the picture, but owing to its
speculative nature I cannot justify the details in any rigorous way. (With reference to the discussion in \sectref{sec:1.4} of whether nonlinguistic properties should be attributed to separate modules of the mind or to the underlying substrate, I have taken the former interpretation here mainly for diagrammatic convenience.)

% \begin{landscape}
\begin{sidewaysfigure}
 	\input{figures/figure1.tex}
 	\caption{Model of Language Processing}
  \label{fig:1}
\end{sidewaysfigure}
% \end{landscape}

The basic computational metaphor used in \figref{fig:1} is that a program, procedure, or strategy uses static data or knowledge to process incoming information and yield information as output. The entire process is viewed as a computation. Thus, each computation symbol is connected by dashed lines to the program(s) that execute in order to perform that computation and to the data source(s) that must be referenced; the solid lines represent the processing flow. Let us first examine the upper portion of the diagram, implicated in the comprehension and production of language. Working from left to right, we see that the input to the system is a linguistic signal (in whatever modality), which undergoes a comprehension process to yield an understanding of the sentence (whatever that means). I take this understanding to be a \textit{temporary} product of the computation, comprising information that might or might not subsequently be stored as part of one's long-term knowledge. Comprehension involves the use of parsing strategies,\is{parsing!strategies} which I construe quite broadly here to include heuristics that do not involve assigning any hierarchical structure to the sentence string, such as interpreting a Noun-Verb-Noun sequence as Agent-Action-Patient. I certainly do not wish to claim that every sentence is assigned a complete constituent structure by the parser. Additionally, comprehension draws on information from competence
(taken broadly here to include the lexicon); it also makes reference to general knowledge\is{general knowledge, effect on grammaticality judgments} and specific memories to resolve ambiguities, etc. (See \citet{BerwickEtAl1984} for a particular view of the interaction between the parser and the grammar.) On the production side, an utterance begins with the intention to communicate something. That message is used in the process of generation, which employs production strategies\is{production strategies, effect on grammaticality judgments} (whatever it takes to produce a sentence word by word) that also make use of linguistic competence and world knowledge\is{general knowledge, effect on grammaticality judgments} (e.g., to decide which referential expressions are appropriate) and yields language output (in whatever modality).

Now let us examine the lower portion of \figref{fig:1}, which illustrates  the grammaticality judgment process. The input to this process is the same sort of input as to the comprehension process, namely, utterances. The output will consist of judgments themselves, plus other related information that might be elicited in response to presentation of an utterance (for more examples, see \sectref{sec:3.2}). Since these need not be expressed through language (they could involve circling numbers on a questionnaire, for instance), no connection to the generation process is shown, although language generation will incidentally be required in some cases. The central question is, what processes or strategies are operative in generating these judgments, and what sources of knowledge do they draw upon? The answer provided in the diagram is in some sense a maximal one. I have included all the major components that \textit{might} be involved. Perhaps not all of them are, and certainly they need not all be implicated in judging a particular sentence. The inherent danger here is that we will accomplish nothing in modeling if we merely supply a new component for each new experimental result we wish to account for. Therefore, we must hypothesize the minimal set of components that could reasonably capture the range of facts we are concerned with. (I do not claim to have struck the perfect balance between these criteria.) Let us consider these components in turn. On the assumption that one of the first things one does when processing a sentence for judgment is to simply try to understand it, the usual parsing strategies\is{parsing!strategies} (in my broad  sense) will be involved, and therefore by assumption so will the linguistic competence that they may draw on and the general cognitive resources they may use (e.g., short-term memory), with their incumbent limitations.\is{memory limitations} ``It is obvious that the processes of perception are involved to some extent in rendering acceptability intuitions, since a sentence must be apprehended  in some sense in order to be adjudged acceptable, ambiguous,  etc. We can expect there to be cases in which  the perceptual  processes  themselves  modify  our apparent
intuitions''  \citep[229]{BeverEtAl1981}. If this step is exactly like normal comprehension, then general knowledge\is{general knowledge, effect on grammaticality judgments} must also be involved, probably including strategies for handling conversational implicature. In reality, I suspect its role is somewhat smaller in the case of judgment, if concerns about plausibility, truth, etc., might be suspended. (See \citealt{BeverEtAl1976a} for a review of work on the components discussed so far.) An interesting question arises if the perception and production processes themselves encode grammatical information, rather than merely referring to the competence module. \citet{BeverEtAl1976a} propose that these systems are substantially independent of the grammar (in adults), so that they may parse or generate sequences that the grammar does not include, e.g., by creative analogy.\is{grammar!role in grammaticality judgments} My model would allow for such sequences to be judged good or bad, depending on how much weight the various judgment sources carry.

The remaining influences are likely to be more controversial. The diagram suggests that production strategies might be involved, in two distinct ways. First, a yes/no judgment might be arrived at by attempting to generate the sentence in question. If our production mechanism cannot do so, then we judge the sentence ungrammatical, unless we have some relevant conscious knowledge about other dialects.\is{dialects (idiolects)}\footnote{I thank LouAnn Gerken\ia{Gerken, LouAnn} for discussion of this idea.}
 %\textsuperscript{1}
It seems that linguists may have better access to this kind of hypothetical production than untrained speakers, if \citet{Kroch1981}
is correct in his claim that \isi{resumptive pronouns} can be generated by the production system despite being ungrammatical; linguists seem to find these more acceptable (see \sectref{sec:2.2}). Second, production strategies might be employed in the scalar rating, locating, explaining, and correcting\is{metalinguistic tasks!correcting ungrammatical sentences} of errors. Intuitively, it seems plausible that all of these activities involve comparison to a correct or predicted version of the sentence, and so it must be generated somehow. I am assuming that, while the parsing mechanism might embody some expectations about its input, it is not capable of generating a grammatical sentence from an intended meaning. In rating a marginal sentence, for example, one might first extract the intended meaning, then generate a grammatical sentence that is the expression of that meaning, then compare the two to decide how far off the original sentence was. But we cannot simply employ the regular generation process for this purpose, because we wish to follow the syntax of the original sentence insofar as it is correct; hence the use of production strategies referring to the input utterance.

Finally, let us consider those components implicated in grammaticality judgments but not in standard linguistic processing. The analyzed linguistic knowledge\is{analyzed knowledge, as component of language skill} component is taken directly from \citet{BialystokEtAl1985}, and is meant to include consciously known rules of language such as the \isi{prescriptive rules} one learns in school, which might be entirely independent of (unconscious) grammatical knowledge. These would be responsible for labeling a sentence as ungrammatical if it ends with a preposition, for instance. \citet{Bialystok1979} uses her experimental findings to argue that an initial good/bad decision is based mostly on implicit knowledge, while the explicit knowledge just described comes into play during subsequent error diagnosis. The control strategies\is{cognitive control, as component of language skill} are also inspired by Bialystok \& Ryan's proposal. These strategies, which I take to be independent of language or any other particular cognitive function, are responsible for bringing the focus of attention to the form of an utterance, coordinating all the sources of information brought to bear in the process, and perhaps even coordinating the other sets of strategies. The latter might be required when, for instance, the parser fails on a sentence that one has been told is grammatical (e.g., a garden path).\is{garden path sentence!failure to parse} While many parsing models have been proposed to account for initial parsing failure on such sentences, very few have dealt with how one can eventually succeed in finding a valid structure for the sentence.\is{garden path sentence!eventual parsing of} One possibility is that control strategies intervene to prompt a search for obscure alternatives, such as verbs that could also be passive participles, as in \textit{The horse \underline{raced} past the barn fell}.
Another possibility is that some sort of sentence frame matching takes place, so that while attempting to figure out \textit{The prime number few}, one would try to think of other sentences that end in \textit{number few}.

The final set of strategies has been simply labeled as metalinguistic\is{strategies!metalinguistic}, following the terminology we have seen in much of the literature. This module is meant to include any algorithm or heuristic used expressly for the purpose of making grammaticality judgments (in the broad sense). This is where we would find, for example, the strategy of trying to imagine\is{imagining situations, and grammaticality judgments} a plausible\is{plausibility, effect on grammaticality judgments} context for some questionable sentence, or enriching the given context to make it seem more natural, as proposed by Nagata and discussed in Sections \ref{sec:5.2.3}\textendash{}\ref{sec:5.2.5}.
It would also include procedures for interpreting the trace of execution of the parser (if this is possible) or the final state of the parser. For instance, failure with a certain set of conditions indicates that the parser could not find a suitable antecedent for some anaphor. Other possible strategies include thinking of a parallel construction to compare the given sentence to (e.g., \textit{The child seems tired} for \textit{The child seems sleeping});
 considering the truth\is{truth of sentence, effect on grammaticality judgments} or plausibility of the situation described, by consulting world knowledge\is{general knowledge, effect on grammaticality judgments} (to the extent that these criteria influence judgments); preliminary checking routines that would be run before parsing begins, as proposed by \citet{LeveltEtAl1977}; and other strategies discussed in \sectref{sec:3.4}. Recall that in \sectref{sec:1.4}, it was hypothesized that there are no \textit{language-specific} extragrammatical factors involved in the process of grammaticality judgment. It might appear that the presence of a set of metalinguistic strategies contradicts this hypothesis, but in fact it does not, unless the strategies contained in that module require language-specific means to be implemented. For example, the imagining of plausible contexts could be carried out in the same way as any other sort of imagination, (presumably) independent of language. The fact that such a strategy can be \textit{employed} for the purpose of judging grammaticality must be a fact about language behavior, however. One possible component that I have not shown explicitly is a decision-making or judgment component for cognition in general, which might reflect, say, the tendency to use rating scales in a particular way.\is{rating scale!subjects' use of} Obviously the mind must have a mechanism for decision making, and it will be implicated in judgments, but it is hard to conceive of this as a separable module of the mind, as opposed to an inherent feature of the low-level processes that underlie higher cognition. I also have not included any reference to general cognitive processes such as analogical reasoning,\is{conscious reasoning!versus judgment} and the oft-mentioned but ill-defined perceptual strategies\is{perceptual strategies, and grammaticality judgments} that are sometimes implicated in language processing.\is{parsing} At this point I consider the evidence for their involvement to be marginal at best. A couple of other omissions are mostly for the sake of diagrammatic clarity. For instance, it is possible that some or all of the three components that are shown connected exclusively to the judgment computation could be used in everyday comprehension\is{grammaticality judgments!everyday uses of} if some special need arose. Also, under certain circumstances, regular communicative output could be filtered through the judgment component as a means of quality control or self-monitoring; perhaps language teachers regularly do something like this, and everyone might do it to some extent.

 If this picture is at all on the right track, then it is clear that we do not expect judgments to give all sentences the same status that linguistic performance does. The differences would be attributable to any or all of the components discussed in the previous two paragraphs. (The results of different metalinguistic tasks will differ as well, by virtue of how the contents of the modules are used, e.g., which metalinguistic strategies\is{strategies!metalinguistic} are employed under what conditions.) In fact, it might appear that grammaticality judgments are the \textit{worst} way to get at linguistic competence, as compared to production and comprehension,\is{competence (grammatical)!versus performance} because they involve the interaction of many more factors. This conclusion has been reached by others before: ``Contrary to what has generally been claimed, the relations between explicit intuitions and underlying competence are \textit{less} direct than those between phenomena of primary language use (speaking, listening) and competence'' \citep[5\textendash{}6]{LeveltEtAl1978}.\is{grammaticality judgments!versus language use} However, this by no means constitutes grounds for abandoning them as a source of data. Several arguments for their use were presented in \sectref{sec:1.1}; I can now provide two more.\is{grammaticality judgments!arguments for use of} First, while more factors are involved in grammaticality judgments, they might be less mysterious than those that are connected to language use. For instance, what exactly is the understanding of a sentence, and how would we ever get at it and draw conclusions about grammaticality from it? The same goes for communicative intentions. Second, grammaticality judgments provide an \textit{alternative path} to the grammar. To the extent that they are subject to \textit{different} influences than language use is, we have a basis on which to search for the common core that underlies both kinds of behavior. This in turn might help us to factor out various nongrammatical contributions, so that each path by itself becomes more informative as well. (Of course, not nearly enough attention is paid to usage data by theoretical linguists for such a convergence to be applied at this time. While the above is an argument for not abandoning judgment data, it is also an argument for increasing the attention paid to other types of data.) Studying nonlinguistic judgment tasks in the framework of this model, as proposed in \sectref{sec:1.4}, will aid in this process by helping to clarify the role of its nonlinguistic elements.

 One thing that is not reflected explicitly in the model presented in \figref{fig:1} is the time course of the process of judging grammaticality. Would all the factors be assessed in parallel, or would some parts necessarily precede others?\is{grammaticality judgments!time course and stages of} My hunch is that it can be usefully thought of in three main phases: parsing, decision, and diagnosis. The first is fairly uncontroversial, when taken to include the kinds of heuristics mentioned earlier. The second involves determining what the rating will be: yes/no, or a number on a scale, or whatever. This might involve an analysis of the remnants of the parsing process, for instance. The third, diagnosis, which might not always occur, involves \textit{consciously} determining reasons for the particular ratings chosen, which could be used in explaining the error or correcting it.\is{metalinguistic tasks!correcting ungrammatical sentences} As we have discussed before, these might or might not bear any relation to the actual causes of the decision. This sketchy account will suffice for the rest of the discussion here; obviously many details remain to be worked out.


 \subsection{Applications of the Model}\label{sec:6.2.3}

 In order to see how my model might actually account for some interesting facts about grammaticality judgments, a bit more needs to be said about how the pieces of this picture are implemented. I will assume the widely used principle of \isi{spreading activation}, together with the parallel-processing\is{parallel processing} concept\is{competition (in parallel processing)} of competition.\footnote{This is just one possibility that strikes me as promising, but certainly not the only  one.}
 That is, multiple processing paths might be active in parallel, and the first one to succeed will determine the outcome of the computation. This approach has already been used by \citet{McRoyEtAl1990} to implement so-called race-based parsing.\is{parsing!race-based} In their model, each parsing rule takes a certain amount of time to execute, determined partially by its complexity but also influenced by the lexical content of the sentence, previously parsed sentences, etc. Multiple parse paths are tried in parallel, and whichever succeeds first is used to interpret the sentence. If none succeeds before a time-out deadline, the parse is considered to have failed. Thus, different readings of a structurally ambiguous sentence\is{ambiguous sentence!parsing} might be found on different occasions because the time weights associated with the relevant rules can change. Many order-of-presentation effects\is{order of presentation (of sentences)!effect on parsing} can be accounted for in this way. For instance, a sentence that could not be parsed at one time (e.g., a garden path)\is{garden path sentence!failure to parse} can be parsed at some other time if the required rules have been strengthened or sped up.\is{garden path sentence!effect of context on} This might be accomplished by employing them in parsing structurally similar\is{context effects!structurally similar sentences} non-garden-path sentences. More generally, context effects due to structural similarity or dissimilarity (see \sectref{sec:5.3.1}) can be derived as well. \citet{Bock1986} provides experimental evidence suggesting that some mechanism of this sort is needed. Her paradigm involved having subjects repeat a sentence they had just heard, and then describe an unrelated picture they were shown, using a single sentence. The pictures were constructed so as to allow two natural types of sentence descriptions: either active versus passive or dative object versus double object. Bock found that the type of sentence that subjects had to repeat influenced their choice of a syntactic form used in describing the picture. She argues that this result cannot be attributed to lexical repetition effects, socially motivated matching of the form of another speaker's utterance, or persistent discourse strategies that trigger the same syntactic rules, but rather must be attributed to some purely syntactic decision process.

 This scheme can be extended very naturally to deal with graded judgments of (un)grammaticality. I shall incorporate the idea of \isi{constraint relaxation} from
 \citegen{Catt1988}'s  work, discussed in \sectref{sec:6.2.1}. While it is fairly clear that relaxing constraints will allow ill-formed input to be processed and the well-formed parts recovered, not all constraints can be of equal status if we are to get graded judgments based on grammatical properties (as opposed to imagery content\is{imagery content of words (concrete versus abstract)} of lexical items or other nongrammatical features). That is, it is not sufficient, as it was for Catt, to know \textit{which} constraint must be relaxed in order to get through a sentence. We must know how much of a concession it was to relax that constraint. While one can imagine an ad hoc weighting function for this purpose, it is perhaps more naturally served using the race-based\is{parsing!race-based} framework. The speed with which a parse path can be followed if its constraint is violated is inversely proportional to the importance of the constraint on that path. That is, a path with a very fundamental constraint (e.g., the lexical category of an input word) can be traversed only extremely slowly if the constraint is not satisfied, whereas a path with a lesser constraint (e.g., a semantic feature restriction on an input word) can be followed faster than the path with the greater constraint when \textit{its} condition is not met, other things being equal.\footnote{It seems that this approach could be applied quite directly to account for prototypicality effects\is{prototype theory} of the kind discussed in \sectref{sec:3.3.1}. If an exemplar of a concept (e.g., bird) lacks a fundamental property (e.g., ability to fly), it will take longer to verify than one that lacks a less important property of the prototype.}
 %\textsuperscript{3}
  Thus, degrees of grammaticality could be equated with parsing speed, where it is understood that speed is meant in a somewhat metaphorical sense that need not correspond to actual processing speed.\footnote{This scheme bears a certain resemblance to the concept of \isi{fuzzy grammar} (see \citet{Mohan1977} for a concise review). The idea is that each derivational rule that applies to generate a sentence rates its output on the basis of features of its input, eventually yielding a well-formedness rating between 0 and 1 for the sentence as a whole. But note that I am crucially \textit{not} attributing this mechanism to the grammar itself.}
 %\textsuperscript{4}


 This measure could yield both absolute and graded judgments. The absolute distinction is based on whether or not any constraints are violated, the graded measure is based on speed, so that a grammatical but hard-to-parse sentence (e.g., a garden path)\is{garden path sentence!effect on grammaticality judgments} would be rated the same as a truly ungrammatical sentence, which is exactly what \citet{WarnerEtAl1987} found (see \sectref{sec:5.3.1}). The relative leniency for ungrammaticality in spoken, as opposed to written,\is{speech versus writing, effect on grammaticality judgments} language could result from an across-the-board reduction in the time cost of traversing paths (including ones whose constraints are violated), in order to keep up with the real-time demands of continuous speech. Situationally related context\is{context effects!semantically related} could speed up parsing by decreasing the time required to access meanings and other properties of relevant words. In the same way, a processing advantage is predicted for frequently
 % Theoretical and Methodological Implications  183
 versus infrequently occurring words. The relative strengths of parse paths should also be reflected in corrections,\is{ungrammatical sentence, correction of} i.e., how you change a bad sentence to make it good. Presumably, whatever was implicated in the constraint that got relaxed\is{constraint relaxation} will be changed, since it is the only known locus of error. If you were to make a correction\is{ungrammatical sentence, correction of} somewhere else, you could not be assured that it would be sufficient. Of course, we have seen that graded judgments can arise on a wide variety of nonlinguistic tasks as well. In my view, this occurs because race-based\is{parsing!race-based} implementation is a feature of cognitive processing in general. I conclude this section by suggesting that the same competition\is{competition (in parallel processing)} principle can be applied at a macro level as well. Consider the situation where an ungrammatical but comprehensible sentence is encountered, e.g., \textit{I just bought a CD for me}. Different knowledge components contribute to different views of this sentence. According to linguistic competence, the sentence is ill-formed  because it contains an improperly bound pronoun. Our knowledge of the world,\is{general knowledge, effect on grammaticality judgments} and specifically the knowledge that Boris just walked in the door with a CD in hand (still in its factory shrinkwrap), allows us to interpret the sentence without any difficulty. Which component will be allowed to determine our reaction to the sentence\schdash{}to ignore the error and take up the conversation, to make a mental note that Boris does not speak perfect English, to tell him he has made a mistake and see if he can discover it, or to blurt out the correct version of the sentence? This decision can be seen as the result of a competition, where the ``speed'' of each processing module is determined by the demands of the situation. Thus, teaching an ESL class primes grammatical competence and correction\is{ungrammatical sentence, correction of} strategies, everyday conversation favors parsing, the current situation activates relevant knowledge of the world,\is{general knowledge, effect on grammaticality judgments} seeing oneself in a mirror might strengthen the communicative over the structurally based strategies, and so forth. Of course, for speakers we know, this choice might have been made for good when we first got to know them. Under this interpretation, the control strategies themselves might not exist as strategies per se, but as the by-products of \isi{spreading activation} and race-based\is{parsing!race-based} competition.

 \section{Methodological Proposals}\label{sec:6.3}

 \epigraph{\itshape More and more subtle theory is now being constructed on less and less clear cases. In such a situation one would expect linguistics to turn to appropriate behavioral methods of data gathering  and (statistical) analysis. Nothing of the sort occurs, however.\\[-2\baselineskip]}{\citep{LeveltEtAl1977}}


 \subsection{Materials} \label{sec:6.3.1}

 There are basic precautions that could easily be taken in preparing materials\is{experimental design} for the elicitation of grammaticality judgments in order to avoid certain obvious kinds of bias.\footnote{Several of the suggestions in \sectref{sec:6.3} have been synthesized from \citet{Birdsong1989}, \citet{RayEtAl1988}, and \citet{Snow1975}.}
 %\textsuperscript{5}
  One potential confound is the order in which sentences are presented to subjects. It has been shown experimentally (e.g., by \citet{Greenbaum1973}) that sentences will be rated differently depending on their order of presentation.\is{order of presentation (of sentences)!effect on grammaticality judgments} A simple way to factor this effect out of results is to counterbalance orders\is{experimental design!order, counterbalancing of} across different subjects, thus controlling for nervousness at the beginning of the session, fatigue at the end, practice effects, the influence of surrounding test items, and any other serial position effects. (Of course, this requires that one consult more than one subject.) A second kind of bias is introduced if there are substantially more grammatical sentences in the test materials than ungrammatical sentences or vice versa. Subjects will tend to get into a yea-saying or nay-saying mode or will come to expect deviance. Thus, the numbers should be kept roughly equal. (We will need pilot trials to gather preliminary data for this purpose, since we presumably do not know the outcome of all the judgments in advance.) A third factor in our list of potential confounds in stimulus materials is the semantic content of the lexical items in the sentence.\footnote{Obviously, some semantic features of words are directly relevant to grammaticality; here, as in \sectref{sec:5.3.2}, I am concerned with properties not generally considered grammatically relevant.}
 %\textsuperscript{6}
  As mentioned in \sectref{sec:5.3.5} it is simply not true that people will rate all structurally identical sentences equally grammatical. For example, \citet{LeveltEtAl1977} found that different ratings could be induced by varying the imagery content of a sentence, i.e., the degree to which it represented an imaginable or concrete situation. With a good understanding of such a factor, one can reduce its effect by avoiding sentences at the extremes of imagistic content,\footnote{Alternatively, \citet{Birdsong1989} proposes that only high-imagery content words should be used, so that all subjects can see the sentences as potentially referential and meaningful. Whether this is a good idea should probably be determined on the basis of experiments comparing the two methodologies; to my knowledge Birdsong's\ia{Birdsong, David} proposal has not yet been followed.}
 %\textsuperscript{7}
  and by using several different exemplar sentences with the structure in question across subjects. That is, the lexical content\is{lexical items, effect on grammaticality judgments} of the sentences should be varied to guard against the influence of imagery, and any other potential biases of lexical items,\is{experimental design!lexical items, varying} such as word length, frequency, and semantic peculiarities. In light of the findings by \citet{Hill1961}, it might also be best to inform subjects
 that only common words will be used, or that if they are not sure about the status of a word, they should ask the experimenter. This would circumvent the possibility of subjects interpreting \textit{of} as an unfamiliar noun, for instance.

 More controversial than any of these issues in preparing materials is the surrounding contextual material, of all the various types. We have all had the experience of thinking at first that a sentence is totally ungrammatical, only to have someone suggest a real-world situation where it is quite plausible and sounds fine.\is{plausibility, effect on grammaticality judgments} As discussed in \sectref{sec:5.3.1}, there are numerous ways that context can influence grammaticality, from bringing out rare word meanings\is{context effects!and lexical ambiguity} to priming certain parsing procedures.\footnote{For some striking demonstrations of how apparent word salad can be made plausible by context, see \citet{Hill1961}, especially fn. 4.}
 %\textsuperscript{8}
  There is certainly no universally correct answer to the question of what sort of context, if any, is suitable for particular elicitation purposes, but it is a variable that cannot be ignored. Ratings of sentences in context cannot be compared with those made in isolation, for example. The consensus among the authors surveyed in the present work seems to be that a supporting pragmatically related context should always be provided, unless that would somehow defeat the purpose of the experiment. Since only structural well-formedness is at issue, not pragmatic appropriateness, if there exists a situation where the sentence would be appropriate, why should we not lead the subject to that situation? Furthermore, we will reduce between-subject variability by not leaving subjects to their own devices in imagining situations where the sentence might occur, which many researchers claim would otherwise be a major part of the judgment process.\is{experimental design} Of course, the question that then arises is what to do with sentences that seem to have no imaginable context. \citet{Householder1973} claims that a sentence can be ungrammatical for that reason alone, i.e., that usability\is{grammaticality!versus usability}\is{usability versus grammaticality} is not entirely separable from structural well-formedness. (The example he gives, which I do not find particularly problematic, is \textit{Harry reminds me of himself}.)

 Depending on the purpose of the experiment, one might wish to avoid choosing sentences whose rating is likely to be confounded by parsing difficulty.\is{experimental design}\is{parsing!effect on grammaticality judgments} For instance, the garden paths\is{garden path sentence} studied by \citet{WarnerEtAl1987} showed extreme parsing difficulty. Since these researchers were interested in the parsing process, rather than in grammaticality per se, these were sensible choices, but if one wishes to know whether a sentence is accepted by the grammar, it does not make sense to confuse grammaticality with low parsability. Of course, the distinction might not always be obvious ahead of time, but one could call on a pilot
 study with a post-test questionnaire, where the intended interpretation of a sentence that was judged ungrammatical is stated, and the subject is asked whether the sentence is still bad under this reading.

 If one wishes to detect very small differences between sentences, then it is crucial that they be matched as closely as possible on as many features as possible, including semantic plausibility\is{plausibility, effect on grammaticality judgments} \citep{CardenEtAl1981}. That is, they should be minimal pairs at the sentence level.\is{experimental design} When the relative grammaticality of two or more related forms is at issue, it is best to allow subjects to see them side by side and draw their attention to the comparison. The order among the related sentences, and the order among the \textit{sets} of such sentences, should still of course be counterbalanced.\is{experimental design!order, counterbalancing of} Judgment tests are likely to give misleading results if the sentences used contain features that are unrepresentative of the whole range of sentences to which the results should generalize. Thus, \citet[vol. 3]{Levelt1974} and \citet{Bolinger1971} plead for the avoidance of additional unnaturalness that has nothing to do with the crucial issue at stake but takes attention away from it. Levelt cites numerous cases where this seemingly obvious admonition has been violated, e.g., by what he views as unnecessary loading of short term memory (\textit{That Tom's told everyone that he's staying proves that it's true that he's thinking that it would be a good idea for him to show that he likes it here}) or by the extra semantic load resulting from an unusual situation (\textit{I dreamed that I was a proton and fell in love with a shapely green-and-orange-striped electron}), when these were not required for the issues under investigation \citep{Levelt1972}. Again, to guard against unintentional distractions of this type, multiple sentence frames should be built around the same crucial construction wherever possible.

 \subsection{Procedure}\label{sec:6.3.2}

 \epigraph{\itshape Good practice in the more advanced sciences distrusts most of all the memory and impressions of the investigator himself.\\[-2\baselineskip]}{\citep{Labov1978}}

 \noindent Once we have minimized potential confounds in the stimulus materials, the next logical step is to remove confounds from the process of gathering judgments.\is{experimental design} The first issue is the selection of subjects, perhaps the worst offense with regard to experimental method in linguistics to date. Here I would implore that these must be people with no linguistic training.\is{linguist!as subject} If it is the competence of normal native speakers that we claim to be investigating, we need to study random samples\is{experimental design!subjects, random sampling of}
 % Theoretical and Methodological Implications  187
 of normal native speakers. This is almost never done by theoretical linguists. (\citet{Bolinger1968}, \citet{Greenbaum1976a} and \citet{Derwing1979} also make this point.) They first consult their own intuitions (one cannot find a more biased subject than the investigator), then their colleagues in the next office (almost as biased), and if they are really ambitious, perhaps a couple of their students (not exactly objective either, since students likely know which result their professors are hoping for and would like to gain their favor.) While striking differences between linguists and nonlinguists\is{linguist/nonlinguist differences} have not been convincingly demonstrated empirically due to poor experimental designs (see \sectref{sec:4.4.1}), we have enough reasons to \textit{expect} them to be different that linguists simply ought to be excluded. Also, the small samples of linguists that are usually available are bound to lead to unreliabilities \citep{BradacEtAl1980}. Nonetheless, linguists continue to insist that the ease of obtaining data is a reason for preferring oneself as a subject, ignoring the inferior quality of the data so obtained \citep[50]{Newmeyer1983}
 claims this justification is uncontroversial!). If linguists wish to live up to scientific standards of data validity, it is time for them to abandon the convenient fiction that data is never further away than their own minds.

 Subjects must be sufficient in number in order for the assumptions of the required statistical tests to be met and to avoid distorting the results with atypical speakers.\is{experimental design} If there is any reason to suspect regional variation on the issue at hand, an effort should be made to find speakers of various dialects\is{dialects (idiolects)} (this would usually be a good idea in any case). \citet{Snow1975} and \citet{Ringen1979} suggest that subjects be pretested and screened for their ability to judge reliably,\footnote{Reliability here means judging consistently on different occasions and under different circumstances, as well as giving reports that correlate as closely as possible with one's true intuitions, e.g., thinking carefully about possible contexts before deciding a sentence is impossible.}
 %\textsuperscript{9}
  but such a procedure might systematically exclude a relevant class of judgments. A similar objection could be raised against the exclusive use of expert language users, e.g., prominent authors. Judgment tests should be carried out in a controlled setting,\is{setting of experiment} to decrease the chances that subjects will be ``inebriated, inattentive, mendacious or whimsical'' \citep{Grandy1981}; the pub where everyone goes at the end of a conference is probably not an ideal locale. Individual differences on potentially relevant factors such as age, sex, and education should at least be noted on a personal questionnaire so that variability attributable to them can be examined in the analysis. If multiple conditions are being used (e.g., with context versus without), random assignment of subjects or counterbalancing on these factors is important.

\enlargethispage{\baselineskip}
 The next problem linguists have is with the instructions to subjects.\is{instructions to subjects!desiderata for} What exactly should one ask them to do? No two studies seem to agree. Certainly we have seen that one cannot hope for the terms \textit{grammatical} or \textit{acceptable} to have their intended meanings for naive subjects.\is{naive subjects (nonlinguists)} \citet{Chaudron1983} and many others point out the potentially nonunitary measure that would result. Experimenters must put considerable effort into designing an explanation for their subjects on how they want them to make their judgments, at least until such time as the field can agree on a standard set of instructions.\footnote{ Standardized instructions might seem unlikely ever to be adopted, given that there are apparently very few such cases in psychology, which is generally much more concerned with procedural matters than linguistics. I would argue that, unlike in psychology, large numbers of linguists are interested in asking exactly the same questions about their stimuli (sentences). At the very least, we can hope to make widely known what sorts of directives do and do not work. In fact, \citet{BleyVromanEtAl1988} reproduce their complete set of instructions and encourage other researchers to use it so that their results will be comparable. The instructions essentially ask the subjects to consider whether they feel the stimuli sound like possible English sentences for them, and to concentrate on structure.
 }
 %\textsuperscript{10}
 This will require linguists to make explicit exactly what counts toward grammaticality, which perhaps can only be done with reference to particular types of theoretical issues being investigated. For this reason, I cannot propose a generally applicable set of instructions here, but I can suggest how to make them effective. Most experiments seem to have erred on the side of describing the task too briefly and vaguely. Instructions should be specific, should mention possible reasons why a sentence \textit{should} be considered bad, and should also mention potential reasons that should \textit{not} come into play. Asking subjects to say sentences out loud rather than just reading them silently may help to overcome some prescriptive\is{prescriptive rules} compunctions associated with written norms.\is{speech versus writing, effect on grammaticality judgments} Give examples of sentences that you consider unequivocally good and unequivocally bad (but that do not contain the construction you wish to test) and explain why the good one is good, despite some irrelevant properties (e.g., meaninglessness) and why the bad one is bad, despite other irrelevant properties (e.g., interpretability). The examples should cover a wide enough range to avoid problems like the one \citet{Birdsong1989} encountered. He reports that his subjects claimed a stimulus item was not a sentence because it was a question! Run some practice trials in which the subjects think aloud during the judgment process, so that you can point out if they are using inappropriate criteria. It is important to keep the statement of instructions itself down to a reasonable length. Otherwise it ``becomes an essay on linguistics that only a sophisticated informant can understand, and only an unusually patient one will read'' \citep[296]{Carden1970a}.



 % Theoretical and Methodological Implications  189

 If the field had a standard set of instructions,\is{instructions to subjects!standardizing} then at the very least everyone would be testing the same thing, even though considerable refinement would be required to make it the thing we are interested in. Results could be meaningfully compared across experiments, which is currently not possible.\footnote{There is still an idealization here: while we can make instructions the same for all subjects, we cannot control for possible differences in the way they interpret those instructions.}
 This must become possible, however, if there is any chance of making linguistics a more objective endeavor. If the only people we can gather data from are other linguists, all hope is lost. (See \citet[61]{Newmeyer1983} for the view that this state of affairs is unlikely to change anytime soon.) An alternative suggestion, made somewhat tongue-in-cheek by \citet[101]{Hirst1981},
 is the establishment of a central sentence-testing service to which linguists would send their crucial sentences (and some money) and get back in the mail a standardized set of experimentally elicited ratings. This would eliminate the time and effort that would be required to set up appropriate testing facilities in each department, ensure consistent procedures, and reduce the overhead expense by dividing it among a larger user population. Of course, it would create a new set of problems, too.

 Having dealt with how the concept of grammaticality is to be conveyed, we must now consider what to ask subjects to do with it. The biggest issue here is whether to use absolute ratings,\is{absolute rating (of acceptability), versus relative ranking}\is{ranking versus absolute rating (of acceptability)} and if so on what scale, or relative rankings, and if so on how many sentences at a time. If rankings are used, should we ask for a grammaticality threshold to be drawn, as some studies have done? The issues surrounding this choice are discussed in detail in \sectref{sec:3.3.4}, and will not  be repeated here. The goals of the experiment will obviously play a role in this decision. All other things being equal, most researchers advocate comparative judgments, on the basis of their higher reliability. If a rating scale\is{rating scale!choice of} is used, I argue that it should be a balanced one. That is, unlike Nagata's scales (see \sectref{sec:5.2.3}) where 1 = grammatical, and 2\textendash{}\textit{n} are degrees of badness, it should range evenly from good to bad, with middling being in the middle. If verbal descriptions of the various positions on the scale are given, some care is called for.\footnote{Wayne Cowart (personal communication)\ia{Cowart, Wayne} recommends anchoring only the endpoints of the scale with descriptions, because labeling intermediate points might induce subjects to use the scale unevenly.}
 %\textsuperscript{12}
  \citet{GreenbaumEtAl1970} and \citet{Ellis1991} advise against calling a middle rating ``not sure,'' for instance, because this carries the potentially negative connotation that the subject is unable to make a decision, rather than labeling the sentence as intermediate in grammaticality. In fact, both answers should be available, so that cases where
 the subject truly \textit{is} unsure can be treated separately. Greenbaum \& Quirk also recommended against calling the middle category ``marginal or dubious,'' as \citet{QuirkEtAl1966} did, because this terminology sounds too technical. In fact, I believe the use of more than one rating criterion should be seriously considered.\is{rating scale!using more than one dimension} If one gives subjects a chance to rate grammaticality, stylistic felicity, likelihood of occurrence in conversation,\footnote{\citet{Householder1973} lists numerous other questions that might be usefully posed, depending on the materials, e.g., Does the sentence sound low-class? Foreign? Rural? British/American? Old-fashioned?  Bookish?}
 %\textsuperscript{13}
  and their own (un)certainty separately, this should reduce the chances that the latter factors will play a role in subjects' ratings of the first. People seem to want to express their feelings about these other matters, so it is best to give them the opportunity to do so explicitly. The effectiveness of the rating scale(s) also depends on warm-up trials\is{practice trials} that encompass a representative range of sentences. At this stage (unlike the detailed examples advocated earlier) they probably \textit{should} include sentences of the type that will occur in the experimental trials, otherwise there is a risk that novel stimuli will show a primacy effect. Using relevant sentences in practice trials is not a problem as long as experimenters do not bias\is{experimenter bias} the subjects with their own opinions of these sentences. In general, the purpose of warm-up trials\is{practice trials} is for subjects to arrive at the response strategy that works best for them, so that subsequent experimental trials  will reflect a fairly stable process.

 \citet{Carden1970a} points out a problem with eliciting grammaticality judgments only on a questionnaire, rather than in an interview: ``You often must focus on a particular reading or construction. It is of no value to know that speaker X considers a sentence ungrammatical if you do not know that his reason for rejecting it is unrelated to the construction you are studying'' (p. 296). He thus argues for greater use of interviews, an issue to which I return below. I agree that asking for some sort of explanation is crucial to knowing that a sentence was rejected for the right reasons in many cases. However, there are ways of getting at which feature(s) of a sentence cause a subject to reject it, even with a written questionnaire. One can ask subjects to indicate the location of any errors they perceive, to explain why sentences are incorrect, and/or to correct them.\is{metalinguistic tasks!correcting ungrammatical sentences} If this is done, however, it is crucial to balance these tasks with corresponding ones to be performed if the sentence is good, otherwise subjects might be biased toward good ratings just to avoid the extra work. (Studies by \citet{Snow1975} and \citet{Hakes1980} had this problem.) As mentioned in \sectref{sec:3.2}, the most obvious candidate task is paraphrase:\is{metalinguistic tasks!paraphrasing} ask the subject to rewrite the sentences in a different way while preserving their
 % Theoretical and Methodological Implications  191
 meaning. This can additionally tell us how the sentence was interpreted, which could be useful information. (Of course, whether paraphrasing is as demanding as explaining errors is hard to assess, but it is a step in the right direction.) A similar kind of bias to that just discussed was exhibited by \citegen{Rose1973} study, described in \sectref{sec:4.4.1}. His materials contained equal numbers of good and bad sentences (according to the sources they were drawn from), but subjects were divided by being asked to mark either the good or the bad sentences, while leaving the other kind unmarked. The groups differed significantly in the number of sentences accepted, with each group leaving more than half the sentences unmarked. This seems to be another instance of bias toward minimal action. To avoid it, subjects must be given the same amount of work to do no matter how they rate a sentence.

 The issue of by what means judgments are to be elicited is another important question of methodology. The most detailed examination of this problem is found in \citet{Carden1976b}. His main concern was to find ways of increasing the \textit{reliability} of elicited judgments, that is, the extent to which later ones by the same speakers or separate ones from other speakers of the same speech community will be consistent. Carden\ia{Carden, Guy} concurs with my own position that the major difficulties lie in explaining the task to naive subjects,\is{naive subjects (nonlinguists)} particularly in noninteractive forms of data elicitation, such as (forced-choice) questionnaires. At the opposite end of the interactivity scale is the open-ended interview, which is rarely used systematically by linguists, but is claimed to yield considerably cleaner data than questionnaires. Carden\ia{Carden, Guy} cites two examples of interview studies that were later replicated with questionnaires. In both cases, the interview results showed clear patterns, whereas virtually no systematic patterns could be found in the questionnaire results. A plausible explanation for this is that interviews provide more opportunity for the experimenter's bias\is{experimenter bias} to influence the subjects \citep{Newmeyer1983}, but Carden argues that there is evidence to suggest that interviews also allow real improvement in data quality, because the task can be explained in more detail, subjects' questions can be answered, and misunderstandings can be set straight. In follow-up interviews to the questionnaires, he found that much of the noise in the data was due to irrelevant readings of stimulus sentences, and in cases where statistical analysis was available, it did show significant patterns of the same sort found in interviews, although they were much less obvious from casual inspection of the unanalyzed data. Still, Carden acknowledges that until potential bias effects are studied in more detail, interviews remain suspect. In fact, he paints a gloomy overall picture that might not have improved much in the intervening years:

 \begin{quote}
 The linguist's own intuitions\is{linguist!as subject} are plainly untrustworthy. Direct observation of performance, while potentially important as a means of validating\is{validation of experimental results} other methodologies is impractical as a primary technique. Performance tasks seem to be even less reliable than evaluation [judgment] tasks, and are difficult to adapt to the more interesting syntactic problems. Forced-choice questionnaires are also difficult to construct, and have at best marginal reliability and very noisy data. Open-ended interviews seem to produce clear results, but are very time-consuming and may have bias problems. (p. 103)
 \end{quote}

 \noindent
 I suggest following the standard practice in social science of using interviews in the preliminary phases of an investigation only. Once potential ambiguities, misunderstandings, etc., have been discovered, the materials can be adjusted to deal with them and controlled experiments run, so that statistical analysis can legitimately be applied to the results. Another standard technique that could be useful in preliminary investigations is the \isi{focus group} (Graeme Hirst, personal communication).\ia{Hirst, Graeme} Speakers could discuss test sentences among themselves, employ them in different contexts, point out problematic features, etc., while the experimenter observes surreptitiously. In this procedure, grammaticality judgment would be a group, as opposed to an individual, activity. Hirst believes this approach is valuable even beyond the preliminary stages. Citing the work of \citet{SchoberEtAl1989}, who argue that understanding in a conversation is a collaborative process wherein the participants work together moment by moment to achieve comprehension (which explains why overhearers do not understand as well as addressees), he proposes that judging grammaticality in a group setting\is{setting of experiment} could be profitably carried out in a parallel manner. I am not aware of this approach having been systematically tried.

 Moving on now from the task itself, psychology has identified several kinds of \isi{experimenter effects}, induced by the behavior of the experimenter, which can bias results (see also \citet{Labov1975} and \citet{Greenbaum1988}). In the linguistic case, there is great potential for the investigator to influence a subject's judgments, even if the experiment is not an interview per se. Experimenters might influence judgments by demonstrating the procedure using sample sentences that are related to the test materials; by the idiolect of their own speech, which might be different from the subject's; or by subtleties of their interaction with the subject, e.g., how they respond when the subject gives a judgment they do not expect. \citet{Heringer1970} raised many of these issues over 20 years ago, in a passage that has been
 % Theoretical and Methodological Implications  193
 widely cited by psycholinguists, but that seems to have been ignored by most theoreticians: ``In the casual interaction between linguist and informant, there are many opportunities for self-fulfilling prophesies to take effect, both ones conditioned by theoretical position\is{linguist!effect of own theory on judgments} and also ones conditioned by the linguist's own idiolect. This could occur even without the conscious knowledge of the linguist, especially if stress and intonation are not controlled'' (p. 294; see also \citealt{BradacEtAl1980}). These dangers are fairly easily removed, if one is aware of them, by not using the investigator as an experimenter\is{experimenter effects} and by scrutinizing the instruction and elicitation phases for potential influence. \citet{Carden1970a} warns us that the linguist could also bias results by inconsistent coding of speakers' responses, so this should be done by disinterested parties as well. Typically, each set of responses would be coded independently by two judges, and consistency between them should be measured and reported.

 Sentence judging is also particularly susceptible to what are known as \isi{maturation effects} (also sometimes called order effects). These include the results of being asked for too many judgments at one sitting, such as boredom, frustration, and fatigue, which lead to inaccurate responses because the subject stops caring about the outcome. Satiation,\is{satiation} whereby symbols lose their meaning after repeated exposure, strips subjects of their intuitions altogether \citep{QuirkEtAl1966}. As \citet{Carden1976a} puts it, ``being an informant is very tiring; they find that after a while all sentences begin to sound alike'' (p. 8). Short sessions and varied stimulus materials are the obvious remedies. Closely related to the effects just mentioned are \isi{testing effects}. These include practice or training, whereby the subject gains skill in the judgment task over time, making early results not comparable with later ones. These can be controlled for across subjects by counterbalancing orders,\is{experimental design!order, counterbalancing of} as discussed in \sectref{sec:6.3.1}, but they will still distort within-subject comparisons. There is also potential for the subject to become aware of what particular issues the experimenter is interested in, which can cause the crucial sentences to be treated specially. Again, \citet{Carden1976a} has recognized this danger: ``If the informant hears similar constructions in quick succession, his remembered response to the previous sentence influences his response to the current one'' (p. 8). For instance, subjects might identify \isi{parasitic gap} constructions as the items of interest and decide that they ought to rate every one of these identically,\is{standard rating of sentence type} regardless of their actual intuitions. (In \sectref{sec:2.3.4}, I suggest that linguists regularly do this.) This should be avoided by using enough filler or distractor sentences, i.e., ones that are unrelated to the crucial construction. These will also serve as
 anchors, to remind subjects of the range of potential goodness and badness; otherwise, after looking at marginal sentences for a long time, subjects might start spreading their ratings out farther on the scale.|is{rating scale, subjects' use of} A more bizarre variable that can apparently affect subjects' perception of the purpose of the study is experimental setting.\is{setting of experiment} In a study by \citet{GreenbaumEtAl1970}, performance tests were conducted on two groups of college students, one in a lecture hall with white-coated strangers as experimenters, the other in the investigators' own English department with familiar professors as experimenters.\is{experimenter effects} The test itself was tape recorded, so there could be no bias in the stimulus materials themselves, and yet the authors found significant differences between the two groups in the number of relevant noncompliances (RNCs):\isi{compliance tests} the group with strangers showed fewer RNCs, i.e., they obeyed the instructions more strictly. Subsequent interviews showed the two groups of subjects had been put into different mental sets, thinking the test had a linguistic versus a psychological purpose. Those with the former opinion were more inclined to make their sentences into correct English,\is{metalinguistic tasks!correcting ungrammatical sentences} while the latter group was more concerned with remembering the stimulus sentence accurately. The authors conclude, ``We have seen that opinions of the test's purpose can importantly affect RNC scores and that the opinions themselves can be easily affected to a significant degree by small changes in test (and pre-test) conditions'' (p. 58). \citet{Greenbaum1977c} recommends telling subjects what the experiment is really about, so that they will not introduce variability in the results by making differing guesses. A final procedural consideration is the mode of presentation of the sentences. It is common knowledge that spoken and written language\is{speech versus writing, effect on grammaticality judgments} have vastly differing norms (which might be attributable to the dimensions of interactivity and/or permanence of the communicative medium), so we should expect that judgments of sentences in the two modalities will reflect these differences (as discussed in \sectref{sec:5.2.6}); the two cannot be directly compared. If oral presentation is used, sentences should be read by a disinterested person, not the linguist, and audio recorded to ensure uniformity of intonation, and to edit out any speech errors; trained announcers serve this purpose well. If instructions are orally presented, these too should be recorded to ensure uniformity.

 \subsection{Analysis and Interpretation of Results}\label{sec:6.3.3}

 \citet{Levelt1974} has complained that linguistics lacks a \textit{theory of interpretation}, that is, a standard specification of how data are considered to bear on the theory. I conclude this section with some specific suggestions about the interpretation
% Theoretical and Methodological Implications  195
 of grammaticality judgment data. The first seems almost too obvious to mention, and yet linguists consistently ignore it: without performing statistical tests of significance,\is{statistical significance} we cannot know whether trends in our data are likely due to chance or to actual facts about grammars (or some other part of the mind), unless we truly have sledgehammer results. The more levels of grammaticality we try to distinguish, the less unanimity we find, and the more we need to rely on statistics. \citet[157, fn. 31]{Hirst1987} cites a particularly serious example of this type of shortcoming. In an empirical study of ambiguity,  \citet{FordEtAl1982} argue for a particular parsing theory on the basis of slight preferences of sentence readings among their subjects (e.g., an 11-to-9 majority in one case). Hirst shows that 12 of the 51 preferences they present as evidence are not statistically significant. (See \citet{Birdsong1989} for other examples of spurious interpretations of experimental data.) Another problem of statistical ignorance, originally pointed out by \citet{Clark1973}, is the \isi{language-as-fixed-effect fallacy}. Clark's point is that even when we find statistically significant results on a grammaticality test, we cannot necessarily generalize from the actual sentences used in the study to all sentences of the same form. The statistical analysis must treat the materials as a random rather than a fixed factor, which results in more stringent criteria for significance, but many studies have failed to do this. Additionally, the implications of the way the stimuli are gathered must be considered. It might not be crucial to do true random sampling of sentences\is{experimental design!stimulus materials, random sampling of} (it is not entirely clear what that would mean), but, as suggested in \sectref{sec:6.3.1}, experimenters must consider the extent to which their materials are representative of the population of sentences to which they would like their results to generalize. (Clark also points out other common statistical problems with psycholinguistic experimentation.)

 Simple statistical comparison of judgment ratings is not the only type of analysis that can be used to learn about grammaticality. \citet{BradacEtAl1980} were motivated by the belief that looking at a single measure, such as grammaticality/acceptability, might conceal the ``rich, multi-dimensional nature of language judgments.'' Thus, their technique was geared to multiple \isi{factor analysis}. Their stimuli were broken down similarly to those of \citet{MaclayEtAl1960}, by the various types of errors in sentences, including ``school grammar'' errors, typical foreign learner errors, and sentences that are supposedly grammatical although unacceptable. They asked 13 questions about each sentence that were answered on 7-point scales, including ``Is this grammatical?''; ``Is this English?''; ``Is this clear?''; and ``Is the speaker educated?''.\is{rating scale!using more than one dimension} As usual, none of these terms were explained to the subjects, so it should not surprise us to see the authors conclude that ``persons may be quite sensitive to the precise way in which such questions are asked,'' especially since half their subjects were linguists, the other half nonlinguists. They also recorded various other attributes of the subjects. The experimental procedure was very carefully controlled. For instance, ratings on the various scales were elicited in different orders on different trials and the positions of the extremes of the scales were reversed for half the trials. The problem with this and most other multivariate\is{multivariate techniques} studies is that it is very hard to draw any firm conclusions from them; what one is left with is a bunch of correlations among variables. For instance, the 13 rating scales were factored into four major dimensions,\is{multidimensional scaling} one of which was interpreted as grammaticality/acceptability.\footnote{The scales that comprised this dimension were  ``is grammatical/is  ungrammatical,'' ``is acceptable/is unacceptable,'' and ``is correct/is incorrect.''}
 %\textsuperscript{14}
 Among the personal attributes, linguistic training or lack of it was a systematic source of variation in judgments, and so were the number of sisters the subject had and the subject's birth order, whereas sex and handedness accounted for very little variation. Still, this type of analysis can yield useful insights that might otherwise be overlooked. 

 One principle  of interpretation  that many researchers in this area have stressed (e.g., \citet{Chaudron1983}) is that \textit{any} conclusion on the basis of a single kind of experimental test is dubious. Wherever possible we should appeal to \isi{cross-method\-ology validation}\is{validation of experimental results} \citep{CardenEtAl1981}. Even in cases where one kind of task (e.g., judgments) yields reliable results, its validity as an indicator of linguistic competence is suspect because of the numerous potential intervening factors, as discussed in \sectref{sec:6.2}. But if the same results show up reliably across additional types of task, such as unwarned judgments, performance tasks like those used by \citet{QuirkEtAl1966}, short-term memory measures, unintrusive reaction measures such as event-related brain potentials,\is{ERPs (Event-Related Potentials)} sentence completion tasks, or naturalistic observation of speech and writing, then the odds are much higher that the evidence does represent a convergence on fundamental underlying knowledge. In his review of early work, \citet{Carden1976b}
 as showing that judgments \textit{are} correlated with other performance measures.

 This raises the more general question of replication. Following basic scientific principles, the elicitation of grammaticality judgments ought to be a replicable method of data gathering. \citet{Greenbaum1977c} proposes four possible types
 % Theoretical and Methodological Implications
 of replication experiment.\is{replication of experimental results} First, one can perform the same experiment on a different set of subjects. However, while the same outcome will support the original result, it is not so clear how to interpret a different outcome. Is the procedure flawed, were the first results a fluke, or do the new subjects actually have different grammars? Thus, one might prefer to repeat the experiment with the same subjects after some time has elapsed. Then interpreting  the results 
 is straightforward,  but
 procedural problems might arise in getting subjects to attend a 
 second session
 and there is the possibility that they will take a different approach to the task based on their first experience. A third possibility would be to keep the subjects,  but replace the stimulus sentences with lexically varied but structurally
 equivalent  ones. Of  course, it is hard to know  in  advance which  lexical items
 could actually be syntactically relevant, so once again negative results are problematic. The fourth possibility is essentially that discussed in the previous paragraph, namely, to keep the stimuli and subjects the same, but take a different measure of intuitions, e.g., change from a rating to a ranking task. Here the blame assignment problem is somewhat easier: differences are most likely caused by extragrammatical factors that differ across the two tasks. The problem is then to determine which set of judgments (if either) reflects the grammar more directly.

 The final and perhaps most troubling problem I will comment on in interpreting grammaticality judgments is what to make of inconsistencies, be  they changes in one subject's judgments over time\is{change in judgments over time} or disagreements among subjects.\is{consistency (between and within subjects)!interpreting inconsistencies}\footnote{In \sectref{sec:3.3.2}, I raise the issue of what should count as an inconsistency. Different experimenters have used different criteria for deciding when two judgments are consistent. Some require them to be identical, while others allow a one-point variation on a scale of three or four values. \citet{Birdsong1989}
 points out that a yea-saying bias, as found by \citet{Mohan1977}, reported in \sectref{sec:3.3.4}, can artificially inflate consistency scores.
 }
 %\textsuperscript{15}
 \citet{Fillmore1979} points out that we must first rule out the possibilities that our data gathering was faulty, or that our subjects were uncooperative, insensitive, or unreliable, before  concluding that different grammars are the cause. Generative linguists have often suggested that the between-speaker differences that  are found represent minor disagreements on fringe data,\is{data disagreements} but that the major substance of the grammar is the same for everyone, being a function of, say, UG plus parameter settings.\footnote{\citet{Newmeyer1983} explicitly argues that the vast majority of alleged \isi{data disagreements} in generative grammar are actually disagreements about the role of the theory, not about judgments. My own experience has been that such a position is untenable, as exemplified by the cases discussed in \sectref{sec:2.3.2}.}
 %\textsuperscript{16}
  Others have disagreed, e.g., \citet{Grandy1981} and \citet{Levelt1972}. \citet{CardenEtAl1981} claim that ``\isi{data disagreements}, regrettably  but perhaps not
 surprisingly, tend to center on theoretically crucial examples'' (p. 584).\footnote{\citet{Newmeyer1983} correctly points out that the particular example that Carden\ia{Carden, Guy} \& Dieterich\ia{Dieterich, Thomas} use to exemplify the situation (the debate between Chomsky\ia{Chomsky, Noam} on the one hand and Katz\ia{Katz, Jerrold J.} \& Postal\ia{Postal, Paul M.} on the other over the interaction between \isi{passivization} and \isi{quantifier scope}) is probably not a true instance of data disagreement.\is{data disagreements}}
 Under a principles-and-parameters approach, we might expect the periphery, that part of the grammar \textit{not} specified by UG but somehow learned, to vary with people's learning abilities and experience, but we would presumably not expect variation on matters directly within the scope of innate universals. While it is hard to find data bearing directly on this point, my suspicion is that it is untrue.\footnote{This is not to deny that there is an (arguably very small) core of simple sentences that all speakers of a language will agree are grammatical. But this set is not identical to the core\is{core grammar} in Chomsky's\ia{Chomsky, Noam} technical sense; far from it.}
 %\textsuperscript{18}
  My own experience is that Binding\is{Binding Theory} and Subjacency,\is{Subjacency violation!interspeaker variation on judgments of} conditions that are paradigmatic examples of the domain of UG, are two of the areas of greatest variation.\is{interspeaker variation!on Subjacency violations} (In fact, recent evidence suggests that Subjacency might not be a grammatical phenomenon after all; see \sectref{sec:7.2}.) As one example, see again the discussion of \textit{that}-trace effects\is{Comp-trace effect} in \sectref{sec:2.3.2}. For another, see \citegen{Kitagawa1991} paper on copying identity. With regard to sloppy versus strict identity interpretations of coreference in \isi{VP-Ellipsis}, Kitagawa identifies five ``dialects''\is{dialects (idiolects)} among fifteen speakers.\footnote{It should be noted that while coreference is in the domain of Binding Theory\is{Binding Theory!and interspeaker variation}\is{interspeaker variation!on Binding Theory}, the explanation that Kitagawa tentatively proposes for the range of dialects\is{dialects (idiolects)} involves differences in feature-copying rules rather than in the conditions of Binding Theory per se. Still, these rules are presumably part of UG too.}
 %\textsuperscript{19}
  Here one really cannot argue that the disagreements\is{data disagreements} involve unimportant or fringe sentences. As rare as they might be in everyday speech, if they are governed by innate principles then this degree of variation is unexpected. The standard appeal to performance factors is also unconvincing here, at least in the usual narrow sense of the term, which typically refers to memory limitations\is{memory limitations} or processing by analogy. While  it is reasonable to suggest that people's ability to process multiply center-embedded\is{center-embedding, multiple} sentences could be a function of their short-term memory capacity independent of their grammar, the same does not ring true for coreference constraints.

 Are we forced to conclude, then, that UG exhibits individual differences,\is{interspeaker variation!in Universal Grammar} that we are not all born with identical principles and parameters? This is certainly a possibility, and would not be a particularly surprising result\schdash{}in general, people do exhibit individual differences on many, perhaps all, innately specified behaviors, while sharing the gross features. In fact, \citet{Chomsky1991} takes it as a\label{ChomskyPrefacestart}
 %\setcounter{itemize}{16}
 % Theoretical and Methodological Implications  199
 truism that genetically based UG will be subject to individual variation.\is{interspeaker variation!in Universal Grammar}  It is merely a theoretically simplifying assumption that UG is invariant. Apparently this view has not been much stressed in the literature, since \citet{Lieberman1991} believes that ``until the past year, virtually all theoretical linguists working in the Chomskian\ia{Chomsky, Noam} tradition claimed that the \isi{Universal Grammar} was \textit{identical} in all humans'' (p.~53, emphasis in original). One way to get at the extent to which inter-speaker variation in judgments can be traced to differences in UG might be to compare the degree of agreement on intuitions between identical versus fraternal twins.\is{twins, use in investigating UG} In principle, areas in which identical twins always agree but fraternal twins do not would be candidates for UG differences,\is{interspeaker variation!in Universal Grammar} while areas in which identical twins disagree would be candidates for a learning account. Whatever the source of individual differences, linguists must take responsibility for the range of variation that is actually found.\footnote{Haj Ross\ia{Ross, John Robert} seems to have felt that some linguists were not doing so; he paraphrased the standard research directive as ``Write a grammar of what you find in your heart'' (class lectures, MIT and Harvard University, 1966\textendash{}67, attributed to Ross\ia{Ross, John Robert} in \citet{Carden1973}). In contrast, Noam Chomsky (personal communication)\ia{Chomsky, Noam} believes that variation has always been taken seriously in linguistic theory.}\label{ChomskyPrefaceend}
 %\textsuperscript{20}


 An explanation in terms of extragrammatical factors seems more likely in the case of changes in one person's judgments from one elicitation to the next.\linebreak (Either that or, as \citet{Snow1975} suggests, poor experimental design could be to blame.) While grammars certainly do change in some aspects over the course of a lifetime, most linguists would probably not want to say that this happens on a day-to-day basis in adulthood. That is why \citet{Carden1973} suggests that individual differences be attributed to the grammar only if they are reliable (he gives several ways of computing reliability indices) and if they correlate with other linguistic differences. Another alternative that has been bandied about occasionally is that grammars are probabilistically defined,\is{probabilistic grammar}\is{grammar!probabilistic} so that some  sentence  will  be judged good 90\% of the time, bad the other 10\%, based on variation in neural signal strength or some such factor. (In fact, the race-based\is{parsing!race-based} approach predicts such a pattern of events, because the speed with which a given rule can be used depends in part on how recently it was used in the past, according to an activation function that decays over time.) The problem with this general line of probabilistic  analysis is that it denies that there are any systematic causes behind the variation we find. If instead we start with the assumption that it has a cause within the system of judgment performance, then as we understand more about that process we might  eventually  be in a position  to say precisely  what  governs  variation  over
 time and predict it as a function of other cognitive and situational variables. Only after we have exhausted the search for such an explanation should we resort to random  probabilities.

 \citet{Labov1975} has proposed a widely cited set of working principles for dealing with variation in grammaticality judgments and interpreting their relationship to the grammar:

 \begin{itemize}
 \item[I.] The Consensus Principle: if there is no reason to think otherwise, assume that the judgments  of any native speaker are characteristic of all speakers of the language.

 \item[II.] The Experimenter Principle: if there is any disagreement on introspective judgments,\is{data disagreements}  the judgments  of those who are familiar with the theoretical issues may not be counted as evidence.\is{linguist!as subject}

 \item[III.] The Clear Case'\is{clear cases!use of} Principle: disputed judgments  should be shown to include at least one consistent pattern in the speech community or be abandoned. If differing judgments  are said to represent different dialects,\is{dialects (idiolects)} enough investigation of each dialect should be carried out to show that each judgment  is a clear case in that dialect. (p. 31)

 \item[IV.] The Principle of Validity: when the use of language is shown to be more consistent than introspective judgments,  a valid description of the language will agree with that use rather than introspections.  (p. 40)
 \end{itemize}

 \noindent
 For the most part, these suggestions strike me as quite reasonable, although a note of caution is in order. Principle I is intended to allow the field to continue without having to resort to experimental verification of sentences whose (un)grammatical status no one has ever questioned. Principle II is intended to guard against   experimenter effects; I suggest strengthening it so that the investigating linguists' own intuitions are \textit{never} counted as evidence, even if their data have not been disputed.\footnote{Of course, linguists' intuitions will always be used to inspire theoretical work; I merely wish to exclude them from the verification of the data.}
 Principle IV jibes well with my comments in \chapref{sec:3} concerning the potential for differences between use and intuitions. Unfortunately, there is still no way of knowing when primary data from linguistic use need to be sought out (since such relevant data are often not immediately available), and there is no obvious procedure for determining whether they are more consistent than judgment data. But the major problem comes with Principle III. Its wording (and that of Principle I) indicates that Labov\ia{Labov, William} is interested in accounting for the grammar of \textit{groups} of speakers (as inferred also by \citet{Newmeyer1983}), but I have argued that it is entirely possible for \textit{individuals} to have unique grammars, so that discarding judgments that are not shared by other speakers could involve throwing away real data. As \citet{Ringen1979} points out,

 \begin{quote}
 Linguists frequently and publicly acknowledge that the reports of intuitions they are using provide data only about the dialect\is{dialects (idiolects)} of a single speaker. ... Such acknowledgements characteristically come as responses to evidence of differences between informant intuitions.\is{data disagreements} ... Where conflicting informant judgments indicate differences of idiolect or dialect, linguists do not conclude that the judgments are not judgments on which a [transformational generative grammar] should be based. Rather they conclude that the judgments must be taken into account by different grammars. (pp. 121\textendash{}122)
 \end{quote}

 \noindent
 Certainly, the more speakers we can find who share a set of intuitions, the more confident we can be of the legitimacy of those intuitions, but at a certain point we will have to hope that our methods have removed as many confounds as possible and treat the resulting data as significant, even if it applies only to a single speaker. While there might be little interest in studying individual idiolects for their own sake, the \textit{range} of possibilities that are found is crucial to the construction of theories.

 \section{Conclusion}\label{sec:6.4}

 In this chapter I have presented two major proposals that assemble the information gleaned from the first five chapters of this work. The first is an initial attempt at a model of mental components of metalinguistic activity, with a focus on grammaticality judgments. There is clearly much more work that could be done in this vein. First, we might now go on to suggest specific experiments that could clarify aspects of the model or show where changes are required. Second, we could derive new empirical predictions regarding how certain effects should manifest themselves in tasks that implicate certain components of the mental structure, and run these tasks experimentally to see whether the predictions are borne out. Third, we might consider whether there is something to be gained from implementing a computer simulation of the model. Since it is highly parallel, and
 relies on very many microcopmutations, simulation could lead to better understanding and refinement, as it has for connectionism and race-based parsing.\is{parsing!race-based} The second major proposal  in this chapter takes the form of methodological guidelines for eliciting grammaticality judgments. I do not go so far as to propose a particular experimental design, since this must vary with the specific purpose of the experiment, but if even some of my suggestions are followed, significant strides toward a solid empirical foundation for linguistic research will have been made. Whether this is likely to occur will be the subject of part of the final chapter, after I propose some more general directions for future research.
