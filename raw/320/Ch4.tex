
\chapter{What happened to underlying representations?} \label{chapter_URs} \label{ch4}

This chapter examines in more detail the concept of morph sets, sets that are composed of  distinct surface morphs sharing some syntactic and semantic features. Such morphs are directly related to the data encountered by a learner. We propose that sets of morphs are the formal instantiation of the phonological forms corresponding to a particular set of morphosyntactic\is{feature!morphosyntactic} features, instead of invoking the more common unique \is{underlying representation}underlying representation (UR). The issue of URs is significant to an Emergent framework because we do not see a plausible way to derive them directly from the input. Thus, if we were to conclude that URs are essential to accounting for phonological patterns, we would have evidence of at least one innate linguistic principle governing phonological systems.\is{innateness} In this chapter, we argue that there is no conceptual necessity for underlying representations; in Chapter \ref{chapter_consequences}, we present our empirical argument against the concept, providing Emergent analyses to demonstrate how a wide range of phonological patterns are explained under Emergence, without recourse to underlying representations.

Throughout our discussion, and especially in this chapter, we use the term \textit{morpheme}  strictly to reference the structuralist\is{structuralism!morpheme} concept (as defined in this chapter), which forms the basis of both the \is{generative phonology}generativist's underlying representation and the optimality theorist's input. We use the term \textit{underlying representation}\is{underlying representation} to refer to the hypothesis that there is a single mental representation for each (regular) ``morpheme''\is{morpheme},  whether it is the \is{underlying representation}underlying representation of generative phonology\is{generative phonology} or the input of Optimality Theory\is{Optimality Theory}.


\section{Relating sound to meaning: Schematising the relations} \label{section_no-phon-motivation}

\is{meaning|(}We begin our discussion by returning to a point of central importance that was raised in Chapter \ref{ch1}, namely that  the core of establishing a morph set\is{acquisition!morph set} -- vocabulary learning -- involves a great deal of memorisation. For a learner to identify the phonetic\is{phonetics} forms of morphs, the learner must encounter them. These forms must occur in the ambient language, and must occur in a salient enough fashion to be committed to memory. Whether or not the occurring surface morphs are grouped into sets related by meaning in the adult grammar\is{grammar!acquisition} or exhibit other systematic redundancies that must be encoded grammatically, the beginning of any such learning involves encountering the relevant phonetic forms and committing some sort of information to memory.\is{memory}


This early learning is central to the Emergent hypothesis:\is{Emergent Grammar hypothesis} adult grammars\is{grammar!acquisition} have the shape they do because those shapes can be acquired by children (\citealt{Deacon:1997}).\is{acquisition} Thus, we begin with acquisition, starting with the straightforward case where a learner encounters no phonologically significant variation\is{variation} in the realisation of a lexical item.  In the absence of any such variation in the form of the lexical item (see \textsection\ref{Yangben_categories_section}), the most straightforward representation of the lexical item would be as it is: what you  hear is what you get.\footnote{For signed languages, the straightforward representation would be based directly on what is seen. The fact that language is readily learned in either an auditory or a visual modality\is{modality} is consistent with our position that much of the learning of the sound system of a language makes use of cognition\is{cognition} that is not specific to language.\is{modality}} In early stages, a generalisation\is{generalisation!lexical} over the observed exemplar cloud\is{Exemplar Theory} might be conceived of as the representation of the lexical item.  Yet acquisition involves more than such holistic learning. At some point in the acquisition of a lexical item,\is{acquisition!morph} the learner connects the holistic lexical item with a temporally arranged sequence\is{sequence} of  individual sound units (\citealt{Bybee:1999}), providing another type of symbolic representation\is{symbol} for the lexical item in development.  If the symbolic sound units making up this lexical item are invariant, then there would be no reason to postulate anything other than that observed string as the representation of the lexical item under consideration.

To make this concrete, consider a learner who is exposed to an English\il{English}  form like [\ipa{dɑɡ}]\down{\sc dog} on multiple occasions. The word may be produced with varying amplitudes, it may be produced with a fully released [\textipa{ɡ}] or with an unreleased [\textipa{ɡ}], on various pitches, and so on -- productions which fall within the range of phonetic realisations encountered for those three segments. In this scenario, a plausible representation for [\ipa{dɑɡ}]\down{\sc dog} would simply be \{\ipa{dɑɡ}\}\down{\sc dog}.

\begin{dadpbox}{The abstract and concrete morph}{box-abstractness-morph}



The proposed lexical representation of a morph\is{morph!concrete} is already a considerable abstraction\is{abstractness} because the production\is{production} of any lexical item will vary according to all manner of factors, including (but not limited to) speaker, speech rate, and social context\is{variation}. We conceive of each morph as a single unimodal exemplar cloud of sound sequences\is{sequence} where there is no systematic variation in the phones making up the lexical item, nor in stress,\is{stress} nor in tone -- in short, no systematic ``higher level'' linguistic variation at all (see \citealt{vandeWeijer:2012}). The \textit{morph}\is{morph} is a label for that cloud; labelling a cloud gives access  both  to the undifferentiated cloud (via the label; in this way a morph is abstract\is{abstractness}, though in a way directly controlled by the content of the cloud)  and to the  individual tokens making up the cloud (in this way the morph is concrete). See relevant discussion in \textsection\ref{Yangben_categories_section}.
\end{dadpbox}



Now consider a somewhat more complex case: the learner encounters two different phonetic\is{phonetics} realisations corresponding to the same meaning. Phonetically, the realisations might be quite similar\is{similarity!morphs} to each other, for example, [\ipa{nʌɪf}]\down{\sc knife} vs. [\ipa{naɪv}]\down{\sc knife} (the latter encountered in plurals), both as encountered by some speaker of ``Canadian'' English.\is{Canadian raising}\il{English} In this case, there are two differences: the vowel quality and the quality of the final consonant.\il{English!Canadian} At an early stage the learner might consider [\ipa{ʌɪ}] and [\ipa{aɪ}] to be variant realisations of a single sound, just like the released or unreleased [\ipa{ɡ}] of [\ipa{dɑɡ}]\down{\sc dog}. However, even at quite an early stage the final consonants are likely to be categorised\is{category} as distinct: knowledge of the contrast\is{contrast} between forms like %[\ipa{fæt}]\down{\sc fat} vs. [\ipa{væt}]\down{\sc vat},
[\ipa{fɛɹi}]\down{\sc ferry} vs. [\ipa{vɛɹi}]\down{\sc very}, [\ipa{weɪfəɹ}]\down{\sc wafer} vs.\ [\ipa{weɪvəɹ}]\down{\sc waver}, [\ipa{seɪf}]\down{\sc safe} vs. [\ipa{seɪv}]\down{\sc save}, and so on, would show the learner that [f] and [v] are different and so neither [\ipa{nʌɪf}] nor [\ipa{naɪv}] would be considered an expected phonetic variant of the other as far as the final consonant is concerned.

Such regular patterns have formed the focus of a great deal of attention for decades. While we might naïvely conceive of such pairs as belonging to the schema in (\ref{morph-schemas-1}a), the generative\is{generative phonology} approach has been to adopt the schema in (\ref{morph-schemas-1}b) wherever possible, where the lines linking /Z/ to [X] and [Y]  represent phonologically predictable relations. The schema in (\ref{morph-schemas-1}a) is typically reserved for cases where the relations between the morphs are not predictable, as in  \citet{Tranel:1996exceptionality, Bonet:2004, Bonet+:2007, Mascaro:2007, Nevins:2011}.

\begin{example}\et{Conceptions of the relationship between morphs} \label{morph-schemas-1}
\begin{multicols}{2}
\ea \{[X], [Y]\}\down{\sc meaning-$\upalpha$} 
\ex \vtop{\strut\vskip-1.5\baselineskip{\begin{forest} for tree = {grow'=90}
        [/Z/,name=z
            [{[X]}] [{[Y]}]
        ]
        \node [right=1ex of z] {\textsubscript{\textsc{meaning-α}}};
\end{forest}}}
\z
\end{multicols}
\end{example}



The schemas in (\ref{morph-schemas-1}) represent cases of various types, with the most heavy restrictions placed on the type in (\ref{morph-schemas-1}b). In (\ref{morph-schemas-1}b), /Z/ is related to both [X] and [Y] by phonological rules/constraints (e.g., in English,\il{English} /z/\down{\sc plural} relates to [z], [s], [\@z]).  In a case where /Z/ is altered in some context but surfaces without change in others, one of [X] or [Y] is related by phonological identity\is{identity} to /Z/. Such phonological identity is not a necessary property of the relation, however, since in some cases all instances of  underlying  /Z/ will undergo phonological change before surfacing (this is illustrated in \textsection\ref{section_allophone} and \textsection\ref{section_Kinande}). Since both [X] and [Y] are phonologically related to /Z/, it follows that [X] and [Y] must be phonologically related to each other. Crucial to note, however, is that this relation of phonological similarity\is{similarity} is instantiated {\it indirectly} in theories with an underlying representation,\is{underlying representation|(}  via the underlying representation itself: the relation is indirect, through /Z/; there is no direct formal relation between [X] and [Y]. 


Three properties are important in understanding these schemas, listed in (\ref{UR-criteria}). The first involves {\it derivability}: can the relationship between /Z/ and each of [X],  [Y] be defined in terms of phonological properties? The second property involves {\it productivity}:\is{productivity|(}\is{derivability|(} are the patterns relating /Z/ to [X] and [Y] observed  systematically in the language or are they \is{idiosyncrasy}idiosyncratic patterns? The third property is {\it optimisation}\is{optimisation|(}: is the choice between [X] and [Y] in a given context determined by phonological properties?\footnote{We use \textit{optimisation} and \textit{optimisable} as defined in (\ref{UR-criteria}c)  (phonologically determined by context, as opposed to being in a phonologically definable relation, i.e.\ \textit{derivable} (\ref{UR-criteria}a)); this is different\is{Emergences vs.\ OT} from the use of these terms in Optimality Theory\is{Optimality Theory} where ``optimisation''\is{optimisation!Optimality Theory} refers to satisfying universal markedness and faithfulness constraints. The two uses are slightly different: for example, choosing a V-initial morph after a consonant and a C-initial morph after a vowel is phonologically determined and satisfies syllabic\is{syllable} markedness constraints; choosing a V-initial morph after a vowel and a C-initial morph after a consonant is again phonologically determined, but counter to syllabic markedness constraints. As the pressures for choosing a particular morph will tend to be  phonetically/phonologically\is{phonetics} motivated, we collapse both possibilities in the discussion here. Note that there has been considerable controversy over whether \is{non-productivity}non-productive relations among morphs are optimising in the optimality theoretic sense (\citealt{Kager:1996, Rubach+:2001, McCarthy:2002}) or not (\citealt{Paster:2005wccfl, Paster:2006, Bye:2007}). Productive cases of the type in (\ref{morph-schemas-1}b) are generally assumed to be optimising in the optimality theoretic sense (though see \citealt{Ford+:1983}); these are the core cases addressed by phonological analysis.} For the ensuing discussion, we use the terms as defined in (\ref{UR-criteria}), so that we have a means of referring to each concept independently.  (In (\ref{UR-criteria}), α\ stands for  morphological, syntactic,\is{syntax} and semantic properties.)\is{underlying representation!criteria,  definition}


\begin{example} \et{Criteria for  /Z/\down{α} given [X]\down{α}, [Y]\down{α}} \label{UR-criteria}
\ea Derivable: The relations between /Z/\down{α} and [X]\down{α} and between /Z/\down{α} and [Y]\down{α} are defined phonologically.
\ex Productive: The relations between /Z/\down{α} and [X]\down{α} and between /Z/\down{α} and [Y]\down{α} are found sytematically in the language.\is{productivity!definition}
\ex Optimisable: The choice between [X]\down{α} and [Y]\down{α} is determined by phonological properties.
\z
\end{example}

 The concepts are familiar, but are not always differentiated in the literature -- which is unfortunate, since these properties do not always correlate. For example, the two suffixal morphs indicating nominative in Korean,\il{Korean} \{i, ka\}\down{\sc nominative}, are not similar enough to be phonologically related to a single underlying form; they are not derivable, yet the choice between the two is phonologically optimising,\is{optimisation!not derivable} with [i] chosen after a consonant and [ka] after a vowel (\citealt{Sung:2005}). The English\il{English} indefinite article, \{\@, \@n\}\down{\sc indefinite}, is similar in that it is also phonologically optimising ([\@] pre-consonantal, [\@n] pre-vocalic) but -- unlike Korean -- the two morphs could be related to a phonologically similar\is{similarity} underlying representation, a relation that is not productive.\is{optimisation!not productive}


 
In generative phonology,\is{generative phonology} the schema in (\ref{morph-schemas-1}b) is generally reserved for cases that satisfy all three criteria: they are phonologically relatable,  productive, and optimising. If any of the three properties is missing, then the different forms are simply listed (\ref{morph-schemas-1}a).\footnote{In some cases, unproductive forms may be treated by rule but their lack of productivity\is{non-productivity} presents problems. See \textsection\ref{section_MS-independence} and \textsection\ref{section_Mayak_low_vowels}.}   Note that while both listed and derived forms may be phonologically optimising, both rule-based and constraint-based accounts treat them as formally distinct objects, either listed morphs (\citealt{Mascaro:2007, Nevins:2011}) or unitary underlying representations (\citealt{Chomsky+:1968, Prince+:1993}).\footnote{Things are a bit more complex in Optimality Theory.\is{Optimality Theory} See discussion  of the rich base in \Sec\ref{section_allophone}.} 

There is no argument from derivability, nor from productivity, nor from being optimising that unambiguously selects (\ref{morph-schemas-1}b) over (\ref{morph-schemas-1}a). Derivability  does not require underlying representations: it is possible to phonologically relate [X] and [Y],  directly by means of Morph Set Relations (MSRs)\is{Morph Set Relation}, rather than relying on indirect encoding  mediated by an abstract representation,\is{abstractness!underlying representation}\is{underlying representation!abstractness} /Z/. Encoding productivity\is{productivity} does not require the postulation of unitary underlying representations: these relations may be highly productive or may be relevant for some (possibly quite small) subset of the lexicon, representing different degrees of productivity.  Finally, being optimising does not motivate (\ref{morph-schemas-1}b): it is possible to use quite standard conditions to choose the optimal member of a  set in a given context, whether that set is listed -- as in Emergence -- or generated -- as in Optimality Theory.\is{Optimality Theory} In Emergence\is{Emergent Grammar}, \is{derivability}derivability is expressed by Morph Set Relations, introduced  in \Sec\ref{section_MSR_introduction}, \is{productivity}productivity by Morph Set Conditions, \Sec\ref{section_MSCs}, and \is{optimisation}optimisation by well-formedness conditions, \Sec\ref{section_choice}. On these concepts, see also  \citet{Archangeli+:2012Korea, Archangeli+:2015_Frontiers, Archangeli+:2015_K-tone, Archangeli+:2015_YVH, Archangeli+:2016mm, Archangeli+:2017-Setswana, Archangeli+:2018routledge}. Hence to motivate the construct ``/Z/'', the underlying representation, requires some sort of evidence that does not depend on \is{phonological relatedness}phonological relatedness, productivity, or optimisation. \is{optimisation|)}\is{derivability|)}

\begin{dadpbox}{Predictable vs.\ idiosyncratic information}{box-idiosyncratic-URs}
\is{idiosyncrasy}The criterion behind underlying representations is whether some aspect of the sounds of a form is predictable or not: ``[t]he underlying representation (UR) ... contain[s] all of the idiosyncratic information about the pronunciation of the constituent morphemes of the utterance, and the phonetic representation (PR) ...  contains the idiosyncratic information plus the predictable information about the pronunciation of the utterance.'' (\citealt[32]{Kenstowicz+:1979}; see also \citealt{Archangeli:1984, Cole+:2011}).\\

In the generative framework,\is{predictable vs. idiosyncratic information}\is{generative phonology} the predictable information was added by rule. Under \is{Emergences vs.\ OT}\is{Optimality Theory}Optimality Theory, the predictable information is determined by a comparison between the input and the output of Evaluation. With the Emergent framework, predictable and idiosyncratic is more nuanced. Morph Set Relations\is{Morph Set Relation} express systematic relations between morphs within a set; productivity\is{productivity} (characterised by Morph Set Conditions)\is{Morph Set Condition} may be unrestricted or may be a property of a subset of the lexicon. Well-formedness conditions\is{well-formedness condition} determine the overall shape of a unit within a particular domain, whether a morph or a polymorphic constituent.\is{predictability}\is{idiosyncrasy}
\end{dadpbox}

\section{Where did the concept of /Z/ come from?}
\label{URs_history_section} \label{morph-sets-as-building-blocks-section}

Since phonological reasons for positing underlying representations fall short, as shown in \Sec\ref{section_no-phon-motivation}, we are left wondering why phonologists have relied on the concept. To answer this, and to determine whether the historical record provides motivation for the notion,  we review why a construct like an \is{underlying representation!motivation|(}{\it underlying representation} was ever posited in the first place: what motivated the postulation of /Z/ in (\ref{morph-schemas-1}b)? 

It is uncontroversial that learning the sound string associated with a given meaning involves memorising\is{memory} the appropriate string and assigning it to the appropriate meaning.\is{acquisition!morph} The learner of English\il{English} must learn that the notion {\sc dog} is encoded by the sounds [\ipa{dɑɡ}], while the learner of Japanese\il{Japanese} encodes (at least roughly) the same notion by [inɯ], the learner of French\il{French}  by [\ipa{ʃj\~ɛ}], and the learner of \Y\ by\il{Yor\`ub\'a} [\ipa{\=aɟá}]. Whether a theory in some general sense tilts the scale towards the nature end or the nurture end, there is agreement that learning lexical items involves committing to memory\is{memory} sound strings paired arbitrarily with  \is{sound-meaning correspondence}semantic and morphosyntactic\is{feature!morphosyntactic} information; that is, learning lexical items involves a large component of  nurture. Our first question then is whether there is something in acquisition\is{acquisition!underlying representation}\is{underlying representation!acquisition} that drives the learner towards postulating some abstract\is{abstractness!underlying representation}\is{underlying representation!abstractness} /Z/ when exposed to [X] and [Y].\is{meaning|)}

\subsection{Does acquisition require /Z/?}

\is{acquisition!underlying representation|(}\is{underlying representation!acquisition}When we consider the various morphs a language learner acquires, we see wide variety in the types of items that must be learned and related to each other. In some instances the formatives corresponding to a particular meaning\is{meaning} may be phonologically unrelated to each other, as in English\il{English} [\ipa{biː}]\down{\sc be}, [\ipa{ɪz}]\down{\sc be.3sg.pres}, [\ipa{ɑ\ur}]\down{\sc be.3pl.pres}, [\ipa{wʌz}]\down{\sc be.3sg.past}, and [\ipa{wə\ur}]\down{\sc be.3pl.past} all encoding (in part) the semantic notion of {\sc be}. Here the relation between the various formatives is just as arbitrary as the relation between form and meaning in a unit like [\ipa{dɑɡ}] = {\sc dog} (\citealt{deSaussure:1916}). Related forms may be natural -- phonologically optimising -- even if not fully productive,\is{optimisation!not productive} as in the English  prefix \{\ipa{ɪn, ɪm, ɪ, ...}\}\down{\sc neg}: [\ipa{ɪn}] (\textit{ineffective}), [\ipa{ɪm}] (\textit{imperfect}), [\ipa{ɪ}] (\textit{irregular}); cf. the invariant prefix\is{morph!invariant} \{\ipa{ʌn}\}\down{\sc neg} (\textit{unafraid}, \textit{unpleasant}, \textit{unresolved}).\footnote{See \textsection\ref{URs_English-nasals} for discussion of this English\il{English} case.} Still other sound strings may be related in a highly productive, regular fashion. For example, English verbs ending in [t] or [d] have related forms ending in a tap, as illustrated by [\ipa{sɪt}]\down{\sc sit}:[\ipa{sɪɾ-ɪŋ}]\down{\sc sit-prog}, [\ipa{weɪd}]\down{\sc wade}:[\ipa{weɪɾ-ɪŋ}]\down{\sc wade-prog}, and so on.

\begin{dadpbox}{How dissimilar can morphs in the same set be?}{box-dissimilar_morphs}
The absence of innate\is{innateness} linguistic predispositions governing the phonological properties of language predicts a wide spectrum of possibilities in \is{morph set!internal similarity}morph set membership, from single forms to multiple forms corresponding to the same meaning,\is{meaning} from phonetically similar\is{similarity!morphs} to phonetically dissimilar forms. Items like [\ipa{dɑɡ}]\down{\sc dog} illustrate the single morph end of the spectrum while  \{\ipa{nʌɪf}, \ipa{naɪv}\}\down{\sc knife} and \{\ipa{sɪt}, \ipa{sɪɾ}\}\down{\sc sit}, etc., have  multiple forms with a fair amount of phonetic similarity. Standard cases of suppletion\is{suppletion} are characterised by multiple morphs with high dissimilarity,  such as [\ipa{ɡoʊ}]\down{\sc go} vs. [\ipa{wɛnt}]\down{\sc go.past} (\{\ipa{ɡoʊ, wɛnt}\down{\sc past}\}\down{\sc go}), and the various forms of {\sc be} just discussed. The  \Identity\ (\ref{identity-assumption})\is{Identity Principle} applies pressure for similarity among morphs in a morph set, but this is not an absolute law.
\end{dadpbox}


Crucially, we see that semantically or syntactically related forms occur on a scale of \is{phonological relatedness}phonological relatedness (\citealt[279--281]{Hockett:1958}), from no significant variation\is{variation!phonological relatedness} \{[P]\} (\tabref{tab:phonological-relatedness}a), to forms that bear a  phonological relation  \{[P\down{i}], [P\down{j}]\} (\tabref{tab:phonological-relatedness}b), whether the relation is productive or not, to forms that are phonologically unrelated \{[P], [Q]\} (\tabref{tab:phonological-relatedness}c). 

\begin{table} \caption{Hockett's scale of phonological relatedness\label{tab:phonological-relatedness}}
\begin{tabular}{lcclll}
\lsptoprule
	&variation?	&relation?&schematic&example\\\midrule
a.	&no&---&\{[P]\}\down{{\sc meaning}-$\upalpha$} &\{\ipa{dɑɡ}\}\down{\sc dog}\\
b.	&yes&yes&\{[P\down{i}], [P\down{j}]\}\down{{\sc meaning}-$\upbeta$} &\{\ipa{sɪt}, \ipa{sɪɾ}\}\down{\sc sit}\\
c.	&yes	&no	 &\{[P], [Q]\}\down{{\sc meaning}-$\upgamma$}& \{\ipa{ɡoʊ}, \ipa{wɛnt}\down{\sc past}\}\down{\sc go}\\
\lspbottomrule
\end{tabular}
\end{table}

 
\largerpage[-2]
Of these three logical possibilities, only \tabref{tab:phonological-relatedness}b meets the criteria in (\ref{UR-criteria}) for having an underlying representation that is distinct from at least one of its surface realisations. Yet, it seems unavoidable that part of learning a language is learning when different strings of sounds  correspond to the same meaning, whether or not those strings are phonologically related. Prior to recognising \is{sound-meaning correspondence}correspondences, learned items are represented as simple invariant pairings between some sound sequence\is{sequence} and a meaning, \tabref{tab:phonological-relatedness}a. As the learner recognises that some meanings\is{meaning} have more than one set of sounds, but before phonological productivity has been established, these would presumably be represented as members of the class with unrelated variation,\is{variation!phonological relatedness} \tabref{tab:phonological-relatedness}c. It is only on recognising phonological relations among some of the varied sets  that a learner can shift some instances of the type in \tabref{tab:phonological-relatedness}c into the type in  \tabref{tab:phonological-relatedness}b. Underlying representation models claim that  the learner would establish a unique \is{underlying representation!unique}underlying phonological form of the type schematised in (\ref{morph-schemas-1}b), but would do so {\it only} for those sets where the observed surface forms are not only phonologically related but related in a \is{underlying representation!productivity}productive way. The postulation of such a unique form -- a unit that has achieved remarkable currency -- cannot be motivated by simple observation since nonuniqueness is the norm in terms of actual observations. Prima facie, this assumption leads to a curious phase of language acquisition, where learners reconfigure their lexicons to include underlying representations for some lexical entries -- precisely those where the relation is productive and completely phonological (that is, it is both derivable and optimisable)\is{derivability}\is{optimisation}. In trying to understand whether this hypothesis can make sense as a model of learner behaviour, we explore the  factors that led linguists to the postulation of this theoretical unit.\is{underlying representation!acquisition}\is{acquisition!underlying representation|)}
\is{underlying representation!motivation|)}\is{productivity|)}


\largerpage[-2]
\subsection{``Morphemes'', syntax, and underlying representations}\label{historical-phoneme}


\is{syntax!underlying representation|(}\is{underlying representation!syntax|(}
Crucial to an understanding of this postulated unit, the underlying representation, is the structuralist\is{structuralism|(} notion that linguistic structures are composed of various kinds of building blocks that are assembled to produce linguistic expressions. In the structuralist view, sentences are composed of words, words\is{word} are composed of \is{morpheme}morphemes --   ``[t]he grammar ... of a language is (i) the morphemes used in the language, and (ii) the arrangements in which these morphemes occur relative to each other in utterances''\is{grammar} (\citealt[129]{Hockett:1958}) -- and morphemes are composed of phonemes.\is{phoneme} Foreshadowing current work in theoretical syntax based on features rather than formatives (with specific phonological shapes), \citet[147]{Hockett:1958} observes that ``[i]n grammatical study we are concerned with morphemes and their arrangements, but not, save in an ancillary way, with the phonemic shapes which represent morphemes.'' \citet[271]{Hockett:1958} illustrates this by examples such as the English\il{English} words {\it bought, went, paid, sold, sang}\is{irregular verbs!English}  which are all analysed as containing two such morphemes (a verb stem and the past tense marker), despite the lack of obvious phonological compositionality in most of the cases he cited. Where most current syntactic theories approach this issue by positing semantic/syntactic features that are not necessarily distinctly \is{spell-out}spelled out for a phonological form (see, e.g. \citealt{Pollock:1989}), the structuralist approach was to posit morphemes linking sound, syntax and semantics, with a phonological representation that abstracts away from the kind of surface variation  that is routinely observed in natural language.  

The move of interest to us is the argument that grouping the surface-occurring morphs into a single abstract  \is{morpheme}morpheme\is{abstractness}  ``simplifies our general picture of linguistic structure, i.e.\ of what relations can be discovered between the elements of linguistic expressions'' (\citealt[179]{Harris:1942}). ``Instead of listing both members of each unit, we now list only one representative of each unit with a general statement of the difference which applies to all of them'' (\citealt[173]{Harris:1942}). This was in essence the move from \{[X], [Y]\}\down{\sc meaning-$\upalpha$} to /Z/\down{\sc meaning-$\upalpha$}.\footnote{Current work continues to explore the two general approaches. For dual mechanism analyses, where regular verbs are treated as compositional and irregular \il{English}\is{irregular verbs!English}verbs are treated as whole words,\is{word} see \citet{Pinker+:1988, Pinker:1991}. For single mechanism compositional analyses for both regular and irregular verbs, see \citet{McClelland+:2002words, McClelland+:2002rules, Stockall+:2006}. See \citet{Albright+:2003} and \citet{Fruchter+:2013} for experimental evidence supporting a single mechanism analysis.} 


\begin{dadpbox}{The morpheme -- the smallest individually meaningful element...}{box-structuralists_on_morphemes}\is{meaning!morpheme}
The fundamental idea of the \is{morpheme!definition}\textit{morpheme} led to a large body of work aimed at establishing what the properties of these postulated units were, work defining the morpheme and then going on to consider implications that these definitions have for sound systems, e.g. \citet{Bloomfield:1933, Bloomfield:1939, Swadesh+:1939, Harris:1942, Wells:1949, Hockett:1958}, etc.  \citet[161]{Bloomfield:1933} described a  simple form, or  morpheme, as ``[a] linguistic form which bears no partial phonetic-semantic resemblance to any other form.'' There was a great deal of discussion of such definitions in the subsequent structuralist literature but the fundamental idea of the morpheme was maintained. \citet[170]{Harris:1942}, for example, states that ``[w]e divide each expression in the given language into the smallest sequences\is{sequence} of phonemes\is{phoneme} which have what we consider the same meaning\is{meaning} when they occur in other expressions, or which are left over when all other parts of the expression have been divided off'', leading to the  much quoted claim that ``[m]orphemes are the smallest individually meaningful elements in the utterances of a language.'' (\citealt[123]{Hockett:1958}).
\end{dadpbox}


For structuralists, \is{morphology}morphology produces the building blocks referred to by the syntax. Since surface variation in phonological form does not translate into syntactic differences, the structuralist approach was to abstract away from such variation, associating a \is{underlying representation!unique, definition}``unique'' phonological form with any given \is{morpheme}morpheme, along the lines of sememes\is{sememe} (the meaning\is{meaning} of a morpheme, \citealt[155]{Bloomfield:1926}):  ``[t]he sememes, on the other hand, {\it which stand in one-to-one correspondence with the morphemes}, cannot be further analyzed by linguistic methods.'' (\citealt[159]{Bloomfield:1926}) [emphasis added -- da/dp].

Fundamentally, the structuralist approach to defining the minimal grammatical building blocks of language involved \is{sound-meaning correspondence}linking a particular minimal sequence of phonemes with a particular meaning. Yet, when that meaning is actually linked  with multiple different sequences\is{sequence} of sounds, which of those different sequences -- which morph -- is the correct one to be linked with that particular meaning when defining the morpheme? There were three parts to answering this question. First, if the syntax operated on units corresponding to \is{morpheme}morphemes, and if observed surface variation in the phonological forms of morphemes was the responsibility of some other component of the grammar,\is{grammar} then the syntax is agnostic about the phonological properties of morphemes. Second, examination led to the observation that in many cases the surface alternants, or allomorphs, of a morpheme  can be phonologically related to each other in a systematic fashion.  Third, it was argued that these observed surface alternants were not all of equal status: ``[s]trictly speaking, we should say that the morpheme [...in cases of alternation...] has two (or, sometimes, more) different phonetic forms...and that each of these \is{alternant!definition}{\it alternants} appears under certain conditions. In our examples, however, one of the alternants has a much wider range than the other and, accordingly, is a \is{alternant!basic}{\it basic alternant}.'' \citet[164]{Bloomfield:1933}; the  non-basic alternant is described as ``a phonetically modified form''. \citet[277]{Hockett:1958} states that if one surface alternant cannot be predicted from one or more other alternants, then the form that cannot be predicted is the ``base form'', giving the relationship in  either (\ref{morph-schemas-base-form}a) or (\ref{morph-schemas-base-form}b) where the \is{theoretical base form|(}base form, /X/ or /Y/, matches one of the surface forms [X] or [Y] respectively, and ``$\upalpha$'' indicates the syntactic/semantic unit.\is{meaning}\is{morpheme}

\begin{example} \et{The ``base form''} \label{morph-schemas-base-form}
\multicolsep=.25\baselineskip\begin{multicols}{2}
\ea ~\\\vspace*{-\baselineskip}\begin{forest} for tree={grow'=90}, baseline
[/X/\down{$\upalpha$}
   [{[X]}]
   [{[Y]}]
]
\end{forest}
\ex ~\\\vspace*{-\baselineskip}\begin{forest} for tree={grow'=90}, baseline
[/Y/\down{$\upalpha$}
   [{[X]}]
   [{[Y]}]
]
\end{forest}
\z
\end{multicols}
\end{example}


The three notions -- that syntax needed no phonetic\is{phonetics} detail, that surface alternants were systematically related on phonological grounds, and that there was a ``base form'' among those alternants -- came together, and the unitary abstract representation was born. However, once a \is{alternant!basic}basic alternant was posited, it quickly became apparent that surface \is{alternant}alternants and the ``base form'' do not necessarily align. ``[T]he base form in some instances is considerably rarer than its replacements. Indeed, in some instances the most conveniently recognised base form never actually occurs; under these conditions we call it a {\it theoretical base form}'' (\citealt[282]{Hockett:1958}). The upshot was that not only were  unique \is{underlying representation!unique}underlying representations posited, these representations could be different from any surface manifestation: in short, \is{underlying representation!abstractness}underlying representations could be abstract -- (\ref{morph-schemas-abstract-base}b) which has no phonetically occurring [W] corresponding to the abstract\is{abstractness!underlying representation}\is{underlying representation!abstractness} /W/ -- alongside the relatively concrete representations in (\ref{morph-schemas-abstract-base}a).\footnote{Note that our use of /W/ here differs from our use of /Z/ in (\ref{morph-schemas-1}) and the preceding discussion. Both are \is{underlying representation!abstract, definition}underlying representations corresponding to the surface forms [X], [Y], but /W/ is specifically restricted to be distinct from both [X] and [Y]. On the other hand, /Z/ above is unrestricted, referring to an underlying representation that matches one of the surface forms (either /X/ or /Y/), or to a representation which does not match any surface form (/W/).}

\begin{example} \et{Concrete and abstract ``base forms''} \label{morph-schemas-abstract-base}
\ea Concrete underlying form\\
    \begin{forest} for tree = {grow'=90}
    [,phantom
      [/X/\down{$\upalpha$}
         [{[X]}]
         [{[Y]}]
      ]
      [/Y/\down{$\upalpha$}
         [{[X]}]
         [{[Y]}]
      ]
    ]    
    \end{forest}
\ex Abstract underlying form (W {\it distinct from} X, Y)\\
   \begin{forest} for tree = {grow'=90}
    [/W/\down{$\upalpha$}
     [{[X]}]
     [{[Y]}]
    ]
    \end{forest}
\z
\end{example}
\is{theoretical base form|)}
\is{structuralism|)}
\is{abstractness!underlying representation}
\is{underlying representation!abstractness}



\subsection{But syntax doesn't need URs, abstract or not}
 
The groundwork for the ubiquitous ``underlying form'' was laid. \is{morpheme}Morphemes were  considered to pair a unique sound string with a particular meaning,\is{sound-meaning correspondence} even though multiple, nonunique sound strings actually occur in many, perhaps most, instances. In effect, the underlying form was a mechanism for asserting the irrelevance for syntax of such phonological alternations.\is{alternation} As a consequence, the {\it underlying phonological representation} was postulated as a core part of every \is{morpheme}morpheme, with morphemes constituting the building blocks for syntax. 

Viewed from the perspective of contemporary syntax, however, this role for underlying representations seems entirely unmotivated. Syntax and \is{morphology}morphology manipulate elements; depending on the theory of syntax and morphology, there are different views of what these elements are and how they are structured, but it is generally agreed that the relevant features are morphosyntactic,\is{feature!morphosyntactic} not phonological.  For instance, \is{Network Morphology}\is{morphology!Network Morphology}Network Morphology (\citealt{Corbett+:1993, Brown+:1996, Fraser+:1997, Brown+:2012}) holds that there is an independent grammatical module that creates words,\is{word} interfacing with syntax, \is{semantics}semantics, and phonology. In \is{Distributed Morphology}Distributed Morphology (\citealt{Halle+:1993, Harley+:1999, Embick+:2007, Siddiqi:2009, Matushansky+:2013}), the syntax operates on sets of morphosyntactic features\is{feature!morphosyntactic} which are \is{spell-out}spelled out into chunks\is{chunk} which may or may not correspond to units comparable to traditional \is{morpheme}morphemes. In both types of theories, the lexical and functional elements available for manipulation by the syntax and/or \is{morphology}morphology are strictly nonphonological, and it is these morphosyntactic features\is{feature!morphosyntactic} that are referred to in \is{spell-out}spell-out or word formation.\is{word} 
 
 In terms of the schemas in (\ref{morph-schemas-1}), the relevant unit for syntax is {\sc meaning-$\upalpha$}\is{meaning} where $\upalpha$\ is whatever syntactic properties are appropriate, information that is accessible whether we adopt the flat set structure of (\ref{morph-schemas-1}a) or the hierachical set with an underlying form as in (\ref{morph-schemas-1}b). Thus syntax has access to the features it needs, regardless of whether there is a unique underlying form or not. There is no argument from syntax to support the \is{underlying representation!unique}unique underlying form.
  \is{underlying representation!syntax|)}\is{syntax!underlying representation|)}
  
\section{Conclusion}

Neither \is{syntax}syntax nor phonology supports the concept of underlying representations, at least conceptually. Our conclusions agree with \citet[123]{Burzio:1996} about the concept of a unique phonological underlying representation:\is{underlying representation|)} It ``is neither conceptually necessary nor empirically supported, and should be dispensed with.'' While relations between surface morphs must be accounted for, we concur with Burzio that the null hypothesis consists of a more direct encoding of such relations, unmediated by abstract\is{abstractness!underlying representation} \is{underlying representation!abstractness}underlying representations (see also \citealt{vandeWeijer:2012}). We hypothesise {\it morph sets}\is{morph set!definition},\is{morph set} each morph set being a collection of occurring  morphs that share some syntactic or semantic label, whether or not there are productive,\is{productivity} derivable,\is{derivability} and/or optimising\is{optimisation} relations among those morphs.  

As a framework which does not mandate \is{underlying representation!unique}unique underlying representations, Emergence is a \is{surface-to-surface}surface-to-surface model. We develop a model where a morph set contains one or more surface-based representations.  However, morph sets\is{morph set!continuum} with multiple members are not all created equal. At the phonologically regular and general end of the scale, the phonological differences between members of a morph set are encoded by a Morph Set Relation\is{Morph Set Relation} and the productivity\is{productivity!Morph Set Condition} of the pattern is encoded by a Morph Set Condition.\is{Morph Set Condition} The relation between coronal stops and flaps in English\il{English|(} falls into this category; which variant is used in a given context is the domain of well-formedness conditions.\is{well-formedness condition} Phonologically regular but non-productive\is{non-productivity} patterns are characterised by a Morph Set Relation\is{Morph Set Relation} with no accompanying Morph Set Condition; this situation is found with \il{English}English morph-final voiceless/voiced pairs like \{nʌɪf, naɪv\}\down{\sc knife}  (but \{bɹi\ipa{ː}f\}\down{\sc brief}  not *\{bɹi\ipa{ː}f, bɹi\ipa{ː}v\}\down{\sc brief}, and \{weɪv\}\down{\sc wave}, not *\{weɪv, weɪf\}\down{\sc wave}) as well as with the Polish\il{Polish} stem-final CVC and CC alternation (see \Sec\ref{section_Polish}). In each case, the relation between morphs within the set can be characterised phonologically, and so can enhance acquisition\is{acquisition} and recognition, but the patterns are not productive. Note that a lack of productivity,\is{non-productivity} encoded as the absence of a Morph Set Condition\is{Morph Set Condition}, would not prevent a creative speaker from the sporadic generalisation of an unproductive Morph Set Relation. Finally, truly suppletive\is{suppletion} morph sets, such as English \{æm, ɪz, wʌz, wəɹ, bɪn\}\down{\sc be}, must simply be memorised,\is{memory!suppletion} with no generalisation\is{generalisation} to be found.\il{English|)} The consequence is that Emergence identifies a continuum between ``regular phonology'' and \is{suppletion}``suppletive allomorphy'' -- including phonologically regular but lexically \is{idiosyncrasy}idiosyncratic sets -- while maintaining \is{surface-to-surface}surface-oriented representations. The role of MSRs and MSCs is to express regularities among members of a morph set, answering, in part,  the charge to ``capture generalizations...[and] capture the speakers' knowledge'' (\citealt[221]{Hyman:2018}).

The remainder of the generalisations and knowledge is represented by the language's well-formedness conditions\is{well-formedness condition} which serve to select among possible morph compilations.\is{compilation} And, similar to morph set membership, well-formedness conditions range from fully phonological to highly morphological (and logically extend to \is{syntax!domain}syntactic domains\is{domain \dom} as well, though our examples do not include such data). \citet{Bermudez-Otero:2018} and \citet{Hyman:2018} raise a variety of issues for a framework which abandons \is{underlying representation}underlying representations in favour of surface morphs. The \is{surface-to-surface}surface-morph model considered in those works appears to have no mechanism for representing productive relations among morphs nor for selection among the multiple possibilities, that is, no counterpart to our network of MSRs,\is{Morph Set Relation} MSCs,\is{Morph Set Condition} and well-formedness conditions.\is{well-formedness condition} At issue therefore is which of the types of generalisations possible with \is{underlying representation}underlying-to-surface relations vs. \is{surface-to-surface}surface-to-surface relations more closely corresponds to what we observe in natural language.

\begin{dadpbox}{Construction Grammar}{box-CG}
\is{Construction Grammar}

The Construction Grammar model of phonology laid out in \citet{Valimaa-Blum:2011} is also a \is{surface-to-surface}surface-to-surface model. Fully systematic phonological patterns are characterised by listing the \textit{co-allophones}\is{allophone} of each \textit{phoneme}\is{phoneme} along with statements about their distribution. Morphophonological patterns are treated quite differently: \is{morphology!Construction Grammar}\is{Construction Grammar!morphology}morphemes are represented as sets of \textit{co-allomorphs},\is{alternant!Construction Grammar}\is{Construction Grammar!alternant} and certain \is{morphology!Construction Grammar}\is{Construction Grammar!morphology}morphological constructions select a morph with a particular sound property. There is nothing in the model to characterise phonological sub-regularities in terms of the sounds themselves. Thus, co-allomorphs like \{nʌɪf, naɪv\}\down{\sc knife} are on a par with co-allomorphs like \{æm, ɪz, wʌz, wəɹ, bɪn\}\down{\sc be}, despite the clear phonological relation between [f] and [v] and lack thereof with the {\sc be} morphs.
\end{dadpbox}

We turn in Chapter \ref{chapter_consequences} to a series of case studies which demonstrate that morph sets allow for concrete, straightforward analyses consistent with the Emergent hypothesis, rather than the kind of abstract analyses often required by frameworks positing single underlying representations.
