\chapter{Interview method}\label{ch.prod_method}

Chapter \ref{ch.var} has introduced the four variables that this book focuses on.
On the basis of previous work, it has also broadly divided them into a (comparatively) non-salient\is{salience} and a highly salient\is{salience}, even \isi{stereotype}d and stigmatise\is{stigmatisation}d group.
However, this distinction was largely based on experts' judgements and evaluations, and especially external \isi{stereotype}s may well ``become increasingly divorced from the forms which are actually used in speech'' \parencite[180]{labov1972}.
This part of the book will therefore try to corroborate the alleged \isi{salience} of the variables ``from the inside'', as it were, and also to go beyond the simple binary distinction of salient\is{salience}/non-salient\is{salience} by ordering our four variables more precisely in relation to each other on the social \isi{salience} scale.

	\section{Interview structure}\label{sec.prod_method.interview}
	
Production data for the four variables of interest were obtained in the form of ``classical'' sociolinguistic interviews.
All of these interviews were one-on-one and conducted by the author.
Being an outsider to the community entails a number of disadvantages with respect to naturalness of speech of the subjects.
However, this was true of all interviews in the same way, so it cannot be a factor influencing inter-group comparisons.
The interviews consisted of a free speech section where subjects were asked a number of questions about the area of the city they grew up in, changes in the city, football and other sports, Liverpool's \isi{image} in the UK and the rivalry with Manchester.\footnote{Although this rivalry has historical reasons (cf. Chapter \ref{ch.hist}), it is today dominated by the rivalry between the football clubs from Liverpool and Manchester in many people's minds. This does not, however, diminish its potential for bringing up questions of \isi{identity} and local pride in the slightest. Indeed, as \textcite[97]{beal2010} remarks, ``[t]he football derby (\dots) is one of the clearest manifestations of local \isi{identity} and rivalry in Britain today''}
Furthermore, subjects were questioned about their use (particularly with respect to themselves) and their understanding of a number of \isi{identity} labels.
See appendix \ref{app.questionnaire} for the complete questionnaire.
Not all questions were asked in all interviews, but all topics were discussed or at least touched upon with every participant, with most of the time typically devoted to the areas ``children's lore'', ``attachment to Liverpool'', ``\isi{identity}'', and ``Liverpool's \isi{image}''.

Towards the end of the interview, participants read out a reading passage (see appendix \ref{app.reading}) and a list of keywords (appendix \ref{app.list}).
Most of the test words on the list were also contained in the reading passage for better comparability.
Next, subjects were asked to read out the reading passage a second time using their strongest Scouse accent. Not all interviewees wanted to do this or explained they weren't capable of ``putting it on'' on demand, but the vast majority of participants completed all three reading tasks.
In graphs showing register differences, the data gathered during the accent imitation\is{accent performance} task will be situated towards the informal end of the style spectrum.
I am aware of the fact that the imitation\is{accent performance} style is almost certainly one where subjects are likely to pay \emph{more} than average \isi{attention} to their speech.
A reviewer quite correctly points out that accent perform\is{accent performance}ance probably qualifies as a \enquote{frozen, ritualistic} style \parencite{labov1972} that, in terms of \isi{attention}, should rather be placed towards the more formal end of the style continuum.
However, this task should still -- for obvious reasons -- trigger the most \enquote*{extreme} and/or most frequent local variants, even when compared to spontaneous speech, so in that sense I would argue it is quite different from, say, a sermon or some other form of scripted public speech.
A linear increase of local variants can be expected from word list through reading and free speech style to accent imitation\is{accent performance}, so it seems to me the placement of the latter towards the \enquote*{informal} end of the style spectrum is justified in that respect.
Purely for reasons of convenience, accent imitation\is{accent performance} will occasionally be referred to as the \enquote*{most informal} speech style, simply because it should be the most \enquote*{vernacular} register, \emph{not} because I believe subjects paid no \isi{attention} to their speech.

Finally, subjects were asked a number of questions concerning Scouse, notably whether they thought the accent had changed in their life time and what features they considered most typical.
Analysis of these statements can only be qualitative in nature and should be considered an impressionistic snapshot rather than anything close to a representative picture of the relevant groups' explicit linguistic knowledge. Usually, the interviews lasted between 50 and 60 minutes (40--45 minutes of free speech and 10--15 minutes of reading/accent imitation\is{accent performance} and metalinguistic comments\is{overt commentary}).
Testing took place in a number of locations: pubs and cafés in central Liverpool, cafeterias at Hope University and the University of Liverpool, people's offices and homes.
Not all of these environments were equally quiet, but recording quality was at least acceptable in all cases. All interviews were recorded using a Roland Edirol R-09HR MP3/Wave recorder, and named according to the following pattern:

\begin{enumerate}
	\item a two digit participant/interview number
	\item ``F'' or ``M'' to code the participant's gender
	\item ``MC'' or ``WC'' to code the participant's social class
	\item two digits coding the participant's age in years at recording time
\end{enumerate}

``02MWC20'', for example, is the code for interview number 2 with a male, working-class subject, who was 20 years old at the time of the interview.
These codes will occasionally be used in this study to refer to specific interviews or to attribute quotations to their sources.

	\section{Participants}\label{sec.prod_method.participants}
	
Participants were recruited through a number of ways. Notes in pubs, cafés, football grounds, community centres, and churches were complemented by e-mail calls for participants through Hope University and the University of Liverpool mailing lists, word-of-mouth advertising and by approaching people in person (mostly students at Liverpool Hope University). Interviews were conducted during two field trips, in September/October 2012 and April/May 2013, respectively. The first 8 subjects participated for free, the remaining ones were offered £10 for their time (some declined). No selection of participants in terms of ``typicality'' or ``strength of accent'' was made (as opposed to, for example, the ``new NORMs'' in \citealt{honeybone2001}).

A total of 38 subjects were interviewed.
All participants were born and/or had grown up in the Liverpool Urban Area since age 12 or younger.
Several subjects had also lived in other cities or towns at one point or another of their life, the reason usually being either job or (university) education related.
Most interviewees, however, had spent all their life in Liverpool and its suburbs.
Both men and women were interviewed and a rough socio-economic distinction into working class or middle class was made.
English was the first (and, with the exception of one participant who was later excluded, also the only) language for all subjects.
All participants were White British.
The age range was 19--85, with people being classified as belonging to one of three age groups (19--29, 30--55, and 56--85) to mirror social, economic, and cultural \isi{change} in Liverpool.
With the boundaries set as they are the formative years (roughly up to and including the 20s) of most of the participants in the respective group fall together with one of the three phases of the city's development in the latter half of the 20\textsuperscript{th} century (cf. \sectref{sec.hist.20} and \sectref{sec.hist.21}): 50s and 60s (post-war recovery and Merseybeat era) for the oldest, 70s and 80s (economic depression) for the middle-aged, and 90s and 2000s (regeneration) for the youngest speakers.
For reasons of time and space, only 20 interviews could be included in the present study.
Interviews entered this sub-sample in the order they had been conducted in until all cells (cf. \tabref{tab.participants}) were represented by 2 informants (1 in the case of the oldest group).
These subjects form what I will call the ``primary sample'' for the production part of this study.
In total, they contributed almost 19 hours of recorded material.
The secondary sample (including all 38 interviews) is the basis for some results in Chapter \ref{prod.res.qual}, but other than that all production analyses are exclusively based on the smaller primary sample.
\tabref{tab.participants} shows how participants in this primary sample are distributed across the categories outlined above.

	\begin{table}
		
		\caption{Age, gender, and social class of subjects (production)}
		\label{tab.participants}
		\begin{tabular}{lcccccc}
			\lsptoprule
			& \multicolumn{2}{c}{19--29} & \multicolumn{2}{c}{30--55} & \multicolumn{2}{c}{56--85}\\
			& F & M & F & M & F & M\\
			\midrule
			WC & 2 & 2 & 2 & 2 & 1 & 1\\
			MC & 2 & 2 & 2 & 2 & 1 & 1\\
			\lspbottomrule
		\end{tabular}
	\end{table}

\figref{fig.map.participants} -- generated with the QGIS software \parencite{QGIS2016}\footnote{Map tiles by Stamen Design, under CC BY 3.0. Data by OpenStreetMap, under CC BY SA. Shapefiles from CDRC 2015 OS Geodata Pack by the ESRC Consumer Data Research Centre; contains Ordnance Survey data © Crown copyright and database right 2015.} -- illustrates which part of the city/conurbation the subjects are from or, to be precise, where they currently live. As is clear from the map, most areas of the city are represented although, to be fair, some (suburban) northern parts of Liverpool are underrepresented. There is also a slight bias towards the area around Liverpool districts Aigburth, Mossley Hill and Allerton in the south end of the city (12 subjects in total are from one of these three areas). Note, however, that all age groups are more or less evenly spread across the city.

	\begin{figure}
		
 		\includegraphics[width=0.8\textwidth]{figures/liverpool-participant-map.png}
		\caption{Geographical distribution of interview subjects}\label{fig.map.participants}
	\end{figure}

The study was not restricted to people from within the Liverpool Council boundaries (black line in the map), but also included areas which are administered by other local councils (Sefton, Knowsley, \isi{Wirral}) and which are, therefore, ``technically not Liverpool'' as a number of subjects put it. This is indeed, however, more of a technicality since we are talking about a contiguously built up area -- just like in most other urban agglomerations. It is clear that invisible lines (sometimes separating one side of a street from the other) can still be important for people's \isi{identity}, but all of the participants in this study self-identified as Liverpudlian\is{identity}s or Scouser\is{identity}s. This also held for the two subjects who were actually living on the \isi{Wirral} and who had both been born in Liverpool (and in one case also lived half her life within Liverpool city boundaries). Generally speaking, people in urban areas often move around quite a bit and this might be especially true for Liverpool where many people from inner city areas were actually relocated (sometimes very reluctantly so) to new housing estates on the outskirts of the city during the slum clearances of the 50s and 60s. This is indeed what many of the older participants experienced themselves. For these reasons it was deemed unjustified to restrict the pool of subjects to those living within Liverpool city boundaries only.

	\section{Transcription}\label{sec.prod_method.transcription}

All interviews were transcribed orthographically in Praat \parencite{praat} by the author.
Since the transcriptions' sole purpose was to serve as input for automatic measuring (cf. \sectref{sec.prod_method.measuring}), pauses, \isi{intonation}, stress, etc. were not marked in the transcripts.
Questions and other utterances by the interviewer were  {also } ignored.
On separate tiers of the Praat TextGrid, speaking style (word ``list'', ``reading'' (passage), ``free'' (speech), and (accent) ``imitation\is{accent performance}'') and topic (``childhood'', ``Manchester'', ``\isi{identity}'' etc.) coded, followed by a third one where the participant's speech was segmented into chunks and transcribed.
Words containing test tokens and the individual variables themselves were marked on individual tiers called ``word'' and ``variable'' respectively.
Finally, a sixth tier called ``aspiration'' was used to mark relevant parts of the consonantal variables (cf. \sectref{sec.prod_method.con}).
\figref{fig.textgrid.ex} provides an extract from a TextGrid (zoomed to word level) for purposes of illustration.

	\begin{figure}
		
			
			\includegraphics[width=0.75\textwidth]{figures/TextGrid_screenshot}
		\caption{Extract of Praat TextGrid (subject 30FMC44)}
		\label{fig.textgrid.ex}
	\end{figure}

	\section{Measuring}\label{sec.prod_method.measuring}

		\subsection{Consonants}\label{sec.prod_method.con}

The two consonantal variables were analysed both acoustically and auditorily.
The method for acoustic measuring of /k/ was heavily inspired by the one used in \citealt{sangster2001} to investigate lenition of alveolar stops. Phonetic plosives have a period of silence, or closure, followed by a burst and friction. For affricates, there is the same silence, but more friction than for plosives, and fricatives have either a very short period of silence or none at all and consist (almost) entirely of friction. 

Beginning and end of the friction phase were marked in a Praat TextGrid for every /k/. 
A script written by the author was then used to automatically measure the duration of these segments as well as the total durations of the plosives (i.e. including the closure phase).
/k/ tokens without any friction phase were registered as ``unreleased'' (and ignored in the analysis).
Next, what \citeauthor{sangster2001} calls ``the proportional duration of friction'' (\isi{PDF}) was calculated by dividing the duration of the friction phase by the total duration of the plosive. The result is a figure between 0 (or 0\%) and 1 (100\%), with lower values for more plosive-like realisations and higher values for sounds that are phonetically speaking affricates or fricatives.

The same technique was applied to /ŋ(ɡ)/.
This decision might seem strange at first, because the realisational options of /ŋ(ɡ)/ do not seem to be readily comparable to those of /k/.
Closer examination, however, reveals that the standard realisation as a nasal [ŋ] involves complete oral closure -- just as with [k] -- and that for the typical Scouse realisation as [ŋɡ] this closure phase is followed by a release burst / friction.
While the friction of [ŋɡ] will never be as long as that of a /k/ realised as a fricative, the \isi{PDF} values will mean the same thing for velar nasal plus as they do for /k/: lower values (no or little friction \(\rightarrow\) [ŋ]) indicate a standard-like realisation and higher scores (presence of friction \(\rightarrow\) [ŋɡ]) mark non-standard, Scouse variants.
Alveolar variants of /ŋ(ɡ)/ were coded as ``in'' and later removed for the quantitative analyses for two reasons.
First, [n] is a non-standard variant that is not limited to Liverpool or even a clearly bounded region, but one that is used in all varieties of English English and many others as well.
It is also rather salient\is{salience} and commented on\is{overt commentary} by many non-linguists as \enquote*{g-dropping}.
However, in order to assess the impact of \isi{salience}, particularly in perception, this study required a local/regional feature with little or no \isi{salience}, to compare to the highly salient\is{salience} and local /k/ lenition.
Alveolar variants of the <ng> cluster fulfil neither criterion, while [ŋɡ] realisations tick both boxes.
The second reason concerns the method of measurement.
Realising <ng> as [n] by definition excludes the presence of even a hint of a plosive, so the \isi{PDF} measurement outlined above is not applicable.
The difference between [ŋ] and [ŋɡ] (or the devoiced\is{devoicing} variant [ŋk]), on the other hand, exhibits the same kind of gradualness and, as explained above, can be measured in the same way as /k/ lenition.
This parallelism is again crucial for the perception experiment, because it means the stimuli for /k/ and /ŋ(ɡ)/ could be manipulated in a way that was phonetically similar (and thus not a confound).
Since linking up data from production and perception is a major interest of this study, the focus in the production part was also exclusively on the [ŋ]-[ŋɡ] distinction.
\figref{fig.automatic.consonants} shows two examples and their respective marking in the TextGrid.

	\begin{figure}
		
		\begin{subfigure}{0.75\textwidth}
			
			\includegraphics[width=\textwidth]{figures/like_plosive}
			\caption{plosive, PDF = 18.47\% (03MMC33)}
		\end{subfigure}
		\begin{subfigure}{0.75\textwidth}
			
			\includegraphics[width=\textwidth]{figures/like_fricative}
			\caption{fricative, PDF = 81.84\% (36FWC20)}
		\end{subfigure}
		\caption{Spectrograms of /k/ (zoomed to word level)}
		\label{fig.automatic.consonants}
	\end{figure}

	\newpage 
This very precise method of acoustically measuring /k/ and velar nasal plus requires high quality recordings with little to no background noise.
As it was unclear at the beginning whether all interviews fulfilled these criteria, the data were also analysed auditorily by the author. 
Coding was `0' (plosive), `1' (affricate), and `2' (fricative) for /k/, and `0' (nasal) and `1' (nasal plus burst) for /ŋ(ɡ)/.
It turned out that all interviews included in this project actually did permit an analysis based on the more precise \citeauthor{sangster2001} method, so the auditory coding was not used in the analysis in the end.
It is, however, still accessible for future research.

		\subsection{Vowels}\label{sec.prod_method.vow}
		
For the measurement of the first two (later three) vowel formants (\textsc{nurse}, \textsc{square}, and \textsc{happy}) a Praat script\footnote{Generously made available by Mietta Lennes -- \url{http://www.helsinki.fi/~lennes/praat-scripts/}, last accessed 2013-01-29 -- and modified by the author.} was used to automatise data collection.
\textsc{nurse} and \textsc{square} were measured first by hand and then in an automated way by the script for the first three (male) subjects.
Paired t-tests were then administered to make sure the automated measurements were reliable. Neither test ([t(545) = -0.975, p = 0.330] for F1 and [t(545) = 1.768, p = 0.078] for F2) found a significant difference between hand and automated measurements, although there was a trend for the F2 values.
However, the mean difference between hand and automated measurements for F2 was a mere 2.15 Hz.
Scatterplots furthermore show a near-perfect correlation of hand and automated measurements, which is why the script was deemed reliable and all formant measurements used in the final analysis were taken automatically only.
Clear mismeasurements were later removed from the dataset.

		\begin{figure}
			
				\begin{subfigure}[b]{0.45\textwidth}
					
					\includegraphics[width=\textwidth]{figures/F1F1AUTO}
					\caption{F1 measurements}
				\end{subfigure}
				\begin{subfigure}[b]{0.45\textwidth}
					
					\includegraphics[width=\textwidth]{figures/F2F2AUTO}
					\caption{F2 measurements}
				\end{subfigure}
			\caption[Manual vs. automatic measurements (\textsc{nurse} and \textsc{square})]{Manual (x-axis) vs. automatic (y-axis) measurements of \textsc{nurse} and \textsc{square}}\label{fig.automatic.measurements}
		\end{figure}

The script took as input pairs of sound files and TextGrids.
It then went through each TextGrid and looked for vowel labels in the variable tier.
When it found a relevant label it noted the start and end of the segment and measured F1, F2, and F3 at midpoint of the vowel.
It then extracted information about the style, topic, carrier word, and the larger context it appeared in from the other tiers and saved all these data into a textfile.
F3 was measured because it was needed for one of the \isi{normalisation} algorithms that were later applied to the raw measurements (cf. \sectref{sec.prod_method.norm}).
In addition to the three vocalic test variables happ\textsc{y}, \textsc{nurse}, and \textsc{square} (of which all instances were included), between 10 and 25 tokens of \textsc{fleece} and \textsc{trap} per subject were also measured.
These were taken from the reading passage and word list sections of the interviews since these contexts were considered most likely to produce the most ``extreme'' realisations (in terms of the periphery of speakers' vowel spaces).
Observations of \textsc{trap} were used exclusively as input for \isi{normalisation} and for comparison of the algorithms (again, cf. \sectref{sec.prod_method.norm}).
\textsc{fleece} measurements were additionally included in the calculation of \isi{Pillai} scores for happ\textsc{y} (cf. \sectref{sec.prod.res.vow.happy.pil}).

\subsection{Normalisation}\label{sec.prod_method.norm}

It is a well known fact among phoneticians and phonologists that there is a huge amount of variation in the acoustic signal that is not due to linguistic or sociolingustic, but rather purely physiological reasons.
Even multiple realisations of one and the same phonological sound chain produced by a single speaker in the same style will all be slightly different from one another.
In addition to these intra-speaker differences, there are also inter-speaker ones.
The most pronounced differences in this area are due to vocal tract length.
The length of the vocal tract correlates inversely with vowel formant values.
On average, therefore, children (with the shortest vocal tracts) have higher formants than women, who in turn have higher formants than men for one and the same phonological vowel.
The potential effect of vocal tract maturation, i.e. changes to length and shape of the vocal tract over the course of an individuals lifetime, further complicates matters \parencite[cf.][440--441]{harrington2006}.

It is therefore not possible (or at least not advisable) to directly compare, for instance, women's and men's raw formant values, or those of younger and older speakers.
This is where \isi{normalisation} comes in.
According to several articles on the matter \parencite[cf., for example,][]{fabriciusetal2009,clopper2009,disner1980,kendallthomas2014,thomas2002}, \isi{normalisation} should ideally achieve four different goals:
\begin{enumerate}
	\item \label{enum.norm.phys}elimination of differences that are due to physiological reasons
	\item \label{enum.norm.soc}preservation of differences that are (socio-)linguistic in nature
	\item \label{enum.norm.phon}preservation (or improvement) of phoneme distinctions
	\item \label{enum.norm.cog}modelling the process that allows listeners to assign realisations from different speakers to one and the same phoneme
\end{enumerate}
The author is well aware of the irony involved here.
This study is, after all, set in an \isi{exemplar} framework which suggests that listeners do \emph{not} normalise\is{normalisation} acoustic input, at least not in the same way and to the same degree as is assumed in most other phonological theories.
This is most relevant with respect to point \ref{enum.norm.cog} in the enumeration above. Sociolinguists, however, usually largely ignore this aspect and focus more on points \ref{enum.norm.phys} and \ref{enum.norm.soc} \parencites(cf.)()[1430]{clopper2009}[414--415]{fabriciusetal2009}{kendallthomas2014}, and the present study is no exception.
By applying a \isi{normalisation} algorithm to the data I do not mean to suggest that this procedure mirrors or approximates what happens in listeners' brains.
Rather, it is simply the only option one has if the goal is to compare production data of men and women (or those of younger and older speakers) to each other instead of treating them separately.

Normalisation methods are generally categorised with respect to two dimensions: vowel-intrinsic vs. vowel-extrinsic and speaker-intrinsic vs. speaker-ex\-trin\-sic \parencite[cf.][]{kendallthomas2014}.
Vowel-intrinsic algorithms extract all data necessary for \isi{normalisation} from the individual token.
Often these methods use F0 and/or F3 to estimate vocal tract length.
Vowel-extrinsic algorithms include formant measurements from more than one vowel in their formulas and achieve \isi{normalisation} with the help of means over several (often all) measured vowels.
Speaker-intrinsic methods differ from speaker-extrinsic ones in that the former perform \isi{normalisation} for each speaker individually (i.e. only taking into account vowels produced by that speaker), whereas the latter include some sort of inter-speaker mean in their calculations (cf., for example, \citegen{labovetal2006} \emph{grand mean}).

A number of algorithms have been proposed over the years, and the question which of those fares best in achieving the goals spelled out above has generated a series of investigations \parencites(among others:)(){hindle1978}{disner1980}{adanketal2004}.
Generally speaking, ``vowel-extrinsic methods tend to perform better overall (\ldots) for vowel space normalization across talkers'', and ``vowel-intrinsic methods are appealing as perceptually plausible models of human speech processing'' \parencite[1440]{clopper2009}.
For this reason, two different \isi{normalisation} methods were tested in this study, a vowel-intrinsic and a vowel-extrinsic one (both of them speaker-intrinsic).
Both \isi{normalisation}s were applied to the raw data using the NORM package for R \parencite{kendallthomas2014}.
The first, Bark difference, was devised by \textcite{syrdalgopal1986}, and is a vowel-intrinsic method.
Formants are, first of all, transformed into -- perceptually ``more accurate'' \parencite[1431--1432]{clopper2009} -- Bark values using the formula taken from \textcite{traunmueller1990}:

\begin{equation}
	Z_{i} = \frac{26.81}{1 + \frac{1960}{F_{i}}} - 0.53
\end{equation}

Where \(F_{i}\) is the raw value of a given formant. The Bark rescaled values \(Z_{1}\) and \(Z_{2}\) are then substracted from \(Z_{3}\) to arrive at normalise\is{normalisation}d measures of height and frontness respectively. \citeauthor{syrdalgopal1986} originally used Bark-converted F0 instead of F3 for the height dimension, but \textcite{kendallthomas2014} argue that a number of things, for instance ``[i]ntonation, tone, and consonantal influences affect F0'' and consider it preferable to use Bark-converted F3 for both the back-front and the high-low dimension.

The most popular vowel-extrinsic \isi{normalisation} method among sociolinguists is probably \textcite{lobanov1971}.
This is unsurprising given the fact that it has frequently been found to be (one of) the most efficient algorithm(s) in reducing physiological and preserving sociolinguistic variation \parencite[cf.][1440]{clopper2009}.
The main drawback of \citeauthor{lobanov1971} -- and many other vowel-extrinsic algorithms -- is that it works best when \emph{all} vowels of a system are measured.
Constraints of time and resources made this endeavour impractical for the present study.
The choice fell on \textcite{wattfabricius2002} in its modified version \parencite{fabriciusetal2009} instead, a method which is ``conceptually similar'' and deemed ``also successful'' \parencite[1440]{clopper2009}.

\textcite{wattfabricius2002} assume a triangular vowel space with the corner vowels \([i]\), \([a]\), and \([u']\).
In RP (for which the algorithm was originally designed), these would correspond to \textsc{fleece}, \textsc{trap}, and \textsc{goose}, but
the NORM package automatically chooses the highest/most fronted and the most open vowel available in the sample as \([i]\) and \([a]\), irrespective of their labels.
Obviously, \([i]\) and \([a]\) should be relatively stable in the variety under scrutiny \parencite[cf.][163]{wattfabricius2002}.
Since I am not aware of any evidence that suggests this is \emph{not} true for \textsc{fleece} and \textsc{trap} in Scouse, these two were used as corners in this study.
From these benchmark vowels, a centroid S or ``centre of gravity'' \parencite[164]{wattfabricius2002} is then computed as follows:
\begin{equation}
	S(F_{n}) = \frac{[i]F_{n} + [a]F_{n} + [u']F_{n}}{3}
\end{equation}
Where \(F_{n}\) is a mean raw formant value of the corner vowels \([i]\), \([a]\), and \([u']\). The centroid value \(S(F_{n})\) is computed separately for each formant, and normalise\is{normalisation}d values are then expressed as the ratio of the raw measurement to the corresponding centroid: \(\frac{F_{n}}{S(F_{n})}\).
Note that \([u']\) is not measured, but derived from \([i]\), assuming that \([u']F_{1}\) = \([u']F_{2}\) = \([i]F_{1}\).
As a result, only \textsc{fleece} and \textsc{trap} have to be measured.
To counter potential skewing due to the fact that \textsc{trap} might not be exactly halfway between \textsc{fleece} and \textsc{goose} with respect to frontness, \([a]F_{2}\) is also derived instead of measured in the modified version of the algorithm employed in this study \parencites(cf.)()[420--421]{fabriciusetal2009}{kendallthomas2014}.

				\begin{figure}
					
					\begin{subfigure}{.49\textwidth}
						
						\resizebox{\linewidth}{!}{\input{figures/plot.scatter.raw.tex}}
						\caption{raw data}
						\label{fig.plot.scatter.raw}
					\end{subfigure}
					
					\begin{subfigure}{.49\textwidth}
						
						\resizebox{\linewidth}{!}{\input{figures/plot.scatter.bark.tex}}
						\caption{Bark difference normalised}
						\label{fig.plot.scatter.bark}
					\end{subfigure}
					\begin{subfigure}{.49\textwidth}
						
						\resizebox{\linewidth}{!}{\input{figures/plot.scatter.watt.tex}}
						\caption{Watt-Fabricius normalised}
						\label{fig.plot.scatter.watt}
					\end{subfigure}
					
					\caption{Vowel distributions (all subjects pooled)}
					\label{fig.normcomp}
				\end{figure}

With respect to the tests applied to assess the power of the \isi{normalisation} algorithms, this study largely follows \citealt{langstrofdiss}.
One criterion for determining whether a \isi{normalisation} process was successful is the degree to which it has reduced variance \emph{within} categories and overlap \emph{across} categories.
In our case this would mean that phonemes should be more distinct\is{distinctness} and that scatter around phoneme means should be reduced in the normalise\is{normalisation}d data.
When we look at \figref{fig.plot.scatter.bark} this is not immediately obvious.
It should be borne in mind that with respect to \textsc{nurse} and \textsc{square} we are talking about a merger for most speakers so we would not necessarily expect these two phonemes to appear more distinct\is{distinctness} in normalise\is{normalisation}d data.
The third vowel under scrutiny here, happ\textsc{y}, however, should be more distant from both \textsc{nurse} and \textsc{square} in the normalise\is{normalisation}d data.
At least for the Bark-difference method, the graph does not suggest that it really is.

It does not look as if scatter for any of the variables had been reduced either.
If anything, scatter around the mean seems to have increased, particularly in the front-back dimension.
The scatter plot for the \citeauthor{wattfabricius2002} normalise\is{normalisation}d data looks a lot more promising.
Scatter in both dimensions seems to have been (slightly) reduced, and the phonemes appear to be more distinct\is{distinctness}.
But then again, we are using different scales in the three representations so a purely visual inspection is insufficient.
We will thus have a look at variation coefficients next.
I am well aware of the fact that the measure of dispersion most commonly used in such cases is the standard deviation. Since we have very different means in our samples due to different scales, however, comparing standard deviations would be highly misleading as they depend on the means of the samples. We will therefore use variation coefficients which normalise\is{normalisation} standard deviations by dividing them by the mean of the sample. These variation coefficients can then be meaningfully compared to each other.

\begin{table}
	
	\caption{Variation coefficients for raw and normalised data}
	\begin{tabular}{lllllll}
		\lsptoprule
		& \multicolumn{3}{c}{F1} & \multicolumn{3}{c}{F2}\\
		vowel & raw & Bark & Watt & raw & Bark & Watt\\
		\midrule
		happ\textsc{y} &
		0.187 & 0.107 & 0.167 &
		0.120 & 0.506 & 0.089\\
		\textsc{nurse} &
		0.127 & 0.101 & 0.115 &
		0.139 & 0.356 & 0.104\\
		\textsc{square} &
		0.123 & 0.101 & 0.115 &
		0.123 & 0.363 & 0.084\\
		\lspbottomrule
	\end{tabular}
	\label{tab.varcoeff}
\end{table}

\tabref{tab.varcoeff} shows a rather mixed picture. While the Bark difference algorithm was successful in reducing variance in the F1 dimension for all three vowels, it actually \emph{increased} variance of F2 considerably for all vowels involved. We thus cannot clearly claim that the Bark difference \isi{normalisation} reduced within-vowel variance overall.
\citeauthor{wattfabricius2002} fares a lot better.
Reduction in variance for F1 is systematic, if only marginal and slightly less successful than Bark-difference.
When we look at F2, however, we see a clear improvement.
Again, the reduction in variance is not huge, but \citeauthor{wattfabricius2002} does reduce variance systematically across all three vowels, whereas Bark-difference actually \emph{in}creases variance dramatically.
On the whole, then, \citeauthor{wattfabricius2002} seems to do a better job than Bark-difference in reducing intra-category variance.

Next, we look at \isi{Pillai} scores as a measure of distance between distributions, in our case of vowel discreteness.
\isi{Pillai} scores were first used in a linguistic study by \textcite{hayetal2006b} and their usefulness for sociolinguistic investigations is discussed in \citealt{halllew2010}.
They are considered to be superior to simple Euclidean distance measures because a \isi{Pillai} score ``takes account of the degree of overlap of the entire distribution'' \parencite[467]{hayetal2006b}.
\isi{Pillai} scores range between 0 and 1, with values close to 0 (and an accompanying high p-value) indicating a large degree of overlap between the distributions, and values near 1 (and a low p-value) representing distributions that are (almost) completely distinct\is{distinctness}.
The pairing \textsc{nurse-square} is not represented in \tabref{tab.pillai} as these two vowels participate in a merger for most speakers and it can therefore not be assumed that they \emph{should} be distinct\is{distinctness} in the first place.

\begin{table}
	
	\caption{Pillai scores for total and female/male vowel distributions}
	\begin{tabular}{lllllll}
		\lsptoprule
		& \multicolumn{2}{c}{raw} & \multicolumn{2}{c}{Bark} & \multicolumn{2}{c}{Watt}\\
		vowel(s) & \isi{Pillai} & p-value & \isi{Pillai} & p-value & \isi{Pillai} & p-value\\
		\midrule
		happ\textsc{y}-\textsc{nurse} &
		0.486 &
		< 0.001 &
		0.460 &
		< 0.001 &
		0.550 &
		< 0.001\\
		happ\textsc{y}-\textsc{square} &
		0.372 &
		< 0.001 &
		0.323 &
		< 0.001 &
		0.425 &
		< 0.001 \\
		happ\textsc{y} (female/male) &
		0.446 &
		< 0.001 &
		0.090 &
		< 0.001 &
		0.020 &
		< 0.001 \\
		\textsc{nurse} (female/male) &
		0.570 &
		< 0.001 &
		0.229 &
		< 0.001 &
		0.131 &
		< 0.001 \\
		\textsc{square} (female/male) &
		0.659 &
		< 0.001 &
		0.185 &
		< 0.001 &
		0.115 &
		< 0.001 \\
		\lspbottomrule
	\end{tabular}
	\label{tab.pillai}
\end{table}

\newpage 
\tabref{tab.pillai} confirms the impression we already got from \figref{fig.normcomp}: the Bark difference \isi{normalisation} does not distinguish happ\textsc{y} from both \textsc{nurse} and \textsc{square} better.
We also see, however, that it does not really fare worse.
\isi{Pillai} scores for raw and normalise\is{normalisation}d data are very similar and p-values are close to 0 in both cases.
So while the Bark difference \isi{normalisation} did not make different phonemes appear more distinct\is{distinctness}, it did at least not result in significantly \emph{less} distinct\is{distinctness} categories either.
\citeauthor{wattfabricius2002}, on the other hand, increases the distinct\is{distinctness}ness of happ\textsc{y} to both \textsc{nurse} and \textsc{square}.
Only slightly so for the former, it has to be said, but quite clearly for the latter.
As is obvious from the table, p-values are extremely low for all pairings (often too small to be treated as different from zero by the R software), which is in all likelihood simply due to the fact that they are based on comparatively large datasets where even small differences will show up as (highly) significant.
When we look at the three vowels individually and compare female to male realisations, we see a clear ``improvement'' in the normalise\is{normalisation}d data.
For all three vowels, female and male realisations are quite distinct\is{distinctness} in the raw data, a fact which is reflected in \isi{Pillai} scores which are comparable or actually higher than those for different phonemes, and p-values that indicate highly significant differences. 

\largerpage[-1]
All \isi{Pillai} scores for the Bark difference normalise\is{normalisation}d data are lower than their counterparts calculated for the raw data.
Intra-category overlap has increased by 0.356 for happ\textsc{y}, 0.34 for \textsc{nurse}, and 0.474 for \textsc{square}.
This means that female vowels are more similar to male vowels in the normalise\is{normalisation}d data, which is precisely what we would expect a vowel \isi{normalisation} process to achieve.
Female and male distributions are still significantly different from each other in the normalise\is{normalisation}d data, but,
\begin{inparaenum}[(a)]
	\item again, this could simply be due to the fact that we have a comparatively large data set where even small differences will come out as significant (cf. the very low \isi{Pillai} score of 0.09 for happ\textsc{y}), and, more importantly,
	\item we do not want \emph{all} differences to be filtered out, but only the \emph{physiological} ones.
\end{inparaenum}

All three vowels are test vowels in this study and we expect to see at least some gender differences which are due to sociolinguistic rather than physiological reasons.
This is particularly true for the \textsc{nurse-square} merger, a sociolinguistic variable which is considered to be highly salient\is{salience} (cf. Chapter \ref{ch.var}) and with respect to which we would therefore not be surprised to see women and men behave differently.
happ\textsc{y}, on the other hand, is believed to be non-salient\is{salience} (again, cf. Chapter \ref{ch.var}), so gender differences are less likely here.
This is exactly what the figures in \tabref{tab.pillai} suggest: a very low \isi{Pillai} score for happ\textsc{y}, indicating almost complete overlap of the distributions (although this small difference is still significant) and considerably larger ones for \textsc{nurse} and \textsc{square}, meaning that women and men differ in their realisations of these vowels even \emph{after} \isi{normalisation}.
It thus appears as if the Bark difference \isi{normalisation} had (largely) eliminated physiological variation but maintained sociolinguistic one, which is just what we want a useful \isi{normalisation} procedure to do.

The values for our other candidate, however, are even better.
\citeauthor{wattfabricius2002} increases intra-category overlap for happ\textsc{y} by 0.426, for \textsc{nurse} by 0.439, and for \textsc{square} by 0.545.
The remaining differences between female/male distributions are also less (though still highly) significant in the \citeauthor{wattfabricius2002} normalise\is{normalisation}d data.
It is possible that \citeauthor{wattfabricius2002} has in fact eliminated some information that we are interested in, namely the assumed sociolinguistic gender difference for \textsc{nurse} and \textsc{square}.
However, the figures show that although the gender distributions are less distinct\is{distinctness} than in the Bark-difference normalise\is{normalisation}d data, they are still (and by a much larger factor than in the Bark values) more distinct\is{distinctness} than the normalise\is{normalisation}d female/male distributions of happ\textsc{y}.
Also, it could very well be that the smaller differences we find for \textsc{nurse} and \textsc{square} in the \citeauthor{wattfabricius2002} normalise\is{normalisation}d data are simply the more realistic ones.
Both algorithms thus create a pronounced relative difference between the female/male \isi{Pillai} scores of happ\textsc{y} and those of \textsc{nurse} and \textsc{square}, but in addition \citeauthor{wattfabricius2002} decreases inter-phoneme overlap more, so the conclusion with respect to \isi{Pillai} scores is again that \citeauthor{wattfabricius2002} seems to be the preferable choice.

Euclidean distance measures can also be used to determine the usefulness of \isi{normalisation} procedures. Once again, we cannot directly compare euclidean distances because of different scales. What we can do, however is look at a ratio that is calculated as follows:

\begin{equation}
	\frac{d_{k}}{d_{l}} = \frac{\langle\sqrt{(F_{1i} - \bar{F_{1j}})^2 + (F_{2i} - \bar{F_{2j}})^2}\rangle}
	{\langle\sqrt{(F_{1i} - \bar{F_{1i}})^2 + (F_{2i} - \bar{F_{2i}})^2}\rangle}
\end{equation}

Where \(F_{1i}\) and \(F_{2i}\) are the F1 and F2 values of tokens in phoneme category ``i'', \(\bar{F_{1i}}\) and \(\bar{F_{2i}}\) are the mean values of category ``i'', and \(\bar{F_{1j}}\) and \(\bar{F_{2j}}\) are the mean values of category ``j''. \(d_{k}\) is then the average distance of tokens in category ``i'' to the mean of category ``j'' (e.g. happ\textsc{y} tokens to the mean of \textsc{nurse}), and \(d_{l}\) is the average distance of tokens in category ``i'' to their own mean (e.g. happ\textsc{y} tokens to the mean of happ\textsc{y}). This ratio should always be greater than 1, i.e. the average distance to the mean of \emph{another} category should be bigger than the average distance to the mean \emph{within} the category. A successful \isi{normalisation} procedure would have to increase this ratio since both intra-category spread and inter-category overlap should be diminished.

\begin{table}
	
	\caption{Euclidean distance ratios for raw and normalised data}
	\begin{tabular}{llll}
		\lsptoprule
		vowels & raw & Bark & Watt\\
		\midrule
		happ\textsc{y}-\textsc{nurse} &
		1.574 &
		1.599 &
		2.326 \\
		happ\textsc{y}-\textsc{square} &
		1.429 &
		1.533 &
		2.187 \\
		\textsc{nurse}-happ\textsc{y} &
		1.694 &
		1.741 &
		2.320 \\
		\textsc{square}-happ\textsc{y} &
		1.579 &
		1.786 &
		2.355 \\
		\lspbottomrule
	\end{tabular}
	\label{tab.euclid}
\end{table}

\tabref{tab.euclid} shows that, while the difference is marginal for the pairing happ\textsc{y}-\textsc{nurse}, all euclidean distance ratios are higher for the Bark difference normalise\is{normalisation}d data than for the raw data.
Normalisation using this method was therefore an improvement.
Yet the figures for \citeauthor{wattfabricius2002} are, once again, even better.
While the distance ratio increases on average only by about 0.096 for the Bark-difference normalise\is{normalisation}d data, \citeauthor{wattfabricius2002} produces distance ratios that are on average 0.728 higher.

With the current dataset \citeauthor{wattfabricius2002} thus yields better results than the Bark-difference method in visual representation (scatter plots), reduction of inter-category variation coefficients, \isi{Pillai} scores for inter- and intra-category (gender) comparisons, and euclidean distance ratios.
Despite the fact that the Bark-differ\-ence \isi{normalisation} is presumably more plausible in perceptual terms, the \citeauthor{wattfabricius2002} algorithm will therefore be used in this study whenever normalise\is{normalisation}d vowel values or plots are reported or represented.

\section{Phonological context}
\label{sec.prod_method.phon}

In order to extract the \isi{phonological context} of the variables under scrutiny orthographical representations of the carrier word and the one following the carrier word were extracted from the transcripts.
These orthographic representations were then automatically replaced (in R) by a phonemic transcription that was gathered from the interactive web-based CELEX lexicon database \parencite{baayenetal1993}.
With regard to those transcriptions, CELEX allows the user to choose from four different character sets.
For this study, the DISC set was selected because it represents each English phoneme with a single character (vowel length is not coded separately as this bit of information is already included in the vowel quality -- in English!).
This is highly useful if the transcriptions are going to be processed automatically, as diphthongs and affricates (which are regarded as single phonemes) are represented by a single character.
It is therefore impossible to misinterpret the first element of a diphthong (or and affricate) as a simple monophthong (or plosive).
This is a crucial advantage, as the software often has no straightforward way of knowing whether it is faced with a diphthong or a sequence of monophthongs.
DISC uses a set of simple ASCII characters.
In \tabref{tab.DISC} the characters that are different from IPA are listed together with their IPA equivalents.

	\begin{table}
		
		\caption{DISC characters and IPA equivalents}
		\begin{tabular}{cccccc}
			\lsptoprule
			\multicolumn{2}{c}{consonants} & \multicolumn{2}{c}{monophthongs} & \multicolumn{2}{c}{diphthongs}\\
			IPA & DISC & IPA & DISC & IPA & DISC\\
			\midrule
			ŋ & N & ɪ & I & eɪ & 1\\
			θ & T & ɛ & E & aɪ & 2\\
			ð & D & æ & \{ & ɔɪ & 4\\
			ʃ & S & ʌ & V & əʊ & 5\\
			ʒ & Z & ɒ & Q & ɑʊ & 6\\
			t͡ʃ & J & ʊ & U & ɪə & 7\\
			d͡ʒ & \_ & ə & @ & ɛə & 8\\
			ŋ̩ & C & iː & i & ʊə & 9\\
			m̩̩ & F & ɑː & \# &&\\
			n̩ & H & ɔː & \$ &&\\
			l̩ & P & ɜː & 3 &&\\
			\lspbottomrule
		\end{tabular}
		\label{tab.DISC}
	\end{table}

The impact of neighbouring sounds on the test variables \emph{will} be investigated to provide a more complete picture of how these sounds are used in Liverpool.
However, since the focus of this study is clearly on independent variables that are social in nature, this part of the analysis will be rather basic.
Only the immediately preceding and the immediately following phonemes are considered.
In the case of the two consonantal variables, measurements were furthermore restricted, from the start, to cases where /ŋ(ɡ)/ and /k/ occurred either intervocallically or at the end of a word, because these contexts have been identified as the ones where lenition is most likely to occur (cf. \sectref{sec.var.con.len}).
The three test vowels were only measured in content words (and, for \textsc{nurse} and \textsc{square}, also exclusively in stressed syllables), both to keep the number of vowels that had to be measured manageable and in order to avoid introducing unnecessary noise into the dataset by including weakened vowels.

All but two measured vowels either occurred at the beginning of a stretch of speech or were preceded by a consonant.
\textsc{nurse} and \textsc{square} tokens, without exception, either were the last phoneme in a stretch of speech or were \emph{followed} by a consonant, too.
Only happ\textsc{y} had a sizeable proportion of observations where the test vowel was followed by another vowel.
The difference between happ\textsc{y} measurements followed by a consonant and those followed by a vowel was small but significiant with respect to the normalise\is{normalisation}d F1 dimension (t(2016.295) = -13.593, p < 0.001), but insignificant as far as the (sociolinguistically more important, \citealt[cf.][502]{labov2006a}) F2 dimension is concerned (t(1935.124) = -1.355, p = 0.176).
It was therefore decided to drop happ\textsc{y} tokens that occurred before another vowel (along with \emph{any} observation where a test vowel was followed or preceded by silence) when fitting mixed linear effects regression models (see \sectref{sec.prod_method.stats}) because this allowed me to use the same set of phonological predictors (place and manner of preceding and following consonant) for all three vocalic test variables and thereby improved comparability of the models.
Measurements of happ\textsc{y} still accounted for the largest share of total observations, and in figures and other statistical comparisons (t-tests), the complete data set (including happ\textsc{y} followed by another vowel) was used.
Of course, this meant that it could not be investigated whether happ\textsc{y} formants might be influenced by vowel harmony.
This is an interesting question, but given the focus of the present analysis, it was considered outside of the scope of this book anyway, and will have to be addressed in a separate study in the future.
Word frequencies were considered for all variables investigated, and operationalised using Zipf\is{Zipf score} scores based on occurrences in SUBTLEX-UK \parencite{heuvenetal2014}.
See \sectref{sec.perc_method.sentences} for a more detailed discussion.

	\section{Statistical analysis}
	\label{sec.prod_method.stats}

Mixed linear effects models have become a sort of gold standard in recent years, especially in subdisciplines like psycho- and neurolinguistics.
Their biggest advantage is the possibility to include so-called random effects.
The reasoning behind this is that in most common experimental designs, we have ``fixed effects'' and ``random effects''.
Fixed effects are the variables the experimenter is primarily interested in and which are, as a consequence, controlled for in the experiment.
They are theorised to have the same or a similar impact in the sample that is the basis for the experiment as in the total population which the sample is drawn from.
Random effects, on the other hand, are responsible for variation that is not part of the experimental design, but due to the particular sample.
As a result, the effects of random factors cannot be extrapolated to the population as a whole \parencite[cf.][]{barretal2013}.

In Mixed linear effects models, the impact of random factors is estimated and taken out of the data before the relevance of the fixed effects is calculated.
The result is a reduction in noise since variation that is supposed to be due to chance is filtered out.
As a common example, consider a hypothetical lexical decision experiment where subjects have to decide whether a particular string of sounds or letters is a word of their language.
The words that are presented fall into two intrinsically different groups (e.g. different word class, length, complexity,\ldots) and the experimenter is interested in whether reaction times for these two word groups differ.
In such an example it is often found that individual words produce generally higher or lower reaction times across subjects (e.g. due to a non-controlled factor such as \isi{frequency} or number of similar words in the language).
The experimenter, however, is not interested in the effect of particular words but only in the general effect of the group they are part of.
The actual words chosen for the experiment are, in this case, considered a random sample of the whole group (\(\rightarrow\) population).
The same goes for the sample of participants, as some people are generally faster or slower to respond than other subjects.
Both sources of variation are ``random'' because re-running the experiment would (or at least \emph{could}) involve choosing a different sample of words and a different sample of participants \parencite[cf.][259--260]{barretal2013}.
It thus makes sense to filter out variation that is due to individual differences between subjects and test words as it is a characteristic of the sample, and not considered representative of the population.

It was thoroughly considered whether subject and carrier word -- the two most straightforward options -- should be entered as random factors in an analysis of the production data presented here.
Especially with respect to word, this would make some sense.
After all, there is no control over which words subjects use the relevant variables in (at least in the free speech part of the interviews which makes up the vast majority of observations).
Treating carrier word as a random factor was still deemed problematic, however.
This is because the \isi{frequency} of the carrier word, as well as the sounds directly preceding and following the target sound are factors of theoretical interest here.
While word itself could be considered a random factor in this research design, it seems likely that filtering out word effects would also eliminate a lot of \emph{relevant} information that is coded in the variables ``preceding sound'', ``following sound'', and ``word \isi{frequency}'', as these bits of information (among others) are included in the overall word context of the observation.
In the end, the risk was considered worth taking in order to counteract a scenario where (highly frequent) individual words would otherwise unjustifiably dominate the sample, and -- possibly -- obscure or overlay any more general effects of \isi{frequency} or phonological environment\is{phonological context}.

Treating interviewee as a random effect is even more of an issue.
As explained above, the reasoning behind treating subject as a random effect in many psycho-linguistic experiments is that the group of people that actually took part is a random subset of the population one wants to extrapolate the results to and that individual differences are therefore noise.
This crucial assumption, however, is not met in the dataset that is analysed in this chapter.
There was no active a priori selection of participants (cf. \sectref{sec.prod_method.participants}) in terms of typicality etc.
Nonetheless, the participants that ended up in the sample \emph{are} considered to be representative of their social group.
We look at a comparatively small number of middle- and working-class (female/male, old/young\ldots) speakers and analyse their speech because we believe our results \emph{can} be generalised to the group as a whole (at least to a certain extent).
This is an essential tenet of any sociolinguistic analysis and argues against treating participant as a random effect.

\largerpage
It is possible to calculate random effects for speaker sub-clusters, e.g. for young working-class women only.
This would eliminate the theoretical problem just outlined, as the variation between, say, young working-class women and young working-class men would not be filtered out, but just the differences between individuals \emph{within} the respective sub-groups.
This course of action was still rejected, because
	\begin{inparaenum}[(a)]
		\item for the relevant sub-groups (divided by gender and social class) among the young and middle-aged subjects this would mean filtering out the variation between two participants only (which does not really seem worth-while), and
		\item more importantly, there is only one subject each in the gender/social class subgroups for the oldest speakers, so there is no other subject to estimate any potential effect of the individual against.		
	\end{inparaenum}

In summary, there are both conceptual and practical problems if one is to consider speaker and/or carrier word as random effects in the production data under scrutiny here.
The use of carrier word as a random effect seemed to be more acceptable, though, since this might, in fact, make the results somewhat more representative and comes with less severe downsides.
A random intercept for carrier word was therefore included in all mixed-effects models that will be reported on.
Sum coding was used for all these analyses so that main effects and interactions (instead of \emph{simple} effects and interactions) could be identified.
For the vocalic variables, the set of main predictors entered into the maximal model was: style, age group, gender, social class, \isi{frequency}, \isi{vowel duration}, place of articulation (preceding sound), manner of articulation (preceding sound), place of articulation (following sound), and manner of articulation (following sound).
Style is the independent variable I am most interested in as the presence or absence of \isi{style shifting} is taken as an indicator of \isi{salience} (cf. Chapter \ref{ch.sal}).
It is quite possible (and actually expected given the main hypothesis of this study) that style differences can be present in one group but lacking in another (or be present in all groups, but not to the same extent).
To test for this (and other, sociolinguistically meaningful combinations), all two-way interactions of style, age group, gender, and class were included as well, along with the two three-way interactions of style, age group, and one of the other social variables gender and social class.
Interactions of the phonetic-phonological factors were not considered, as these predictors are not of primary interest in this study, and adding their interactions would have unduly inflated the models.

Model structure for the two consonantal variables velar nasal plus and /k/-lenition was identical as far as the social predictors are concerned (both in terms of main effects and interactions).
Frequency\is{frequency} of the carrier word was also included, but the set of phonetic and phonological predictors had to be different.
Firstly, \isi{vowel duration} is not applicable to consonants (plus the timing domain is already included in the dependent variable -- proportional duration of friction), so this factor was not relevant for the mixed-effects regression models that were fit to the /ŋ(ɡ)/ and /k/ measurements.
Secondly, the \isi{phonological context} had been restricted to intervocalic\is{phonological context} and word-final\is{phonological context} occurrences from the start, so it was considered unnecessary to enter information in the same way as it had been done for the two vocalic variables (i.e. ``spread out'' over four different independent variables).
Instead, phonological environment\is{phonological context} was summarised in a single predictor (``Environment'' in the spreadsheet), which was to code whether the measurement had been taken in an intervocalic\is{phonological context} context (within a word) or at the end of a word.
The second context was further divided with respect to whether the measurement was followed by silence (pre-pausal), or by another word, in which case the type of the first sound in the following word (vowel, affricate, liquid\ldots) was coded.

All statistical test were performed using the R software \parencite{R}.
Mixed linear effects models were computed with the help of lmerTest \parencite{lmerTest}, an R package which builds on lme4 \parencite{lme4}, but adds p-values calculated on the basis of F statistics, with degrees of freedom derived from Satterthwaite's approximation.
Sum coding, instead of R's default treatment coding, was used for all regressions.
Model selection was based on AIC scores and F-tests comparing nested models.
Calculating a simple goodness-of-fit measure is not a straightforward task in the context of mixed-effects models.
As a rough (!) equivalent of the R\textsuperscript{2} value known from linear regression models this book reports the R\textsuperscript{2} of a linear model that regresses the observed values on the fitted ones from the linear mixed-effects model \parencite[cf.][]{glmwiki}.
Models were checked for \isi{collinearity} using the kappa.mer and vif.mer functions written by Austin Frank.\footnote{Code downloadable from \url{hlplab.wordpress.com/2011/02/24/diagnosing-collinearity-in-lme4/}}