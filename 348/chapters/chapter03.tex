\chapter{Simultaneous interpreting as a complex cognitive activity} \label{chapter3}\largerpage[2]

As discussed in the previous chapter, the main points of criticism concerning the use of CAI tools for terminology look-up during interpreting, and in particular during SI, refer to the addition of yet another task to the concurrent mental processes involved in interpreting, i.e. that of interacting with a digital support tool to deal with specialised terminology perceived as an element of difficulty during interpreting (see \sectref{CAI_attitudes}). The hypotheses formulated on the cognitive implications of a CASI task, both when manual look-up is involved and when it is replaced by an ASR module are, however, mostly based on personal assumptions or unstructured observations and have not yet been grounded in empirical analysis aimed at investigating the effects of technological support on the interpreter's cognition. Such hypotheses refer to constructs that have been formulated and explored in the context of cognitive psychology, learning psychology and human factors research and which have been widely applied in TPR: the concept of interference between tasks, the assumption that humans have access to a limited amount of cognitive resources, the issue that attention must be allocated to and shared among different co-occurring tasks during a limited amount of time, and that this requires coordination and monitoring, and, finally, the construct of cognitive load (CL), often mentioned in reference to the presumed additional effort posed by CAI tool usage.

The present section will review and discuss these concepts, their application and empirical validation with the aim to provide a conceptual framework for the formulation of hypotheses on SI with digital terminological support and for the definition of the research questions guiding the present study.

\begin{sloppypar}
I will start by discussing some basic assumptions about working memory (WM) and attention allocation (\sectref{workingmemory}, \sectref{attention}), and discuss their relevance for the investigation of CL (\sectref{CL}) on the basis of related empirical research within the field of cognitive psychology and TPR. After defining and exploring these key concepts, I will consider how they have been integrated into cognitivist models of SI which view this process primarily as an issue of multitasking (\sectref{interpreting_cognitive}), as this is the framework within which I conduct my analysis, define my research questions and formulate hypotheses on CL and task interference in SI with CAI tools (\sectref{mymodel}).
\end{sloppypar}

\section{Working memory and information processing} \label{workingmemory}
The concept of WM was first introduced in the seminal work by \citet{bower_working_1974}. Until the authors' investigations into the construct, little empirical evidence had been collected to support the idea of WM. The development of a construct of WM represents a step forward in the understanding of the role of memory in human information processing, specifically in how information is processed over a short period of time, for instance during reasoning, language comprehension, and learning, the three cases on which Baddeley and Hitch concentrated. The construct of short-term memory (STM, \citealt{atkinson_human_1968}) had been used to represent the temporary retention of a small part of information over a limited amount of time. As for processing in STM tasks, the role of the short-term store (STS) as WM, as proposed by \citet{atkinson_human_1968,atkinson_control_1971}, had found little empirical evidence in non-memory related tasks. Baddeley and Hitch provided first evidence supporting the idea of a common WM system responsible for both short-term information retention and processing. Thus, they depart from Aktinson and Shiffrin's assumption that the STS is a single unit and that it is modality-independent. They describe WM as ``a control system with limits on both its storage and processing capabilities'' \citep[86]{bower_working_1974}: we can only store and process a limited amount of information over a brief period of time.


The role of WM is essential to interpreting as it is a highly complex cognitive activity which requires both retention of transient information and processing of said information during a short time-span. In addressing the issue of CAI tools integration into SI, it is often pointed out that interpreters may not always have the necessary resources (see \sectref{interference}) or sufficient time (see \sectref{barrouillet}) to attend to the additional sub-processes required by glossary querying or by the interaction with an ASR system. As a consequence, an interpreter's WM may not be able to retain and process all stimuli that must be attended to. This hypothesis reflects one of the key assumptions about WM, i.e. its limited capacity. This fundamental tenet of WM plays an essential role in all models of WM, despite the ongoing debate on its nature \citep[3474]{seel_encyclopedia_2012}, which is, to some extent, still unresolved. One element of dispute lies in the architecture of WM: some scholars, as exemplified by the very successful modular model by Baddeley and Hitch, postulate a WM comprising a set of related components covering stimulus processing and attention allocation, while others, most notably \citet{cowan_evolving_1988}, view memory as a unitary store.


In Baddeley and Hitch's model, the WM system involves a phonological loop (PL), a visual-spatial sketch pad (VSSP) and a structure responsible for executive functions, the Central Executive (CE). According to the authors, verbal information is ``phonemically coded'' (ibid.), and is rehearsed (either overtly or covertly) in a limited-capacity phonemic buffer. Following Atkinson and Shiffrin's model, Baddeley and Hitch postulate that rehearsal is necessary for information retention. They propose that WM is modality-dependent: while verbal information is thought to be temporarily stored and encoded in the PL, visual-spatial information is encoded in the VSSP. Both substructures later received further specification. The PL was thus subdivided into a storage component, i.e. the phonological store – where phonological traces are stored up to 2s \citep{baddeley_human_1990} due to the word-length effect \citep{baddeley_word_1975} – and a rehearsal subsystem responsible for refreshing memory traces in order to prevent their decay (the articulatory loop). Similarly, the VSSP was divided by \citet{logie_visuo-spatial_1995} into the visual cache (retention) and the inner scribe (processing). Later on, \citet{baddeley_short-term_2000} introduced the construct of an Episodic Buffer (EB) which stores and integrates information not only from the PL and the VSSP, but also from long-term memory (LTM) to form a single percept. Baddeley and Hitch's model of WM posits important consequences for our understanding of WM. According to the model, retention and processing are managed by different memory structures. This in turn supports the idea of multitasking, which is only possible if resources can be shared between retention and processing, and, conversely, if retention and processing correspond to separate structures in WM.


The assumptions put forward by Baddeley and Hitch have received ample empirical support. Of particular relevance to the task of SI are the PL, the CE and the EB. The double function of the PL, i.e. perception and rehearsal, has been evidenced by two related effects found in empirical testings of the model: the phonological similarity effect \citep{baddeley_is_2018} and the word-length effect \citep{baddeley_word_1975, jacquemot_is_2011}. The first shows a reduced recall for phonologically similar words, the second a decay in memory traces and thus an impaired recall for visually presented words when articulatory rehearsal is suppressed. Neurological evidence also supports this distinction, as different brain areas have been found to activate for storage and rehearsal tasks \citep{papagno_mapping_2017}. \citet{gieshoff_aus_2012} found supporting evidence from interpreting as, in her experiment, longer numbers were more difficult to recall. This aligns with the word-length effect, as in interpreting phonological rehearsal is suppressed due to the concurrent production of the interpretation. The concept of a CE responsible for focusing, dividing and switching attention and interacting with the LTM store is supported by evidence from studies investigating executive functions (e.g. \citealt{godefroy_dysexecutive_2010}), although the notion that it is a unitary system may be oversimplified \citep{stuss_is_2007,logie_retiring_2016}. Finally, the introduction of an EB was justified by findings that recall for longer sets of words was possible than what the PL would allow \citep{baddeley_sentence_1987}. More specifically, \citet{baddeley_working_2012} postulates a capacity of four chunks of information. Further evidence of an integration and a facilitation effect between visual-spatially and verbal-vocally encoded information is provided by studies on bootstrapping data \citep{darling_visuospatial_2017,darling_visuospatial_2010}.

Concurring accounts of WM, exemplified by \citegen{cowan_evolving_1988} unitary store model, propose an alternative to Atkinson and Shiffrin's multi-storage model, which, as discussed above, was highly influential in Baddeley and Hitch's development of their own model of WM. The development of \citegen{cowan_sensory_2009} model was based on evidence that there might be interference between the auditory and the visual buffers, which does not support the notion of separate stores. In Cowan's model the existence of a single, long-term store (LTS) is postulated which contains units of information. STM is described as the activated portion of long term memory (LTM), while the items currently being processed are attended to in the so-called ``focus of attention''. Thus, WM, i.e. the processing of STM items, is located in the activated portion of LTM that is receiving attention at a certain moment in time. The main point of criticism for Cowan's model is its oversimplification inherent to the assumption that STM is only the activated portion of LTM. Additionally, studies on amnesic patients have identified impairment in STM, but not in LTM, or viceversa.
This model of WM is valuable in that it poses the focus on the relationship between information processing and attention, an essential component in the interpreting process, as I will discuss in the following section (\sectref{attention}). Even if WM is structurally considered part of long term memory, its function is nonetheless distinct from LTM, as is the case in the multi-component model which further postulates a structural separation of the two stores.


Another key assumption about the human cognitive architecture is that control processes aimed at allocating attention to the stimuli to be processed must be governed by a dedicated cognitive structure. A CE responsible for voluntary processing and directing attention to relevant items is found both in modular and in unitary models of attention. In Baddeley and Hitch's model, for instance, the CE supervises the PL, the VSSP and the EB, i.e. the structures responsible for information retention and processing. Similarly, although based on largely different assumptions, Cowan also postulates the existence of a CE responsible for attention and voluntary processing, such as the activation and focusing of items. The CE also has the role to activate items stored in long term memory which are necessary for stimulus processing. The link between WM and a long term store emerges clearly in Cowan's model, which promotes a unitary view of human cognitive architecture, as discussed above.

The role of a CE is essential to free up cognitive capacity and avoid cognitive overload when capacity is exceeded. As postulated by \citet{miller_magical_1956}, the (limited) capacity of our STM depends not on the amount of information, but on how it is compounded: chunks of information are more easily remembered than single elements of information. The CE is thought to intervene by re-coding information in order to free up capacity, re-combining single elements in larger chunks and thus reducing WM load. An example of chunking is present in instructional design theory (see \citealt{van_merrienboer_cognitive_2005}) in the notion of schemata for information and knowledge organisation. The development of higher-order schemata allows learners to process information more easily, thus acting as a CE. This also relates to the translation process, in that the development of strategies to address a text to be translated or common sources of difficulty in speeches to be interpreted can alleviate WM by freeing up cognitive capacity for intentional processing. Studies on translation and interpreting competence have highlighted how one essential difference between novice and experts lies in the fact that the latter have developed more solid schemata (or strategies) which allow them to effectively process complex information and avoid cognitive overload, with important consequences for training (see for instance \citealt{riccardi_evolution_2005}).

Both approaches to the definition of the architecture of WM present some shortcomings. As discussed above, the very influential multi-component model by Baddeley and Hitch has received repeated empirical support over the years from studies conducted in the field of cognitive psychology. In addition, it has been widely influential in TPR, where it has been adopted as a framework in a number of empirical studies \citep{daro_verbal_1994,dragsted_segmentation_2004,mizuno_process_2005,padilla_articulatory_2005,kosma_fonctionnement_2007,hvelplund_allocation_2011,kopke_methodological_2012,ferreira_simultaneous_2015}.
In this framework, however, it is not clear how other types of sensory input may be processed in addition to auditory and visual information. This shortcoming emerges also on the basis of recent evidence which found that different areas of the brain are activated when different types of auditory and visual stimuli are processed. As discussed by \citet{postle_working_2006}, the consequence of such evidence for the ``standard'' model of WM is a potentially unlimited proliferation of subsystems, which would undermine the very role of the model: 

\begin{quote}
Followed to its logical extreme, the cognitive architecture of the standard model would eventually depict a WM system organized into hundreds (if not thousands or more) of domain-specific buffers, each responsible for the WM processing of a different kind of information.\hfill\hbox{\citep[25]{postle_working_2006}}
\end{quote}
On the other hand, an account of WM which views it as a unitary store also conflicts with such evidence. Additionally, it appears limited for its assumption that information is merely ``activated'' through focused attention, but does not offer a framework for the integration of new information in a long term store, presenting a unidirectional view of human memory architecture which brings information to the surface, but does not explain how information has entered the store in the first place. The value of Cowan's account of WM, taken to exemplify unitary models of WM, lies in its holistic view of information processing compared to the more rigid account by the more successful model by Baddeley and Hitch. A unifying view of WM may come from \citet{postle_working_2006}, who approaches WM from the perspective of cognitive neuroscience rather than cognitive psychology. He defines WM as a function that ``arise[s] through the coordinated recruitment, via attention, of brain systems that have evolved to accomplish sensory-, representation-, and action-related functions'' \citep[23]{postle_working_2006}. It is this functional view which, in my opinion, best serves the discussion around WM for the translation and interpreting process. Thus, the separation of processing buffers for audio and visual stimuli is applied here functionally, rather than structurally. When referring to separate buffers for audio and visual stimuli, which will be pivotal in my discussion of task interference, I start from the assumption, backed by recent evidence, that there are indeed separate channels for the processing of this information. As I embed my methodological approach in the tradition of TPR, which has widely adopted and operationalised the model of WM by Baddeley and Hitch, I will be referring to two single channels dedicated to processing visual stimuli on the one hand and auditory on the other, while implicitly acknowledging that the cognitive structure underlying such systems may very well be more complex.

To sum up, though the approaches discussed present some differences in how they view the structure of WM, they share common assumptions in terms of its function. First of all, in both cases WM is considered to have both a retention capacity and a processing capacity. If the elements temporarily stored in WM are not attended to, not refreshed nor activated, their traces decay from memory. This, in turn, underlines the role of attention allocation, which must take place effectively in order to preserve such memory traces in WM. However, attentional capacity is considered to be limited. Thus, attention must necessarily be distributed, shared or switched to the different elements that require processing. The task of attention distribution, sharing and switching must be regulated by control functions, which in the models discussed is identified as a CE. How attention is allocated to the stimuli competing for attention is the object of theories of attention distribution and resource sharing, which will be the object of the following sections.

\section{The role of attention in processing visual stimuli} \label{attention}
Closely linked to WM is attention, which represents a key constituent in numerous models of human memory architecture, most notably in Baddeley and Hitch's and especially in Cowan's model, and in models of resource allocation among concurrent tasks, as I will discuss in \sectref{interference}. Attention is a multifaceted construct, which can be studied from different perspectives. Of particular interest for the present research object are the concepts of focused or selective attention and of divided attention. In particular, divided attention and its effects on information processing and performance has been in focus in Cognitive Load Theory (CLT), as will be discussed in \sectref{CL}.

Interpreting may be viewed as an activity requiring the allocation of attention to multiple streams of information \citep{seeber_multimodal_2017}. This is especially true today, as communication at multilingual events is rarely achieved through a single medium, but often foresees the combination of oral presentations and, for instance, slide presentations. This requires interpreters to process multiple types of inputs and several information flows in parallel derived from the external world (e.g. the speech, the presentation, support materials such as speech transcripts or glossaries), in addition to monitoring their own rendition. When a CAI tool or a conventional glossary is used as a support to deal with terminology, additional visual-verbal information enters the perceptual space of the interpreter. Some of these stimuli capture the interpreter's attention in a bottom-up way. However, it is required of the interpreter to actively divide their attention between the relevant streams of information and, for instance when the rendition of a specialised term requires additional effort, to actively focus their attention on a single input while at the same time keeping the other stimuli in the focus of attention. Thus, interpreting may be seen as an activity requiring both focused and divided attention, even more so when the processing of multimodal stimuli is involved – as is the case with a digital glossary or an ASR system – and involving both bottom-up and top-down attentional processes.


As a consequence, SI with digital terminological support may be seen as an activity imposing a high perceptual load as well as a high CL (see \sectref{chandler_sweller_CLT}) on the interpreter's WM. The concept of perceptual load is pivotal in Lavie's (\citeyear{lavie_perceptual_1995,lavie_selective_2000,lavie_distracted_2005,lavie_attention_2010}) perceptual load theory, which provides an explanation of how attention is selectively allocated to stimuli concurring for human attention. Her proposal outcomes the dichotomy of early selection models \citep{broadbent_perception_1958,treisman_selective_1964} and late selection models \citep{deutsch_attention_1963,norman_toward_1968}. The first postulate, respectively, either an all-or-nothing filter which lets only salient items pass through and enter our focus of attention, or an attenuator which lets through only relevant enough elements. The latter, on the contrary, propose that selection occurs only at a later stage: everything is first perceived and processed, and then priority is assigned to the most relevant items.

In light of supporting empirical evidence for both models (e.g. \citealt{simons_gorillas_1999} for early selection or \citealt{stroop_studies_1935} and \citealt{eriksen_effects_1974} for late selection), Lavie put forward a model which overcomes the limitations of the preceding models and integrates their strengths. Her model thus represents a ``resolution to the long-standing early and late selection debate on the extent to which irrelevant distractors can be ignored'' and may be viewed as a ``hybrid model of selection'' \citep[353]{lavie_load_2004}. Lavie's theory is particularly relevant to the present research object as it has been tested within the framework of visual attention. According to Lavie, attention allocation is dependent on the perceptual load posed by the task. Low-load conditions allow for late selection (more stimuli can be processed and are only later selected), while high-load conditions require early selection of relevant information. The reduction in distractor processing under high perceptual load has been shown by several studies (for a review, see \citealt{lavie_distracted_2005}). At the same time, in situations of high perceptual load, limited attentional capacity is left for processing. Therefore, we can hypothesise that during SI with terminological support, if the suggested terms are presented in a way that imposes high perceptual load (e.g. within the context of a glossary rather than in isolation), fewer resources will be left for the processing of other stimuli, such as the speaker's words or one's own rendition.



\section{Attention sharing and task interference} \label{interference}
Lavie's theory is helpful in understanding how visual stimuli to be processed are selected during high-load tasks such as SI. However, it is insufficient to formulate hypotheses on how multiple tasks interfere with each other. Additionally, in her model attention is viewed as a general resource, with no further specification. As a general theory of attention, her model is not sufficient to explain why certain concurrently performed tasks interfere with each other more than others, nor at which level this interference occurs, and which attentional resources are shared. The issue of task interference is highly relevant to a complex cognitive task such as interpreting, and even more so when the additional task of looking up terminology or processing a term presented automatically on a screen must be integrated with an already multi-layered task such as SI. Since in the present work SI is approached from the perspective of multitasking, I will now discuss attention allocation as a matter of resource sharing among concurrent tasks, focusing on two models which are reflected in models of the interpreting process seen as a matter of task coordination (see \sectref{interpreting_cognitive}).

Similarly to Lavie, \citet{kahneman_attention_1973} postulates the presence of a single pool of attentional (or cognitive) resources that are shifted from one task to another. Kahneman's single resource theory can therefore be seen as a ``general resource model of task interference'' \citep[162]{wickens_multiple_2002}, which explains a decrease in performance levels simply with the concurrent performance of the tasks at hand. According to Kahneman, variance in dual-task performance is due either to the level of difficulty of the individual tasks or to the preference given to one of the tasks (if a task is not favoured, its performance suffers, while the favoured task is carried out successfully). He distinguishes between the idea of load, i.e. the amount of resources demanded by a task, and that of effort, i.e. the amount of cognitive resources and energy the subject exerts in order to perform a task. When task demands are higher than the available capacities, performance suffers. Kahneman also addresses the role of arousal for the availability of cognitive resources: the higher the level of arousal, i.e. of conscious attention, the higher the amount of attentional capacities available. Kahneman's assumptions have, however, been challenged empirically (for a discussion in light of neuroscientific evidence, see \citealt{bruya_is_2018}) and criticised for their vagueness. One major drawback of his theory is that it does not allow for a modulation of hypotheses on task interference based on the nature of the tasks. This stems from his equation of attention with effort, which does not allow for the integration of bottom-up processes of attention capturing. It does, however, focus the spotlight on one important quality of attention, which aligns with accounts of WM and is largely supported by empirical evidence: that attention is limited. Additionally, while limiting on the one hand, the model stresses the role of intentionality on the allocation of attention, which is essential in a complex activity such as interpreting.

In order to overcome the limitations of Kahneman's model, and to account for the fact that ``differences in time-sharing efficiency'' may be due to the quality of the resources concurrently recruited by multiple tasks (ibid.), as postulated by \citet{kantowitz_experimenter-limited_1976} and \citet{wickens_effects_1976} himself, \citet{wickens_processing_1984,wickens_multiple_2002} put forward an alternative model of resource sharing which posits that ``time-sharing between two tasks [is] more efficient if the two [utilise] separate structures than if they [utilise] common structures'' (ibid.).

At the core of Wickens's model are three underlying assumptions:

\begin{enumerate}
\item every non-automated task produces load;
\item two interacting tasks demand a higher amount of resources than the performance of any single task;
\item tasks recruiting the same type of resources exhibit a higher level of interference than tasks recruiting resources of discrete structures.
\end{enumerate}
Unlike Kahneman, Wickens does not assume the existence of a single pool of resources, but rather of discrete attentional structures. As a consequence, what is shared among tasks are not the structures themselves, but rather their underlying resources. It follows that two or more tasks recruiting the same resources may be very difficult (or impossible) to perform simultaneously than tasks demanding separate resources. This would explain why we can simultaneously look at a painting and talk with a friend, while listening to the radio and to a friend at the same time will inevitably lead to a loss of information from one of the two sources. In the first case (simultaneous performance of a visual and an auditory task), resource sharing will be easier, and thus more efficient, than in the latter (two auditory tasks), which share the same underlying resources.

\begin{figure}
\includegraphics[width=.8\linewidth]{images/wickenstiescube.pdf}
\caption[Wickens's Cognitive Load Model]{Wickens's multiple resource model \protect\citep[163]{wickens_multiple_2002}}
\label{fig:wickensm}
\end{figure}

Wickens's model distinguishes between four dimensions, each further subdivided into two levels, as summarised in \tabref{tab:wickens}.

\begin{table}
\begin{tabular}{lll}
    \lsptoprule
    Dimensions &  \multicolumn{2}{c}{Levels}\\\midrule
    processing stages & perception \& cognition & response\\
    perceptual modalities & visual & auditory\\
    processing codes & spatial & verbal\\
    visual processing & ambient & focal\\
    \lspbottomrule
\end{tabular}
\caption{Dimensions and respective levels in Wickens's multiple resource model\label{tab:wickens}}
\end{table}

The fourth dimension (visual processing), with its respective levels, is a later addition \citep{wickens_multiple_2002} to the original model.


According to the model (see Figure \ref{fig:wickensm} for a graphic representation), processing occurs at two stages (perception and cognition are subsumed in a single stage, since one cannot occur without the other, and thus share the same pool of resources). Perception can be either visual or auditory. This points to the same distinction posited by Baddeley and Hitch and operationalised through the PL and the visuospatial sketchpad. The perceived information can be processed either as spatial or as verbal information. In addition to the four dimensions, Wickens also ``concedes the existence of a residual pool of general resources which, albeit not reflected in his model, is available to and demanded by all tasks, modalities, codes, and stages as required'' \citep[1382]{seeber_thinking_2007}, and which may be, to some extent, equated to the CE.

This model of resource-sharing can be used to operationalise hypotheses on the level of task interference and thus to compute an ``interference score'', which can be adopted to predict the efficiency with which two tasks can be performed at the same time. Wickens develops a ``conflict matrix'' (CM) to show the level of resource recruitment by the single sub-tasks (expressed by ``demand vectors'') and the degree to which co-occurring sub-tasks are expected to interfere with each other (represented by the ``conflict coefficients''), which is higher if the two tasks both demand the same level of a given dimension \citep{wickens_multiple_2002}. Demand vectors can range from a value of 0 (no dependence on a certain resource) to 2 (extreme dependence on a resource) and are assigned for each dimension of a certain task. Conflict coefficients can be assigned a value between 0.2 and 1, where 1 represents two tasks that cannot be performed simultaneously, as they are both entirely dependent on the same resource, and 0.2 is the necessary interference cost of the simultaneous performance of two tasks. A conflict coefficient of 1 corresponds to a quantification of the central bottleneck assumed by several models of WM \citep{wickens_multiple_2002}. The total interference score between tasks is thus calculated as the sum of demand vectors and conflict coefficients. A higher total interference score points to less efficient time-sharing between simultaneously performed tasks. Several findings support Wickens's model. For instance, experiments conducted by \citet{wolfe_divided_2012} and \citet{mcleod_dual_1977} support the notion that concurrent tasks in the same modality interfere with each other, while the research reviewed by \citet{lu_supporting_2013} provides support for reduced interference of tasks performed in different modalities.


One weakness of Wickens's model is the subdivision of tasks in a processing and response stage, which may represent too limiting an account of complex activities such as translation and interpreting, where these stages often overlap. It is, however, more in line with neurocognitive evidence suggesting that different areas of the brain are responsible for processing different types of stimuli, similarly to what has been discussed for Baddeley and Hitch's model (see \sectref{workingmemory}), albeit with the same limitations. An additional benefit provided by the model is that it allows to operationalise and empirically test hypotheses on the interference of similar but different tasks, such as SI with different types of digital terminological support, as I will discuss further in \sectref{mymodel}. In turn, being able to test hypotheses at this level of granularity may prove particularly useful in practice in order to fine-tune the type of support provided to interpreters, where small differences may have a significant impact on the level of interference between tasks experienced and on the alleviation of WM demands. Therefore, Wickens's model will be especially relevant in the formulation of hypotheses for the present analysis (see \sectref{hypotheses}) and in the present empirical investigation of CASI. Additionally, as I will discuss in \sectref{interpreting_cognitive}, the model has already been operationalised in empirical interpreting research concerning itself with issues of attention allocation.

\section{The construct of cognitive load} \label{CL}
The notions of WM and attention allocation are particularly relevant to a complex cognitive activity such as SI. As such, they represent fundamental tenets for the construct of CL, ubiquitous in cognitive models of the interpreting process postulated within the framework of Interpreting Studies. In exploring the cognitive underpinnings of (simultaneous) interpreting, scholars have adopted a rather diverse terminology, not only referring to the notion of CL, but also to the concept of processing load or mental (work)load (see for instance \citealt{gieshoff_impact_2018}). Additionally, the notion of effort, which has been highly influential in Interpreting Studies (see \sectref{gile}), represents an important related construct.

The adoption of such diversified terminology reflects the interfacing of translation and interpreting studies with other disciplines, primarily cognitive psychology and human factors, in particular cognitive ergonomics. The former has been very influential in both areas of study, providing ``the basic premise of the behavior– mind correlation'' \citep[23]{jakobsen_TPR_2017}. As the present study aims to approach the use of digital terminology support tools by interpreters from an explicitly cognitive perspective, investigating the ``how'' behind the ``what'' of the interpreting performance, the adoption of models and theories formulated within the field of cognitive psychology is expected to constitute a useful reference for the formulation of hypotheses about this research object. Additionally, although the present investigation does not directly aim to explore the ergonomics of the tools employed as terminological support\footnote{The interest in the cognitive ergonomics of CAI tools is picking up. A joint project currently underway at the University of Ghent and at the University of Mainz is concerned with the question of defining the best interface for the ``artificial booth mate''. See the webpage of the Ergonomics for the Artifical Booth Mate project \citep{EABM2021} for preliminary results: \url{https://www.eabm.ugent.be/survey/} (Accessed: 01.11.2021).}, the interpreter's experience in interacting with the tools can reasonably be expected to influence cognition during SI, particularly in terms of the load experienced, similarly to how the interaction between translator/post-editors and CAT tools has been shown to play a crucial role for the disposition towards support technologies and for the load experienced by translators (see \citealt{obrien_translation_2012,OBrien_Ehrensberger-Dow_Connolly_Hasler_2017,moorkens_assessing_2016}).


In this section, I discuss the concept of CL from the perspective of cognitive psychology, focusing on the foundational model developed within the framework of CLT \citep{chandler_cognitive_1991}, which has been widely adopted to model the translation and interpreting process and has received ample empirical support in TPR. I thus aim to provide first of all a terminological clarification of the concept, and to delineate a framework for the discussion of how the construct has been adopted by Interpreting Studies to discuss the cognitive implications of interpreting (\sectref{interpreting_cognitive}). Particular attention will be devoted to the predictions of CLT for the load imposed on the interpreter by SI with digital terminological support and potential effects on attention and WM, which will serve as the theoretical basis for the discussion of results in \sectref{discussion}.
\subsection{Cognitive load in interpreter-computer interaction} \label{chandler_sweller_CLT}
The construct of CL was first delineated within the framework of \citegen{chandler_cognitive_1991} CLT. In developing their theory, they were aiming to answer salient questions in instructional design, i.e. how to facilitate knowledge acquisition by effectively designing learning tasks that support students in their learning process. The authors distinguish between three types of CL: intrinsic, extraneous, and germane load.


Intrinsic cognitive load (ICL) can be defined as the CL that is experienced by the subject while learning. It ``depends on the number of elements that must be processed simultaneously in WM, and [this] in turn, depends on the extent of element interactivity of the materials or tasks that must be learned.'' \citep[150]{van_merrienboer_cognitive_2005}. ICL thus increases when element interactivity increases. The experienced load depends on the task itself and its level of interactivity: the higher the interactivity of the task elements, the higher the ICL. The level of interactivity, in turn, depends on expertise: through the development of schemata, several interacting elements can be processed as a single input, thus reducing the experienced load. Interpreting may be considered as a process with a high level of interactivity. When multi-modal input is involved, such as in SI with digital terminological support, the interactivity is even higher. According to CLT, the intrinsic load of the task may be expected to increase (see also \sectref{split_attention}). Similarly to the field of learning, expertise in SI also leads to the development of schemata, which can prove useful to automatise several subprocesses involved in interpreting. As a consequence, the intrinsic load of the task may be lower for more experienced interpreters, especially if they have received training or enjoyed extensive practice in CASI. While the present study is not conducted within the expert-novice paradigm, the predictions of CLT for the intrinsic load produced by the task in question as a function of interpreters' expertise will be relevant for the discussion of results, especially in terms of their generalisability. Although the aspect of expertise is not included in Wickens's model (see \sectref{attention}), the total interference score may be seen as a theoretical quantification of intrinsic load as a function of element interactivity.

Extraneous cognitive load is a concept that refers to task design and presentation. Unlike intrinsic CL, extraneous CL is not dependent on the nature of the task to be performed, but rather on the way the task is presented. Given that intrinsic and extraneous CL are additive \citep[150]{van_merrienboer_cognitive_2005}, in the presence of a high ICL, extraneous CL should be kept as low as possible, whereas in a lower load task, performance may not suffer from high extraneous load. If the intrinsic load of SI with terminology tools cannot be reduced, it may be possible to affect the total load imposed by the task by operating on the extraneous load determined by the tool interface or by the way information is visually organised in the digital glossary. In turn, differences in the load experienced when working with different tools may be traced back to differences in their interface, which may for instance be perceived as non conducive by experienced interpreters who have been using different tools for several years and may be one of the sources of resistance towards new tools among seasoned professionals. This ``cognitive friction'' \citep[19]{cooper_inmates_2004} may be the source of frustration and irritation, which has been shown to negatively affect CL in workplace studies on technology-assisted translation (e.g. \citealt{bundgaard_translator-computer_2016,risku_investigating_2019}). A similar effect may reasonably be expected to occur also in technology-supported interpreting.

Finally, germane load is the mental effort that the learner or the subject exerts in order to perform a certain task. Germane load is subject-dependent and, like intrinsic load, can be expected to decrease with increased expertise. The concept of germane load is valuable as it highlights the role of individual preferences in interacting with the tools and points to the potentially beneficial effect of higher personalisation of support tools for interpreters, similarly to what has been suggested for translators \citep{taravella_acknowledging_2013}. Recent approaches exemplified by \citegen{vogler_lost_2019} proposal of automatically predicting useful terminology to be displayed by ASR systems for interpreters may offer beneficial insights and practical solutions to positively intervene on germane load. Additionally, the notion of germane load as a function of competence emerges in the redundancy effect predicted by CLT, as will now be discussed in \sectref{split_attention}.


\subsection{Attention splitting and audio-visual integration} \label{splitatt_audiovisual}
As discussed above, CLT postulates that extraneous load is influenced by the way in which information is presented. The task of interpreting a speech simultaneously while being able to draw support from a digital terminology tool involves the processing of several streams of input (aural and visual): it is therefore useful to consider several additional principles which have been formulated within the framework of CLT and have received strong empirical support also within the field of TPR: the split-attention effect, the redundancy effect and the modality effect.



\subsubsection{Split attention} \label{split_attention}
The split-attention effect was identified by \citet{tarmizi_guidance_1988}, who found that worked examples of geometry problems were more effective if the various sources of information (e.g. the diagram and the diagram description) were presented in an integrated fashion rather than spatially separated. This is because in the conventional mode of presentation, the various sources of information must be integrated for learning to occur, which strains WM. There is a positive split-attention effect if information processing is more effective when the sources of information are integrated in a single percept. Not only is spatial contiguity important to promote effective information processing, but so is temporal contiguity, as demonstrated by \citet{mayer_redundancy_2005} in a series of experiments on multimedia learning. As the time component is of the essence in SI, the temporal contiguity principle holds the potential to predict important effects on the timing of the terminological information presented on screen. In order to avoid or at least to reduce split-attention between the speaker's words and the terminological pair presented on the screen, it is essential that the term be found as quickly as possible by the interpreter when manual look-up is involved, and that the latency of the ASR system be kept as low as possible (see \citealt{montecchio_masterarbeit_maddalena_2021}). At the same time, the information presented by the tool must remain visible long enough to avoid having to retain the visually-presented information in WM (see \sectref{workingmemory}), which would cause attention splitting. The robustness of the split-attention effect has been corroborated by numerous empirical investigations (for a meta-analysis, see \citealt{ginns_meta-analysis_2005}) and has been applied and found support in studies on subtitle perception, which bears some similarities to technology-supported SI due to its multi-modality (on the positive effects of integrated subtitles, see for instance \citealt{fox_can_2018}).

\subsubsection{Redundancy and modality} \label{redundancy_modality}
An important addition to the split-attention principle came from a study conducted by \citet{chandler_cognitive_1991}. The study revealed that an important prerequisite for the split-attention effect to occur is that the information presented in an integrated format must not be redundant. On this basis, the redundancy principle postulates that having to integrate redundant information poses an unnecessary load on WM hindering information processing, as part of the processing capacity is devoted to the mental integration of the redundant sources of information. This understanding is also valuable for CASI. As discussed above (\sectref{chandler_sweller_CLT}), experience affects the germane load of a task. In dealing with specialised terminology, provided that the aural information has been clearly perceived and correctly decoded by the interpreter, a term visually presented on screen may be perceived as redundant if effective terminological preparation has occurred and/or the term is available in the interpreter's LTM, or if strategies are applied to bypass the difficulty posed by the speaker's use of a specialised term. This may be expected to occur especially for terms automatically suggested by an ASR system, which currently does not discriminate between the terms presented (but see \citealt{vogler_lost_2019} for an alternative approach), as the interpreter has no control over what is shown on the screen. In other words, unnecessary multi-modal presentation of a stimulus term may impose additional extraneous load which may impair processing, rather than facilitate it by alleviating WM.

The split-attention effect operates on the extraneous load by reducing the strain imposed on WM. The modality effect arises from a different approach, i.e. expanding WM capacity. In alignment with \citegen{baddeley_human_1990} model of WM, this may be achieved by dividing information processing between the subsystem devoted to processing auditory stimuli and the buffer devoted to visual stimuli. As for the split-attention effect, a positive effect of modality only occurs if the information presented across different modes is not redundant. A positive modality effect may occur in SI supported by an ASR system if the interpreter has not heard a term pronounced by the speaker or has not been able to decode it and the term is presented on the screen: in other words, if the system processes the term for the interpreter. Additionally, the visual presentation of terms on the screen may be beneficial due to the transient information effect, which occurs ``when learning is reduced as a result of current information such as speech or animations being replaced by new'' \citep[242]{mayer_modality_2014}.

The modality effect has been formulated within studies in the field of learning psychology and instructional design, which have mainly considered the combination of images or graphs and of instructional cues in written or auditory format. As, according to the WM model by Baddeley and Hitch, verbal information is coded by the PL (see \sectref{workingmemory}), the presentation of completely redundant verbal information in auditory and visual form may not alleviate WM by distributing information processing across two separate buffers. However, as observed by \citet{seeber_multimodal_2017}, SI is a ``noisy environment'' (p. 464): a term presented in auditory and visual information may therefore not be perceived as entirely redundant. Rather, the multi-modal presentation may facilitate processing especially during comprehension through multi-modal integration (for a thorough discussion of multi-modal processing in SI, see \citealt{seeber_multimodal_2017}). However, as both the visual and the auditory stimuli are presented in the verbal code, there might be a negative trade-off due to interference, although multitasking may still be possible as the information is presented in different perceptual modalities, as predicted by Wickens (see \sectref{interference}).



\subsection{Cognitive load as time-based resource sharing} \label{barrouillet}
Despite the structural differences in the models of (working) memory proposed by Baddeley and Hitch and Cowan (see \sectref{workingmemory}), a notion shared by both theories is that of memory decay. Because of the inherent limitation of WM, due to the processing-retention trade-off, items temporarily stored in memory decay if they are not refreshed or attended to, which leads to performance deterioration. This is particularly relevant in multitasking, where information retention and processing compete for cognitive resources.

\citet{barrouillet_time_2004} look at CL in terms of the time allocated to the items that must receive attention in order to be processed. Their model reconciles previously held views that the inherent limitation of WM was dependent on the amount of cognitive resources available (a matter of resource-sharing) and other models which define WM spans as dependent on the duration of the processing component (and thus view it as a question of time-sharing, see \citealt{towse_is_1995}). Barrouillet and his colleagues posit that:

\begin{enumerate}
\item attention is required both by storage and by processing, and, being limited, it must be shared between the two;
\item when attention is switched away from retention, memory traces decay;
\item information retrieval from memory is constrained by a central bottleneck \citep{pashler_psychology_1998,rohrer_when_1998}, which requires attention (and so maintenance suffers);
\item if processing involves retrieval tasks, attention sharing is time-based due to the aforementioned bottleneck, and can thus be viewed as rapid switching between processing and maintenance.
\end{enumerate}
Barrouillet and colleagues define CL as the number of retrievals:time ratio for tasks in which retrievals are all of the same type and difficulty. Thus, CL can be measured as the time during which attention is captured. This understanding of CL may also be applied to translation and interpreting, which share similar processes of information retrieval from LTM for target text production. The availability of a system which takes care of information retrieval (in the form of a translation memory or of an ASR system for terminology) on the part of the translator and the interpreter may have beneficial effects on processing time and alleviate CL. If, however, processing of the visually presented information requires a considerable amount of attentional resources, attention may be diverted from retention of the auditory input, with potentially negative effects on task performance and, as predicted by the model, also in terms of processing speed.

\section{Cognitive implications in interpreting} \label{interpreting_cognitive}\largerpage
The models and theories discussed so far were developed within the field of cognitive and learning psychology. Due to the highly influential role played by these disciplines in the early development of research paradigms for Interpreting Studies (see \citealt[61]{pochhacker_introducing_2004}, \citealt{ferreira_position_2015}), the notions of WM, CL, attention allocation and resource sharing have found wide adoption in the theoretical and empirical inquiry into the black box of the interpreter's mind.


As discussed in the previous sections, the main criticisms towards the possibility of integrating digital support tools into the in-process phase of interpreting may be traced back to a view of interpreting primarily in terms of cognitive processing and specifically as a matter of resource sharing and attention allocation to several co-occurring tasks (see \sectref{CAI_attitudes}). Early models of the cognitive processes involved in SI approaching this activity from the perspective of multitasking have favoured a bird's eye-view of the issue. They have taken the valuable step of identifying relevant sub-processes involved in SI \citep{lederer_traduction_1981} and of underscoring the capacity constraints which affect multiple task performance \citep{kirchhoff_simultaneous_1976}.

In the present study, I adopt a ``micro-cognitive approach'' \citep[57]{martin_translation_2020} to the analysis of specific conditions under which SI occurs, investigating the effects of consulting digital terminological resources as a way to cope with specialised terms, common problem triggers in SI. In doing so, I will focus on the effects on the CL of the co-occurring tasks of interpreting and interacting with the computer.

Therefore, in the following sections, I discuss and compare two cognitive processing models of (simultaneous) interpreting which have approached the phenomenon primarily as a question of multitasking: Gile's Effort Model of SI and Seeber's Cognitive Load Model (CLM) of SI. 

These models interpret issues surfacing in the interpretation as problems in the allocation of limited cognitive resources between competing tasks.

There are several reasons for choosing to focus on this subset of models over other cognitive, psycholinguistic and neurolinguistic/neurophysiological models of SI (see p. \pageref{paradigm}--\pageref{paradigmEnd} in the Introduction). First, both Gile's and Seeber's models are cognitive models from the area of Cognitive Interpreting Studies which the present work is situated into and are grounded in the notions of cognitive psychology discussed in the previous sections of this chapter. Second, they have already been adopted as a theoretical reference in CAI research (see \sectref{CAI_evaluation}). Third, they allow modelling the interaction with external written traces (e.g. glossaries and transcripts of the ST) in addition to the internal interaction and competition between cognitive subprocesses. As such, they allow modelling several sources of cognitive load, both intrinsic and extraneous (see \sectref{chandler_sweller_CLT}). Fourth, they both appear directly relevant to the present research object. Gile's Effort Model of SI incorporates specifically specialised terminology as a source of increased effort, whereas Seeber's CLM has already been applied and validated in studies on simultaneous interpreting with text, which shares many features with CASI (as discussed in \sectref{mymodel}), in particular in terms of the interpretation of specialised terminology. Finally, they lend themselves to being tested in a laboratory environment while allowing to study SI under relatively naturalistic conditions.

After illustrating and discussing the models, I motivate the theoretical framework chosen for the present empirical investigation and discuss its application to the present object of inquiry.
\subsection{Gile's Effort Model of simultaneous interpreting} \label{gile}
\citet{gile_partage_1988,gile_conference_1997,gile_testing_1999} developed his Effort Models (EM) to explain why errors, omissions and ``infelicities'' (EOIs, see \citealt{gile_errors_2011,gile_effort_2015}), i.e. suboptimal rendition of the source speech, occur in interpreting. As specified by the author, the EMs should not be considered as ``operational testing or calibrating'' \citep[18]{gile_processing_1991} tools but were rather designed for the classroom to intuitively explain certain phenomena that can be observed in SI \citep[188]{gile_basic_2009}. For this reason, they have been regarded as a useful pedagogical tool. Nonetheless, the EMs have encountered the favour of many researchers and have been adopted as a conceptual framework ``with explanatory and predictive potential on the level of actual interpreting performance'' \citep[2]{gile_testing_1999}.

In developing his models, Gile refers to a key concept widely accepted in cognitive psychology and put forward by \citet{shannon_mathematical_1949}, i.e. that controlled processes are managed by an inherently limited system, developing further the considerations expressed by \citet{kirchhoff_simultaneous_1976}. Such is the case in interpreting, which involves several sub-processes. These operations are not automatic, but rather require the active allocation of limited cognitive resources. Through the development of interpreting expertise, however, some components of these inherently controlled operations can become automatic, freeing up more processing capacity and reducing the chances of EOIs.

Gile defines the sub-processes involved in interpreting as ``efforts'' and identifies:\largerpage

\begin{itemize}
\item a listening and analysis effort (L), or more generally, a reception effort (R), as it was later renamed to account for visual perception during sign language interpreting and of additional visual inputs (e.g. PowerPoint presentations)
\item a memorisation effort, i.e. the storage of the information to be processed in memory (M)
\item a production effort, i.e. the delivery of the message in the target language (P), including self-monitoring
\item a coordination effort (C) which is responsible for the allocation of the attentional resources and the successful concurrent performance of the above-mentioned sub-tasks
\end{itemize}
SI is thus defined as the sum of the three efforts:
\[ \text{SI} = \text{L (or R)} + \text{M} + \text{P} + \text{C}\]

Gile assumes that if the sum of the resources required by the different efforts does not exceed the sum of the attentional capacities available, then SI is feasible: 
\[\text{SI} = \text{R (the sum of attentional resources for each effort)} \leq \text{A.}\]

The same is true for each sub-process, which must not recruit ``more than the specific capacity available to it'' \citep{setton_models_2003}. Otherwise, problems arise. It is important to clarify that the additivity of the efforts is not intended in the arithmetic sense, as the efforts also overlap and compete for resources (\citealt[184]{gile_basic_2009}, \citealt[4]{gile_testing_1999}).

The equation should not be seen as static either, but can rather vary during the interpreting process according to variations in task difficulty. In this respect, \citet{gile_local_2008} introduces the notion of ``local cognitive load'' to indicate that overload may happen around occasional sources of difficulty.

Gile's EM of SI is integrated by the Tightrope Hypothesis \citep{gile_testing_1999}, i.e. the assumption that interpreters work close to saturation levels most of the time \citep[198]{gile_basic_2009}. Like tightrope walkers, interpreters must constantly strive to keep their balance between the individual sub-tasks which require careful coordination. According to Gile, EOIs therefore arise when the system is saturated as the interpreter experiences cognitive overload due to the inability to effectively deal with what \citet[157]{gile_testing_1999} defines as ``problem triggers'', e.g. proper names, specialised terms, numbers and enumerations, as they require increased cognitive resources, or because of suboptimal allocation of resources to the individual efforts. This is particularly true for novices, while expert interpreters may be better capable to effectively deal with problem triggers and may have better resource management, but are nonetheless constantly exposed to the risk of cognitive saturation.




A second addition to the effort models is the Gravitational Model of Language Availability (see also \sectref{featurestermwint}), which is useful to intuitively explain why specialised terminology may trigger overload or processing issues. Gile added this component based on the observation that the effortfulness of speech comprehension and production was influenced by the availability of ``Units of Linguistic Knowledge''. When words or expressions are used often, they are more readily available (they gravitate to the centre of the model). Otherwise, they tend to drift outwards, and their understanding and/or production is more effortful. According to the Gravitational Model, technical terms which cannot easily be retrieved from LTM may impose heightened attentional requirements on the listening effort (as the term may not be easily recognised and understood) as well as on the production effort. Interpreters may cope with such problem triggers by consulting electronic dictionaries or digital glossaries, although this may require time and attention \citep[219]{gile_basic_2009}.

Although reference is quite often made to ``the'' Effort Model to designate the EM of SI, Gile developed several effort models to provide an intuitive representation of the efforts involved in different modes of interpreting, e.g. SI with text, consecutive interpreting, interpreting from sign languages, and even remote interpreting. Where additional components seem to require considerable additional efforts on the part of the interpreter at the detriment of other efforts, Gile adds effort components to the equation, such as the human-machine interaction (HMI) effort for remote interpreting, a notion which may also be applied to SI with digital terminological support.

Despite the conceptual nature of the Effort Models, they have been adopted as a research framework in a number of studies. Most of these studies have provided support for the notion that the efforts are not automatic \citep[19]{gumul_searching_2018} and that the human processing capacity is limited, a generally-accepted principle which is also at the core of Baddeley and Hitch's model of WM (\citealt{bower_working_1974}, see \sectref{workingmemory}). Additionally, the findings by several studies (e.g. \citealt{gile_testing_1999,gumul_searching_2018,gile_errors_2011,matysiak_controlled_2001}), including a recent ERP study by \citet{koshkin_testing_2018} have been interpreted as support for the tightrope hypothesis.

Gile's Effort Models have been subjected to criticism by other interpreting scholars. For instance, \citet{pym_omission_2008} conducted an additional analysis of omissions in \citegen{gile_testing_1999} experiment stressing their functional role, which is not in contrast with the key principles of the model, but not explicitly included either. Other researchers have criticised the lack of temporal resolution of the model \citep{pochhacker_introducing_2016}. The harshest critic of the model is \citet{seeber_cognitive_2011}, who focuses on the tightrope hypothesis. Seeber agrees that the tightrope hypothesis aptly describes cases in which the source speech presents specific sources of difficulty, such as high delivery rate, non-native accent or high information density. However, he observes that multitasking may very well be possible in interpreting, as commonly observed among professional interpreters, who, unlike budding interpreters, in some cases may have enough cognitive resources left to spare. The misunderstanding about the EM (e.g. \citealt{gile_effort_2017}) probably originates from Seeber's view of the interpreting process from the perspective of cognitive psychology, which leads him to interpret the equation provided by Gile in the Effort Models as a reflection of \citegen{kahneman_attention_1973} single resource theory (see \sectref{interference}), or to equate the memory effort with WM and the coordination effort with \citegen{bower_working_1974} CE. Since the effort models present some parallels with key concepts of cognitive psychology\footnote{For instance, the non-automaticity of the sub-processes, the inherent limitation of the processing capacity, the idea of attention allocation and of task interference.}, it is easy to understand where the misunderstanding stems from, as discussed by \citet{gile_basic_2009} himself. After all, similar interpretations of Gile's Effort Models can also be found among cognitive psychologists \citep{gile_basic_2009}.



Gile responded to these criticisms in subsequent and regular updates of the models (e.g. \citealt{gile_effort_2016, gile_effort_2017, gile_2020_2020}). He observed that most criticism stems from the use of the models in empirical cognitive explorations of the interpreting process despite them having been conceived to provide a ``holistic and intuitive'' \citep[10]{gile_effort_2017} explanation of EOIs. The intended use of the models is to provide prospective interpreters with a functional explanation of why problems arise in interpreting, and to help them develop and reflect upon tactics and strategies to be used in interpreting \citep{gile_2020_2020}.

Nonetheless, \citet[205]{gile_basic_2009} claims that ``the competition-between-Efforts principle is consistent with the theory of one central pool of processing capacity, not with the theory that there may be several pools that the Efforts can draw upon without there being interference with them''. However, a multiple resource model does not negate interference. Rather, it offers a framework to differentiate between tasks which can be performed simultaneously without interference and tasks which interfere, and to describe the extent to which they do. If analysed from the perspective of theories formulated in cognitive psychology, it seems to me that \citegen{gile_basic_2009} ``competition hypothesis'' may also be explained by the interference of sub-tasks which draw from separate dimensions but share resources. This would be compatible with Wickens's model (\sectref{interference}). Indeed, empirical evidence taken as support of the tightrope hypothesis \citep{koshkin_testing_2018,gumul_searching_2018} mainly points to interference between efforts, but does not explore the structural reason for this interference. After all, the EM does not aim to provide an architectural explanation underlying information processing.



The notion that the co-existence of multiple ``efforts'' may increase capacity requirements \citep[156]{gile_testing_1999} would also hold true within the framework of an architectural model assuming interference between tasks which share resources in some dimension (e.g. Wickens's multiple resource model, see \sectref{interference}). This is the case for SI, during which auditory-verbal resources are required both in the reception phase (Listening + Analysis Effort) and in the response phase (Production Effort). Additionally, Gile suggests that it might be useful to ``develop `tuning' or `scaling' rules for the quantification of processing capacity or time requirements for interpretation tasks'' \citep[18]{gile_processing_1991}. This may be achieved through the ``demand vectors'' proposed by \citet{wickens_effects_1976,wickens_processing_1984,wickens_multiple_2002}. Finally, the assumption that interpreters' resources are at risk of saturation most of the time has not yet received empirical support, as suggested by cases of perfect time-sharing (\citealt{schumacher_virtually_2001}, see also \citealt{seeber_cognitive_2011}). Gile concedes that ``though the evidence supports the hypothesis of cognitive saturation, it does not necessarily show that such saturation occurs at global level'' \citep[61]{gile_local_2008}. \citegen{seeber_cognitive_2012} eyetracking study also found support for a local increase of CL, rather than a general increase of pupil dilation compared to the baseline. Note, however, that the tightrope hypothesis does not state how close interpreters supposedly come to saturation \citep{gile_biases_2017}. Gile further observes that pupillometry can only capture instances of heightened load if the interpreter does not intervene to prevent it, and thus the risk of overload may not show in the data. It would be interesting to conduct further studies using other physiological measures (see \sectref{neuromeasures_CL} for an overview), for instance sensitive to stress, which is likely to be experienced when having to deal with problem triggers, and to verify whether this correlates with pupillary dilation.

To sum up, Gile's EMs interpret EOIs in the TT as evidence of the competition between efforts recruiting resources from a single pool of mental capacity. The models have had the merit of conceptualising the idea of the distribution of resources between concurring tasks through a series of components (the tightrope hypothesis, the gravitational model, and the competition-between-efforts principle) which have proved quite productive in training.

The main limitation of the models for the present exploration of CASI lies in the lack of components modelling the structural nature of the interference between tasks and explaining why, for instance, the human-machine interaction and the listening or the production effort may compete for resources. This level of detail appears, however, essential for interventions on the design of support tools aiming to reduce such interference.

Furthermore, the lack of a clear stance as to the models' grounding in cognitive psychology, coupled with unresolved issues preventing an unequivocal validation of the tightrope hypothesis, represent limitations for the models' application to experimental research aiming for an operational testing of its theoretical framework, which the present study aspires to do. For these reasons, I examine Seeber's CLM of SI in the following section and I illustrate the motivation for choosing the CLM as theoretical framework for the present study in \sectref{choiceofmodel}.


\subsection{Seeber's Cognitive Load Model of Simultaneous Interpreting} \label{seeber}
Unlike Gile, Seeber explicitly derives his model from cognitive psychology. He adapts Wickens's model of task interference to SI, while introducing some variations \citep{seeber_thinking_2007}. First of all, he turns the three-dimensional model into a bi-dimensional model. This offers a double advantage. First, it enables to graphically represent all components of the model at once (some were ``hidden'' in the non-visible faces of the cube). Second, it reintroduces the general capacity, the pool of general resources postulated by Wickens, into the model, which did not previously fit into the cube. Seeber further expands the model by adding a Cognitive Resource Footprint (CRF), a visual representation of which resources are shared between the co-occurring tasks. Finally, he keeps Wickens's conflict matrix, with some modifications. Seeber uses this adaptation of Wickens's model, his own CLM, to represent and explore resource sharing during four language processing tasks: shadowing, sight translation, SI \citep[1383]{seeber_thinking_2007} and SI with text \citep{seeber_multimodal_2017}.

\subsubsection{Cognitive Load Model of Simultaneous Interpreting} \label{CLM_standard}
\flushbottom
Seeber describes SI as a combination of two main tasks: 1) a listening and comprehension task and 2) a production and monitoring task. Listening and comprehension recruits auditory-verbal and cognitive-verbal resources at the perceptual-cognitive stage: conference interpreters receive the auditory stimulus, i.e. the source speech as pronounced by the speaker, and must analyse the verbal message for comprehension. In a more recent adaptation of the model \citep{seeber_multimodal_2017}, a visual-spatial component was added to account for the paraverbal information the interpreter perceives while interpreting (for visual information in interpreting, see also \citealt{seubert_visuelle_2019}). Interpreters then ``respond'' to this stimulus by delivering the message in the target language. At the same time, they must monitor their own rendition. The production and monitoring task thus demands auditory-verbal and cognitive-verbal resources at the perceptual-cognitive stage and additional vocal-verbal resources at the response stage.

\figref{fig:CRF_SI} represents the CRF of SI with visual input.

\begin{figure}
\includegraphics[width=.75\linewidth]{images/Seeberlozenge.pdf}
\caption[Cognitive resource footprint for SI with visual input]{Cognitive resource footprint for SI with visual input \citep[468]{seeber_multimodal_2017}\label{fig:CRF_SI}}
\end{figure}

As described in \sectref{interference}, Wickens's model represents the level of dependence of a task on a resource by assigning demand vectors comprised between 0 (no dependence) and 2 (extreme dependence). Seeber postulates a demand vector of 1 for each of the concurring sub-tasks (resources), which in SI occur at both stages of processing (perception + cognition, responding), in both perceptual modalities (auditory and visual) and in the two processing codes (spatial and verbal). The revised model foresees three possible levels (0, 0.5, 1), where the use of half vectors serves to model complementarity between information sources (specifically between the auditory verbal and the visual spatial modalities/codes), while redundant information (see \sectref{redundancy_modality}) within a stage is represented with a full (1) demand vector \citep[481]{seeber_multimodal_2017}.

The sum of the demand vectors and conflict coefficients thus assigned to SI is equal to a total interference score (TIS) of 11.6 (Figure \ref{fig:CM_SI}).\footnote{In the original model \citep{seeber_thinking_2007}, the TIS was equal to 9. The higher score in the revised model \citep{seeber_multimodal_2017} is determined by the addition of demands on visual-spatial resources due to the inclusion of paraverbal information provided by the speaker.}

\begin{figure}
% % % \includegraphics[width=\linewidth]{images/CM_SI_visual.png}
	\resizebox{\textwidth}{!}{\begin{tikzpicture}[
			hea/.style={align=flush center,text width=1.33cm},
			rsma/.style={rotate=90},
			rhea/.style={align=flush center,text width=1.33cm,rotate=90},
			row 1/.style={minimum height=0.665cm},
			row 2/.style={minimum height=0.665cm},
			column 1/.style={minimum width=0.665cm},
			column 2/.style={minimum width=0.665cm},
			]
			\sffamily\footnotesize
			\matrix (prandifig3) [matrix of nodes, nodes in empty cells,ampersand replacement=\&] {
				\&  \&  \&  \&  \& ~ \&  \&  \&  \&  \&  \&  \\  %\multicolumn{8}{c}{listening \\& comprehension}\\
				\&  \&  \&  \&  \& ~ \&  \&  \&  \&  \&  \&  \\  % \multicolumn{4}{c}{perceptual} \& \multicolumn{2}{c}{cognitive} \& \multicolumn{2}{c}{response}\\
				\&  \&  \& {vector} \& {0.5} \& {$\emptyset$} \& {$\emptyset$} \& {0.5\vphantom{$\emptyset$}} \& {0.5} \& {0.5\vphantom{$\emptyset$}} \& {$\emptyset$} \& {$\emptyset$}\\
				\&  \& \node[rsma]{demand}; \&  \& \node[hea]{visual\linebreak spatial}; \& \node[hea]{visual\linebreak verbal}; \& \node[hea]{auditory\linebreak spatial}; \& \node[hea] (prandifig3-4-8) {auditory\linebreak verbal}; \& \node[hea]{cognitive\linebreak spatial}; \& \node[hea] (prandifig3-4-10) {cognitive\linebreak verbal}; \& \node[hea]{response\linebreak spatial}; \& \node[hea] (prandifig3-4-12) {response\linebreak verbal}; \\
				\&  \& \node[rsma] (prandifig3-5-3) {$\emptyset$}; \& \node[rhea]{visual\linebreak spatial};                       \& {0.8} \& {0.6} \& {0.6} \& {0.4} \& {0.7} \& {0.5} \& {0.4} \& {0.2}\\
				\&  \& \node[rsma] (prandifig3-6-3) {$\emptyset$}; \& \node[rhea]{visual\linebreak verbal};                        \& {0.6} \& {0.8} \& {0.4} \& {0.6} \& {0.5} \& {0.7} \& {0.2} \& {0.4}\\
				\&  \& \node[rsma] (prandifig3-7-3) {$\emptyset$}; \& \node[rhea]{auditory\linebreak spatial};                     \& {0.6} \& {0.4} \& {0.8} \& {0.4} \& {0.7} \& {0.5} \& {0.4} \& {0.2}\\
				\&  \& \node[rsma] (prandifig3-8-3) {1\vphantom{$\emptyset$}};           \& \node[rhea]{auditory\linebreak verbal};    \& {0.4} \& {0.6} \& {0.4} \& {0.8} \& {0.5} \& {0.7} \& {0.2} \& {0.4}\\
				\&  \& \node[rsma] (prandifig3-9-3) {$\emptyset$}; \& \node[rhea]{cognitive\linebreak spatial};                    \& {0.7} \& {0.5} \& {0.7} \& {0.5} \& {0.8} \& {0.6} \& {0.6} \& {0.4}\\
				\&  \& \node[rsma] (prandifig3-10-3) {1\vphantom{$\emptyset$}};           \& \node[rhea]{cognitive\linebreak verbal};  \& {0.5} \& {0.7} \& {0.5} \& {0.7} \& {0.6} \& {0.8} \& {0.4} \& {0.6}\\
				\&  \& \node[rsma] (prandifig3-11-3) {$\emptyset$}; \& \node[rhea]{response\linebreak spatial};                     \& {0.4} \& {0.2} \& {0.4} \& {0.2} \& {0.6} \& {0.4} \& {0.8} \& {0.6}\\
				\&  \& \node[rsma] (prandifig3-12-3) {1\vphantom{$\emptyset$}}; \& \node[rhea] (prandifig3-12-4) {response\linebreak verbal};   \& {0.2} \& {0.4} \& {0.2} \& {0.4} \& {0.4} \& {0.6} \& {0.6} \& {1.0}\\
			};
			\node [fit=(prandifig3-1-5)(prandifig3-1-12)] {listening comprehension};
			\node [fit=(prandifig3-2-5)(prandifig3-2-8)] {perceptual};
			\node [fit=(prandifig3-2-9)(prandifig3-2-10)] {cognitive};
			\node [fit=(prandifig3-2-11)(prandifig3-2-12)] {response};
			\node [overlay,fit=(prandifig3-5-2)(prandifig3-8-2)  ,rotate=90,text width=2.66cm,inner sep=0pt] {perceptual};
			\node [overlay,fit=(prandifig3-9-2)(prandifig3-10-2) ,rotate=90,text width=2.66cm,inner sep=0pt] {cognitive};
			\node [overlay,fit=(prandifig3-11-2)(prandifig3-12-2),rotate=90,text width=2.66cm,inner sep=0pt] {response};
			\node [overlay,rotate=90,fit=(prandifig3-5-1)(prandifig3-12-1),text width=8cm,inner sep=0pt] {production \& monitoring};
			\begin{scope}[on background layer]
				\foreach \i in {8,10,12} \node [fit=(prandifig3-\i-3)(prandifig3-\i-12), fill=black!12,minimum height=1.33cm,yshift=-.5ex] {};
				\foreach \j in {5,8,9,10} \node [fit=(prandifig3-3-\j)(prandifig3-12-\j), fill=black!12,minimum width=1.33cm,inner xsep=0pt] {};
				\foreach \x/\y in {8/5,8/8,8/9,8/10,10/5,10/8,10/9,10/10,12/5,12/8,12/9,12/10} \node [fit=(prandifig3-\x-\y), fill=black!50,minimum width=1.33cm,minimum height=1.33cm,yshift=-.75ex] {};
			\end{scope}
			\draw (prandifig3-4-12.south east) -| (prandifig3-12-4.south west);
			\draw (prandifig3-4-12.north east) -| (prandifig3-12-4.north west);
			\node (temp32113212) [overlay,fit=(prandifig3-2-11.south west)(prandifig3-2-12.south east),inner ysep=5pt] {}; \draw (temp32113212.north west) -- (temp32113212.north east);
			\node (temp3393310) [overlay,fit=(prandifig3-3-9.north west)(prandifig3-3-10.north east),inner ysep=5pt] {};\draw (temp3393310.north west) -- (temp3393310.north east);
			\node (temp335338) [overlay,fit=(prandifig3-3-5.north west)(prandifig3-3-8.north east),inner ysep=5pt] {};\draw (temp335338.north west) -- (temp335338.north east);
			\node (temp31133123) [overlay,fit=(prandifig3-11-3.north east)(prandifig3-12-3),inner xsep=5pt] {};\draw (temp31133123.north west) -- (temp31133123.south west);
			\node (temp3933103) [overlay,fit=(prandifig3-9-3.north east)(prandifig3-10-3),inner xsep=5pt] {};\draw (temp3933103.north west) -- (temp3933103.south west);
			\node (temp353383) [overlay,fit=(prandifig3-5-3.north east)(prandifig3-8-3),inner xsep=5pt] {};\draw (temp353383.north west) -- (temp353383.south west);
		\end{tikzpicture}
	}
	\begin{center}\scriptsize\tabcolsep=0.5\tabcolsep
		\begin{tabular}{@{}lclcl@{}}
			Total interference score & = & demand vectors & + & conflict coefficients\\
			& = & ($1+1+1+0.5+0.5+0.5+0.5$)    & + & $(0.4+0.5+0.2+0.8+0.7+0.4$\\
			& & & + & $0.5+0.6+0.4+0.7+0.8+0.6) = 11.6$ \\
		\end{tabular}
	\end{center}
\caption[Conflict matrix for SI with visual input]{Conflict matrix for SI with visual input \citep[469]{seeber_multimodal_2017}\label{fig:CM_SI}}
\end{figure}

The application of the model to the three tasks of shadowing, sight translation and SI operationalises the hypothesis that SI requires the higher amount of individual resources as compared to the other tasks, as it involves more concurrent sub-processes, which results in the highest level of task interference.

The CLM of SI in its original version (without the inclusion of visual information) was tested by \citet{seeber_cognitive_2012} in an eyetracking experiment on the effect of asymmetric syntactical structures between English and German on the interpreter's CL. The authors applied the CLM to represent local variations in CL for verb-final sentences and symmetrical structures, predicting higher CL for asymmetrical structures. The CLMs effectively predict that ``the interpretation of syntactically asymmetrical structures causes more CL than the interpretation of syntactically symmetrical structures towards the end of the sentence'' (ibid., p. 238). The CLM may thus be used not only to model interference between tasks on a global level (i.e. listening and comprehension vs monitoring and production), but also to formulate more in-depth hypotheses on local CL.

\citet{gieshoff_impact_2018,gieshoff_impact_2021} conducted an experiment aimed at verifying whether seeing the speaker's lip movements during SI reduces CL. Inter alia, she used silent pause duration as an indicator of CL and found that silent pauses were shorter when the speaker's lips were visible. Her findings lend support to the hypothesis that auditory-verbal and visual-spatial information is integrated, as predicted by the CLM in alignment with abundant empirical evidence on multimodal integration (see \sectref{redundancy_modality}). It should be noted that pupillometric data did not support the hypothesis, though Gieshoff interpreted larger pupils for the multimodal condition as an indicator of higher arousal rather than increased cognitive effort \citep[242]{gieshoff_impact_2018}.\largerpage

\citet{seubert_visuelle_2019} also investigated the processing of visual information during SI with an exploratory eyetracking study conducted on a sample of 13 professional interpreters. The naturalistic research design, which favours the proximity to a real-life interpreting situation rather than a strict control of empirical variables, does not allow for an in-depth analysis of the cognitive interactions between different types of visual support with the interpreting process. Nonetheless, Seubert's research provides valuable observations, some of which offer support to the predictions of the CLM. In particular, the reported strategic behaviour of experienced professionals in dealing with different sources of visual input supports Seeber's hypothesis that strategies modulate the allocation of cognitive resources in order to avoid cognitive overload, and that the supportive or distracting potential of visual input depends, inter alia, also on the type of input processed. For instance, the observation that Seubert's test subjects devoted a high proportion of their visual attention to the speaker supports the hypothesis that paraverbal information may provide a valuable integration of the auditory channel. This is in line with Gieshoff's findings for lip movements, although in Seubert's experiment the speaker area of interest was much larger due to the situated nature of her experiment. It also aligns with the predictions of the CLM, but it should be noted that Seubert did not explicitly test such predictions. Her finding that informants' visual processing behaviour varied along with the (postulated) variations in CL during the interpreting session is also valuable. Before and after their interpreting turn, the interpreters' visual perceptual field appears to be larger than during the more cognitively demanding phases, which Seubert interprets as a higher amount of cognitive resources available for visual processing due to a lower CL (supporting Lavie's theory, as discussed in \sectref{attention}). This observation also supports the idea that the assumptions of the tightrope hypothesis \citep{gile_testing_1999} may be valid more on a local level rather than on a global level, as pointed out in \citet{seeber_cognitive_2012}.

\subsubsection{Cognitive Load Model of SI with text} \label{CLM_with text}
The addition of the visual-spatial component to the CLM does not include written information, which according to standard models of WM is processed in the PL, while gestures, lip movements and expressions are processed in the VSSP (see \sectref{workingmemory}). To account for the processing of visual-verbal (written) information during SI, \citet{seeber_multimodal_2017} applied his model to a specific instantiation of SI with written information, i.e. SI with the full transcript of the speech (SIMTXT). For SIMTXT, the inclusion of the written text requires the addition of visual-verbal resources to the cognitive resource footprint (Figure \ref{fig:CRF_SIMTXT}).

\begin{figure}
\includegraphics[width=.75\linewidth]{images/Figure34.pdf}
\caption[Cognitive resource footprint for SIMTXT]{Cognitive resource footprint for SI with text \citep[471]{seeber_multimodal_2017}\label{fig:CRF_SIMTXT}}
\end{figure}

In the conflict matrix, visual-verbal processing is added to the listening and comprehension phase and receives a full demand vector. The attribution of a demand vector of 1 reflects the duplication of aural information in written form. Hence, the total interference score is higher than for SI without written input (14.3), as can be seen from the expanded conflict matrix (Figure \ref{fig:CM_SIMTXT}).

\begin{figure}
% % \includegraphics[width=\linewidth]{images/CM_SIMTXT.png}
\resizebox{\textwidth}{!}{\begin{tikzpicture}[
			hea/.style={align=flush center,text width=1.33cm},
			rsma/.style={rotate=90},
			rhea/.style={align=flush center,text width=1.33cm,rotate=90},
			row 1/.style={minimum height=0.665cm},
			row 2/.style={minimum height=0.665cm},
			column 1/.style={minimum width=0.665cm},
			column 2/.style={minimum width=0.665cm},
			]
			\sffamily\footnotesize
			\matrix (prandifig3) [matrix of nodes, nodes in empty cells,ampersand replacement=\&] {
				\&  \&  \&  \&  \& ~ \&  \&  \&  \&  \&  \&  \\  %\multicolumn{8}{c}{listening \\& comprehension}\\
				\&  \&  \&  \&  \& ~ \&  \&  \&  \&  \&  \&  \\  % \multicolumn{4}{c}{perceptual} \& \multicolumn{2}{c}{cognitive} \& \multicolumn{2}{c}{response}\\
				\&  \&  \& {vector} \& {0.5} \& {1} \& {$\emptyset$} \& {0.5\vphantom{$\emptyset$}} \& {0.5} \& {1\vphantom{$\emptyset$}} \& {$\emptyset$} \& {$\emptyset$}\\
				\&  \& \node[rsma]{demand}; \&  \& \node[hea]{visual\linebreak spatial}; \& \node[hea]{visual\linebreak verbal}; \& \node[hea]{auditory\linebreak spatial}; \& \node[hea] (prandifig3-4-8) {auditory\linebreak verbal}; \& \node[hea]{cognitive\linebreak spatial}; \& \node[hea] (prandifig3-4-10) {cognitive\linebreak verbal}; \& \node[hea]{response\linebreak spatial}; \& \node[hea] (prandifig3-4-12) {response\linebreak verbal}; \\
				\&  \& \node[rsma] (prandifig3-5-3) {$\emptyset$}; \& \node[rhea]{visual\linebreak spatial};                       \& {0.8} \& {0.6} \& {0.6} \& {0.4} \& {0.7} \& {0.5} \& {0.4} \& {0.2}\\
				\&  \& \node[rsma] (prandifig3-6-3) {$\emptyset$}; \& \node[rhea]{visual\linebreak verbal};                        \& {0.6} \& {0.8} \& {0.4} \& {0.6} \& {0.5} \& {0.7} \& {0.2} \& {0.4}\\
				\&  \& \node[rsma] (prandifig3-7-3) {$\emptyset$}; \& \node[rhea]{auditory\linebreak spatial};                     \& {0.6} \& {0.4} \& {0.8} \& {0.4} \& {0.7} \& {0.5} \& {0.4} \& {0.2}\\
				\&  \& \node[rsma] (prandifig3-8-3) {1\vphantom{$\emptyset$}};           \& \node[rhea]{auditory\linebreak verbal};    \& {0.4} \& {0.6} \& {0.4} \& {0.8} \& {0.5} \& {0.7} \& {0.2} \& {0.4}\\
				\&  \& \node[rsma] (prandifig3-9-3) {$\emptyset$}; \& \node[rhea]{cognitive\linebreak spatial};                    \& {0.7} \& {0.5} \& {0.7} \& {0.5} \& {0.8} \& {0.6} \& {0.6} \& {0.4}\\
				\&  \& \node[rsma] (prandifig3-10-3) {1\vphantom{$\emptyset$}};           \& \node[rhea]{cognitive\linebreak verbal};  \& {0.5} \& {0.7} \& {0.5} \& {0.7} \& {0.6} \& {0.8} \& {0.4} \& {0.6}\\
				\&  \& \node[rsma] (prandifig3-11-3) {$\emptyset$}; \& \node[rhea]{response\linebreak spatial};                     \& {0.4} \& {0.2} \& {0.4} \& {0.2} \& {0.6} \& {0.4} \& {0.8} \& {0.6}\\
				\&  \& \node[rsma] (prandifig3-12-3) {1\vphantom{$\emptyset$}}; \& \node[rhea] (prandifig3-12-4) {response\linebreak verbal};   \& {0.2} \& {0.4} \& {0.2} \& {0.4} \& {0.4} \& {0.6} \& {0.6} \& {1.0}\\
			};
			\node [fit=(prandifig3-1-5)(prandifig3-1-12)] {listening \& reading comprehension};
			\node [fit=(prandifig3-2-5)(prandifig3-2-8)] {perceptual};
			\node [fit=(prandifig3-2-9)(prandifig3-2-10)] {cognitive};
			\node [fit=(prandifig3-2-11)(prandifig3-2-12)] {response};
			\node [overlay,fit=(prandifig3-5-2)(prandifig3-8-2)  ,rotate=90,text width=2.66cm,inner sep=0pt] {perceptual};
			\node [overlay,fit=(prandifig3-9-2)(prandifig3-10-2) ,rotate=90,text width=2.66cm,inner sep=0pt] {cognitive};
			\node [overlay,fit=(prandifig3-11-2)(prandifig3-12-2),rotate=90,text width=2.66cm,inner sep=0pt] {response};
			\node [overlay,rotate=90,fit=(prandifig3-5-1)(prandifig3-12-1),text width=8cm,inner sep=0pt] {production \& monitoring};
			\begin{scope}[on background layer]
				\foreach \i in {8,10,12} \node [fit=(prandifig3-\i-3)(prandifig3-\i-12), fill=black!12,minimum height=1.33cm,yshift=-.5ex] {};
				\foreach \j in {5,6,8,9,10} \node [fit=(prandifig3-3-\j)(prandifig3-12-\j), fill=black!12,minimum width=1.33cm,inner xsep=0pt] {};
				\foreach \x/\y in {8/5,8/6,8/8,8/9,8/10,10/5,10/6,10/8,10/9,10/10,12/5,12/6,12/8,12/9,12/10} \node [fit=(prandifig3-\x-\y), fill=black!50,minimum width=1.33cm,minimum height=1.33cm,yshift=-.75ex] {};
			\end{scope}
			\draw (prandifig3-4-12.south east) -| (prandifig3-12-4.south west);
			\draw (prandifig3-4-12.north east) -| (prandifig3-12-4.north west);
			\node (temp32113212) [overlay,fit=(prandifig3-2-11.south west)(prandifig3-2-12.south east),inner ysep=5pt] {}; \draw (temp32113212.north west) -- (temp32113212.north east);
			\node (temp3393310) [overlay,fit=(prandifig3-3-9.north west)(prandifig3-3-10.north east),inner ysep=5pt] {};\draw (temp3393310.north west) -- (temp3393310.north east);
			\node (temp335338) [overlay,fit=(prandifig3-3-5.north west)(prandifig3-3-8.north east),inner ysep=5pt] {};\draw (temp335338.north west) -- (temp335338.north east);
			\node (temp31133123) [overlay,fit=(prandifig3-11-3.north east)(prandifig3-12-3),inner xsep=5pt] {};\draw (temp31133123.north west) -- (temp31133123.south west);
			\node (temp3933103) [overlay,fit=(prandifig3-9-3.north east)(prandifig3-10-3),inner xsep=5pt] {};\draw (temp3933103.north west) -- (temp3933103.south west);
			\node (temp353383) [overlay,fit=(prandifig3-5-3.north east)(prandifig3-8-3),inner xsep=5pt] {};\draw (temp353383.north west) -- (temp353383.south west);
		\end{tikzpicture}
	}
	\begin{center}\scriptsize\tabcolsep=0.5\tabcolsep
		\begin{tabular}{@{}lclcl@{}}
			Total interference score & = & demand vectors & + & conflict coefficients\\
			& = & ($1+1+1+0.5+1+0.5+0.5+1$)    & + & $(0.4+0.5+0.2+0.6+0.7+0.4$\\
			& & & + & $0.8+0.7+0.4+0.5+0.6+0.4$\\
			& & & + & $0.7+0.8+0.6) = 14.8$
		\end{tabular}
	\end{center}
\caption[Conflict matrix for SIMTXT]{Conflict matrix for SI with visual-verbal input \citep[472]{seeber_multimodal_2017}\label{fig:CM_SIMTXT}}
\end{figure}

The application of Seeber's CLM of SIMTXT was adopted as a theoretical framework in a recent experiment by \citet{seeber_when_2020} and by \citet{chmiel_eye_2020}. Seeber and colleagues report on an eyetracking experiment designed to test how attention is allocated to redundant written information during SI. The authors contrasted SIMTXT with reading while listening (RWL) as a control task. They found that interpreters attend to the visual-verbal support during their production, probably in order to ``offload short term memory'' \citep[13]{seeber_when_2020}, rather than exploiting redundancy effects to improve their comprehension. This is in line with Seeber's CLM which postulates the attribution of shared vectors to visual-spatial and auditory-verbal resource demands (i.e. for complementary information), and not for visual-verbal and auditory-verbal stimuli. In essence, their redundancy may require excessive effort for their integration to be possible in the listening and comprehension phase, but may prove beneficial during the production phase to assist with control processing.

\citet{chmiel_eye_2020} investigated source language interference in an English to Polish SI and sight translation (ST) task. They measured the number of cognates, homographs and passive structures, in addition to time lag and total translation time as indicators of CL, adapting Seeber's CLM to operationalise their hypotheses. They observe that in ST the visual-verbal input is the only source of information, and thus its processing differs from SIMTXT and would deserve different values for the demand vectors and the conflict coefficient, though they do not explain what demand vector may be assigned for ST. Additionally, they propose a higher conflict coefficient for cognitive verbal vs response verbal demands in ST based on the inherent higher complexity of textual processing, but this contrasts with Wickens's observation that ``the adjustment of conflict values should not be based on differences in single task demands, since these [are] captured by the single task analysis shell'' \citep[170]{wickens_multiple_2002}. Furthermore, in their adaptation, they do not mention removing the visual-spatial component, which \citet{seeber_multimodal_2017} had added to account for paraverbal information from the speaker. In ST, this component is not relevant. This would have probably resulted in an even lower TIS for ST than for SI. Their findings on time lag (longer for ST than for SI) did not elicit a unequivocal interpretation, as the external pacing in SI inherently affects time lag in SI. Additionally, total translation time was found to be longer in SI, which, contrary to their predictions, might point to higher CL in SI than in ST. Despite some limitations in the authors' adaptation of the model, the CLM proved a valuable tool for the formulation of hypotheses on SI with text.


In her 2019 experiment, Seubert also included written support material in the wide array of visual input presented to her test subjects. She did so by observing the interpreters' behaviour during the interpretation of citations, which they had not prepared beforehand \citep[198]{seubert_visuelle_2019}. Seubert reports that, when faced with longer text passages, 8 out of 11 interpreters averted their gaze from the speaker and the slide containing the quote. She interprets this as an indication of higher cognitive effort, which is corroborated by numerous hesitations and deficient content in the renditions (ibid., p. 209). This observation may lend support to the hypothesis that redundant information replicated across two different channels may lead to an increase in CL, which the CLM predicts. It is interesting to observe that for more isolated textual information, which only partially replicates the spoken input (e.g. the presentation table of contents, p. 199), the interpreters' gaze continuously switched from the speaker to the slides, which Seubert interprets as an indication that this type of visual support may be useful both for the planning and for the production and monitoring phase (p. 205). These findings partially contrasts with \citegen{seeber_when_2020} findings that redundant textual support is used mainly in the production phase. It should be noted that Seeber's experiment was conducted in a laboratory setting under stringent variable control, which reduced the visual input to the speech transcript. In Seubert's experiment, the sheer amount of sources of visual information may have contributed to the perceptual overload which led the interpreters to avert their gaze and not to consult the slides containing the quotes. Her second observation that isolated information is consulted during both phases should be confirmed under more strict experimental conditions. However, I should mention that her findings were for a very specific type of support, i.e. a table of contents, which is different from a speech transcript and may therefore also require fewer plausibility checks on the part of the interpreters, as they may expect it to be a reliable source of information with fewer discrepancy than the written transcript compared to the spoken discourse. Different findings for different types of visual support further corroborate Seeber's observation that ``although signal complementarity and signal redundancy appear to be important components of our natural environment, and we seem to have evolved to expect and rely on them, the way in which we process them may well depend on the composition of the signal'' \citep[463]{seeber_multimodal_2017}. Conducting targeted studies on visual input during interpreting therefore seems motivated.

The analysis of Seeber's CLM and of relevant research in the area of simultaneous interpreting with visual support has highlighted how Seeber's conceptualisation of SI and SIMTXT may represent a more suited theoretical starting point for the present study than Gile's EMs (see \sectref{gile}). The following section reviews the main differences between the two models and illustrates the rationale behind the choice of Seeber's CLM for the present inquiry.

\subsection{Discussion and choice of a model for the present work} \label{choiceofmodel}
The two models which have been in focus in the previous sections (\sectref{gile}, \sectref{seeber}) represent SI essentially as a multitasking activity. They both postulate a limited attentional capacity constraining WM (though Gile refers to a more general ``Memory Effort'', see \citealt{gile_basic_2009}) and explicitly include the processing of textual information during SI \citep{gile_basic_2009,gile_2020_2020,seeber_multimodal_2017}.\footnote{Although they are not the only models to do so. Other authors from different research paradigms have also included visual information in their models (for a review, see \citealt{seubert_visuelle_2019}).} The textual component is pertinent to the present inquiry since terminology support is also presented in the visual-verbal modality and in part replicates the auditory input.





One important difference lies in Seeber's clear stance as to which framework he grounds his model in, i.e. Wickens's multiple resource theory. As such, his model is clearly rooted in cognitive psychology. As the present work is conducted within a cognitive processing paradigm adopting consolidated methods derived from TPR, which have in turn largely been adopted (and adapted) from cognitive psychology, choosing Seeber's CLM as the theoretical framework to operationalise my hypotheses seems the more coherent approach. Additionally, the model has been used to effectively predict a number of effects of interaction with visual-verbal input in SI (as discussed in \sectref{CLM_with text}) and to my knowledge, no empirical evidence has been found yet to contrast its assumptions. Though the initial model did not provide for facilitation effects due to crossmodal integration \citep{seeber_thinking_2007}, Seeber's adaptation of Wickens's model through half-scores for the individual demand vectors allows to include such effects and to model hypotheses in this respect. In this sense, the CLM always posits higher or equal CL with the addition of further sub-tasks (e.g. interacting with a speech transcript or with a computer for terminology look-up), never lower.

Gile's Effort Model may be less strict in that in principle it allows to include facilitation effects by, for instance, combining auditory and visual processing in a single reception effort (see \citealt{gile_basic_2009}). If facilitation effects due to redundancy across different modalities were found (though, at present, this is not yet the case), the lower reception effort would leave more processing resources available for memory, coordination and production. However, it may be argued that, since aural and visual stimuli are processed separately, the elaboration of additional stimuli should be modelled as an extra effort, as suggests \citet[74]{gieshoff_impact_2018}. This would require distributing attentional capacities across a higher number of sub-tasks, with fewer resources available for each task.

As for terms as problem triggers, they are discussed explicitly in \citet{gile_basic_2009} as potential causes of locally increased CL during SI. They may pose a higher load on the Reception Effort (if the term cannot be quickly recognised or identified) as well as on the Production Effort (if the target language equivalent is not available). As \citet{wickens_multiple_2002} postulates a three-tier system for the allocation of demand vectors, it may theoretically be possible to postulate higher demands also within the framework of Seeber's CLM, either for the listening and understanding task or for the production task, or for both.

Despite the differences discussed above, evidence congruent with both accounts of multitasking during interpreting has been found (among recent studies, see for instance \citealt{chmiel_eye_2020,gieshoff_impact_2021,seeber_when_2020}). Yet, the two models have often been contrasted as antithetic, as stressed by \citet{seeber_cognitive_2011} himself. Approaching inquiries into CL from the perspective of cognitive psychology, Seeber views Gile's model as reflective of Kahneman's single resource theory, which contrasts with his CLM based on Wickens's multiple resource theory. As discussed above (\sectref{gile}), Gile does not support this interpretation of his model and further criticises the CLM as ``not indicative of what actually happens in the booth'' \citep[9]{gile_2020_2020}. In my view, the two models do not necessarily contradict each other. Rather, Gile's EM offers a broader, more holistic view of multitasking in SI. Seeber's CLM may, on the other hand, be seen as a micro-cognitive model of the interpreting process, rooted in the theories and findings of cognitive psychology and allowing for the formulation of fine-grained hypotheses on how the sub-components of interpreting may interfere with each other, and of why certain sub-components do so more than others.

As the present study contrasts the provision of terminological support through three different kinds of digital tools, this level of granularity may prove particularly suited to identifying specific sources of extraneous load and modelling their impact on the CL of CASI. Adopting a model of the interpreting process originating from a psychological model should further facilitate the interpretation of results in the present study in view of accepted theories stemming from cognitive psychology.

Additionally, Seeber's CLM presents several specificities:

\begin{enumerate}
\item It defines local CL as ``a function of input and output features'' \citep[189]{seeber_cognitive_2011} in relation to the amount of parallel processing and the amount of time for which elements must be stored.
\item It shows how, while interpreters might indeed reach maximum CL locally, most of the time they work below this ``red line''.
\item It accounts for local variations in CL, which can be explored at a microscopic level. The output in SI is seen as the result of strategies aimed at managing the limits inherent to the task at hand and at saving elaboration capacity, as exemplified by his application of the model in the framework of an experiment investigating the impact of syntactical structure for the language pair German-English on CL in SI \citep{seeber_cognitive_2011}.
\item It is able to ``account for the conflict potential posed by an overlap [of tasks] and the interference they cause'' \citep[189]{seeber_cognitive_2011}.
\item It illustrates how the overall cognitive demands are affected by the different combinations of sub-tasks.
\item It offers a ``first attempt at quantifying CL, relying principally on Wickens's demand vectors and conflict coefficients'' (ibid.).
\end{enumerate}

It is this level of granularity and flexibility of the model, already adapted to SI with text, which may represent the most valuable aspects of the CLM. Additionally, by postulating different demand vectors for a certain sub-task, it would be possible to further differentiate between diverse interpreting scenarios, predicting differences in the CL inherent to SI performed under different conditions and tracing them back precisely to the interference of defined sub-processes.

For the above-mentioned reasons, Seeber's framework is best suited to operationalise hypotheses on digital terminological support during SI through standard digital glossaries, CAI tools, and ASR-CAI hybrids.
\section{A model of SI with digital terminology support} \label{mymodel}
SI can be carried out in forms which add elements to its basic constellation of sub-tasks and resources recruited, as is the case for SI with text, or for assignments during which presentations are shown during speech delivery, an additional input that is also processed by the interpreter. What happens, then, when the interpreter searches for terminology in a glossary while interpreting simultaneously? Or when an interpreter is automatically prompted with terminology by an ASR system? Which cognitive resources are recruited, and in which of the four dimensions identified by Wickens? How much do said resources interfere with each other and why? As discussed in the previous sections (\ref{seeber}), the CLM has been used to formulate hypotheses on ``standard'' SI (with visual input) and on SI with text. In order to formulate hypotheses around these questions, I propose to apply Seeber's CLM to SI with digital terminology support.



In previous publications \citep{prandi_designing_2017,prandi_exploratory_2018}, I had suggested an adaptation of Seeber's CLM to SI with digital glossaries, CAI tools and ASR based on the initial version of the model \citep{seeber_thinking_2007,seeber_cognitive_2011,seeber_cognitive_2012}, as at the time of submission I was not yet aware of his more recent publication proposing an application of the model to SI with text \citep{seeber_multimodal_2017}. In my initial application of the CLM to SI with digital terminology support, I had not discussed the beneficial audio-visual integration effects due to the processing of paraverbal information provided by the speaker. The visual-spatial component had been included to account for visual search operations required in the case of morphological neighbours for target terms \citep{prandi_exploratory_2018} and had therefore received a full demand vector. I will therefore revise and update my proposed application of the CLM to SI with digital glossaries, CAI tools and ASR based on the more recent expansion of the model \citep{seeber_multimodal_2017}.
\subsection{Application of Seeber's CLM to SI with terminological support} \label{description_mymodel}\largerpage
Specialised terminology may not constitute a source of difficulty if the target language equivalent is readily available during the interpretation. In that case, the interpreter recruits cognitive resources to retrieve the equivalent from LTM. This may also result in higher CL, without, however, disrupting the rendition. Thorough preparation and terminological activation ahead of the assignment may help prevent impasses due to the use of specialised terminology. Indeed, assignment preparation, including terminological preparation, is considered an essential constituent of a successful interpreting performance, and is therefore often presented as a valuable strategy that interpreter trainees must learn to apply (e.g. \citealt{gile_basic_2009}). When the term cannot be retrieved from LTM, a series of coping tactics may be applied, such as paraphrasing, transcoding, generalising, and so forth (for an overview and discussion of different coping tactics, see \citealt{gile_basic_2009}). The progressive penetration of the digital medium in the interpreting profession, however, has made it relatively quick and easy to perform online queries in terminological resources, either peri-process or in-process. Glossaries are only one example of such resources, as mentioned in \sectref{terminology_interpreting}. For the scope of the present inquiry, I will focus on the consultation of terminological resources as a coping tactic \citep[203]{gile_basic_2009} to deal with specialised terminology. I will do so by examining three potential types of digital support interpreters may utilise in order to cope with specialised terminology: digital glossaries, CAI tools, and ASR-CAI hybrids.

\subsection{Manual terminology look-up} \label{manual_query}\largerpage
When terminology is manually looked up during SI, additional attentional resources are recruited. In order to search for a term in a digital glossary or a CAI tool database, the interpreter must perform several operations: (a) type a term or part thereof to query the database (and in most traditional digital glossaries, also click the enter key), (b) locate the relevant term on the page/in the list of terminological pairs, and (c) read the term and integrate it into the rendition. It should be noted that locating the term may not always require visual search in a digital glossary prepared, for instance, with Word or Excel or saved as a PDF. In all of these cases, all occurrences for the string searched may be highlighted, so the interpreter would need to visually identify the relevant term. However, if no orthographic neighbours are present in the glossary, only one term will be highlighted. The visual cue should attract the interpreter's visual attention through a bottom-up mechanism (see for instance \citealt{seubert_visuelle_2019}), rendering the identification of the target term more agile. Of course, much depends on the search settings chosen by the interpreters and on the strategies they adopt. For instance, one may select ``search only whole words'', to further reduce the number of results. For bigrams and trigrams, i.e. terms composed of more than one component, the number of results may depend on which element is searched. For instance, in a speech on nuclear energy, several types of reactors may be mentioned: if the glossary contains ``boiling water reactor'', ``pressurised steam reactor'' and ``nuclear reactor'' and the interpreter looks for ``reactor'', all three results will be highlighted and the interpreter may need to skip to the next occurrence or scroll down in the case of a multi-page glossary, whereas searching for ``boiling'' will only highlight one term and no further operations will be required. In a CAI tool such as InterpretBank, results which do not correspond to the search string are not displayed thanks to a dedicated search algorithm. However, visual search may still occur, as for digital glossaries, if several orthographic neighbours are shown on the screen.

However, InterpretBank poses three main advantages. First, it reduces the amount of visual input to be processed. Second, it does not require the user to position the cursor in the search field. This happens automatically in the Conference Mode: after a query, the programme is ready for the next search. If this operation has not been automatised by the interpreter, a digital glossary may cause the querying process to slow down, as the user has to prepare for the following query. Third, the search bar is cleared automatically after each query in InterpretBank, which is not the case for a standard digital glossary. Forgetting to clear the search bar at the end of a query may interfere with other sub-processes during the following query.

Using the CRF from the CLM as theoretical framework, there is first of all a ``response'' to the auditory stimulus during manual look-up. This recruits manual-spatial resources in addition to the vocal-verbal response, i.e. the interpreter's rendition. It seems correct to assign the terminology query to the production and monitoring stage as the manual query is conducted to support target language rendition. If the term has not been recognised, no manual query can be performed. Furthermore, visual-spatial resources are recruited at the perceptive-cognitive stage, to identify the term, while visual-verbal resources are required to read the term (Figure \ref{fig:CRFexp_a}). SI with a glossary therefore shares something with sight translation and with SI with text, which also require visual-verbal resources during perception/cognition. As observed by \citet[74--75]{gieshoff_impact_2018}, we may expect the glossary query to ``interfere with the speech, the auditory stream, as both elements are verbal and cognitive-perceptual inputs''.

The cognitive resource footprint of SI with manual look-up (digital glossary\slash InterpretBank) illustrates the recruitment of additional resources (Figure \ref{fig:CRFexp_b}). It should be noted that the CRF for SI with terminology look-up applies only to the instances in which a query occurs, and not to the entire interpreting task. When no query is performed, one can apply Seeber's CLM for SI. In sum, the CRF posits a recruitment of:\largerpage

\begin{itemize}
    \item the general capacity available for all tasks
    \item visual-verbal, visual-spatial and auditory-verbal resources at the perception and cognition stage
    \item manual-spatial, vocal-verbal and auditory-verbal resources at the production and monitoring stage
\end{itemize}
Thus, auditory-verbal and cognitive-verbal resources are recruited during both sub-tasks.

A comparison with the conflict matrix for ``standard'' SI (with visual input, Figure \ref{fig:CM_SI}) highlights how manual terminology look-up during SI should produce a higher CL, not only because more resources are mobilised, but also because they are shared across a higher number of sub-tasks.

\begin{figure}
\includegraphics[width=.9\linewidth]{images/fig2-4.pdf}
\caption[Additional cognitive resources recruited during SI with manual terminology lookup]{Additional cognitive resources recruited during SI with manual terminology lookup in a digital glossary or a CAI tool \protect\citep[36]{prandi_exploratory_2018}}
\label{fig:CRFexp_a}
\end{figure}

\begin{figure}
\includegraphics[width=0.75\linewidth]{images/fig2-5.pdf}
\caption[Cognitive Resource Footprint for SI with manual terminology lookup]{Cognitive Resource Footprint for SI with manual terminology lookup in a digital glossary or a CAI tool \protect\citep[37]{prandi_exploratory_2018}}
\label{fig:CRFexp_b}
\end{figure}

As discussed above, however, CAI tools may offer a series of advantages which have the potential to partly reduce the additional load resulting from the interaction with the computer. This does not emerge from the CRF. In his model, \citet[172]{wickens_multiple_2002} contemplates the use of three levels in the assignment of demand vectors to represent cases in which a sub-task recruits a certain resource to a high degree. Seeber applies this principle in the CLM of SI with visual input and of SIMTXT, where a demand vector of 0.5 is assigned in the case of multimodal integration due to beneficial modality effects (see \sectref{CLM_standard} and \sectref{CLM_with text}). In theory, it could be possible to assign a higher demand vector, for instance 1.5, to further differentiate between the tools used for manual look-up, which may differ in the degree of recruitment both of visual-spatial resources and of manual-spatial resources at the production/monitoring stage. The different levels of recruitment of cognitive resources may thus be visually represented by the conflict matrices of SI performed with the support of different tools, and could in turn result in higher total interference scores. At this stage, however, these remain theoretical speculations which need to be verified empirically.
\subsection{Automatic terminology look-up} \label{automatic_query}
A CAI tool with ASR integration does not require active operation of the technological support by the interpreter. Specifically, the tool does not recruit manual-spatial resources. Nonetheless, visual-spatial and visual-verbal resources are recruited to locate and process the term visualised on the screen.

A further differentiation from tools with manual look-up lies in the potentially double advantage offered by speech recognition: the tool may support both comprehension and production processes. As observed by \citet{pym_what_2011}, technologies applied to translation and interpreting essentially externalises cognitive processes, acting as an external memory, or as a second brain. On the one hand, an ASR tool performs operations similar to those performed by the PL: it decodes the acoustic information and maps it against its internal lexicon, which results in ``understanding'', i.e. in the presentation of the term pronounced by the speaker on the screen. On the other hand, when coupled with an extraction tool, as is the case for the ASR integration in InterpretBank, it interacts with its ``LTM'' (the glossary) to retrieve the target-language equivalent. This is similar to the purpose of a translation memory, which retrieves pre-processed text segments facilitating the translator's work. Using an ASR tool may thus be valuable to facilitate terminology recognition during listening and, as for tools with manual look-up, to optimise the rendition of specialised terms during production.

\begin{figure}
\includegraphics[width=0.75\linewidth]{images/Figure38.pdf}
\caption[Cognitive Resource Footprint for SI with ASR support]{Cognitive Resource Footprint for SI with ASR support}
\label{fig:CRF_SI_ASR}
\end{figure}

The cognitive resource footprint for automatic terminology look-up during SI is represented in Figure \ref{fig:CRF_SI_ASR}. Of course, the advantage described above presupposes that the term recognition is successful. This is not the case in 100\% of the cases with ASR: if the wrong term is recognised (for instance due to homophones or to a non-native accent), an imprecise or wrong suggestion, or a lack thereof, might go against the interpreter's expectations, resulting in irritation and thus potentially causing additional CL. Additionally, the system's latency also plays a role: long latencies lead to a drop in accuracy and fluency (for a dedicated analysis, see e.g. \citealt{montecchio_masterarbeit_maddalena_2021}). Although current systems seem to perform sufficiently fast \citep{brusewitz_simultandolmetschen_2019}, in real-life laptops do not always perform as expected and may become slow due to a number of reasons. If the term is not presented quickly enough on the screen, the potentially beneficial effect resulting from cross-channel redundancy may be hindered by a lack of temporal contiguity (see \citealt{mayer_principles_2014}): the tool's suggestions may be perceived as a distraction rather than as a facilitation \citep{van_cauwenberghe_etude_2020}.

A recent study by \citet{chmiel_multimodal_2020} has focused precisely on the issue of incongruence between auditory and written input, although in the framework of SI with text. The authors' findings indicate that when both auditory and written stimuli are presented, interpreters tend to focus on the visual modality. When the stimuli are incongruent, the visual modality interferes with the auditory input to the point that interpreters include incorrect units of information in their rendition – in this study, this happens especially for terms. Similar findings of imported errors from incorrect visual support for terms were also found in an experiment by \citet{van_cauwenberghe_etude_2020} on the provision of ASR support for specialised terminology. It is interesting that such effects were found not only for students \citep{van_cauwenberghe_etude_2020}, but also for professional interpreters. \citet{chmiel_multimodal_2020} also found that incongruent items tended to be fixated longer than congruent ones.

It may be argued that similar sources of irritation or distraction may also arise with manual terminology look-up: provided that the interpreters have correctly identified the term heard, they may not find it in the glossary, or may not find it quickly enough: in the case of very large glossaries, or if the interpreters have not had sufficient time to thoroughly prepare, this may not be a seldom occurrence. Even though they exceed the scope of the present study, the above-described scenarios are more than probable in real-life and would deserve further dedicated explorations, both in terms of their effect on cognition and on target-text production.
