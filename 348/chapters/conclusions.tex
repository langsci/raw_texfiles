\chapter{Conclusion}\label{conclusions}\largerpage[2]
%\addcontentsline{toc}{chapter}{7 $\,$ Conclusion}

The present study set out to explore the impact of digital terminology support tools on the SI process. Through an experimental contribution comparing traditional digital glossaries, CAI tools with manual look-up and ASR-enhanced CAI tools, the study addressed two main limitations in current CAI research: the almost exclusive focus on the product of CASI and the lack of a validated methodology for the exploration of the CASI process. Building upon previous research conducted on the topic, I explored the impact of the different support solutions on the SI process through product-related measures, but I also analysed the usefulness of additional process-based measures. The present study was therefore the first to adopt a mixed-method approach for the exploration of the cognitive processes of CASI, deriving its methods from TPR, and exploring assumptions on the impact of CAI tools on the process of SI through a systematic approach.

\chapref{chapter1} introduced the topic of terminology in conference interpreting and described the relevance of terminology as a quality factor. Additionally, it reviewed conference interpreters' habits for terminology preparation pre-as\-sign\-ment and for terminology look-up during the assignment emerging from several surveys conducted on the topic.

\begin{sloppypar}
After reviewing the main technologies applied to interpreting, \chapref{chapter2} broadened the analysis to supporting technologies for terminology work, with a focus on the most recent development in this field: CAI tools with and without ASR support. The chapter reviewed current CAI research and discussed open questions not yet addressed in scholarship.
\end{sloppypar}

As the main aspect of innovation of the present doctoral work consisted in the exploration of technology-supported SI cognition, \chapref{chapter3} discussed interpreting from a cognitive standpoint. The chapter illustrated and contrasted relevant theoretical models derived from cognitive psychology and Interpreting Studies and previously applied to experimental research on the interpreting process with CAI tools and multimodal input. Seeber's CLM of SI with text was applied to the present research object to illustrate the hypothesised differences in the cognitive impact of tools under the three conditions contrasted during the experiment.

\chapref{chapter4} discussed the various approaches adopted in Interpreting Studies and TPR to measure CL, discussing the benefits and shortcoming of theoretical approaches as well as subjective, performance, behavioural and physiological methods.

In \chapref{chapter5}, I defined the research gap addressed by the experimental contribution and formulated the hypotheses on CL in CASI. Additionally, I motivated the selection of the metrics analysed in the experimental contribution and illustrated the methodology of the experiment conducted to verify my hypotheses. I first presented the method and objectives of the pilot study carried out to validate the stimuli and methodology adopted in the main experiment. I then discussed the main experiment, going into the details of the participants' training, of the materials and apparatus used and of data collection and preparation.

\chapref{chapter6} presents and discusses the results of the analyses of the experimental data, which overall support the research hypotheses. The chapter also illustrates the main lacunae of the study.

In this final chapter, I offer some reflections on the methodological, didactic and practical implications of the findings of the present study and suggest potential areas of exploration to be addressed in future studies on the relatively new field of computer-assisted (simultaneous) interpreting. \sectref{implications_method} presents the methodological implications for future studies on this topic. In \sectref{implications_didactic}, I address the implications for the inclusion of CAI tools with and without integrated ASR in the interpreting curriculum. \sectref{implications_practical} discusses practical implications for the development and improvement of bespoke support tools for conference interpreters. \sectref{futurework} concludes the work by suggesting potential avenues for future CAI research.

\section{Methodological implications} \label{implications_method}
The main contribution of the present study lies in the development of an experimental methodology for the exploration of the CASI process. As described in Chapters \ref{chapter5} and \ref{chapter6}, the research object was investigated through the combination of multiple methods for the collection of primarily quantitative data.

Building on a previous study which had highlighted the importance of training for effective in-process interaction with CAI tools \citep{prandi_uso_2015,prandi_use_2015}, the pilot study and the main experiment were preceded by a training phase. The choice to switch to an online training may prove particularly useful also in future studies, as it has the potential to reach a higher number of participants while at the same time allowing for a more personalised and flexible, self-paced training process, both in terms of the frequency and of the integration of the training into the subjects' schedule. The online format may also allow for an easier integration of the participants' training into the study design as compared to face-to-face training.

As for the stimulus material used in the experiment, the preparation of the speeches turned out to be highly time-consuming. Nonetheless, the result is a set of highly controlled, highly comparable speeches which may be used to further explore the cognitive implications of human-machine interaction during interpreting, for instance in terms of coping tactics adopted during interpreting. In light of the current lack of uniform methods and validated materials for the investigation of the CASI process and product, it is my hope that this material will prove useful also for future studies in the field.

With reference to the study design, the adoption of a mixed-method approach appears promising. This approach allowed me to link observations derived from the product-based measures (term accuracy, errors and omissions) with the findings from process-related measures derived from TPR. This represents a step forward as compared to previous studies which had adopted only product-based metrics. In addition, the choice to combine several metrics allowed for a deeper understanding of the process of SI with digital terminological support, bringing to light a series of phenomena which would have otherwise remained unknown.

The inclusion of multiple measures and methods commonly adopted in TPR to study the translation and interpreting process proved beneficial. Further work is however necessary to refine the measures used and identify additional useful metrics for the investigation of CASI.

\begin{sloppypar}
Following this approach is however likely to produce a large amount of data which requires extensive preparation, thus complicating the analysis. Future studies may therefore choose to focus on individual aspects which the present work has touched upon.
\end{sloppypar}

The choice of a within-subject design proved valuable to cope with the limited number of participants available. In particular, it allowed for the use of inferential statistics even on a limited population of participants, improving the reliability of the results presented. Larger samples, however, would provide greater confidence in the results. 

A between-subject design, despite requiring accurate participant selection to ensure sample homogeneity, may ensure even greater comparability in the stimuli used and lend further support to some tentative observations formulated in the present contribution. However, until the use of CAI tools becomes mainstream, it is possible that between-subject designs with sufficiently large samples may be difficult to adopt and that within-subject designs may constitute a more practical choice. Additionally, it may be considered unethical to only provide training to one group, so this should be taken into consideration especially for studies involving students. Furthermore, if we are to establish which tools may best support interpreters during interpreting while interfering the least with the other subprocesses involved in SI, intra-subject explorations may indeed represent a more adequate design choice to address our research questions.

Since a few institutions have already introduced CAI tools into their curricula, studies involving larger populations of student participants would represent a valuable contribution. However, an important limitation of the present study and of previous CAI research lies in the almost exclusive involvement of trainee interpreters in the experiments, as discussed in \sectref{limit_design}. Hence, it appears necessary to also include professional conference interpreters in studies on technology-enhanced interpreting.

\section{Didactic implications} \label{implications_didactic}
The outcome of the present study presents a series of implications for training, especially because the sample population involved in the experiment and in the pilot study was made up of student interpreters.

To start, the study explored the possibility to train students on the tool functionalities through distance-learning. I see potential for the development of e-learning modules on this topic. In light of the still limited inclusion of CAI tools into the training of 21st century interpreters, online training may represent an efficient way to promote the development of new digital skills despite bureaucratic or logistic limitations. Especially the logistic limitations which have emerged significantly in the wake of the COVID-19 pandemic may be partly addressed by distance training. However, it should be remarked that, for the present experiment, no didactic intervention aimed to promote the students' effective use of CAI tools was included in the training module: the participants' training mostly included self-directed practice sessions. Our currently still limited understanding of the CAI process and of the impact of CAI tool use on the product of SI represents an important limitation for CAI tool training. Nonetheless, as not only training, but also research has had to address the logistic limitations imposed by the pandemic, using online modules may be useful if participants are only to gain sufficient practice in the experimental task ahead of data collection.

Anecdotal observations conducted on the students' interaction with the different support tools during the experiment (see \sectref{additional_obs}) highlighted a sometimes ineffective approach to the use of the tools, emerging for instance as repeated queries or as queries performed for terms of which the spelling was unknown. These phenomena, combined with a certain over-reliance on the tools observed in the present and previous studies (e.g. \citealt{prandi_uso_2015,prandi_use_2015,van_cauwenberghe_etude_2020}), would suggest that training may not only be necessary to develop the required practical skills in operating the tools in the booth, but also as concerns the strategic dimension of the in-booth interaction with CAI tools. In particular, it appears important that students and professionals know the technologies behind ASR-enhanced CAI tools and be able to adjust their expectations on the systems and adopt effective coping tactics in case of system failure.

In light of the above, I believe that training should also address the benefits and shortcomings of each type of solution also from a strategic standpoint, i.e., in terms of how the tool selected may affect the process and product of interpreting. An example is the positive, although unsurprising, effect on the EVS observed for the ASR mock-up (\sectref{EVSdisc}). As IS literature has found that adjusting the d√©calage may be an effective tactic to cope with very dense or fast speeches (e.g. \citealt{gile_basic_2009}), the choice between an ASR-enhanced and a CAI tool with manual look-up may also be motivated by reasons of this kind. At the same time, in \sectref{EVSdisc}, I had formulated the hypothesis, which remains to be tested in future studies, that a faster integration of the term into the rendition may also coincide with a syntactic structure closer to the original. For some language pairs, this may result in a less fluent or idiomatic delivery. This, however, also remains to be explored in future research. Overall, I believe that it would be beneficial to discuss the implications of the choice of one tool over other solutions not only in terms of its potential impact on the delivery, but also of its interference with the other cognitive subprocesses of interpreting.

The strategic dimension of human-tool interaction may also be addressed at a deeper level, for instance in terms of the query strategy to adopt during interpreting for manual look-up. In my study, trigrams were the category of terms that were found more easily in the PDF and CAI condition, presumably because participants had more linguistic material to use for the query (see \sectref{queriesdisc}). On the other hand, participants had more difficulties in finding unigrams. Trainers may therefore draw the students' attention to this aspect by pointing out effective querying strategies also oriented to the morphology of the terms.

Despite the potential for accuracy improvement with support tools, the presence of errors and omissions highlighted the crucial role of preparation in SI. Therefore, guided in-booth experience with the tool may also prove useful to stress the importance of the pre-assignment phase and to ensure a more effective interaction with the tool.

Finally, in light of the severe errors and complete omissions observed despite the high level of terminological accuracy achieved, trainers may want to raise awareness on the trade-off between the support provided by the machine and the additional effort inherent to human-machine interaction during SI.

The suggestions outlined above are not intended to be exhaustive, but were presented as a means of illustration of the potential implications of CAI research for training. At present, these suggestions remain hypotheses based on the observations conducted in the present study. For all its limitations, however, the present contribution highlighted several issues which, if corroborated by further studies, may offer important implications not only for professional practice, but also for training. If we are to prepare interpreting trainees to effectively use CAI tools in their professional career, it appears necessary to conduct further research to gain a deeper understanding on the impact of CAI tools on the process and product of SI, and to align training with the findings of CAI research.


\section{Practical implications} \label{implications_practical}
The findings from the present study, which are in line with similar experiments conducted on ASR-enhanced CAI tools for the in-booth prompting of numbers, may have important implications also for the future development of support technologies for interpreters. If the ASR module does not fail, as was tested in the context of the present experiment, it seems to provide a superior type of support to the trainee interpreter, with the lowest additional cognitive effort and the highest degree of accuracy observed. Against this background and in light of the considerable advances in AI, in particular in the performance of ASR engines, it is safe to assume that AI-enhanced, third generation CAI tools may represent the in-booth support tool of choice for a large number of interpreters in the future.

In response to a question in the debriefing questionnaire, some students had highlighted the inability to perform manual queries when needed in the simASR condition as a shortcoming of the system. Therefore, while it seems reasonable to focus on the development of ASR-enhanced CAI tools in the near future, i. e. requiring no active search in the glossary by the interpreter, hybrid systems may also be explored as an option to reconcile the benefits of automatic support with the need to actively query the glossary under certain circumstances.

However, some of the benefits observed for the ASR-CAI mock-up may have originated from the specific user interface and terminology presentation mode chosen for the experiment. Both the present study and previous research have highlighted potential pitfalls in interpreter-tool interaction, such as irritating or distracting features, which may be addressed by interventions on the tools' UI design. Valuable steps in this direction have been taken in TPR to explore the origins of the cognitive friction experienced by translators using CAT tools. CAI research may derive useful methods and insight from this area of TPR, thus informing the design of future tools.


\section{Future work} \label{futurework}
In addition to the tentative conclusions formulated in the previous sections, several aspects have emerged from the present study which deserve to be further explored in future research.

One area of research may focus on the impact of the performance of the ASR engine on the product and process of SI. Previous studies have identified the risk of over-reliance on the tool \citep{prandi_uso_2015,prandi_use_2015,defrancq_automatic_2020,van_cauwenberghe_etude_2020}. At the same time, \citet[87]{defrancq_automatic_2020} reported a potentially beneficial psychological effect deriving from the perception of the ASR tool as a ``safety net''. Both aspects also emerged from the debriefing questionnaire administered to my participants post-study. However, in my experiment, no system failures were simulated for the simASR tool. Explicitly introducing this variable in future studies may provide further insight into the psychological and practical impact of system failures when ASR is provided in the booth.

The questionnaire adopted in the study only explored the reception of the tools at a broad level. Nonetheless, it was useful to generate a series of hypotheses, which may be further tested in future explorations of the research object. If CAI tools become a staple in the standard toolkit of conference interpreters, large-scale questionnaires may be used to further explore the reception of such tools and identify potential shortcomings to be addressed by developers and trainers. First steps in this direction have been taken\footnote{See for instance the \citet{EABM2021} project.}, but there are still a lot of aspects which deserve further exploration, and which may be investigated in future studies focused on the CAI process.

A third avenue, only briefly touched upon in the pilot study, may investigate how the provision of CAI support in the booth affects the tactics used to cope with specialised terminology. In particular, future studies may explore the impact of preparation on the interaction with the tool in the booth, also with the goal to establish which strategies may lead to the best outcome in terms of the trade-off between terminological accuracy and overall quality of the rendition.

Additionally, it should be noted that CAI research has thus far mostly focused on the simultaneous mode. With a few exceptions (e.g. \citealt{wang2019can}), consecutive interpreting has not yet been in focus. However, it may be hypothesised that the technologies deployed to support the SI process may also prove valuable for the consecutive mode. Further research appears necessary to determine the impact of supporting technologies on the process and product of consecutive interpreting, and to establish validated methodologies for the exploration of this research object.

Finally, future studies may choose to explore the adoption of other metrics for the investigation of the product and process of SI with CAI tools, with and without integrated ASR. For instance, the analysis of the quality of the interpreters' output may be conducted using a more comprehensive framework going beyond the broad categories of grave error and complete omission chosen for the present study. As discussed in \sectref{erromdisc}, the adaptation of established and standardised quality evaluation frameworks, as has been done for instance in research on human translation and post-editing, may offer a more nuanced picture of the impact of live in-booth support on the quality of SI.

\begin{sloppypar}
Furthermore, it would certainly be interesting to include metrics centred around the presentation of the interpreted texts, such as prosody and pause patterns, and to include final users in the evaluation. In addition to cognitive effort, the stress experienced in working with in-process support tools may also be investigated, ideally with a combination of physiological measures and subjective measures.
\end{sloppypar}

Despite having produced a growing amount of research in recent years, the area of Interpreting Studies focusing on CAI is still in its infancy. The present study was conceived at a time when ASR support for interpreters was just starting to emerge. Since then, the application of technology to interpreting has experienced a quantum leap, and an increasing technologisation of the profession may reasonably be expected in light of the increasing uptake of technology by interpreters over the past few years, further accelerated by the recent pandemic. The increasing sophistication and capabilities of technology thanks to the advances in AI may equally be expected to further promote the permeation of technology into the interpreting profession. Despite its focus on a specific set of technological solutions, it is my hope that the methodological contribution offered by the present study may prove valuable for further explorations on technology applied to interpreting, a research subject which is bound to become increasingly relevant for the interpreting profession in the near future, but which currently remains still largely unexplored. 
