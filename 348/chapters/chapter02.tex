\chapter{Information technologies and interpreting} \label{chapter2}




In view of the complexity and the necessity of terminology work in interpreting for LSP settings, interpreters have looked for ways to facilitate their terminology work through technology.

While interpreters can use tools that are also available to translators to prepare for their assignments and to access their terminological resources while interpreting, they can also adopt software developed specifically for interpreters. Known as CAI tools, these solutions aim to address interpreters' unique needs and overcome the limitations of traditional tools identified in \sectref{proconstools}.

With the aim to provide an in-depth discussion of CAI tools, the present chapter introduces the topic of technologies applied to interpreting and illustrates CAI tools within this larger framework. Special attention is dedicated to InterpretBank\footnote{\url{https://interpretbank.com/} (Accessed: 24.07.2022)} \citep{fantinuoli_interpretbank_2012, fantinuoli_computer-assisted_2017}, the CAI tool adopted in the present study. To determine whether and to what degree interpreters include CAI tools in their workflows, the terminographic practices of conference interpreters are presented. The potential and limitations of CAI tools in addressing interpreters' needs are discussed against the background of current CAI research, which motivates the contribution provided by the present work.

\section{Overview and classification of technologies} \label{tech_overview}
Like translation and numerous other areas of human life and work, the interpreting profession has not remained indifferent to technological advances. Some developments in the field of technology have led to considerable progress in the interpreting practice, while other technologies have been perceived as a threat to its very existence since their inception. Something similar can be said of the translation profession, which has experienced radical changes that have optimised translators' workflows, but also threatened the status of human translation.

\begin{sloppypar}
Technologies can both mediate, generate and support interpretation (see \citealt{braun_technology_2020}). Supporting technologies include CAI tools. CAI tools can, however, also integrate technologies used to generate interpretation (e.g. ASR and MT), and may, in turn, be integrated into technologies mediating interpreting (see \citealt[65]{will2020computer}). To introduce the topic of CAI and define it in relation to other information and communication technologies (ICTs), the following sections provide an overview and a classification of interpreting technologies.\footnote{This chapter focuses on applications to professional conference interpreting. Therefore, technologies which support training, known as Computer-Assisted Interpreter Training (CAIT) tools are not discussed here.}
\end{sloppypar}

\subsection{Technologies mediating interpreting} \label{tech_mediation}
The first category of technologies applied to interpreting comprises solutions that have led to the emergence of new interpreting modes, or that allow for the performance of interpreting in previously inaccessible settings. The most prominent example of the first is simultaneous interpreting technology. Up until the 1920s, interpreting was only performed in the consecutive mode, or in the form of whispered interpretation, i.e. synchronously but without any technological aid. The first (successful attempt) at using simultaneous interpreting at a conference was at the 1928 ILO conference, where real SI was used during entire meetings, involving up to seven different languages \citep[33]{baigorri-jalon_conference_1999}. After this first experiment, SI reached its ``coming of age'' (ibid., p. 34) at the Nuremberg Trials almost 20 years later. The simultaneous mode faced initial resistance by consecutive interpreters, who feared a decay in the quality of interpretation and, as a result, of communication, and perceived headphones and SI equipment as foreign objects. Nonetheless, SI quickly imposed itself for its time-saving character and cost-effectiveness, and remains the most widespread interpreting mode in the conference setting to date.

If simultaneous interpreting can be perceived as the first revolution brought about by technology in the field of interpreting, distance interpreting can be viewed as the second. This innovation made it possible to perform both modes of interpreting in new settings and with multiple possible configurations in the speaker-listener-interpreter triad. Distance interpreting ``covers a whole range of technologically different setups'' \citep[121]{ziegler_present?_2018}, which vary according to the constellation in the communication, the interpreting mode (e.g. in terms of the range of audio frequencies required), but also according to whether only the audio signal or both audio and video data are to be captured and transmitted. Since its inception, distance interpreting has posed the conundrum of ``striking a balance between cost-effectiveness and quality of interpretation'' \citep[36]{baigorri-jalon_conference_1999}. Not only financial, but also organisational and logistical issues must be addressed, without sacrificing the quality of audio and video streams. Although some perceived and factual issues can be overcome through proper set-ups, a certain degree of resistance towards the ``new technologies'' remains among some conference interpreters. This extends to the other two categories of interpreting technologies, as discussed in the following sections. The successful implementation of distance interpreting in several settings has, however, shown that this technology is here to stay. Indeed, it could lay the foundations for the emergence of new conference interpreter profiles who fully embrace the home-office, location-independent alternative to traditional conference settings, as the COVID-19 pandemic has shown \citep{fantinuoli_technological_2019}. Additionally, distance interpreting will require adjustments not only in attitudes, but also in training, for instance through the development of ``training modules designed specifically for this modality, addressing cognitive, communicative and technical aspects'' \citep[137]{ziegler_present?_2018}. Furthermore, the integration of augmented reality technologies, such as VR glasses, could represent the next step in distance interpreting by helping address the perceived feeling of isolation through distance and the need for ``self-control of the direction of sight'' (ibid., p. 136).














In translation, a comparable level of innovation was introduced by the advent of personal computers, which allowed for the execution of this intellectual activity on a new medium. At the same time, this innovation brought about evident advantages in terms of productivity and quality, especially thanks to CAT technologies (see \sectref{tech_support}). Technology has also modified how translation is performed. For instance, moving translation to the cloud has led to the creation of collaborative translation platforms, which allow for an unprecedented level of interaction between translators cooperating despite geographical limitations. The resulting translation is thus the product of a joint intellectual effort. ASR has allowed translators to dictate their interpretation, rather than typing it, with evident gains in productivity and potentially also in quality \citep{carl_comparing_2016}. The use of machine translation has, to some extent, replaced translators' work, but it has also offered language service providers and individual translators ways to speed up human translators' work, e.g. through human post-editing of machine-translated texts. For this reason, machine-translation post-editing (MTPE) can be placed at the intersection of technology-generated and technology-mediated translation. The combination of ASR and MTPE has even made post-editing of ASR output in audio-visual translation possible, as explored in the CompASs (Computer-Assisted Subtitling) project, a joint EU-financed effort of the German TV channel ZDF and of the Translation \& Cognition Center (TRA\&CO) of the University of Mainz (see \citealt{tardel_automatization_2018,tardel_attention_2021}).


\subsection{Technologies generating interpreting} \label{tech_generation}
When considering technologies for the provision of intercultural communication services without the involvement of human interpreters, an inevitable parallel emerges between translation and interpreting. Over the years, although with different levels of perceived pressure, both translators and interpreters have increasingly been faced with what they consider a potential threat to their livelihood: machine translation, on the one hand, and machine interpreting (MI), or speech translation, on the other. Just like MT, MI also aims to generate interpreting without the contribution of human interpreters. 

Despite its having long been discarded as a merely theoretical threat, the considerable advances brought about by neural networks and artificial intelligence (AI) have led to a resurfacing of machine interpreting.

Like MT, MI requires a combination of several technologies. The essential steps involve ASR or speech-to-text technology (STT) to turn the speaker's words into written text, a machine translation system to translate such text, and speech synthesis, or text-to-speech, to turn the translation into its oral form in the target language. The spoken output can, however, also be replaced by the creation of subtitles, without the use of speech synthesis.

At present, the two main models are cascading and end-to-end systems. In cascading systems, the above-mentioned steps are performed consecutively and the source speech must be segmented. End-to-end systems do not require the intermediate step of ASR. This last possibility has only recently started to be explored, but it is increasingly reaching the quality produced by cascading systems. End-to-end systems are exemplified by Google's Translatotron \citep{jia2019direct} and Translatotron 2 \citep{jia2022translatotron}. The further development of the ``neural paradigm'' \citep[296]{braun_technology_2020} could lead to rapid advances in the quality of MI output: ``especially neural networks which can learn from previous tasks and shift attention according to the relevance of an element in the source speech may have the potential to make machine interpreting more human-like'' (ibid.).

Most systems developed thus far work consecutively, i.e. the interpretation in written or oral form is made available after the speaker has produced an utterance. However, simultaneous machine interpreting has also been explored (e.g. \citealt{cho2013real}) and is attracting growing interest.

The first MI systems were of the consecutive type and relegated to limited domain applications. One example is the German Verbmobil project \citep{wahlster2013verbmobil}, a consecutive speech translation system for the domain of appointment-making. It was one of the first projects combining ASR and speech synthesis. Another domain-specific system is VoiceTRAN Communicator, a cascading speech-to-speech system for the language pair Slovenian-English \citep{vzganec2005voicetran}.

These first systems had limited applications. However, in recent years, machine interpreting has become increasingly known to the general public, thanks to the implementation of general-purpose solutions capable of handling conversations on a variety of topics. A well-known example is Microsoft's Skype Translator\footnote{\url{https://www.skype.com/it/features/skype-translator/} (Accessed: 11.09.2021)}, which offers ``real-time machine translation in 10 languages in voice and video chats and 60 languages in text chats'' \citep[21]{hoberg2021dialogue}. Microsoft Azure also offers a speech translation API.\footnote{\url{https://azure.microsoft.com/en-us/services/cognitive-services/speech-translation/} (Accessed: 15.09.2021)}
Currently, there is growing interest for simultaneous machine interpreting systems capable of handling continuous speech. The Karlsruhe Institute of Technology (KIT) has developed a lecture translator to provide automatic simultaneous interpreting for foreign students who do not understand German. The output is made available in the form of written subtitles (see \citealt{dessloch2018kit} for a detailed description of the system). In addition to fostering accessibility in the university environment, the lecture translator further supports the students' learning as the recordings of the lectures and their translations are stored in a repository. Another key advantage of using the lecture translator is the greater affordability of the system compared to human interpreters, despite the lower quality \citep[89]{dessloch2018kit}. User tests involving students suggest that the lecture translator is well received and considered useful, especially by foreign students.

\begin{sloppypar}
A similar application of a system combining ASR with MT developed in the field of audiovisual translation is the CompAsS project (see also \sectref{tech_mediation}). The \mbox{CompAsS} tool aims at automating the subtitling process wherever possible, supporting the workflow of subtitlers. Initial studies suggest that the tool reduces the technical effort experienced by subtitlers \citep{tardel_automatization_2018,tardel_attention_2021}.
\end{sloppypar}

What could seem like a relatively easy feat considering the sizeable improvements made by machine translation is, however, complicated by the very nature of spoken discourse. Unlike written communication, speech presents a certain degree of spontaneity and ambiguity, which machines are still unable to deal with without human assistance. Nor are they capable of inference and context anticipation: as \citet[342]{fantinuoli_technological_2019} observes, ``they still lack background and context knowledge''. There is, additionally, the issue of the suitability of input for MI processing: unlike MT, which allows for a quick test to verify whether a certain document can effectively be machine translated, MI does not allow for a re-do if things go south – if ``a[n] MI system [...] fails to deliver a usable translation, the communication simply breaks down'' (ibid.). The interplay of these factors, coupled with the immediacy of simultaneous interpreting, is one of the reasons why fully automated machine interpreting will probably require further effort and time. As \citet[295]{braun_technology_2020} points out, the application of MI systems ``to situations in which highly accurate professional language mediation is required remains a nontrivial challenge''. In order for MI to enter the third phase of human-machine interaction, i.e. that in which interpreters will go from machine-assisted to machine-assisting professionals, not only would the MI output need to be of a quality comparable to human interpreting, but it would also need to become more convenient in economic terms. Despite some scholars' assertions that a total replacement of human interpreters by machines will never be possible, ``the real question is if AI will ever be able to tackle [the above-mentioned] issues at some point in the future'' \citep[345]{fantinuoli_technological_2019}. There is no reason to affirm with absolute certitude that this will never be possible. At present, the question remains unanswered.

There is, however, no doubt that machine interpreting will impact the interpreting market in some way or another, at the very least in terms of the perception of conference interpreters' role and professionalism in the eyes of the public. \citet{fantinuoli_technological_2019} envisages a near future in which MI will start entering the low-end segment of the market, following its short-term entering of the recreational sector, where professional interpreting services were not used before. It is plausible to imagine that high-quality and highly professional human interpreting will be relegated to the higher end of the market, ``at least until the advent of real human-like MI.'' (p. 345).

The use of machine interpreting in formal and high-level contexts should, however, not be excluded. There is growing interest for machine interpreting from business and institutional players,\footnote{For instance, Cisco Webex offers ``real time translation'' \citep{webex2022}. The European Parliament's innovation partnership also aims at the development of a ``Live Speech to Text and Machine Translation Tool for 24 Languages'' \citep{EPtender2019}} and the quality of MI continues to improve. What remains to be determined is how the use of MI affects communication. Further insight into this aspect of MI-mediated communication may reasonably be expected to impact its adoption by end-users and its perception by interpreters. This has been a concern of interpreting scholars from the beginning, as consecutive systems applied to dialogic conversations have been explored from a discourse-oriented perspective (see e.g. \citealt{apfelbaum1997does} for Verbmobil, \citealt{hoberginformationsintegration} for Skype Translator). This type of evaluation is, however, still in its infancy for continuous systems in conference settings (see \citealt{fantinuoli2021evaluation}). A valuable step in this direction is the QEMI-C corpus \citep{mauri2021QEMIC}. QEMI-C is a manually-compiled and -annotated, trilingual parallel corpus comprising 40 authentic speeches. It can serve as a basis for the comparative quality evaluation of MI and human interpretation (ibid., p. 95) in conference settings, which research has yet to address to a large extent.

Understanding the effects of MI use on communication appears particularly urgent, especially considering the overall negative perception of this technology by interpreters. In translation, where MT has long entered the profession, translators' resistance towards this technology and a certain dislike of related translation tasks (e.g. MTPE) is well known, surfacing as negative attitudes for instance in surveys (e.g. \citealt{moorkens2015post}) and in social media discourse (e.g. \citealt{laubli2017google}), especially among experienced professionals. Nonetheless, MT can also be used as a support, for instance to speed up the translation process for certain types of texts. Similarly, MI, especially with written output, may also be integrated into CAI tools to alleviate part of interpreters' cognitive efforts (see \sectref{CAItools} and e.g. \citealt{wang2019can} for consecutive interpreting). A deeper understanding of these technologies may help interpreters embrace them as valuable support tools.

\subsection{Supporting technologies for interpreting} \label{tech_support}
If technology-mediated and technology-generated interpreting may, for various reasons, encounter the adversity of practitioners, supporting technologies are the group of solutions which conference interpreters may be expected to embrace. This subset of technologies encompasses different types of applications, both hardware and software. The most remarkable examples are tablet interpreting, the sim-consec pen, supporting ICTs for terminology work also used by translators, and bespoke tools for interpreters (CAI).

\subsubsection{Tablet interpreting}
Tablets are a rather new addition to the interpreter's toolkit. The still rather scarce amount of research published on this subject has highlighted how tablets are applied in a variety of settings and can be used not only for consecutive interpreting \citep{rosado_note_2013,behl_paperless_2013-1,behl_paperless_2013,goldsmith_consecutive_2015,goldsmith_comparative_2017,drechsel_tablet_2016}, which has been the main focus of the analyses conducted so far, but also for assignment preparation and during simultaneous interpreting \citep{paone_mobile_2016}. As for tablet usage during consecutive interpreting, a pilot study conducted in 2015 by Goldsmith and Holley offers a comparative user evaluation of tools suitable for note-taking during consecutive interpreting, tablet features, and styluses. It highlights how tablet interpreters mostly seek reliability, durability and a good user experience when selecting tablets and tools. Research conducted thus far has identified several advantages provided by tablets over pen and paper for consecutive interpreting and over laptops in the interpreting booth. Tablets offer a ``simplified user experience'' \citep[11]{drechsel_tablet_2016} and longer-lasting batteries, can easily fit in the small perimeter of a booth and are quieter than paper and most laptops. These aspects also favour their use for terminology look-up during interpreting. \citet[17]{drechsel_tablet_2016} even go so far as hypothesising that using such a ``streamlined device may decrease cognitive load by allowing interpreters to focus on the necessary complements to the task at hand'', although they recognise that research is needed to test such a hypothesis. As with all tools, it is reasonable to assume that training may improve users' command, and tablet interpreting performance as a consequence \citep[43]{goldsmith_comparative_2017}. \citet{goldsmith_consecutive_2015} identify potential disadvantages: using tablets when moving can be cumbersome, tablets may generate mistrust in clients who are not familiar with this technology applied to interpreting, and they do come with additional stress, costs and a certain learning curve. As for the perceived professionalism, this largely depends on clients' knowledge of and attitudes towards this technology applied to interpreting.

\subsubsection{Sim-consecutive and digital pen}
The digital pen is another technology that can provide interesting advantages both for training and for practitioners. It belongs to the category of mobile computing platforms and consists of ``a microphone, a built-in speaker, 3D recording headsets, and an infrared camera'' \citep[77]{orlando_digital_2010}. Users can write as they would with any other pen, but must use special micro chipped paper onto which data is captured. Since the notes and the recording are synchronised, the interpreter can then play back the recording from the notes.

This technology opens up new possibilities for the profession, giving birth to a new hybrid mode of interpreting known as simultaneous consecutive interpreting, sim-consec, or consec-simul with notes. In this interpreting mode, the interpreter takes notes as usual using the digital pen, and can then deliver the speech simultaneously while playing back the recording from the pen's ear set and looking at her notes at the same time. The digital pen also allows for playback speed adjustment, which facilitates rendition and promotes precision. Overall, the advantages of the sim-consec pen have been identified by scholars as ``better interpreting performance, which was seen in `more fluid delivery, closer source-target correspondence' \citep[14]{hamidi_simultaneous_2007}, greater accuracy, fewer `disfluencies' (hesitation phenomena), greater interpreter confidence, and a more complete rendition'' \citep{orlando_study_2014}. \citet[78]{orlando_digital_2010} adds that ``tablet PCs are more expensive and less portable than a pen and a notepad'', which speaks in favour of a digital pen as an alternative to traditional pen and paper support for consecutive interpreting.

Digital pens also offer interesting advantages for the training of future interpreters. As \citet[72]{orlando_digital_2010} observes, trainers are often faced with the issue of ``encouraging their students to develop their own personal [note-taking] systems freely'', while at the same time being unable to ``observe these systems in the process of being developed throughout the training''. As a consequence, they are unable to intervene with effective feedback, or to address the issues underlying a poor rendition or an ineffective note-taking technique. The possibility of observing the notes while in the making and to link the audio and the video of the notes taken does not only support trainers, but could additionally prove beneficial in terms of students' self-awareness, self-evaluation and self-regulation, and encourage more objective, evidence-based assessment of the learners' notes.

\subsubsection{Supporting ICTs for terminology work}
Interpreters can make use of a host of technologies to support their terminology work before, during, and after the assignment. These supporting technologies include general-purpose tools, tools also used by translators, and bespoke tools for interpreters, i.e. CAI tools.

For instance, interpreters can use text-processing or database software (e.g. MS Word or Excel) to compile their glossaries. While not developed specifically for interpreters, these solutions are very flexible and can easily be adjusted to interpreters' individual needs.
CAT tools and other resources and solutions commonly used in translation such as TETs and TMSs can also be applied to interpreters' terminology work. These tools can be used to process preparation documents and extract terminology to compile domain-specific glossaries. Online databases and electronic dictionaries can be used to look up terminology, while concordancers can be used to explore the use of terms in context. As pointed out in \sectref{proconstools}, however, these tools are not optimised for interpreters, and present a series of limitations.

\begin{sloppypar}
CAI tools have been developed with the goal of addressing said limitations, targeting the specific needs of interpreters' terminology work. During the preparation phase, for instance, CAI tools can help ``moving cognition upstream'' \citep{stoll_jenseits_2009} by helping interpreters extract terminology from ad-hoc corpora created through the automatic collection of texts on a particular subject, automatically annotating speech transcripts provided by clients, and looking up translation equivalents, definitions and other linguistic and extra-linguistic information from several sources simultaneously. They can help interpreters increase their productivity by speeding up glossary creation and terminology memorisation, facilitate information sharing through dedicated import and export tools, and provide seamless access to the terminology databases compiled during the preparation phase. Due to their relevance for the present work, CAI tools are discussed in detail in the following sections.
\end{sloppypar}

\section{CAI tools} \label{CAItools}
\begin{sloppypar}
Among the technologies aimed to support the interpreting process, CAI tools have received an increasingly wider share of attention. Unlike technologies which mediate the provision of the interpreting service (see \sectref{tech_mediation}) and can be described as setting-oriented technologies, CAI tools fall into the category of pro\-cess-ori\-ent\-ed technologies \citep{fantinuoli_computer-assisted_2018}. The rationale behind their creation is namely that of providing targeted support for each of the interdependent sub-processes involved in interpreting, thanks to a dedicated architecture and to features optimised for the interpreting workflow.
\end{sloppypar}
\subsection{Definition} \label{CAIdef}
Due to the multitude of tools and resources which interpreters can use as support, there has been some inconsistency in the use of the term CAI \citep[46]{will2020computer}. As remarked by \citet{will2020computer}, the term CAI tool can in principle be used broadly to indicate any kind of supporting technology applied to interpreting. Some authors (e.g. \citealt{fantinuoli_computer-assisted_2018,prandi_designing_2017,prandi_exploratory_2018}) have discussed as CAI tools only those bespoke tools explicitly developed to address interpreters' needs. Other authors, on the other hand, use the term CAI tool in broader terms. For instance, \citet{costa_technology-assisted_2014} also include unit converters; \citet{ortiz_computer-assisted_2018} also mention ``note-taking software, audio and video conference systems or learning platforms'' (see also \citealt[47]{will2020computer}). Other authors have even used the term to indicate other categories of technologies applied to interpreting, including ``terminology aids, such as laptops, notebooks, small handheld PDAs (Personal Digital Assistants) or similar instruments with Internet accessibility that may facilitate interpreters' work'' \citep[90]{tripepi_winteringham_usefulness_2010}.

To provide some clarity in the use of the term, \citet[47]{will2020computer} proposes to define non-bespoke tools targeting the pre- and post-process phases as ``secondary CAI tools''. This term thus indicates ``any computer-based applications to search, compile and record terminologically relevant structures for a subsequent interpretation'' \citep[47]{will2020computer}. Secondary CAI tools are therefore mainly derived from computer linguistics and can also comprise corpus managers and corpus analysis tools, semantic networks (e.g. Babelnet, see \citealt{navigliBabelNetAutomaticConstruction2012,navigliTenYearsBabelNet2021}), terminology extraction tools, etc, i.e. the technologies discussed in \sectref{termtoolsint}.

In addition to secondary CAI tools, ``primary CAI tools'', i.e. tools explicitly targeted to interpreters, address the specific ergonomic and cognitive requirements of the in-process phase. Among primary CAI tools, \citet{will2020computer} identifies a subcategory defined as ``integrated'' CAI tools, i.e. those tools which represent a complete workstation for interpreters, integrating both primary and secondary CAI functions, similarly to what CAT tools represent for translators (although in principle, interpreters could also use CAT tools to cover many subphases of their workflow). For the purpose of the present study, I henceforth use the term CAI tools to indicate only those tools which \citet{will2020computer} defines as primary CAI tools.

\subsection{Overview of CAI tools} \label{CAI_overview}
\citegen{rutten_why_2004} model of a CAI tool (see \sectref{termwmodels}) envisages a software programme capable of providing support for each phase of the workflow and of optimising time-consuming operations. Not all tools currently available on the market, however, represent a complete technical implementation of the model. In their relatively short history, CAI tools have gone through an evolution from simple terminology management tools to all-around solutions for conference preparation, even going beyond what had been envisioned by the first scholarly speculations on the topic.

In providing an overview of the tools available, and of those no longer supported, I follow \citegen[44]{fantinuoli_interpretbank._2016} classification of (primary) CAI tools according to their ``architecture and functionality spectrum''. This overview will serve as the basis to motivate the selection of the tool employed in the present study.

In addition to a zero generation of tools, comprising non-bespoke-tools applicable to interpreting (i.e. secondary CAI tools), CAI software can be subdivided into two generations \citep{fantinuoli_interpretbank._2016,fantinuoli_computer-assisted_2018}. This categorisation should, however, not be interpreted in strictly chronological terms. Rather, it mirrors the degree of sophistication of the individual applications.

The first generation of tools consists of programs which offer little more than terminology management for interpreters \citep[212]{hansen2012nutzbarkeit}. This category includes Terminus\footnote{\url{http://www.wintringham.ch/cgi/ayawp.pl/t/terminus} (Accessed: 01.11.2021)} \citep{terminus}, Glossarmanager,\footnote{\url{https://www.glossarmanager.de} (Accessed: 01.11.2021)} Glossary Assistant \citep{glossaryassistant}, Interplex\footnote{\url{http://www.fourwillows.com/interplex.html\#} (Accessed: 01.11.2021)} \citep{sand2003manage,sand2010new} and flashterm Interpreter \footnote{\url{https://www.flashterm.eu/en/} (Accessed: 01.11.2021)} \citep{flashterm}. These tools can be used to organise terminological entries by topic, client, event and other criteria inside multilingual glossaries, the basic components of these tools' architecture. The only exception is flashterm Interpreter. This tool is not term-based, but rather concept-based: the terminological entries can be assigned to categories and tagged individually, and filtered to create ad-hoc glossaries. Some tools, such as Interplex, allow for the creation of multiple databases, while in most CAI tools (also of the second generation) all terminological entries are contained in a single database. Even though the basic functions offered by first-generation tools are similar (glossary creation and storage, basic import and export functions, a feature for glossary printing), some of the more recent tools provide additional functions that expand the range of elaboration by prospective users, such as the creation of ad-hoc term lists for quick terminology memorisation in flashterm Interpreter, or the inclusion of images in the terminological entries. These tools usually also provide a feature for quick terminology look-up, both within single glossaries and/or in the whole database.

To the second category of CAI tools can be ascribed applications that go beyond providing a structured way of organising terminological resources for interpreters. These solutions aim to offer a complete workstation for conference preparation and to support interpreters along the different phases of their workflow. Second-generation CAI tools typically provide the terminology management and glossary creation features present in first-generation solutions, but additionally offer further functions for workflow optimisation. Some examples are document integration and terminology extraction, quick search for translation equivalents and other linguistic and extra-linguistic information across multiple sources (such as online dictionaries and terminological databases), memorisation of relevant terminology and terminology look-up both during the preparation phase and on assignment thanks to the integration of search algorithms to speed up the querying process and effectively deal with time constraints. Second-generation CAI tools thus represent, to a large extent, the actualisation of \citegen{rutten_why_2004} model. To this category one can ascribe Intragloss (discontinued), and Interpreter's Help\footnote{\url{https://interpretershelp.com} (Accessed: 01.11.2021)} with its offline companion tool BoothMate.\footnote{\url{https://interpretershelp.com/boothmate} (Accessed: 01.11.2021)} Intragloss was only available for the Mac operating system, while Interpreter's Help is web-based and provides multi-platform offline applications. Intragloss allowed for quick terminology look-up across multiple online sources within the application itself, thus eliminating the need to switch between the tool and, for example, a search engine. Interpreter's Help is a community-oriented tool where glossaries can be accessed both through the online platform or offline from the companion app BoothMate. In addition to the above-mentioned features common to all second-generation tools, Interpreter's Help also provides functions for managing assignments, sharing glossaries and assignment details online with colleagues, creating ad-hoc flashcards that allow users to memorise translation equivalents and other data, but also features that promote collaboration within the interpreting community: a public glossary database (Glossary Farm), a feature for uploading practice speeches, asking and providing feedback, and a community section with useful links and resources. BoothMate enables users to query their database thanks to a progressive search function that simply requires users to start typing the term they are looking for, and incrementally reduces the number of results presented.

While Fantinuoli distinguishes between two generations of CAI tools, the technological advances provided by artificial intelligence hold great potential for further development of such tools towards fully-fledged virtual boothmates. This third generation of CAI tools, exemplified by InterpretBank \citep{fantinuoli_interpretbank_2012, fantinuoli_computer-assisted_2017}, could represent the next step in human-machine interaction in the field of CAI. While first-generation tools mainly only provide a more rational and streamlined infrastructure for terminology work in interpreting with the bulk of the information processing still done by users, and second-generation tools take a step further by automatising and speeding up individual operations traditionally carried out by the interpreter, third-generation, AI-enhanced CAI tools could provide a framework for optimising each step of the interpreting workflow through technology. When working with these tools, interpreters can focus on refining the work done by the tool, with the bulk of conference preparation having been pre-processed by the software. Even though this goal has not been fully achieved yet, and much will depend on the progress made by machine learning and AI, the CAI tool InterpretBank already presents some features that go beyond what is currently offered by second-generation tools and exemplifies third-generation CAI tools. For its innovativeness, I chose InterpretBank as the tool used in the study. In the following section, I therefore describe this CAI tool in detail.

\subsection{InterpretBank} \label{IB}
InterpretBank combines a central Edit Modality – \citegen{rutten_informations-_2007} central starting page (see \sectref{requirements_CAI}) – with three modules each dedicated to a stage of conference preparation: the Document Modality, the Memo Modality, and the Booth Modality.\footnote{For a detailed and up-to-date description of InterpretBank's modules and functions, the reader may refer to \url{https://interpretbank.com/site/index.html\#features} and to the user guide at: \url{https://www.interpretbank.com/site/docs/index.html} (Accessed: 01.11.2021).} From the Edit Modality, users can access the database, update old glossaries and create new ones, merge glossaries and move terms to other glossaries, automatically search for translation equivalents and definitions both offline, in the integrated resources, and online in pre-selected web pages. InterpretBank is currently the only tool that offers solutions for creating glossaries starting from a single term thanks to the integration of corpus creation tools, and for automatically translating the whole glossary. The user's intervention is still required to assess the results of automatic translation, but such a feature can help optimise interpreters' preparation under time pressure by enabling them to focus on higher-level processing instead of devoting most of their time to manually compiling glossaries ahead of the event. These functions might prove particularly useful when conference interpreters are faced with a scarcity of preparation materials to be used as a basis for terminology extraction and key topic identification. While glossaries are organised within a single database, it is possible to create subglossaries and group glossaries together with tags, which provides an additional layer of structure and customisation.

\begin{figure}
\includegraphics[width=\linewidth]{images/IB_edit.png}
\caption[InterpretBank – Edit Modality]{The Edit Modality in InterpretBank}
\label{fig:IB_edit}
\end{figure}

When interpreters do receive preparation documents from their clients or have found relevant resources on the internet, the Document Modality can assist them in making the most of the available resources. InterpretBank is one of the few tools that support users in extracting terminology from preparation documents, allowing for an application of the corpus-driven interpreter preparation (CDIP, see \sectref{termwmodels}) put forward by \citet{fantinuoli_specialized_2006}. Like Interpreter's Help and Intragloss, InterpretBank makes it possible for users to select relevant terms while reading through conference materials or other sources and add them to the glossary. When working with parallel texts, users can mark term pairs in parallel in order to quickly add them to their glossary, a feature also available in the two second-generation CAI tools previously mentioned. A unique feature offered by InterpretBank is the automatic terminology extraction feature, which can be used to mine terminology either from the whole set or from subsets of available sources, or from single files. The SMART terminology extraction function learns from the user's behaviour to improve terminology extraction results in subsequent TE tasks. The tool helps effectively process speech transcripts by allowing for automatic document annotation, a function which can represent a useful emergency strategy when interpreters receive written speeches to be read aloud shortly before the conference starts. An additional feature which can prove useful for interpreters dealing with EU-related topics is the possibility of downloading the texts of EU legislation directly from EUR-Lex\footnote{\url{https://eur-lex.europa.eu/} (Accessed: 24.07.2022)} into InterpretBank. Interpreters can mine these documents for terminology as with any other document added to the current glossary. The Edit and the Document Modality are therefore strictly intertwined: users can add entries to the glossary that they are currently working on from the Documents modality, and at a later time explore how terms are used in the context of their preparation documents from the glossary entries. The synergy between the two modalities also emerges from their presentation on the user's interface: the Documents modality appears as an additional window juxtaposed to the glossary currently being processed by the user.

After compiling terminological databases, interpreters can receive support in memorising event-related terminology in the Memory Modality, which creates virtual flashcards from the current glossary. Users can choose between manual and automatic presentation. The manual mode can prove particularly useful in the early stages of terminology memorisation, during which it can be useful for the user to mark the terms as ``known'' or ``forgotten''. Following the principle of spaced repetition, the tool presents the user with the forgotten terms at the end of the practice session, so that said terms can be practised once again. The automatic flashcard presentation can be used to test one's own reaction time to the term/stimulus, since presentation speed can be varied, but can also represent an easy way to quickly review the terminology right before the assignment begins or during breaks. A similar option is also present in Interpreter's Help, which provides the additional option of creating ad-hoc flashcard decks. InterpretBank offers two additional features: an option to view examples of the terms in the context of preparation documents, and the possibility of having the terms read aloud. This feature, which makes use of speech synthesis technology, is particularly suited to the needs of interpreters, who process oral stimuli (with the exception of sight and signed language translation). Additionally, it can prove particularly useful for highly non-phonemic languages such as English.

The phase of interpretation proper is covered by the Booth Modality, which completes the architecture of the tool. A similar function is also offered by Interpreter's Help companion app BoothMate. Like BoothMate, InterpretBank's Booth Modality can also be used offline. In this modality, interpreters can quickly search for terminology in their glossaries. Unlike in the Edit Modality, in which users can only work on one glossary at a time, in the Booth Modality it is possible to activate multiple glossaries which can all be queried simultaneously (the ``active glossary''). Additionally, users can also choose to have InterpretBank perform the search inside the whole database or even exploit external resources as an emergency strategy.

The default search mode in the Booth Modality is the dynamic search, which progressively reduces the number of results with increasing input. It is, however, also possible to manually start the query. A host of additional options, such as the fuzzy search and the ``case and access insensitive'' search, facilitate the lookup process during interpreting. 

\begin{figure}
\includegraphics[width=\linewidth]{images/IB_booth.png}
\caption[InterpretBank – Booth Modality]{The Booth Modality in InterpretBank}
\label{fig:IB_booth}
\end{figure}

Perhaps the most advanced feature offered by InterpretBank is the integration of ASR technology. While still marketed as an experimental feature in the freelance version, the integrated ASR option represents the next step in supporting interpreters through technology. The goal of ASR integration into the tool is that of presenting interpreters with elements typically deemed difficult to interpret, ``problem triggers'' \citep{gile_basic_2009} such as numbers, specialised terminology, and named entities. This represents a step towards the creation of CAI tools serving as artificial boothmates and providing support without requiring extensive human-machine interaction. At the moment of writing, InterpretBank offers ASR support for specialised terminology and numbers. A similar feature is also offered for consecutive interpreting: users can create an ``artificial notepad'' allowing them to visualise the automatically-generated transcription of the source speech, looking up term equivalents with a click, automatically convert units, and share the ASR session with a colleague.

Like Interpreter's Help, InterpretBank also offers browser-based features that can be accessed through a private Cloud account. In the cloud, users can upload, edit, share and download glossaries, and access the memorisation and look-up features from the internet, an option particularly appreciated by interpreters who prefer to be device-independent. The cloud options can also represent a practical alternative to using traditional import and export features to share glossaries as text or Excel files.

\section{Conference interpreters' use of supporting technologies} \label{habits_terminology_int}
Given the role of terminology acquisition for the interpreting process, the distinctive features of terminology work in interpreting, and the availability of dedicated software for interpreters, scholars have taken interest in exploring interpreters' practices when compiling terminological databases for assignment preparation and consulting them during interpreting.

The surveys conducted over the years paint a picture of conference interpreters' level of computerisation, use of technological support pre-, peri-, in- and post-process (both in terms of hardware and software), and of their needs in terms of dedicated solutions for terminology work. These surveys provide valuable information on the extent to which CAI tools and other supporting ICTs are actually employed by interpreters in their professional workflows.

\subsection{Conference interpreters' level of computerisation} \label{computerisation}\largerpage
When discussing the individual solutions chosen by interpreters as a support for their terminology work, their overall level of computerisation and their adoption of computer support in the various phases of interpretation is worth considering, as it may help put their practices into perspective.

The first inquiry into conference interpreters' preparation practices dates back to 1992. \citet{moser-mercer_banking_1992} distributed a questionnaire among 260 interpreters, all AIIC active members with English among their working languages. Among the 130 respondents, the level of ``computerisation'' \citep[510]{moser-mercer_banking_1992}, i.e. the percentage of respondents who own or have access to a computer, was already quite high (62.3\%), and seemed to correlate positively with the years of professional experience and the number of interpreting days per year. Moser-Mercer speculated that this trend could be due to a higher level of specialisation among more experienced professionals, which would in turn promote computer use for terminology work. A survey conducted by \citet{drechsel_computereinsatz_2004} supports \citegen{moser-mercer_banking_1992} findings, with only two respondents not using the PC in any of the phases of an interpreting assignment. It should be noted, however, that the sample was quite small and only representative of the German market (46 professional interpreters). A more nuanced picture of the use of computers as technological support for terminology emerges when considering the individual phases of the interpreting assignment.

\subsection{Computer and software use for assignment preparation} \label{pc_prep}
\citegen{moser-mercer_banking_1992} survey did not venture into a detailed analysis of the tools used for preparation. However, it provides valuable insight into which types of solutions interpreters used at a time when both CAT and CAI tools were starting to be developed. The survey reports that 51.3\% of those who used a computer medium chose terminology databanks (40\%), databases (35.5\%) and spreadsheet software (31\%) to compile and organise terminological information and documentation. The main sources for documentation ahead of the event were event documents and bilingual dictionaries, and a widespread use was made of terminology lists compiled personally or supplied by the clients. External databases were used only to a limited extent. These findings support the notion that terminology work in interpreting (as in translation) is performed ad-hoc and strictly interlinked with the individual assignment. The survey does, however, provide us with two interesting findings. At the time of her study, 67\% of respondents showed an interest in terminology management software, while 72.7\% expressed an interest in exchanging terminology in electronic form. This seems to speak in favour of a high degree of computerisation for preparation work. About a decade later, \citet{valentini_uso_2001,valentini_uso_2002} conducted a similar survey on a sample of 130 professional conference interpreters, both freelancers and staff, 40\% of which with more than 20 years in the profession, working mostly (94.5\%) in the simultaneous mode. In the preparation phase, a third of her sample used electronic terminology databases (37\% used paper glossaries), and 11.3\% conducted terminology extraction (TE) automatically. The most widespread programs for terminology work were Microsoft Word or similar (67.7\%), followed by Excel or similar (11.4\% of respondents). Users of these solutions generally showed a higher degree of satisfaction than users of dedicated terminology software.

A similar picture of the software used by conference interpreters emerges from the t-survey by \citet{zielinski_forschung_2005}: of the 81 interpreters involved, 63\% performed terminology work; 66.1\% used Word or Excel tables for terminology management, while 53.2\% also used terminology management systems (TMS). In this survey, no mention of tools developed specifically for interpreters (see \chapref{chapter3}) is made, even though some of them were already available at the time (e.g. Interplex, LookUp/DolTerm, and TermDB). As for TE, the trend is similar to the study by \citet{valentini_uso_2001,valentini_uso_2002} (13.9\% informants used terminology extraction tools).

\citet{bilgen_investigating_2009} conducted a small-scale survey on a sample of experienced CACI members, the Canadian branch of AIIC. \citegen{bilgen_investigating_2009} findings are along the lines of the surveys previously mentioned: 70\% of respondents used word processors or spreadsheets for terminology management, while 85\% recorded terms on paper (multiple answers were possible). On-screen work was preferred before and after conferences. Interestingly, 77\% of the sample never used a TMS, and no mention was made of interpreter-specific software. This contrasts with \citegen{zielinski_forschung_2005} findings, but in their sample most interpreters also worked as translators. \citet{bilgen_investigating_2009} does not specify whether this is the case in her survey. Only one respondent reported using a TMS; another interpreter a database management programme. None of the surveyed interpreters mentioned interpreter-specific software.

In a survey conducted in 2010 on a sample of 222 conference interpreters (mostly AIIC members and/or working for the EU or the UN), \citet{berber-irabien_information_2010} found that ICTs were mainly used in the preparation phase, and only scarcely (15\%) for post-assignment debriefing. Terminology databases (such as IATE) were used by 88\% of her sample. Disappointingly, terminology management software, and in particular programs for interpreters such as Interplex or LookUp, were mentioned in the overview of tools for interpreters, but were not included in the questionnaire categories. Of all ICTs considered\footnotemark, search engines were those used with more frequency (in 38\% of cases). While these findings overall support previously identified trends, no distinction was made between setting-oriented and process-oriented technologies, a limitation which hinders the direct comparison with previous studies.
\footnotetext{\citet{berber-irabien_information_2010} looked at search engines, online dictionaries and encyclopedias, terminology databases, electronic norms manuals, parallel texts, do-it-yourself corpora; technologies now considered obsolete – pocket electronic dictionaries, CD-ROM dictionaries, paper encyclopedias – and terminology databases, as well as setting-oriented technologies \citep[155]{fantinuoli_computer-assisted_2018} such as remote interpreting, videoconferencing and telephone interpreting.}

In \citeyear{wagener2012vorbereitende}, Wagener conducted a survey on 102 interpreters, mainly German. In line with previous survey work, she found that most interpreters in her sample used general-purpose tools such as MS Word and even paper, while MS Excel was less popular (less than 30\% of the sample). Only 26\% of her sample used interpreter-specific tools. Regrettably, it was not mandatory for her respondents to include the names of the tools used. An even smaller percentage (13\%) used terminology software.

\citet{jiang_interpreters_2013} and \citet{corpas_pastor_survey_2016} conducted the two most recent surveys available on interpreters' terminology practices. \citegen{jiang_interpreters_2013} survey focused on conference interpreters' glossaries for SI. The response rate was very high at 21\%, and the large sample ($n = 476$) mostly consisted of AIIC members, two thirds of whom had more than 15 years of professional experience. \citet{jiang_interpreters_2013} analysed several aspects of glossary creation for SI, such as the items included in the glossary, the sources used and the frequency of glossary creation. A very interesting finding was that the preferred medium remained loose paper (57.6\%), followed by Word glossaries (55.7\%). Most interpreters seemed to combine digital glossaries with a printout, so it can be assumed that both were taken into the booth. A smaller percentage of the surveyed interpreters (15\%) used ``glossary software''. An even smaller number of respondents use other tools such as Trados Multiterm and Interplex. An interpreter's glossary consists mainly of a table or a list with glossary items (93.7\% of responses). Given the high response rate and large sample, \citegen{jiang_interpreters_2013} findings can be considered quite representative of the glossary creation practices of experienced, professional conference interpreters working in the simultaneous mode until some years ago.

Finally, \citet{corpas_pastor_survey_2016} aimed to explore interpreters' use of ``technology tools'' in the various interpreting modes and settings. For the purpose of this study, I will take into consideration the responses regarding simultaneous interpreting (a total of 92 out of 133). The respondents used mainly bilingual dictionaries, digital glossaries and thesauri, but also databases and term banks during preparation. Despite the rather small sample and the – in my opinion – somewhat arbitrary interpretation of data by the authors, their findings align with those of similar surveys.

The surveys presented above span over 25 years. The sample sizes vary, as does the specific focus of each survey, although they all relate to technology use during preparation. Even though these surveys are only comparable to some extent, they provide a picture of technology use for terminology work prior to the (simultaneous) interpreting task. On average, at least until 2016, conference interpreters tended to use computers for preparation, consult digital terminology databases and compile digital glossaries, mostly in the form of terminology lists and tables. General software prevailed, with a preference for Word or similar text processing programs, followed by Excel or other spreadsheet applications. The interest in software solutions for preparation identified by \citet{moser-mercer_banking_1992} seems to have led to a widespread use of various technologies for assignment preparation. Despite these developments, which – there is reason to believe – will continue in the years to come, paper has not yet disappeared as an additional support medium for glossary work. On the contrary, paper seems to remain an integral component of interpreters' terminology work and is often combined with the afore-mentioned text-processing programs. To a limited extent, terminology management systems such as Trados Multiterm are also used, although it seems that especially interpreters who also work as translators use these kinds of tools. As emerges from the t-survey \citep{zielinski_forschung_2005}, automatic terminology extraction with dedicated TET seems to be a rare practice among interpreters, who prefer manual TE. Considering the speed at which technology progresses, and the acceleration, also due to the COVID-19 pandemic, of what has been defined as ``the technological turn'' in interpreting \citep{fantinuoli_technological_2019}, these results are in all probability no longer representative of the situation in 2022. It can be reasonably assumed that the ratio of interpreter-specific technologies for assignment preparation compared to more ``traditional'' solutions has now shifted more towards the first. Regrettably, to the best of my knowledge, no survey on interpreters' use of technology pre-process has been conducted since 2016.


\subsection{Computer and software use peri- and in-process} \label{pc_during}
If the paper medium has not yet been entirely supplanted by the electronic one in the preparation of glossaries \citep{bilgen_investigating_2009, jiang_interpreters_2013}, it is nonetheless undeniable that there has been a progressive penetration of technological support in the interpreting profession. As emerged from the surveys, however, at least until some years ago, the technological support inside the booth has remained limited. In Valentini's (\citeyear{valentini_uso_2001}) survey, dating back almost 20 years, only 27.6\% of survey participants stated that they use a computer in the booth. The largest percentage of booth computer users in her sample worked for the European institutions. At EU institutions, ``the greater availability of infrastructure [...] facilitates and encourages the penetration of information technology compared to other national and international institutions'' (p. 162). A similar result emerged from \citegen{bilgen_investigating_2009} and \citegen{berber-irabien_information_2010} surveys, which found that computer and software use was more popular before and after the assignment, while limited inside the booth. An encouraging piece of data that emerges from the survey conducted by \citet{valentini_uso_2001,valentini_uso_2002} is that 66.1\% of respondents considered ICT support as potentially useful for SI. This is, however, a rather general claim and tells little about which ICTs are being referred to, nor which sub-processes they could support. Interestingly, 43.4\% of the sample deemed terminology look-up with technological support ``very useful''. \citegen{bilgen_investigating_2009} sample was also largely in favour of computer use in the booth, and half of the sample used one.

In Valentini's (\citeyear{valentini_uso_2001,valentini_uso_2002}) survey, no distinction was made between peri-pro\-cess and in-pro\-cess with reference to technology use in the booth. \citet{drechsel_computereinsatz_2004} did make this distinction. In the small sample he considered, 16 interpreters used a PC peri-process, 16 to help their boothmates and 13 to look up terminology themselves; 14 respondents used laptops to work on documents and 16 for follow-up work during the conference. As for the medium, 11 respondents out of 46 used paper glossaries in addition to digital glossaries.

The most recent inquiries in the terminology management practices of conference interpreters also show that, although with some limitations, the technological support has increasingly made its way into the interpreting booth. For instance, \citet{berber-irabien_information_2010} found that terminology databases are the preferred technology tool for accessing terminology during simultaneous interpreting. \citet{corpas_pastor_survey_2016} also came to a similar conclusion, identifying bilingual dictionaries and personal glossaries as the preferred digital tool used by interpreters to search for terminology during the task. Nonetheless, most conference interpreters seem not to rely on tools created specifically for interpreters. \citet{corpas_pastor_survey_2016} observe that ``regarding technology tools during an interpreting task, most of our simultaneous interpreters do not count on help from technology resources. The only tools used in specific circumstances during an assignment are bilingual dictionaries, glossaries and, in some cases, web-based resources'' \citep[26]{corpas_pastor_survey_2016}.

\citet{wagener2012vorbereitende} had also found a widespread use of online dictionaries, search engines and other search tools in the booth, pointing to terminology work also happening peri- and in-process and not only pre-process. On the other hand, she had found a very limited use of terminology management systems in the booth, similarly to what had been postulated by \citet{stoll_jenseits_2009} and \citet{rutten2011TMS} (see \citealt{wagener2012vorbereitende}). However, the vast majority of her respondents bring a technological support into the booth, be it a laptop, a netbook, a smartphone or a tablet, almost always coupled with handwritten or printed documents (90\% of surveyed interpreters).

To date, the only inquiry into conference interpreters' use of CAI tools for simultaneous interpreting is the survey conducted by the Sprachen und Dolmetscher Institut (SDI Munich) in \citeyear{sdi_munchen_detaillierte_2007}. The sample was made up of 135 AIIC members and conference interpreters members of other associations. Unfortunately, the survey was conducted in German, limiting the representativity of the sample. As for computer use, 68\% of the sample brought a PC in the booth and 41\% used it during interpreting, while 26\% preferred booth-specific software. The participants who did not use CAI tools mainly used other tools, a good percentage also ``during interpreting'' (59\%). It is unclear whether ``during interpreting'' (``während des Dolmetschens'', \citealt[28]{sdi_munchen_detaillierte_2007}) should be intended as during delivery itself, or whether this could also refer, for instance, to helping the boothmate with terminology look-up during their turn. A surprising finding, which would deserve further exploration, is that 41\% used self-developed tools. Because of the specificity of the sample, these findings cannot be generalised. Furthermore, the survey dates back to 2007 and is in all probability no longer representative. There is a need for an up-to-date inquiry into interpreters' level of computerisation and especially of their use of software in all phases of an interpreting assignment. Except for this survey, CAI tools are yet to be systematically integrated into such inquiries.

Despite the limitations of these surveys, they suggest a few trends in conference interpreters' use of terminology management software and other ICTs for terminology work, as well as in their level of computerisation. The average modern conference interpreter seems to make extensive use of ICTs in the pre-process phase, bringing a laptop into the booth, often together with some information on paper or a printed glossary, and conducts post-conference work on a laptop, mostly in the form of terminology update.
The most popular technologies used to compile glossaries are general-purpose text-processing or database software, such as MS Word or Excel. Terminology extraction and terminology management tools are also used, especially by interpreters who also work as translators. However, the use of these tools is quite limited among interpreters, as is the use of CAI tools, although they seem to be more popular. This may suggest that there is still room for further optimisation and tailoring of these tools to interpreters' needs.

The widespread use of paper, despite the possibilities offered by modern technology for a paperless booth, may also point to a limitation of current CAI tools. It is possible, as \citet[77]{wagener2012vorbereitende} observes, that digital glossaries and paper are used for different purposes. The first support a kind of terminology work which aims at creating terminology resources that can be helpful also beyond the individual event. Having long-lasting terminological resources saves preparation time and makes terminology work more sustainable in the long run. Paper, on the other hand, may represent the ideal support for short-term terminological needs, i.e. to provide interpreters with the necessary \textit{aide-memoires} for those terms which tend to be forgotten. CAI tools currently do not seem to address this specific need.

\subsection{Attitudes towards CAI tools} \label{CAI_attitudes}
Having considered the current state of CAI tool development, the specific interpreter needs and the potential of ASR for an even more efficient interpreter-tool interaction in-process, it is somewhat surprising that CAI tool usage is still relatively limited, as emerges from the surveys presented in \sectref{pc_during}. While providing a snapshot of interpreters' terminological practices at the moment of data collection, these surveys also bring to light some of the motivations behind the limited inclusion of CAI tools in interpreters' workflows. While some negative attitudes have subsided over time, when asked to comment on their tool choice or to provide their opinion on the adoption of computers and CAI tools, conference interpreters seem to share some common points of criticism.

\citet[512]{moser-mercer_banking_1992} observed how the only tools that ``met almost all requirements stipulated by interpreters'' were Term-PC and SDL Multiterm. Both programs allowed for multilingual glossary creation, quick terminology retrieval, free definition of entry structures and options for glossary import, export and printing. Since then, several CAI tools were developed. Their use in the booth is, however, still considered problematic both by practitioners and researchers. In discussing the results of her survey on computer use in the interpreting booth, Valentini observed that terminology look-up while ``on air'' would only be possible for redundant terminology, i.e. when terms are repeated more than once within a speech. In her opinion, interpreters would prefer other strategies such as simplification through paraphrasing or the use of hypernyms to the more distracting search in their terminological resources, since clear and close rendition of the source message is a more prominent quality factor than terminological accuracy.

The distraction potential of CAI tools seems, indeed, to be a common point of criticism on CAI tools and, more generally, of terminology look-up during interpreting, as emerges from the SDI (\citeyear{sdi_munchen_detaillierte_2007}) questionnaire and \citegen{bilgen_investigating_2009} survey. In the first, the distracting effect (``ablenkende Wirkung'', \citealt[29]{sdi_munchen_detaillierte_2007}) of terminology software is mentioned by 6\% of the 82 interpreters not using such solutions. The main reasons for the exclusion of such software from interpreters' toolkit are however the lack of necessity (57\%), because more traditional solutions are preferred, the lack of knowledge about such tools (35\%) and the fact that these tools were considered unconvincing or not yet sophisticated enough (22\%). In view of the recent developments in CAI technology, this last point may not be as relevant as before. Other reasons mentioned are, in descending order of importance, lack of space in the booth, poor customisation and resistance to technology because of excessive complexity of use. Similarly, \citegen{bilgen_investigating_2009} survey respondents observed that using the computer in the booth might be distracting for the interpreter and noisy, since the sound of typing could be picked up by the microphone, thus distracting the audience, too. This argument is, however, increasingly losing strength, as many modern laptops come with a silent keyboard, and some interpreters have already successfully replaced their laptops with tablets.

To explain the continued presence of paper as additional support in the booth, even considered the preferred medium used for interpreters' glossaries in her survey, \citet{jiang_interpreters_2013} advanced the hypothesis that interpreters' may jot down essential glossary items on loose paper sheets, which would make terminology access immediate. This is a necessity, since ``accurate and just-in-time retrieval of glossary items is vital, especially at technical meetings'' \citep[90]{jiang_interpreters_2013}. While this is true, Jiang seems not to take into consideration the quick search function in Word or Excel files and the progressive search function available in some CAI tools when stating that ``physically turning a page is probably simpler and faster than having to access a given item or page in a sizeable computer file or database'' \citep[91]{jiang_interpreters_2013}. Rather, the choice to include paper may be more of a strategic nature (see \sectref{pc_during}).

The potential disadvantages of CAI tools for terminology look-up have also been discussed in several publications on the application of technologies to conference interpreting. While CAI tools should theoretically ``represent the most effective information interface when interpreting'' \citep[90]{tripepi_winteringham_usefulness_2010}, the feasibility of their use is often questioned. These tools are described as potentially ``time-consuming and distracting'' (ibid.), or leading to a ``loss of concentration'' \citep[91]{tripepi_winteringham_usefulness_2010}. \citet{berber-irabien_information_2010} similarly observes that their use might interfere with listening and concentration. Given the complexity of the interpreting task, while using CAI tools ``the interpreter [...] may not have the time or the cognitive ability to look up a word [...] or detect and choose the correct translation [...]'' \citep[49]{fantinuoli_interpretbank._2016}, because ``typing an unknown word [...] requires an additional time-consuming effort which would affect the already existing efforts that interpreters support during their work'' \citep[91]{tripepi_winteringham_usefulness_2010}. Additionally, ``should the right word be found it may not be possible to incorporate it smoothly in speech'' \citep[80]{veisbergs_terminology_2007}.

The surveys and publications discussed suggest a certain interest in technologies for conference preparation and terminology work specifically developed to meet interpreters' requirements and the need for dedicated tools. While CAI tools' potential is overall acknowledged, their hypothesised and perceived limitations should not be ignored. The disadvantages that these analyses point to mainly concern the application of such tools on the simultaneous, in-process phase.

The negative attitudes and the indifference encountered among interpreters towards non-bespoke supporting technologies and CAI tools may be compared to translators’ attitudes towards CAT tools and MT, a technology often integrated into CAT tools. While a considerable number of translators seem to have adopted CAT tools as a staple in their workflows, as suggested by recent surveys (e.g. \citealt{moorkens_assessing_2016,steurs2017translators}), many translators express dissatisfaction towards their tools or frustration in their use. In translation, this feeling of frustration may be even more pronounced than in interpreting, as the use of specific tools is somehow imposed by the client, e.g. the translation agency. Translators' ``cognitive friction'' \citep{ehrensberger2015ergonomics} in using CAT tools manifests in the irritation and negative attitudes expressed in a number of surveys (e.g. \citealt{OBrien_Ehrensberger-Dow_Connolly_Hasler_2017}). Translators' dissatisfaction concerns complex user interfaces, a lack of intuitiveness and user-friendliness and suboptimal navigation within the tool which slows down the workflow. This contrasts with the identification of high working speed and intuitive user interfaces as essential features of translator tools (see \citealt{OBrien_Ehrensberger-Dow_Connolly_Hasler_2017}).

In interpreting, a certain amount of frustration may be avoided by simply choosing not to use tools perceived as useless or unsatisfactory, as the choice of supporting technologies is often left to the individual interpreter. This may, in part, be mirrored in the lower percentages of translation tools and CAI tools users among interpreters and the resulting digital divide with translators. However, if other players become involved in the development of CAI tools, e.g. RSI providers including CAI as support in their platforms, it is possible that interpreters may soon have to use tools they have not personally selected. 
As remarked by \citet{hansen2012nutzbarkeit}, most tools for translators and interpreters are yet to exploit computational linguistics and speech technologies to their fullest extent, which results in tools not entirely optimised for their end-users. As for translation tools, greater involvement of interpreters in the development of supporting tools may help to mitigate some of their limitations and perceived drawbacks. At the same time, research on the use of CAI tools can help define how they impact the product of interpretation and to what extent they may support or impair the cognitive processes underlying interpreting.

\section{Research on CAI tools} \label{CAI_evaluation}
The recent developments in the field of CAI have renewed and multiplied the interest of the interpreting community for this subject. This is demonstrated by the increasing number of publications on the topic. In addition to the foundational works by \citet{rutten_terminologieprogramme_2000,rutten_why_2004,rutten_informations-_2007}, \citet{stoll_jenseits_2009} and \citet{will_bemerkungen_2000,will_terminology_2007} providing a model of software programs for interpreters (see \sectref{termwmodels}), the publications devoted to CAI tools address a number of topics and issues inherent to the tools, ranging from a simple presentation and comparison of the available solutions to the first empirical tests conducted on one or more tools.

Among the first publications which appeared on the topic, several contributions aim to provide prospective users with an overview of the CAI tools to choose from and a set of criteria for their selection. Several articles by \citet{costa_technology-assisted_2014,costa_comparative_2014,costa_interpreters_2015} detail the tools available on the market and highlight the features addressing conference interpreters' needs. The authors offer ``a tentative catalogue of current language technologies for interpreters, divided into terminology tools for interpreters, note-taking applications for consecutive interpreting, applications for voice recording and training tools'' \citep[68]{costa_interpreters_2015}. CAI and related terminology management tools, as well as other technologies relevant to interpreting, are discussed together. In \citet{costa_interpreters_2015}, the authors focus on CAI tools, analysing both three of the best-known CAI tools (Intragloss, InterpretBank and Interplex), and other lesser-known or non interpreter-specific terminology management software (i.e. SDL MultiTerm, AnyLexic, Lingo, Unilex and The Interpreter's Wizard). In their analysis, the authors evaluate the tools chosen for the comparison against a set of 15 features identified as priorities in relation to conference interpreters' needs. Of the 15 criteria, five are classified as fundamental and ten as secondary. The authors do not clarify the rationale behind this distinction, nor do they specify which features are deemed essential and which secondary. Additionally, they seem to base their evaluation on the rather unjustified goal of identifying the most complete solution. While this might be a useful piece of information, the tool so identified may not coincide with the one most suited to the needs of interpreters. In the authors' analysis, the programme which received the highest score is SDL MultiTerm. Overall, the evaluation appears rather arbitrary, as it excludes features which are particularly relevant to the interpreter's workflow such as quick terminology look-up or terminology extraction from preparation documents \citep{fantinuoli_interpretbank._2016}.

\citet{will_zur_2015} proposes a similar evaluation of CAI tools and lays down a set of criteria for their assessment, with the goal of identifying deficits and proposing potential solutions to be implemented. Will's contribution has the merit of basing the definition of the evaluation criteria on a theoretical model of interpreters' terminological work, which he defines as ``dolmetschorientierte Terminologiearbeit (DOT)'' [interpreter-oriented terminology work] \citep[181]{will_zur_2015}, and is at the intersection of the terminology models by \citet{wuster_einfuhrung_1979} and \citet{gerzymisch-arbogast_termini_1996}, of \citet{moser_simultaneous_1978} and \citegen{hauenschild_process_1997} process model of simultaneous interpreting, and of \citegen{gile_regards_1995} effort model (see \sectref{gile}). The three principles thus identified as fundamental for the implementation of the model (adequacy and pattern building, simultaneity, and phase-specific usage) in CAI tools are used as a basis for the definition of three key criteria against which the tools should be evaluated: flexible visualisation, comprehensive database and help functions (1), ergonomics (2) and user-friendliness (3). Unlike \citet{costa_technology-assisted_2014,costa_comparative_2014,costa_interpreters_2015}, the author compares Interplex, Terminus, LookUp professional and InterpretBank 3, i.e. CAI tools as they are intended in the present work. The tool evaluation presents the limitation of being subjective, although based on clearly motivated criteria. The author does not involve additional raters. The involvement of a large sample of conference interpreters in the evaluation would have been welcome. Some of his suggestions (such as terminology extraction, automatic glossary population with definitions and translation equivalents) have, however, already been implemented into some tools, a sign of the rapid evolution of technology in this field.

In addition to these comparisons and evaluation attempts of several tools by scholars, a number of bachelor's and master's theses have been devoted to the subject. This suggests a growing interest for these tools among the newer generations of conference interpreters. In particular, \citet{de_merulis_luso_2013} focused his analysis on the CAI tool InterpretBank, which he describes in detail. His was one of the first attempts at investigating the impact of CAI tool use on the quality of simultaneous interpreting in terms of terminological accuracy. Similarly, \citet{gacek_softwarelosungen_2015} reviews several CAI tools and offers a detailed description of InterpretBank, defined as one of the most user-friendly tools available to interpreters. He reports the results of two experiments carried out with the tool, for which qualitative data was collected through questionnaires. Users were asked to rate the usability of InterpretBank during a simultaneous interpreting session (first experiment) and after two months of usage (second experiment) and to compare it with printed glossaries prepared in Word and Excel. Data analysis, although limited to a sample of 12 questionnaires, seems to indicate that InterpretBank provides an advantage in terms of efficiency, thanks to features such as the dynamic search function or the Memory Modality.

Drawing on trainee interpreters' interest into new technologies, interpreting research has looked at how CAI tools, in addition to more established technologies such as RSI, could be integrated into the interpreting curriculum. \citet{prandi_uso_2015,prandi_use_2015} carried out an exploratory study on the integration of CAI tools into the Master's degree in Interpreting at the University of Bologna/Forlì. The 12 study participants were divided into two groups: one group attended an introductory class on InterpretBank and then received practical training in the booth (three sessions), while the other attended three introductory classes on the topic and trained with the tool only once. Students worked in pairs and were free to establish how to interact with the software and with the boothmate while using the tool during SI. While the study was of qualitative nature and the sample relatively small, results seem to indicate that CAI tools may help achieve high terminological accuracy. InterpretBank was overall judged as user-friendly. Nonetheless, the study showed that hands-on training with the tool is also necessary: the group which enjoyed more booth time with InterpretBank before data collection showed a greater deal of independence in working with the tool during interpreting. The participants in this group had started to develop their own strategies for looking up terminology within the tool, for instance deciding beforehand whether terms should be searched by the active interpreter or by the boothmate. They also showed greater agility in coordinating CAI tool usage with more traditional methods for suggesting equivalents for specialised terms, such as writing down terms. While these results cannot be generalised, they seem to provide an argument for the introduction of these increasingly relevant technologies into the interpreting curriculum.

On the background of the increasing interest for CAI tools, it is interesting to consider their level of integration into the interpreting curriculum. In 2017, \citet{prandi_cai_2020} conducted a survey involving 25 higher education institution members of the CIUTI\footnote{Conférence Internationale Permanente d'Instituts Universitaires de Traducteurs et Interprètes} network from 15 countries offering training programmes in conference interpreting. Survey results show that CAI tools are mostly seen as a secondary technology to be taught to prospective interpreters, whereas higher priority is given to remote interpreting technologies. With a few exceptions, the responses also pointed to a lack of knowledge on the topic among trainers, which emerged from the confusion around the term ``computer-assisted interpreting'', which is often interpreted to include other technologies applied to interpreting, such as RSI or computer-assisted interpreter training (CAIT). From the survey emerges, however, a certain openness towards conducting more research into the subject. The reasons why CAI has not yet been included in the curriculum are often of financial nature\footnote{As mentioned by some respondents who may, however, be actually making reference to remote interpreting systems.} or organisational, as this would require a restructuring of the training curriculum. Very often, the lack of knowledge on the subject among trainers makes it difficult to expand the curriculum to include this topic. There are, however, a few exceptions: notably the Universities of Bologna/Forlì, Mainz/Germersheim, Innsbruck and Heidelberg. These institutions either offer dedicated courses on CAI tools or organise workshops on the subject. The training usually involves a mix of theory and practice, and presents students with several tools. Suggestions for the inclusion of CAI tools and other interpreting technologies (RSI and MI) in interpreter training are offered by \citet{fantinuoli_teaching_2018}, who proposed a training programme providing recommendations and best practices rooted in socio-constructivism. As the authors observe, ``the introduction of CAI tools in interpreting courses should serve the purpose of exposing students to these solutions, and of providing them with the means to make an informed use of such tools. Thus, an introduction to CAI tools can be beneficial, even if trainees will not reach complete mastery of the tools.'' \citep[175]{fantinuoli_teaching_2018}. The authors thus put forward ideas on how to structure a training programme focused on CAI tool usage in the booth. The proposal involved a theoretical module to introduce students to the rationale behind CAI tool creation and integration into the interpreter's workflow, and a set of practical exercises of increasing complexity targeting the different sub-skills involved in SI with CAI. This approach aimed to foster the students' awareness of potential advantages and pitfalls in CAI usage, such as the risk of relying too much on the tool when faced with highly specialised terminology to be rendered into the target language \citep[53]{prandi_use_2015}.

Another strain of research, currently among the most prolific ones in the field of CAI research, focuses on exploring the impact of CAI tools usage on the quality of SI. The studies conducted so far are mostly pilot studies of exploratory nature, and do not attempt a holistic evaluation of the quality of the interpreting performance in broader terms, but rather narrow it down to terminological accuracy and omissions. The study by \citet{prandi_uso_2015,prandi_use_2015} included an evaluation of this type. She considered the percentage of terms included in the glossary that had been looked up and correctly identified. She found that the participants did not seem to have difficulties in using the tool to look for terms, as shown by the high percentage of terms looked up and found. The percentage of terms found and correctly interpreted as per glossary is not as high as the percentage of terms found, which could point to a difficulty in coordinating the look-up effort with the other sub-processes involved in SI. Drawing on Prandi's (\citeyear{prandi_uso_2015,prandi_use_2015}) experimental design, \citet{biagini_glossario_2015} was the first to empirically test the use of CAI tool glossaries in comparison with paper glossaries during SI. His study also involved a relatively small sample of advanced interpreting students. The participants were trained in using InterpretBank while interpreting terminology-dense texts. In the final experiment, they were asked to interpret two similar speeches while looking up terms in a printed paper glossary and using InterpretBank. The test-subjects' renditions were transcribed and rated on terminological accuracy and omissions. The difference between the paper glossary and the CAI tool proved statistically significant for the criteria ``percentage of terms interpreted as per glossary'' and ``number of omissions''. Based on these initial results, CAI tools seem to provide an advantage in terms of terminological accuracy and completeness of information (fewer cases of omissions were observed even after performing a search).

More recently, scholars have started investigating the potential of integrating ASR into CAI tools, a development which would signify a step closer to a third generation of AI-enhanced CAI tools. The goal of integrating an ASR system into a CAI tool is that of leveraging speech recognition to provide interpreters with live support during SI, with a view to reducing interpreters' active interaction with the machine. As \citet[25]{fantinuoli_speech_2017} observes, ``the main drawback [of traditional CAI tools] is that the database is queried manually, adding more cognitive effort to the interpreting process. This disadvantage could be addressed by automating the query through the use of Automatic Speech Recognition (ASR), as recent advances in Artificial Intelligence have considerably increased the quality of this technology.'' Fantinuoli first postulated the possibility of integrating ASR into a CAI tool in 2017, although this idea had already been put forward before (see \citealt{hansen2012nutzbarkeit}). In his paper, he presents a model and a prototype of an ASR-CAI integration and discusses the requirements of both the CAI tool and the ASR system. In order for ASR integration to be possible, both systems need to fulfil a set of criteria.

First of all, the ASR system must be able to deal with the typical disfluencies of spoken language and cope with speaker variability, as well as with foreign accents and mispronunciations, especially in the context of English as \textit{lingua franca}. Other issues inherent to spoken language are ambiguities, such as homophones, and poor articulation which can occur in the case of fast speech. Finally, speech is not segmented, but continuous, and pauses appear not at word boundaries, but are rather syntactical. The recognition of word boundaries is an issue that the ASR system must be able to deal with, or else the quality of the database querying mechanism necessary for producing the text may be compromised. Especially in consecutive interpreting, the ASR system must also be able to deal with background noise \citep[28]{fantinuoli_speech_2017}. As \citet[29]{fantinuoli_speech_2017} observes, an ASR system must also be able to ``support large-vocabulary recognition'' and ``support vocabulary customisation'' which is necessary to recognise specialised terminology. It must also have a low word error rate (WER), i.e. be highly accurate, and a low real-time factor (RTF), i.e. be fast. CAI tools must also present a certain profile: they must have high precision and recall, with priority given to precision if necessary, be able to deal with morphological variations, and have a sleek and user-friendly interface.

The prototype described recognises numerals and terms that have been added to the event database. The speech is first transcribed and pre-processed. The system then ``queries the terminological database and identifies the entities from the text flow'' \citep[30]{fantinuoli_speech_2017}, which are extracted and visualised on the interpreter's screen. This initial prototype showed encouraging results: with a WER of 5.04\% and a F1 score of 0.97\footnote{The best possible value being 1, the worst 0.}, such a system could be used at least in standard settings. A recent study by \citet{brusewitz_simultandolmetschen_2019} suggests that the commercial ASR solutions currently available already perform rather satisfactorily, at least for the recognition of numerals and specialised terminology, while for named entities there is still a certain margin for improvement. In the study, which tested solutions by Google, Watson (IBM), Sonix and Speechmatics on six parameters (numbers, proper names, terminology, homophones, nonsensical utterances, and speech rate), the Google API was the best-performing system.

Following up on the initial prototype proposition by \citet{fantinuoli_speech_2017}, the first investigations were conducted to further test the potential of an ASR-CAI system in experimental settings. So far, the focus has been on the issue of numerals, typically considered one of the most common problem triggers for interpreters \citep{gile_basic_2009}. \citet{desmet_simultaneous_2018} conducted a pilot study involving a small sample of advanced conference interpreting trainees. The objective was twofold: ``to determine if limited technological support can improve the accuracy of interpreted numbers, and how this improvement breaks down over different number and error types'' (p. 18). In the experiment, no commercially available CAI tool with integrated ASR was used. The authors created a prototype using PowerPoint presentations based on the speech transcripts which contained the numerals present in the speech, presented simultaneously to the occurrence of the oral stimulus. Thus, the results describe what an ideal system would be able to achieve, i.e., following the criteria outlined above, an ASR-CAI hybrid with perfect recognition and very low latency. The results support what has been outlined by Fantinuoli: in the case of numbers, a system with such characteristics is capable to improve accuracy (from 56.5 to 86.5\%) with statistical significance, and to drastically reduce the occurrence of approximations (by 90\% for the experiment), the second most frequent type of error after non-strategic omissions. Overall, intelligent CAI tools with integrated ASR seem to offer a promising upgrade to the toolkit currently available to interpreters. As the authors observe, however, there is still a lot to explore in this respect, and ``further studies should be carried out on how interpreters deal with discrepancies between auditory input from a speaker and visual input from an automatic recognition system, increased delay or different modes of presentation'' \citep[26]{desmet_simultaneous_2018}.

A follow-up experiment \citep{defrancq_automatic_2020} studied ASR support for numerals in a more naturalistic setting, using real-time transcription from the InterpretBank ASR tool. Data was collected through audio and video recordings and a follow-up questionnaire. Additionally, the study took a first look at the impact of a sudden loss of ASR support, which occurred in several cases during the experiment. The results confirm that the tool presents high precision (96\%) and low enough latency to fit the interpreter's ear-voice-span (EVS). Overall, an increase in complete renditions (from 67.7\% to 90.2\%) and a drop in omissions (from 15.8\% to 3.5\%) due to ASR support was also observed. This aligns with previous findings, although the accuracy gain is less significant. This may be due, among other things, to the fact that numerical information was not presented in isolation like in the previous experiment, but rather highlighted within the context of the complete ASR transcription, requiring deeper processing by participants. Training would have probably led to even more significant improvements in the subjects' rendition. It should be noted that significant accuracy gains were observed intra-subject only for two participants out of six.

Interesting findings emerged from the questionnaire. The tool was judged positively in terms of ergonomics, although some participants would have preferred a more minimal presentation of the numerical information. A certain tendency to over-rely on the tool for support was also observed, which aligns with first observations by \citet{prandi_uso_2015, prandi_use_2015}. Interestingly, the authors speculate that the provision of ASR support might have had a positive psychological effect: knowing numerals would be shown on the screen might reduce stress and/or boost confidence \citep[93]{defrancq_automatic_2020}.

\citet{van_cauwenberghe_etude_2020} reached similar conclusions in his experiment on ASR support for terminology. However, like \citet{defrancq_automatic_2020}, he also contended that interacting with the tool may not be a trivial feat from a cognitive standpoint, and observed cases of imported errors from the ASR tool into the interpreters' renditions.  
In \citet{defrancq_automatic_2020} and \citet{van_cauwenberghe_etude_2020}, the system latency was deemed sufficiently short. On the topic of latency, \citet{montecchio_masterarbeit_maddalena_2021} and \citet{fantinuoliDefiningMaximumAcceptable2022} conducted a dedicated study precisely aimed at defining the maximum acceptable latency in ASR-enhanced CAI tools. Using an ASR mockup with increasing latencies varying from 1 to 5 seconds, \citet{montecchio_masterarbeit_maddalena_2021} explored the impact of latency on the rendition accuracy for numerals and referents as well as the effect on the perceived delivery flow. She found that both accuracy and delivery flow declined with increasing latency, interpreting this loss in quality as evidence of increased cognitive load to cope with the longer ear-voice span (EVS).

\begin{sloppypar}
A recent development in this area is the integration of AI-enhanced CAI tools into RSI platforms, as exemplified KUDO Interpreter Assist \citep{fantinuoliKUDOInterpreterAssist2022} and by SmarTerp \citep{rodriguezSmarTerpCAISystem2021}.

KUDO Interpreter Assist includes two features designed to support interpreters working remotely: an automatic glossary creation tool and a virtual boothmate for terms and numbers. This second feature presents a similar architecture to the ASR function offered by InterpretBank (see \sectref{IB}), comprising a cascade of ASR, identification of units of interest through a language model (LM), and automatic display of suggestions for terminology, numbers and named entities on the interpreter's screen. The terminological suggestions are based on the glossary curated by the interpreter\footnote{In the glossary creation tool, the target-language equivalents for specialised terminology are first generated through MT and then validated by the interpreter.}, while numbers and proper names are extracted directly by the LM. The benchmark tests conducted on a general language and a specialised corpus show promising results in terms of precision, recall and F1 value, both for medium-sized and large glossaries (200 vs. 10,000 terms), with an average F1 value of around 98\%. The tool performed better for named entities than for specialised terminology. Although the authors reported quite encouraging lowest F1 values of 84\% and 81\% respectively \citep[7]{fantinuoliKUDOInterpreterAssist2022}, they also noted that individual terms and the glossary used can impact results considerably, as shown by a rather poor performance achieved for a speech about social issues ($\text{F1}=76.19\%$ for the medium and 68.90\% for the large glossary). The average latency was of 1.6 seconds (minimum = 1.1s, maximum = 2.3s), i.e. low enough to fit into an interpreter's average EVS.
\end{sloppypar}

The CAI tool to be integrated into SmarTerp was tested on two components: its ASR system and its semantic interpretation module, which detects relevant entities of interest for the interpreter. For each interpreted session, the LM is adapted on the bases of the interpreter's event glossary, from which seed words are extracted to be added to the glossary and to select texts from the training corpora for the LM adaptation. The semantic interpretation module deploys three underlying resources: a multilingual general purpose, a domain-specific and a user-specific knowledge graph \citep[105]{rodriguezSmarTerpCAISystem2021}. The system evaluation showed rather positive results for the three languages analysed (English, Italian, Spanish), with F scores ranging from 0.82 (English) to 0.90 (Italian). The tests also showed a positive impact of the adaptation systems for all three languages and for all metrics \citep[108]{rodriguezSmarTerpCAISystem2021}.

In light of these initial results, the integration of CAI tools, particularly of those based on ASR, appears feasible. Nonetheless, a salient issue to be considered is the trade-off between the amount of information offered by a system of this kind and the additional cognitive load needed to operate a CAI tool during interpretation. This applies both to ``traditional'' in-booth CAI tools and CAI-ASR integration, and not only to numerals, but also to other problem triggers, such as specialised terminology. \citet[109]{stewart_automatic_2018} observe that ``while displaying all terminology in a glossary achieves high recall of terms, it suffers from low precision. This could potentially have the unwanted effect of cognitively overwhelming the interpreter with too many term suggestions''. For this reason, the authors explore the possibility of integrating an NLP tool capable of predicting the elements likely to be missed by interpreters, with a view to reducing errors and improving performance. Such a system would need to be trained on a corpus of data that have been processed to identify problem triggers using the combined criteria of ``termhood'' (is the term difficult to recall and non-ambiguous?), relevance (should the term necessarily be translated?) and interpreter coverage (has it been left untranslated or mistranslated?). In addition, such a system must also consider task-relevant criteria, such as fatigue at the end of the interpreting turn (``elapsed time''), speech rate (``word timing''), terms left untranslated because they are rare and thus more difficult to recall from memory (``word frequency''), or because they are long and thus likely to represent technical terminology (``word characteristics and syntactic features''). With a system of this kind, capable of processing the source speech and identifying potentially challenging terms based on these criteria, users could ``theoretically adjust the precision-recall threshold'' \citep[115]{stewart_automatic_2018}, even from speaker to speaker and for each assignment or presentation, in order to achieve a positive trade-off between useful term suggestions and additional cognitive effort required to deal with an extra source of information.

The findings of the empirical studies conducted thus far on the product of CASI appear encouraging. However, it should be noted that current investigations have been highly focused on individual units of information. Little is known as to how CAI tools' impact quality on a broader level, although first studies are starting to discuss the effects on the product more holistically and through qualitative analysis \citep{frittella_cai-supported_2021}.

Regrettably, while research on the product of CASI is increasing, the hypotheses on CAI tools' impact on the cognitive subprocesses involved in CASI are yet to be tested empirically in controlled settings. Yet, gaining a more profound understanding of the CASI process and of interpreter-computer interaction during the in-process use of CAI tools appears to be essential in light of the postulated challenges in integrating CAI tools into the SI process. The insight gained through cognitive studies on CAI tools may prove helpful on different fronts. First, it may promote a better understanding of what discourages interpreters from using tools during SI. Second, it may help develop CAI tools truly targeting interpreters' needs and addressing the cognitive constraints inherent to SI. In turn, this may result in a wider acceptance of tools which have the potential to improve interpreters' workflow and the quality of interpretation.

The assumptions on the impact of CAI on mental processes in SI presented in \sectref{CAI_attitudes} point to the idea of interference, of a limited amount of cognitive resources and time, and to the concepts of attention sharing and task coordination in view of the additional effort posed by terminology look-up. In order to formulate hypotheses on the impact of CAI tools on the cognitive processes involved in SI, which the present study aims to test, some attention should first be devoted to the exploration of such constructs both from a cognitive psychology perspective and within the context of simultaneous interpreting. This is the topic of the following chapter.





































