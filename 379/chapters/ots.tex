\documentclass[output=paper]{langscibook}
 
\ChapterDOI{10.5281/zenodo.7777530}

\author{Nele Ots\orcid{0000-0002-4660-434X}\affiliation{Goethe-University Frankfurt} and Piia Taremaa\orcid{0000-0003-1535-9449}\affiliation{University of Tartu}}

\lsConditionalSetupForPaper{}

\title[Chunking an unfamiliar language]{Chunking an unfamiliar language: Results from a perception study of German listeners}


\abstract{%Abstract goes here
This study investigates the impact of prosodic boundary phenomena and syntactic clause boundaries on native and non-native speech chunking. German and Estonian listeners were asked to listen to spontaneous utterances spoken in Estonian and to mark in corresponding written transcripts when they perceived any sort of a break between the words. Estonian listeners were the strongest guided by the clause boundaries whereas German listeners were sensitive to all of the prosodic boundary phenomena but resistant to the presence of clause boundaries. In particular, both German and Estonian listeners utilized longer pauses and rising F0 contour as cues for chunk boundaries. German listeners additionally employed phrase-final lengthening and intensity drop. These results suggest strong bottom-up effects in non-native speech processing, and both bottom-up effects and top-down effects in native processing of speech. Thus, the well-known prosodic boundary phenomena trigger bottom-up processing in on-going spontaneous speech comprehension. %Moreover, the results indicate that the crosslinguistic applicability of prosodic boundary cues depends on the prosodic characteristics of the crossed languages.
}

\begin{document}
\maketitle

%\onehalfspacing
	\section{Introduction}
	
	Speech comprehension starts with and depends on the extraction of discrete sequential units  from continuous speech flow. In order to discern and maintain these units in working memory, listeners interpret smaller units detected in the context of larger ones, that is, in (speech) chunks  \citep[][]{dahanFerreira2019, christiansenChater2016}. Speech chunking operates across multiple levels of linguistic representation and is related to top-down as well as bottom-up processing \citep[see, e.g.,][]{dahanFerreira2019}. Top-down processing concerns world  and linguistic knowledge (including lexical, semantic and syntactic knowledge), whereas bottom-up processing relates to sensory input from acoustic signals. Native listeners, when extracting discrete units from speech, are known to exploit their top-down knowledge about lexical-semantic and syntactic information \citep[][]{mattysEtAl2005}. Thus, top-down processing is decisive for chunking a continuous stream of speech into units. This speeds up spoken language comprehension by helping listeners to rapidly recognize and process segments of language that are syntactically, lexically and semantically coherent and plausible, given the context.
	
	In certain aspects of linguistic structures, the extent of bottom-up processing in speech chunking is unclear. In particular, signal-driven prosodic cues (e.g., lengthening of the segments) have proven to be highly functional for the recognition of words \citep[e.g.,][]{whiteEtAl2020}. Whether listeners are also able to recognize chunks at a higher level, i.e., intonational phrases, is only vaguely understood. Recently, \citet[][]{ordinEtAl2017} pointed out that listeners may apply phrase-level prosody alongside word-level prosody for the generation of so-called prosodic frames \citep{keatingShattuckHufnagel2002, schildEtAl2014, silbertEtAl2014}. Understanding the role of phrase-level prosody in chunking processes is necessary because prosodic frames are proposed to take part in encoding as well as decoding processes in language production and perception \citep[][]{keatingShattuckHufnagel2002, schildEtAl2014, silbertEtAl2014}.
	
	A handful of phonetic perception studies have indicated that signal-driven prosodic information (e.g., durational or tonal discontinuities in terms of pausing, lengthening and pitch reset) ranks rather low in native speech chunking \citep{coleEtAl2010, christodoulidesEtAl2018, duez1985}. In contrast, several psycho-linguistic studies have demonstrated the significant role of phrasal prosody in recognizing and remembering novel words \citep[][]{langusEtAl2012, ordinEtAl2017}. This, in turn, drives our investigation of speech chunking in non-native listeners in comparison with native listeners \citep[for a similar approach, see][]{himmelmannEtAl2018, riesbergEtAl2020}. The current study asks to what extent speech chunks are accessible from signal-driven prosodic information.
	
	\subsection{Signal-driven prosodic boundary cues}
	
	A type of well-known prosodic unit is the so-called tone group \citep{halliday1967a}, also known as the intonation unit \citep[][]{chafe1987} or, more commonly, an intonational phrase \citep{pierrehumbert1980, ladd2008}. In intonational phonology, intonational phrases (IPs) constitute abstract phonological units that are composed of discrete abstract categories of pitch accents and boundary tones \citep{ladd2008, pierrHirsch1990}. The identification of phonological categories of pitch accents and boundary tones in spoken sentences usually follows from phonological analysis. As such, the well-known concept of IP constitutes top-down information about the phonological structure of a language. For the purposes of this study, it is interesting that IPs frequently correspond with concrete acoustic regularities directly observable in the speech signal. 
	
	IPs are frequently characterized as units of tonal coherence \citep[][]{duBoisEtAl1992, breenEtAl2012, buhmannEtAl2002, himmelmannEtAl2018}. An underlying acoustical phenomenon of the significant percept of tonal coherence is the continuous decline of fundamental frequency (F0, acoustic approximation of sentence intonation) from the beginning to the end of an IP. This decline was traditionally measured considering the F0 maxima in phonological pitch accents \citep[see, e.g.,][]{ladd1988, libermanPierr1984, pierrehumbert1979}. More recent research has found a more automatic way to fit a straight line to the F0 contour as a function of time \citep[][]{yuanLiberman2014}. F0 declination is a global component of the F0 contour, and it should interact only mildly with local F0 movements determining pitch accents and boundary tones \citep[][]{fujisaki1983, fujisakiHirose1982}. The regularity of F0 declination underlies the readily audible cue of pitch reset, which means that the continuous decline of the F0 contour is disrupted by setting the level of F0 much higher than predicted by an on-going F0 decline, e.g., by stepping up the pitch. In intonation research, the pitch reset has often been utilized as a valuable cue signaling the right edge of an IP \citep[][]{cooperSorensen1981, couperKuhlen2001, himmelmannEtAl2018, ladd1988, schuetzeCoburnEtAl1991, thorsen1985}.
	
	\begin{sloppypar}
	In the stream of speech, IPs are most easily defined by their boundaries. The IP boundaries in spoken language are associated with a battery of phonetic boundary phenomena encompassing systematic changes in duration, intensity and F0. In particular, a durational discontinuity that involves slowing down speech, or, more specifically, lengthening speech segments, constitutes a type of signal-driven prosodic cue that is frequently referred to as pre-boundary or phrase-final lengthening (\citealt{berkovits1994, Fon2011, Nakai2009, petroneEtAl2017, Wightman1992}; for this cue in German, see also \citetv{chapters/schuboe}, \citetv{chapters/huttenlauch}, and \citetv{chapters/wellmann}). %A durational discontinuity in the opposite direction (i.e., the acceleration of speech or shortening of speech segments) at the beginnings of IPs is also possible and indexes a prosodic boundary cue called phrase-initial lengthening \citep[see][]{keatingEtAl2003}.
	In terms of prosodic boundary cues, intensity has attracted interest to a lesser degree. However, some studies have indicated that an intensity curve within words may also function as a boundary cue. The increasing intensity difference between the initial and final syllable in a word constitutes the phenomenon of intensity drop \citep[][]{TrouvainEtAl1998, Wagner2019}. Finally, IP boundaries are well known to be indexed by intonational movements (boundary tones at the abstract level of intonational phonology), which are indexed by falling or rising F0 contours at the ends of IPs (e.g., consider falling intonation in statements and rising intonation in questions; on the role of rising F0 contours, see \cite{petroneEtAl2017},  \citetv{chapters/huttenlauch}, and \citetv{chapters/wellmann}). 
	Thus, signal-driven prosodic cues, such as phrase-final lengthening, intensity drop, pitch reset and F0 movements, define IPs in spoken utterances. These cues have certain acoustic correlates in the speech signal and these can be investigated as input for bottom-up processing.
	\end{sloppypar}
	
	\subsection{Perception of phrasal prosody}
	
	In the auditory processing of language, the discontinuities of duration and F0 have been shown to be highly functional. Namely, phrase-final lengthening and continuous F0 declination can help listeners to discover long-distance dependencies between words, or tentatively, clausal relationships \citep[][]{cruzPaviaEtAl2019, langusEtAl2012, ordinEtAl2017}. For example, in an experiment with Italian listeners, \citet[][]{langusEtAl2012} created a novel language by defining words and long-distance semantic dependencies between them through systematically manipulating the probability distributions of sounds and syllables. Importantly, the stipulative sentences of the novel language were additionally accompanied by pre-boundary lengthening and continuous F0 declination. \citet[][]{langusEtAl2012} were able to demonstrate that long-distance dependencies between the words were only discovered in the presence of prosodic cues. Moreover, they found that while F0 declination is useful for detecting dependencies at the level of a stipulative sentence or a clause, phrase-final lengthening induces the listener to perceive a stipulative syntactic phrase. Thus, they were able to separate the functions of the two types of prosodic cues at two different linguistic levels -- a stipulative phrase vs. a stipulative clause. Altogether, the results from \citet[][]{langusEtAl2012} demonstrate that the presence of phrase-final lengthening and F0 declination clearly enforces perception of a sort of language chunk. For additional functionality in infant language acquisition see \citetv{chapters/wellmann}.
	
	Phonetic studies of perceptual speech chunking further indicate that there is an unavoidable syntactic component in the perceptual chunking of language. For example, \citet{duez1985} presented listeners with natural, distorted and synthesized speech and asked them to explicitly mark silent pauses. Remarkably, the results show that listeners detected significantly fewer pauses in distorted and synthesized speech than in normal speech. Thus, the study indicates that listeners, even when explicitly detecting signal-based information, may rely more strongly on syntactic-semantic information than acoustic information or may ignore the latter altogether \citep[for a replication of these results, see][]{simonChristo2016}. In a more recent study, \citet{coleEtAl2010} asked native listeners of American English to listen to broadcasted conversations and to mark in written transcripts where they heard some sort of a break or juncture. The results show that clause boundaries had the strongest impact on boundary perception; phrase-final lengthening or a duration cue ranked lower, and F0 did not play any role. A study by \citet[][]{christodoulidesEtAl2018} employed slightly different methodology by asking French listeners to press a button when they heard some sort of a break in speech. The timeline of button presses was synchronized with the stream of speech, and without having any written input, the outcome was nevertheless that syntactic clause boundaries most strongly contributed to boundary perception. These results further demonstrate how influential the access to clausal information is in the metalinguistic tasks. As the clause boundaries constitute the linguistic knowledge, they can be taken as input for the top-down processing. As such, the existing studies demonstrate pervasive top-down processing in native speech comprehension.
	
	Strikingly, \citet[][]{riesbergEtAl2020} found that lexical and syntactic variables participate even in non-native perception of speech chunks. Their study employed the same methodology as in \citet[][]{coleEtAl2010} and asked native speakers of German to listen to short stories spoken in Papuan Malay and mark in written transcripts where they heard some sort of a break. Speakers of Papuan Malay were presented with short stories in German with the same task. Both language groups also judged the stories spoken in their native language. For listeners from both language groups, clause boundaries were the second strongest factor that contributed to the perception of chunks in the unfamiliar languages, while pauses were the strongest cue.
	
	This result becomes less surprising when considering language production. Specifically, several studies have found that syntactically defined segments, such as clauses and phrases, are often accompanied by acoustic discontinuities \citep[see, e.g.,][]{cutlerEtAl1997, petroneEtAl2017}. For example, \citet{feryIshihara2009} demonstrated in a reading experiment that speakers tended to reset pitch and start a new declination trend for F0 at the beginning of embedded subclauses. This indicates that IPs, or the signal-driven prosodic cues of duration, and F0 in particular, tend to strongly associate with the syntactic representation of language. In other words, syntactic elements such as clauses are produced as prosodically coherent speech chunks, and the results from \citet[][]{riesbergEtAl2020} suggest they will also be perceived as such regardless of the listener’s language background.
	
	\subsection{The current study}

    The aim of this study is to determine the impact of signal-driven prosodic cues (i.e., bottom-up processing) separately from syntactic-semantic information (i.e., top-down processing) in speech chunking. For this, we investigate how non-native speakers perceive an unfamiliar natural language. When processing an unfamiliar language, semantic-syntactic cues are not available to the listener. Arguably, this forces non-native listeners to rely on signal-based acoustic cues whilst chunking speech \citep[][]{himmelmannEtAl2018, riesbergEtAl2020}. By investigating chunking of speech flow in an unfamiliar language, we are able to examine the role of signal-based prosodic information in bottom-up processing of language.

    To assess the influence of prosodic information on speech chunking, we conducted a chunking experiment based on Rapid Prosody Transcription \citep[RPT;][]{coleEtAl2010, coleEtAl2011, lmeds} in which Estonian and German listeners had to chunk excerpts of spontaneous utterances spoken in Estonian. We investigated the impact of signal-driven prosodic cues (i.e., phrase-final lengthening, intensity drop, rate of F0 declination, and pause duration) against the clausal structure of spontaneously spoken utterances and the listeners’ language background. Signal-driven prosodic information serves as input for bottom-up processing, whereas the clausal structure provides input for top-down processing. Crucially, the clausal structure of Estonian utterances is not available for German listeners who are unfamiliar with the Estonian language. Therefore, we hypothesized that the impact of bottom-up information in speech chunking is modulated by the listener’s language background. Based on the notion of top-down processing, we expected the German listeners to be less affected by the clausal structure and to be more sensitive to the signal-driven prosodic cues, whereas the Estonian listeners were expected to use both clausal and acoustic cues. The alternative prediction relies on the results in \citet[][]{riesbergEtAl2020}. Namely, the German listeners could perform similarly to Estonian listeners in terms of clausal cues. This outcome would indicate a strong relationship between prosodic information and clausal structure in Estonian speech production because, arguably, the German listeners would rely on the prosodic cues that are tightly associated with clausal structure.
    
    \section{Materials and method}

    For our experiment, we applied the methodology of Rapid Prosody Transcription (RPT), in which listeners are typically asked to listen to excerpts of speech and mark the words that they perceive as prominent or that stand before some sort of a break \citep{coleEtAl2010, coleEtAl2011, lmeds}.

    \subsection{Participants} 
    Altogether, 47 Estonian listeners (average age 30.0 years) took part in an earlier experiment \citep{otsTaremaaOpli2022}. They originated from various regions of Estonia. Given their age, they most likely speak Standard Estonian, and the dialectal variation in Estonia is probably not that pronounced in young speakers. 
    
    For this study, 90 native speakers of German were recruited through a crowd-sourcing marketplace designed for conducting research (Prolific). They were paid about £2.50 to complete the task, which took about 20 minutes. The average age of the participants was 28.8 years (with 0.03 percent of participants not reporting). 48.9 percent of participants were female, and 46.7 percent were male (with 0.04 percent of participants not reporting). All participants reported German to be their first language. 86.7 percent of participants reported having knowledge of some other language, most frequently English. None reported having knowledge of Estonian.

    \subsection{Stimuli}
    We extracted 396 excerpts of spontaneous speech (4727 words altogether) from 10 native Estonian speakers (5 male and 5 female speakers with an average age of 25.3 years) from the phonetic corpus of spoken Estonian \citep[][]{lippusEtAl2015}. Auditive analysis did not reveal any distinctive dialectal characteristics in these speakers. They appeared to use Standard Estonian as it is taught in schools. %40 percent of speakers had a background of South-Estonian (including Tartu) and 30 percent of speakers had a background of Middle-Estonian.
    The excerpts constituted a stretch of fluent speech between silent pauses of 400 ms or longer. The excerpts contained 18 to 24 syllables, yielding an average duration of 3300 ms. For the experiment with Estonian listeners, the 396 excerpts were randomly distributed between 4 different lists, each containing 99 excerpts in total. 
    The lists for German listeners were kept shorter, as their task was to listen to non-native language. Thus, the 396 excerpts were randomly distributed between 9 lists, with each list containing 44 excerpts in total. 
    
    \subsection{Procedure} 
    The Estonian excerpts were presented to native speakers of German, unfamiliar with the Estonian language. The study was conducted over the internet using LMEDS software \citep[][]{lmeds}. Based on RPT methodology \citep[see, e.g.,][]{coleEtAl2010, coleEtAl2011, riesbergEtAl2020}, the participants were asked to listen to speech excerpts and identify the chunks of words (``kõnejupp" in Estonian, ``Wortgruppierung" in German) in the written transcripts appearing on the screen. Technically, they needed to click on the words that they perceived as occurring at some sort of a break. In essence, the task was to make a binary choice to either place a boundary or not at each consecutive pair of words in an excerpt. No additional instructions on what exactly this break might be were provided. The Estonian listeners were allowed to listen to the excerpts two times, the German listeners were able to listen to the excerpts as many times as they needed.

    As this task requires listening to speech excerpts and simultaneously reading written transcripts, it is recognizably difficult for a non-native listener to perform. However, it has already been successfully administered with languages that are typologically far apart in a study by \citet[][]{himmelmannEtAl2018}, in which German listeners were asked to chunk speech excerpts from Indonesian languages, and speakers of Indonesian languages were asked to chunk speech excerpts in German. \citet[][]{riesbergEtAl2020} followed a similar procedure with German and Papuan Malay speakers. Both studies yielded interpretable and plausible results. The researchers’ justification for this procedure was based on the shared orthographic conventions of the languages. 

    Estonian orthography is phonemic, and therefore, it should be easily accessible to a German listener/reader. Except for some contrasts in phoneme length, each symbol is encoded by exactly one sound, and most of the graphemes correspond to symbols in German. The survey conducted after the completion of the task indicated that the participants were happy to take part in the study: the average satisfaction on a scale of 0 to 100 was 78.7 ($\text{SD}=20.7$). 13.3 percent of participants claimed to have difficulties with mapping speech sounds to written words, and 11.1 percent of participants even reported having fun listening to a language that they did not know.\largerpage[2]

    We did not manage to present the lists to equal numbers of participants, as the LMEDS software does not have the option to define different lists of experimental stimuli. Unfortunately, our own solution for extending the LMEDS with this feature did not work properly. Thus, the number of listeners per excerpt varies across the lists, ranging from a total of 6 to a total of 12 listeners per list.
    
    The participants’ responses were encoded at the final boundary of every word, using 0 when no boundary was placed and 1 when a boundary was placed. Altogether, the Estonian results consisted of 55,541 data points, and the German results consisted of 47,257 data points (number of words multiplied by the number of listeners). We did not instruct the participants to listen for breaks in the very last words of excerpts, and therefore, the final words of each excerpt were excluded from the evaluation of effects, leaving us with 50,889 data points for the Estonian data and 43,291 data points for the German data.  
    
    \subsection{Test variables} 
    Four test variables capturing the variation in duration (syllable duration, pause duration), intensity (intensity difference) and F0 (F0 proportion) were automatically extracted from all words in the excerpts. The absolute duration of the last syllable of every word (syllable duration in milliseconds) was taken to index pre-boundary lengthening. An utterance was defined to be a stretch of fluent speech between silent pauses of 400 ms or longer. Thus, the selected utterances did not contain pauses that were longer than 400 ms. However, they did contain silent and filled pauses shorter than 400 ms (352 instances (0.07\%) in a corpus of 4372 words). The duration of these silent and filled pauses was collected as the second durational variable after syllable duration (pause duration in milliseconds).\largerpage[2]

    For the third variable, intensity difference, the intensity as root mean square (RMS) amplitude of the very first and the very last syllable of a word was automatically extracted, and the intensity curve within a word was approximated by subtracting the RMS value of the last syllable from the RMS value of the first syllable (intensity difference). The intensity difference was calculated to index the intensity drop. The larger the  intensity difference, the likelier it is that a word contains the intensity drop. A small or negative difference is an indication that a word does not contain an intensity drop.

    F0 contours (Hz) were extracted from the excerpts in two passes with the help of the auto-correlation method available in Praat \citep[][]{boersmaWeenink2019}. During the first pass, F0 tracks were extracted with Praat default settings for the lowest and highest F0, the “floor” and “ceiling” (75 Hz and 600 Hz, respectively). Then, the first and third quartiles of F0 (Q1 and Q3) were calculated for each speaker and recorded in a table. In the second pass, F0 contours were extracted with speaker-specific settings (0.75*Q1 for the floor and 1.5*Q3 for the ceiling). Finally, the resulting F0 contours were smoothed by 4 Hz and quadratically interpolated using the corresponding functions in Praat. Based on the F0 contours, F0 maxima (in Hz) were automatically identified in the vowels of the word-initial lexically stressed syllables. This identification procedure is well justified because, in Estonian, %the lexical stress is located in the first syllable of each word \citep[with very few exceptions; see][]{erelt2003}. Phonologically, 
    the high tone of the falling pitch accent is most frequently aligned with the first syllable \citep[see, e.g.,][]{asuNolan1999}. Therefore, relatively high F0 maxima from the word-initial syllables can be taken to index intonational pitch accents.
    
    For the fourth variable  --  F0 proportion, F0 maxima were divided with the corresponding utterance’s mean F0. As such, the F0 proportion was devised to approximate the height of a pitch accent relative to the utterance's mean F0. F0 proportion was calculated to normalize the speaker-specific and item-specific tonal variation in the utterances. Due to the well-known phenomenon of F0 declination, F0 maxima are higher at the beginnings of the corresponding domains (e.g., IP, clause, or a perceptual speech chunk) than at the ends of these domains \citep[][]{cooperSorensen1981, libermanPierr1984, yuanLiberman2014}. Therefore, F0 maxima decrease across the domain also relative to the utterance's mean. In other words, F0 proportion is smaller at the ends of corresponding domains than at the beginnings of these domains. Followingly, the F0 proportion should be smaller at the end of the perceived boundaries than at the non-boundaries if the non-expert perception of a break, or more generally, the perception of a speech chunk relies on the tonal coherence.

    The material was also scored for the boundaries of clauses. This scoring was not devised in a particular syntactic framework but followed the functional approach provided in \citet[][]{estSynt2017}. A clause was defined as consisting of a finite verb together with elements that cluster around the verb and are not finite verbs themselves. Clauses were allowed to also consist of non-constituents, such as disclosures and interjections. In practice, conjunctions served as a frequent cue for the separation of utterances into smaller units of clauses  (see rows 7 and 12 in Table \ref{tab:1:clauses}). For clausal structure, the last word in a clause was encoded as being at the clause boundary.
    
    \begin{table}%[H]
	    \caption{Sample of the scoring of clause boundaries in conversational utterances.}
	    \label{tab:1:clauses}
	    \begin{tabular}{l rrrr}
		    \lsptoprule
		    Row & Transcription & Translation &  Function & Clause boundary \\
		    \midrule
		    1 & \textit{ja} & and&	conjunction	&  no\\
		    2 & \textit{siis}& then &	adverbial &	no\\
		    3 & \textit{käisi-me}& went-we &	verb & no\\
		    4 & \textit{seal}& there& adverbial & no\\
		    5 & \textit{iisraeli}& Israelian&	adverbial & no\\
		    6 & \textit{muuseum-is}& museum-in&	adverbial &	yes \\
		    7 & \textit{kus}& where&	conjunction & no\\
		    8 & \textit{see}& this&	subject & no\\
		    9 & \textit{suur}& big&	subject & no\\
		    10 & \textit{makett}& maquette&	subject & no\\
		    11 & \textit{oli}& was&	verb &	yes\\
		    12 & \textit{mis}& which&	conjunction & no\\
		    13 & \textit{oli}& was &	verb & no\\
	    	14 & \textit{päris}& pretty & predicative &	no\\
		    15 & \textit{võimas}&	awesome & predicative &	yes\\
		\lspbottomrule
	\end{tabular}
    \end{table}

    \subsection{Analysis} 
    In our analysis, the continuous variables of syllable and pause duration, intensity difference, and F0 (F0 proportion) function as bottom-up information, whereas clause boundaries function as top-down information. In terms of the impact of continuous signal-based prosodic variables in perceptual chunking, we expected the likelihood of boundary perception to increase
    
    \begin{enumerate}
	    \item together with increasing syllable duration,
	    \item together with increasing pause duration,
	    \item together with increasing intensity difference,
	    \item together with decreasing F0 proportion.
    \end{enumerate}

    We predicted that the perception of both types of information would be modulated by the listener’s linguistic background (familiar vs. unfamiliar) such that the effects of prosodic variables would be larger for German than for Estonian listeners and that the effect of clause boundaries would be larger for Estonian than for German listeners.

    The effects of clause boundaries, syllable duration, intensity difference, F0 proportion and pause duration were estimated in relation to the language background in the general linear mixed effects regression analysis as provided in the \texttt{lme4} package \citep{batesEtAl2015} in R \citep{rWare}. We defined five predictors of the binomially distributed response variable:\largerpage
    
    \begin{enumerate}
	    \item an interaction between clause boundaries and language,
	    \item an interaction between syllable duration and language, 
	    \item an interaction between pause duration and language, 
	    \item an interaction between intensity difference and language,
	    \item an interaction between F0 proportion and language. 
    \end{enumerate}

    Pause and syllable durations were logarithmically transformed with the base of 10. To maintain the interpretability and comparability of the slopes, all continuous variables were z-scored before entering the regression analysis. The generalized linear mixed effects model was defined to contain the number of listeners as an exposure variable because the four lists of excerpts in the Estonian experiment and the nine lists of excerpts in the German experiment were exposed to different numbers of listeners. The random effects structure included random slopes for listeners because we reasoned that listeners are highly likely to vary in their sensitivity to the clausal structure, syllable duration, pause duration, intensity difference and F0 proportion. We also included random slopes for excerpts because they originated from the conversations of 10 different speakers and displayed considerable and systematic variation in speech rhythm, intensity, and melody. The converging model fit was obtained by using the \texttt{optimx} optimizer \citep[][]{nash2014, nashVaradhan2011}.
    
    \section{Results}
	\largerpage
    \subsection{The impact of prosodic cues on non-native speech chunking}

    The aim of the analyses was to determine the impact of phonetic variation of duration, intensity and F0 as bottom-up information in non-native speech chunking. Before proceeding to the statistical evaluation, the explanatory variables were checked for correlations (see Table \ref{tab:1:correlations}).
    
\begin{table}
\caption{Correlations between the explanatory variables as estimated by Pearson’s \textit{r} coefficient. The significance stars indicate how likely they are to be found in the whole population, given the sample means. ***: $p<0.001$, **: $p<0.01$, *: $p<0.05$.}
\label{tab:1:correlations}
    \begin{tabular}{l *4{S[table-format=-1.2{***}]}}
	    \lsptoprule
	    & {Clause} & {Syl. dur.} & {Int. dif.} & {F0 prop.} \\\midrule
	    Clause &  &  &  &  \\ 
	    Syllable dur. &  0.08{***} &  &  &  \\ 
	    Intensity dif. &  0.12{***} & -0.02  &  &  \\ 
	    F0 prop. &  0.04{**}  &  0.04{*}  &  0.19{***} &  \\ 
	    Pause dur. & -0.01  &  0.07  & -0.06  &  0.03  \\ 
	    \lspbottomrule
    \end{tabular}
\end{table}
    
    The correlations between the selected variables in Table \ref{tab:1:correlations} are very close to zero. This indicates that they are appropriate as explanatory variables for the multiple regression analysis with mixed effects. The results of the analysis are presented in Table \ref{tab:2:estimates}. The column “Est.” contains the log odd estimates of the fixed effects clause, syllable duration, intensity difference, pause duration and F0 proportion in interaction with language. The third and the fourth column give the 95\% confidence intervals of the estimates. The \textit{t}-values and \textit{p}-values can be found in the last two columns. The \textit{p}-values are given together with the significance codes (asterisks).\largerpage

\begin{table}%[H]
\caption{Log odd estimates and significance of the standardized variables in predicting boundary perception. ***: $p<0.001$, **: $p<0.01$, *: $p<0.05$.}
\label{tab:2:estimates}
    \begin{tabular}{l *4{S[table-format=-2.2]} S[table-format=1.2{***}]}
	    \lsptoprule
	    &		{Est.}	&	{2.5\%}	&	{97.5\%}	&	{$t$}	&	{$p$}\\\midrule
	    (Intercept)	&		-12.22		&		-12.99		&		-11.46		&		-31.35		&		0.00{***}	\\
        Language [Ger]	&		1.84		&		0.97		&		2.71		&		4.15		&		0.00{***}	\\
        Clause [yes]	&		3.18		&		2.65		&		3.71		&		11.72		&		0.00{***}	\\
        Syllable dur.	&		0.04		&		-0.21		&		0.29		&		0.3		&		0.77		\\
        Intensity dif.	&		0.06		&		-0.31		&		0.44		&		0.34		&		0.73		\\
        Pause dur.	&		0.53		&		0.27		&		0.79		&		4.06		&		0.00{***}	\\
        F0 prop.	&		0.27		&		0		&		0.54		&		1.98		&		0.05{*}	\\
        Language [Ger]:Clause [yes]	&		-2.57		&		-3.11		&		-2.04		&		-9.41		&		0.00{***}	\\
        Language [Ger]:Syllable dur.	&		0.22		&		0.01		&		0.42		&		2.1		&		0.04{*}	\\
        Language [Ger]:Intensity dif.	&		0.32		&		0.08		&		0.56		&		2.57		&		0.01{**}	\\
        Language [Ger]:Pause dur.	&		0.06		&		-0.15		&		0.26		&		0.54		&		0.59		\\
        Language [Ger]:F0 prop.	&		0.16		&		-0.04		&		0.37		&		1.55		&		0.12		\\
	    \midrule
	    AIC     &  \multicolumn{5}{r}{5770.47\hphantom{***}} \\
	    R$^{2}$ (fixed effects) &  \multicolumn{5}{r}{0.15\hphantom{***}}\\
	    R$^{2}$ (all effects)   &  \multicolumn{5}{r}{0.78\hphantom{***}}\\
	    \lspbottomrule
    \end{tabular}
\end{table}
    
    The positive values of the log odd estimates indicate an increase in the probability of boundary perception, whereas the negative values suggest a decrease in the probability of boundary perception. Given that the variables were standardized before entering the regression analysis, the estimates enable us to see that the presence of a clause boundary is the factor that has the most profound effect on boundary perception. This is followed by the effect of the interaction between the language and clause and the main effect of the language. The lower-ranking effects stem from the signal-based prosodic variables. The main effect of the language is followed by the main effect of pause duration. The next strongest effect is the intensity difference in the interaction with language. This is followed by the main effect of F0 proportion. Finally, syllable duration also contributes to the boundary perception in the interaction with language. The main effects of syllable duration and intensity difference, and the interactions between language and pause duration and between language and F0 proportion did not turn out significant. The results of the linear-mixed effects regression analysis are illustrated in the effect plots in Figure~\ref{fig:1:estimates}. These plots highlight the predicted influences of clause boundaries, syllable duration, intensity difference, pause duration and F0 proportion on boundary perception.

    \begin{figure}%[H]
		\centering\includegraphics[height = .87\textheight, width= \textwidth]{figures/glmerEstimates.pdf}\\
	    \caption{Predicted probabilities of boundary perception as a function of clause boundaries (A), syllable duration (B), intensity difference (C), pause duration (D) and F0 proportion (E) while holding other variables constant. The shadowed bands around the lines represent 95\% confidence intervals of the estimates. The change in the probability function is significant when the confidence intervals do not overlap from left to right along the probability function.}
	    \label{fig:1:estimates}
    \end{figure}
    
    \begin{sloppypar}
    Figure \ref{fig:1:estimates}A further demonstrates how the significant main effect of clause boundaries is modulated by the significant interaction between clause boundaries and language background. In particular, we can see that the Estonian listeners are strongly affected by the presence of a clause boundary whereas the German listeners are insensitive to the presence of clause boundaries (compare blue points and whiskers to red points and whiskers). Figure \ref{fig:1:estimates}B demonstrates that increasing duration of the last syllable contributes to the perception of a boundary for German (see the blue line and confidence intervals that are not overlapping from left to right) but not for Estonian listeners (see the red line and the red confidence intervals that are overlapping from left to right along the probability function). Similarly, Figure \ref{fig:1:estimates}C indicates that the probability of hearing a boundary increases together with increasing intensity difference for German listeners (see the blue line and confidence intervals that are not overlapping from left to right) but not for Estonian listeners (see the red line and the red confidence intervals that are overlapping from left to right along the probability function). Figures \ref{fig:1:estimates}D and \ref{fig:1:estimates}E underscore the main effects of pause duration and F0 proportion. We can readily observe that regardless of the listener’s language background, the probability of boundary perception increases as the pause duration and F0 proportion increase (see the rising probability functions and non-overlapping confidence intervals in blue and red from left to right along the probability functions).
    \end{sloppypar}
    
    \subsection{Interrater agreement}

    To establish the interrater agreement, we calculated Fleiss’ $\kappa$ scores between the Estonian and German listeners according to the lists of excerpts (see Table \ref{tab:2:irr}).

\begin{table}%[H]
    \caption{Fleiss’ $\kappa$ scores for boundaries in the familiar (Estonian) and unfamiliar (German) language conditions. $N$: Number of listeners. The $\kappa$ values between 0--0.20 indicate \textit{slight} agreement, 0.21--0.40 suggest \textit{fair} agreement, 0.41--0.60 indicate \textit{moderate} agreement, 0.61--0.80 indicate \textit{substantial} agreement, and 0.81--1 suggest \textit{almost perfect} agreement \citep[see][]{landisKoch1977}.}
    \label{tab:2:irr}
	    \begin{tabular}{l r cc r l}
		    \lsptoprule
		   List	&	$N$	&	$\kappa$	&	95\% CI	&\multicolumn{1}{c}{$z$}	& Agreement\\\midrule
			\multicolumn{3}{l}{\itshape Estonian}\\
			1	&	13	&	0.47	&	(0.46, 0.47)	&	142.32	& moderate\\
		    2	&	9	&	0.41	&	(0.40, 0.42)	   &	85.67	& moderate \\
			3	&	14	&	0.39	&	(0.38, 0.39)	&	126.14	& fair \\
			4	&	11	&	0.27	&	(0.26, 0.28)	&	68.37	& fair \\\midrule
			\multicolumn{3}{l}{Mean (SD):} & \multicolumn{2}{c}{0.38 (0.08)}  & {(fair)} \\
		    \midrule
			\multicolumn{3}{l}{\itshape German}\\
		    1	&	10	&	0.29	&	(0.28, 0.30)	&	45.05	& fair\\
		    2	&	10	&	0.34	&	(0.33, 0.36)	&	51.91	& fair\\
		    3	&	9	&	0.33	&	(0.31, 0.34)	&	44.12	& fair\\
		    4	&	11	&	0.25	&	(0.24, 0.26)	&	42.17	& fair\\
		    5	&	13	&	0.25	&	(0.24, 0.26)	&	42.17	& fair\\
		    6	&	12	&	0.28	&	(0.27, 0.29)	&	56.33	& fair\\
			7	&	7	&	0.23	&	(0.22, 0.24)	&	42.42	& fair\\
			8	&	6	&	0.32	&	(0.30, 0.34)	&	28.17	& fair\\
			9	&	12	&	0.27	&	(0.26, 0.28)	&	51.07	& fair\\\midrule
			\multicolumn{3}{l}{Mean (SD):} & \multicolumn{2}{c}{0.28 (0.04)} &	{(fair)}\\
		    \lspbottomrule
	    \end{tabular}
\end{table}

    The $\kappa$ scores in Table \ref{tab:2:irr} show fair agreement within Estonian listeners and within German listeners. While Estonian listeners of Lists 1 and 2 perform moderately, the scores for other lists remain below 40, yielding an average $\kappa$ score of 0.38 for Estonians. The average $\kappa$ score for German listeners is 0.28, also indicating fair agreement. It was not possible for us to calculate the $\kappa$ scores between the Estonian and German listeners because the excerpts were distributed among the different lists (among four lists for Estonians and nine lists for Germans).
    
    Therefore, we decided to investigate the perceptual chunks to see whether they show any similarities between the native and non-native speakers. The results of the regression analysis have strongly indicated that for the Estonian listeners, the boundaries of chunks correspond with clause boundaries. Additionally, they are guided by pause duration and F0 proportion. The German listeners, in contrast, are not affected by clause boundaries and rely more strongly on the acoustic characteristics of words (syllable duration, intensity difference, pause duration and F0 proportion). Therefore, we decided to investigate some lexical and prosodic characteristics of the chunks that were identified by the German and Estonian listeners. Firstly, we examined the length of the chunks in terms of duration (in milliseconds) and the number of words. There is an idea that chunking processes could be constrained by the capacity of working memory, which has been frequently measured in how many words a person is able to recall \citep[][]{green2017}. The finding is that the working memory mostly spans from five to seven words (sometimes even nine words, \citealp[][]{miller1956}). We speculated that the German listeners might be stronger constrained by the memory capacity than the Estonian listeners because language processing and memory of the Estonian listeners are supported by the semantic and syntactic information that is inaccessible to the German listeners. So, we expected the duration of non-clausal chunks that were perceived by German listeners to conform stronger with the memory constraint than the duration of the clausal chunks that were identified by Estonian listeners. In particular, we expected non-clausal chunks to be shorter and less variable than the clausal chunks.
    
    Secondly, we analysed the lexical constituency of the chunks. Concerning words, we expected that the chunks identified by the Estonian listeners are more likely to begin with conjunctions and the so-called clausal connectors (e.g. \textit{et}, ‘that’; \textit{aga}, ‘but’; \textit{kui}, ‘if/when’; etc.) than the chunks identified by the Germans. This is because conjunctions signal the beginning of a new clause (in our analysis) and only the native speakers have access to this syntactic information. Thus, it is not likely that the German listeners would consistently identify conjunction-initial chunks. Finally, we explored the tonal coherence of the perceptual chunks. As discussed in the Introduction, the tonal coherence can be approximated by the decline of F0 across the respective domain (e.g., IP, clause or perceptual chunk). Thus, we visually estimated the degree of tonal coherence of the perceptual chunks by observing the averaged F0 contours of the native and non-native language chunks. We speculated that the non-native chunks (non-clausal chunks) exhibit tonal coherence to a larger degree than the native chunks (clausal chunks) because the German listeners were stronger guided by the bottom-up prosodic cues than were the Estonian listeners.
    
    \subsection{Any shared characteristics between the native and non-native chunks?}
    \largerpage

    We examined the chunks identified by the Estonian and German listeners considering the chunks’ length (in duration and number of words, Table \ref{tab:3:chunkDurs}), lexical characteristics (Table \ref{tab:4:wordFreqs}) and tonal coherence (Figure \ref{fig:2:contours}). %Furthermore, we explore boundary perception considering the prominence judgements and the pitch accents obtained in Ots \& Asu (2019).

    \begin{table}
	    \caption{Lengths of chunks in German and Estonian listeners as estimated by duration (ms) and number of words in chunks.}
	    \label{tab:3:chunkDurs}
		    \begin{tabular}{l *4{c}}
			    \lsptoprule
			                   & \multicolumn{2}{c}{Av. duration (ms)} & \multicolumn{2}{c}{Length in words} \\\cmidrule(lr){2-3}\cmidrule(lr){4-5}
			    Language group & Mean & SD & Mean & SD \\   \midrule
			    Estonian & 1452 & 850 & 5.85 & 3.35\\
			    German   & 1417 & 749 & 5.86 & 3.24\\
			    \lspbottomrule
		    \end{tabular}
    \end{table}

    The averages of duration and length in words in Table \ref{tab:3:chunkDurs} indicate that the perceptual chunks do not differ in duration or the number of words between the two language groups. In other words, listeners with Estonian and German backgrounds identify chunks of the same length and size. The difference is that the chunks identified by Estonian listeners are more likely to form a clause than the chunks identified by the German listeners.

    For the lexical characteristics in Table \ref{tab:4:wordFreqs}, we identified words that appeared most frequently in the first, second, third and final positions in the chunks. The aim was to see if the lexical content of the chunks differs between the two language groups.

    
    % THIS IS THE ORIGINAL TABLE AND BOTH AUTHORS WOULD PREFER THIS ONE, BUT THEY PROVIDED 2 AlTERNAIVES, which I copy-in below
    \begin{table}%[H]
	\caption{The 10 most frequent words in the first, second, third and final positions of chunks identified by Estonian and German listeners. FR: frequency ranking}
	\label{tab:4:wordFreqs}
		\fittable{\begin{tabular}{l *4{l@{~}l}}
			\lsptoprule
			FR & \multicolumn{2}{l}{First pos.} & \multicolumn{2}{l}{Second pos.} & \multicolumn{2}{l}{Third pos.} & \multicolumn{2}{l}{Last pos.}\\\midrule
			\multicolumn{9}{l}{\emph{Estonian}}\\
			%\midrule
			1	&	\textit{et} &  ‘that’	&	\textit{siis} &  ‘then'	&	\textit{on} &  ‘is'	&	\textit{et} &  ‘that'	\\
			2	&	\textit{ja} &  ‘and'	&	\textit{ei} &  ‘no'	&	\textit{ei} &  ‘no'	&	\textit{noh} &  ‘well, uhm'	\\
			3	&	\textit{siis} &  ‘then'	&	\textit{ma} &  ‘I'	&	\textit{oli} &  ‘was'	&	\textit{on} &  ‘is'	\\
			4	&	\textit{ma} &  ‘I'	&	\textit{see} &  ‘this'	&	\textit{et} &  ‘that'	&	\textit{siis} &  ‘then'	\\
			5	&	\textit{aga} &  ‘but'	&	\textit{on} &  ‘is'	&	\textit{me} &  ‘we'	&	\textit{see} &  ‘this'	\\
			6	&	\textit{see} &  ‘this'	&	\textit{oli} &  ‘was'	&	\textit{see} &  ‘this'	&	\textit{ka} &  ‘too'	\\
			7	&	\textit{kui} &  ‘if, when'	&	\textit{et} &  ‘that'	&	\textit{nagu} &  ‘like'	&	\textit{oli} &  ‘was'	\\
			8	&	\textit{või} &  ‘or'	&	\textit{ta} &  ‘(s)he'	&	\textit{ma} &  ‘I'	&	\textit{jah} & ‘yes'\\
			9	&	\textit{ei} &  ‘no'	&	\textit{me} &  ‘we'	&	\textit{seal} &  ‘there'	&	\textit{ja} &  ‘and'	\\
			10	&	\textit{mingi} &  ‘some'	&	\textit{seal} &  ‘there'	&	\textit{kui} &  ‘if, when'	&	\textit{seda} &  ‘this [\scshape{PART}]'\\
			\midrule
			\multicolumn{9}{l}{\emph{German}}\\
			%\midrule
			1	&	\textit{et} &  ‘that'	&	\textit{siis} &  ‘then'	&	\textit{on} &  ‘is'	&	\textit{et} &  ‘that'	\\
			2	&	\textit{ja} &  ‘and'	&	\textit{ma} &  ‘I'	&	\textit{ei} &  ‘no'	&	\textit{see} &  ‘this'	\\
			3	&	\textit{siis} &  ‘then'	&	\textit{ei} &  ‘no'	&	\textit{oli} &  ‘was'	&	\textit{ja} &  ‘and'	\\
			4	&	\textit{ei} &  ‘no'	&	\textit{et} &  ‘that'	&	\textit{et} &  ‘that'	&	\textit{siis} &  ‘then'	\\
			5	&	\textit{on} &  ‘is'	&	\textit{see} &  ‘this'	&	\textit{see} &  ‘this'	&	\textit{nagu} &  ‘like'	\\
			6	&	\textit{ma} &  ‘I'	&	\textit{on} &  ‘is'	&	\textit{ma} &  ‘I'	&	\textit{mingi}  &  ‘some'	\\
			7	&	\textit{see} &  ‘this'	&	\textit{oli} &  ‘was'	&	\textit{me} &  ‘we'	&	\textit{on} &  ‘is'	\\
			8	&	\textit{oli} &  ‘was'	&	\textit{seal} &  ‘there'	&	\textit{kui} &  ‘if, when'	&	\textit{seda} &  ‘this [\scshape{PART}]'	\\
			9	&	\textit{noh} &  ‘well, uhm'	&	\textit{ja} &  ‘and'	&	\textit{nagu} &  ‘like'	&	\textit{oli} &  ‘was'	\\
			10	&	\textit{aga} &  ‘but'	&	\textit{kui} &  ‘if, when'	&	\textit{siis} &  ‘then'	&	\textit{noh} &  ‘well, uhm'	\\
			\lspbottomrule
		    \end{tabular}}
\end{table}


\begin{comment}
% THIS IS ALTERNATIVE 1 provided by the authors
% This table does not fit on the page. It would be possible to insert it sideways but I did not manage to find time to figure it out how it's best done in Latex. Thanks for understanding!
\begin{table}[H]
	\caption{The ten most frequent words in the first, second, third and final positions of chunks identified by Estonian and German listeners. The columns are merged when the words were same for the both languages.}
	\label{tab:4:wordFreqs}
	\scalebox{0.9}{
		\begin{tabular}{l llllllll}
			\lsptoprule
			Freq.	&	\multicolumn{2}{c}{First pos.}			&	\multicolumn{2}{c}{Second pos.}			&	\multicolumn{2}{c}{Third pos.}			&	\multicolumn{2}{c}{Last pos.}			\\
ranking	&	Est.	&	Ger.	&	Est.	&	Ger.	&	Est.	&	Ger.	&	Est.	&	Ger.	\\
		\midrule															
1	&	\multicolumn{2}{c}{\textit{et} 'that'}			&	\multicolumn{2}{c}{\textit{siis} 'then'}	&			\multicolumn{2}{c}{\textit{on} 'is'}	&			\multicolumn{2}{c}{\textit{et} 'that'}			\\
2	&	\multicolumn{2}{c}{\textit{ja} 'and'}			&	\textit{ei} 'no'	&	\textit{ma} 'I'	&	\multicolumn{2}{c}{\textit{ei} 'no'}	&			\textit{noh} 'well, uhm'	&	\textit{see} 'this'	\\
3	&	\multicolumn{2}{c}{\textit{siis} 'then'}			&	\textit{ma} 'I'	&	\textit{ei} 'no'	&	\multicolumn{2}{c}{\textit{oli} 'was'}	&			\textit{on} 'is'	&	\textit{ja} 'and'	\\
4	&	\textit{ma} 'I'	&	\textit{ei} 'no'	&	\textit{see} 'this'	&	\textit{et} 'that'	&	\multicolumn{2}{c}{\textit{et} 'that'}	&			\multicolumn{2}{c}{\textit{siis} 'then'}			\\
5	&	\textit{aga} 'but'	&	\textit{on} 'is'	&	\textit{on} 'is'	&	\textit{see} 'this'	&	\textit{me} 'we'	&	\textit{see} 'this'	&	\textit{see} 'this'	&	\textit{nagu} 'like'	\\
6	&	\textit{see} 'this'	&	\textit{ma} 'I'	&	\textit{oli} 'was'	&	\textit{on} 'is'	&	\textit{see} 'this'	&	\textit{ma} 'I'	&	\textit{ka} 'too'	&	\textit{mingi}  'some'	\\
7	&	\textit{kui} 'if, when'	&	\textit{see} 'this'	&	\textit{et} 'that'	&	\textit{oli} 'was'	&	\textit{nagu} 'like'	&	\textit{me} 'we'	&	\textit{oli} 'was'	&	\textit{on} 'is'	\\
8	&	\textit{või} 'or'	&	\textit{oli} 'was'	&	\textit{ta} '(s)he'	&	\textit{seal} 'there'	&	\textit{ma} 'I'	&	\textit{kui} 'if, when'	&	\textit{jah} 'yes'	&	\textit{seda} 'this [\scshape{PART}]'	\\
9	&	\textit{ei} 'no'	&	\textit{noh} 'well, uhm'	&	\textit{me} 'we'	&	\textit{ja} 'and'	&	\textit{seal} 'there'	&	\textit{nagu} 'like'	&	\textit{ja} 'and'	&	\textit{oli} 'was'	\\
10	&	\textit{mingi} 'some'	&	\textit{aga} 'but'	&	\textit{seal} 'there'	&	\textit{kui} 'if, when'	&	\textit{kui} 'if, when'	&	\textit{siis} 'then'	&	\textit{seda} 'this [\scshape{PART}]'	&	\textit{noh} 'well, uhm'	\\

			\lspbottomrule
		    \end{tabular}
	    }
    \end{table} 
\end{comment}



\begin{comment}
    %this is alternative 2 provided by the authors
    % Please load package longtable in the preamble to insert this table
\begin{center}
    \begin{longtable}{p{1.5cm}ll}
    \lsptoprule
    Freq. ranking	&	Estonian	&	German	\\
    		\midrule
	&	\multicolumn{2}{c}{\textbf{First position}}			\\
		\midrule
1	&	\multicolumn{2}{c}{\textit{et} 'that'}			\\
2	&	\multicolumn{2}{c}{\textit{ja} 'and'}			\\
3	&	\multicolumn{2}{c}{\textit{siis} 'then'}			\\
4	&	\textit{ma} 'I'	&	\textit{ei} 'no'	\\
5	&	\textit{aga} 'but'	&	\textit{on} 'is'	\\
6	&	\textit{see} 'this'	&	\textit{ma} 'I'	\\
7	&	\textit{kui} 'if, when'	&	\textit{see} 'this'	\\
8	&	\textit{või} 'or'	&	\textit{oli} 'was'	\\
9	&	\textit{ei} 'no'	&	\textit{noh} 'well, uhm'	\\
10	&	\textit{mingi} 'some'	&	\textit{aga} 'but'	\\
	\midrule				
	&	\multicolumn{2}{c}{\textbf{Second position}}			\\
		\midrule
1	&	\multicolumn{2}{c}{\textit{siis} 'then'}		\\
2	&	\textit{ei} 'no'	&	\textit{ma} 'I'	\\
3	&	\textit{ma} 'I'	&	\textit{ei} 'no'	\\
4	&	\textit{see} 'this'	&	\textit{et} 'that'	\\
5	&	\textit{on} 'is'	&	\textit{see} 'this'	\\
6	&	\textit{oli} 'was'	&	\textit{on} 'is'	\\
7	&	\textit{et} 'that'	&	\textit{oli} 'was'	\\
8	&	\textit{ta} '(s)he'	&	\textit{seal} 'there'	\\
9	&	\textit{me} 'we'	&	\textit{ja} 'and'	\\
10	&	\textit{seal} 'there'	&	\textit{kui} 'if, when'	\\
	\midrule				
	&	\multicolumn{2}{c}{\textbf{Third position}}			\\
		\midrule
1	&	\multicolumn{2}{c}{\textit{on} 'is'}		\\
2	&	\multicolumn{2}{c}{\textit{ei} 'no'}		\\
3	&	\multicolumn{2}{c}{\textit{oli} 'was'}		\\
4	&	\multicolumn{2}{c}{\textit{et} 'that'}		\\
5	&	\textit{me} 'we'	&	\textit{see} 'this'	\\
6	&	\textit{see} 'this'	&	\textit{ma} 'I'	\\
7	&	\textit{nagu} 'like'	&	\textit{me} 'we'	\\
8	&	\textit{ma} 'I'	&	\textit{kui} 'if, when'	\\
9	&	\textit{seal} 'there'	&	\textit{nagu} 'like'	\\
10	&	\textit{kui} 'if, when'	&	\textit{siis} 'then'	\\
	\midrule				
	&	\multicolumn{2}{c}{\textbf{Last position}}			\\
		\midrule
1	&	\multicolumn{2}{c}{\textit{et} 'that'}			\\
2	&	\textit{noh} 'well, uhm'	&	\textit{see} 'this'	\\
3	&	\textit{on} 'is'	&	\textit{ja} 'and'	\\
4	&	\multicolumn{2}{c}{\textit{siis} 'then'}			\\
5	&	\textit{see} 'this'	&	\textit{nagu} 'like'	\\
6	&	\textit{ka} 'too'	&	\textit{mingi}  'some'	\\
7	&	\textit{oli} 'was'	&	\textit{on} 'is'	\\
8	&	\textit{jah} 'yes'	&	\textit{seda} 'this [\scshape{PART}]'	\\
9	&	\textit{ja} 'and'	&	\textit{oli} 'was'	\\
10	&	\textit{seda} 'this [\scshape{PART}]'	&	\textit{noh} 'well, uhm'	\\
\lspbottomrule
    \caption{The ten most frequent words in the first, second, third and final positions of chunks identified by Estonian and German listeners (the cells are merged when the words did not differ between the languages).} \label{tab:long} \\
    \end{longtable}
    \end{center}
    
\end{comment}



    
    Table \ref{tab:4:wordFreqs} reveals no differences in the lexical constituency of Estonian and German chunks. The word frequencies reflect the nature of spontaneously spoken Estonian, in which the connectors (\textit{et} ‘that', \textit{ja} ‘and') and the pronouns (\textit{ma} ‘I', \textit{see} ‘this') have the highest frequency \citep[see][]{lippus2019}.

    Furthermore, we investigated the tonal coherence of the perceptual chunks that were identified by German and Estonian listeners. For this, we extracted F0 contours of each excerpt identified by each listener and categorized them based on their position within the excerpt: (i) at the beginning of the excerpts, that is, first chunk, (ii) following the first chunk, that is second chunk, (iii) at the end of the chunk, that is final, (iv) and all others between the second and the last chunk within the excerpt. There were 3999 three-chunk excerpts (46.9 percent of all the chunked excerpts), 2615 four-chunk excerpts (30.6 percent of all the chunkings) and only 1099 two-chunk excerpts (12.9 percent of all the chunkings). F0 contours of the perceptual chunks were then time-normalized by extracting 32 F0 measures, equally distributed within a respective perceptually identified chunk. The 32 measurements of F0 were then averaged by their position (see Figure \ref{fig:2:contours}). The different panels in Figure \ref{fig:2:contours} enable us to follow the decline of F0 in the excerpt-initial chunks, in the chunks of second position, the chunks of excerpt-medial position, and the chunks of the excerpt-final position.

    \begin{figure}%[H]
		\centering\includegraphics[height = .36\textheight, width= \textwidth]{figures/pitchContours_resized.pdf}\\
	    \caption{Time-normalized F0 contours converted into semitones (st) by position in excerpts and by language background of listeners. “First” refers to the excerpt-initial position and “Second” to the second position in an excerpt. “Medial” incorporates all other positions except the final position, and “Final” indicates the excerpt-final chunks.
	    }
	    \label{fig:2:contours}
    \end{figure}

    We can observe a continuous decline in F0 over the entire excerpt but also over the chunks identified at the different positions in the excerpts. Tonally, the chunks identified by German and Estonian listeners are comparable, and no major differences occur.%This is highly interesting, given that the majority of chunks identified by Estonian listeners are syntactic clauses.
    
    \section{Discussion}
    
    This study set out to investigate the impact of signal-driven prosodic cues on speech boundary perception in listeners of an unfamiliar language. We employed an RPT experiment in which German listeners unfamiliar with the Estonian language were asked to chunk spontaneous utterances spoken in Estonian. The results of the experiment were compared to the results of a previous experiment in which Estonian listeners were asked to perform a similar task listening to the same speech excerpts \citep[][]{otsTaremaaOpli2022}. We examined the duration of word-final syllables, the duration of pauses, intensity curves and F0 (F0 maxima relative to average F0 of respective sentences) as set against the clausal structure at the chunk boundaries identified by German and Estonian listeners.

    The results show that German listeners appear to use all the phonetic cues of syllable duration, intensity, pause duration and F0, and to ignore the clausal information. In contrast, Estonian listeners mostly utilize top-down information, as they largely relied on clause boundaries in the chunking task. After the clausal information, Estonian listeners also used the phonetic cues of pause duration and F0 but not syllable duration and intensity difference.

    More specifically, the results demonstrate for German listeners that the probability of boundary perception increased together with increasing duration of the word-final syllable. The longer syllable duration corresponding with the chunk boundary resembles the well-known prosodic boundary cue  --  the pre-boundary or phrase-final lengthening (\citealt{berkovits1994, Fon2011, Nakai2009, petroneEtAl2017, Wightman1992}; for German, see also \citetv{chapters/schuboe}, \citetv{chapters/huttenlauch}, and \citetv{chapters/wellmann}). Thus, it seems that the German listeners are guided by phrase-final lengthening while chunking an unfamiliar language. Furthermore, the analysis indicates that boundary perception became likelier among the German listeners as the intensity difference between the first and last syllable in the word increased. This suggests that German listeners interpreted the intensity drop as an additional cue for a chunk boundary.

    Although pauses are usually infrequent in conversational utterances \citep[][]{bironEtAl2021}, they are known to be accessible and reliable cues for boundary perception \citep[][]{himmelmannEtAl2018, riesbergEtAl2020, petroneEtAl2017}. In our study, we observe that listeners of both familiar and unfamiliar language backgrounds benefited from the presence of longer, rather than shorter, pauses: the longer the pause, the likelier the perception of a chunk boundary. Similarly, both language groups benefited from variation of F0. However, the tonal cue was interpreted in the opposite direction from what was predicted. The higher the word-initial stressed syllable was relative to the sentence’s mean F0, the likelier it was that the listener would perceive a boundary after this word.

    At first sight, the result concerning intonation is somewhat puzzling. As an explanation, we consider that the F0 maxima in our materials index a sort of rising boundary tone and not pitch accents. Theoretically, the stressed syllable preceding a rise is pitched low, and the F0 maxima in the final unstressed syllables should index the rise right before the phrase boundary. The lexical makeup of the identified chunks in Table \ref{tab:4:wordFreqs} demonstrates that the most frequent words at the ends of chunks were monosyllabic words. Monosyllabic words are considered to carry lexical stress, but they tend to become reduced and unstressed in unaccented positions of spoken utterances \citep[][54]{lehiste1960}. As such, they may well serve as carriers of the phrase-final tonal rise. Thus, our listeners, irrespective of their language background, interpreted increasing F0 contour as a cue for a chunk boundary. As such, the result corroborates the findings in \citet[][]{petroneEtAl2017} and in \citet[][]{KentnerFery2013}, who have found for German that the F0 in the first and last syllables of phrase-final words at the IP-medial positions is high, that is, the IP-medial phrase-final words have a strong tendency to carry a tonal rise. Our study, together with \citet[][]{petroneEtAl2017}, establishes that tonal rises are interpreted as boundary cues also in the perception of spontaneous speech natively and non-natively.

    In comparing the two language groups, we discovered that while phrase-final lengthening and intensity drop functioned as boundary cues for German listeners, they did not for Estonian listeners. It is possible that this difference might relate to the differing prosodic profiles of these languages. For example, steep F0 falls accompanied by a deep intensity drop are quite common for German declarative sentences \citep[][]{peters1999, ulbrich2002}. Thus, German listeners might be attuned to hearing large intensity drops accompanied by tonal falls as boundary cues. Similarly, phrase-final lengthening is most frequently attested in German and English. However, the lengthened segments signal the three-way quantity contrast of phonological feet that distinguishes between morpho-lexical functions in Estonian \citep[][]{eek1990, lehiste1960, lehiste1997}. Although the phonological variation of duration does not directly confine the phenomenon of phrase-final lengthening in production, Estonian listeners might nevertheless concentrate on aspects of segmental lengthening differently from German listeners. Thus, the results on intensity drop and pre-boundary lengthening indicate that the crosslinguistic applicability of prosodic boundary cues depends on the prosodic characteristics of the crossed languages.

    Clause boundaries, phrase-final lengthening, intensity drop and rising boundary tone performed well in explaining the distribution of boundary marks in the logistic mixed-effects analysis, but the concordance within the two groups of participants showed that the listeners demonstrated only fair agreement in identifying the presence of a boundary. The Fleiss’ $\kappa$ scores compared to the $\kappa$ scores reported in previous studies were considerably lower \citep[see, e.g.,][]{himmelmannEtAl2018, riesbergEtAl2020}. This holds true especially for the Estonian listeners who attended to their native language. On the one hand, this result might arise from the nature of the materials the participants were asked to listen to. The utterances were extracted from a corpus of dialogues that were held among friends or acquaintances on a freely chosen topic. Although they were recorded in an unnatural recording situation (in a professional sound-attenuated recording studio), these utterances represent highly conversational speech. The low agreement numbers most likely reflect the high acoustic variability characteristic of conversational speech. Also, the selected utterances probably display several different combinations of acoustic boundary cues in which pauses, pause duration, pre-boundary lengthening, intensity drop, and increasing F0 contour are produced at varying strengths. Rising F0 movement is usually accompanied by a decrease in intensity difference. As such, the rising boundary cue might counteract the cue of intensity drop. On the other hand, the low concordances suggest that listeners vary greatly in their cue weighting. For example, \citet[][]{baumannWinter2018} found that German listeners in a similar chunking task were divided into two groups: those who attend to pitch-related cues (such as pitch accent type, mean and maximum F0) and those who instead rely on duration and lexical and syntactic information. Most likely, the participants of the experiment made sense of numerous combinations of boundary cues in many different ways, which also explains the low agreement scores.

    In the final part of the analysis, we compared the lexical and acoustic characteristics of the speech chunks identified by the German and Estonian listeners. The native and non-native speech chunks displayed a number of shared characteristics. Specifically, the chunks were comparably long in duration and in the number of words. They also displayed very similar lexical variation, common for spontaneous speech in general. More importantly, the average F0 contours demonstrate that the speech chunks identified by both language groups conform to the concept of tonal coherence. Regardless of position in the excerpts, F0 was gradually declining across the native as well as non-native speech chunks. Thus, the chunks identified by the German and Estonian listeners differed from each other neither prosodically nor lexically.
    
    The Estonian chunks, however, corresponded more frequently with the syntactic clauses. To stay within the boundaries of the current study, we must refrain from further examination of the chunks that the German listeners identified. However, we find it very interesting that the German participants clearly found types of speech chunks that are not clauses but show prosodic coherence and high comparability with the clauses detected by native listeners. For future research, we propose to investigate what types of chunks German listeners identify in terms of semantic and pragmatic coherence and whether these could be helpful for language learners when decoding a second language.

    Overall, the study provides evidence that the two language groups  --  German and Estonian listeners  --  employed longer pauses and rising F0 contour in a speech chunking task. In other words, we have found crosslinguistic application of pausing and F0. As non-native listeners, Germans additionally utilized pre-boundary lengthening and intensity drop. Thus, while German listeners made use of all acoustic variables we investigated here, Estonian listeners applied only a few of them and relied mainly on the presence of clause boundaries.
	
	\begin{sloppypar}
    We categorized phonetic variables (duration, intensity and F0) as bottom-up information and clause boundaries as top-down information. We predicted less influence from clausal information but more influence from signal-based prosodic information for German listeners than for Estonian listeners. As discussed above, the results support this prediction. As expected, in chunking Estonian speech, German listeners unfamiliar with the Estonian language make use of bottom-up information only, whereas Estonian listeners mostly utilize top-down information, as they largely relied on clause boundaries in the chunking task. This outcome runs counter to the results in \citet[][]{riesbergEtAl2020} and demonstrates that the production of prosody in Estonian spontaneous speech is not too tightly bound to the clausal structure. Nevertheless, the results reflect well on the bottom-up and top-down processing mechanisms. %The study demonstrates that signal-driven prosodic cues, that is bottom-up information, are a powerful source of information not only for non-native but also for native listeners.
    \end{sloppypar}
    
    Clearly, when a listener has no knowledge of a language, prosodic boundary cues are the primary source of information for making sense of speech in an unfamiliar language. Native listeners, however, mainly employ semantic and syntactic knowledge, that is, top-down information, but, as we have seen, benefit from prosodic information as well. We speculate that the role of prosodic information is even greater but in the type of RPT task, it is flooded with semantic and syntactic information which emerges from lexical sources. Therefore, the role of prosody in the earliest stages of spoken language processing might be better established by using more sensitive methods being able to tap into the on-going decoding processes (see \citetv{chapters/wellmann} for boundary perception in infants). Nevertheless, our study of non-native listeners in comparison to the previous study of native listeners has successfully demonstrated both bottom-up and top-down effects in the processing of spontaneous speech. %thus, cannot be accessed with the RPT methodology employed here or with the button-press methodology employed in \citet[][]{christodoulidesEtAl2018}.

    We probably see top-down processing somewhat overriding bottom-up processing in native speech processing. This is understandable because top-down processing, together with prediction, is an efficient way to reduce the cognitive load, as it enables one to avoid processing every single aspect of information available in the environment \citep[][]{barEtAl2006, clark2016, engelEtAl2001}. We believe that the phenomenon of top-down processing also explains the results of previous phonetic perception experiments in which boundary perception in native listeners has been shown to be mediated mainly by syntactic and lexical variables \citep[e.g.,][]{coleEtAl2010, christodoulidesEtAl2018, baumannWinter2018}. To demonstrate the impact and functions of bottom-up information  --  signal-driven prosodic boundary cues in particular  --  for native listeners, future studies should involve more rigorous research techniques that can assess on-going comprehension.
    
    \section{Conclusion}\largerpage
    
    In this study, we investigated the impact of signal-driven prosodic cues on chunking excerpts of a natural language. For this, we utilized RPT methodology and asked non-native listeners (Germans) to identify speech chunks in excerpts spoken in an unfamiliar language (Estonian). We examined the acoustic variation at the boundaries of chunks identified by German listeners with reference to chunk boundaries detected in the same excerpts by Estonian listeners in an earlier experiment. The results show that German listeners, having no access to the semantic-syntactic structure of Estonian, largely rely on signal-driven prosodic information and utilize syllable duration, intensity curves, pause duration and rising F0 contour when dividing a continuous stream of speech into smaller chunks. Estonians, on the contrary, rely mainly on the presence of clause boundaries, but they additionally apply pause duration and rising F0 contour for the identification of speech chunks. The results demonstrate the importance of signal-driven prosodic boundary cues in bottom-up processing of spoken language and highlight the interaction between bottom-up processing (sensory input from speech acoustics) and top-down processing (linguistic knowledge about clause structure) in native speech comprehension.
    \largerpage




%\section*{Abbreviations}
%\begin{tabularx}{.45\textwidth}{lQ}
%	IP & \\
%	RPT & \\
%	PART & \\
%\end{tabularx}
%\begin{tabularx}{.45\textwidth}{lQ}
%	intonational phrase & \\
%	Rapid Prosody Transcription & \\
%	partitive case form & \\
%\end{tabularx}

\section*{Acknowledgments}

We are extremely thankful to the Estonian volunteers and the German participants who took part in our experiments. We further appreciate the warm and supportive audience of the workshop ``Prosodic boundary phenomena" at the 43rd annual meeting of the DGfS (Deutsche Gesellschaft für Sprachwissenschaft), who strongly motivated a study with non-native listeners.


\section*{Funding information}
This work was supported by research funding awarded to the first author by Fritz Thyssen Stiftung in Germany (10.18.2.040SL, “Planning sentences and sentence intonation cross-linguistically”) and by funding from the European Union through the European Regional Development Fund (Centre of Excellence in Estonian Studies) and from the research fund of Kadri, Nikolai, and Gerda Rõuk, both of which were awarded to the second author.

\printbibliography[heading=subbibliography,notkeyword=this]

\end{document}
