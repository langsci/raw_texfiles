\section[head=Experiment 9]{Experiment 9: Self-paced reading study on \emph{de qui} relative clauses with an animate antecedent and animate subject and object}
\label{ch:exp09}

This experiment is an online study variant of Experiment~7. Our goal was to see how participants process subextractions from subjects and objects. 

\subsection{Design and materials}

We used materials (items and distractors) similar to those in Experiment~7.\footnote{More exactly, Experiment~7 was intended as a calibration study for the self-paced reading Experiment~9.} We made some small changes in order to avoid repetition within the same sentence (e.g.\ \emph{de qui les étudiants étonnent mes étudiants} `of who the students astonish the students') and to match the length of the subject and object nouns (with +/- one character). As in Experiment~7, we compared extractions out of subjects (\ref{ex:exp09-subj-pp}) with extractions out of objects (\ref{ex:exp09-obj-pp}), and paired each of them with a coordination (\ref{ex:exp09-subj-no};\ref{ex:exp09-obj-no}) and an ungrammatical control with the preposition \emph{de} missing (\ref{ex:exp09-subj-un};\ref{ex:exp09-obj-un}). The square brackets indicate the regions (i.e., groups of words) that were presented together on the screen:

\eal 
\ex[]{{Condition subject + PP-extracted:}\nopagebreak\\
\gll  [J' ai pris]$_1$ [un avocat]$_2$ [de qui]$_3$ [le confrère]$_4$ [aide]$_5$ [mon parrain]$_6$ [sans]$_7$ [contrepartie]$_8$.\\
\sbar{}I have taken \sbar{}a lawyer \sbar{}of who \sbar{}the colleague \sbar{}helps \sbar{}my godfather \sbar{}without \sbar{}counterpart\\
\glt `I took a lawyer of who the colleague helps my godfather without compensation.'}
\label{ex:exp09-subj-pp}
\ex[]{{Condition object + PP-extracted:}\nopagebreak\\
\gll  [J' ai pris]$_1$ [un avocat]$_2$ [de qui]$_3$ [mon parrain]$_4$ [aide]$_5$ [le confrère]$_6$ [sans]$_7$ [contrepartie]$_8$.\\
\sbar{}I have taken \sbar{}a lawyer \sbar{}of who \sbar{}my godfather \sbar{}helps \sbar{}the colleague \sbar{}without \sbar{}counterpart\\
\glt `I took a lawyer of who my godfather helps the colleague without compensation.'}
\label{ex:exp09-obj-pp}
\ex[]{{Condition subject + noextr:}\nopagebreak\\
\gll [J' ai pris]$_1$ [un avocat]$_2$ [et]$_3$ [son confrère]$_4$ [aide]$_5$ [mon parrain]$_6$ [sans]$_7$ [contrepartie]$_8$.\\
\sbar{}I have taken \sbar{}a lawyer \sbar{}and \sbar{}his colleague \sbar{}helps \sbar{}my godfather \sbar{}without \sbar{}counterpart\\
\glt `I took a lawyer and his colleague helps my godfather without compensation.'}
\label{ex:exp09-subj-no}
\ex[]{{Condition object + noextr:}\nopagebreak\\
\gll [J' ai pris]$_1$ [un avocat]$_2$ [et]$_3$ [mon parrain]$_4$ [aide]$_5$ [son confrère]$_6$ [sans]$_7$ [contrepartie]$_8$.\\
\sbar{}I have taken \sbar{}a lawyer \sbar{}and \sbar{}my godfather \sbar{}helps \sbar{}his colleague \sbar{}without \sbar{}counterpart\\
\glt `I took a lawyer and my godfather helps his colleague without compensation.'}
\label{ex:exp09-obj-no}
\ex[]{{Condition subject + ungrammatical:}\nopagebreak\\
\gll [J' ai pris]$_1$ [un avocat]$_2$ [qui]$_3$ [le confrère]$_4$ [aide]$_5$ [mon parrain]$_6$ [sans]$_7$ [contrepartie]$_8$.\\
\sbar{}I have taken \sbar{}a lawyer \sbar{}who \sbar{}the colleague \sbar{}helps \sbar{}my godfather \sbar{}without \sbar{}counterpart\\
\glt `I took a lawyer who the colleague helps my godfather without compensation.'}
\label{ex:exp09-subj-un}
\ex[]{{Condition object + ungrammatical:}\nopagebreak\\
\gll [J' ai pris]$_1$ [un avocat]$_2$ [qui]$_3$ [mon parrain]$_4$ [aide]$_5$ [le confrère]$_6$ [sans]$_7$ [contrepartie]$_81$.\\
\sbar{}I have taken \sbar{}a lawyer \sbar{}who \sbar{}my godfather \sbar{}helps \sbar{}the colleague \sbar{}without \sbar{}counterpart\\
\glt `I took a lawyer who my godfather helps the colleague without compensation.'}
\label{ex:exp09-obj-un}
\zl 

About a third of the experimental items and distractors were followed by a comprehension question.

\subsection{Experimental method}

Self-paced reading tasks were first introduced by \citet{Just.1982}. 
As in eye tracking experiments, the underlying assumption is that participants' reading pace slows down (and hence their reading time increases) when they are having difficulty processing a sentence chunk. The methodology is therefore comparable to eye tracking experiments, but with only one type of reaction times.

In a self-paced reading experiment, sentences are presented as a series of smaller segments appearing one at a time. Participants control the reading pace by pressing a key or button to get from one region to the next. 
In contrast to eye tracking experiments (Section \ref{ch:exp03}), participants cannot compensate for memory difficulties by going back to a previous part of the sentence. Difficulties in retrieving the filler's information, integration problems, or difficulties with an improbable gap site are assumed to be reflected in longer reading times.

\subsection{Predictions} 

In general, all accounts assume that subextractions induce more processing costs than non-subextractions. Therefore, when examining the extraction conditions vs.\ the non-extraction conditions, we expect to see a penalty on the reading times for the subject in (\ref{ex:exp09-subj-pp}) compared to (\ref{ex:exp09-subj-no}), and for the object in (\ref{ex:exp09-obj-pp}) compared to (\ref{ex:exp09-obj-no}). As we will see, there is one exception to this prediction.

It is not entirely clear what reading time effects to expect under accounts that predict a penalty for extracting out of the subject. Syntactic approaches assume that readers do not attempt to posit a gap inside the subject, because they know that it would be ungrammatical. Readers should also not attempt to posit a gap inside the subject under processing accounts based on subject complexity. According to \citet{Kluender.2004}, complex subjects are not frequent and thus a gap in this position is not expected. However, the same cause can lead to two different scenarios.

The first scenario is the following: Readers are surprised to find a gap in the subject that they did not anticipate. The consequence is that reading times for extractions out of the subject increase more than reading times for extractions out of the object, resulting in an interaction effect. In reference to \citegen{Hale.2001} notion of surprisal, I call this the ``surprisal'' scenario.

In the second scenario, at the subject, readers do not posit any gap, because it is highly improbable. At this point, they expect to encounter a gap later. The consequence is that there is no increase in reading time on the subject for (\ref{ex:exp09-subj-pp}) compared to (\ref{ex:exp09-subj-no}). This is the approach of \citet{Yoshida.2014}. It predicts an interaction effect, such that extraction out of the object (\ref{ex:exp09-obj-pp}) leads to longer reading times than the other conditions (\ref{ex:exp09-subj-pp}), (\ref{ex:exp09-subj-no}) and (\ref{ex:exp09-obj-no}). The processing difficulty caused by the subextraction from the subject may arise at the end of the sentence, as readers still have an unintegrated filler in memory, because \emph{de qui} in (\ref{ex:exp09-subj-pp}) can neither be the complement of the object noun nor of the verb. I call this the ``giving up'' scenario. 

Under a processing account based on memory costs, when readers encounter the filler, they will anticipate a gap at the closest possible site, i.e.\ in the subject. In the condition with subextraction out of the subject (\ref{ex:exp09-subj-pp}), this expectation is met. When subextraction takes place out of the object (\ref{ex:exp09-obj-pp}), the reader has to revise this prediction and posit another gap at the closest possible site. This results in filled-gap effects on the subject (see Section \ref{ch:processing} about filled-gap effects). The consequence is that reading times for extractions out of the object increase more than reading times for extractions out of the subject in this region. I call this the ``asap'' scenario. 

An account based on the FBC constraint expects no special behavior in subject vs.\ object subextractions: reading times for extractions out of the object should increase as much as reading times for extractions out of the subject. I call this the ``nothing to report'' scenario.

Before we look at the results of the experiment, it is important to note that reading time data are very messy, and difficult to interpret. The predictions of the different scenarios described above are themselves debatable, because they are much too simple and cannot reflect every processing factors that should be considered when trying to explain the results. However, they are the only way to prevent post hoc explanations of the observed results.

\subsection{Procedure} 

The experiment was conducted at the Laboratoire de Linguistique Formelle (LLF) in the Université Paris Cité. The investigators were Aixiu An and myself. The experiment was run on E-Prime experimental software (Psychology Software Tools, Pittsburgh, PA). Testing was done individually.

The participants received written instructions and gave informed consent. Before the actual experiment, participants provided information on their linguistic background. These information forms were treated anonymously during data processing.

Sentences were presented one region at a time on a computer screen, with the other missing words of the sentence replaced by placeholders. Participants would press a button to proceed to the next chunk of words corresponding to the next region. They were instructed to read the sentence as fast as possible while maintaining good comprehension. At the end of each sentence, they would press a button to move on. 
In some trials, a comprehension question would appear on the screen related to the sentence just read. Participants responded to it by choosing one of two possible answers on the screen. 
We used a Latin square design, such that each participant saw each item and distractor in only one condition.
The items were pseudo-randomized, to avoid having two items in the same condition or two non-distractors following each other.

The experiment lasted approximately 20 minutes. At the end, participants were debriefed and they received a payment of 8€.


\subsection{Participants}

The study was run between November 2018 and February 2019.  
Partipants were recruited on the R.I.S.C.\ website (\url{http://experiences.risc.cnrs.fr/}) and on social media (e.g.\ Facebook). 

\pagebreak
48 participants took part in the experiment, all monolingual native speakers of French. They all had more than 75\% accuracy in the comprehension questions.\footnote{To calculate accuracy, we excluded the answers to comprehension questions of the practice items and of the ungrammatical conditions (\ref{ex:exp09-subj-un}) and (\ref{ex:exp09-obj-un}).} Data from all 48 participants were included in the analysis.

\subsection{Results and analysis}

We excluded outliers for every region: taking only the experimental items into account (i.e.\ ignoring practice items and distractors that have very different regions), we calculated each participant's mean and standard deviation and excluded reading times that were over 3 standard deviations from the mean; we also calculated for each condition the mean and standard deviation and excluded reading times that were over 3 standard deviations from the mean. 

The distribution of the reading times is not normal. For this reason, we log-transformed them using the function \texttt{log()} in R \citep{R}, to get a distribution closer to normal. The data shown in the graphs are log-transformed reading times by character, i.e. the total reading time on a region divided by the number of characters and then log-transformed.

\figref{fig:exp09-rt} display the reading times across regions.  We can see that the non-extraction conditions were generally read more quickly than the extraction conditions, whereas the ungrammatical conditions were read more slowly. There is also more variation between conditions in regions 3 and 6, where the words differ. Regions 1 and 2 show some variation as well, which can only be noise given that the condition did not differ. The variation across extraction types in region 3 is probably an artefact of the important difference in length (e.g.\ \emph{et} vs.\ \emph{de qui}). On regions 4 (subject of the relative) and 5 (verb of the relative), the subject conditions were read more slowly than the object conditions (except for the ungrammatical control, where subject and object conditions are almost indistinguishable). On region 6 (object of the relative) however, the reading times for the object conditions increase. In this respect, we see no obvious difference between subextraction and anaphoric binding (linking the possessive article to his antecedent).  \figref{fig:exp09-rt-456} shows regions 4--6 in more detail in the non-extraction and subextraction conditions.\largerpage[-1]

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{chapters/part2-Empirical/Exp09-dequi-RC-animacy-match-SPR/RT-experiment.jpeg}
    \caption[Mean log-transformed reading times by character by condition in Experiment 9]{Mean log-transformed reading times by character by condition in Experiment~9
    (regions = 1: matrix clause; 2: antecedent; 3: relative phrase/coordination; 4: Subject; 5: Verb; 6: Object, 7: 1st part of AdvP, 8: 2nd part of AdvP)}
    \label{fig:exp09-rt}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{chapters/part2-Empirical/Exp09-dequi-RC-animacy-match-SPR/RT-zones456.jpeg}
    \caption[Mean log-transformed reading times by character for the grammatical conditions of Experiment~9 (regions 4--6 only)]{Mean log-transformed reading times by character for the grammatical conditions of Experiment~9 (regions 4--6 only)\\
    (Regions = 4: Subject; 5: Verb; 6: Object)}
    \label{fig:exp09-rt-456}
\end{figure}

\pagebreak
\subsubsection{Effect of frequency} 

We assigned a frequency value to regions 4--6 based on the frequency of the head noun for regions 4 and 6 and the frequency of the verb for region 5. The frequency value was taken from \url{lexique.org}.\footnote{The Lexique database was implemented by Boris New and Christophe Pallier. We used the frequency of the lemma, called \texttt{freqlemfilm2} and based on the frequency in French subtitles.} Frequencies, like the reading times, are not normally distributed, so we used the log-transformed frequency.

The effect of frequency on the different conditions is shown in \figref{fig:exp09-frequency} (for the sake of clarity, the figure does not include the ungrammatical controls). There is a general impact of frequency on reading times: more frequent words are read more quickly. This effect seems stronger for the subject conditions (which, as we have seen, have longer reading times) than for the object conditions. 

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{chapters/part2-Empirical/Exp09-dequi-RC-animacy-match-SPR/frequency-noung.jpeg}
    \caption{Changes in the reading times (log-transformed reading times by character) depending on the frequency (log-transformed frequency) for subextraction and non-extraction conditions of Experiment~9}
    \label{fig:exp09-frequency}
\end{figure}

Considering only the subextraction site (i.e.\ only the two subextraction conditions, and the reading times on region 4 for extraction out of subject and on region 6 for extraction out of object), we fitted a first model crossing syntactic function (mean centered with subject coded positive and object coded negative) and log-transformed frequency. The variable to be explained are log-transformed reading times. We included characters (the number of characters in the region), participants and items as random factors. The results of the model are reported in Table \ref{tab:exp09-m1}. 
There is a significant main effect of frequency, but no interaction effect; the frequency effect on the extraction site is not significantly different in extractions out of the subject and extractions out of the object. 

\input{chapters/part2-Empirical/Exp09-dequi-RC-animacy-match-SPR/m1.tex}

\subsubsection{Effect of extraction on the extraction site}

Turning to the subject (region 4), we fitted a second model to compare the extractions out of the subject with their non-extraction controls (mean centered with subextraction coded negative and non-extraction coded positive). We included log-transformed frequency as a covariate, and characters, participants and items as random factors. The results of the model are reported in Table \ref{tab:exp09-m2}. 
There is a significant main effect of frequency, but no effect of extraction type. Non-extractions were read more quickly, but not significantly more quickly, than the subextractions.

\input{chapters/part2-Empirical/Exp09-dequi-RC-animacy-match-SPR/m2.tex}

We fitted a third model to compare the extractions out of the object with their non-extraction controls (mean centered with subextraction coded negative and non-extraction coded positive), i.e.\ on region 6. We included log-transformed frequency as a covariate, and characters, participants and items as random factors. The results of the model are reported in Table \ref{tab:exp09-m3}. 
There is no significant difference between the subextraction and its non-extraction control. Again, non-extractions were read more quickly, but not significantly more quickly, than the subextractions.

\input{chapters/part2-Empirical/Exp09-dequi-RC-animacy-match-SPR/m3.tex}

\subsubsection{Do reading times for extraction out of the subject increase more/less than reading times for extraction out of the object? (``surprisal'' and ``giving up'' scenarios)}

In a fourth model, we compared the two extraction sites: region 4 for extractions out of the subject and their non-extraction control, and region 6 for extractions out of the object and their non-extraction control. We fitted a model crossing syntactic function (mean centered with subject coded positive and object coded negative) and extraction type (mean centered with extraction coded positive and non-extraction coded negative). We included log-transformed frequency as a covariate, and characters, participants and items as random factors. The results of the model are reported in Table~\ref{tab:exp09-m4}. 
There is a significant main effect of syntactic function (objects were read more slowly), and a significant main effect of frequency. In line with models n$^{\circ}$2 and n$^{\circ}$3, there is no significant main effect of extraction type. There is also no significant interaction. 
\figref{fig:exp09-interaction} shows the interaction with only a small tendency toward an interaction effect.

\input{chapters/part2-Empirical/Exp09-dequi-RC-animacy-match-SPR/m4.tex}

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{chapters/part2-Empirical/Exp09-dequi-RC-animacy-match-SPR/Interaction-Extr.jpeg}
    \caption{Interaction between syntactic function and extraction type on the respective extraction site in Experiment~9. Reading times are indicated as log-transformed reading times by character.}
    \label{fig:exp09-interaction}
\end{figure}

\subsubsection{Do reading times for extraction out of the object increase more than reading times for extraction out of the subject in region 4? (``asap'' scenario)}

In a fifth model, we compared the difference between the subextractions and their respective non-extraction controls in region 4. We fitted a model crossing syntactic function (mean centered with subject coded positive and object coded negative) and extraction type (mean centered with extraction coded positive and non-extraction coded negative). We included log-transformed frequency as a covariate, and characters, participants and items as random factors. The results of the model are reported in Table \ref{tab:exp09-m5}. 
There is a significant main effect of extraction type (subextractions were read more slowly), and a significant main effect of frequency. There is no significant main effect of extraction type, and no significant interaction. The non-significant interaction can be seen in \figref{fig:exp09-interaction-4}: the lines are perfectly parallel.

\input{chapters/part2-Empirical/Exp09-dequi-RC-animacy-match-SPR/m5.tex}

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{chapters/part2-Empirical/Exp09-dequi-RC-animacy-match-SPR/Interaction-zone4.jpeg}
    \caption{Interaction between syntactic function and extraction type in region 4 (subject of the relative) in Experiment~9. Reading times are indicated as log-transformed reading times by character.}
    \label{fig:exp09-interaction-4}
\end{figure}

\subsection{Discussion}

Even though participants discriminated strongly between subextractions with \emph{de qui} and their non-extraction controls, we could not find any strong effect due to the subextraction itself in reading times (models n$^{\circ}$2, n$^{\circ}$3 and n$^{\circ}$4). One possible explanation may lie in our non-extraction control, which involved a coordination with anaphoric binding (the possessive article). \citet[641]{Keshev.2019} conducted an experiment on anaphoric binding, using \citeauthor{Sprouse.2016}'s superadditivity design for islands and found a marginal interaction effect (p = 0.08).
The retrieval costs for anaphoric binding may have canceled out the costs of extraction in our design. This was not an issue in Experiment~7, where the non-extraction controls were complex NPs with non-anaphoric \emph{de}-complements.

In Experiment~9, we failed to find statistically significant evidence for any of the differences expected under the different scenarios. Perhaps we find ourselves in the ``nothing to report'' scenario, where, indeed, no difference is expected apart from the difference between extraction and non-extraction. However, it could also be the case that the experiment just did not have enough participants to detect significant effects. % cohen's d could be a measure

\pagebreak
To conclude, none of the scenarios we have presented in the prediction section was falsified by the experiment. The least probable is, however, the ``surprisal'' scenario, whose predictions are the opposite of the tendency in \figref{fig:exp09-interaction}.

This experiment shows that, if there is any effect of subextraction out of the subject on reading times, this effect is subtle. Under the assumption that reading times and acceptability ratings correlate to a certain degree, the results are in line with those of the previous experiments on relative clauses.
