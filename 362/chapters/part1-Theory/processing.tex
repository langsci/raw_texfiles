% LI article : Hofmeister \& Sag \citet[406]{Hofmeister.2010} suggested that most ``island'' constraints are ``arbitrary in the sense that they bear no relationship to other constraints, emanate from no general principles of language'' and ``offer little insight into anything about language or cognition, except islands themselves.'' Recent work in HPSG assumes that no general locality constraints are needed in the syntax of long distance dependencies and that most difficulties come from processing, pragmatics or from the mere definition of the constructions \cite{Chaves.2012,Chaves.2013}.

\section{General mechanisms of processing associated with extraction}
\label{ch:processing}

Language is used in two different ways: production (generation) and comprehension (parsing), performed respectively by an addressor (speaker, writer or signer) and an addressee (hearer or reader).
Different linguistic resources are needed to perform these two tasks: a common grammar, procedures for constructing representation during comprehension, and procedures for building sentence structures during production \citep[236-237]{Momma.2018}. 
There is compelling evidence that the latter two mechanisms (construction of representation and sentence structure building) appeal to common cognitive resources. For example, agreement attraction\footnote{Agreement attraction is a particular linguistic illusion involving ungrammatical agreement that is perceived by a large number of native speakers as grammatical under certain conditions. For example, participants in experiments are very likely to accept a sentence like (i):
\begin{itemize}
    \item[(i)] The bed by the lamps were undoubtedly quite comfortable. \citep{Schlueter.2019}
\end{itemize}}
happens similarly in production and comprehension tasks.
I will therefore adopt here \citegen{Momma.2018} view that the two mechanisms are related, though this is still debated.

I here use the term ``processing'' to account for the cognitive process of using these linguistic knowledge resources. Some utterances involve more processing costs than others, in both production and comprehension.

Extraction is known to cause processing difficulty. Structures with gaps are harder to process than structures without gaps \citep{Wanner.1978,Kluender.1993.Subjacency}. A variety of models exist in order to account for the distribution of costs in these structures. I present in Section~\ref{ch:dlt+dg} the model adopted by the Dependency Locality Theory (DLT) in detail. But online experiments reveal at least two main processing difficulties, one due to the filler and the second due to the gap.

\subsection{Processing cost for the filler}

The first processing cost is incurred at the filler site. During comprehension, the phenomenon is called ``active gap search'': As soon as the filler is encountered, it is recognized as a signal for an upcoming gap, and processing mechanisms start to postulate potential gap sites. This induces memory costs (for remembering the morphosyntactic properties of the filler), but also costs for anticipating the potential gap sites. One consequence of the latter are so-called filled-gap effects. Discovering that a postulated (because highly probable) gap site is already filled produces additional processing costs \citep{Stowe.1986}. For example, in an self-paced reading experiment conducted by \citeauthor{Stowe.1986}, participants had to read the sentence (\ref{ex:filled-gap-effect}) word by word. When they reached the end of the fragment in (\ref{ex:filled-gap-effect-uncomplete}), they presumably postulated a gap in the object position, because an increase of the reading times (linked to additional processing costs) was measured on the direct object \emph{us}. Scholars generally assume that the reader has to re-anticipate the next probable gap site when the most probable one is already filled. This is linked to additional processing costs.
% (not sure if I need it) : the longer you are commited to a wrong analysis, the harder it is to retrieve the right one \citep{Bailey.2003}
% other phenomenon: hyperactive gap filling (Omaki A, Lau EF, Davidson White I, Dakan ML, Apple A, Phillips C. 2015. Hyper-active gap filling. Front. Psychol. 6:384)
% other phenomenon : garden path (Osterhout, L., & Holcomb, P.J. (1992). Event-related brain potentials elicited by syntactic anomaly. Journal of Memory and Language , 31 , 785–806.)

\begin{exe}
\ex \citep[234]{Stowe.1986}
\begin{xlist}
\ex[]{My brother wanted to know who$_i$ [Ruth will bring us home to \trace{}$_i$ at Christmas]}
\label{ex:filled-gap-effect}
\ex[]{My brother wanted to know who Ruth will bring\dots}
\label{ex:filled-gap-effect-uncomplete}
\end{xlist}
\end{exe}

Less work has been done on the processing costs during generation. Production errors show that it is difficult for the speaker to anticipate the gap site and choose the correct filler accordingly. In a very typical disfluency during spontaneous speech, the speaker begins a structure involving an extraction, commits to a certain filler, and realizes later in the clause that the filler is illicit \citep[243]{Momma.2018}.

\subsection{Processing cost for the gap}

The second processing cost is incurred when the integration of the information from the filler takes place. Again, the phenomenon has been well studied in comprehension, but less so in production. Intuitively, it is easy to understand how identifying a gap site can be hard for the addressee. By definition, a gap is not overtly signaled in the sentence, and there is also no overt indication whether a filler is linked to one or to several gaps. But beyond this first intuition, there is also empirical evidence that the ``resolution'' of the filler-gap dependency is associated with processing costs. 

\citet{Kaan.2000} have shown by recording online event-related potentials (ERPs) in reading experiments that integration elicits P600 effects\footnote{P600 = The waveform of the ERPs has a positive peak around 600 ms after the word onset.}, such that the more complex the integration is, the higher the amplitude of the P600. Note that this integration cost has been observed at the subcategorizing head (the P600 peaks around 600 ms after the verb's onset when extracting an argument of the verb). 
% other ref: Phillips C, Kazanina N, Abada S. 2005. ERP effects of the processing of syntactic long-distance dependencies. Cogn. Brain Res. 22:407–28

\citet{Momma.2019} also present preliminary results that seem to indicate that some additional costs are associated with the integration of the gap. Taking advantage of the PP/NP alternation in English with \emph{give}-like ditransitive verbs (the benefactive can be expressed as a PP or NP), they made participants produce interrogatives with extraction of the PP object (the only felicitous variant in interrogatives), with and without prior priming for the NP variant. They observe a slowdown in producing the verb when participants were primed for the NP variant, see example (\ref{ex:giving-experience-momma}). This indicates that the integration of the filler is taking place when planning the subcategorization of the verb: participants notice that the structure they have been primed to is not felicitous and take more time to integrate the gap with the appropriate syntax.

\ea[]{\emph{Priming}: The girl is reading the boy the book.\\
      \emph{Production}: Who is the doctor \textit{giving} the trumpet to?}
\label{ex:giving-experience-momma}
\z 

These observations suggest that extraction is a syntactic mechanism that brings with it big additional processing costs. In this chapter, I will present two main approaches to subextraction from subjects from a processing point of view. These approaches make opposite predictions for subextraction from the subject: under processing accounts based on memory costs, it should be easier to process than subextraction from the object (no ``subject island'' effect), while processing accounts based on relevance and surprisal predict an increase of processing costs associated with subextraction from (sentential, infinitival or NP) subjects.

% definition of superadditivity

\section{Dependency-length minimization}
\label{ch:dlt+dg}
\largerpage
I will present two accounts based on dependency-length minimization, the DLT and Dependency Grammar. Both have their origin in the Active Filler Hypothesis \citep{Frazier.1987,Clifton.1989}, which states that when one encounters a filler (or a cue that a gap is coming), one postulates the closest possible gap. Because filler-gap dependencies are cognitively costly, the longer the distance between the filler and the gap, the the longer one has to keep the content of the filler in memory \citep{Fadlon.2019}. As a consequence, the mental representation of the filler becomes weaker as the distance to the gap increases \citep{Lewis.2005}. This also has an impact on sentence production, because of a cooperation principle between the speaker and the addressee: the speaker tries to make the sentence as easy to understand as possible, while the addressee tries to make sense of the sentence to the best of their capacity. This results in a general preference in language to minimize the distance between the filler and the gap. 

Some processing-based models of filler-gap dependencies, therefore, predict that shorter distances between the filler and the gap are easier to process, leading to an increased acceptability. Depending on the model, the distance may be measured in terms of linear distance \citep{Gibson.1998,Gibson.2000} or in terms of structural distance \citep{Rizzi.1990,Hawkins.1999}. Both approaches lead to similar expectations, and make the same predictions in the case of subextraction from the subject, namely that extraction out of the subject should actually be easier than extraction out of the object, because the dependency (be it linear or structural) between the filler and the gap (or between the filler and the subcategorizer of the gap) is shorter in extraction out of subjects.\largerpage

%The topic of subject island is not addressed directly by these theories.\footnote{Or from a different perspective, as in \citet{Hawkins.1999}, see section \ref{ch:Hawkins}.} 
%\footnote{There is one indirect mention in \citet{Candito.2012.ldd}, see below.}
%\citet{Hawkins.1999} develops the idea of ``Minimize Filler-Gap Domains'', which is a formalization of the principle of dependency-length minimization, and he addresses directly the problem of islands, among which the Subject Condition, 
One important issue is the asymmetry between subject vs.\ object relative clauses: Subject relative clauses are easier to process than object relative clauses and are rated higher in acceptability judgment tasks (\citealt{Holmes.1981}; \citealt{Wanner.1978} and many more). A classical example in the literature is the contrast in (\ref{ex:contrast-SRC-ORC}) between an extraction of the subject (\ref{ex:contrast-SRC}) and of the object (\ref{ex:contrast-ORC}). 

\begin{exe}
\ex \citep[20--21]{Gibson.1998}
\label{ex:contrast-SRC-ORC}
\begin{xlist}
\ex[]{The reporter [who$_i$~\trace{}$_i$ attacked the senator] admitted the error. \label{ex:contrast-SRC}}
\ex[]{The reporter [who$_i$ the senator attacked~\trace{}$_i$] admitted the error. \label{ex:contrast-ORC}}
\end{xlist}
\end{exe}

This asymmetry holds cross-linguistically and is attributed to the shorter (linear and structural) distance between filler and gap in (\ref{ex:contrast-SRC}) than in (\ref{ex:contrast-ORC}). \citet[252--256]{Hawkins.1999} emphasizes the similarity between dependency-length minimization strategies (not only for filler-gap dependencies) and the Accessibility Hierarchy of \citet{Keenan.1977}.\footnote{The Accessibility Hierarchy is a typological hierarchy of arguments. The hierarchy in \citet{Keenan.1977} is the following: Subject $>$ Direct Object $>$ Indirect Object $>$ Oblique $>$ Genitive $>$ Object of comparative (in subsequent works of \citeauthor{Keenan.1977}, Indirect Object and Oblique are collapsed into one). One observation of \citet{Keenan.1977} is that languages that allow only one type of extraction (e.g., Maori) allow the extraction of the subject; languages with two extraction types (e.g., Luganda) allow the extraction of the subject and of the direct object, and so forth.} The subject island constraint seems to go against all expectations of the dependency-length minimization strategies, but also against \citegen{Keenan.1977} Accessibility Hierarchy. 

\subsection{Dependency Locality Theory (DLT)}

\citet{Gibson.1998,Gibson.2000} proposes the Dependency Locality Theory (DLT), a cognitive model of sentence processing with a particular focus on filler-gap dependencies. This model identifies two costs of cognitive resources involved in filler-gap dependencies: (i) memory costs and (ii) energy costs. Memory costs are caused by the need to store the predictions made about the upcoming structure as the sentence continues, e.g.\ predictions on the gap site (see above). Energy costs, on the other hand, are caused by the need to integrate every new word into the structure. 

These integration/energy costs are twofold. 
\begin{enumerate}
    \item For every new referential word, a new referent must be introduced in the discourse representation. As a simplification, \citeauthor{Gibson.2000} assumes a cost of one unit of energy for each new discourse referent. Pronouns are either anaphoric or deictic and do not introduce any new referent. 
% Pronoun are easier to process : intuition from Bever 1974
% Bever, T. B. (1974). The ascent of the specious, or there’s alot we don’t know about mirrors. In D Cohen (Ed.),Ex-plaining  linguistic  phenomena(pp.  173–200).  Wash-ington, DC: Hemisphere.
    \item Furthermore, filler-gap dependencies (or any other dependency) also imply additional energy costs for every referent introduced between the filler and the gap. As a simplification again, \citeauthor{Gibson.1998} assumes a cost of one unit of energy for each new discourse referent. 
\end{enumerate}

We can illustrate the DLT with (\ref{ex:contrast-SRC-ORC-DLT}), in which the latter kind of energy costs are indicated below each new referent (memory costs and costs for introducing more referents are the same in both sentences).

\eal \label{ex:contrast-SRC-ORC-DLT}
\ex \gll The reporter [who$_i$~\trace{}$_i$ attacked the senator] admitted the error.\\
{} 0 {} 0 {} 0 0 {} 0 = 0\\  \label{ex:contrast-SRC-DLT}
\ex \gll The reporter [who$_i$ the senator attacked~\trace{}$_i$] admitted the error.\\
{} 0 {} {} 1 1 0 {} 0 = 2\\ \label{ex:contrast-ORC-DLT}
\zl 

The integration costs are higher in the object relative clause than in the subject relative clause, given that the filler-gap dependency adds no cost in the latter but two units of energy in the former.

If we apply DLT to extraction out of the subject vs.\ the object, it is obvious that extraction out of (preverbal) subjects create lower energy costs in English and French: the head of the NP introduces at least one new referent for both, but in extraction out of the object, the verb and the subject intervene between the filler and the gap and introduce new referent(s) (if the subject is not pronominal).


\subsection{Dependency Grammar}

Dependency Grammar (DG) represents syntactic dependencies by means of a dependency graph like (\ref{ex:dependency-graph}).

\ea \label{ex:dependency-graph}
\attop{%
\begin{forest}
[[The, no edge, name = the1] 
[reporter, no edge, name = reporter] 
[attacked, no edge, name = attacked] 
[the, no edge, name = the2] 
[senator., no edge, name = senator]]
\draw[->] ([xshift= 0pt]attacked.north) .. controls +(up:6mm)  and +(up:6mm)  .. node[above] {subj} ([xshift= 3pt]reporter.north);
\draw[->] ([xshift= 0pt]attacked.north) .. controls +(up:15mm)  and +(up:15mm)  .. node[above] {obj} ([xshift= 3pt]senator.north);
\draw[->] ([xshift= -3pt]reporter.north) .. controls +(up:6mm)  and +(up:6mm)  .. node[above] {atr} ([xshift= 0pt]the1.north);
\draw[->] ([xshift= -3pt]senator.north) .. controls +(up:6mm)  and +(up:6mm)  .. node[above] {atr} ([xshift= 0pt]the2.north);
\end{forest}}
\z 

A central concept in DG is projectivity. The sentence in (\ref{ex:dependency-graph}) contains only projective dependencies, because the dependency arrows never cross. Many non-local dependencies lead to non-projective structures. Projectivity is considered in DG to be one of the factors determining word order: The language tries to avoid non-projectivity whenever possible (see \citealt[Section~7.4.2]{Hudson.2010}; \citealt[Section~7.3]{Osborne.2019}). Non-local dependencies can override this requirement because extraction (``displacement'' in DG) is pragmatically highly motivated \citep[Section~7.6.7]{Hudson.2010}. But short-distance dependencies do not necessarily lead to non-projectivity. Interestingly, subextraction from the subject mostly results in projective structures, as noticed by \citet[Section~4.3]{Candito.2012.ldd}. An example can be seen in (\ref{ex:subextraction-dg}).\footnote{For the dependency graphs, I adopt the rules of Universal Dependency Grammar, widely used for annotating corpora in DG: nouns are heads of NPs and select their determiner; nouns are heads of PPs and select their preposition. Some scholars, however, prefer treating the determiner as the head of DPs, and/or the preposition as the head of PP. This alternative analysis would have no impact on projectivity in my examples.}

\ea \label{ex:subextraction-dg}
\attop{\oneline{
\begin{forest}
[[the, no edge, name = the1] 
[newspaper, no edge, name = newspaper] 
[of, no edge, name = of]
[which, no edge, name = whom]
[the, no edge, name = the3]
[reporter, no edge, name = reporter]
[attacked, no edge, name = attacked] 
[the, no edge, name = the2] 
[senator, no edge, name = senator]]
\draw[->] ([xshift= -3pt]attacked.north) .. controls +(up:6mm)  and +(up:6mm)  .. ([xshift= 3pt]reporter.north);
\draw[->] ([xshift= 3pt]attacked.north) .. controls +(up:9mm)  and +(up:9mm)  ..  ([xshift= 3pt]senator.north);
\draw[->] ([xshift= -3pt]reporter.north) .. controls +(up:6mm)  and +(up:6mm)  ..  ([xshift= 0pt]the3.north);
\draw[->] ([xshift= -3pt]senator.north) .. controls +(up:6mm)  and +(up:6mm)  ..  ([xshift= 0pt]the2.north);
\draw[->] ([xshift= -0pt]reporter.north) .. controls +(up:9mm)  and +(up:9mm)  .. ([xshift= 3pt]whom.north);
\draw[->] ([xshift= -3pt]whom.north) .. controls +(up:6mm)  and +(up:6mm)  .. ([xshift= 0pt]of.north);
\draw[->] ([xshift= 3pt]newspaper.north) .. controls +(up:12mm)  and +(up:12mm)  .. ([xshift= 0pt]attacked.north);
\draw[->] ([xshift= -3pt]newspaper.north) .. controls +(up:6mm)  and +(up:6mm)  .. ([xshift= 0pt]the1.north);
\end{forest}}}
\z 

Additionally, word order is constrained by Dependency Distance. For reasons similar to the ones mentioned for the DLT, Dependency Distance should be reduced whenever possible. \citet{Liu.H.2009} propose a method to measure Mean Dependency Distance (MDD) by adding up the number of words that every dependency arrow has to cross from the beginning to the end of the dependency \citep[see also][]{Liu.H.2008}. The shortest Dependency Distance is one, except for the main verb of the matrix clause, which is not selected and therefore has a Dependency Distance of zero. In (\ref{ex:src-orc-dg}), from \citet[167]{Liu.H.2008}, we can see how the asymmetry in (\ref{ex:contrast-SRC-ORC}) is accounted for in DG. The Dependency Distance of each dependency is indicated under the dependency arrow-head. The subject relative (\ref{ex:src-dg}) has an MDD of 1.875, and is for this reason preferred over the object relative (\ref{ex:orc-dg}), which has an MDD of 2.25.

\eal \label{ex:src-orc-dg}
\ex MDD {=} 15/8 {=} 1.875\label{ex:src-dg} \nopagebreak
\oneline{
\begin{forest}
[[The\\1, no edge, name = the1] 
[reporter\\5, no edge, name = reporter] 
[who\\1, no edge, name = who]
[attacked\\2, no edge, name = attacked] 
[the\\1, no edge, name = the2]
[senator\\2, no edge, name = senator] 
[admitted\\0, no edge, name = admitted]
[the\\1, no edge, name = the3]
[error.\\2, no edge, name = error]
]
\draw[->] ([xshift= -3pt]reporter.north) .. controls +(up:6mm)  and +(up:6mm)  .. ([xshift= 0pt]the1.north);
\draw[->] ([xshift= -3pt]admitted.north) .. controls +(up:15mm)  and +(up:15mm)  .. ([xshift= 0pt]reporter.north);
\draw[->] ([xshift= -3pt]attacked.north) .. controls +(up:6mm)  and +(up:6mm)  .. ([xshift= 0pt]who.north);
\draw[->] ([xshift= -3pt]senator.north) .. controls +(up:6mm)  and +(up:6mm)  .. ([xshift= 0pt]the2.north);
\draw[->] ([xshift= 3pt]attacked.north) .. controls +(up:9mm)  and +(up:9mm)  .. ([xshift= 3pt]senator.north);
\draw[->] ([xshift= 3pt]reporter.north) .. controls +(up:9mm)  and +(up:9mm)  .. ([xshift= 0pt]attacked.north);
\draw[->] ([xshift= -3pt]error.north) .. controls +(up:6mm)  and +(up:6mm)  .. ([xshift= 0pt]the3.north);
\draw[->] ([xshift= 3pt]admitted.north) .. controls +(up:9mm)  and +(up:9mm)  .. ([xshift= 3pt]error.north);
\end{forest}}
\ex MDD {=} 18/8 {=} 2.25 \label{ex:orc-dg}
\oneline{
\begin{forest}
[[The\\1, no edge, name = the1] 
[reporter\\5, no edge, name = reporter] 
[who\\3, no edge, name = who]
[the\\1, no edge, name = the2] 
[senator\\1, no edge, name = senator]
[attacked\\4, no edge, name = attacked] 
[admitted\\0, no edge, name = admitted]
[the\\1, no edge, name = the3]
[error.\\2, no edge, name = error]
]
\draw[->] ([xshift= -3pt]reporter.north) .. controls +(up:6mm)  and +(up:6mm)  .. ([xshift= 0pt]the1.north);
\draw[->] ([xshift= -3pt]admitted.north) .. controls +(up:15mm)  and +(up:15mm)  .. ([xshift= 0pt]reporter.north);
\draw[->] ([xshift= 0pt]attacked.north) .. controls +(up:9mm)  and +(up:9mm)  .. ([xshift= 0pt]who.north);
\draw[->] ([xshift= -3pt]senator.north) .. controls +(up:6mm)  and +(up:6mm)  .. ([xshift= 0pt]the2.north);
\draw[->] ([xshift= -3pt]attacked.north) .. controls +(up:6mm)  and +(up:6mm)  .. ([xshift= 3pt]senator.north);
\draw[->] ([xshift= 3pt]reporter.north) .. controls +(up:12mm)  and +(up:12mm)  .. ([xshift= 3pt]attacked.north);
\draw[->] ([xshift= -3pt]error.north) .. controls +(up:6mm)  and +(up:6mm)  .. ([xshift= 0pt]the3.north);
\draw[->] ([xshift= 3pt]admitted.north) .. controls +(up:9mm)  and +(up:9mm)  .. ([xshift= 3pt]error.north);
\end{forest}}
\zl 

If we apply the same method to measure the MDD of subextraction from subject and object NPs, it gives us the results in (\ref{ex:subextraction-mdd}). The extraction out of the object in (\ref{ex:subextraction-mdd-object}) not only has a higher MDD than the extraction out of the subject in (\ref{ex:subextraction-mdd-subject}), but is also non-projective.\footnote{Notice that in English interrogatives, because of the presence of the auxiliary, extraction similar to (\ref{ex:subextraction-mdd-subject}) would be non-projective, while extraction like (\ref{ex:subextraction-mdd-object}) would be projective. Yet, the extraction out of the object would have a higher MDD, like in relative clauses.}

\eal \label{ex:subextraction-mdd}
\ex MDD = 14/9 = 1.556 \label{ex:subextraction-mdd-subject}
\oneline{
\begin{forest}
[[the\\1, no edge, name = the1] 
[newspaper\\0, no edge, name = newspaper] 
[of\\1, no edge, name = of]
[which\\2, no edge, name = whom]
[the\\1, no edge, name = the3]
[reporter\\1, no edge, name = reporter]
[attacked\\5, no edge, name = attacked] 
[the\\1, no edge, name = the2] 
[senator\\2, no edge, name = senator]]
\draw[->] ([xshift= -3pt]attacked.north) .. controls +(up:6mm)  and +(up:6mm)  .. ([xshift= 3pt]reporter.north);
\draw[->] ([xshift= 3pt]attacked.north) .. controls +(up:9mm)  and +(up:9mm)  ..  ([xshift= 3pt]senator.north);
\draw[->] ([xshift= -3pt]reporter.north) .. controls +(up:6mm)  and +(up:6mm)  ..  ([xshift= 0pt]the3.north);
\draw[->] ([xshift= -3pt]senator.north) .. controls +(up:6mm)  and +(up:6mm)  ..  ([xshift= 0pt]the2.north);
\draw[->] ([xshift= -0pt]reporter.north) .. controls +(up:9mm)  and +(up:9mm)  .. ([xshift= 3pt]whom.north);
\draw[->] ([xshift= -3pt]whom.north) .. controls +(up:6mm)  and +(up:6mm)  .. ([xshift= 0pt]of.north);
\draw[->] ([xshift= 3pt]newspaper.north) .. controls +(up:12mm)  and +(up:12mm)  .. ([xshift= 0pt]attacked.north);
\draw[->] ([xshift= -3pt]newspaper.north) .. controls +(up:6mm)  and +(up:6mm)  .. ([xshift= 0pt]the1.north);
\end{forest}}
\ex MDD = 17/9 = 1.889 \label{ex:subextraction-mdd-object}
\oneline{
\begin{forest}
[[the\\1, no edge, name = the1] 
[newspaper\\0, no edge, name = newspaper] 
[of\\1, no edge, name = of]
[which\\5, no edge, name = whom]
[the\\1, no edge, name = the3]
[senator\\1, no edge, name = senator]
[attacked\\5, no edge, name = attacked] 
[the\\1, no edge, name = the2] 
[reporter\\2, no edge, name = reporter]]
\draw[->] ([xshift= 3pt]attacked.north) .. controls +(up:9mm)  and +(up:9mm)  .. ([xshift= 0pt]reporter.north);
\draw[->] ([xshift= -3pt]attacked.north) .. controls +(up:6mm)  and +(up:6mm)  ..  ([xshift= 3pt]senator.north);
\draw[->] ([xshift= -3pt]reporter.north) .. controls +(up:6mm)  and +(up:6mm)  ..  ([xshift= 0pt]the2.north);
\draw[->] ([xshift= -3pt]senator.north) .. controls +(up:6mm)  and +(up:6mm)  ..  ([xshift= 0pt]the3.north);
\draw[->] ([xshift= 3pt]reporter.north) .. controls +(up:15mm)  and +(up:15mm)  .. ([xshift= 3pt]whom.north);
\draw[->] ([xshift= -3pt]whom.north) .. controls +(up:6mm)  and +(up:6mm)  .. ([xshift= 0pt]of.north);
\draw[->] ([xshift= 3pt]newspaper.north) .. controls +(up:12mm)  and +(up:12mm)  .. ([xshift= 0pt]attacked.north);
\draw[->] ([xshift= -3pt]newspaper.north) .. controls +(up:6mm)  and +(up:6mm)  .. ([xshift= 0pt]the1.north);
\end{forest}}
\zl 

Hence, based on Dependency Distance, extraction out of the subject should be easier to process than extraction out of the object. This is not to say that extraction out of the subject is usually analyzed this way in DG. \citet[58--59]{Broeker.1999}, \citet[186]{Hudson.2010} and \citet[Chapter~9]{Osborne.2019} treat islands in a relatively traditional manner as blocking some kinds of dependencies. \citeauthor{Broeker.1999} addresses extraction out of infinitival subjects and sees it as a constraint on dependencies over dependencies. \citet[Section~9.7]{Osborne.2019} describes sentential and NP subject islands, and proposes that ``rising catenae reluctantly include a normal dependency that bears the subject grammatical function'' \citep[286]{Osborne.2019}. He notices, however, that acceptability judgments on such structures are ``not always clear'' \citep[285]{Osborne.2019}. Consequently, we can see that DG's approach to subject island does not much differ from the traditional syntactic accounts, but projectivity and Dependency Distance make interesting predictions nonetheless. 

\section{Processing accounts based on surprisal}

\subsection{Processing difficulty of subjects}
\label{ch:processing-kluender}

In this section, I summarize the analysis proposed by \citet{Kluender.2004}, which, to my knowledge, is the most articulated argumentation around the idea that superadditivity effects in extraction out of subjects arise from the fact that subjects (and especially complex subjects) are hard to process. 

\subsubsection{Processing difficulty for subjects} 

There is strong evidence that non-finite clauses are easier to process than finite ones. \citet[27]{Ross.1967} already noticed that extractions out of an embedded question (so-called ``\textit{wh}-islands'') are more felicitous if this embedded question is non-finite, and therefore has no overt subject. 

\begin{exe}\judgewidth{??}
\ex \citep[27]{Ross.1967}
\begin{xlist}
\ex[]{He told me about a book which I can't figure out how to read.}
\ex[??]{He told me about a book which I can't figure when I should read.}
\label{ex:surprisal-ross-whislands}
\end{xlist}
\end{exe}

\citet[106]{Kluender.2004} also points out that extraction out of relative clauses, albeit always very degraded, is still easier to process when the relative clause is non-finite.

\pagebreak
\begin{exe}
\judgewidth{??}
\ex \citep[106]{Kluender.2004}
\begin{xlist}
\ex[?]{That's the campaign that I finally thought of someone to spearhead.}
\ex[??]{That's the campaign that I finally thought of someone who could spearhead.}
\label{ex:surprisal-kluender-rcislands}
\end{xlist}
\end{exe}

\citet[110]{Kluender.2004} explains the contrasts in acceptability illustrated by (\ref{ex:surprisal-ross-whislands}) and (\ref{ex:surprisal-kluender-rcislands}) by hypothesizing that overt subjects have a ``greater discourse referential processing cost'' than covert ones. Obviously, this is based on the assumption that subjects in non-finite clauses are covert. But if one posits that there are no subjects in non-finite clauses, the DLT predicts the contrast between extraction out of finite and non-finite clauses: one referent less (the subject) reduces the integration costs. This is not related to the syntactic function of the subject. Furthermore, in DLT, only finite verbs introduce a new referent in discourse (because only tensed verbs have a spatiotemporal location, \citealt[103]{Gibson.2000}). The DLT can therefore explain why extraction out of non-finite relative clauses is easier to process. 

Further evidence comes from a study by \citet{Clark.1998}, also mentioned by \citet[114]{Kluender.2004}. 
% En fait Kluender dit qu'ils montrent qu'il y a plus de reprises en début de phrase. Je ne suis pas sûre que ce soit ce qu'ils disent (j'ai juste parcouru l'article mais n'ai rien vu). Peut-êter qu'il parle des topicalisations (voir partie sur discours dans leur article).
\citet{Clark.1998} conducted a study on two corpora of spontaneous oral speech in English, the Switchboard corpus \citep{Godfrey.1992} and the London-Lund corpus \citep{Svartvik.1980}, and looked at a certain form of disfluencies: repetitions. Among 353,820 pronouns repeated, 173,348 (49\%) were nominative pronouns, like in (\ref{ex:repetition-nominal-pronoun}). As a comparison, only 19,927 (5.6\%) were accusative pronouns \citep[215]{Clark.1998}. They also found a ratio of 45 repetitions of the determiner \emph{the} of simple subject NPs against 30 repetitions of \emph{the} in simple object NPs per 1,000 NPs \citep[213]{Clark.1998}. In both cases, they hence observed a higher amount of this kind of disfluencies related to subjects than to direct objects. Unfortunately, they do not seem to consider the relative frequency of subjects and objects (pronouns or nominal): Almost all finite verbs have a subject, whereas only transitive verbs have an object, therefore the ratio cannot be compared directly.

\ea  \citep[220]{Clark.1998}\\
yes, I \{uh\} I wouldn't be surprised at that
\label{ex:repetition-nominal-pronoun}
\z 

\subsubsection{Processing difficulty for complex subjects}

\citet[213]{Clark.1998} do not only observe a higher proportion of repetitions in subjects, but also a higher proportion of repetition for complex NPs. They define complex NPs as NPs that contain material after the head noun. They found a ratio of 65 repetitions of the determiner \emph{the} in complex subject NPs, against 55 repetitions of the same determiner in simple object NPs per 1,000 NPs \citep[213]{Clark.1998}. Thus the impact of complexity seems even a bit stronger than the impact of the grammatical function mentioned above. Notice that the two factors do not appear to be superadditive\footnote{Complexity: there are 30 repetitions in simple NPs and 55 repetitions in complex NPs. Function: there are 30 repetitions in objects and 45 repetitions in subjects. We would hence predict around 82.5 (55*45/30) repetitions for complex subject NPs, and \citeauthor{Clark.1998} find 65 repetitions. The observed results are therefore in the range of simple additive effects.}.

\citet{Kluender.2004} reports several pieces of evidence from various studies and authors that show that the complexity of the subject and the complexity of the rest of the VP are in competition in terms of processing. In spontaneous production, they tend to be in complementary distribution: the longer the subject, the shorter the VP and conversely. This is attested in English for children (corpus studies on early acquisition in \citealt{Bloom.1990,Bloom.1993}), for adults (diachronic corpus study of diaries in \citealt{Kemper.1987}) and for seniors (corpus study in \citealt{Kynette.1986}). It has also been found in Italian for adults \citep[440]{Hyams.1993} and in Japanese for children and adults \citep{Ueno.2009}\footnote{Cited under a different title in \citet{Kluender.2004}.}. The general observations are the following: (a) the longest VPs tend to have clitic subjects, (b) subjects are on average shorter than objects, (c) pro-drop (in pro-drop languages) is more frequent with transitive than intransitive verbs. Some experiments on processing by seniors in \citet{Kemper.1986} (repetition task) and \citet{Norman.1992} (self-paced reading task) corroborate this: complex subjects are skipped in repetition tasks 92\% of the time (only 11\% for complex objects), and are read more slowly as well. Notice that the authors tested a wide variety of complex subjects (e.g.\ NP with a relative clause, sentential subjects). Based on these data, I expect that complex NPs with a PP-complement, which are often cited in the literature on subject islands, are less difficult to process than NPs with a relative clause complement, infinitival subjects or sentential subjects. 

\subsubsection{Processing difficulty for verbal subjects}

Lastly, \citet{Kluender.2004} mentions some processing difficulties inherently related to verbal subjects. Infinitival and sentential subjects are of course difficult to process for the same reason as any complex subject. Furthermore, following \citet[106]{Kluender.2004}, comprehenders quickly forget the syntactic configuration of a clause when they reach its end. This, he claims, is what makes it difficult to process center-embedded sentences. It also explains the difficulty of extraction out of an infinitival or sentential subject like in (\ref{ex:kluender-sentential-subject}). This argument is somewhat similar to some syntactic approaches like Spell-out, but restricted to clauses.

\begin{exe}
\judgewidth{??}
\ex \citep[118]{Kluender.2004}
\label{ex:kluender-sentential-subject}
\begin{xlist}
\ex[*]{Who does [that she can bake ginger cookies for \trace{}] give her great pleasure?}
\label{ex:kluender-sentential-subject-finite}
\ex[??]{Who does [to be able to bake ginger cookies for \trace{}] give her great pleasure?}
\label{ex:kluender-sentential-subject-infinite}
\ex[?]{Who does [being able to bake ginger cookies for \trace{}] give her great pleasure?}
\label{ex:kluender-sentential-subject-gerund}
\end{xlist}
\end{exe}

%This does not explain the ameliorating effects of parasitic gap or the fact that some very simple subjects do not allow for extraction.


\subsection{Valency Completeness}

\citeauthor{Hawkins.1999} proposes the Valency Completeness preference to account for extraction out of nominal, infinitival and sentential subjects:

\ea Valency Completeness:\\
The human processor prefers [Filler-Gap Domains] to include the subcategorizors for all phrases within the domain that contains the gap. \citep[278]{Hawkins.1999}
\z 

The Filler-Gap Domain of the extraction out of the subject in (\ref{ex:fgd-whole-sentence}) is (\ref{ex:fgd-stop}).  When the addressee reaches the gap, the structure (\ref{ex:fgd-stop}) includes the direct subcategorizer of the gap (\emph{disliked}), but not the subcategorizer of the sentential subject (\emph{surprise}). Hence, the addressee cannot know at this point the syntactic role of the clause in which the gap is located. 

\eal \label{ex:fgd}
\ex[*]{Who$_i$ did [that Mary disliked~\trace{}$_i$] surprise Sue?} \label{ex:fgd-whole-sentence}
\ex[]{Who did that Mary disliked ...} \label{ex:fgd-stop}
\zl 

Extraction out of nominal subjects has the same problem. This leads to additional processing difficulty when extracting out of subjects and explains the contrast with extraction out of objects.

The Valency Completeness preference predicts that extraction out of postverbal constituent should be more acceptable. Hence, extraction out of postverbal subjects should be as felicitous as extraction out of objects.

% Il n'y a pas de recours exclusif à surprisal de la part de Kluender il me semble

As a matter of fact, \citeauthor{Kluender.2004}'s and \citeauthor{Hawkins.1999}'s approach are not mutually exclusive. Several factors may have an impact on subextraction from subjects. Since superadditivity effects are caused by an accumulation of several factors, both proposals may bring us closer to understanding the processing of subject islands. We may even go so far as saying that these approaches are compatible with accounts based on dependency-length minimization, even though they make opposite predictions. Several processing preferences may be at play, especially in constructions as complex as filler-gap dependencies \citep[this is actually the view defended by][]{Hawkins.1999}.

\section{Definiteness, referentiality and specificity}
\label{ch:specificity-definiteness}

In this section, I briefly address other semantic factors that have been known to influence extraction phenomena and have been linked to processing. I present the general discussion, and how these factors have been part of the discussion about subject islands.

% probably first to talk about : Diesing 1992
% Diesing, Molly 1992 Indefinites. Cambridge, MA: MIT Press.
% Davies & Dubinsky 2003
% Davies, William & Dubinsky, Stanley 2003 On extraction from NPs. Natural Language & Linguistic Theory 21:1-37.

The contrast between subextraction from an indefinite and from a definite NP has been well known since it was pointed out by \citet{Chomsky.1973} and \citet{Erteschik-Shir.1973}. This phenomenon, illustrated by (\ref{ex:indefinite-np-island}), is sometimes called the definite NP island.

\begin{exe}
\ex \citep{Radford.2009} \label{ex:indefinite-np-island}
\begin{xlist}
\ex[]{Who$_i$ were you reading a book about?}
\ex[*]{Who$_i$ were you reading the/this/that/his book about?}
\end{xlist}
\end{exe}

For \citet{Ariel.1988}, definite descriptions are cognitively less accessible than indefinite ones. The reason is that definite descriptions contain more information, which makes retrieving them more costly. Definite descriptions are stored in long-term memory, while indefinite ones are in short-term memory, ready to be retrieved as soon as necessary. \citet[269]{Kluender.1998} proposes to use this theory to account for the contrast in (\ref{ex:indefinite-np-island}).

Subextraction from subject NPs is by definition impacted by this contrast. Extraction out of definite NP subjects is not necessarily ungrammatical, but extraction out of demonstrative NP subjects is less acceptable \citep{Jimenez-Fernandez.2009}.

\begin{exe}
\ex \citep[117]{Jimenez-Fernandez.2009}
\begin{xlist}
\ex[]{\gll \textquestiondown{}[De qué cantante]$_i$ has dicho que son muy provocativas [varias/las fotos~\trace{}$_i$]?\\
\ssbar{}of which singer have\textsc{.2sg} said that are very provocative \sbar{}several/the photos\\
\glt `Of which singer have you said that several/the photos are very provocative?'}
\ex[*]{\gll \textquestiondown{}[De qué cantante]$_i$ has dicho que son muy provocativas [estas fotos~\trace{}$_i$]?\\
\ssbar{}of which singer have\textsc{.2sg} said that are very provocative \sbar{}these photos\\
\glt `Of which singer have you said that these photos are very provocative?'}
\end{xlist}
\end{exe}

\citet{Simonenko.2015} explains this by the semantic contradiction between the presupposition invoked by the demonstratives (they are deictic or anaphoric, hence their referent is known in the discourse situation) and the presupposition of questions (the \emph{wh}-phrase refers to an unknown individual), \citep[see also][]{Erteschik-Shir.1973}.

The research on islands also tends to emphasize the role played by fillers with high referentiality. The discussion mostly revolves around interrogatives in English. In English, the determiner \emph{which} + N or \emph{what} + N is used to build filler phrases that are more referential than, for example, \emph{what}. The corresponding filler in French is \emph{quel(le)(s)} + N (lit.\ `of which(.\textsc{fem}.\textsc{pl}'). The contrast between these fillers and other less referential ones, illustrated in (\ref{ex:typical-dlinking}), has long been under discussion, especially for extraction out of embedded questions \citep[e.g.][]{Pesetsky.1982,Kluender.1993.Bridging,Kluender.1993.Subjacency,Erteschik-Shir.2006,Jimenez-Fernandez.2009,Chaves.2013}. This phenomenon is often referred to as ``d(iscourse)-linking'' in the literature, a denomination that goes back to \citet{Pesetsky.1982}. 

\begin{exe}
\judgewidth{??}
\ex \citep[318]{Erteschik-Shir.2006}
\label{ex:typical-dlinking}
\begin{xlist}
\ex[?]{[Which book]$_i$ did you wonder [whether John bought~\trace{}$_i$]?}
\ex[??]{What$_i$ did you wonder [whether John bought~\trace{}$_i$]?}
\end{xlist}
\end{exe}

Many introspective and experimental data suggest that these referential fillers improve extraction, regardless of islandhood \citep{Kluender.1993.Bridging,Kluender.1993.Subjacency}. 
% But Tollan & Heller 2016 find the contrary: the observe longer filled-gap effects with specific fillers than with non-specific ones. (pc by Yingtong Liu) 

% Pesetsky, 2000, 16: d-linking

Referential fillers have also been addressed in the discussion on subject islands. Scholars observed that the acceptability of subextraction from subject improves with referential fillers.

\ea \citep[242]{Ross.1967}\\
{} [Of which cars]$_i$ were [the hoods \trace{}$_i$] damaged by the explosion? % must check !
\z 

\citet{Jimenez-Fernandez.2009} proposes a syntactic explanation of the phenomenon, and accommodates \citegen{Chomsky.2008} analysis of subject islands based on phases. \citet{Jimenez-Fernandez.2009} assumes that DPs are by default weak, but may become strong DPs if they are definite and ``non-d-linked''. Strong DPs are then phases, and are therefore islands to extraction.
\citet[313]{Chaves.2013} points out the weaknesses of this analysis, which is not independently motivated and circular. The general impression is that definite NPs with a non-specific element extracted are phases because extraction is prohibited, and as \citeauthor{Chaves.2013} complains ``the causal nexus between movement and D-linking remains obscure''.

\citet{Erteschik-Shir.2006} proposes an explanation at the interface between syntax and information structure. She redefines d-linking as a property of being referential that is inherent for \emph{which} + N fillers, and can be attributed to other \textit{wh}-words by the discourse context (if for example \emph{what}, as in (\ref{ex:double-wh-context}), has identified referents in the Common Ground). 

\ea (\citealt{Pesetsky.1987}, from \citealt{Bolinger.1979})\\
I know that we need to install transistor A, transistor B, and
transistor C, and I know that these three holes are for transistors,
but I'll be damned if I can figure out from the instructions where
what goes! .
\label{ex:double-wh-context}
\z 

In \citegen{Erteschik-Shir.2006} analysis, these d-linked NPs are the topic of the interrogative. Consequently, strictly speaking, there would be no extraction, because the gap is not a trace but a silent anaphoric pronoun. Example (\ref{ex:anaphoric-gap}) illustrates \citeauthor{Erteschik-Shir.2006}'s proposal.

\ea \citep[327]{Erteschik-Shir.2006}\\
{} [Which book$_i$]$_T$ [did you choose $\varnothing{}_i$]$_F$?
\label{ex:anaphoric-gap}
\z 

However, observe example (\ref{ex:where-having-dinner}), in which extraction of the adverb out of the non-finite subject seems completely acceptable:

\ea \citep[72]{Grosu.1981}\\
The “Hunan” restaurant is a place [where$_i$ [having dinner \trace{}$_i$] promises to be most enjoyable].
\label{ex:where-having-dinner}
\z 

The filler in (\ref{ex:where-having-dinner}) is neither d-linked nor referential, but we know that it refers to a location as soon as we encounter it. The filler \emph{where} is more specific than an imprecise filler like \emph{what}. First, it is harder to have a mental representation of the referent of \emph{what}, which could be anything. Second, \emph{where} is compatible with fewer potential semantic roles, and this helps the active gap search to postulate the adequate gap, which reduces filled-gap effects. This all contributes to making the processing of (\ref{ex:where-having-dinner}) easier.


The same is true for questions with \emph{which} + N. In (\ref{ex:typical-dlinking}), \emph{which book} is semantically more informative than \emph{what} \citep{Hofmeister.2013,Chaves.2013}.


%NB: some effect on island of restrictive vs. attributive relative clause?
