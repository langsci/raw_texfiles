\chapter{Backchannels and filled pauses} \label{backchannels}

\section{Introduction}\label{sec:BCFP_introduction}

This part of the book is dedicated to a comparative analysis of backchannels (BC; listener signals such as \emph{mmhm} or \emph{okay}) and filled pauses (FP; hesitation signals such as \emph{uhm}) by speakers with and without a diagnosis of autism spectrum disorder.

Backchannels are a ubiquitous and essential feature of spoken interaction. They are used predominantly by listeners to support the ongoing turn of the interlocutor and to signal understanding and agreement (see references in \sectref{BCFP_BC_background}). Previous research has shown that listeners are highly sensitive to the exact realisations of backchannels and that they judge deviations from typical forms (by e.g.~non-native speakers) as negative \citep[e.g.][]{liBackchannelResponsesMisleading2006}. Previous research on backchannelling in ASD is limited to two studies.

It was found that in the corpus of Map Task dialogues under investigation, the backchannel productions of autistic speakers were characterised by 1) a lower rate of BCs per minute (particularly in the early stages of dialogue), 2) less diversity in the use of different BC types and 3) a lower degree of flexibility and diversity in the mapping of different intonation contours to different BC types. These results can be interpreted as reflecting more general characteristics of autistic people engaged in communicative social interaction, namely differences in how and to what extent interest and attention are expressed towards an interlocutor as well as a tendency for more stable (or less flexible) patterns of behaviour.

Filled pauses are another kind of discourse marker which is extremely common in spontaneous speech (see references in \sectref{BCFP_FP_background}). In contrast to backchannels, filled pauses are used by speakers to hold (or take) the floor (instead of giving up their own as of yet incomplete turn) and to signal hesitancy and inchoateness. Previous research on filled pauses in ASD is fairly limited and has yielded somewhat mixed results.

No differences between groups were found regarding the rate of filled pauses produced, nor the preference of one filled pause type (\emph{uhm}) over the other (\emph{uh}). In contrast, group differences were found for intonational realisation, with autistic speakers producing fewer FPs with the ``default'' level intonation contour and using a higher proportion of both falls and rises instead.
Based on these results, claims from previous studies on the use of filled pauses in ASD are critically evaluated regarding the listener-oriented nature of filled pauses in general and of \emph{uhm} in particular. \

Finally, a number of related phenomena were examined, showing that 1) ASD dyads produced more long silent pauses, 2) there were longer silent intervals following \emph{uhm} than following \emph{uh} (independent of FP duration) in both groups and 3) CTR dyads produced more laughter per minute than ASD dyads.

Importantly, for all measures described in the rest of the chapter (and in the book as a whole), group differences were indicative of robust trends across speakers and dyads, but in all cases at least some autistic speakers and dyads behaved within the range of the CTR group. In other words, there was considerable overlap between the ASD and the CTR group.

In the following, I will first summarise the data and methods used and then turn to detailed analyses of backchannels and filled pauses. After a discussion of silent pauses and laughter, I will finally summarise and interpret the most important findings, point out limitations of the present study and suggest promising avenues for future investigations.

The backchannel analysis (\sectref{sec:BCFP_BC}) has previously been reported in \citet{wehrleBackchannelsConversationsAutistic2023}, the filled pause analysis (\sectref{sec:BCFP_FP}) in \citet{wehrleFilledPausesProduced2023} and the silent pause analysis (\sectref{sec:BCFP_FP_silent}) in \citet{wehrleCharacteristicsDistributionSilent2023}.





\section{Data and analysis}\label{sec:BCFP_data}

The analysis is based on the same corpus of semi-structured Map Task dialogues referred to throughout the book (see \chapref{sec:data}), that is, on approximately 5 hours of speech produced by 28 native German adults, half of which had been diagnosed with autism spectrum disorder.

In total, 2371 backchannel tokens and 1027 filled pause tokens were extracted.

Backchannels were coded according to strict criteria, following the \textsc{Acknowledgement} move in \citet{carlettaReliabilityDialogueStructure1997}, but excluding repetitions. Thereby, all utterances signalling that a speaker had heard and understood their interlocutor were initially included. Importantly, all of the following were then excluded: 1) turn-initial backchannels (where a backchannel directly precedes a more substantial utterance by the same speaker, e.g.~``Okay, and what's next?''), 2) answers to polar questions (such as ``Do you see this?'') and 3) answers to tag questions (such as ``Near the corner, right?''). The remaining utterances were, therefore, backchannels in a strict sense, as they were not part of a larger unit and were not explicitly invited by the interlocutor (e.g. through a question). Note that this operationalisation of backchannels differs markedly from looser categorisations such as the \textit{VSU} (very short utterance) category used in e.g. \citet{heldnerVeryShortUtterances2011,sbrannaUseBackchannelsOther2023}; see \citet{fujimotoListenerResponsesInteraction2009} for a discussion regarding issues of terminology in previous work on backchannels. 

Filled pauses were defined as all hesitations roughly of the form `äh' or `ähm' in German. All tokens including a final nasal were included in the \emph{uhm} category and all tokens without a nasal were included in the \emph{uh} category (the written form \textless uh(m)\textgreater{} is used rather than \textless äh(m)\textgreater{} in order to remain consistent with the terminology used in most previous research). Tokens with slightly different vowel qualities which were clearly identical in function and comparable in form were included. Additionally, a very small number of tokens that were realised with only a nasal (/m/) were included in the \emph{uhm} category, since in practice it was very difficult to determine a threshold for distinguishing realisations with short, reduced vowels (which can also be nasalised) followed by a nasal from those consisting of nothing but a nasal.

 All annotation and coding were performed by the first author as well as a previously trained student assistant. In the very rare cases of ambiguity or disagreement regarding the coding of an utterance, both annotators discussed the issue and arrived at a unanimous solution.

For prosodic analysis of both backchannels and filled pauses, all tokens were first hand-corrected and smoothed using \textit{Praat} \citep{boersmaPRAATDoingPhonetics2021} and \emph{mausmooth} \citep{cangemiMausmooth2015a} (cf.~the analysis of intonation styles in \sectref {int_analysis_processing}). Then, a custom \textit{Praat} script was used to extract pitch values at 10\% and 90\% of token duration and the difference between those values in semitones (with a reference value of 1 Hz) was calculated, with positive values indicating pitch rises and negative values indicating falls \citep[cf.][]{haSpeechProsodyPossible2016,sbrannaBackchannellingLanguagesRate2022}. Values at 10\% and 90\% of token duration (rather than the very first and last values) were used in order to minimise possible effects of microprosody and glottalisation that are known to occur at the extreme edges of syllables. If there was no pitch information available at either one of these time points (usually because there were unvoiced segments at the edges or because non-modal voice quality was used), the point of extraction was moved by 10\%, yielding e.g.~20\%--90\% or 10\%--80\% windows. This procedure was repeated up to a maximum of 40\% at the beginning and 70\% at the end. The majority of pitch values, however, were extracted within 20\% of start duration and 80\% of end duration (\textgreater80\% of tokens for BCs and 65\% for FPs). Finally, all extracted values were verified through a comparison with the original extracted BC token and the smoothed pitch contour and any tokens that were unsuitable for intonational analysis were excluded. This was typically the case for tokens with a very short vocalic portion and/or those produced with creaky voice.


In the sections that follow, I will present background and results first for backchannels (\sectref{sec:BCFP_BC}) and then for filled pauses (\sectref{sec:BCFP_FP}).








\section{Backchannels}\label{sec:BCFP_BC}

In this section, I will present a brief overview of research on backchannels, before turning to an in-depth description of experimental results on dialogues between German dyads with and without a diagnosis of ASD. 

\subsection{Background}\label{BCFP_BC_background}

Backchannels (BCs) are short utterances such as \emph{yeah} or \emph{mmhm} whose primary function is to signal a combination of a listener’s 1) understanding of, 2) attention to and 3) agreement with the interlocutor’s speech. Although there is generally neither a conscious awareness of nor a formal set of rules for backchannelling, it is nevertheless a ubiquitous and essential feature of spoken communication. Backchannels have been a focus of linguistic research at least since the inception of conversation analysis in the 1970s \citep{clarkContributingDiscourse1989, ehlichInterjektionen1986, jeffersonNotesSystematicDeployment1984, schegloffDiscourseInteractionalAchievement1982, whiteBackchannelsCulturesStudy1989,fries1952structure,birdwhistell1962critical,yngveGettingWordEdgewise1970,kendonFunctionsGazedirectionSocial1967}.\footnote{Please note that, as mentioned elsewhere, I only focus on spoken language here, leaving aside related visual feedback signals such as eye gaze, nods and gestures, for the simple reason that conducting and analysing video recordings was note feasible at the time of data collection (see \sectref{BCFP_Discussion_limitations}).}

The highly influential work of \citet{wardProsodicFeaturesWhich2000} has highlighted the complexities of the precise prosodic, temporal and lexical realisation of backchannels and backchan\-nel-inviting cues in English and Japanese \citep[see also e.g.][]{wardIssuesTranscriptionEnglish2000,wardProsodicPatternsEnglish2019,wardLearningShowYou2007}. Previous work has also shown that the rate of BCs produced and, more importantly, their specific lexical and intonational realisation, can have a profound influence on (perceived) communicative success and mutual understanding, as well as on subjective judgements by conversational partners. This has been explored both in the interactions of humans with virtual agents in spoken dialogue systems \citep{fujieConversationRobotBackchannel2004a,wardChallengesBuildingHighlyinteractive2016,wardResponsiveDialogSystem1999} and in natural conversations, usually in cross-cultural or comparative settings \citep[e.g.][]{cutroneCaseStudyExamining2005,cutroneCrossculturalExaminationBackchannel2014,dingemanseTextTalkHarnessing2022,liBackchannelResponsesMisleading2006,tottieConversationalStyleBritish1991,xudongUseListenerResponses2008,youngIdentifyingUnitsInteraction2004}.

Various studies have shown that listeners are highly sensitive to the frequency and temporal placement of backchannel tokens, suggesting that unusual realisations are likely to lead to misunderstandings and negative judgements. For instance, \citet{fujieConversationRobotBackchannel2004a} report that both the lexical content and, in particular, the timing of backchannel feedback influenced the ratings of users interacting with a robotic dialogue system. \citet{cutroneCaseStudyExamining2005,cutroneCrossculturalExaminationBackchannel2014} investigated BC productions in dyadic interactions between Japanese EFL (English as a foreign language) and British speakers and concluded that between-group differences in rate, type and timing negatively affected intercultural communication. Similarly, \citet{liBackchannelResponsesMisleading2006} found differences in the rate of BCs produced in Mandarin Chinese compared to Canadian English dialogues and, further comparing cross-cultural interactions, reports that backchannelling can be a cause for miscommunication.

Further work has analysed the prosodic realisation of backchannels in various languages in detail \citep{benusProsodyBackchannelsAmerican2007,caspersMelodicCharacteristicsBackchannels2000,savinoIntonationalStrategiesBackchanneling2010,stocksmeierSynthesisProsodicAttitudinal2007}. The general consensus is that BCs are typically rising in Germanic and Romance languages \citep[but more often falling in, e.g., Japanese or Vietnamese; see][]{haProsodyVietnameseIntonational2012,haModellingInteractionIntonation2010}, although there are increasing hints that there is a complex interaction of this presumed ``default" intonation contour with pragmatic functions and choice of lexical type \citep[see the results in this section and subsequent related work in][]{sbrannaBackchannellingLanguagesRate2022}. In a small number of pilot studies, the influence of the exact prosodic realisation of backchannels on listeners’ judgements and character attributions has been explored \citep{haSpeechProsodyPossible2016,wehrleExploringDynamicsBackchannel2018,wehrleFunctionProsodicForm2019}. \citet{wehrleFunctionProsodicForm2019} compared the intonation of BCs in German and observed that Vietnamese learners of German produced twice as many non-lexical BCs (\emph{mmhm}) with a flat intonation contour as German natives. As discussed in \citet{haSpeechProsodyPossible2016} and supported by results from a mouse-tracking experiment presented in \citet{wehrleExploringDynamicsBackchannel2018}, a flat BC contour in German might be interpreted to signal a lack of attention or interest \citep[see also][]{stocksmeierSynthesisProsodicAttitudinal2007}. These studies confirm the acute sensitivity of listeners to even small differences in the acoustic realisation of backchannel tokens.

Despite this variety of previous research, to the best of my knowledge, only two studies have touched on the topic of backchannelling in autism. The first of these studies qualitatively investigated the use of the Japanese conversational token `ne' in highly structured interactions (in conjunction with a neuroimaging study). The authors report that `ne' as a backchannel was not used at all by the autistic children in the sample, whereas it was used frequently by non-autistic children \citep{yoshimuraTurntakingChildrenAutism2020}. The second study analysed the use of BCs (and mutual gaze) in story-telling-based interactions and found a lower rate in autistic and mixed as compared with non-autistic dyads of adults \citep{rifaiInvestigatingMarkersRapport2022}.

Although this lack of previous studies is not entirely surprising given that research on naturalistic conversations in ASD is still rare, there is a great theoretical and practical interest in further examining backchannelling in autistic populations in particular. Backchannels are implicit, other-oriented vocal signals with a predominantly social function. Given the characteristic patterns of social communication in ASD, it seems highly likely 1) that speakers with ASD might be less inclined to perform backchannelling at the same rate as non-autistic speakers (in line with previous results) and 2) that BC productions might differ in subtle ways between speakers with and without a diagnosis of ASD.

For the current study, conversations between dyads of German native speakers who either both did or did not have a diagnosis of ASD were compared. The rate of backchannels produced was analysed, taking into account different dialogue stages, as well as their lexical and prosodic realisation. The rate of BCs can indicate how much speakers explicitly supported the ongoing turn of their interlocutor, and the early stages of a social interaction are known to disproportionately influence personality judgements and character attributions \citep[see \sectref{turntaking_conclusion_discussion_gaps};][]{mcaleerHowYouSay2014}. For the analysis of the lexical realisation of backchannels, the aim was to connect the diversity of productions with the assumed general tendency towards restricted behaviour in ASD. Finally, the intonational realisation of BCs was analysed in detail, as a broad range of previous work suggests not only that prosody plays a special and potentially distinctive role in ASD \citep[see \chapref{intonationstyle} and e.g.][]{krugerProsodicDecodingEncoding2018,griceLinguisticProsodyAutism2023,mccannProsodyAutismSpectrum2003a,paulPerceptionProductionProsody2005}, but also that intonation may be of particular relevance in the production and perception of BCs (as pointed out above).

\subsection{Results}\label{BCFP_BC_results}

In this section, I will present results first on the rate of backchannels, then on the lexical types of backchannel used and finally on their prosodic realisation. The duration of individual backchannel tokens was very consistent and practically identical across groups, with a grand mean of 375 ms (SD = 161), and will therefore not be considered in any more detail in the following.

\subsubsection{Rate of backchannels}\label{BCFP_BC_results_BCRate}


Overall, speakers in the ASD group produced fewer backchannels per minute of dialogue, with an average of 6.9 BCs per minute compared to the CTR group with an average of 9.2 BCs per minute. Bayesian modelling strongly suggests that this is a robust difference between groups (see below).

Analysis at the dyad-level confirms the impression from the group-level analysis. The four lowest mean values of backchannels per minute were produced by autistic dyads (the lowest rate being 3 BCs per minute), while three out of the four highest mean values were produced by non-autistic dyads (including the highest rate, 12.3 BCs per minute); see Figure \ref{fig:BCRateDyad}. Please note that, once more, these data do not suggest a clear dividing line between the behaviour of autistic and non-autistic dyads. They instead reveal a considerable degree of overlap between groups. For instance, although the ASD group as a whole clearly produced fewer backchannels per minute, the dyad with the second-highest overall rate was part of the ASD group.

Data were considered only at the level of the dyad, not the level of the individual, for this analysis, as the rate of backchannelling fundamentally depends on the behaviour of the interlocutor and their production of silences and backchan\-nel-inviting cues, among other factors \citep[and because interlocutors should not be treated as independent by default due to factors such as accommodation to the conversational partner; see e.g. results in \sectref{BCFP_FP_results_rate} and][]{winterIndependenceGeneralizabilityLinguistics2021}.



\begin{figure}

{\includegraphics[width=1\linewidth]{figures/graphics-BCRateDyad-1}
	
}

\caption{Rate of backchannels produced per minute of dialogue by dyad. ASD group in blue, CTR group in green.}\label{fig:BCRateDyad}
\end{figure}

The group difference in the rate of BCs per minute of dialogue was not dependent on different overall amounts of speech produced: as has already been established (\sectref{turntaking_results_signal_signal}), extremely similar proportions of silence, single-speaker speech and overlapping speech were produced by both groups. A related way of corroborating this finding is to calculate the rate of BCs not per minute of dialogue but per minute of speech produced within a dialogue (i.e. excluding all stretches of silence). This analysis yields an almost identical finding to the above, with a lower rate for the ASD (9.1) compared with the CTR group (11.8). In other words, the CTR group produced about 1.3 times more backchannels than the ASD group, regardless of whether the rate of BCs per minute of dialogue or per minute of speech is considered.

\subsubsubsection*{Bayesian modelling}\label{BCFP_BC_results_BCRate_Bayes}

A Bayesian model was fitted to the rate of backchannels per minute using negative binomial regression. Negative binomial regression is a more robust extension of Poisson regression. The Poisson distribution is the canonical distribution for characterising count data \citep{winterPoissonRegressionLinguists2021a}. Both negative binomial regression and Poisson regression were tested and the negative binomial model was found to perform better. Negative binomial regression is also usually the more conservative choice and thereby reduces the chance of Type I errors \citep{winterPoissonRegressionLinguists2021a}.

The input for the model was a data frame with one row per dyad containing columns to specify the overall count of backchannels and the duration of the respective dialogue. Total number of backchannels was used as the dependent variable, with group as the independent variable and dialogue duration as the offset (or exposure variable).

Bayesian modelling supports the observation that there was a difference between groups of autistic and non-autistic dyads. Model estimates show a lower rate of BCs per minute for ASD dyads (\(\hat{\beta}\) = 7.39, CI = {[}5.72, 9.57{]}) than for CTR dyads (\(\hat{\beta}\) = 9.64, CI = {[}7.47, 12.45{]}).

The group difference in the model is reported with the ASD group as the reference level. Mean \(\delta\) = 2.25, indicating a higher rate of BCs in the CTR group. The 95\% CI {[}-0.22, 4.88{]} includes zero by a small margin and the posterior probability \(P(\delta > 0)\) is 0.94. Although these values reflect a more than negligible degree of uncertainty, the overall tendency towards a higher rate of backchannels in non-autistic speakers is very strong. At the very least, we can conclude that, based on the model, the data and prior beliefs, it is far more probable that the difference between groups is a robust effect.

Regularising weakly informative priors with a normal distribution were specified for the intercept (\(\mu\) = 0, \(\delta\) = 12) and for the regression coefficient (\(\mu\) = 0, \(\delta\) = 3) and used the default priors of the \emph{brms} package for the shape parameter (\(\gamma\) = 0.01).

\subsubsubsection*{Stage of dialogue}\label{BCFP_BC_results_BCRate_Stage}

For the comparison of dialogue stages, resolution of the first Mismatch was used as the cut-off point. Detection of the first Mismatch was not used simply because for many dyads there was not enough backchannel data available prior to detection of the first Mismatch to allow for a reliable comparison (five dyads produced only seven BCs or less prior to detection of the first Mismatch; see also \sectref{materials}, \sectref{turntaking_results_FTO_group_stage} and \sectref{turntaking_results_FTO_stage_corroboration} for definition and analysis of dialogue stages).

At the group level, the pattern of the ASD group producing fewer backchannels is shown to be very robust for the early stages of dialogue, but not for the remainder; see Figure \ref{fig:BCRateStage}. Specifically, in the first few minutes of dialogue, the ASD group produced an average rate of 5.8 backchannels per minute and the CTR group produced an average rate of 9.8 backchannels per minute (\(\delta\) = 4). In the remainder of the dialogue, rates were more similar between groups, with the ASD group producing an average rate of 7.2 backchannels per minute and the CTR group producing an average rate of 8.6 (\(\delta\) = 1.4).



\begin{figure}

{\includegraphics{figures/graphics-BCRateStage-1}
	
}

\caption{Rate of backchannels per minute by dialogue stage (before and after resolution of the first Mismatch). CTR group in green, ASD group in blue.}\label{fig:BCRateStage}
\end{figure}

Bayesian modelling clearly confirms the difference between groups in the early stages of dialogue, but not in the remainder. Differences between groups are presented with the ASD group as the reference level. Before resolution of the first Mismatch, mean \(\delta\) = 3.9, with a 95\% CI of {[}0.9, 7.13{]} and a posterior probability \(P(\delta > 0)\) of 0.98. This reflects a robust difference, with a higher rate of BCs in the CTR group

After resolution of the first Mismatch, mean \(\delta\) = 1.89, with a 95\% CI of {[}-1.01, 4.89{]} and a posterior probability \(P(\delta > 0)\) of 0.87.  This is indicative of the same trend as for the early dialogue stage, but does not signify a robust difference between groups. This model contained dyad as a random factor, which was not included in the model for the dialogue as a whole, as in that case there was only one observation per dyad.

At the dyad level, we can see that a high degree of variability underlies the group-level results, particularly in the ASD group, where by-dyad variability was much greater than in the CTR group; see Figure \ref{fig:BCRateStageDyad}. To compare rates in the beginning and the remainder of the dialogue, ratios were calculated, such that a ratio of two, for instance, represents twice as many backchannels \emph{after} resolution of the first Mismatch.

For all CTR dyads (bottom row in Figure \ref{fig:BCRateStageDyad}), the rate of backchannels was similar throughout the conversation, represented in ratios ranging from 0.78 to 1.19. In this group, two dyads produced almost exactly the same rate throughout (with ratios of 1 and 1.05, respectively), one dyad produced fewer backchannels in the beginning and three dyads produced more backchannels in the beginning (see Table \ref{tab:BCRateRatio} in Appendix \ref{appendix:c} for ratios by dyad).

ASD dyads (top row in Figure \ref{fig:BCRateStageDyad}) lie at the edges of the overall distribution, with all of them producing either higher or lower ratios than any non-autistic dyad. Ratios ranged from 0.64 to 2.78. No dyad produced the same (or nearly the same) rate of backchannels throughout, four dyads produced fewer backchannels in the beginning and three dyads produced more backchannels in the beginning. It is important to note that the group level pattern is thus representative only of the behaviour of a little more than half of all autistic dyads.



\begin{figure}

{\includegraphics[width=1\linewidth]{figures/graphics-BCRateStageDyad-1}
	
}

\caption{Rate of backchannels per minute by dialogue stage (before and after resolution of the first Mismatch) and dyad. The left dot in each panel represents the rate for the beginning of the dialogue, the right dot the rate for the remainder. ASD dyads on top and in blue, CTR dyads on the bottom and in green.}\label{fig:BCRateStageDyad}
\end{figure}

\subsubsubsection*{Speaker roles}\label{BCFP_BC_results_BCRate_Role}

In the analysis of speaker roles, rather than calculating rates of backchannel per minute of dialogue, the relative duration of backchannels in proportion to the duration of all speech produced (excluding silence) was calculated. A comparison based on overall dialogue duration would not be informative as it fails to acknowledge the fact that instruction followers produced far less speech overall than instruction givers.

As backchannels are specifically a signal produced by the listener, it is not surprising that instruction followers produced a much higher proportion of backchannels than givers, in both the ASD group (followers: 11.2\%; givers: 2.1\%) and in the CTR group (followers: 14.5\%; givers: 3.4\%). A by-dyad analysis confirms this pattern while once again highlighting the greater variability in the ASD group.


\subsubsection{Lexical realisation}\label{BCFP_BC_results_BCType}


In this section, the frequency of occurrence for different lexical types of BC is examined. Backchannel tokens were divided into four main categories: \emph{genau} (`exactly'), \emph{ja} (`yes/yeah'), \emph{okay} and finally what I refer to as \textit{non-lexical} backchannels and transcribed \emph{mmhm}. The vast majority of the tokens in the \emph{mmhm} category were produced with two energy peaks, leading to their perception as ‘disyllabic’ and corresponding to the orthographic form of the chosen category label, \(\langle\)mmhm\(\rangle\). Although the remaining tokens only had one clear energy peak each, being closer in realisation to what might be transcribed as \(\langle\)mm\(\rangle\) (or described as monosyllabic), they were subsumed under the same category of \emph{mmhm} as there is no clear and categorical distinction between these two types of phonetic realisation, but rather a continuum, and because the /mmhm/ realisation (with two peaks) was far more frequent overall.

The four main categories (\emph{genau, ja, mmhm, okay}) cover 91.8\% of all backchannel tokens in the data set. All remaining tokens were classified as \emph{other}. The most frequent types of BC in this \emph{other} category were \emph{gut} (`good/fine'), \emph{alles klar} (`alright') and \emph{richtig/korrekt/exakt} (`right/correct/exactly'), in descending order of frequency.

Results at the group level show that choice of backchannel type was very similar between groups overall; see Figure \ref{fig:BCTypeGroupPic}. The most commonly used BC type in both groups was \emph{ja} (`yes/yeah'), with proportions of 47.7\% (ASD; n = 336) and 44\% (CTR; n = 733), respectively. The second most frequent BC type differed between groups. The ASD group showed a stronger preference for \emph{mmhm} (25.6\%; n = 180) than the CTR group (16.5\%; n = 275), but in turn produced fewer \emph{okay} tokens  (11.6\%; n = 82) than the CTR group (20.5\%; n = 341).  The remainder was made up of tokens from the \emph{genau} (ASD: 7.4\% (n = 52); CTR: 10.7\% (n = 178)) and \emph{other} categories (ASD: 7.7\% (n = 54); CTR: 8.4\% (n = 140)).



\begin{figure}

\includegraphics[width=1\linewidth]{images/BC_Types_Group_labelled} \hfill{}

\caption{Stacked bar charts by group showing proportions of different backchannel types. ASD group on top, CTR group below.}\label{fig:BCTypeGroupPic}
\end{figure}

Analysis at the level of the individual reveals some intriguing speaker-specific variation that also has implications for the group comparison, but is hidden when only considering proportions averaged across speakers within a group. The general trends seen in the group analysis are clearly reflected in the behaviour of individual speakers and the choice of backchannel type remained similar across groups. We can observe, however, that half of the ASD speakers used a narrower \emph{range} of BC types and showed clearer preferences for particular BC types over others, compared to CTR speakers. These differences will be described first in absolute terms and then using Shannon entropy as a measure of diversity.

\hspace{-2.4pt}All 14 speakers from the CTR group used all five categories of BCs (see overview plot in Figure \ref{fig:BCTypeSpeaker} in Appendix \ref{appendix:c}). This was not the case for the ASD group, in which only 7 out of 14 speakers used BCs from all five categories, and only 9 speakers used BCs from all four main categories (excluding \emph{other}). Additionally, ASD speakers accounted for six out of the seven clearest individual preferences. For instance, speaker M10A produced 75\% \emph{ja} (n = 75) and two speakers from the same dyad (M04\_M05) both produced 69\% \emph{ja} (M04: n = 40; M05: n = 24). In contrast, most CTR speakers used a fairly even mixture of different BCs. Overall, 11 out of 28 speakers used just one type of BC for 50\% or more of all BC tokens produced, and 8 out of these 11 speakers (72\%) were part of the ASD group.

\subsubsubsection*{Entropy as a measure of backchannel diversity}\label{BCFP_BC_results_BCType_entropy}

While the above pattern of results can be understood quite well through description and visualisation alone, this approach does not provide us with any quantifiable measure of how diverse the production of different backchannel types actually was for individual speakers or by group. (The focus here is on speakers rather than dyads for the sake of clarity, but it was verified that analysis at the dyad level yields equivalent results.) The measure of Shannon entropy can be used as an index of diversity for this purpose \citep{shannonMathematicalTheoryCommunication1948}. The higher the value of entropy (\(H\)), the more diverse the signal.

To give two extreme examples from the data set under investigation, Speaker M13 from the CTR group had the highest entropy value (\(H\) = 2.23); see Figure \ref{fig:BCTypeExamplePic}. Like all non-autistic speakers, M13 produced backchannels from all five categories, and in this specific case, there was no strong preference for any one type. The least frequent category was \emph{mmhm}, with 13.3\% (n = 16), and the most frequent category was \emph{ja}, with 34.3\% (n = 36).  This high degree of diversity or, in other words, less predictable behaviour, is reflected in a higher entropy value.

By contrast, speaker M10A from the ASD group had the lowest entropy value of all speakers (\(H\) = 1.18). Interestingly, this speaker in fact belonged to the 50\% of individuals from the ASD group who \emph{did} use BCs from all five categories. However, tokens were far from evenly spread out among these categories. M10A used \emph{ja} in 75\% of cases (n = 75), followed by \emph{mmhm} with a proportion of 14\% (n = 14), as shown in Figure \ref{fig:BCTypeExamplePic}. Such a clear preference for one type of backchannel corresponds to a lower degree of diversity, or in other words, more predictable behaviour, and is reflected in a lower entropy value.



\begin{figure}

\includegraphics[width=1\linewidth]{images/BC_Types_Example_labelled} \hfill{}

\caption{Stacked bar charts showing proportions of different backchannel types for the two speakers with the highest entropy value (M13, CTR group; \(H\) = 2.23) and the lowest entropy value (M10A, ASD group; \(H\) = 1.18), respectively.}\label{fig:BCTypeExamplePic}
\end{figure}




Entropy values for all 28 speakers are shown in Figure \ref{fig:BCTypeEntropy}, revealing a clear pattern of higher entropy values for non-autistic speakers overall. Note that while in this case there is a fairly clear separation between groups, there is still overlap between them. For instance, several autistic speakers have very high values of entropy and one non-autistic speaker has the second lowest entropy value overall.



\begin{figure}

{\includegraphics[width = 1\linewidth]{figures/graphics-BCTypeEntropy-1}
	
}

\caption{Entropy as a measure of the diversity of lexical types of backchannel produced, by speaker. ASD group in blue, CTR group in green.}\label{fig:BCTypeEntropy}
\end{figure}

Bayesian modelling confirms that backchannels were more diverse in the CTR group. A Bayesian model was fitted to entropy values by speaker using a log-normal distribution. Model output shows that the difference between groups is robust, in showing a lower estimated entropy value for the ASD group (\(\hat{\beta}\) = 1.68, CI = {[}1.53, 1.81{]}) than for the CTR group (\(\hat{\beta}\) = 1.88, CI = {[}1.73, 2.04{]}).

The group difference in the model is reported with the ASD group as the reference level. Mean \(\delta\) = 0.21, indicating higher entropy in the CTR group. The 95\% CI {[}0.05, 0.38{]} does not include zero and the posterior probability \(P(\delta > 0)\) is 0.99. The lower end of the 95\% credible interval is relatively close to 0, but because values are generally low (the maximum possible entropy value would be 2.32) and and the posterior probability is very high, this can be considered as compelling evidence for the observation that CTR speakers were more diverse in their production of BC types than ASD speakers.

Regularising weakly informative priors with a normal distribution  were specified for the intercept (\(\mu\) = 0, \(\delta\) = 0.5) and for the regression coefficient (\(\mu\) = 0, \(\delta\) = 0.3) and used the default priors of the \emph{brms} package for the standard deviation of the likelihood function, Student's \emph{t}-distribution (\(\nu\) = 3, \(\mu\) = 0, \(\delta\) = 2.5).

\subsubsubsection*{Speaker roles and dialogue stages}\label{BCFP_BC_results_BCType_roleandstage}

The choice of backchannel type was consistent throughout conversations for both groups. In other words, proportions of backchannel types were the same for all stages of dialogue within each group.

Considering speaker roles, however, revealed some interesting differences in the way backchannels were used by instruction followers compared to instruction givers; see Figure \ref{fig:BCTypeGroupRolePic}. For example, \emph{genau} (`exactly') was used far more frequently in the speech of instruction givers compared with followers (ASD: followers 2.3\% -- givers 21.5\%; CTR: followers 5\% -- givers 23.5\%; see black bars in Figure \ref{fig:BCTypeGroupRolePic}). This was compensated for with a decrease of \emph{ja} (`yes/yeah') and \emph{mmhm}, while the proportion of \emph{okay} remained more or less constant. This pattern holds true for the majority of individual speakers in both groups.

The most obvious explanation for this finding is that the backchannel token \emph{genau} (`exactly') is likely to be a semantically appropriate choice in many cases for a speaker who possesses, provides and, crucially, confirms information regarding the route and landmarks, but less so for an instruction follower (and vice versa for the non-lexical BC type \emph{mmhm}).



\begin{figure}

\includegraphics[width=1\linewidth]{images/BC_Types_Group_Role_labelled} \hfill{}

\caption{Stacked bar charts by group and role showing proportions of different backchannel types. For each group, instruction givers are displayed above instruction followers. ASD group in the top panel, CTR group in the bottom panel.}\label{fig:BCTypeGroupRolePic}
\end{figure}


\subsubsection{Intonational realisation}\label{BCFP_BC_results_BCIntonation}


As described in \sectref{sec:BCFP_data} above, all backchannel tokens were hand-corrected and smoothed before undergoing prosodic analysis. No sufficient pitch information for prosodic analysis could be extracted for 302 tokens; these were usually rather short and/or produced with non-modal voice quality. After careful inspection of the extracted pitch contours for the remaining tokens, a further 20 tokens that were not suitable for intonational analysis were excluded (most of these were produced with very creaky voice).  Following this step, 2069 BC tokens remained for analysis (87.3\% of the original 2371). It is interesting to note that there was a far lower proportion of the usually disyllabic and fully voiced \emph{mmhm} type (5\%) in the subset of excluded tokens than in the full data set, reflecting the fact that the other lexical types (e.g. \emph{okay}) are inherently more susceptible to being realised in forms with reduced periodic energy, which in turn makes such realisations problematic for prosodic analysis.

Finally, all tokens that were not part of the four main categories (\emph{ja, mmhm, okay, genau}) were excluded. This necessitated the exclusion of a further 137 tokens, leaving a total of 1932 tokens (81.4\% of the original 2371). This step was taken because prosodic realisation was analysed separately for different lexical types of BC. As we shall see, speakers used very specific mappings for different backchannel types, thereby greatly reducing the utility of a monolithic analysis across different types.

I will first describe a continuous analysis, then a categorical view in which realisations were split up into the three categories of rising, falling and level pitch contours (more information in \sectref{BCFP_BC_results_BCIntonation_categorical}). The categorical analysis not only facilitates detecting and describing overarching patterns of prosodic realisation, but also makes it possible to explicitly account for the potentially distinct status of level (or flat) intonation contours \citep[see \sectref{sec:BCFP_FP}; cf.][]{griceIntegratingDiscretenessContinuity2017,sbrannaBackchannellingLanguagesRate2022}.

Speaker roles and different stages within dialogues did not have any major effects on intonational realisation. There was a slight tendency for more falling contours in the later stages of dialogue across groups and BC types. Similarly, there was a slight overall tendency for more falling contours in the speech of instruction givers compared with followers across groups and BC types. However, as these effects were weak and not consistent across speakers, they will be disregarded in the following analyses.

\subsubsubsection*{Continuous analysis}\label{BCFP_BC_results_BCIntonation_continuous}


Figure \ref{fig:BCIntContinuous} shows violin (and scatter) plots of intonation contours by backchannel type and across groups. Values are shown across groups in order to emphasise the differences between lexical types of backchannel. Group differences will be analysed separately for each type in the following section.  Across groups, intonation greatly differed according to backchannel type. For instance, \emph{mmhm} tokens were produced almost entirely with rising intonation by both groups of speakers, while there was a clear preference for falling intonation contours on \emph{genau} for both groups.



\begin{figure}[p]
	
	{\includegraphics[width=1\linewidth]{figures/graphics-BCIntContinuous-1}
		
	}
	
	\caption{Intonational realisation of backchannels by type in semitones (pooled across speakers and groups). Negative values indicate falling contours; positive values indicate rising contours. Blue diamonds represent mean values.}\label{fig:BCIntContinuous}
\end{figure}



\begin{figure}[p]
	
	{\includegraphics[width=1\linewidth]{figures/graphics-BCIntContinuousType-1}
		
	}
	
	\caption{Mean values (dots) and SD (error bars) for intonation contours, by backchannel type and group. ASD group on the left side of each panel, CTR group on the right side of each panel.}\label{fig:BCIntContinuousType}
\end{figure}


 An analysis by group and lexical type reveals that there were between-group differences in intonational realisation for all lexical types except \emph{mmhm}. Figure \ref{fig:BCIntContinuousType} and Table \ref{tab:BCIntTable} show mean ST values for pitch movement and standard deviations by group and backchannel type.



\begin{table}

		\caption{\label{tab:BCIntTable}Intonational realisation of BCs by type and group. Negative values indicate falling contours; positive values indicate rising contours. ST = semitones; SD = standard deviation.}
		
		\begin{tabularx}{.8\textwidth}{XXrY}
			\lsptoprule
			&  & \multicolumn{2}{c}{Contour (ST)} \\
			\cmidrule(r){3-4}
			BC Type & Group & Mean & SD\\
			\midrule
			genau & ASD & -4.30 & 5.65\\
			genau & CTR & -2.53 & 5.13\\
			ja & ASD & 3.15 & 4.26\\
			ja & CTR & 1.74 & 3.67\\
			mmhm & ASD & 5.70 & 4.27\\
			mmhm & CTR & 5.98 & 3.64\\
			okay & ASD & 1.38 & 5.70\\
			okay & CTR & -0.63 & 4.89\\
			\lspbottomrule
		\end{tabularx}

\end{table}


 Bayesian linear regression modelling confirms that there were robust group differences in the intonational realisation of three out of the four BC types (\emph{okay}, \emph{ja} and \emph{genau}). In contrast, there was clearly no difference between groups for \emph{mmhm}, recalling the special status of this non-lexical BC type and reflecting the fact that almost all \emph{mmhm} tokens were realised with rises, in both groups. Model results are summarised below by BC type. More details can be found in the accompanying scripts and files (see \url{https://osf.io/jcb7t/}).

For \emph{okay}, mean \(\delta\) = -2.2 (ST), indicating more falling and fewer rising contours in the CTR group. The 95\% CI {[}-4.16, -0.19{]} does not include zero and the posterior probability \(P(\delta > 0)\) is 0.96. This indicates that there war a robust difference between groups in the intonational realisation of \emph{okay} BCs.

For \emph{mmhm}, mean \(\delta\) = 0.49, the 95\% CI is {[}-1.33, 2.29{]} and the posterior probability \(P(\delta > 0)\) is 0.67. This clearly shows that there was no robust group difference in the intonational realisation of \emph{mmhm} tokens.

For \emph{ja}, mean \(\delta\) = -2.03, indicating more falling and fewer rising contours in the CTR group. The 95\% CI {[}-3.37, -0.67{]} does not include zero and the posterior probability \(P(\delta > 0)\) is 0.99. This very clearly indicates that there was a robust difference between groups in the intonational realisation of \emph{ja} BCs.

For \emph{genau}, mean \(\delta\) = 1.77, indicating more rising and fewer falling contours in the CTR group. The 95\% CI is {[}-0.06, 3.54{]} and the posterior probability \(P(\delta > 0)\) is 0.95. Although the CI includes zero by a very narrow margin, this model output still very strongly favours the interpretation that there was a robust group difference in the intonational realisation of \emph{genau} tokens. 

\subsubsubsection*{Categorical analysis}\label{BCFP_BC_results_BCIntonation_categorical}


For the categorical analysis of intonation, all contours with pitch movement within the range of \pm1 semitone were counted as \textit{level} (i.e.~all tokens with absolute values \leq 1). An absolute pitch difference of 1 semitone is somewhat greater than the thresholds of ``just noticeable'' pitch differences reported in some recent experimental studies \citep{jongmanJustNoticeableDifferences2017,liuJustNoticeableDifference2013}, but considerably smaller than the values proposed in \citet{thartDifferentialSensitivityPitch1981}. In any case, auditory inspection of all tokens in the relevant range confirmed that pitch movement was subtle at most and that the extracted values accurately reflected the original intonation contours.

Figure \ref{fig:BCIntCategoricalGroupPic} shows the proportions of falling, level and rising pitch contours by group and backchannel type, and confirms that 1) differences between groups were subtle and 2) intonational realisation varied greatly by BC type. In other words, there was a specific, albeit probabilistic mapping of intonation contours to different types of backchannel for both the ASD and the CTR group. The only difference between groups noticeable at this level of analysis is a stronger overall preference for rising backchannels in the ASD group. Averaging across backchannel types, 67.6\% (n = 427) of contours were rises in the ASD group, compared to 54\% (n = 702) in the CTR group. This pattern will be elucidated in the following through detailed analyses of speaker-specific behaviour and of the diversity of intonation contours produced.



\begin{figure}

\includegraphics[width=1\linewidth]{images/BC_Int_Group_labelled} \hfill{}

\caption{Intonation contour by group and backchannel type. Rising contours in yellow, level contours in orange and falling contours in red. Level contours were defined as all tokens with a pitch difference in the range of \pm1 semitone.}\label{fig:BCIntCategoricalGroupPic}
\end{figure}


Speaker-specific analysis of the intonational realisation of backchannels reveals firstly that the behaviour of the CTR group was more homogeneous overall than that of the ASD group (as was the case for many other measures reported in this book). The individual distributions of almost all non-autistic speakers matched the averaged group distribution to an almost uncanny degree, as shown in Figure \ref{fig:BCIntCategoricalSpeaker} (bottom two rows). This was not the case for the ASD group (uppermost rows). Besides the fact that 5 out of 14 autistic speakers did not produce backchannels from all four main categories (whereas all non-autistic speakers used all categories), many speakers also do not show evidence for the precise mapping of intonation contour to backchannel type that is evident at the group level. Instead, around half of all autistic speakers used predominantly rising contours \emph{regardless} of backchannel type.



\begin{figure}

{\includegraphics[width=1\linewidth]{figures/graphics-BCIntCategoricalSpeaker-1}
	
}

\caption{Intonation contour by speaker and backchannel type. ASD speakers in the top two rows and with blue outlines, CTR speakers in the bottom two rows and with green outlines. Rising contours in yellow, level contours in orange and falling contours in red. Level contours were defined as all tokens with a pitch difference in the range of \pm1 semitone.}\label{fig:BCIntCategoricalSpeaker}
\end{figure}



The relevance and robustness of the diversity of such distributions can be quantitatively analysed using the measure of Shannon entropy (as for the analysis of lexical types in \sectref{BCFP_BC_results_BCType_entropy}). An entropy value (\(H\)) of 0 signifies that all backchannels of a category were produced with the same intonation contour, while the maximum entropy value in this case is 1.58 (equal proportions for all three types of contour). At the group level, entropy was higher for the CTR group across backchannels and also for each individual BC type except \emph{mmhm}. For a more representative, in-depth analysis, entropy was also calculated by speaker (and BC type). Results confirm that entropy was higher on average for non-autistic speakers in all categories except \emph{mmhm}. Results by group are shown in Table \ref{tab:BCIntEntropyGroup} and results by speaker are shown in Figure \ref{fig:BCIntEntropy}.

The non-lexical backchannel \emph{mmhm} stands out by having a lower entropy value. This is because, as observed above, it was realised with a rising contour in the vast majority of cases. This held true for all but two speakers (M08 and M10A, both from the ASD group).



\begin{table}
		\caption{\label{tab:BCIntEntropyGroup}Shannon entropy (\(H\)), measuring the diversity of intonation contours, by BC type and group.}
		
		\begin{tabular}{lll}
			\lsptoprule
			BC Type & Group & H\\
			\midrule
			genau & ASD & 0.80\\
			genau & CTR & 1.13\\
			ja & ASD & 1.20\\
			ja & CTR & 1.43\\
			mmhm & ASD & 0.64\\
			mmhm & CTR & 0.46\\
			okay & ASD & 1.27\\
			okay & CTR & 1.40\\
			\lspbottomrule
		\end{tabular}

\end{table}



\begin{figure}

{\includegraphics[width=1\linewidth]{figures/graphics-BCIntEntropy-1}
	
}

\caption{Entropy as a measure of the diversity of intonation contours, by speaker and backchannel type. ASD group in blue, CTR group in green.}\label{fig:BCIntEntropy}
\end{figure}

Bayesian modelling confirms these group differences as robust except in the case of the non-lexical backchannel type \emph{mmhm}. Details are reported in the following paragraphs.

Entropy values by speaker were fitted to four separate Bayesian models, one for each main type of backchannel. All models used a skew normal distribution. While log-normal distributions were used for Bayesian models of entropy elsewhere, this was not suitable in this case as the data contained a number of data points with entropy values of 0 (where all backchannels were produced with the same type of contour). A hurdle log-normal distribution can be used in such cases, but skew-normal distributions provided a considerably better fit in every instance. The ASD group was used as the reference level for the group comparison. Results for the difference between groups for each backchannel type in turn are reported below. For further details, see scripts and files in the accompanying repository.

For \emph{okay}, mean \(\delta\) = 0.36, indicating higher entropy values in the CTR group. The 95\% CI {[}0.12, 0.63{]} does not include zero and the posterior probability \(P(\delta > 0)\) is 0.99. This confirms that intonation contours were less diverse for autistic speakers (many of whom used predominantly rises for \emph{okay}).

For \emph{mmhm}, mean \(\delta\) = 0, indicating no difference whatsoever between groups. The 95\% CI {[}-0.17, 0.17{]} is centered at zero and the posterior probability \(P(\delta > 0)\) is 0.51. This unequivocally shows that there was no difference between groups (most speakers across groups produced at least 80\% rises on \emph{mmhm}).

For \emph{ja}, mean \(\delta\) = 0.26, indicating higher entropy values in the CTR group. The 95\% CI {[}0.03, 0.57{]} does not include zero and the posterior probability \(P(\delta > 0)\) is 0.97. This confirms that intonation contours were less diverse for autistic speakers (most of whom showed a clear preference for rises). Please note that the lower end of the credible interval is very close to zero, meaning that results should be interpreted with at least a certain amount of caution here.

For \emph{genau}, mean \(\delta\) = 0.41, indicating higher entropy values in the CTR group. The 95\% CI is {[}0, 0.77{]} and the posterior probability \(P(\delta > 0)\) is 0.95. This confirms that intonation contours were less diverse for autistic speakers (most of whom showed a clear preference for falls -- or produced no \emph{genau} tokens at all). Please note that as the lower end of the credible interval just includes zero, results should be interpreted with a certain degree of caution.

\subsection{Summary}\label{BCFP_BC_summary}

This in-depth analysis of backchannel productions has yielded a number of insights, both at a general level and specifically for the comparison of dialogues by autistic and non-autistic dyads. First, it was found that ASD dyads produced fewer backchannels per minute than CTR dyads and that this effect was particularly clear in the early stages of dialogue (cf.~the similar pattern for turn-timing described in \sectref{turntaking_results_FTO_group_stage}). It was also shown that instruction followers produced a far higher rate of backchannels than instruction givers (across groups).

Second, an analysis of lexical realisation revealed that \emph{ja} (`yes/yeah') was by the far most common type across groups, but that groups differed in the diversity of their BC productions. In other words, ASD speakers showed clearer preferences for certain BC types and used a smaller range of different BC types, whereas all CTR speakers employed BCs from all five lexical categories and spread tokens out more evenly across these different categories. It was also shown that speaker roles influenced the choice of BC type, with e.g.~instruction givers using considerably more \emph{genau} (`exactly') than instruction followers.

Third, prosodic analysis revealed a number of interesting patterns. Across groups, intonation contours were (probabilistically) mapped onto specific backchannel types, with e.g.~\emph{mmhm} produced almost exclusively with rising intonation and \emph{genau} (`exactly') produced predominantly with falling intonation. Both the continuous and the categorical analysis of backchannel intonation showed that ASD speakers and CTR speakers differed in their prosodic realisations, with many ASD speakers e.g.~preferring rises regardless of BC type, reflecting a less flexible mapping of intonation contours to BC types.

It bears repeating that these patterns held true for most but not all speakers, and that there was considerable overlap between groups.





\section{Filled pauses}\label{sec:BCFP_FP}

This section will first provide a synopsis of research on filled pauses in conversation and then a description of the results on data from dialogue between German dyads with and without a diagnosis of autism spectrum disorder. The subsequent sections report on analyses of the role of silent pauses, of the interaction between filled pauses and following stretches of silence, and of laughter.

\subsection{Background}\label{BCFP_FP_background}

Similarly to backchannels, filled pauses such as \emph{uh(m)} are a ubiquitous feature of spoken interaction. Functionally, however, they are the polar opposite, as they are typically used to signal hesitation or uncertainty (rather than understanding and agreement) and are intended to help the current speaker hold the floor, or sometimes to take over the floor from the interlocutor (rather than supporting their ongoing turn) \citep{belzPhonetikAhUnd2021, benusVariabilityStabilityCollaborative2009, fischerDiscourseParticlesTurntaking2000, schettinoPhoneticFunctionalFeatures2019, shribergErrrrHumanEcology2001, wardNonlexicalConversationalSounds2006}. Another similarity to backchannels is that filled pauses, too, are rarely, if ever, produced consciously and deliberately. In contrast to backchannels, the use of which is usually either ignored or encouraged, producing filled pauses has often been judged and perceived to be undesirable, with certain educational and training settings actually aiming to eradicate their use, at least in formal, monologic speech \citep{erardUmSlipsStumbles2008, fischerCognitiveSemanticsLexical2013, foxtreeInterpretingPausesUms2002, niebuhrNotHesitateUnless2019a, oconnellHistoryResearchFilled2004,smithCourseAnsweringQuestions1993,wardProsodicPatternsEnglish2019}.

Although a higher rate of filled pauses can lead to more negative judgements in the specific case of public speaking \citep{niebuhrNotHesitateUnless2019a}, filled pauses in dialogue actually facilitate understanding and aid the flow of conversation. Filled pauses can serve a range of crucial functions in conversation, e.g.~signalling politeness and attention or foreshadowing the duration and informativeness of upcoming linguistic elements, which aids in the planning and processing of complex utterances \citep{corleyHesitationSpeechCan2003,foxtreeListenersUsesUm2001,fruehwaldFilledPauseChoice2016,levinsonPragmatics1983,niebuhrNotHesitateUnless2019a,schegloffOtherUh2010}.

I will focus on the two most common types of filled pause (by far), those realised either with only a central vowel (\emph{uh}) or a central vowel followed by a nasal (\emph{uhm}). Although similar in segmental form, a number of studies have found important differences between \emph{uh} and \emph{uhm}, suggesting e.g.~that \emph{uh} is perceived more negatively than \emph{uhm} \citep{niebuhrNotHesitateUnless2019a} and that \emph{uhm} is not only more frequent than \emph{uh}, but is also continuing to gain ground in an ongoing process of linguistic change \citep{fruehwaldFilledPauseChoice2016,wielingVariationChangeUse2016}. Some authors have further proposed that \emph{uhm} might be functionally different from \emph{uh}. \emph{Uhm} not only seems to reliably cue longer silent pauses than \emph{uh} \citep{clarkUsingUhUm2002,foxtreeListenersUsesUm2001} -- a finding which I have examined and attempted to replicate separately; see \sectref{sec:BCFP_FP_silent} -- but it has also been suggested that \emph{uhm} might be a more specifically listener-oriented conversational signal than \emph{uh} \citep{gormanUhUmChildren2016,irvineUhUmAutism2016,mcgregorBriefReportUm2020}. 

It is important to note at this point that all of these specific aspects of filled pause production can only safely be assumed to apply to West Germanic languages, as most studies used data from German, English or Dutch (for which results are very similar). A number of studies from other language families show that, while a distinction between two filled pause types -- one consisting of only a vowel and the other with the addition of a final nasal -- is very common, there are differences in their exact phonetic realisation, especially in terms of vowel quality \citep{anansiripinyoAcousticphoneticCharacteristicsThai2019, dinapoliFilledPausesProlongations2020,kosmalaDualStatusFilled2022,nguyenAcousticCorrelatesListeneridentified2015,schettinoPhoneticFunctionalFeatures2019,yuanPausesPauseFillers2016}. There also seems to be a differential (possibly increased) use of other forms of hesitation such as repetition and prolongation in other languages, and particularly in tone languages \citep{betzProlongationGerman2017,leeProlongationSpontaneousMandarin2004,tsengTaxonomySpontaneousSpeech2003}.

Regarding prosodic realisation, there is abundant, cross-linguistic evidence that filled pauses are typically produced with flat or level intonation contours, and that they tend to be relatively low in pitch \citep{adellModellingFilledPauses2010,belzPitchCharacteristicsFilled2015,oshaughnessyRecognitionHesitationsSpontaneous1992,shribergIntonationClauseinternalFilled1993}. The current study is the first to consider prosodic aspects of filled pauses in ASD.


\subsubsection{Previous work on filled pauses in autism}\label{BCFP_FP_background_ASD}

Research on the use of filled pauses by speakers on the autism spectrum is limited, but growing. To my awareness, there are eight previous studies focussing on filled pauses in ASD, none of which analysed conversations between autistic adults (as in the current work). Seven out of these eight studies analysed the speech of children or adolescents \citep{gormanUhUmChildren2016,irvineUhUmAutism2016,jonesItImportantFrequency2022,lunsfordAutismUseFillers2010,mcgregorBriefReportUm2020,parish-morrisLinguisticCamouflageGirls2017,suhNarrativePerformanceOptimal2014}, while one analysed the speech of autistic adults interacting with a -- presumably non-autistic -- experimenter \citep{lakeListenerVsSpeakeroriented2011}. Most studies analysed speech that was either monologic or produced in the context of structured interviews with a trained professional \citep[with the exception of][here, semi-structured double interviews were used]{jonesItImportantFrequency2022}, in many cases through use of the autism diagnostic observation schedule (ADOS) \citep{lordAutismDiagnosticObservation2000}.

All studies but one \citep{suhNarrativePerformanceOptimal2014} found differences between the filled pause productions of autistic and non-autistic participants \citep[but see also related results in][]{booConversationVirtualReality2022}. Of these, the only previous study on filled pauses in the speech of adults on the autism spectrum found a lower rate of filled pauses across lexical types (\emph{uh} and \emph{uhm}), while the remaining six studies considering children all report a lower proportion (or rate) of only \emph{uhm}, but not \emph{uh}, in the speech of autistic as compared to non-autistic participants.

These findings have led to a suggestion in some of the works cited above that the nasal filled pause type \emph{uhm} might have a distinctly listener-oriented function, and that the pattern of a reduced production of \emph{uhm}, specifically, might help to distinguish ASD from related diagnoses \citep{gormanUhUmChildren2016} and serve as a pragmatic \citep{irvineUhUmAutism2016} or even clinical marker \citep{mcgregorBriefReportUm2020}. \citet{gormanUhUmChildren2016} further suggest that ``fillers (…) may be a useful target for intervention” (p. 862). Such speculations have to be treated with caution, however. Not only is the amount of evidence rather limited to date, especially when taking into account the serious and pertinent issue of publication bias \citep[whereby studies that find a ``significant” effect are vastly more likely to be published than those that do not;][]{devitoCatalogueBiasPublication2019,easterbrookPublicationBiasClinical1991,johnMeasuringPrevalenceQuestionable2012,sterlingPublicationDecisionsTheir1959}. More specifically, the relevant pattern of a reduced use of \emph{uhm} (specifically and exclusively) does not seem to hold true for autistic adults, as suggested by the only relevant previous study \citep{lakeListenerVsSpeakeroriented2011} as well as the findings presented in this section.

\subsubsection{Current study}\label{BCFP_FP_background_current}

With the current study, I aim to make a novel contribution to the literature on filled pause production in ASD by 1) analysing conversations between autistic adults (for the first time) and 2) considering the prosodic realisation of filled pauses in the context of ASD. As emphasised throughout this book, investigating the behaviour of disposition-matched dyads seems to me the most promising way to gain insights into what might justifiably be called an autistic conversation style \citep{bolisAutismIntroducingDialectical2017,davisWhatNewFindings2021,miltonOntologicalStatusAutism2012,mitchellAutismDoubleEmpathy2021,sheppardHowEasyIt2016}. Furthermore, while there is a substantial amount of previous research on the prosodic realisation of filled pauses in the general population, this aspect has not been considered in work on ASD to date. Since previous findings point to a very clear cross-linguistic tendency for filled pauses being produced with flat or level intonation, the focus in this study lies mainly on investigating whether there is any deviation from this convention in the data set under investigation. Based on current knowledge and findings regarding the intonation of backchannels (\sectref{sec:BCFP_BC}), it can be speculated that the exact prosodic realisation of filled pauses may be similarly impactful.




\subsection{Results}\label{BCFP_FP_results}

I will first present results on the rate and type of filled pauses, and then discuss prosodic aspects. The average duration of filled pauses was very similar across groups (ASD: 423 ms; CTR: 456 ms), with a grand mean of 444 ms (SD = 247), and will therefore not be considered in any more detail in the following.


\subsubsection{Rate of filled pauses}\label{BCFP_FP_results_rate}


Both groups produced an identical average rate of filled pauses per minute (3.63). Underlying this was a very high degree of by-dyad variability in both groups, with filled pause rates ranging from 0.82 to 4.82. Furthermore, it was found that interlocutors in the ASD group seemed to adapt less to each other within dyads compared to dyads in the CTR group. Specifically, the difference between by-speaker filled pause rates within dyads tended to be much lower in the CTR group (mean = 0.53; SD = 0.44) than in the ASD group (mean = 1.56; SD = 1.18), and ASD dyads also accounted for the four greatest within-dyad differences; see Figure \ref{fig:FPRate}. 

\begin{figure}
	
	{\includegraphics{figures/FPRate}
		
	}
	
	\caption{Rate of filled pauses produced per minute of dialogue, by speaker, dyad and group. Speakers within a dyad are connected by lines representing within-dyad differences (by which dyads are ordered on the x-axis). ASD group in blue, CTR group in green.}\label{fig:FPRate}
\end{figure}

As for backchannels (see details in \sectref{BCFP_BC_results_BCRate_Bayes}), Bayesian negative binomial regression modelling of rates by dyad was used to test the group difference. Model output unambiguously confirms that there was no difference in the rate of filled pauses between the ASD and the CTR group (mean \(\delta\) = -0.4; 95\% CI {[}-1.63, 0.78{]}; \(P(\delta > 0)\) = 0.72); see the accompanying repository for further details on the Bayesian model (\url{https://osf.io/6zu4g/}).

Looking at different stages of dialogue reveals an overall trend for both groups to produce more filled pauses in the later stages of dialogue. However, those differences were far from robust within and across groups due to massive dyad-specific variability, as confirmed by Bayesian modelling (see repository for details). Variability was greater in the ASD group than in the CTR group. The mean rate of filled pauses per minute across groups was 3.19 before resolution of the first Mismatch and 3.73 after resolution of the first Mismatch.

For speaker roles, proportions were calculated, i.e. the summed duration of filled pauses was divided by the summed duration of all speech for givers and followers separately, as opposed to a calculation of FP rates (as for backchannels; see \sectref{BCFP_BC_results_BCRate_Role}). Proportions were calculated instead of rates because speaking times differed considerably between speaker roles.

There was a tendency across groups for instruction givers to produce a higher average proportion of filled pauses (3.71\% overall) than instruction followers (2.41\% overall). Bayesian modelling taking into account dyad as a random factor suggests that this difference between roles was reliable across groups (mean \(\delta\) = 1.72; 95\% CI {[}-0.01, 3.61{]}; \(P(\delta > 0)\) = 0.95). Within groups, however, the difference between roles was shown to be reliable only for the ASD group (\(P(\delta > 0)\) = 0.95) and not for the CTR group (\(P(\delta > 0)\) = 0.84). This discrepancy seems to stem from a higher degree of dyad-specific variability in the CTR group. Overall, the behaviour of 9 out of 14 dyads clearly reflected the group level pattern of more and/or longer filled pauses produced by instruction givers.



\subsubsection{\texorpdfstring{Lexical choice: \emph{uh} vs.~\emph{uhm}}{uh vs.~uhm}}\label{BCFP_FP_results_type}


There is a long tradition in the literature on filled pauses of contrasting and comparing nasal (\emph{uhm}) with non-nasal (\emph{uh}) filled pauses. I followed this in dividing all filled pauses into these two categories (see \sectref{sec:BCFP_data}).
In all the following analyses, I will use \emph{uh} to refer to filled pauses without a final nasal and \emph{uhm} to refer to filled pauses with a final nasal. I use this transcription to ensure consistency and comparability with previous studies (on languages other than German), even though filled pauses are almost always represented orthographically as \textless äh(m)\textgreater{} in German language materials.

Choice of filled pause type was very similar at the group level. Both groups used more \emph{uhm} than \emph{uh} overall, although this preference was slightly stronger for the CTR group (60\% \emph{uhm}) than for the ASD group (55.3\% \emph{uhm}). This group pattern obscures a very high degree of individual variability, however, with \emph{uhm} proportions ranging from 0\% to 100\% for different speakers; see Figure \ref{fig:FPType}. Although fewer CTR speakers showed a preference for \emph{uhm} (7 out of 14) than ASD speakers did (11 out of 14), the preference for one filled pause type over another was not systematic at the group level and instead seems to be a correlate of individual variability.

\begin{figure}
	
	{\includegraphics{figures/FPType}
		
	}
	
	\caption{Proportion of filled pause type by group and speaker (as a percentage of their total filled pause productions). \emph{Uhm} (nasal) in black, \emph{uh} (non-nasal) in pink. ASD group in the top row, CTR group in the bottom row. Speakers from the same dyad are plotted next to each other; dyads are separated by vertical lines.}\label{fig:FPType}
\end{figure}

This high degree of individual specificity combined with the very small initial difference of group averages makes it unsurprising that Bayesian regression modelling of \emph{uhm} proportions by speaker strongly suggests that there was no reliable group difference in choice of filled pause type (mean \(\delta\) = -4.9; 95\% CI {[}-15.78, 6.08{]}; \(P(\delta > 0)\) = 0.77; further details in the accompanying files).


\subsubsection{Intonational realisation}\label{BCFP_FP_results_intonation}

For the prosodic analysis, 176 tokens were discarded because pitch information was not available or was found to be unreliable upon manual inspection (e.g. because tokens were extremely short and/or produced with non-modal voice quality). This left 851 of the original 1027 tokens (82.9\%). Note that one speaker (M14, from the CTR group) did not produce any filled pause tokens suitable for prosodic analysis (having produced only 2 filled pauses in total; the average number of filled pauses produced per speaker is 37). Therefore, the following analyses will be limited to the remaining 27 speakers (14 ASD; 13 CTR).

\subsubsubsection*{Continuous analysis}\label{BCFP_FP_results_intonation_continuous}

A continuous analysis of intonation contours on filled pauses revealed very little difference between groups. Both groups produced average values very close to 0 ST, representing little to no pitch movement, i.e. level intonation contours. This is expected according to previous results on the intonational realisation of filled pauses. Mean values were slightly closer to 0 for the CTR group (mean = -0.29; SD = 1.26) compared to the ASD group (mean = -0.44; SD = 1.51). Bayesian modelling broadly confirms this trend, but also strongly suggests that it is unlikely to be a robust difference between groups (mean \(\delta\) = 0.25; 95\% CI {[}-0.16, 0.67{]}; \(P(\delta > 0)\) = 0.84; further details in the accompanying files).

\subsubsubsection*{Categorical analysis}\label{BCFP_FP_results_intonation_categorical}

To better account for the special status of level contours (the typical realisation) in the intonation of filled pauses, a categorical analysis was conducted in which all filled pauses with pitch movement within the range \pm1 ST were categorised as \textit{level}. The tokens exceeding these values were categorised as rises (positive values) and falls (negative values), respectively (see \sectref{BCFP_BC_results_BCIntonation_categorical} for details and rationale).

Across filled pause types, the CTR group produced a considerably higher proportion of the expected and widely attested level contours on filled pauses (70.3\%) than the ASD group (55.3\%), who produced higher proportions of both rises and falls instead; see Figure \ref{fig:FPIntCatGroupPic}. Falling intonation was the second most common realisation in both groups, with rising intonation the least frequent. 

Proportion of level contours by speaker was used as the dependent variable for Bayesian modelling. The model output confirms that the group difference in prosodic realisation is robust (mean \(\delta\) = 12.99; 95\% CI {[}4.28, 21.87{]}; \(P(\delta > 0)\) = 0.99; further details in the accompanying files).

Speaker-specific analysis confirms this pattern in showing, for instance, that 9 out of the 10 lowest proportions of level contours were produced by autistic speakers, whereas the 5 highest proportions of level contours were produced by non-autistic speakers (range 23.1\% -- 90\%; see Figure \ref{fig:FPIntCatSpeaker} in Appendix \ref{appendix:c}).



\begin{figure}

\includegraphics[width=1\linewidth]{images/FP_Int_Group_labelled} \hfill{}

\caption{Intonation contour by group. Rising contours in yellow, level contours in orange and falling contours in red. Level contours were defined as all tokens with a pitch difference in the range \pm1 semitone.}\label{fig:FPIntCatGroupPic}
\end{figure}

Comparing the two filled pause types \emph{uh} and {uhm} across groups, it was found that \emph{uh} was more often produced with the canonical level contour (70\%) than  \emph{uhm} (62.1\%). Bayesian modelling of the proportions of level contours by filled pause type (\emph{uhm} was the reference level) and speaker (which was treated as a random factor) confirms this as a robust difference (mean \(\delta\) = 17.05; 95\% CI {[}9.23, 24.82{]}; \(P(\delta > 0)\) = 1).

Table \ref{tab:FPlevel} shows the proportions of level contours used by group and filled pause type. It is clear that level contours constituted the preferred intonational realisation of filled pauses across groups and types (followed by falls, and then rises, which were only rarely used). The pattern is comparatively less obvious for productions by autistic speakers, however. The ASD group produced fewer level contours than the CTR group for both \emph{uhm} and \emph{uh}, but the difference between groups is clearer for \emph{uhm}, as only 49.5\% of tokens in the ASD group were produced with a level contour, compared to 68.9\% in the CTR group. However, a high degree of by-speaker variability underlies these group-level results and hence, there is no clear effect of the interaction of lexical type and intonation contour in a group-level comparison.

\begin{table}
			
    \caption{\label{tab:FPlevel}Proportion of intonation contour by group and filled pause type (level proportions in bold).}

    \begin{tabular}{llll}
	    \lsptoprule
	    Group        & Type         & Contour        & Proportion\\
	    \midrule
	    ASD          & uhm          & Fall           & 32.61\%\\
	    \textbf{ASD} & \textbf{uhm} & \textbf{Level} & \textbf{49.46\%}\\
	    ASD          & uhm          & Rise           & 17.93\%\\
	    ASD          & uh           & Fall           & 27.03\%\\
	    \textbf{ASD} & \textbf{uh}  & \textbf{Level} & \textbf{64.86\%}\\
	    ASD          & uh           & Rise           & 8.11\%\\
	    CTR          & uhm          & Fall           & 22.09\%\\
	    \textbf{CTR} & \textbf{uhm} & \textbf{Level} & \textbf{68.90\%}\\
	    CTR          & uhm          & Rise           & 9.01\%\\
	    CTR          & uh           & Fall           & 22.64\%\\
	    \textbf{CTR} & \textbf{uh}  & \textbf{Level} & \textbf{72.64\%}\\
	    CTR          & uh           & Rise           & 4.72\%\\
	    \lspbottomrule
    \end{tabular}

\end{table}

A Bayesian model of proportion of intonation contour by speaker, including the interaction between group and filled pause type and with speaker as a random effect, provides conclusive evidence that 1) fewer level contours were produced by autistic speakers than controls for both \emph{uh} (mean \(\delta\) = −14.28; 95\% CI {[}−25.91, −1.51{]}; \(P(\delta > 0)\) = 0.96) and  \emph{uhm} (mean \(\delta\) = − 10; 95\% CI {[}−19.75, 0.32{]}; \(P(\delta > 0)\) = 0.95) and 2) that \emph{uh} was produced with a higher proportion of level contours than \emph{uhm} in both the ASD group (mean \(\delta\) = 16.52; 95\% CI {[}6.47, 26.12{]}; \(P(\delta > 0)\) = 1) and the CTR group (mean \(\delta\) = 20.8; 95\% CI {[}9.8, 31.45{]}; \(P(\delta > 0)\) = 1). Although the difference between groups for intonational realisation was slightly greater for \emph{uhm} compared to \emph{uh}, there is no robust effect for the interaction between group and filled pause type (mean \(\delta\) = 4.29; 95\% CI {[}-9.26, 17.84{]}; \(P(\delta > 0)\) = 0.71).

\subsubsubsection*{Diversity of prosodic realisation (entropy)}\label{BCFP_FP_results_intonation_entropy}

As in the analysis of backchannels (Section \ref{BCFP_BC_results_BCIntonation_categorical}), Shannon entropy (\(H\)) was used as a measure of diversity in order to quantify proportional differences. In the case of the prosodic realisation of filled pauses, higher entropy values are indicative of more unusual behaviour, as speakers were expected to produce a (very) large proportion of filled pauses with a single intonational contour (level). More predictable and less diverse behaviour is represented with lower entropy values (\(H\) = 0 if only one contour was used for all tokens). Based on the results described above, we can expect to find higher entropy values for autistic speakers (as they produced fewer level contours). The highest possible entropy value in this case is 1.58 (equal proportions for all three types of rises).

Results at the group level indeed reveal a higher entropy value for the ASD group (1.4) compared to the CTR group (1.12). Speaker-specific analysis confirms this pattern as, e.g., six out of the seven highest entropy values were recorded for autistic speakers; see Figure \ref{fig:FPEntropy}.

\begin{figure}

\includegraphics[width=1\linewidth]{figures/FPEntropy.png} \hfill{}

\caption{Entropy as a diversity measure of the prosodic realisation (rising, level or falling) of filled pauses, by speaker. Higher entropy values (\(H\); on the y-axis) represent a more diverse realisation. ASD group in blue, CTR group in green.}\label{fig:FPEntropy}
\end{figure}

\newpage
Bayesian modelling of entropy values by speaker confirms the group-level difference in the intonational realisation of filled pauses as a robust effect (mean \(\delta\) = − 0.14; 95\% CI {[}− 0.28, 0{]}; \(P(\delta > 0)\) = 0.96).

It has to be noted that entropy operationalised this way does not specifically measure proportions of level contours (as in the preceding section), but rather the diversity of intonation contours used. This means that if a speaker (unusually and unexpectedly) showed a clear preference for a non-level intonation contour (rise or fall), this behaviour would still be represented by a low entropy value. Indeed, 5 out of the 28 speakers in the data set under investigation did show a preference for falling instead of level contours in the realisation of filled pauses. However, especially as four out of those five speakers were part of the ASD group, this does not mitigate the fact that separate but related evidence has been presented for the observations 1) that autistic speakers produced fewer filled pauses with the canonical level contour and 2) that autistic speakers were more diverse in the intonational realisation of filled pauses.

\subsection{Summary}\label{BCFP_FP_summary}


The results presented in this section show that autistic and non-autistic speakers did not differ (at all) in the rate of filled pauses produced, nor in their preference of filled pause type (both preferring \emph{uhm} over \emph{uh}). The only group-level difference was in prosodic realisation, with ASD speakers producing fewer filled pauses realised with the typical level intonation contour than CTR speakers (although both groups did show a preference for level contours overall). Additionally, interlocutors in the CTR group seemed to adapt more to each other in terms of the rate of filled pauses produced compared to the ASD group. It is also interesting to note that the more frequent lexical type \emph{uhm} was less consistently produced with a level contour, across groups, although this could simply be related to the fact that \emph{uhm} was, on average, almost twice as long as \emph{uh}. This increase in duration might in itself have led to the production of more falling contours \citep[see \sectref{sec:BCFP_FP_silent} and][]{fuchsAssessingRespiratoryContributions2015,gussenhovenFundamentalFrequencyDeclination1988}.













\section{Silent pauses}\label{sec:BCFP_FP_silent}

To complement the analysis of filled pauses (and the analysis of silent gaps between turns in \chapref{turntaking}), an analysis of silent pauses (within speaker-turns) was conducted.

\subsection{Background}\label{BCFP_FP_silent_background}

Silent pauses feature in the majority of spoken utterances, and they are particularly prevalent in conversational speech. While there is a solid amount of general research on the topic, and in the context of second-language speech in particular \citep{bradlowLanguageindependentTalkerspecificityFirstlanguage2017,dejongChoosingThresholdSilent2013}, very little is known about the use of silent pauses in atypical populations, such as in the speech of persons diagnosed with ASD.

Previous work on silent pause use in ASD seems to be limited to three studies comparing autistic speakers with matched controls, with contradictory results. In \citet{thurberPausesNarrativesProduced1993}, fewer silent pauses in picture book narrations by English-speaking autistic children are reported. In contrast, \citet{lakeListenerVsSpeakeroriented2011} report a higher rate of silent pauses in interview-style conversations between experimenters and English-speaking autistic adults. Finally, \citet{engelhardtSpeakerVersusListenerOrientedDisfluency2017} found equivalent silent pause rates for autistic and matched non-autistic adults in  a sentence repetition task.

 Crucial differences in the age of participants and/or speech material make comparison with the corpus under investigation difficult in the cases of \citet{thurberPausesNarrativesProduced1993,engelhardtSpeakerVersusListenerOrientedDisfluency2017}. As these confounding factors are less of a concern regarding the work by \citet{lakeListenerVsSpeakeroriented2011} (age range and speech data being similar to the data at hand), I will focus on this latter study for comparison. 
 
\citet{lakeListenerVsSpeakeroriented2011} report a higher rate of silent pauses in autistic adults compared to non-autistic controls, but did not examine any silent pauses with a duration of under 2 seconds. The authors provide no specific reasons for using this extremely high cut-off point, only stating that ``this was done in order to ensure that we excluded normal prosodic pauses” (p. 138). The sheer utility of such a threshold can further be called into question from a pragmatic--analytic point of view, as employing it entails excluding almost all silent pauses in a given data set: speakers from the control group in \citet{lakeListenerVsSpeakeroriented2011} in fact did not produce any silent pauses longer than 2 seconds.

For this study, separate analyses were conducted of 1) silent pauses of any duration, 2) a subset of silent pauses over 2 seconds in duration \citep[for comparison with][]{lakeListenerVsSpeakeroriented2011} and 3) silent pauses of 700 ms or longer, a subset of 1) and a superset of 2) (see \sectref{BCFP_FP_silent_results_700} for rationale). 

In addition to simply comparing the rate and duration of silent pauses, other potential group differences were explored in the form of the distributional characteristics of silent pauses. Specifically, it was examined which effect the lexical form of a preceding filled pause (\textit{uh} or \textit{uhm}) had on the duration of the following silent pause. 
This is chiefly inspired by the highly influential work in \citet{clarkUsingUhUm2002} comparing the use of \emph{uh} and \emph{uhm} in spontaneous speech. The authors claim that there is a considerable difference in the average duration of silences following \emph{uh} as compared to \emph{uhm}, with \emph{uhm} preceding silences of at least twice the duration of silences following \emph{uh}. In a comparison of autistic and non-autistic children, \citet{lunsfordAutismUseFillers2010} confirmed this effect for their CTR, but not their ASD group. 

While \citet{clarkUsingUhUm2002} also showed, in a binary distinction, that silences following “lengthened” productions of both \emph{uh} and \emph{uhm} were considerably longer overall, the duration of the \emph{uh} vs. \emph{uhm} tokens themselves was not controlled for. In fact, to my knowledge, none of the subsequent papers examining this phenomenon involved an analysis that systematically controlled for the inherent average duration of \emph{uh} and \emph{uhm}.

This is a serious concern since, in the current data set at least, \emph{uhm} is considerably longer (521 ms) than \emph{uh} (329 ms) on average. Thus, it is important to establish whether and to what extent the effect ascribed to a difference in filled pause type (nasal vs. non-nasal) is in fact simply due to filled pause duration, independent of whether a final nasal was present (which for simple reasons of physiology and aerodynamics increases the likelihood of longer durations). An attempt was thus made to replicate the relevant effect while controlling for the confound of filled pause duration, all in the context of investigating differences between the ASD and CTR group in the current data set.

\subsection{Data}\label{BCFP_FP_silent_data}

The corpus contains a total of 3473 silent pauses.
Portions of dialogue that contained only audible breathing, clicks, and similar noises were counted as being part of silent intervals. In contrast, all other speech sounds, including filled pauses, were counted as being part of IPUs. While it has to be acknowledged that most such ``silent” pauses are not completely silent from a strictly acoustic perspective \citep{belzAreSilentPauses2019}, I chose to adhere to the conventional definition outlined above, since the main aim of this study is to enable comparison with the (sparse) previous literature on silent pauses in ASD as well as with the more general literature on the topic.

For the analysis of silences following filled pauses, all 1027 filled pause tokens in the data set as well as their surrounding linguistic context (see \sectref{sec:BCFP_FP}) were investigated. If filled pauses were followed not by any period of silence, but instead directly by another utterance (by either of the interlocutors), a duration of 0 was assigned to the following silence. All relevant code, scripts, model specifications and data frames are available in the \textit{OSF} repository at \url{https://osf.io/bph2t/}.

\subsection{Results}\label{BCFP_FP_silent_results}

I will report results first on silent pause rate, using different durational cut-offs, and then on silences following \emph{uh} vs. \emph{uhm}.

\subsubsection{All silent pause tokens}\label{BCFP_FP_silent_results_all}

The mean duration of silent pauses was close to identical across groups, with means of 677 ms (SD = 563) for the ASD and 628 ms (SD = 527) for the CTR group. The mean rate of silent pauses was exactly identical across groups, with a value of 12.2 silent pauses per minute. A dyad-specific analysis of  silent-pause rates also gives no indications  of ASD-specific behaviour; see Figure \ref{fig:silentall}. Note that there was a considerable degree of by-dyad variability and overlap between groups, not only for this analysis, but also all the ones described below. 

\begin{figure}

\includegraphics[width=1\linewidth]{images/SilentPause_min.png} \hfill{}

\caption{Rate of silent pauses by dyad and group (ASD in blue, CTR in green).}\label{fig:silentall}
\end{figure}



\subsubsection{\texorpdfstring{Silent pauses >2 seconds}{over 2 secs}}\label{BCFP_FP_silent_results_2s}

To allow for a direct comparison with \citet{lakeListenerVsSpeakeroriented2011}, a subset of all silent pauses with a duration of over 2 seconds was analysed. Silent pauses of this kind were very rare in the corpus under investigation (73 tokens, or 2\%, of the total 3473). The number of such pauses produced by each dyad ranged from 0 to 13.

The ASD group produced a higher mean rate of long silent pauses (>2 s) per minute (0.33; n = 34) than the CTR group (0.21; n = 39); see Figure \ref{fig:silent2s}. Given the low overall number of instances, a more intuitive way of stating the same observation is that a 20-minute dialogue (average duration) would typically contain seven long pauses (>2 s) in the ASD group and four long pauses (>2 s) in the CTR group.

Bayesian Poisson regression suggests that this was a robust difference between groups (mean \(\delta\) = -0.12; 95\% CI {[}-0.23, -0.01{]}; \(P(\delta > 0)\) = 0.97). However, the proximity of the higher end of the credible interval to zero and the very low overall number of observations are reasons for exercising some caution in the interpretation of these data.

\begin{figure}

\includegraphics[width=1\linewidth]{images/LongSilentPause_min.png} \hfill{}

\caption{Rate of silent pauses >2 s in duration, by dyad and group (ASD in blue, CTR in green).}\label{fig:silent2s}
\end{figure}


\subsubsection{\texorpdfstring{Silent pauses \geq700 milliseconds}{over 700 secs}}\label{BCFP_FP_silent_results_700}

For a more reliable and representative metric of long pauses in dialogue, a lower cut-off value, at 700 milliseconds, was used. This particular threshold was chosen mainly because it clearly exceeds mean pause durations in the data set used here (646 ms across groups) as well as in previous work \citep{dejongChoosingThresholdSilent2013,choContributionSilentPauses2006,megyesiProductionPerceptionPauses2002}. The same value was used for categorising long silent gaps between
speakers (in \sectref{turntaking_results_categorical}), based on the finding that gaps of 700 ms or longer are perceived as unusual by listeners and often cue repair initiations or non-affiliating responses \citep{kendrickIntersectionTurntakingRepair2015,kendrickTimingConstructionPreference2015a,robertsIdentifyingTemporalThreshold2013}. As the difference between within-speaker pauses and between-speaker gaps structurally lies only in who takes the following turn, the relevant findings further support the use of a 700-millisecond threshold for silent pauses.

Using this cut-off point leaves far more observations for analysis (n = 1052) and will therefore also yield more robust and reliable results. 

The group rate of silent pauses \geq700 ms was higher for the ASD group (4.02) than for the CTR group (3.52); see Figure \ref{fig:silent700ms}. Although this group difference is not very large, Bayesian negative binomial regression shows the effect to be robust, confirming that the CTR group produced a lower rate of long silent pauses (\geq700 ms) than the ASD group (mean \(\delta\) = -0.5; 95\% CI {[}-0.9, -0.1{]}; \(P(\delta > 0)\) = 0.98).

 Thus, we can conclude that autistic dyads produced more long silent pauses than non-autistic dyads, independently of the exact cut-off point used to define a long pause, although no difference between groups was found when tokens of any duration were taken into account.

 
\begin{figure}

\includegraphics[width=1\linewidth]{images/MidSilentPause_min.png} \hfill{}

\caption{Rate of silent pauses \geq700 ms in duration, by dyad and group (ASD in blue, CTR in green).}\label{fig:silent700ms}
\end{figure}

\subsubsection{\texorpdfstring{Silence following \emph{uh} vs. \emph{uhm}}{uh vs. uhm}}\label{BCFP_FP_silent_results_uhm}

The effect of \emph{uh} and \emph{uhm} on subsequent stretches of silence was equivalent for the ASD and the CTR group overall, as \emph{uhm} was followed by longer silences in both groups and for all analyses. I will therefore report results across groups below. 

When disregarding filled pause duration (as in previous studies), a clear difference in the mean duration of following silence according to filled pause type was found: silences were on average 355 ms longer following \emph{uhm} (mean = 541; SD = 1056) than following \emph{uh} (mean = 186; SD = 517). Further, the proportion of filled pauses followed by a period of silence with a duration > 0 (i.e. not followed directly by speech) was calculated. This was the case more frequently for \emph{uhm} (69.4\%) than for \emph{uh} (45\%). 

As a sanity check, a Bayesian linear regression model with a hurdle log-normal distribution was run to check whether filled pause duration, independent of filled pause type, could actually be shown to be correlated with the duration of the following silence at all. The model output unambiguously confirms this to be the case (mean \(\delta\) = 0.29; 95\% CI {[}0.16, 0.43{]}; \(P(\delta > 0)\) = 1): longer filled pauses clearly tended to be followed by longer intervals of silence.

To conclusively establish whether differences between filled pause types were independent of the fact that \emph{uhm} tokens in themselves were typically considerably longer than \emph{uh} tokens, a model with log-normal distribution was fitted to the duration of the following silence, with speaker and, crucially, duration of filled pause, as random factors.

Results show that silences following \emph{uhm} were indeed longer than those following \emph{uh}, regardless of the duration of filled pause tokens, even though the difference was quite small (150 ms). More details on statistical modelling are reported below.

In the main model, only observations where filled pauses were followed by at least 200 ms of silence (i.e. followed by a new, separate IPU) were included. The difference between types is presented with \emph{uhm} as the reference level. The model output shows the difference to be robust, even though the upper bound of the credible interval is close to zero (mean \(\delta\) = -0.15; 95\% CI {[}-0.28, -0.02{]}; \(P(\delta > 0)\) = 0.97). A second model, including also all cases where the following silence was 0 (using a hurdle log-normal model), confirms the finding in also showing a robust effect for the difference between filled pause types (mean \(\delta\) = -0.12; 95\% CI {[}-0.19, -0.07{]}; \(P(\delta > 0)\) = 1).

\subsection{Summary}\label{BCFP_FP_silent_discussion}

The analyses presented in this section show that there were more long silent pauses in conversations between autistic dyads as compared to non-autistic control dyads. This is broadly in line with results from one of the three previously published studies on the same topic \citep{lakeListenerVsSpeakeroriented2011}, but stands in contradiction to an earlier account \citep{thurberPausesNarrativesProduced1993}. No group differences were found when considering all silent pauses regardless of duration, nor for mean pause duration \citep[similarly to results in][]{engelhardtSpeakerVersusListenerOrientedDisfluency2017}. There was also no between-group difference regarding the effect of preceding filled pause type on subsequent silent pause duration. This stands in contrast to results in \citet{lunsfordAutismUseFillers2010}, where longer silences following \emph{uhm} were found for non-autistic, but not autistic children.







\section {Laughter}\label{sec:BCFP_Laughter}

While an analysis of laughter is not directly related to that of filled pauses (or related discourse markers such as backchannels), there are two reasons for including a preliminary analysis of rates of laughter here. First, laughter by a single speaker (rather than two speakers at once) often falls into the category of \textit{non-Duchenne laughter} \citep{gervaisEvolutionFunctionsLaughter2005,keltnerStudyLaughterDissociation1997,mehuSmilingLaughterNaturally2011}, that is, it is used not to express genuine joy or amusement as a reaction to an outside stimulus, but rather it is self-generated and essentially emotionless. This kind of laughter can be observed in moments of nervousness or hesitation, among others \citep{pietrowiczDimensionalAnalysisLaughter2019,ruchExpressivePatternLaughter2001}. Thus, laughter by a single speaker can be considered to at least sometimes be functionally related to filled pauses such as \emph{uh} or \emph{uhm}. Previous research suggests that individual laughter differs from shared (or overlapping) laughter in both form and function \citep{trouvainConvergenceLaughterConversational2012,trouvainExploringSequencesSpeech2013,trouvainLaughter2017,truongAcousticsOverlappingLaughter2012}. Intriguingly, shared laughter seems to also be correlated with accommodation and convergence in a way that individual laughter is not.

Second, in discussions of the corpus and related results as well as in annotation and analysis of the data itself, it was anecdotally observed that autistic conversations seemed to contain far less laughter. This can also be related to the observations that Map Tasks tended to be completed in a much shorter amount of time in the ASD group and that autistic dyads produced fewer backchannels, in the sense that these patterns might reflect a more goal-oriented or functionally efficient way of navigating the task and the social interaction in itself.

The literature on laughter in ASD is very limited and characterised by inconclusive results, highlighting mainly a high degree of individual variability \citep{hudenkoLaughterDiffersChildren2009,reddySharingHumourLaughter2002} -- indeed, essentially the same can be said about research on the frequency of laughter in non-autistic conversation \citep{trouvainLaughter2017,vettinLaughterConversationFeatures2004}.

For pragmatic reasons, this account is limited to a superficial analysis of rates of laughter, leaving in-depth acoustic, prosodic and contextual analysis for future work. All instances of laughter in the corpus were annotated, counted, and labelled  as being either individual laughter or shared (overlapping) laughter by both interlocutors within a dyad. Any instances where laughter from both speakers overlapped for at least 200 milliseconds were counted as shared laughter.

The corpus under investigation contains 385 bouts of laughter in total. A descriptive analysis at the group level reveals a clear tendency for higher rates of laughter in the CTR group compared to the ASD group, for both individual laughter (ASD: 0.67; CTR: 1.38) and shared laughter (ASD: 0.12; CTR: 0.29); see Figure \ref{fig:LaughterRateGroup}. In other words, non-autistic dyads produced more than twice as much individual and shared laughter than autistic dyads on average. This pattern is supported by analysis at the dyad level. Strikingly, two out of seven ASD dyads did not produce any laughter whatsoever, whereas this was not the case for any CTR dyads, who also produced five out of the six highest overall rates of laughter (across types).



\begin{figure}

{\includegraphics{figures/graphics-LaughterRateGroup-1}
	
}

\caption{Rate of laughter per minute (y-axis) by group (x-axis) and type (shared / individual).}\label{fig:LaughterRateGroup}
\end{figure}

Bayesian negative binomial regression was used to analyse rates of individual and shared laughter per minute, as for the rates of backchannels (\sectref{BCFP_BC_results_BCRate}) and filled pauses (\sectref{BCFP_FP_results_rate}). Output from Bayesian modelling confirms the pattern described above in showing higher mean rates in CTR dyads for both individual laughter (mean \(\delta\) = 1.09; 95\% CI {[}0.02, 2.68{]}; \(P(\delta > 0)\) = 0.95) and shared laughter (mean \(\delta\) = 0.25; 95\% CI {[}0, 0.62{]}; \(P(\delta > 0)\) = 0.95). Although these trends are very strong, the lower ends of both credible intervals are (virtually) at zero, suggesting that observing no difference in laughter rate between groups would be not entirely incompatible with the model, the data and prior assumptions.

Due to the shortage of previous studies, it is not clear whether simply counting the number of bouts of laughter, independent of their duration and other characteristics, is the best shorthand for characterising laughter behaviour, even in a first exploratory analysis such as this one. To complement the analysis of laughter rates described above, \emph{proportions} of laughter relative to dialogue duration were therefore also calculated. To do so, the duration of all instances of laughter (separately for individual laughter and shared laughter) produced within a dyad was summed, and this number was divided by the total duration of the respective conversation. Bouts of laughter are usually both relatively short (mean = 683 ms) and relatively rare (total combined duration of all tokens in the corpus = 263 seconds (\textasciitilde4 minutes) in a corpus with a total duration of 17065 seconds (\textasciitilde5 hours)). As a result, proportion values on a percent scale are very low (ranging from 0 to 0.0311). For ease of computation and analysis, these values were multiplied by 1000, resulting in \emph{per cent mille} (pcm) values, ranging from 0 to 31.1.

Overall, the pattern of results found using the variable of laughter proportion very closely resembles that of results using the variable of laughter rates, thereby strengthening the validity of both measures. Higher laughter proportions were found for the CTR group in terms of both individual laughter (ASD: 7.78 pcm; CTR: 16 pcm) and shared laughter (ASD: 1.77 pcm; CTR: 2.68 pcm). Results are shown by dyad and laughter type in Figure \ref{fig:LaughterProportionDyad}.



\begin{figure}

{\includegraphics[width=1\linewidth]{figures/graphics-LaughterProportionDyad-1}
	
}

\caption{Proportion of laughter in pcm (\emph{per cent mille}; y-axis) by group and dyad (x-axis). ASD group in blue, CTR group in green. Individual laughter represented with inverted triangles, shared laughter represented with diamonds. Dyads are ordered by combined proportion of individual and shared laughter.}\label{fig:LaughterProportionDyad}
\end{figure}

\hspace*{-4.1pt}There was substantial overlap across and considerable variability within groups. The differences between groups were less pronounced for proportions than they were for rates, especially in the case of shared laughter (which was rare across groups and dyads). Accordingly, Bayesian modelling of laughter proportion by dyad confirmed the observed group difference for individual laughter (mean \(\delta\) = 7.63; 95\% CI {[}2.9, 12.27{]}; \(P(\delta > 0)\) = 0.99), as it had done for rate of laughter, but not for shared laughter (mean \(\delta\) = 1.45; 95\% CI {[}-3.55, 6.59{]}; \(P(\delta > 0)\) = 0.69), in contrast to the analysis of laughter rates.

In sum, the ASD group produced considerably less laughter overall than the CTR group. This finding is robust -- and independent of measurement (rate or proportion of laughter) -- for individual laughter, but less clear for shared laughter.











\section{Discussion}\label{sec:BCFP_Discussion}

This chapter discussed the use of backchannels and filled pauses (as well as silent pauses and laughter) in German adults with and without a diagnosis of autism spectrum disorder. This is the first study of backchannels and of filled pauses in conversations between autistic adults.

In the corpus of semi-spontaneous speech under investigation, consistent differences in the rate as well as the lexical and intonational realisation of backchannels in the ASD group were found. Filled pauses differed between groups only in their prosodic realisation. Further, differences between groups were found for the frequency of silent pauses and, in a preliminary investigation, for laughter.

In this section, I will first interpret these results in some more detail and then point out the limitations of the current approach and the resulting potential for future work.


\subsection{Backchannels: Reduced rate and flexibility in ASD}\label{BCFP_Discussion_BC}

The result that autistic speakers produced fewer backchannels per minute than matched controls suggests that autistic individuals are overall less inclined to explicitly (and verbally) support the ongoing turn of their interlocutor. Backchannelling is a prosocial and specifically listener-oriented signal, which, moreover, is not governed by explicit rules and rather seems to follow complex, implicit, culture-specific conventions. Autistic individuals have been reported to show differences in understanding and interacting with their conversational partners. Furthermore, communication styles in ASD have been claimed to differ more from those of their non-autistic peers regarding implicit, rather than explicit, aspects of language. Thus, the analysis of backchannel rates can be linked to more general aspects of ASD.

The fact that there was a greater difference in the rate of backchannels between groups in the early stages compared with the remainder of the dialogue furthermore suggests that ASD dyads eventually produced a backchannelling style quite similar to that of CTR dyads, but that they took a certain amount of time to reach this point (reflecting results from the domain of turn-timing; see \chapref{turntaking}). It can further be speculated that a lower rate of BCs in the ASD group might indicate that autistic speakers focussed more on the collaborative completion of the task at hand, rather than on purely affiliative aspects of social interaction. This interpretation is supported by results from \citet{dideriksenContextualizingConversationalStrategies2019}, who found that (non-autistic) speakers produced a higher rate of BCs in fully free conversations compared with task-oriented conversations \citep[such as Map Tasks; see also][]{janzNavigatingCommonGround2022}.

This observation can also be related to the fact that CTR dyads tended to take far longer to complete the task (mean duration: 26 minutes) than ASD dyads (mean duration: 15 minutes; see \sectref{turntaking_results_signal_signal}). Qualitative assessment clearly confirms that this increased duration was usually not due to greater difficulties with completing the task, but rather due to more conversational content of a purely social nature (essentially \textit{small talk}). This is mirrored by a higher rate of laughter in the CTR group (as shown in \sectref{sec:BCFP_Laughter}) compared to the ASD group. These observations in themselves can be taken, if somewhat speculatively, as further support for the notion that ASD dyads were focussed more on efficient completion of the experimental task and less on purely social aspects of the interaction.

\largerpage
Backchannel productions in the ASD group were also characterised by a less flexible realisation regarding lexical choice. Autistic speakers tended to use a smaller range of different BC types, and in turn often showed a clear preference for one particular lexical type which was used for the majority of tokens. This is analogous to the findings for prosodic realisation: many autistic speakers predominantly used rises, across different BC types, whereas non-autistic speakers tended to show a more complex probabilistic mapping of different (proportions of) intonation contours to different types of backchannel. This pattern held true for all BC types except non-lexical \emph{mmhm}, which was produced with rises in almost all cases by almost all speakers. I will further discuss the special status of \emph{mmhm} and its relation to filled pauses below in \sectref{BCFP_Discussion_BCvsFP}.

Differences between groups aside, the current findings on the prosodic realisation of backchannels are significant in themselves, as earlier accounts (of backchannels in West Germanic languages) instead tended to assume a kind of ‘default’ BC contour (rising) for all different types of BCs. It is interesting to note that the prosodic realisation of the non-lexical BC \emph{mmhm} comes closest to such a simple mapping -- perhaps because its meaning has to be conveyed purely by means of prosody -- and in turn particularly intriguing that many autistic speakers seemed to apply this one-to-one mapping to all different lexical types of BCs (in contrast to non-autistic speakers). This result can also be related to an earlier finding (involving speech from some of the same autistic subjects) according to which the ASD group showed a stronger preference (compared with a control group) for using one particular pitch accent type (H*) over other types \citep{krugerProsodicMarkingInformation2018}.

In sum, the findings reported suggest that a lower rate and a less variable realisation characterise backchannel production in ASD. We can conclude 1) that autistic speakers are less inclined to use BCs in order to support the ongoing turn of their interlocutor in the early stages of a social interaction and 2) that when they do so, productions are less diverse and less flexible. This latter observation can be seen as a specific, micro-level instantiation of the pattern of circumscribed and stereotypical behaviour that is used as a key diagnostic criterion for ASD at the macro level.

While this work is the first study of backchannelling in (semi-)spontaneous conversations between autistic adults, the finding that autistic dyads used fewer BCs is in line with results from the only two related studies published to date \citep{rifaiInvestigatingMarkersRapport2022, yoshimuraTurntakingChildrenAutism2020}. In expanding our perspective beyond ASD, we can further compare the current findings to the extensive literature on BC productions across different cultures. This body of work suggests that listeners are highly sensitive to deviations from a given ``standard" realisation of BCs and that they judge such deviations negatively. It thus stands to reason that the differences in backchanneling behaviour found in the ASD group in the current work might also lead to misunderstandings and negative impressions, at least in interactions with non-autistic interlocutors. I would nevertheless like to stress once again that while a comparative analysis of cross-cultural communication on the one hand and autistic vs.~non-autistic communication on the other hand doubtlessly has a certain heuristic value and intuitive appeal, cultural differences are obviously not equivalent to differences in cognitive style, regardless of phenotypical similarities in certain aspects of social interaction.

\subsection{Filled pauses: Differences specifically in prosodic realisation}\label{BCFP_Discussion_FP}


It was shown that autistic and non-autistic speakers did not differ (at all) in the rate of filled pauses produced, nor in their preference of filled pause type (both preferring \emph{uhm} over \emph{uh}). The only group-level difference detected concerns the prosodic realisation of filled pauses, with ASD speakers producing fewer FPs with the typical level intonation contour than CTR speakers (although both groups did show a preference for level contours overall). Additionally, interlocutors in the CTR group seemed to adapt more to each other in terms of the rate of filled pauses produced compared to the ASD group. It is also interesting to note that the more frequent lexical type \emph{uhm} was less consistently produced with a level contour, across groups, although this could simply be related to the fact that \emph{uhm} was, on average, almost twice as long as \emph{uh}. This increase in duration might in itself have led to the production of more falling contours.

While the study reported here is the first to analyse prosodic aspects of filled pause production in ASD, we can compare the current results on rate and lexical choice with previous studies on these aspects. Superficially, the fact that no differences were found in filled pause rate or preference of type (\emph{uhm} over \emph{uh}) perhaps surprisingly supports the findings from only one study \citep{suhNarrativePerformanceOptimal2014} and stands in contrast to the other relevant findings \citep{gormanUhUmChildren2016,irvineUhUmAutism2016,jonesItImportantFrequency2022,lakeListenerVsSpeakeroriented2011,lunsfordAutismUseFillers2010,mcgregorBriefReportUm2020,parish-morrisLinguisticCamouflageGirls2017}.

A direct comparison with the results reported here, however, is not possible as none of the previous studies investigated semi-structured conversations between autistic adults, instead tending to focus on speech elicited in more highly structured, formal contexts and produced by children (usually interacting with non-autistic adults). A related issue is the inclusion of (autistic and non-autistic) speaker groups with a very wide age range in previous work, leading to one such sample being described as ``children from 8 to 21 years old” \citep[p. 1684]{suhNarrativePerformanceOptimal2014}.

Findings from the only other study investigating filled pause productions by autistic adults \citep{lakeListenerVsSpeakeroriented2011} crucially differ from the findings reported here. No difference in filled pause rate was detected in the current analysis, whereas this earlier study found a lower rate for both \emph{uh} and \emph{uhm} in their ASD group. At the same time, there is an important similarity between this previous study and the current work, as in both cases there is no evidence for a special role of \emph{uhm}, in particular, for distinguishing the behaviour of autistic and control subjects (in contrast to all the studies on autistic children mentioned above). While I do not wish to speculate widely about causes and implications on the basis of two studies, it does seem plausible 1) that the role of \emph{uhm} as being more listener-oriented compared to \emph{uh} may have been exaggerated in some previous research, at least where such conclusions were drawn on the basis of the fact that some autistic speakers seemed to produce \emph{uhm} less often than control speakers, and 2) that continuous development and successful social camouflaging might play important roles in autistic adults behaving more similarly to their non-autistic peers than is the case for children.

More generally, as filled pauses are most prevalent and functionally important in conversational interaction \citep{corleyHesitationSpeechCan2003, foxtreeListenersUsesUm2001}, the external validity of results based on speech elicited through, e.g., highly structured interviews with children \citep{gormanUhUmChildren2016}, picture story narrations \citep{suhNarrativePerformanceOptimal2014} or descriptions of a series of paintings with the added task of simultaneously tapping an index finger as fast as possible \citep{irvineUhUmAutism2016} has to be questioned. Speculations as to the pro-social nature of filled pauses are similarly problematic when they are founded on this kind of speech data. \citet{engelhardtSpeakerVersusListenerOrientedDisfluency2017} rightly point out some important issues in the interpretation of conversational behaviours as being either speaker- or listener-oriented in such contexts (and also criticise the fact that previous research did not appropriately account for individual differences). Somewhat puzzlingly, the authors then proceed to describe production data from a sentence-repetition task, which did not yield a single filled pause token (as might be expected, partly because there is no need in this context to use filled pauses to facilitate the planning of an utterance).

To sum up, as the current analysis did not confirm previous finding of filled pauses being produced at a lower rate in ASD, or that nasal filled pauses (\emph{uhm}) are dispreferred in ASD, it seems reasonable to call into question 1) the causal interpretation of filled pauses as specifically and exclusively ``other-directed” signals \citep[e.g.][]{lakeListenerVsSpeakeroriented2011} and 2) the appropriateness of using characteristics of filled pauses, specifically the production of \emph{uhm}, as a pragmatic or clinical marker for ASD, as has been suggested in previous work \citep{irvineUhUmAutism2016,mcgregorBriefReportUm2020}. In general, the use of \emph{uhm} might well differ from that of \emph{uhm} in important and general ways. For instance, it has been shown that silences following \emph{uhm} are longer than silences following \emph{uh} \citep[\sectref{sec:BCFP_FP_silent}; ][]{clarkUsingUhUm2002}. However, just as no differences between the ASD and the CTR group were found in this regard here, both the results presented in the current work and in the previous study by \citet{lakeListenerVsSpeakeroriented2011} suggest that while the use of \emph{uhm} may differ between autistic and non-autistic children, this is not necessarily the case for adult speakers.


\subsection{\texorpdfstring{Comparing \emph{mmhm} and \emph{uhm}}{Comparing mmhm and uhm}}\label{BCFP_Discussion_BCvsFP}


I proposed in Section \ref{BCFP_FP_background} that, functionally, backchannels and filled pauses are polar opposites, since backchannels are used by listeners to support the ongoing turn of the interlocutor, whereas filled pauses are used by speakers to hold the floor and retain their own turn. In other words, filled pauses are ``the most common way to hold the turn'' for a speaker, while backchannels are signals by the listener that they are ``paying attention to the speaker and\ldots.encouraging him {[}sic{]}'' \citep[pp. 157, 162]{wardProsodicPatternsEnglish2019}. This can be related to the higher rates of backchannels but lower rates of filled pauses found in the speech of instruction followers compared to instruction givers in the current analysis.

With this in mind, consider that the most frequent type of filled pause in the corpus under investigation is \emph{uhm} (n = 600) and the second most frequent type of backchannel is \emph{mmhm} (n = 456). Thus, there are over 1000 cases in which these classes of discourse marker are extremely similar in segmental form (some tokens from both classes are indeed identically produced, as /m/), while having directly contrasting functions in dialogue management.

This brings us back to the observation that the non-lexical backchannel \emph{mmhm} stands out among other BC types, as it was very consistently (in 90\% of cases) produced with rising intonation. Compare this to the filled pause type \emph{uhm}, which was produced with a rising contour in only 12\% of all cases (typically produced with a level contour instead).

\hspace*{-2.1pt}Relevant results from the continuous analysis of intonation contours are shown in Figure \ref{fig:BCvsFP}, confirming that there was very little overlap in the distributions of ST values for \emph{mmhm} (mean = 5.87 ST) and \emph{uhm} (mean = -0.33 ST). Another way to describe the same pattern would be to say that 88.4\% of pitch values for \emph{mmhm} exceeded the 95th percentile of pitch values for \emph{uhm} (1.67 ST).



\begin{figure}

{\includegraphics[width=1\linewidth]{figures/graphics-BCvsFP-1}
	
}

\caption{Mean values for pitch contours produced on the backchannel \emph{mmhm} (in burgundy) and the filled pause \emph{uhm} (in yellow), across groups. Error bars represent one standard deviation from the mean.}\label{fig:BCvsFP}
\end{figure}

I propose that this complementary distribution of intonational realisation is not merely a reflection of the opposing functions of backchannels and filled pauses, but may be causally related to it. Following this hypothesis, speakers are (at least implicitly) aware of both the contrast in function and the similarity in segmental form between \emph{mmhm} and \emph{uhm} (and the absence of lexical meaning in both cases) and therefore use suprasegmental features (i.e.~intonation) in order to distinguish between \emph{mmhm} and \emph{uhm} in order to ensure accurate transmission of their communicative intent. While it is true that the potential for misunderstanding is limited by the fact that \emph{uhm} is usually (but not always) uttered by speakers (turn-holders) whereas \emph{mmhm} is almost exclusively uttered by listeners, this does not negate the facts that 1) the similarities in segmental form remain a potential source of confusion, 2) listeners are highly sensitive to \emph{any} deviances in the precise realisation of discourse markers and 3) redundancy of this kind is not an unusual feature of spoken communication in general \citep{winterSpokenLanguageAchieves2014a,winterCoevolutionSpeechLexicon2016,corettaMultidimensionalSignalsAnalytic2023,aylettSmoothSignalRedundancy2004}.

In sum, I have suggested that the contrasting functions of filled pauses and backchannels are reflected in their prosodic realisation. Specifically, there is very little overlap in the intonation contours used for the segmentally similar backchannel type \emph{mmhm} (typically rising) and the filled pause type \emph{uhm} (typically level).


\subsection{Silent pauses}\label{BCFP_Discussion_silent}

In expanding the current investigation beyond backchannels and filled pauses (and silent gaps), evidence was presented for a robust tendency towards a higher rate of long silent pauses in conversations between autistic compared to non-autistic dyads, while at the same time many similarities in the silent pause use of both groups were found.


While differences were thus rather subtle overall, the higher rate of long silent pauses in the ASD group is still likely to have a discernible effect on spoken interaction \citep{dejongChoosingThresholdSilent2013,goldman-eislerPsycholinguisticsExperimentsSpontaneous1968}, and might thus contribute to perceptions of a difference in communication styles. This is all the more true when considering that the current work provides evidence for idiosyncratic behaviour by the same autistic speakers in the related domain of turn-timing, where they produced more long silent gaps between speakers compared to non-autistic dyads (but only in the early stages of conversations; see \chapref{turntaking}).

Besides uncovering group differences in silent pause use, the current study replicates the finding that silences tend to be longer following \emph{uhm} compared to \emph{uh} \citep{clarkUsingUhUm2002}. The analysis presented here does not merely provide a replication, however, but rather extends and qualifies the original finding, as the duration of filled pauses was added as a random factor in a Bayesian regression model. This way, it could explicitly be shown that the effect described is independent of intrinsic filled pause length (importantly, as \emph{uhm} tends to be longer than \emph{uh}).

 Moreover, the current results suggest that the effect of longer silences following \emph{uhm} compared to \emph{uh} is more subtle than previously described. While a two-fold difference in silence duration according to filled pause type is reported in \citet{clarkUsingUhUm2002}, a difference of only 150 ms (with an average silent pause duration of 646 ms) when factoring in filled pause duration was found in the analyses presented here. It is not obvious how relevant such a relatively small difference might be in real-life spoken interaction -- this question will have to be left open here and is hoped to inform future perception experiments.

 
\subsection{Limitations}\label{BCFP_Discussion_limitations}

There are a number of limitations to the approaches used here to analyse backchannels and filled pauses.

First, it has to be acknowledged that task-based rather than fully free conversations were investigated. The experimental setup also deliberately limited participants to the spoken modality by placing an opaque barrier between them during the Map Task experiment. There is little doubt that visual signals such as head nods, gesture and eye gaze can be used in ways that are functionally equivalent to spoken backchannels \citep{bevacquaMultimodalBackchannelsEmbodied2010, hjalmarssonGazeDirectionBackchannel2012, meschManualBackchannelResponses2016, oertelGazePatternsTurntaking2012, saubestyMultimodalAnalysisHand2016, szatrowskiRelationGazeHead2000} and filled pauses \citep{beattiePlanningUnitsSpontaneous1979,broneEyeGazeViewpoint2017,kosmalaPreliminaryStudyHesitation2017} and that there is a complex interplay between these modalities in fully natural conversation. Despite these constraints, I am confident that the elicitation method used here constitutes an improvement over those used in related studies and described above, foremost because it enables us to analyse social \textit{interactions} between \textit{disposition-matched} interlocutors \citep[cf. ][]{dingemanseSingleMindednessFigureGroundReversal2023}.

Second, the current analysis is limited to a quantitative account, as no analysis of the conversational context of backchannel and filled pause productions can be provided in the scope of this work. Similarly, analysing the interaction of different functional types of hesitations and feedback signals (e.g. passive recipiency vs. incipient speakership) with lexical and prosodic realisation holds promise for future investigations \citep{jeffersonNotesSystematicDeployment1984, jurafskyLexicalProsodicSyntactic1998, savinoIntonationalStrategiesBackchanneling2010, sbrannaBackchannellingLanguagesRate2022,sbrannaUseBackchannelsOther2023}.

Third, a specific methodological limitation concerns the prosodic analysis of BCs and filled pauses. In this account, the difference in pitch between two fixed time points was calculated (near the beginning and the end of each token) to represent intonation contours (having discarded all tokens for which the calculation of pitch was unreliable). As backchannels and filled pauses are very short (<500 ms in almost all cases), this somewhat simplified view does still capture the essential qualities of intonation contours and is perceptually valid. Nevertheless, the method used cannot reliably account for very fine-grained details of intonational realisation and adequately capture more complex contours such as rise--fall--rises. Future investigations might avoid these shortcomings by using more temporally fine-grained techniques such as polynomial modelling \citep{belzPitchCharacteristicsFilled2015}, generalised additive mixed modelling \citep{soskuthyEvaluatingGeneralisedAdditive2021} or analyses in the ProPer framework \citep{albertUsingPeriodicEnergy2018,albertModelSonorityBased2023,albertProPerPROsodicAnalysis2020,cangemiModellingIntonationSegments2019}. Explorations of the data set under study with the latter two methodologies suggest, however, that the very short durations of individual tokens can be problematic for analysis in at least these frameworks, and that achieving an improvement over the current intonational analysis is therefore not guaranteed. Alternatives to the analysis and modelling of intonation contours will be explored in more detail in forthcoming work. 

 Finally, a limited sample of subjects from one extreme end of the autism spectrum (verbal, socially relatively skilled and motivated individuals with average or above-average IQ) was investigated for the current work. The data at hand do not allow us to generalise the present findings to interactions between disposition-mixed dyads (ASD--CTR) or to fully spontaneous, multi-modal interaction (see \sectref{Conclusion_discussion_HFA}).


