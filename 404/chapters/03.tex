\chapter{Intonation style} \label{intonationstyle}

\section{Introduction}\label{sec:int_intro}

In this part of the book, I focus on what I term intonation style, and on how it characterises the speech of autistic adults. The definition of intonation style is based on previous accounts of what the speech melody of certain speakers or groups of speakers ``sounds like''. If this sounds vague, it reflects the fact that there simply is no single unified account of how to define or quantify such global impressions of the prosodic characteristics of speech. Neither is there an established term that has consistently been used for the corresponding descriptions. I have chosen to refer to intonation styles, then, in an attempt to bring together insights from diverse accounts that share the aim of describing the prosodic features of speech mainly along the dimensions of liveliness and melodicity \citep[a term used in related work by][]{hindRegularityMelodicityStereotyping1999,hindMetricalPatternsMelodicity2002}. I will pick up on the lack of consistent terminology again in discussing issues concerning the measurement and description of intonation styles in the following.

Intonation style has featured in research on autism starting with the very first descriptions in the 1940s. However, there is no clear consensus on what actually characterises the speech melody of autistic speakers. Also starting from the very first accounts, researchers have offered a vast range of mutually exclusive adjectives to account for what supposedly makes autistic intonation ``atypical''. These range from ``robotic'' or ``monotonous'' to ``melodic'' and ``singsongy''.

I will begin by reviewing the literature on the topic and in the process attempt to point out some reasons for this ambiguity. I suggest that, besides the underlying issue of the high degree of inter-individual variability in ASD, various factors are at play. These include the limited sample of the autistic population used in experimental studies (mostly English-speaking children), the methods used for eliciting speech (mostly unnatural) and the measures and analytical techniques employed (often vague or simplistic).

Following this, I present a novel method for capturing intonation styles and its application to the corpus of semi-spontaneous speech by 28 autistic and non-autistic German speakers investigated in this book. The results lend support to accounts describing a more melodic intonation style in ASD, but not to accounts describing a more monotonous intonation style.

I will conclude by summarising the results, putting them into a broader perspective and stating the limitations of the approach and the data at hand.

Parts of the background (\sectref{sec:intonation_background}) and an account of a prototype of the methodology described in the analysis (\sectref{sec:intonation_analysis}) have previously been published in \citet{wehrleSomewhereSpectrumRobotic2018,wehrleNewEvidenceMelodic2022c}. Key results presented in this chapter have been reported in \citet{wehrleAssessingIntonationStyle2020, wehrleNewEvidenceMelodic2022c}.



\section{Background}\label{sec:intonation_background}

At first glance, judging a speaker's intonation style seems to be a comparatively straightforward task. Listeners intuitively form impressions based on intonation, among other things, in many different contexts and without conscious effort. Putting such impressions into words with any degree of accuracy and confidence is a much more difficult task, however. This often results in the use of a very limited range of terms, with notions like robotic (i.e.~flat or monotonous) or singsongy (i.e.~lively or repeatedly spanning a large range) used as two endpoints of the same scale. An even greater challenge lies in the formation of scientifically testable operationalisations, which in itself presupposes the existence of measurements accurate enough to uncover the underlying features and parameters of intonation styles.

In \sectref{sec:intonation_analysis}, I present a novel method of measurement capable of reliably quantifying intonation styles. An application of this method to the speech data from the corpus of conversations between autistic and non-autistic speaker pairs analysed in this book is reported in \sectref{sec:intonation_results}.

In the following section, I will first give some background on the linguistic interest of intonation styles in general before examining the case of ASD in particular and pointing out methodological issues surrounding the description and measurement of intonation styles.

	\subsection{The linguistic interest of intonation styles}\label{int_back_interest}

Intonation styles in general are of interest to linguists for a number of reasons. First, they are characteristic properties of individual speakers. Besides the character attributions formed in everyday spoken interaction, this facet of individual specificity is of interest from both a more practical and a more theoretical standpoint. Practical applications include forensic phonetics and emotion profiling  \citep{laddEvidenceIndependentFunction1985, mohammadiSpeechPersonalityMapping2012}. Regarding theory, the issue is pertinent both to the long-standing debate around the concept of idiolects \citep{paulPrincipienSprachgeschichte1880} and to the more recent, related debate about individual grammar networks \citep{cangemiListenerspecificPerceptionSpeakerspecific2015}.

Second, intonation styles are relevant for describing the behaviour of specific groups of individuals (within a language community). Intonation has featured particularly prominently in research on the speech of autistic persons \citep[see][]{griceLinguisticProsodyAutism2023,mccannProsodyAutismSpectrum2003a}. Surveying previous work on the topic, there seems to be a broad consensus that many speakers with ASD produce ``atypical'' intonation. Quite what this means, however, and how it can be measured, is less clear. These issues will be discussed further in \sectref{int_back_ASD}, dedicated to an in-depth discussion of intonation styles in ASD, and \sectref{int_back_measures}, focussing on methods and measurements that have been used to capture intonation style.

Third, intonation styles are also very relevant for the description of language varieties. There is abundant evidence for the influence of intonation styles on impressionistic judgements of different dialects. Data in \citet[p. 258]{kuiperParisianPerceptionsRegional1999} show that Parisians consider the Proven\c{c}al variety of French to be ``singsongy'', whereas they consider the Alsatian variety of French to be ``jerky'' \citep[see also][]{nolanIntonation2006}. While it is always difficult to isolate such attributions from the wide range of cultural factors and stereotypes that may play a role, intonation styles in and of themselves are almost certain to be one crucial factor underlying such judgements. Intonation styles are in turn shaped by the phonological properties of the regional variety spoken. For instance, the varieties of French spoken in southern France are characterised by the production of clearly audible final schwas (mid central unstressed vowels) that would be much less prevalent in e.g.~Parisian French \citep{coquillanFrancaisMeridionalElements2010}. This extends the segmental material available for the production of intonation contours and thereby provides an opportunity for more pitch movement \citep{griceWordFinalSchwa2018,torreiraMelodicConstructionsSpanish2018}. Although this phonological change does not necessarily lead to a more lively intonation style, it is likely to be one of the factors underlying the impression of singsonginess in this variety.

Fourth, intonation style is also related to the choice of register in speech. For instance, melodic intonation seems to be characteristic of infant-directed speech (IDS) \citep[e.g.][]{holmesIntroductionSociolinguistics2013}. More melodic or even exaggerated intonation styles have been shown to correlate not only with better mother--infant bonding, but also with higher intelligibility and, as a consequence, with better language development in later life \citep{kuhlPhoneticLearningPathway2008,liuAssociationMothersSpeech2003}. Livelier pitch movement has furthermore been linked to speech by adults talking to (perceivedly) more attractive conversation partners \citep{leongomezVocalModulationCourtship2014}. Why a more melodic intonation style might be used in such contexts is not entirely clear, but the choice of speech style in courtship is probably not orthogonal to experiences of, and positive associations with, IDS (as described above). More generally, lively intonation styles can be seen as indicative of evolutionarily desirable traits such as vitality and a lack of threat. Converging evidence can be found in studies reporting a \emph{decreased} variability of fundamental frequency (f0) in conversational contexts marked by competition and high aggressiveness \citep{hodges-simeonDifferentVocalParameters2010}.

Finally, intonation styles are an important consideration in research on bilingual and second-language speech.
It has been suggested that different languages can be described as, on the whole, having narrower or larger overall f0 ranges relative to one another. For instance, Dutch and Japanese have been shown to have an overall narrower f0 range than English while Swiss German and Norwegian have been shown to have an overall wider f0 range than English \citep{celce-murciaTeachingPronunciationReference1996,grahamFundamentalFrequencyRange2014}. \citet{celce-murciaTeachingPronunciationReference1996} compare data describing the f0 range of English learners' various native languages (L1) with their productions of English as a second language (L2). Their results suggest that a speaker's f0 range in the respective L1 is transferred to the L2, with e.g.~Dutch-accented English described as sounding ``somehow flat'' and Swiss-German-accented English said to have ``a somewhat sing-songy quality'' \citep[p. 193]{celce-murciaTeachingPronunciationReference1996}.

	\subsection{Intonation style in autism}\label{int_back_ASD}

 As adumbrated above, the picture emerging from previous reports on intonation in ASD is far from conclusive. Quite remarkably, seemingly contradictory statements on intonation style in autistic speech even go back to the very first descriptions of autism. Sixteen pages into his landmark report, \citet{kannerAutisticDisturbancesAffective1943} describes one of the 11 subjects portrayed, Herbert B. (``Case 7"), as uttering ``sounds in a \emph{monotonous singsong} manner'' \citep[p. 232; emphasis S. W.]{kannerAutisticDisturbancesAffective1943}.

 Similarly, \citet{aspergerAutistischenPsychopathenIm1944a} in the original German refers four times to \emph{Singsang} as characteristic of speech by the children he describes (pp.~87, 89, 93, 114), but equally notes that speech ``proceeds\ldots{}\emph{monotonously}, without rising or falling'' (p.~114; emphasis and translation S. W. -- the standard English translation by Uta Frith does not capture this subtlety; cf. \citet{aspergerAutisticPsychopathyChildhood1991} p. 70\footnote{Original: ``{{[}die Stimme{]} geht\ldots monoton dahin, ohne Hebung und Senkung}''}).

While this descriptions might seem to be contradictory, it is important to remember that not only is the terminology used problematic (see below), but also that when describing more than one autistic individual, a high degree of variability should be all but expected. As we will see, apparent contradictions in autism research often seem to be partly due to the related failures of 1) not adequately taking into account individual specificity and 2) not acknowledging the importance of the quintessential and intrinsic heterogeneity across the autism spectrum.

	\subsubsection{A note on terminology}\label{int_back_ASD_terminology}

The use of the terms monotonous and singsongy is problematic in itself, especially when these terms are used subjectively and without reference to any specific kind of measurement or rating scale. As the above quote from \citet{kannerAutisticDisturbancesAffective1943} shows, the two terms might in fact be used to refer to one and the same intonation style.

The issue seems to lie mostly with the use of the term \emph{monotonous}. This can be understood either as referring to a sameness of pitch, in the truly ``robotic'' sense, or as being simply unvarying, in a tedious manner (imagine the siren of a fire truck). This latter meaning is much more open to interpretation and is reminiscent of Kanner's description of a ``monotonous singsong''. Such an intonation style can then be imagined as being indeed singsongy, but in a stereotyped, repetitive manner, resolving the apparent contradiction. We also have to note that, quite problematically, the term singsongy can in fact be used with precisely and exclusively the above meaning, i.e. when it is taken to imply a repetitive melodic structure (often aided by rhythmic isochrony) that does not necessarily feature many changes in pitch. This stands in contrast to the usage in this chapter, where sinsonginess always implies a high degree of liveliness, melodicity and pitch dynamics. I will pick up on this terminological difficulty in Section \ref{int_back_ASD_evidence_monotone}.

Occasionally, the term \emph{monotone} is used in place of monotonous. This usage seems to be more clearly with reference to a flat, robotic intonation style, but even here the dictionary definition is not unambiguous and allows for interpretations of sameness and tedium. In Section \ref{int_back_measures_LTD} I try to clarify the issue to some extent while introducing yet another closely related term, i.e.~of a function being \emph{monotonic} in the mathematical sense.

To add to the confusion (or possibly bearing a causal relation to it), all three terms -- monotonous, monotone and monotonic -- translate to the same word,\emph{mo\-no\-ton}, in German. It is hence impossible to know precisely which nuance \citet{aspergerAutistischenPsychopathenIm1944a} was aiming to convey in the excerpt cited above.

For the purposes of this book, I resign myself to using \textit{monotonous} with the meaning of flat, unchanging pitch, in contrast to speech that is is \textit{singsongy} in the sense of being melodic (or lively) and featuring many perceptible changes in pitch (occasionally substituting or adding the terms \textit{robotic} or \textit{monotonic} for reasons of style and clarity).

\subsubsection{Evidence from previous research}\label{int_back_ASD_evidence}

In the following sections, I will take a closer look at some key studies describing intonation style in ASD. I will conclude by highlighting shared commonalities and contradictions in an attempt to identify possible causes for the lack of coherence and common conclusions. Please note that the vast majority of investigations into the communication of autistic individuals has been based on data from (English-speaking) children or adolescents, not (German-speaking) adults, as in the current work. Studies on intonation style are no exception. Accordingly, unless otherwise noted, the studies summarised in the following are based on data from (English-speaking) children or adolescents.

The following account is by no means intended to serve as an exhaustive review of prosody in ASD. For an in-depth and up-to-date overview,the interested reader is referred to \citet{griceLinguisticProsodyAutism2023} and \url{https://ifl.phil-fak.uni-koeln.de/phonetik/forschung/prosody-on-the-spectrum}.


\subsubsubsection*{Evidence for melodic intonation styles in ASD}\label{int_back_ASD_evidence_singsong}


I will begin this survey with studies reporting more melodic intonation styles in autistic individuals. In total, such findings clearly outweigh those showing the opposite, i.e.~a more monotonous intonation style in ASD. While claims to either effect have been made in the past, more recent research has quite clearly tipped the scales in favour of more melodic, not more monotonous, intonation styles as being characteristic of speech in ASD.

\citet{simmonsLanguagePatternsAdolescent1975} found that speech in ASD is characterised by what could be described as more melodic intonation, or more specifically, speech with excessive pitch variation. They analysed the language of seven adolescents and young adults ranging in age from 14 to 21. There was no control group. The authors describe the speech elicitation process as ``informal''. The speech data elicited were clearly not spontaneous, however, as the autistic subjects, variously described as ``isolated'', ``aggressive'' or ``naive'' by the authors, were asked a set series of questions by (presumably) the experimenters, certainly by non-autistic adults unfamiliar to them. These questions ranged from the ``informal'', such as ``Where do you live?'', to the ``abstract'', such as ``What do you think of the Vietnamese War?'' \citep[p. 336--338]{simmonsLanguagePatternsAdolescent1975}.

Speech was analysed following the list of criteria used by \citet{goldfarbSpeechLanguageFaults1972}, who investigated language in children with schizophrenia. The relevant criteria and the assessment are rather subjective \citep[as acknowledged by][]{simmonsLanguagePatternsAdolescent1975} and wide-ranging. The most relevant criteria for our purposes are ``excessive variation'' of pitch level (see their Table II; p.~339) as well as ``excessive pitch rise for stress'', ``excessive inflection'' and ``stereotyped (singsong)'' intonation (see their Table III; p.~340). Simmons and Baltaxe ticked the boxes for all these criteria for the same four out of seven participants in their sample (probably reflecting the unclear distinction between some of these criteria in part). In sum, the study seems to show a trend for singsongy speech in ASD, but only for slightly more than half of all autistic participants -- a pattern that, as we will see, mirrors the present findings in more ways than one.

 In a more recent study, \citet{nadigAcousticPerceptualMeasurement2012} report more melodic speech in the guise of expanded pitch range in a group of speakers diagnosed with ASD. They tested 15 autistic children aged 8 to 14, with 13 matched non-autistic children as a control group. Subjects were recorded in conversation with an unfamiliar adult research assistant in what is somewhat vaguely described as a ``comfortable lab setting'' \citep[p. 4]{nadigAcousticPerceptualMeasurement2012}.

 The data used for acoustic analysis in the first part of the study is quite severely limited in both quantity and quality. The authors chose to analyse only ``audio of the longest uninterrupted segment of each child's speech'' (p.~5). Concretely, this means that for each individual only about 11 seconds of speech data was available. Additionally, this speech sample was by definition far from representative of participants' general speech style in being far longer than the average utterance. Nadig and Shaw do not provide information on average utterance duration in this part of the task, but in the later structured task that was part of the same study (see below), the average utterance duration was 2 seconds (comparable to the average IPU length of 1.4 seconds in the corpus analysed here).

 The peculiar filtering of data performed by the authors is problematic not only as it entails excluding the vast majority of speech data recorded, but also because it is highly likely to have a direct bearing on the variable of interest (pitch range). Unusually long utterances can be expected to be produced with a more animated, lively speech style in general, and indeed a clear positive correlation between utterance length and melodicity was found in the corpus analysed in this book \citep[see also][]{demoraesIntonation1998,cooperFundamental1981}. If we add to this the fact that sound was recorded through a single, ceiling-mounted microphone, leading to ``sound quality {[}that{]} was not always ideal and sometimes contained environmental noise'' (p.~5), it is not clear how valid any findings based on these data alone can be.
 
In any case, for this part of the experiment, \citet{nadigAcousticPerceptualMeasurement2012} report a significantly higher pitch range for the ASD (median = 200 Hz) compared to the control group (median = 124 Hz). Mean values and standard deviations are not reported. Unfortunately, the data are also not available for inspection and independent corroboration. The authors report no difference between groups for mean pitch (mirroring the results reported here; see Section \sectref{int_results_overall_comparison_meanfzero}).

As a second part of the study, Nadig and Shaw ran subjective perceptual tests performed by non-autistic subjects listening to data from the first part of the study. Contrary to results from production, the perceptual ratings of both pitch range and mean pitch revealed no significant group differences. There was a significant difference only in ratings of ``overall impression'', which were given on a reduced, four-point Likert scale ranging from ``normal'' to ``atypical''.

Finally, the same autistic participants as in the first task were recorded performing a structured task. This task consisted of the children describing one out of four household objects. Compared to the first task, this yielded more and more varied data (8 to 15 utterances per child, with a mean duration of 2 seconds). However, ecological validity is a real concern in this particular setting, as the speech elicited was monologic and decidedly non-spontaneous. Similarly to the conversational data described above, results for this part of the task reveal a slightly higher mean pitch range for the autistic participants (156 Hz) compared to control participants (122 Hz), but no difference in mean pitch.

Despite the methodological shortcomings of parts of this work, the results in \citet{nadigAcousticPerceptualMeasurement2012} reveal a clear tendency towards more melodic speech in ASD, and, crucially, do not give any indication whatsoever of the opposite, i.e.~a robotic or monotonous intonation style.

Other studies providing evidence for an expanded pitch range in ASD include \citet{fosnotProsodicCharacteristicsChildren1999,edelsonEmotionalProsodyChildren2007,hubbardIntonationEmotionAutistic2007,diehlAcousticAnalysisProsody2009} on English as well as \citet{shardaSoundsMelodyPitch2010} on Hindi and \citet{chanIndividualsHighfunctioningAutism2016} on Cantonese. I am not aware of any pertinent results on autistic speakers of German.

\subsubsubsection*{Evidence for monotonous intonation styles in ASD}\label{int_back_ASD_evidence_monotone}

Although some authors (including ourselves in previous work) have claimed that a monotonous speech style has in the past been generally assumed to be the typical intonation style for autistic speakers \citep{nadigAcousticPerceptualMeasurement2012,wehrleSomewhereSpectrumRobotic2018}, closer investigation reveals that there is hardly any \emph{unambiguous} evidence for this assertion. Take the pioneering work of \citet{kannerAutisticDisturbancesAffective1943}, which is often cited as an example for descriptions of monotonous speech in ASD. As pointed out above, the only direct reference to intonation here is the highly ambiguous description of utterances produced by an autistic child in a ``monotonous singsong manner'' (p.~232). What this use of ``monotonous'' here and in many other early studies \citep[including][]{aspergerAutistischenPsychopathenIm1944a} seems to actually refer to is a general impression of repetitive or constrained behaviour (rather than a flat intonation style, specifically). Repetitiveness, however, can be just as much a part of a typically singsongy as of a typically monotonous speech style. In Kanner's concrete example, it probably refers to a speech style perceived as repetitive due to being particularly invariable or inflexible in nature.

\hspace{-2.5pt}I have indeed not been able to find any clear indications of a purely monotonous speech style in the literature, certainly not any based on pitch range or similar acoustic measures. However, there are some related findings that make claims to the same effect based on investigations of pitch accent choice and placement within the framework of autosegmental-metrical intonational phonology \citep{laddIntonationalPhonology2008}. \citet{kalandAccountingListenerComparing2013}  primarily investigated the intonational marking of contrastiveness by Dutch adults (not children as in all studies above) with and without a diagnosis of ASD, having elicited speech with a bingo-like game. The authors show that the productions of Dutch autistic adults are characterised by less variation in pitch accent types as well as a narrower pitch range, and that productions were judged by listeners to sound ``less dynamic''.

Despite some minor methodological issues, these results genuinely seem to reflect a more monotonous speech style in Dutch-speaking autistic adults. It is interesting to note that this study in particular stands out for not investigating the speech of either children or native English speakers. It is impossible to ascertain what role these factors might play without further work on adults and speakers of languages other than English. The results from the corpus investigated here, based on speech from adults speaking a closely related West Germanic language, however, do not support such an account of more monotonous speech in ASD in any way. Further, the work of \citet{kalandAccountingListenerComparing2013} seems to stand alone in making such a claim, as all other studies that also find monotonous intonation in ASD simultaneously find evidence of singsongy intonation, as laid out below.

	\subsubsubsection*{Evidence for both singsongy and monotonous intonation styles in ASD}\label{int_back_ASD_mixed}

In the following, I briefly summarise studies that show results consistent with \emph{both} less melodic speech \emph{and} more melodic speech in ASD within the same respective sample population.

\citet{greenProsodicAnalysisDifficult2009} recorded 10 Hebrew-speaking children with and 10 He\-brew-speaking children without a diagnosis of ASD \citep[see also][]{greenIntonationHebrewspeakingChildren2009}. The authors elicited both read and spontaneous speech. Results show that the ASD group as a whole had an extended pitch range compared to the control group. However, typically for the inherent variability in ASD, the authors identified three distinct subgroups within the 10 ASD children: those with narrow, wide or, typical pitch range. This suggests that there were some individuals with more melodic speech and some with less melodic speech as compared to the control group.

Green and Tobin also carried out a categorical analysis in the tradition of auto\-segmental-metrical intonational phonology and ToBI annotation conventions \citep{beckmanOriginalToBISystem2004,greenIntonationHebrewSpeaking2008}. In this framework, the authors simultaneously found greater variation and a more repetitive use of pitch accent tones as well as a limited repertoire and more repetitive use of specific edge tones. This pattern is again consistent with both a more melodic and a more monotonous intonation style in ASD.

Thus, although results are not presented in exhaustive detail, it seems clear that both the acoustic and the phonological analysis in \citet{greenProsodicAnalysisDifficult2009} suggest that ASD intonation style can be in line with control behaviour but also deviate towards either extreme, that is, towards a more melodic intonation style on the one hand and a more monotonous intonation style on the other. This is, again, indicative of the heterogeneity we can expect to find within any group of individuals diagnosed with ASD and also of the fact that we cannot expect communicative behaviour to reflect an idealised clear line of demarcation separating all participants with a diagnosis of ASD from all those without.

Other studies supporting the view that both more and less melodic speech can be found within a given sample of autistic speakers include \citet{baltaxeUseContrastiveStress1984,rapinAutisticChildrenDiagnosis1991} and \citet{depapeUseProsodyInformation2012}.

	\subsubsubsection*{Causes for conflicting results}\label{int_back_causes}

There are at least three possible reasons for the uncertainty regarding the nature of intonation styles in ASD. First, the speech data used in previous studies were usually elicited through reading tasks, narrations, task-oriented conversation (as in this work) or structured interviews, none of which are guaranteed to yield examples of natural intonation \citep{deruiterInformationStatusMarking2015,griceIntonationQuestionsBari1997,spaniolMultimodalSignallingInterplay2023,kuglerDIMA2015}.

Second, as pointed out at various points above, speakers diagnosed with ASD constitute a very heterogeneous group, characterised by a high degree of individual variability. If speaker- and dyad-specific behaviour is not appropriately taken into account, as has all too often been the case in previous research in this and related fields, averaged values alone cannot be expected to paint a realistic picture of either the behaviour of the group as a whole or of any of the individuals within it \citep[cf.][]{cangemiSpeakerspecificIntonationalMarking2016}. A particularly important aspect of individual specificity in this particular case is that of age. The vast majority of previous studies only tested children or adolescents and/or featured very wide age ranges. This is not only problematic in itself, but also because, with age, many autistic individuals learn to employ compensation mechanisms in order to attenuate any behaviours that they have felt (or have been told) might make them appear unusual or conspicuously different from their non-autistic peers -- but of course we neither can nor should assume that all autistic people indeed wish to camouflage such behaviours.

Third, where past research on intonation styles has gone beyond subjective impressions, it has often relied on vaguely defined and technically underspecified terms which do not stand up to rigorous empirical investigation. In the next section (\sectref{int_back_measures}), I aim to show that traditional measures are in principle not even capable of distinguishing stereotypical cases of robotic and singsongy speech.

To recap, despite the clear relevance of intonation styles to manifold aspects of language and to various levels of linguistic inquiry, the methods employed to measure, analyse and describe them have been far from uniform in past research. More importantly, it seems reasonable to question the adequacy of even the more common of such measures. To the best of my knowledge, there is nevertheless no (published) work dedicated specifically to tackling the issue of how to best quantify intonation styles. The current suggestions on how to ameliorate this situation were first described in \citet{wehrleSomewhereSpectrumRobotic2018}, and I will summarise the approach in the following paragraphs.

	\subsection{Measuring intonation style: Past practice and new directions}\label{int_back_measures}

While the characterisation of intonation styles has often been ill-defined and in the end achieved only through subjective listener judgements, there is a long tradition of studies investigating the closely related concept
of pitch range \citep{laddEvidenceIndependentFunction1985,lehistePhoneticStructureParagraphs1975}. Together with the similarly widely used measure of mean f0 in the description of prosody, these measures form the core of a number of approaches that have aimed to capture the levels and fluctuations of a given speaker's minimum and maximum pitch values.

The most recent and widespread characterisation of pitch range can be found in the work of \citet{mennenCrosslanguageDifferencesFundamental2012a} and subsequent work by e.g. \citet{urbaniPitchRangeItalians2013} and \citet{grahamFundamentalFrequencyRange2014}. In this approach, pitch range is essentially described through a combination of linguistic and distributional parameters. This method will be critically analysed in the next section and followed by suggestions for how it may be complemented and refined, with the ultimate aim of better capturing and representing different kinds of intonation styles.


	\subsubsection{Linguistic measures}\label{int_back_measures_linguistic}


The idea of using so-called ``linguistic measures'' for determining pitch range originates with \citet{laddModellingIntraandInterspeaker1995} and is fleshed out in \citet{pattersonLinguisticApproachPitch2000}. The key feature of this approach lies in the identification of ``linguistically relevant landmarks'' \citep{mennenCrosslanguageDifferencesFundamental2012a} in the f0 contour. These landmarks are subsequently used in place of global, purely instrumentally determined minima or maxima for the calculation of a speaker's f0 range.
In practice, this entails first reducing the f0 contour of a given utterance to a series of either high or low turning points. These points are then labelled as phonological tones, and averaged values are calculated within equivalent labels.

This approach has proven itself useful and yielded convincing results in the application to a number of different languages. Nevertheless, some aspects of the method suggest that there might be room for improvement in alternative approaches. For instance, the central operationalisation inherent in this method is rooted less in theoretical deliberations, but rather in purely pragmatic reasons, as pointed out by \citet{mennenCrosslanguageDifferencesFundamental2012a} themselves:

\begin{quote}
	Our decision to assume a direct relationship between turning points and phonological tones was driven by practical reasons so as to ensure consistency in our labelling. However, tones and turning points may not necessarily map in a one-to-one fashion, so that some tones may not be realized as turning points and some turning points may not constitute an underlying phonological tone \citep[footnote 3]{mennenCrosslanguageDifferencesFundamental2012a}.
\end{quote}

More importantly, the value and validity of intonational labels has come under increasing scrutiny and critical re-examination in recent years \citep[see the contributions in][]{dimperioAdvancingProsodicTranscription2016}. The method for measuring pitch range described above fundamentally relies on intonational labels, as they form the \emph{starting point} for further analysis by providing a symbolic reduction of the continuous phonetic signal. This is consistent with a widespread approach in intonation research, used in studies from \citet{hirstIntonationSystemsSurvey1998} to \citet{hualdeInternationalProsodicAlphabet2016}.

However, recent research strongly suggests that it might be more fruitful to take the opposite approach and use intonational labels only as the \emph{outcome} of phonological analysis \citep{cangemiImportanceDistributionalApproach2016,frotaSurfaceStructureTranscribing2016}. In this approach, the use of phonological labels requires an evaluation of intonational meaning and of prosodic structure, rather than a discretisation of the phonetic signal. More recent developments go one step further by embracing this perspective while at the same time proposing a new method of analysis which promises to avoid many of the issues that are all but intrinsic to the practices of segmenting and labelling speech \citep{albertUsingPeriodicEnergy2018,albertModelSonorityBased2023,cangemiModellingIntonationSegments2019}.

	\subsubsection{Long-Term Distributional measures}\label{int_back_measures_LTD}


The second pillar of the method employed by \citet{mennenCrosslanguageDifferencesFundamental2012a} (and others), besides turning points based on symbolic labels, takes the form of so-called ``Long-Term Distributional'' (LTD) measures. These measures are used to describe the range, mean, skewness and kurtosis of the distribution of f0 values. Using LTDs is an appropriate, even sophisticated way for describing pitch range, compared to earlier methods. LTDs are, however, still not ideal for exploring intonation styles, as illustrated in the following example.

Consider the f0 contour in Figure \ref{fig:Monotonic}. This contour is stylised to the point that it would never be found in human speech data, but what it does give us is a useful idealisation of an f0 contour that would deserve the label \textit{robotic}.



\begin{figure}[p]
	
	{\includegraphics[width=0.4\linewidth]{images/f0_monotonic}
		
	}
	
	\caption{Hypothetical f0 contour of a monotonous (and monotonic) intonation style.}\label{fig:Monotonic}
\end{figure}

\begin{figure}[p]
	
	{\includegraphics[width=0.4\linewidth]{images/f0_singsongy}
		
	}
	
	\caption{Hypothetical f0 contour of a lively intonation style.}\label{fig:Singsongy}
\end{figure}

\begin{figure}[p]
	
	{\includegraphics[width=0.5\linewidth]{images/f0_LTD}
		
	}
	
	\caption{Frequency distribution (LTD) of both the monotonic f0 contour shown in Figure \ref{fig:Monotonic}
		and the lively f0 contour shown in Figure \ref{fig:Singsongy}.}\label{fig:LTD}
\end{figure}




To show why LTDs are problematic for capturing intonation styles, compare the contour in Figure \ref{fig:Monotonic}, which represents monotonous speech (and is monotonic in the mathematical sense, i.e.~it never changes direction) with the one in Figure \ref{fig:Singsongy}. This represents a stylised version of the other extreme: a thoroughly lively intonation style.




The crucial problem here is that these two very different contours yield exactly the same result in an analysis of LTD measures, as can be seen in Figure \ref{fig:LTD}. An analysis relying on LTDs therefore obscures the polar nature of these two styles of intonation (at least in their hypothetical versions considered here).






	\subsection{Summary}\label{sec:int_back_measures_summary}

I have shown that LTDs along with linguistic measures based on phonological labels cannot be considered satisfactory measurements for the characterisation of intonation styles. While a measure of pitch range should certainly be included, we need to also add a metric which truly captures the time-varying dynamics of pitch contours and is able to unambiguously distinguish (e.g.) the two very different speech styles exemplified in Figures \ref{fig:Monotonic} and \ref{fig:Singsongy}. I will describe a two-dimensional analysis designed for this purpose, capturing both dynamics (\textit{Wiggliness}) and pitch range (\textit{Spaciousness}), in the following section.


	\section{Analysis: Wiggliness and Spaciousness}\label{sec:intonation_analysis}

The aim of the novel approach described here is to avoid the shortcomings inherent to approaches relying only on linguistic and Long-Term Distributional measures by concentrating on the time course and excursion of f0 trajectories. Two parameters are used to capture the melodicity of speech: Wiggliness and Spaciousness. The parameters are described in detail in the following. Since this approach was first described in \citet{wehrleSomewhereSpectrumRobotic2018}, the method has seen 1) further improvement and automatisation; see the tutorial in \citet{wehrleBriefTutorialUsing2022}, and 2) the successful application to an unrelated data set along with perceptual validation of the metrics used; see \citet{wehrleEvaluatingProsodicAspects2023}. 

	\subsection{Data}\label{intonation_analysis_data}

For the analysis of intonation style, all interpausal units (IPUs) with a duration of less than 1 second were excluded from further analysis, as such utterances cannot be guaranteed to contain enough speech material for a dynamic characterization of intonation styles. A large part of these short IPUs consisted of backchannels (listeners signals such as \emph{mmhm} or \emph{okay}) and filled pauses (hesitation signals such as \emph{uhm}). The use of these specific discourse markers, including their prosodic realisation, is described separately in \chapref{backchannels}.

After the exclusion of very short IPUs, 4059 IPUs (with a mean duration of 2.67 seconds) remained for analysis. Any extreme values along all extracted parameters, as well as a number of randomly sampled IPUs, were hand-checked. After exclusion of any data points based on pitch tracking or processing errors, 4043 IPUs remained (\textgreater{} 99\%).

An example IPU annotated with the relevant parameters is shown in Figure \ref{fig:WigSpacExample} and will be referred to throughout this chapter.




\begin{figure}
	
	{\includegraphics[width=1\linewidth]{images/WigSpac_Example_edited}
		
	}
	
	\caption{Representative example IPU with relevant parameters annotated. The grey speckles represent the original pitch track. The red line is the hand-corrected and smoothed pitch contour. The green line is the smoothed and corrected contour after stylisation to 2-semitone (ST) steps. The blue circles denote turning points in the stylised contour, used for calculating Wiggliness. The black arrows denote the two largest pitch excursions between turning points, used for calculating Spaciousness (see text for more details).
		This IPU has a Wiggliness value of 2.78 (8 turning points divided by a pitch duration of 2.88) and a Spaciousness value of 5.81 (average of the two largest excursions in ST), which is close to the respective mean values across groups.\\}\label{fig:WigSpacExample}
\end{figure}

	\subsection{Processing}\label{int_analysis_processing}

All pitch contours were extracted from individual IPUs (original extracted pitch contour represented as grey speckles in Figure \ref{fig:WigSpacExample}), hand-corrected and smoothed \citep{cangemiMausmooth2015a} (corrected and smoothed contour represented as a red line in Figure \ref{fig:WigSpacExample}). The smoothed contours were then automatically stylised to a resolution of 2 semitones using the Manipulation function in \textit{Praat} \citep{boersmaPRAATDoingPhonetics2021} (stylised contour represented as a green line in Figure \ref{fig:WigSpacExample}). By applying smoothing before stylisation, turning points are only located where an actual tonal movement is likely to be perceived.

Contours that have been smoothed and stylised at this resolution seem to be perceptually robust while also facilitating the further processing required to yield the final values of Wiggliness and Spaciousness. The threshold of 2 semitones for smoothing was chosen in \citet{wehrleSomewhereSpectrumRobotic2018} as an approximation for how intonation contours may be perceived auditorily. Careful experimentation has shown that the 2-semitone setting is a useful heuristic for capturing the essence of pitch contour dynamics. Moreover, the results reported in \citet{wehrleEvaluatingProsodicAspects2023} provide a first, highly promising perceptual validation for the chosen method. Comparison of a number of test utterances additionally revealed that \emph{automatic} stylisation with a 2-semitone resolution, as performed here, leads to final contours that are very similar to the outcome of a \emph{manual} procedure, as employed in e.g. \citet{mennenCrosslanguageDifferencesFundamental2012a}, while being considerably more efficient. That being said, follow-up perception experiments are planned which may inform possible adjustments to the current method.

The additional steps necessary to yield the final characterisation of intonation styles along the two dimensions of Wiggliness and Spaciousness are laid out in the following sections.

	\subsection{Wiggliness}\label{int_analysis_wiggliness}

The term Wiggliness is borrowed from statistical analysis \citep[see, for instance,][]{hallLocalMinimaCrossValidation1991}. Wiggliness is operationalised as the amount of times an f0 contour changes direction in a given unit of speech (i.e.~IPU) or, in other words, as slope changes per second. An automatic procedure was employed in \emph{R} to compute the number of rises and falls within each stylised ``Pitch object" in \textit{Praat} (blue circles in Figure \ref{fig:WigSpacExample}). This number was then divided by the total duration of the ``Pitch object" to yield the final Wiggliness value. Wiggliness values ranged from 0.57 to 8.82 in the data set, with a mean value of 3.14 (SD = 1.07) across all IPUs.

    	\subsection{Spaciousness}\label{sec:int_analysis_spaciousness}

Spaciousness is operationalised as the extent of the slopes of individual f0 rises and falls within a given IPU, i.e.~maximum f0 excursions. The final Spaciousness measure was automatically computed in \emph{R} as the average between the absolute values of the two largest excursions (black arrows in Figure \ref{fig:WigSpacExample}), calculated in semitones (ST). Spaciousness ranged from 0.01 ST to 15.63 ST in the data set, with a mean value of 6.03 ST (SD: 2.42) across all IPUs. Semitones (with a reference value of 1 Hz) were chosen for the calculation of Spaciousness rather than Hertz \citep[originally used in][]{wehrleSomewhereSpectrumRobotic2018} for being a unit of measurement that is much more closely linked to human auditory perception \citep{nolanIntonationalEquivalenceExperimental2003} and for additionally facilitating comparison between male and female speakers. A common reference level rather than one based on speaker means was chosen in order to obtain a more generalised and context-independent measure of melodicity.

	\subsection{Comparison with other measures}\label{int_analysis_comparison}

For comparison with measures used in previous studies, values of pitch range and mean f0 are also reported. Pitch range was calculated as the difference (in ST) between the maximum and minimum of (hand-corrected) f0 values in each IPU. The measure of ST was chosen over Hz here for the reasons laid out above regarding the measure of Spaciousness (i.e.~perceptual validity and facilitated cross-gender comparison). This operationalisation of pitch range is in essence very similar to the Spaciousness measure introduced above, albeit less fine-grained. We can therefore expect results for pitch range and Spaciousness to be highly correlated.

Mean f0 was calculated as the average of all (checked and corrected) extracted f0 values from the speech of a given subject (total n = 658034) in Hertz \citep[semitone measurements are not suitable for level measures; cf.][]{mennenCrosslanguageDifferencesFundamental2012a}.

The pilot results in \citet{wehrleSomewhereSpectrumRobotic2018} provide initial empirical evidence for the conceptual assumption that intonation styles described as more melodic are indeed accurately represented by \emph{higher} values of both Wiggliness and Spaciousness and, conversely, that intonation styles described as more monotonous are accurately represented by \emph{lower} values of both Wiggliness and Spaciousness. These assumptions are validated and strengthened by the analyses in \citet{wehrleEvaluatingProsodicAspects2023}. It was further shown in \cite{wehrleSomewhereSpectrumRobotic2018} that the dimensions of Wiggliness and Spaciousness are highly correlated, but that each dimension contains some information that cannot be captured by the other. This observation, too, is firmly corroborated by the work reported in \citet{wehrleEvaluatingProsodicAspects2023}. Wiggliness and Spaciousness can therefore be considered as complementary measures to a certain extent, and using them together rather than in isolation promises to yield a more accurate representation of intonation styles. Accordingly, the dimensions of Wiggliness and Spaciousness are considered, plotted and reported together, yielding a two-dimensional characterisation of intonation styles.


\section{Results}\label{sec:intonation_results}

I will first present overall results by group, then by speaker and finally with respect to speaker role, gender and dialogue stage.

	\subsection{Overall results by group}\label{int_results_overall_group}





\begin{figure}
	
	{\includegraphics{figures/graphics-WigSpacGroup-1.pdf}
		
	}
	
	\caption{Mean Spaciousness (in ST, on the y-axis) and Wiggliness (on the x-axis) by group. ASD group in blue, CTR group in green. Error bars represent one standard deviation from the mean.}\label{fig:WigSpacGroup}
\end{figure}

Figure \ref{fig:WigSpacGroup} shows mean Wiggliness and Spaciousness values by group. See Table \ref{tab:WigSpacGroupTable} for means and standard deviations (SD).
The ASD group had higher Wiggliness and higher Spaciousness overall than the CTR group. The difference between groups is slightly greater for Wiggliness than for Spaciousness (as confirmed by Bayesian modelling, see below).


\begin{table}
	\caption{\label{tab:WigSpacGroupTable}Results by group (Spaciousness in ST).}

	\begin{tabularx}{.8\textwidth}{lYYYY}
		\lsptoprule
		& \multicolumn{2}{c}{Wiggliness} & \multicolumn{2}{c}{Spaciousness} \\
		\cmidrule(r){2-3} \cmidrule(r){4-5}
		& Mean & SD & Mean & SD\\
		\midrule
		ASD & 3.34 & 1.06 & 6.54 & 2.45\\
		CTR & 3.04 & 1.05 & 5.75 & 2.36\\
		\lspbottomrule
	\end{tabularx}
\end{table}




	\subsubsection*{Bayesian analysis}\label{int_results_overall_group_bayesian}


Models for Wiggliness and Spaciousness were ran separately.
Random intercepts for individual speakers were included in all models.

No effects of gender interacting with either Wiggliness or Spaciousness were found. Results will therefore be presented in models aggregating across male and female speakers (see the accompanying  files and scripts for more detail).

	\subsubsubsection*{Wiggliness}\label{int_results_overall_group_bayesian_wiggliness}

For the dimension of Wiggliness, the model output confirms that ASD speakers produced speech with higher Wiggliness (\(\hat{\beta}\) = 3.45, CI = {[}3.25, 3.63{]}) than CTR speakers (\(\hat{\beta}\) = 3.04, CI = {[}2.86, 3.22{]}).

Conversely, CTR speakers produced speech with lower Wiggliness -- the group difference is presented from this latter perspective as the ASD group constitutes the reference level of the model by default. The estimated Wiggliness difference in the model is \(\delta\) = -0.41, with a 95\% CI of {[}-0.62, -0.19{]} and a posterior probability \(P(\delta > 0)\) = 1. This is evidence for a robust difference between groups.

The model used a skew normal distribution, as this provided a better fit to the data than a standard normal distribution. Regularising weakly informative priors with a normal distribution were specified for the Intercept (\(\mu\) = 0, \(\delta\) = 6) and for the regression coefficient (\(\mu\) = 0, \(\delta\) = 2). The default priors of the \emph{brms} package were used for the shape parameter (\(\alpha\) = 4), the standard deviation of the likelihood function, Student's \emph{t}-distribution (\(\nu\) = 3, \(\mu\) = 0, \(\delta\) = 2.5), and the standard deviations of random effects, Student's \emph{t}-distribution (\(\nu\) = 3, \(\mu\) = 0, \(\delta\) = 2.5).


	\subsubsubsection*{Spaciousness}\label{sec:int_results_overall_group_bayesian_spaciousness}

For the dimension of Spaciousness, the model output confirms that ASD speakers produced speech with higher Spaciousness (measured in ST) (\(\hat{\beta}\) = 6.79, CI = {[}6.25, 7.4{]}) than CTR speakers (\(\hat{\beta}\) = 5.79, CI = {[}5.16, 6.34{]}).

Conversely, CTR speakers produced speech with lower Spaciousness -- the group difference is presented from this latter perspective as the ASD group constitutes the reference level of the model by default. The estimated Spaciousness difference in the model was \(\delta\) = -1.04, with a 95\% CI of {[}-1.7, -0.38{]} and a posterior probability \(P(\delta > 0)\) = 1. This constitutes unambiguous evidence for a robust difference between groups.

The model used a skew normal distribution, as this provided a better fit to the data than a standard normal distribution. Weakly informative priors with a normal distribution were specified for the Intercept (\(\mu\) = 0, \(\delta\) = 15) and the regression coefficient (\(\mu\) = 0, \(\delta\) = 4). The default priors of the \emph{brms} package were used for the shape parameter (\(\alpha\) = 4), the standard deviation of the likelihood function, Student's \emph{t}-distribution (\(\nu\) = 3, \(\mu\) = 0, \(\delta\) = 2.5), and the standard deviations of random effects, Student's \emph{t}-distribution (\(\nu\) = 3, \(\mu\) = 0, \(\delta\) = 2.5).

	\subsection{Overall results by speaker}\label{sec:results_overall_speaker}

Figure \ref{fig:WigSpacSpeaker} presents results by speaker (and gender). This analysis reveals a considerable amount of individual-specific variation and a substantial degree of overlap underlying the between-group differences, although the overall tendency for higher Wiggliness and higher Spaciousness in the ASD group remains clear.
The global impression of more singsongy speech in the ASD group is validated by the observation that both the five speakers with the highest mean Spaciousness values and the five speakers with the highest mean Wiggliness values were part of the ASD group. Conversely, the eight speakers with the lowest mean Spaciousness values and seven of the eight speakers with the lowest Wiggliness values were part of the CTR group (see Table \ref{tab:WigSpacSpeakerTable} in Appendix \ref{appendix:a} for detailed results by speaker).



\begin{figure}
	
	{\includegraphics{figures/graphics-WigSpacSpeaker-1}
		
	}
	
	\caption{Mean Spaciousness (in ST, on the y-axis) and Wiggliness (on the x-axis) by speaker, group and gender. Circles represent females, triangles males. ASD group in blue, CTR group in green.}\label{fig:WigSpacSpeaker}
\end{figure}

	\subsection{Comparison with pitch range and mean f0}\label{int_results_overall_comparison}

For comparison with previous studies, the global measures of pitch range and mean f0 were calculated in addition to the novel measures described above.

	\subsubsection{Pitch range}\label{int_results_overall_comparison_range}

Results for pitch range (in ST) are in line with the results for Wiggliness and Spaciousness by indicating a more melodic intonation style for ASD speakers, in the form of an extended pitch span (mean = 9.82 ST; SD = 4.09) as compared to CTR speakers (mean = 8.38 ST; SD = 3.78); see Figure \ref{fig:PitchRange}.

Side-by-side comparison of Spaciousness and pitch range in semitones (as operationalised here) shows that, as expected, the two measures are very highly correlated (Pearson's \emph{r} = 0.99).

A comparison of Spaciousness with pitch range measured in \emph{Hertz} (rather than semitones) yielded a considerably lower correlation measure (Pearson's \emph{r} = 0.64). More importantly, it was shown that an analysis based on the measure of pitch range in Hertz fails to clearly reveal the crucial between-group difference in intonation style, highlighting instead only the relatively obvious (and expected) separation of speakers by gender. This finding stands in contrast to results in \citet{mennenCrosslanguageDifferencesFundamental2012a}, where only ``marginally larger effect sizes for the span measures that were expressed on a ST (or ERB) scale compared to the corresponding Hz measures'' are reported (for a data set of all-female speakers; p.~2256).

Figure \ref{fig:PitchRange} also serves to reiterate the crucial point that while there was a high degree of overlap between groups, about half of the speakers on the autism spectrum nevertheless clearly deviated from the intonation style of the CTR group (as can also be seen in Figure \ref{fig:WigSpacSpeaker}). These speakers produced higher values of pitch range and Spaciousness (as well as Wiggliness), indicating a more lively intonation style compared to control speakers.



\begin{figure}
	
	{\includegraphics{figures/graphics-PitchRange-1}
		
	}
	
	\caption{Mean pitch range (y-axis in Panel A) and Spaciousness (y-axis in Panel B) by speaker, group and gender. Circles represent females, triangles males. ASD group in blue, CTR group in green.}\label{fig:PitchRange}
\end{figure}

The Bayesian analysis of pitch range confirms that ASD speakers produced speech with a wider pitch range (\(\hat{\beta}\) = 10.32, CI = {[}9.19, 11.34{]}) than CTR speakers (\(\hat{\beta}\) = 8.45, CI = {[}7.46, 9.43{]}) (measured in ST).
Conversely, CTR speakers produced speech with a narrower pitch range -- the group difference is presented from this latter perspective as the ASD group constitutes the reference level of the model by default. The estimated pitch range difference in the model was \(\delta\) = -1.85, with a 95\% CI of {[}-2.98, -0.67{]} and a posterior probability of \(P(\delta > 0)\) = 0.99. This constitutes robust evidence for a group difference in pitch range. Further details on the Bayesian model can be found in the accompanying files and scripts (see \url{https://osf.io/6vynj}).



\subsubsection{Mean f0}\label{int_results_overall_comparison_meanfzero}




\begin{figure}
	
	{\includegraphics{figures/graphics-MeanfZero-1}
		
	}
	
	\caption{Mean Spaciousness (y-axis) and mean f0 (x-axis) values by speaker, group and gender. Circles represent females, triangles males. ASD group in blue, CTR group in green.}\label{fig:MeanfZero}
\end{figure}

While both Spaciousness and pitch range, along with Wiggliness, have proven to be useful measures for analysing and displaying crucial features of intonation style, a comparison with mean f0 values reveals that this metric, although very commonly used in previous studies, is not sufficient to reveal the patterns described above. Mean f0 values are highly similar between groups, and a speaker-specific analysis does not reveal any meaningful underlying patterns; see Figure \ref{fig:MeanfZero}. See also Tables \ref{tab:MeanfZeroGroup} and \ref{tab:MeanfZeroSpeaker} in Appendix \ref{appendix:a} for values by group, gender and speaker.

	\subsection{Effects of dialogue stage}\label{int_results_stage}

Intonation styles were very stable across different parts of the dialogue (before, during and after discussion of the first Mismatch), with no clear differences whatsoever at the group level. A minority of speakers did show changes in Wiggliness or Spaciousness values as the task progressed, but these changes were very subtle and not unidirectional. See Table \ref{tab:IntonationGroupTable} for values by group, and Table \ref{tab:WigSpacMismatchSpeakerTable} in Appendix \ref{appendix:a} for values by speaker.



\begin{table}
	
	\begin{center}
% 		\begin{threeparttable}
			
			\caption{\label{tab:IntonationGroupTable}Results by group and part of dialogue (before, during and after discussion of the first Mismatch). Spaciousness in ST.}
			
			\begin{tabularx}{.8\textwidth}{l@{\qquad}X rr@{\qquad}rr}
				\lsptoprule
				&  & \multicolumn{2}{c}{Wiggliness} & \multicolumn{2}{c}{Spaciousness} \\
				\cmidrule(r){3-4} \cmidrule(r){5-6}
				& Mismatch 1 & Mean & SD & Mean & SD\\
				\midrule
				ASD & before & 3.37 & 1.11 & 6.70 & 2.58\\
				ASD & during & 3.37 & 1.05 & 6.55 & 2.45\\
				ASD & after & 3.33 & 1.06 & 6.51 & 2.44\\
				CTR & before & 3.06 & 0.98 & 5.59 & 2.22\\
				CTR & during & 3.11 & 1.11 & 5.88 & 2.40\\
				CTR & after & 3.02 & 1.05 & 5.76 & 2.38\\
				\lspbottomrule
				\addlinespace
			\end{tabularx}
% 		\end{threeparttable}
	\end{center}
	
\end{table}

In the Bayesian analysis, models comparing early and remaining dialogue stages revealed estimates and 95\% CIs around 0 and low posterior probabilities in the ASD group for both Wiggliness (\(\delta\) = 0.03; 95\% CI {[}-0.12, 0.19{]}; \(P(\delta > 0)\) = 0.39) and Spaciousness (\(\delta\) = -0.03; 95\% CI {[}-0.37, 0.29{]}; \(P(\delta > 0)\) = 0.55).
The same is true for CTR speakers, with models for both Wiggliness (\(\delta\) = 0.05; 95\% CI {[}-0.19, 0.08{]}; \(P(\delta > 0)\) = 0.75) and Spaciousness (\(\delta\) = 0.04; 95\% CI {[}-0.23, 0.33{]}; \(P(\delta > 0)\) = 0.41) providing no evidence for a difference between dialogue stages. The models also clearly indicate no interaction between speaker group and stage of dialogue. Further details on Bayesian modelling can be found in the accompanying scripts and files.

These results strengthen the view that intonation styles can be considered as stable characteristics of speakers, differing considerably between individuals but proving robust across time and conversational context.

	\subsection{Effects of gender}\label{int_results_gender}

Contrary to a speculative interpretation of the pilot data in \citet{wehrleAssessingIntonationStyle2020} suggesting that the difference between the ASD and the CTR group was less pronounced for female speakers, Bayesian modelling clearly shows that this was not the case. The data set was split by (self-reported) gender and differences for Wiggliness and Spaciousness were evaluated across groups (ASD/CTR) for each gender group. The resulting model estimates were nearly identical for the subsets for male and female speakers. For a complementary perspective, differences between male and female speakers were also analysed \emph{within} groups. This confirmed that there was no gender difference in either the ASD or CTR group (e.g. the posterior probability in the ASD group was 0.43 for Wiggliness and 0.51 for Spaciousness; more details in the \textit{OSF} repository at  \url{osf.io/gqe9n/}).


	\subsection{Effects of speaker role}\label{int_results_role}



\begin{figure}
	
	{\includegraphics{figures/graphics-WigSpacRoles-1}
		
	}
	
	\caption{Intonation style by speaker role and group. Spaciousness (in ST) on the y-axis, Wiggliness on the x-axis. ASD group in blue, CTR group in green. Values for instruction givers are presented with a black outline, values for instruction followers with an orange outline.}\label{fig:WigSpacRoles}
\end{figure}

Comparing the roles of instruction giver and follower in the Map Task revealed a trend towards slightly more melodic speech by instruction givers across groups, as shown in Figure \ref{fig:WigSpacRoles}. However, the effect is clearer for the CTR compared to the ASD group. On average, ASD speakers produced higher Spaciousness in the role of instruction givers, but not higher Wiggliness; CTR speakers on the other hand on average produced both higher Spaciousness and higher Wiggliness as instruction givers.

In Bayesian terms, models comparing speaker roles for the ASD group clearly show that the speech of instruction givers was characterised by more Spaciousness (\(\delta\) = 0.61; 95\% CI {[}0.28, 0.95{]}; \(P(\delta > 0)\) = 1), but not by more Wiggliness (\(\delta\) = -0.11; 95\% CI {[}-0.3, 0.07{]}; \(P(\delta > 0)\) = 0.16).

For the CTR group, on the other hand, models comparing speaker roles confirm that there was both slightly more Wiggliness (\(\delta\) = 0.18; 95\% CI {[}0.01, 0.35{]}; \(P(\delta > 0)\) = 0.96) and more Spaciousness (\(\delta\) = 0.64; 95\% CI {[}0.35, 0.94{]}; \(P(\delta > 0)\) = 1) in the speech of instruction givers.

A speaker-specific analysis further reveals that the pattern of more melodic speech for instruction givers holds true for about half of the speakers within each group. In accordance with the group-level analysis, this pattern is, however, clearer for speakers in the CTR group (see Figure \ref{fig:WigSpacRoleFigure} in Appendix \ref{appendix:a}).





	\section{Discussion}\label{sec:intonation_discussion}

The goal of this chapter was to appropriately measure, analyse and describe the intonation styles of autistic and non-autistic speakers. In order to achieve this, a novel method for capturing intonation styles using the two dimensions of Wiggliness (slope changes) and Spaciousness (pitch excursions) was outlined and then applied to a corpus of semi-structured dialogue.

	\subsection{Summary}\label{int_disc_summary}

Overall, a clear tendency for more melodic speech in the ASD compared to the CTR group was revealed. This tendency is evident for both parameters used, but the between-group difference is more pronounced for Wiggliness than for Spaciousness.

It is crucial, however, to expand on the simplifications inherent in any group-level analyses with a detailed investigation of speaker-specific behaviour, especially when working on data involving autistic persons. The speaker-specific analysis shows that group means accurately reflect the behaviour of speakers from both groups overall, but also highlights the fact that there is considerable overlap between speakers with and without a diagnosis of ASD. Half of the speakers from the ASD group (7 out of 14) produced a more melodic intonation style than any speaker from the control group, while the intonation style of the other 7 autistic speakers falls well within the range of values produced by non-autistic speakers.

It is important to note that where the behaviour of autistic speakers did differ from that of the CTR group, this happened only in the direction of more lively and melodic speech. It follows that the current study adds support to previous studies indicating a more melodic intonation style in ASD, but not to those describing monotonous or even robotic speech in ASD. Although findings on intonation style in ASD have been somewhat contradictory in the past, more recent studies have tended to find evidence only for more melodic speech (where differences were detected at all; see Section \ref{int_back_ASD}). This trend is corroborated by the results presented here.

One important caveat is that data from German-speaking adults were analysed. A comparison of the resulting findings is problematic in many ways, as results in the literature are overwhelmingly based on speech data from English-speaking participants, usually children. However, until we know more about the differences in behaviour of adults and children with ASD, or can make specific predictions about the interaction of autism with culture and language, this must remain a limitation which must be acknowledged but cannot be overcome. Overall, the fact that we now have converging experimental evidence from both children \emph{and} adults, and from a range of different languages, strengthens the notion that there is a tendency towards more rather than less melodic speech in ASD.


	\subsection{Methodological aspects}\label{int_disc_methods}

A methodological comparison revealed that the patterns which were identified by using the dynamic characterisation of intonation styles along the two dimensions of Wiggliness and Spaciousness would not necessarily have been detected with the help of conventional linguistic and long-term distributional measures.

As pointed out above (\sectref{sec:intonation_analysis}), Wiggliness and Spaciousness are related measures. It is therefore not surprising that, in the current data set, speakers with relatively high (or low) values for Wiggliness usually also had relatively high (low) values for Spaciousness (and vice versa). This was not always the case, however. Speaker M08 (from the ASD group) has the highest mean Wiggliness value of all speakers, but a mean Spaciousness value that is very close to the group average. This underlines the importance of the \emph{two-dimensional} approach to capturing intonation styles employed here \citep[for further evidence supporting distinct functions and the partial independece of Wiggliness and Spaciousness, see][]{wehrleEvaluatingProsodicAspects2023}. Without reference to the novel measurement of Wiggliness, the intonation style of speaker M08 would have been falsely characterised as lying well within the range of intonation styles produced by control speakers and as being neither particularly monotonous nor melodic, when it in fact represents the \textit{wiggliest} intonation style out of all 28 speakers.

\hspace*{-2.2pt}Although the dimension of Wiggliness is conceptually related to what is known as macro-rhythm in prosodic typology \citep{junProsodicTypologyRevisited2012,junProsodicTypologyProminence2014}, its use as a metric and measurement is novel \citep[but see also][]{kalandBendingStringIntonation2022,prechtelCrossLinguisticComparisonLexical2023}. Spaciousness, on the other hand, is essentially an analogue of pitch range, one of the most frequently used metrics in previous descriptions of intonation styles. I have shown that Spaciousness and pitch range values taken from the data set under study in this book are almost perfectly correlated. However, it is important to note that extensive correction and smoothing of \textit{Praat}-extracted pitch tracks preceded any further analysis in this investigation. This level of rigour is not matched by all previous research in the field, particularly in cases where the authors' main expertise lay in fields other than acoustic phonetics (e.g.~in the bulk of autism or second-language acquisition research). Therefore, pitch range as reported in previous studies is not necessarily a direct equivalent of pitch range as operationalised here. I am aiming to test, evaluate and adapt the measure of Spaciousness and to ultimately assess its usefulness beyond the established measure of pitch range in future work.

Potential adjustments notwithstanding, I have demonstrated the considerable methodological and conceptual proximity of pitch range and Spaciousness, and have have thereby shown that the proposed novel method of analysis is firmly anchored in more conventional, long-established research traditions and methodological approaches. This fundamentally strengthens the reliability and interpretability of the findings presented here and those of any future studies using the measurements of Wiggliness and Spaciousness.

In stark contrast, a comparison of Wiggliness and Spaciousness to mean f0, a measure very frequently used in previous research to characterise speakers or speaking styles, shows that an analysis relying solely on mean f0 would be unable to capture any of the patterns revealed using the measures described above. It follows that mean f0 is in fact not a suitable metric for capturing and characterising intonation styles, at least as defined here. Used in isolation, it seems to be too static and simplistic a metric to capture all of the complex, time-varying pitch dynamics that contribute to the perception of an intonation style as being more or less monotonous melodic. This fact does not, of course, invalidate any previous results relying on mean f0 for the description of intonation. It does strongly suggest, however, that more complex and comprehensive measures are needed to capture perceptual correlates of liveliness and melodicity.

	\subsection{Dialogue stage, gender, and speaker role}\label{int_disc_part_role}

It was shown that intonation styles within speakers remain very stable across the duration of the recorded dialogue. This stands in contrast to findings from the same corpus showing that some other conversational behaviours, such as turn-timing and backchannelling, clearly differed between early and later stages of dialogue, particularly for the ASD group (see \chapref{turntaking} and \chapref{backchannels} for details). Intonation styles may therefore be considered as global, identifiable characteristics of a given speaker which are relatively independent of external factors such as interlocutor and conversational context. This invariance makes the identification of commonalities in intonation style across different individuals on the autism spectrum all the more relevant. Such common characteristics could ultimately serve as a kind of marker associated specifically with the language of at least some autistic speakers. Given the current results and those of recent research, a highly melodic intonation style seems to be a prime candidate for just such a pattern.

While no effect of gender was found, intonation style did seem to change subtly depending on speaker role. Speech tended to be more melodic for instruction givers overall, but this effect was more pronounced for speakers from the CTR group (who showed changes in both Wiggliness and Spaciousness, whereas speech in the ASD group did not change in Wiggliness). It might be speculated that CTR speakers were simply somewhat more flexible in adapting their conversational and intonational styles to their assigned roles than their autistic counterparts were. It is important to keep in mind, however, that the differences in intonation style according to speaker role were very small overall (for both groups). It is therefore not clear how robust or perceptually relevant these subtle changes might be in real-life interactions.

	\subsection{Limitations and implications}\label{intonation_limitations}

The data analysed and presented here strongly support the notion of a more melodic intonation style in (some) autistic speakers, while no support for the notion of robotic intonation in individuals with ASD was found. Any such claims will of course have to be tested in future studies on larger data sets of autistic and non-autistic speakers. Clearly, in a group of speakers as typically heterogeneous as that of individuals diagnosed with ASD, investigating 14 speakers will not be sufficient for drawing firm conclusions about the population as a whole.

Regarding methodological limitations, I acknowledge that although the comparison with conventional operationalisations of pitch range confirms the validity of the novel metrics used, the reliability (and potential advantages) of the two-dimensional Wiggliness/Spaciousness approach need to be critically tested and examined in future work. The main aim in such work will be to test how well Wiggliness and Spaciousness are aligned with listeners' subjective judgements of intonation styles. Some very reassuring first results from subsequent work can be found in \citet{wehrleEvaluatingProsodicAspects2023}.

I will point out once more that previous studies on the same topic were performed almost exclusively using speech data from children and adolescents (or young adults). The results in this work provide a starting point for the characterisation of intonation styles in autistic adults, but it is important to keep in mind that results from children's speech will not necessarily be reflected in the speech of adults. In particular, it is likely that the relatively subtle group-differences shown here stem at least partly from the fact that many autistic speakers are able to adapt to the behaviours (including intonation style) of their non-autistic peers over time, if they so desire, in acts of social camouflaging \citep{hullPuttingMyBest2017,laiQuantifyingExploringCamouflaging2017}.

This process may be aided by dedicated speech and language therapy, but such training is not a prerequisite for successful adaptation. With regard to the specific results and measurements presented here, it is entirely feasible that some autistic speakers in the sample may have been aware of having produced an unusually \emph{monotonous} intonation style at some point in their lives and since learned to (over)compensate in producing a particularly \emph{melodic} intonation style by the time of recording. Clearly, such speculations are not testable within the scope of the current data, but could be fruitfully considered as part of future longitudinal studies.

Furthermore, communication in the corpus under investigation was not fully natural or spontaneous. Task-oriented dialogue between autistic individuals (as in the Map Task paradigm) has to be considered as a major improvement on the read speech or formally constrained interactions between autistic speakers and non-autistic interlocutors that form the basis of most previous studies. However, there are also important limitations to the external validity of semi-structured dialogues as investigated in this book. Having to fulfil an unfamiliar task puts certain pressures and constraints on participants and the resulting linguistic output. This may have affected speakers in the ASD group differently than those in the CTR group. On the other hand, a restricted set of dialogue options and reduced chance of unexpected events should, if anything, suit the cognitive styles of autistic speakers more than fully free and spontaneous conversation. Combined with the fact that participants clearly formed part of the more socially motivated end of the autism spectrum, any differences between groups that were discovered in this study could be considered as all the more remarkable and meaningful.
