\chapter{Eye Tracking and subtitling: Eye tracking as a research tool}\label{eyetracking}

Early scientists of the 19\textsuperscript{th} century were the first to be involved with eye movement analysis and associated cognitive processes. The investigation of eye movements nowadays is done by means of sophisticated \isi{eye tracking} methods, research in this area has since come a long way, and, as Kruger has put it, \isi{eye tracking} “provide[s] us with a window on the internal systems of the mind (cf. \citealt{marchant2009})” (\citealt{Kruger????}). It is well-developed in several related fields such as reading and \isi{translation process} research as well as psycholinguistics and was established in audiovisual translation studies “even before it had gained prominence within Translation Studies in the late 1990s” (\citealt{Kruger????}). In analysing the processing of audiovisual text, and mainly subtitles, a wide range of different factors have to be taken into account.

The following section focuses on the relevant fundamentals of \isi{eye tracking} research, including the anatomical structure of the eye and its function, \isi{eye tracking} itself, its practical application in general and \isi{usability} as well as audiovisual research in particular.

\section{Function of the eye and eye tracking research}\label{sec:6.1}

Even though the human eye is quite simple in its physical structure and movements (\citealt{Joos-Helmert2005}: 1), it is not a mere sensor and by itself responsible for the exploration of the surroundings but also part of communicative interaction and indicative of cognitive processes (\citeyear{Joos-Helmert2005}: 1). The strong \isi{eye-mind hypothesis} by Just and Carpenter states that eye movements are correlates of mental processing as “there is no appreciable lag between what is being fixated and what is being processed” (\citeyear{Just1980}: 331), and Holmqvist et al. see “functional links between what is fixated and cognitive processing of that item – the longer the \isi{fixation}, the ‘deeper’ the processing” (\citeyear{Holmqvist2011}: 328). While interpretation of eye movement data should take place “within the context of a given theoretical framework” (\citealt{radach-kennedy2004}: 8), “numerous subsequent studies have shown that the spatial and temporal relationship between eye movements and information processing cannot be captured by these simple principles” (\citealt{radach-kennedy2004}: 8; cf. \citealt{rayner1998}: 375ff.), referring to the \isi{eye-mind hypothesis} and immediacy assumptions by Just and Carpenter. While this depends on the field of study, some limitations of these assumptions should be taken into account:

\sloppy
\begin{itemize}
\item Attention of viewers might be affected by “mind wandering” or “mind drifting” (\citealt{Hvelplund2014}: 209) as well as “thoughts may drift unintentionally during reading” (\citeyear{Hvelplund2014}: 209), which is a “frequent and common phenomenon […]” (\citealt{Hvelplund2014}: 219).
\item Eye trackers might produce “drift” (\citealt{Hvelplund2014}: 210), leading to the recorded eye position becoming gradually displaced.
\item Posner noted that – in “simple laboratory tasks” (\citealt{schotter2012}: 85) – focus and attention “may be separated or dissociated” (\citeyear{Posner1980}: 5). Therefore, it is “[…] important to distinguish between overt changes in orienting that can be observed in head and eye movements, and the purely covert orienting that may be achieved by the central mechanism alone […]” (\citeyear{Posner1980}: 5). Schotter and Rayner also note that, while “overt attention (where the eyes are fixating) is tightly linked to covert attention (where the mind is attending)” (\citealt{schotter2012}: 85) and the “most thorough and effective processing is reserved for that done in the fovea, some processing can also be accomplished for information in the parafovea and peripheral vision” (\citeyear{schotter2012}: 85).
\item Additionally, Posner noted that “in many tasks, a shift of attention to the \isi{saccade} target precedes the actual eye movement […]” (\citeyear{Posner1980}: 5). Hvelplund reports that it is possible for the mind to be “up to 250 milliseconds ahead of the eye” (\citeyear{Hvelplund2014}: 210; cf. \citealt{obrien2009}: 252, \citealt{Holmqvist2011}: 379). Additionally to being ahead, the mind can also “lag a little behind” (\citealt{Hvelplund2014}: 211).
\end{itemize}
\fussy 

Taking all these limitations into consideration, \citet[9]{radach-kennedy2004} still rate “the relation between \isi{fixation} positions and durations and local processing”  as “strong enough to produce reliable effects when sampled over groups of participants and items and in this sense eye movement measures provide an extremely sensitive index of local processing load” (\citeyear{radach-kennedy2004}: 9; \citealt{Hvelplund2014}: 211).

Overall, the eye can cover a visual field of approximately 120° vertically and 150° horizontally (\citealt{Flothow2009}: 3). Light is let in through the pupil and projects an upside down image onto the retina. The fovea centralis, also known as the central fovea or just fovea, has the highest density of receptors (cones) and allows for the sharp central vision needed to perceive visual details, for example during reading. Here, the eye achieves its highest resolution in less than 2° of our visual field (cf. \citealt{Kruger????}). Therefore, the eye has to be constantly adjusted in order to focus on specific elements in the visual field (\citealt{Holmqvist2011}: 21--24). This small area of sharp central vision and the constant adjustments underline the \isi{eye-mind hypothesis} by Just and Carpenter, as the position of the optical axis is relevant in order to determine the attention focus of a person (\citealt{Just1980}; \citealt{Flothow2009}: 3).

The different kinds of observed eye movements are divided into various categories. Fixations and saccades are particularly relevant for the analysis of eye movements. During fixations, a specific point in space – the \isi{fixation point} – is at the centre of \isi{visual attention} and the eye relatively inactive for a short period of time. During fixations, visuospatial processing (perceiving objects in space) takes place and information is taken in. The typical mean duration of a \isi{fixation} is between 200 and 300~ms with the minimal \isi{fixation duration} being around 100~ms (\citealt{rayner1998}: 373; \citealt{Flothow2009}: 2; \citealt{Holmqvist2011}: 23). Usually, fixations are considerably longer, especially during reading (225--250~ms) and oral reading (275--325~ms), but also during tasks such as \isi{scene perception} (260--330~ms) or visual search (180--275~ms) (\citealt{rayner1998}; \citealt{Jakobsen2008}).

Saccades are the movements between the \isi{fixation} points, describing the movement of the eye from one \isi{fixation point} to another. These fast ballistic eye movements are especially abrupt – according to Joos et al. (\citeyear{Joos-Roetting-Velich2003}: 17), the latency is around 150 to 200~ms – and with speeds up to 1000°/s (\citeyear{Joos-Roetting-Velich2003}: 17) and durations between 30 and 80 ms (\citealt{Holmqvist2011}: 23), they are so fast that the eye cannot absorb or process any information during a \isi{saccade} (\citealt{Flothow2009}: 4; “saccadic suppression”, \citealt{Volkmann1978}; “saccadic omission”, \citealt{Chekaluk1994}: 373; \citealt{schotter2012}: 84--85). Information absorbed during fixations, however, can be partially processed during the following saccades \citep{Holmqvist2011}, usually preventing information loss and deficits. Therefore, saccades are “rapid, ballistic movements […] that abruptly change the point of \isi{fixation}” (\citealt{purves2001}: 431) that can be both voluntary and reflexive and cannot be corrected during the movement. They are part of four groups of eye movements that are generally distinguished (\citealt{purves2001}; \citealt{Joos-Helmert2005}):

\begin{itemize}
\item Saccades
\item Smooth pursuit movements
\item Vergence movements
\item Vestibulo-ocular movements
\end{itemize}

Smooth pursuit movements are so-called “tracking movements” (\citealt{purves2001}: 431) and prevent information from leaving the central field of sharp vision (\citealt{Joos-Roetting-Velich2003}: 1; cf. \citealt{rickheit2003}). They are the reactions to movements of the body or the surroundings and stabilize the focus. They can be voluntary as a person can decide to track a moving stimulus or not (\citealt{purves2001}: 431) and include the opto-kinetic nystagmus\footnote{An involuntary reflex to maintain a stable retinal image (\citealt{Joos-Roetting-Velich2003}: 4) during a “replacement of the retinal image” (\citealt{Joos-Roetting-Velich2003}: 4, author’s translation).} and the vestibular nystagmus.\footnote{An involuntary reflex to maintain a stable \isi{fixation} during head and body movement (\citealt{Joos-Roetting-Velich2003}: 4).} Vergence movements can be seen as part of the smooth pursuit movements but can also happen involuntarily (\citealt{Joos-Roetting-Velich2003}: 4). They “align the fovea of each eye with targets located at different distances from the observer” (\citealt{purves2001}: 432). The vestibulo-ocular movements compensate for head movements. \citet{Joos-Roetting-Velich2003} also mention that fixations are not completely motionless themselves. Micro movements occur within fixations and include drifts, micro saccades and tremors. Drifts are the constant ‘slipping’ from the \isi{fixation} target, and they are compensated by micro saccades. Tremors are the smallest, trembling movements of the eye with movements slightly less than one minute of arc and frequencies around 50~Hz. This ‘inaccuracy’ in the eye muscle control prevents exhaustion in the photoreceptors and is necessary as these receptors only react to a change in light.

So far, mainly fixations and saccades have been analysed during research. Another measure mentioned in several studies is \isi{pupil size}. However, Holmqvist et al. advise caution due to the pupil’s sensitivy “to not only changes in cognitive load” (\citeyear{Holmqvist2011}: 393) but also to light intensity, emotions such as fear, stress, and pain as well as medicine and stimulants (\citeyear{Holmqvist2011}: 393, \citealt{Hvelplund2014}: 214). Therefore, this study focuses on fixations and saccades to analyse the viewer’s \isi{gaze behaviour} and measure \isi{visual attention}. These eye movements can be recorded with an \isi{eye tracker},\footnote{For a short overview on \isi{eye tracking} history, refer to \url{http://www.uxbooth.com/blog/a-brief-history-of-eye-tracking/} [2014--11--21, in German] and \url{https://www.cs.hs-rm.de/~linn/fachsem0809/eyetracking/Eye_Tracking.pdf} [2014--11--21, in German].} in this case the Tobii TX300 which is introduced and discussed in \sectref{sec:7.1}.

While there are quite different methods of eye movement registration (for an overview, see \citealt{rickheit2003}: 147), all of them are based on anatomical and physiological properties of the eye that are accessible by self-evaluation or through the observation of others (see \citealt{rickheit2003}: 145).\footnote{For a description of the early efforts and history of \isi{eye tracking}, see this presentation: \url{https://www.uniklinik-freiburg.de/fileadmin/mediapool/07_kliniken/psy_psykuj/pdf/lehre/ESSEM_2014/ESSEM_2014_--_Lecture_slides_--_Hutton_-_Technical_challenges.pdf} [2015--12--08].} Electro-oculography uses “carefully positioned electrodes” to measure changes “in [the] electrical potential between the front and the back of the eye” (\citealt{technical_challenges2014}) caused by the eye position and is widely used, e.g. in fMRI setups. It works relatively to the head position but is prone to artifacts and not suitable for infants or other viewers that might not be able to control or suppress their head movements. Other systems are based on infrared limbal reflections, canthus tracking and scleral coil techniques. Eye trackers making use of one or two Purkinje images were very accurate and could even record micro saccades, but were also expensive and are now widely replaced by video-based eye trackers. These video systems are based on cameras that film one or both eyes and image processing software that determines the position of a “salient feature” (\citealt{technical_challenges2014}) such as pupil and corneal reflections of infrared light (\citealt{Duchowski2007}: 54; cf. \citealt{Hvelplund2014}: 205). These “two points of reference on the eye are needed to separate eye movements from head movements” (\citealt{Duchowski2007}: 60) and most head-mounted and desk-mounted video-based eye trackers achieve the necessary data by subtracting the corneal reflection created by (near) infrared light sources from the pupil position, i.e. its centre. Two techniques are used to create the reflection, called dark-pupil and bright-pupil, depending on the \isi{placement} of the illumination source. If the illumination source is placed within the optical axis of the camera, the light is reflected off the retina and the pupil appears to be bright – similar to the red eye effect during photography. If the illumination source is placed somewhere else, the light reflected off the retina is directed away from the camera and the pupil appears dark, thus creating the dark-pupil effect.

Eye tracking systems that are based on Purkinje images (or reflexes) summarise at least four reflections of objects that are created due to the eye’s structure. Normally, the first and the fourth image are analysed and can be seen as “small white dots in close proximity to the (dark) pupil” \citep{Curtis2015}:
\begin{quote}
These two images move similarly under translation of the eye, that is, they move through the same distance and in the same direction as the eye. During rotation of the eye, the separation between the two images changes proportionally with the sine of the angle of rotation. Thus angular eye position can be obtained from the relative positions of the two images (disregarding their absolute position), free of error induced by translation. (\citealt{Ku_leuven????}: para. 4)
\end{quote}
These \isi{eye tracking} systems are calibrated by “measuring user gazing at properly positioned grid points (usually 5 or 9)” (\citealt{Ku_leuven????}: para. 4). Their accuracy is “typically measured in degrees of visual angle” (\citealt{Hvelplund2014}: 205), with other relevant factors being the “degree of invasiveness” (\citeyear{Hvelplund2014}: 205) and sampling rate. Remote (or desktop) eye trackers can be seen as less invasive than other systems and are “generally the preferred type in translation research” (\citealt{Hvelplund2014}: 205; cf. \citealt{obrien2009}: 263). Studies relevant for this experiment are those on eye movements in reading, \isi{scene perception}, \isi{usability}, and, subsequently, subtitling.

\section{Eye movements in reading}\label{sec:6.2}

Radach and Kennedy claim that much of the knowledge of eye movements has been “established in the context of reading research” (\citeyear{radach-kennedy2004}: 5), which can be seen as quite a specific field of study. Hvelplund states that “visual exposure to letters automatically activates a processing stream that cannot be interrupted intentionally, unless looking away from those letters” (\citeyear{Hvelplund2014}: 209; cf. \citealt{Valdes2005}: 279). While the beginnings of \isi{eye tracking} research can be traced back to Huey in 1908, and the mid-1970s are seen as the starting point of modern \isi{eye tracking} research (cf. \citealt{rayner1976}; \citealt{Just1980}; \citealt{rayner1989}), Frenck-Mestre and Pynte (\citeyear{Frenck-mestre1997}) published what Keating calls the “first published eye-tracking study” (\citeyear{Keating2014}: 69) of “reading behavior of adult second language (L2) learners” (\citeyear{Keating2014}: 69). Eye tracking offered possibilities of “detecting subtle differences between native and non-native language processing” (\citealt{Keating2014}: 70) in real-time. Further relevant studies and overviews were published by \citet{rayner1998} and \citet{radach-inhoff-heller2004}. Rayner and colleagues showed that “\isi{fixation duration} and \isi{saccade} lengths in reading do not correlate with those measures in \isi{scene perception} and search” (\citealt{rayner2009}: 1459) and offers especially insights into “how readers respond to processing difficulties” (\citealt{Keating2014}: 87).

As Radach and Kennedy state, “fixations [in reading] are positioned in a very systematic, word-based, fashion” (\citeyear{radach-kennedy2004}: 5). Eye tracking data can therefore show whether a word is fixated or not, where it is fixated, amplitudes of “incoming and outgoing saccades” (\citealt{radach-kennedy2004}: 6), their direction (progressive or regressive) as well as interword and intraword movements of saccades (\citealt{radach-kennedy2004}: 6). An overview of “word-based spatial eye movement measures” and “word-based temporal eye movement parameters” can be found in Radach/Kennedy (\citeyear{radach-kennedy2004}: 6f.) as well as information on \isi{fixation} patterns in passes, i.e. first and second pass \isi{gaze} durations (\citealt{radach-kennedy2004}: 7). Depending on their function, \isi{fixation probability} of words differs strongly – while “content words are fixated about 85\,\% of the time, […] function words are fixated about 35\,\% of the time” (\citealt{rayner1998}: 375; cf. \citealt{rayner2009}: 1461). Additionally, \isi{fixation probability} rises with increasing word length (\citealt{rayner1976}; \citealt{rayner1996}; \citealt{rayner2009}).

Referred to by Rayner and Pollatsek as direct control of eye movements (\citeyear{rayner1989}), “information acquired during a given \isi{fixation} can influence the duration of that \isi{fixation} as well as the amplitude of the outgoing \isi{saccade}” (\citealt{radach-kennedy2004}: 5). Fixation duration is said to increase with perceived difficulty (\citealt{Hvelplund2014}: 211; cf. \citealt{rayner1986}), decreasing frequency and predictability of words (\citealt{Hvelplund2014}: 211), and increasing complexity and difficulty of words (\citealt{Hvelplund2014}: 211; cf. \citealt{rayner1989}, \citealt{rayner1986}). Furthermore, “lexical and/or syntactic ambiguity […] affect \isi{fixation duration}” (\citealt{Jakobsen2008}: 103).\footnote{As skipping and refixations occur regularly during reading, alternative measures of \isi{fixation} time have been developed. These include “first-\isi{fixation duration} (the duration of the \isi{first fixation} on a word), single-\isi{fixation duration} (those cases where only a single \isi{fixation} is made on a word), and \isi{gaze} duration (the sum of all fixations on a word prior to moving to another word). All of the measures are contingent on the word being fixated on a first-pass forward \isi{fixation}.” (\citealt{rayner2009}: 1461)} Typical \isi{fixation} durations are associated with various eye movement behaviours such as silent reading, oral reading, \isi{scene perception}, and visual search (\citealt{rayner2009}: 1460; \citealt{rayner1998}: 375), and differing reading purposes such as for comprehension or for translation influence eye movements and \isi{gaze} times (\citealt{Jakobsen2008}: 120; cf. \citealt{Hvelplund2014}: 212).

As information is only taken in during fixations, the term “\isi{perceptual span}” (\citealt{Keating2014}: 72) describes the “amount of useful information that a reader can extract from a text on a given \isi{fixation}” (\citeyear{Keating2014}: 72). The spread of the \isi{perceptual span} is asymmetric as more information to the right of the \isi{fixation} is perceived than to the left (\citeyear{Keating2014}: 72). For English readers, research states that about 14--15 characters to the right and 3--4 characters to the left are noticed. However, only words up to 7--8 characters to the right can be identified (\citeyear{Keating2014}: 72). This is, of course, different for other writing systems such as Hebrew or Chinese (\citealt{rayner2009}: 1462; \citealt{Keating2014}: 73). Part of the amount of useful information a reader can extract can also be what is referred to as a “parafoveal preview benefit” (\citealt{Keating2014}: 74f.), i.e. information about the upcoming word. If that kind of information is perceived, words visible during previous fixations are read faster (\citealt{Keating2014}: 74f.; cf. \citealt{rayner1998}, \citealt{rayner2009}: 1466f.).

Research indicates that saccades are usually “aimed at the centre of the selected target word” (\citealt{radach-kennedy2004}: 10), which seems optimal for word processing. Their length is on average nine characters and in between one and 20 characters (\citealt{Keating2014}: 71). Mature readers initiate about 85--90\,\% forward (progressive) saccades and 10--15\,\% backward (regressive) saccades (\citealt{rayner1998}: 375, 387; \citealt{rayner2009}: 1460; \citealt{Keating2014}: 71). These backwards directed saccades, also called regressions (\citealt{Keating2014}: 71) are due to comprehension difficulties or errors in \isi{saccade} programming (\citealt{Keating2014}: 71) with visible differences between good and poor readers (\citealt{rayner1998}: 375). Additionally, backwards directed saccades can be “return sweeps […] to move the eyes from the end of one line of text to the beginning of the next line of text” (\citealt{Keating2014}: 72). However, progressive saccades form the vast majority of saccades and usually land on the following word or that after (N+1 or N+2), with regressions predominantly landing on words N-1 or N-2 (\citealt{radach-kennedy2004}: 10; \citealt{rayner2009}: 1461ff.). Further relevant aspects are “\isi{saccade} latency” (\citealt{rayner1998}: 372) that describes the time “it takes to initiate an eye movement” (\citeyear{rayner1998}: 372) and the skipping of words, i.e. words not being fixated. This happens from errors in \isi{saccade} programming or “when a word is visible and identifiable in the parafovea” (\citealt{Keating2014}: 74). The probability for being skipped is below 20\,\% for content words and about 60 to 80\,\% for function words (\citealt{Carpenter1983}), with word length being relevant (cf. \citealt{rayner1976}; \citealt{Keating2014}). Most of the mentioned values are
\begin{quote}
very much influenced by text difficulty, reading skill, and characteristics of the writing system. Thus, as text gets more difficult, fixations get longer, saccades get shorter, and more regressions are made […]. Also, typographical variables like \isi{font} difficulty can influence eye movements; more difficult to encode fonts yield longer fixations, shorter saccades, and more regressions […]. (\citealt{rayner2009}: 1460)
\end{quote}
Dependent variables and further measures are listed by Jakobsen and Hvelplund Jensen (\citeyear{Jakobsen2008}: 107), Hvelplund (\citeyear{Hvelplund2014}: 215), and Rayner (\citeyear{rayner1998}, \citeyear{rayner2009}). The analysis of cognitive processes in reading is based on \isi{fixation} times and regressions (\citealt{Keating2014}: 75). As mentioned before, processing difficulty leads to longer reading times and “may induce regressions to words previously read” (\citealt{Keating2014}: 75). The overall word identification process is affected by various factors such as “frequency, word familiarity, age of acquisition [and] number of meanings” (\citealt{Keating2014}: 77).

Concerning \isi{scene perception}, Rayner states that fixations are longer and saccades are larger than in reading (\citeyear{rayner2009}: 1476). Not every part of a scene is fixated but mostly the “informative parts” (\citeyear{rayner2009}: 1476) and the \isi{perceptual span} covers “about half of the total scene” (\citeyear{rayner2009}: 1476). Various characteristics of objects within a scene affect “the ease with which an object is identified” (\citealt{rayner2009}: 1477), such as frequency, orientation, and “how well camouflaged it is” (\citeyear{rayner2009}: 1477). Further information on preview benefit and eye movement control in \isi{scene perception} can be found in Rayner (\citeyear{rayner1998}: 398ff.; \citeyear{rayner2009}: 1477ff.). Rayner also mentions a study by \citet{Carroll1992} on cartoons that reports “longer \isi{fixation} durations on the cartoon (…) than on the \isi{caption}” (\citealt{rayner1998}: 392), no consistent movement back and forth between elements, and dominance of the \isi{caption} over the picture. Additionally, research on how people look at advertisements by \citet{pieters2008} and on how viewers alternate their \isi{visual attention} between information sources \citep{rayner2001} might offer further insight on static combinations of image and text.

The visual processing of the moving image in film can be quite similar. While there are many studies on general image processing, \citet{Lautenbacher2012} makes a case of specific elements capturing the human’s \isi{gaze} like no other: “The attention capturing strength of certain visual elements seems to be so strongly linked to human communicational behaviour that they could almost be considered bottom-up factors, even though they are not of an intrinsic pictorial nature” (\citeyear{Lautenbacher2012}: 140) – this seems to especially be the case with “human faces and their \isi{gaze} directions in pictures” (\citeyear{Lautenbacher2012}: 140) as they are “very powerful \isi{gaze} catchers” (\citealt{Lautenbacher2012}: 141--142; cf. \citealt{Birmingham2008}) and salient features. As subtitles mainly appear during dialogues that are strongly connected to faces, this strong attraction to the human face in images and the “coercive force of the viewed human \isi{gaze}” (\citealt{Lautenbacher2012}: 144) tell us that conventional subtitles are not placed ideally. On the other hand, the response time has been found to be shorter “when the target appears at the gazed-at location than when it appears at the non-gazed-at location” (\citealt{Birmingham2008}: 986). However, viewers usually look at “areas that […] support human communication (e.g. mouth, eyes, and \isi{gaze} direction” (\citealt{Lautenbacher2012}: 145). Without a given task “the default point of observation will be the human face and the \isi{gaze} directions it suggests, thus putting the human face somewhere between a bottom-up visual saliency and a top-down search object” (\citealt{Lautenbacher2012}: 145--146). Therefore, if observing the human face is seen as a “communicational reaction” (\citeyear{Lautenbacher2012}: 145--146), Lautenbacher sees a possibility of successfully integrating “significance and social attention triggered by human face and text” (\citeyear{Lautenbacher2012}: 145--146) and concludes that a “global, integrated approach to the translation of audiovisual documents” (\citealt{Lautenbacher2012}: 153) is needed. As Gottlieb states, it is “hardly surprising [that] this additive nature of subtitling – in which the near-empty visual verbal channel is suddenly ‘flooded’ with subtitled lines – changes the working strategies of the translator as well as viewers’ strategies of perception” (\citeyear{Gottlieb2012}: 39). Whether the \isi{eye tracking} of subtitles can simply be seen as a combination of reading and image processing or should be treated as a separate field with unique characteristics and challenges will be discussed in the following chapter.

\section{Eye tracking and subtitling}\label{sec:6.3}

Perceiving and processing subtitles is very different to reading static texts or looking at static scenes. The combination of \isi{eye tracking} and dynamic content such as film creates challenges such as the high probability of moving fixated elements (cf. \citealt{Huff2010}) and deviating reading strategies:
\begin{quote}
[…] any text that appears in film (e.g. subtitles), is on screen for a limited period of time, forcing the reader to adopt reading strategies that differ slightly from those in the reading of static text where the reader is much more in control of the pace of reading. (\citealt{Kruger????}; cf. \citealt{Kruger2014})
\end{quote}
Film viewers have to “read at a pace imposed by the movie” (\citealt{schotter2012}: 83) and keep shifting their gazes between image and subtitle (\citeyear{schotter2012}: 83). The goal of performing \isi{eye tracking} on subtitles is to create an understanding of, on the one hand, what is perceived in the image, the \isi{fixation duration} on relevant elements in the scene, and on the other hand, the processing of audiovisual text, how fast and thoroughly the audiences read the subtitles and what parts they fixate longer, how they split their \isi{visual attention} between image and film, and – of course – the overall impact of the subtitles on the audience’s comprehension of the film (cf. \citealt{Fox2012}, \citealt{Kruger????}). Concerning perception, Lautenbacher summarises it this way:
\begin{quote}
Because of the \isi{simultaneity} of these visual elements, the question is whether this combination of pictures and text creates a contradiction in the perception process or not. More specifically, with subtitled films, the question is how this combination affects the reception of films, and what implications this might have for subtitling strategies. (\citeyear{Lautenbacher2012}: 135)
\end{quote}
When faced with the question whether the presence of subtitles might “over-shadow important semiotic pictorial elements for meaning construction or diegesis in film” (\citealt{Lautenbacher2012}: 149), subtitles should be seen as part of the many elements films consist of and that build the “overall meaning of an audiovisual document” (\citealt{Lautenbacher2012}: 150). In Belgium, d’Ydewalle and his colleagues conducted some of the first and during recent years most relevant \isi{eye tracking} studies on subtitling. The first studies focused on attention allocation (e.g.  \citealt{Dydewalle1985}) and how it overlaps with sound, image and text (see \citealt{Dydewalle1992}). While these studies laid the foundations of today’s \isi{eye tracking} research on subtitles and indicated “a human propensity to read what is on the screen to be read” (\citealt{Lautenbacher2012}: 148, cf. “Automatic Reading Behaviour”, \citealt{Dydewalle1991}), the study conducted in \citeyear{Dydewalle2007} by d’Ydewalle and De Bruycker brought “\isi{eye tracking} research in AVT to the next level” (\citealt{Kruger????}) – it illustrated that automatic processing of subtitles does indeed take place and that two-line subtitles were processed more thoroughly and being skipped less. Recent years have produced a wide variety of studies focused on aspects such as the processing of linguistic features or suitable presentation rates. \citet{Ghia2012} found significantly more deflections in the presence of non-\isi{literal translation}, therefore showing the impact of the translation quality on subtitle reading, and \citet{moran2008} discussed the effects of linguistic variation on the reception of subtitles. Jensema and colleagues focused on changes in eye-movement patterns and researched the impact of presentation rate on \isi{deaf} viewers (\citeyear{Jensema-Danturthi2000}), finding that hearing viewers spent between 10 and 31.8\,\% on subtitles and \isi{deaf} viewers up to 84\,\% (\citeyear{Jensema-ElSharkawy2000}, \citeyear{Jensema-Danturthi2000}). Szarkowska and colleagues found similar values while studying the impact of verbatim, standard and edited subtitles (\citeyear{szarkowska2011}). While there was little difference for hearing participants, \isi{deaf} viewers’ attention allocation was very different in between these conditions: They spent just under 70\,\% on verbatim subtitles, 60\,\% on standard subtitles, and 50\,\% on what they called ‘edited subtitles’. The hard-of-hearing spent 60\,\% on verbatim and under 50\,\% on edited subtitles.

\citet{romero-fresco2015} finally deviates from the strict separation of image and subtitle processing and focuses on the overall viewing speed opposed to “\isi{presentation speed} or \isi{reading speed}” (\citealt{Kruger????}). He defines viewing speed as “the speed at which a given viewer watches a piece of audiovisual material, which in the case of subtitling includes accessing the subtitle, the accompanying images and the sound” (\citeyear{romero-fresco2015}: 337). His extensive \isi{eye tracking} study showed that \isi{presentation speed} is closely connected to the \isi{split attention} between image and subtitle reading. While viewers spent about 60\,\% of the time on the image at a speed of 120~wpm (words per minute), increasing the speed to up to 200~wmps, viewers spent less and less time on the image with finally only exploring the image 20\,\% of the time a subtitle was visible. This is of course closely connected to the decreasing time available to read the subtitle and offers good indicators of what makes a suitable \isi{presentation speed}.

Studies as the one by Romero-Fresco show that there are not only differences in the \isi{reading behaviour} of static text and subtitles but also in the way it is measured. Therefore, the following section will provide a basic overview of suitable \isi{eye tracking} measures for the analysis of subtitle reception.

\subsection{Measuring eye movements in AVT}\label{sec:6.3.1}

Based on recent \isi{eye tracking} research on audiovisual translation (\citealt{Dydewalle1991}; \citealt{Dydewalle2007}; \citealt{moran2008}; \citealt{Caffrey2009}; \citealt{Ghia2012}; \citealt{Kruger2014}), a number of values and measurements of \isi{eye tracking} in audiovisual translation can be identified. Kruger lists the following as most useful:

\begin{itemize}
\item \textit{Mean \isi{fixation} duration}: This measure provides a useful index of the \isi{processing effort}, but should be used only to compare similar activities (e.g. reading of different types of subtitles and not reading to \isi{scene perception}).
\item \textit{Dwell time}: This provides a measure of the total time viewers spent looking at a particular area of interest, including both fixations and saccades.
\item \textit{Number of fixations per word}: This is particularly useful when an attempt is made to measure the extent to which subtitles were processed, although a more nuanced measure would take into account refixations and regressions.
\item \textit{Average forward \isi{saccade} length}: Like the number of fixations per word, this measure makes it possible to determine whether viewers performed regular reading.
\item \textit{Glance count}: This measure gives an indication of the number of times viewers shifted between different areas on the screen (e.g. image and subtitle)
\item \textit{Number of skipped subtitles:} This is a fairly rough indication of how many subtitles were not even noticed by viewers, but should be considered together with other measures (\citealt{Kruger????}).
\end{itemize}

Further interesting measures are the latency time, or ‘\isi{reaction time}’ or ‘response time’, the “time between the appearance of the subtitle and the \isi{first fixation} on the subtitle” (\citealt{Kruger????}), the \isi{saccade} amplitude or \isi{saccade length}, regressions and revisits, \isi{fixation} counts and total \isi{fixation duration}.

\subsection{Relevant studies}\label{sec:6.3.2}

While there is a noticeable number of \isi{eye tracking} studies on subtitling in general,\footnote{For an overview, see \citet{perego2012}.} there are only a few studies on alternative subtitling strategies similar to integrated titles. In the following, four studies will be presented. The studies by \citet{Kunzli2011} and \citet{Caffrey2009} are relevant due to their structure and use of both \isi{eye tracking} and questionnaire data to investigate innovative subtitling strategies. The other two studies by \citet{Armstrong2014} and \citet{Brown2015} are relevant due to their focus on what they call “dynamic subtitles”, a concept similar to integrated titles.

Künzli and Ehrenberger-Dow looked at the “reception capacity and audience response” (\citeyear{Kunzli2011}: 187) of 27 participants that watched four film excerpts with either standard subtitling or “innovative subtitling” (\citeyear{Kunzli2011}: 187). These innovative subtitles (or surtitles) comprised “additional information regarding language and culture-specific elements in the original soundtrack” (\citeyear{Kunzli2011}: 187) and were investigated by means of simultaneous \isi{eye tracking} and consecutive questionnaires. The reception was analysed based on mean \isi{fixation} durations and percentage of \isi{gaze} time in specific areas. The questionnaire focused on film content, its perception and the participant’s satisfaction. While they did not find significant differences in between the two modes (possibly due to the very specific participant group of young students), the experiment design provides a good basis for similar studies.

\citet{Caffrey2009} investigated the impact of pop-up glosses similar to the surtitles in Künzli and Ehrensberger-Dow. They are mostly used in the translation of Japanese \isi{anime} and originate from fansubbing. Based on \isi{eye tracking} measures such as skipped subtitles, \isi{gaze} time, \isi{mean fixation duration}, \isi{word fixation probability}, and \isi{pupil size}, he reported “a higher number of skipped subtitles, and a lower percentage \isi{gaze} time in the \isi{subtitle area}, lower \isi{mean fixation duration}, and lower \isi{word fixation probability}” (\citealt{Kruger????}). The questionnaire data suggested an increase of the \isi{processing effort} and the perceived subtitle speed.

In their 2014 TVX conference paper, \citet{Armstrong2014} discussed the enhancement of subtitles through “integrating them with the moving image, and enabling choice in subtitle size and style” (\citeyear{Armstrong2014}). Besides discussions of the \isi{placement}, ways of feature avoidance, and the relevance of the screen size, Armstrong and Brooks developed a “positional subtitle editor in HTML5 and JavaScript that reads popular subtitle formats and allows them to be positioned and saved” (\citeyear{Armstrong2014}) in BBC’s own format. While this is also possible with editors such as \textit{Aegisub},\footnote{Cf. \url{http://www.aegisub.org} [2016--08--07].} the editor includes a simple image analysis that scores “areas of the image based on how much they change, and whether they contain an important feature such as a face or on-screen graphics” (\citeyear{Armstrong2014}). Additionally, their subtitle format includes the bounding box of the subtitle and therefore allows for easy cross-referencing with and visualisation of the corresponding \isi{eye tracking} data.

Their study included four 90 seconds clips from three episodes of the BBC drama series \textit{Sherlock}. Five versions were created that combined French audio with traditional and dynamic subtitles, English audio with traditional and dynamic subtitles, and one unaltered version without subtitles as a baseline for comparison. Using a Tobii X-120, they recorded the \isi{gaze behaviour} of 24 English native speakers who did not understand French and were not habitual subtitles users. They created 420 areas of interest for the subtitles and found that “people spent less time reading subtitles, and more time looking at the drama when using dynamic subtitles” (\citealt{Armstrong2014}, cf. \citealt{Brown2015}).

In a follow-up article, Brown et al. designed two more experiments on the “dynamically positioned subtitles” (\citeyear{Brown2015}) presented in the 2014 article, one of them with hearing-impaired users. They compared the baseline of viewers without subtitles with the \isi{gaze behaviour} of viewers with dynamic subtitles and found it to be closer to the baseline for dynamic subtitles. They used a 1:50 minutes clip from \textit{Sherlock} (S01E01) with 34 subtitles and presented it to 26 participants that were habitual subtitle users (on a daily basis) and eight~participants that would watch it without subtitles and were no habitual subtitle users. As factors for the \isi{placement} of the dynamic subtitles, they named “the character speaking the line; the background; and; the position of the previous and subsequent subtitles” \citep{Brown2015}. For four subtitles, they tested alternative positions and re-authored these and two more. The subtitles were displayed in the \isi{sans-serif} \isi{typeface} Helvetica Neue in 32 pixels, white, and with a slim black outline. They kept the timing of the traditional subtitles.

Based on their research on \isi{user experience} (UX) design, they propose a new framework for subtitle evaluation that takes into consideration \isi{visual attention}, \isi{aesthetics}, involvement, familiarity, perceived usefulness, perceived \isi{usability}, and endurability \citep{Brown2015}. The measurement of the \isi{gaze} pattern based on dwell time was inconclusive between the traditional and dynamic subtitle conditions. Their interview-based qualitative analysis, however, revealed that five participants disliked the dynamic titles, eight participants were “broadly positive” and twelve “very keen on the idea” \citep{Brown2015}:
\begin{quote}
The majority of people who watched dynamic subtitles enjoyed the experience, and wanted to try them further. A number of participants were very keen, and would have liked to convert to dynamic subtitles immediately. \citep{Brown2015}
\end{quote}
Participants wished for \isi{speaker identification}, \isi{readability} and subtitles not obscuring the action. Brown et al. concluded that participants felt more immersed and missed less (\citeyear{Brown2015}). They found \isi{gaze} patterns more similar to the baseline without subtitles and those participants who disliked the dynamic titles stated that they did not really rely on subtitles anyway. The most enthusiastic participants were those who rely “on subtitles as an access service” \citep{Brown2015}, therefore Brown et al. concluded that it would be “desirable for viewers to have the option to revert to traditional subtitles if they, or their viewing companions preferred” (\citeyear{Brown2015}).

\section{Eye tracking and usability research}\label{sec:6.4}

As mentioned in \sectref{sec:3.2} and as there are no specific \isi{usability} guidelines for subtitles, Mosconi and Porta recommend to generally apply web accessibility and \isi{usability} rules to them (\citealt{mosconi2012}). Similarly, there’s little \isi{eye tracking} research in the area of subtitle \isi{usability} or \isi{layout}. And while \isi{eye tracking} has been present in cognitive studies for quite some time, it is still comparably new in the area of \isi{usability research}. Schiessl et al. see the limitations of “conventional methods […] to those processes which are part of conscious reflection and conscious control” (\citeyear{schiessl2003}: 2) while \isi{eye tracking} can “provide detail data about the users’ \isi{visual attention} on user interface elements” (\citealt{manhartsberger2005}: 141; cf. \citealt{schiessl2003}: 2) and as “source of information about user behaviour” (\citeyear{schiessl2003}: 2). It can “provide insight into users’ decision making while searching and navigating interfaces” (\citealt{Goldberg2002}: 3) and allows understanding of “visual and display-based information processing and the factors that may impact upon the \isi{usability} of system interfaces” (\citealt{poole2005}: 1). As \isi{eye tracking} can “unveil response biases of subjects due to an artificial testing environment” (\citealt{schiessl2003}: 9), its use often “results in a higher validity of \isi{usability} data” (\citeyear{schiessl2003}: 9). Limitations and shortcomings are discussed in \citet{Jacob2003}.

The \isi{main focus} of \isi{eye tracking} studies in \isi{usability research} is the allocation of \isi{visual attention} and “amount of processing” (\citealt{Jacob2003}) an item receives, usually in order to improve interfaces, processes, human-computer interaction (HCI), and real-time \isi{eye tracking} for disabled users (for a discussion of \isi{eye tracking} as an input device, see e.g. \citealt{Jacob2003}, \citealt{Kaur2003}, \citealt{poole2005}: 8ff.) in both “commercial and academic practice” (\citealt{Ehmke2007}: 1). Especially websites and software programmes are being analysed in eye tracking-based \isi{usability research} and the demand “is flourishing and it is becoming more common to include eye-tracking in the range of techniques used for this purpose” (\citealt{Ehmke2007}: 2). Researchers analyse visualisations of \isi{eye tracking} data to “identify confusion on the part of the user, reading or scanning behaviours, or simply […] areas that users are not looking at” (\citealt{Ehmke2007}: 2). Studies such as \citet{Goldberg2002} indicate a “connection between eye-tracking patterns and users’ decision making processes” (\citealt{Ehmke2007}: 2). Common topics are the distinction between reading or scanning text elements (\citealt{manhartsberger2005}: 147f.), wording problems as users will “rather ignore a link they do not understand, than finding out what is behind that link” (\citeyear{manhartsberger2005}: 149), the definition and testing of \isi{layout} and web standards (\citeyear{manhartsberger2005}: 150), affordance, i.e. the degree of “an object’s sensory characteristics intuitively [implying] its functionality and use” (\citeyear{manhartsberger2005}: 150), and “wrong eye catchers and vampire effects” (\citeyear{manhartsberger2005}: 151) that “draw away and consume the users attention completely” (\citeyear{manhartsberger2005}: 151).

In using \isi{eye tracking}, researchers try to relate eye movement patterns to specific \isi{usability} problems. Ehmke and Wilson give an overview of common \isi{usability} problems such as “expected information missing” (\citeyear{Ehmke2007}: 9), “ineffective presentation” (\citeyear{Ehmke2007}: 9) or “unclear input format” (\citeyear{Ehmke2007}: 9) that can be based on single eye movement measures or a combination of patterns, i.e. correlating “a high number of fixations across the page and navigation, followed by fixations on one element only” (\citeyear{Ehmke2007}: 9) to the \isi{usability} problem of “ineffective presentation through unclear item grouping” (\citeyear{Ehmke2007}: 9). The following measures and possible interpretations are mentioned in Ehmke and Wilson (\citeyear{Ehmke2007}: 2), based on Poole and Ball (\citeyear{poole2005}: 4ff.) and Jacob and Karn (\citeyear{Jacob2003}: 582):

\begin{itemize}
\item \textit{Overall number of fixations}: This measure is “thought to be negatively correlated with search efficiency […]” (\citealt{Jacob2003}: 585) and is usually strongly connected to the task duration (\citeyear{Jacob2003}: 585).
\item \textit{Gaze (\%) on each AOI}: The “proportion of time looking at a particular display element (of interest to the design team) could reflect the importance of that element” (\citealt{Jacob2003}: 585).
\item \textit{Overall \isi{fixation duration} mean}: Long fixations can indicate interest or confusion (\citealt{Ehmke2007}: 2) or “a participant’s \isi{difficulty extracting information} from a display […]” (\citealt{Jacob2003}: 585).
\item \textit{Number of fixations on each AOI}: Used by \citet{Cowen2002} in connection to the “standard task performance measure (time)” (\citealt{mccarthy2003}: 404). It is also said to be “strongly correlated with task duration, and this measure has been used as a proxy for measures of task performance […]” (\citealt{mccarthy2003}: 404).
\item \textit{Gaze duration mean on each AOI}: This can reflect the “difficulty of information extraction” (\citealt{mccarthy2003}: 409; cf. \citealt{Fitts1950}) and is “longer if participant experiences difficulty” (\citealt{Jacob2003}: 585). Gaze frequency can reflect the “importance of that area of the display” (\citeyear{Jacob2003}: 585).
\item \textit{Overall \isi{fixation} rate}
\item \textit{Scanpath}: An analysis of the scanpath can indicate the “efficiency of the arrangement of elements in the user interface” \citealt{Jacob2003}: 585). Goldberg and Kotval (\citeyear{Goldberg1999}) defined an optimal scanpath as a “straight line to a desired target, with relatively short \isi{fixation duration} at the target” (\citealt{poole2005}: 6). The scanpath length can indicate “less efficient searching (perhaps due to a sub-optimal \isi{layout})” (\citeyear{poole2005}: 6) and the “transition probability between \isi{AOIs}” (\citealt{Ehmke2007}: 4) can “indicate efficiency of the arrangement of elements in the user interface” (\citeyear{Ehmke2007}: 4).
\end{itemize}

Jacob and Karn also mention the “number of gazes on each area of interest” (\citeyear{Jacob2003}: 582), the “number of involuntary and number of voluntary fixations” (\citealt{Ehmke2007}: 585), the “percentage of participants fixating an area of interest” (\citeyear{Ehmke2007}: 585) as this “can serve as a simple indicator of the attention-getting properties of an interface element” (\citeyear{Ehmke2007}: 586), and the “time to \isi{first fixation} on target area of interest” as a “useful measure when a specific search target exists” (\citeyear{Ehmke2007}: 586). Goldberg and Kotval (\citeyear{Goldberg1999}) also name the following measures: Number of fixations, (total) \isi{fixation duration}, average \isi{fixation duration}; \isi{fixation}/\isi{saccade} ration, \isi{fixation} spatial density (as a “global measure of the total amount of processing performed on each page” \citep{Cowen2002}, and \isi{saccade} amplitude (as “larger saccades can indicate more meaningful cues, as attention is drawn from a distance” [\citealt{Ehmke2007}: 2]). Finally, \citet{mccarthy2003} added “glance frequency”, defined as “one or more successive fixations to the same screen object” (\citeyear{mccarthy2003}).

Further possibly interesting aspects of eye movement behaviour mentioned by Ehmke and Wilson (\citeyear{Ehmke2007}: 2) are backtracking saccades that can indicate confusion, participants not looking at specific elements, scanning and searching behaviour instead of \isi{reading behaviour}, specific patterns such as a back and forth between two elements, the first and last area or element users look at, and interaction such as clicking or following links. This behaviour should be “discussed with users afterwards” (\citealt{Ehmke2007}: 2) or the study extended with “retrospective protocols […] to explain their decisions and thoughts”, e.g. in form of post-experience eye-tracked protocols (PEEP, cf. \citealt{Ball2006}).

Concerning the relevance for the present topic, the study by \citet{mccarthy2003} is especially interesting: They analysed the conflicting advice on the best position for navigation menus on websites,\footnote{Concerning web search, relevant studies include the Stanford-Poynter study (\citealt{Lewenstein2000}; cf. \citealt{mccarthy2003}: 403), \citet{Cowen2002}, and \citet{Goldberg2002}.} as these either follow user expectations or are based on “results from user testing with alternative layouts” (\citeyear{mccarthy2003}: 401). Their results show that “users rapidly adapt to an unexpected screen \isi{layout}” (\citeyear{mccarthy2003}: 401) and concluded that “designers should not be inhibited in applying design recommendations that violate \isi{layout} conventions as long as consistency is maintained within a site” (\citeyear{mccarthy2003}: 401). While \citet{nielsen1999} found that menu labels that follow user expectations lead to an 80\,\% success rate in product search and only 9\,\% if not (\citealt{mccarthy2003}: 401) and also IBM design guidelines (\citeyear{Ibm2003}) recommend \isi{placement} in expected areas – in the case of navigation menus, in the upper left area of a site. McCarthy et al. see web search as a combination of expectations that “exert a top-down influence” (\citeyear{mccarthy2003}: 402; cf. \citealt{Goldberg2002}) and the display that “exerts a bottom-up influence” (\citeyear{mccarthy2003}: 402; cf. \citealt{Goldberg2002}), influenced by e.g. “layering, separation, colours and contrast” (\citeyear{mccarthy2003}: 402, cf. \citealt{tufte1990}) as well as “motion or animation” (\citeyear{mccarthy2003}: 402; cf. \citealt{Hillstrom1994}). McCarthy et al. tested for a difference in simple and complex websites and found differences in task duration (\citeyear{mccarthy2003}: 407), confirming their hypotheses that “performance will be better with the left menu” (\citeyear{mccarthy2003}: 407), meaning the menu being placed in the expected area. However, this only applied to the “first page visit” (\citeyear{mccarthy2003}: 407). The users’ expectations are “rapidly updated to reflect the \isi{layout} of the current page” (\citeyear{mccarthy2003}: 407) and “showed a significant decrease in task completion time after the first page visit” (\citeyear{mccarthy2003}: 409). They see the advantage of “sites that conform to expectations” (\citeyear{mccarthy2003}: 412) as “short-lived” (\citeyear{mccarthy2003}: 412), which shows that “violating the expectation or convention of the left menu bar has little long-term effect on task performance” (\citeyear{mccarthy2003}: 412). They noted a “rapid adaption to the unexpected \isi{layout}” (\citeyear{mccarthy2003}: 413), which led to their conclusion that mainly the “internal consistency of a site […] is important” (\citeyear{mccarthy2003}: 413). As the integrated titles analysed in the present study also violate \isi{placement} and \isi{layout} conventions as well as user expectations, their \isi{usability} is a relevant issue, reflected in the applied eye movement measures and the reported \isi{enjoyment} and \isi{entertainment value} by the viewers.

\section{Summary}\label{sec:6.5}

Eye tracking research and reading studies have shown that “visual exposure to letters automatically activates a processing stream that cannot be interrupted intentionally” (\citealt{Hvelplund2014}: 209; cf. \citealt{Valdes2005}: 279) and that fixations and their analysis in reading take place word-based. Typographical variables can influence eye movements (\citealt{rayner2009}: 1460) and salient features in images are highly relevant, revealing human faces and \isi{gaze} directions as strong \isi{gaze} catchers (\citealt{Lautenbacher2012}: 141f.). Subtitled film, however, has to be treated as a separate, very specific field of both \isi{scene perception} and reading: Text is only visible a limited period of time and the \isi{reading speed} is imposed by the film (\citealt{schotter2012}: 83). Additionally, \isi{gaze} shifting between image and subtitles sets audiovisual products apart from static text or \isi{scene perception}. Researchers look at what is perceived, the \isi{fixation duration} on specific elements, the \isi{split attention} between image and subtitle, text processing, and image processing. In that combination, statements on the overall perception, comprehension, and \isi{enjoyment} of subtitled film can be made and basic \isi{usability} problems be discussed.

To gain further basic insight into the perception of integrated titles, the impact of position and \isi{layout} of integrated titles will be investigated. Simultaneous \isi{eye tracking} will be used to analyse the perception and cognitive processing, analysing \isi{mean fixation duration}, dwell time (in \isi{AOIs}), and \isi{reaction time}. Additionally, a \isi{post-hoc questionnaire} will focus on \isi{enjoyment}, satisfaction, the \isi{aesthetic experience} of the participants and the \isi{usability} of the integrated titles. The aim is to determine whether there are differences in the perception and \isi{enjoyment} of integrated titles compared to conventional subtitles.

