\chapter{Audiovisual translation}\label{audiovisual}

Audiovisual Translation comprises all those modes of translation that are applied with multimodal texts based on both auditory and visual channels (cf. \citealt{Jungst2010}:~1). It provides “access to […] audiences who are either excluded from one or more of the auditory or visual codes, or who only have partial access to these codes” (\citealt{Kruger????}), including various kinds of subtitling and \isi{synchronisation}, it also includes game localisation and the translation of other modern multimedia products. Four communication channels can be differentiated according to Gottlieb (\citeyear{Gottlieb1998}:~245):

\begin{itemize}
\item \textit{Verbal auditory channel}: This channel includes all auditory elements produced by speech, thus not only dialogues etc. but also background voices or song lyrics.
\item \textit{Non-verbal auditory channel}: This channel includes non-verbal music elements as well as all background noises.
\item \textit{Verbal visual channel}: This channel covers all written texts in the film material such as subtitles, displays, and captions.\footnote{More details on the various types of text elements are to be found in \sectref{sec:2.4}.}
\item \textit{Non-verbal visual channel}: Here, all the elements that create the overall image are summarized.
\end{itemize}

Based on these channels, a number of common shifts between these channels can be defined:

\begin{itemize}
\item \textit{Diasemiotic translation}: In this type of translation, a shift from channel a) to c) takes place (\citealt{Leisner2009}:~24), which means a conversion from spoken elements to written text. Accordingly, diasemiotic translation describes the subtitling process. As text not included in the original version is added, this change is of an “additive” (\citealt{Leisner2009}:~25) nature.
\item \textit{Isosemiotic translation}: With this form of translation, the verbal \isi{auditory channel} is retained. It describes different types of \isi{dubbing}: \isi{synchronisation}, commentary, voice-over, etc. In general, they are usually considered to be “replacing” (\citealt{Leisner2009}:~25) elements, although they are sometimes better characterized as additive, for example when an additional sound track is added, e.g. during the voice-over.
\item \textit{Intersemiotic translation}: In addition to the common types of translation, Jüngst describes this change of channel which she also refers to as “transmutation” (\citeyear{Jungst2010}:~5). This term defines a change in the sign system, so a shift from d) to a) (picture to spoken elements) or vice versa – for example verbal to non-verbal or auditory to visual. This includes, among others, the description of the picture for the blind.
\end{itemize}

The following \tabref{tab:TAB1} lists the main forms of audiovisual translation that can be distinguished.

\begin{table}[b]
\begin{tabularx}{\textwidth}{lQl}
\lsptoprule
 Form &  Professional &  Non-professional\\
 \midrule 
 Subtitling & Conventional subtitling\footnote{This work makes use of both the terms ‘traditional subtitles’ as it was used in the underlying pilot study and the term ‘conventional subtitles’ (\citealt{Foerster2010}: 81). They are considered interchangeable.} & Fan subs\\
& (Semi-)live subtitling & \\
& Subtitles for the \isi{deaf} and hard-of-hearing (SDH) & \\
\tablevspace
 Synchronisation & \isi{dubbing} & Fan dubs\\
& Voice-over & \\
& Commentary & \\
& Audio description & \\
\lspbottomrule
\end{tabularx} 
\caption{Forms of Audiovisual Translation}
\label{tab:TAB1}
\end{table}

Synchronisation or ‘\isi{dubbing}’ is a substituting form of translation and should be as synchronous as possible with regard to lexis, syntax, semantics, etc. This means that the audiovisual translation has to match lip movements as well as gestures and facial expression in the film material (\citealt{Herbst1994}:~87, \citealt{Leisner2009}:~23). For a long time, \isi{synchronisation} aimed to convince the viewer of watching the original version of the film. In Germany, it is the main form of translation used for film material and games. Regarding the dominance of \isi{synchronisation} in comparison to subtitling still being prevalent, Jüngst (\citeyear{Jungst2010}:~5) assumes that because of the numerous jobs related to it as well as of the habituation of the audience, “countries of synchronization […] will presumably stay countries of synchronization” (\citeyear{Jungst2010}:~5). However, Jüngst admits that due to DVDs no clear prediction can be made “since DVDs have massively changed the habits of watching and the young generation might be already completely used to watch subtitled versions” (\citeyear{Jungst2010}:~5), including subtitled videos on the internet and fan-produced subtitles.

The voice-over aims at a true translation as synchronous as possible to the original text (OT). In addition to the OT, a translation is put “over” it, while reducing the volume of the original to a minimum (\citealt{Luyken1991}:~80; \citealt{Leisner2009}:~21). The translation begins a little later and ends a bit earlier (\citealt{Herbst1994}:~19). Complete \isi{synchronisation} is not the objective and the voice-over is mainly used for newscasts and interviews, but can also be found in fiction films in America and Eastern Europe (cf. \citealt{szarkowska2009}). Moreover, narration is also counted as voice-over. In narration however, the text is shortened and altered, therefore the translation is an entirely different lingual process. This more formal result is usually used for documentary productions (\citealt{Luyken1991}:~80; \citealt{De_linde1999}:~2; \citealt{Gambier1994}:~276).

Similar to narration, \isi{dubbing} for commentaries does not aim for a true translation. A modification of the foreign language film material for the target language and culture takes place. Due to deletions, additions, etc., a “new” original is produced (\citealt{Luyken1991}:~82; \citealt{Leisner2009}:~22).

Furthermore, so-called audio described films are produced for the blind and visually impaired who cannot, or only partially, access the visually channels. They are equipped with an “audio description” (\citealt{Jungst2010}:~3) that describes what can be seen in the film. They therefore offer access to the visual channels by describing elements relevant to the story as well as the overall atmosphere visible in the image. While the various audiences include a range of needs from people who are born blind to partially visually impaired people and those who became blind later in their life, the goal is usually the same: to provide understanding and \isi{enjoyment}.

Another rather rare and very specific form is the live interpretation, which is only used at festivals (\citealt{Jungst2010}: 3). This interpretation can be simultaneously heard through headphones or loudspeakers while the original is playing. It is used less and less often.

\newpage 
While the audience for \isi{synchronisation} is one of the least heterogeneous, targeting exclusively hearing viewers that cannot understand the language in the original film, subtitling has a wide range of target groups: \isi{deaf} audiences,\footnote{This includes both viewers that were born \isi{deaf} or became \isi{deaf} before spoken language acquisition and after.} hard-of-hearing audiences, viewers with cognitive disorders, language learners, and those who need \isi{interlingual} translation. The following section will give an overview over the various kinds of subtitles, challenges, and strategic solutions.

\section{Subtitling}\label{sec:1.1}

Intertitles, or title cards (\citealt{Diaz_cintas2007}:25), are often seen as the “origin of subtitles” (\citealt{Diaz_cintas2007}:~26) and accompanied the first silent films. Modern subtitling is defined as “diamesic translation in polysemiotic media (including films, TV, video, and DVD) in the form of one or more lines of written text presented on the screen in sync with the original verbal content” (\citealt{Gottlieb2012}:~37). Nowadays, there are at least three types of text that can be found in a film: subtitles, captions, and displays. These can be accompanied by additional text elements such as the \isi{film title}, inserts, prologues and epilogues, opening and closing credits or other elements that do not always require a translation. While a subtitle is a written \isi{intralingual} or \isi{interlingual} translation of the spoken content, the other text elements might already exist in the original film and might or might not require translation. Captions are types of information which are important for a plot of a film, and which are inserted on a separate layer in the foreground. Typical captions are, for example, people’s names and indications of places or time. Displays, however, are an essential component of the picture such as street names, letters, and newspaper headlines. They are additionally mentioned in the subtitle according to their relevance whereas captions usually appear in the subtitle (unless they are comprehensible without subtitling as it is usually the case for people’s names and indications of places). As significant progress has been made and there seems to be more liberty in the creative handling of these additional written information than with subtitles, \sectref{sec:2.4} gives an overview of the various text elements in film and their visual translation. 

Most challenges and shortcomings in subtitle production arise due to the overt character of subtitles: They are superimposed on the original and co-exist with the source text in an interlinear way, and therefore are constantly open to comparison and criticism if the audience has at least basic knowledge of the source language. While the term ‘captions’ is often used to describe additional text elements such as name and place indicators, in the United States they refer to the subtitles for the \isi{deaf} and hard-of-hearing – either simply as “captions” or “closed captions” (CC, \citealt{Diaz_cintas2007}:~14).

Gottlieb describes five types of subtitles (\citeyear{Gottlieb2012}: 43--44):
\begin{itemize}
\item I   normally visible (= \textit{open}) subtitles for special cinema screenings,
\item II   open TV subtitles broadcast as part of an analogue transmission signal,
\item III   optional (= \textit{closed}) TV subtitles, transmitted via teletext (Santiago 2007),
\item IV   closed TV subtitles broadcast digitally, and
\item V   optional DVD subtitles selected via the on screen menu.
\end{itemize}

As is visible from this classification, subtitles are technically divided into ‘open’ and ‘closed’ (\citealt{Diaz_cintas2007}:~21). Open subtitles are always visible, including not only the mentioned analogue broadcast or special screenings but also subtitles that are part of the original version of a film, e.g. as translation of an \isi{additional language} (see \chapref{overview} for examples). Closed subtitles, on the other hand, can be switched on optionally, including \isi{intralingual} and \isi{interlingual} subtitles in television, video-on-demand and DVDs respectively Blu-rays. Digitally extracted professional subtitles and fan-produced subtitles (“Fansubs”, \citealt{ohagan2009}:~94) can also often be downloaded and then added to a film or programme. Gottlieb also defines at least nine forms of \isi{interlingual} subtitles (\citeyear{Gottlieb2012}:~45). Multilingual subtitling that includes more than one language\footnote{Bilingual or multilingual subtitles are often used in countries that have more than one official language such as Belgium (Dutch, French, and German) and Finland (Finish, Swedish, and Sami). In these countries, each language takes up one or even two line(s) in the subtitle. Additional disadvantages arise, such as the image always being covered by at least two lines of text, a reduced display time and the general disadvantage of speakers of the language subtitled in the second row as they might intuitively read the previous line first.} and “pivot subtitling” (\citealt{Leisner2009}:~27), which works indirectly through a more common language when “movie material from an exotic language has to be subtitled” (\citealt{Leisner2009}:~27) can be seen as special forms of subtitling. Another specialised group of subtitles are those displayed during live performances such as conferences, in the theatre, at the opera or at concerts – called super-, supra- or surtitles (\citealt{Diaz_cintas2007}:~25). Since these variations are rather rare, too specialised and not especially relevant for this book, they will not be discussed in the following. 

Intralingual subtitling works exclusively with the language of the original film, with the hearing-impaired usually being the main target group. However, \isi{intralingual} subtitles are also very useful for a better understanding of foreign language films or dialects and accents and are widely used by language learners, studies including \citet{Danan2004}, \citet{Bianchi2007}, and \citet{remael2008}. Intralingual subtitles do not only provide access for entertainment reasons but also to daily information and target an audience far from homogeneous. Concerning hearing-impaired audiences, four major groups are usually distinguished here: Hard-of-hearing, people who became \isi{deaf} postlingually, people who were born \isi{deaf}, and those who wear Cochlear implants (CI).\footnote{For an overview and impression of the difference in frequency range of Cochlear implants, see \url{http://www.telegraph.co.uk/news/health/10848586/What-the-world-sounds-like-with-a-cochlear-implant.html} [2016--05--01].} While the hard-of-hearing and postlingually \isi{deaf} feel as part of the hearing society, an independent Deaf culture emerged (\citealt{Jungst2010}:~125), and while the first group usually develops the language of their country as their native language, people who became \isi{deaf} prelingually communicate with the sign language of their country or region that has its own grammar and distinctive features. The challenge for someone creating \isi{intralingual} subtitles is that of not only understanding the target audiences and their culture but also the physical and psychological implications of being \isi{deaf} or hard-of-hearing (\citealt{remael2007}:~44). Additional decisions have to be made concerning the presentation of information, its density, and the amount of supplementary information. While redundancies of auditory and visual information make it easier for a hearing audience to follow the plot presented as an polysemiotic audiovisual text, SDH also has to provide access to relevant noises and music, etc. (\citealt{neves2009}:~156). Professionals have to be literate in the film code and \isi{image composition} to be able to understand and communicate various effects (\citealt{neves2009}:~157) as well as understand the variety “in terms of literacy, hearing loss and socio-economic factors” (\citealt{Itc1999}:~4).

Relatively young subgroups of SDH are semi-live and live subtitles. They provide real-time access to live film material such as sport events, news programmes or political debates and are displayed with a delay of a few seconds. Also called “simultaneous subtitling” (\citealt{Luyken1991}:~80) and “real-time subtitling” (\citealt{orero2006}), it is prone to mistakes (\citealt{Jungst2010}:~138). Live subtitles are a live broadcasted written form of spoken language in television that is produced during the broadcast (see \citealt{Kraus2010}:~12) and normally offered as closed captions that can be added manually. Semi-live subtitles are pre-prepared subtitles (\citealt{Jungst2010}:~138--139) for live programmes that have a relatively dense script. The goal is to minimise the risk of mistakes, which is relatively high for live subtitling. Live subtitling and semi-live subtitling are often combined and produced with speech recognition software such as that offered by Nuance.\footnote{An overview of the \textit{Dragon} speech recognition software offered by Nuance can be found here: \url{http://www.nuance.com/dragon/index.htm} [2016--05--01].} Traditional guidelines for \isi{intralingual} subtitles are discussed in the following chapter.

Interlingual translation accounts for the largest part of audiovisual translation as this mode describes translations from one language to another (\citealt{Diaz_cintas2007}:~13). While Germany is historically and traditionally a \isi{dubbing country}, inter- and \isi{intralingual} subtitles are becoming more and more attractive, not only offering more access for hearing-impaired audiences but also catering to audiences that value the original audio channel of a film but do not (fully) understand the source language. Costing less than 10\,\% of lip-sync \isi{dubbing} (\citealt{media_consulting_group2007}:~38), subtitles generally allow for a higher number of films translated, more access for both hearing-impaired and hearing viewers as well as a faster overall process while adding an additional text layer instead of replacing the verbal audio track.

However, subtitles are seen as a “necessary evil” (\citealt{Foerster2010}:~82; cf. \citealt{marleau1982}) and cannot fulfil the often voiced demand of “transparency of the target text and […] invisibility of the translator” (\citealt{Foerster2010}:~83) that “still dominate[s] the commercial world” (\citealt{Foerster2010}:~83). Norms and guidelines demand “invisibility” (\citealt{Ivarsson1998}:~157--159) and that subtitles “blend in with the film in such a way that the viewer doesn’t notice them” (\citealt{subtitling_international_uk1994}:~3). While \isi{dubbing} sometimes might be able to “provide the illusion of the original” (\citealt{subtitling_international_uk1994}:~3), “this industry does not pay much attention to the actual process of translation, and tends to adhere overwhelmingly to domesticating translation theories and to producing the illusion of transparency” (\citealt{subtitling_international_uk1994}:~83--84). Díaz Cintas and Remael describe this predicament the following way:
\begin{quote}
However, the general opinion is that the best subtitles are those that the viewer does not notice. From this perspective, the subtitler’s task seems to be a contradiction in terms: to provide a translation that is written a posteriori on the original programme, flashes in and out at the bottom of the screen but pretends not to be there. (\citeyear{Diaz_cintas2007}: 40)
\end{quote}

This “attempt at invisibility […] tends to have a negative impact on the social recognition of subtitlers” (\citealt{Diaz_cintas2007}: 40), even though they have the same copyright as writers (\citealt{Ivarsson1992}: 106). 

The skopos of the source text should determine the approach (\citealt{stolze1997}:~155) and even though Benjamin speaks of the content of translation, his demand for transparency (\citeyear{Benjamin1972}:~18) seems to apply to subtitling, considering its interlinear character. Source and target texts are available at the same time and “aiming for invisibility becomes a paradox verging on the absurd” (\citealt{Foerster2010}:~83): “Subtitles have never been and will never be invisible” (\citealt{Foerster2010}:~83) – so we should try to make the best out of their presence instead of denying it.

Due to this \isi{simultaneity} of source and target text and their combination with the moving image, viewers have to split their \isi{visual attention} between reading the subtitles and processing the image (\citealt{Bayram2012}). This and other characteristics of subtitles such as time and space constraints lead to several challenges subtitle professionals and viewers are confronted with. Common strategic solutions to these challenges and a basic set of guidelines are summarised in the following section.

\section{Strategic solutions for subtitles}\label{sec:1.2}

Subtitling and its various subgroups have lacked binding norms ever since. However, there are basic guidelines concerning both \isi{interlingual} and \isi{intralingual} subtitles most subtitle professionals agree on. These are reflected in articles such as the “Code of Good Subtitling Practice” (\citealt{Ivarsson1998}:~157--159) and “A Proposed Set of Subtitling Standards in Europe” \citep{Karamitroglou1998}, various books and book chapters (e.g. \citealt{Leisner2009}; \citealt{Diaz_cintas2007}; \citealt{Diaz_cintas2007b}), as well as official guidelines by companies such as the “ITC Guidance on Standards for Subtitling” (Independent Television Commission, \citealt{Itc1999}) and the “BBC Online Subtitling Editorial Guidelines” (\citealt{Ford_williams2009}).\footnote{More information on British guidelines can be found here: \url {http://hub.eaccessplus.eu/wiki/ Standards\_and\_Guidelines\_for\_accessible\_audio-visual\_media\_in\_the\_United\_Kingdom} [2016--02--09].} While the lack of standardised norms can be criticised (\citealt{Leisner2009}:~30), it also provides – at least theoretically – creative freedom and room for adjustments for individual applications, just as with any other multimedia form of translation. Most authors of guidelines point out that “good subtitling is a complex balancing act” (\citealt{Ford_williams2009}:~3) and that “it will never be possible to apply all of the guidelines all of the time” (\citealt{Ford_williams2009}:~3) as they are sometimes “mutually exclusive” (\citealt{Ford_williams2009}:~3). It is therefore a “question of deciding which elements in the soundtrack merit reporting” (\citealt{Eaccess+2016}). Additionally, the focus of a set of guidelines might be on language, appearance, or a mixture of both. The ITC standard lists the subtitler’s priorities for SDH as follows (\citealt{Itc1999}:~4):

\begin{quote}
\begin{itemize}
\item[1)] Allow adequate \isi{reading time}. […]
\item[2)] Reduce viewers' frustration by:
\begin{itemize}
\item[a)] attempting to match what is actually said, reflecting the spoken word with the same meaning and complexity; without censoring
\item[b)] constructing subtitles which contain all obvious speech and relevant sound effects; and
\item[c)] placing subtitles sensibly in time and space.
\end{itemize}
\item[3)] Without making unnecessary changes to the spoken word, construct subtitles which contain easily-read and commonly-used English sentences in a tidy and sensible format. In the case of subtitles for children, particular regard should be given to the reading age of the intended audience.
\end{itemize}
\end{quote}

In order to define the gap integrated titles could fill, challenges and traditional solutions of subtitling are discussed in the following. This will provide a basis for the criticism of traditional subtitling guidelines and suggestions for improvement or alternatives. As both solutions for visual and content-related challenges might offer a basis for new guidelines, content-related strategies are presented as well. The focus is on general guidelines for traditional subtitles and SDH – semi-live and live subtitles are not taken into account due to their highly specific nature.

\subsection{Time \& space}\label{sec:1.2.1}

Time and space limitations are likely the most obvious and restricting constraints in audiovisual translation, but also one of the more frequently discussed and researched features. The various guidelines are based on an \isi{average reading speed}, for example based on viewers “aged between 14--65, from an upper-middle socio-educational class” and “for a text of average complexity” \citep{Karamitroglou1998}.\footnote{This excludes, for example, children with an \isi{average reading speed} of around 90--120 words per minute (aged 6--14, \citealt{Karamitroglou1998}). Karamitroglou therefore advises to adjust the subtitles for children’s programmes accordingly (\citealt{Karamitroglou1998}). For prelingually \isi{deaf} children, the ITC guidelines state a presentation rate of 70--80 words per minute as suitable (\citeyear{Itc1999}:~19).} While Karamitroglou sets the \isi{average reading speed} at 150--180 words per minute (wpm), corresponding to 2.5--3 words per second (wps), other guidelines state that the display speed “should not exceed 140 words per minute”, with 180~wpm for “exceptional circumstances” (\citealt{Itc1999}:~11; cf. \citealt{Ford_williams2009}:~7). There should also be extra time allocated for unfamiliar words, several speakers, labels, flashing subtitles, visuals and graphics, placed subtitles, long figures, shot changes, and slow speech (\citealt{Ford_williams2009}:~8). If subtitles are targeted at a hearing-impaired audience or are supposed to cover both audiences, the significantly lower \isi{reading speed} and reading literacy for the \isi{deaf} has to be taken into account (\citealt{Jungst2010}:~125).

Concerning \isi{synchronicity} and rhythm, subtitles should “adhere to a regular viewer reading rhythm” and the leading-in and -out times should “reflect the rhythm of the film” (\citealt{Ivarsson1998}:~157--159; cf. \citealt{Ford_williams2009}:~17). Good subtitles are in \isi{synchronicity} with the film (\citealt{Ivarsson1998}:~72, \citealt{Diaz_cintas2007b}:~88), even though Ivarsson/Carroll noted it as a challenge for viewers to follow a \isi{fast-paced dialogue} and image at the same time (\citeyear{Ivarsson1998}:~72). Readability, however, should not suffer in order to gain \isi{synchronicity}, and content should not be subtitled before it has actually been said (\citealt{Ivarsson1998}:~75, \citealt{Diaz_cintas2007b}:~91). While it has become customary with many professionals to display \isi{fast-paced dialogue} between two speakers in one subtitle (\citealt{Diaz_cintas2007b}:~89), the BBC guidelines state the opposite: “Do not simultaneously \isi{caption} different speakers if they are not speaking at the same time” (\citealt{Ford_williams2009}:~12).

All guidelines that discussed the number of lines set a maximum of two lines per subtitle. This would ensure that “no more than 2/12 of the screen image would be covered by subtitles at all time” \citep{Karamitroglou1998}, with single-line subtitles occupying the lower of the two possible lines. Leißner (\citeyear{Leisner2009}:~31) also sees reason for four-line subtitles in case of bilingual subtitles but mentions herself that this practice is rather rare due to the significant impact on the image. Ivarsson and Carroll give a maximum of 40 characters for cinema and 35~characters for television (cf. \citealt{Karamitroglou1998}) and Karamitroglou reasons that fitting more than 40 characters per line “reduces the \isi{legibility} of the subtitles” (\citealt{Karamitroglou1998}). More recent articles , however, propose a maximum of 38--40 characters per line (\citealt{Diaz_cintas2007b}:~82). Ford Williams sees the maximum at “roughly 32 or 34 characters per line” (\citeyear{Ford_williams2009}:~13) – however, as BBC’s subtitles are generally targeted at hearing-impaired audiences, this might be connected to the lower reading literacy and speed of these viewers.

\largerpage
Considering these limits, subtitle professionals regularly have to make decisions about where to insert a \isi{line break} or whether to keep a long one-liner instead of splitting the sentence into two lines. Ivarsson and Carroll mention studies showing a higher \isi{reading speed} for two-liners (\citeyear{Ivarsson1998}:~64) while these also cover more of the image than long one-liners – therefore it’s easily possible to argue for both strategies, and consistency might be the most relevant factor for a good \isi{viewing experience}. If, however, a \isi{line break} is necessary, the subtitle should be split into logical units (\citealt{Leisner2009}:~36) that also create preferably short eye movements, and, for \isi{aesthetic} reasons, with the first line shorter than the second one (\citealt{Ivarsson1998}:~77; \citealt{Diaz_cintas2007b}:~87). Additionally, three-line subtitles are seen as acceptable in case of SDH (\citealt{Diaz_cintas2007b}:~82) – while some might argue that the additional coverage of the image should result in further shortening, this might feel like censorship to SDH audiences and should be avoided (\citealt{Jungst2010}:~131; \citealt{neves2009}:~160). Overall, three-line subtitles are not used in many countries anymore, and it is almost impossible to find examples of four-line subtitles, even though they are mentioned now and then.

Based on the \isi{average reading speed}, Gottlieb sees 2--6~seconds as the maximum durations for subtitles (\citeyear{Gottlieb2012}:~162; cf. \citealt{Ivarsson1998}:~157--159), and also Díaz Cintas et al. speak of a ‘six seconds rule’ as the maximum duration for subtitles (\citeyear{Diaz_cintas2007b}:~96; also “six-second rule”,\footnote{The six-seconds rule is based on television subtitle lines containing 35 to 37 characters on average, resulting in 70 to 74 characters in six seconds and therefore around 12 characters per second (\citealt{Diaz_cintas2007}:~23).} \citealt{Diaz_cintas2007}:~23). This is supposed to allow the viewer enough time to read two full lines and explore the image at the same time. The maximum of 6~seconds should prevent the audience from re-reading and longer speech acts should be split into multiple subtitles (\citealt{Karamitroglou1998}:~89; \citealt{Ivarsson1998}:~64). A minimum of 1--1.5~seconds is sufficient for the eye not to miss a title and 1~second is considered the minimum for even a one-word subtitle (\citealt{Karamitroglou1998}; \citealt{Ivarsson1998}:~65; \citealt{Diaz_cintas2007b}:~92).

\largerpage[2]
The BBC guidelines are very precise concerning timing as they generally do not focus on language but the form. Therefore, the display times for full two- and one-liners are defined in detail: A full two-liner of about 14--16 words should be displayed for 6~seconds. Of that, 5.5~seconds are calculated by the \isi{average reading speed} per word, plus ¼ to ½~second the brain needs to “start processing the subtitle” \citep{Karamitroglou1998}. The one-liner (or single-liner) of about 7--8~words should be displayed for about 3.5~seconds, including the \isi{reaction time} and the slower processing compared to a full two-liner that “signals an acceleration of the \isi{reading speed}” \citep{Karamitroglou1998}. As Karamitroglou states, this is not triggered “with the single-line subtitle” (\citeyear{Karamitroglou1998}). In all cases, subtitles should not stand significantly longer to prevent re-reading. The duration of $\frac13$~second per word can be see as average time for easily processable text.\footnote{See the BBC guidelines for standard timing for up to three lines (\citealt{Ford_williams2009}:~9).}

\newpage 
Pauses between consecutive subtitles should be at least ¼~second to prevent “overlay” effects \citep{Karamitroglou1998}, as “this break is necessary to signal to the brain the disappearance of one subtitle as a piece of linguistic information, and the appearance of another” \citep{Karamitroglou1998}. This is also defined as a “minimum of four frames [that] should be left between subtitles to allow the viewer’s eye to register the appearance of a new subtitle” (\citealt{Ivarsson1998}: 157--159).

Concerning cuts or camera takes, the definition is crucial: Not every change from long shot to close-up is a relevant cut, but rather “camera takes/cuts that signify a thematic change in the film product” (\citealt{Karamitroglou1998}; cf. \citealt{Ivarsson1998}: 157--159). Subtitles “should disappear before the cuts” \citep{Karamitroglou1998} as “subtitles that are allowed to over-run shot changes can cause considerable perceptual confusion and should be avoided” (\citealt{Itc1999}: 12; cf. \citealt{Ford_williams2009}: 14). However, increasing use of quick shot changes and cuts in modern film making has let to some kind of acceptance of ignoring this rule now and then:

\begin{quote}
In practice, it is recognised that the frequency and speed of shot changes in many programmes present serious problems for the subtitler.~A subtitle should, therefore, be ‘anchored’ over a shot change by at least one second to allow the reader time to adjust to the new picture. Shot changes normally reflect the beginning or end of speech. The subtitler should, therefore, attempt to insert a subtitle on a shot change when this is in synchrony with the speaker. (\citealt{Itc1999}: 12)
\end{quote}

Concerning the leading-in time, the analysed guidelines give different instructions. While Karamitroglou states that a delay of ¼~seconds should be between speech and subtitle onset (\citeyear{Karamitroglou1998}), the ITC and BCC guidelines suggest an immediate appearance of the subtitles. Karamitroglou references unnamed tests of eye and brain reactions for his instructions:

\begin{quote}
Subtitles should not be inserted simultaneously with the initiation of the utterance but ¼ of a second later, since tests have indicated that the brain needs ¼ of a second to process the advent of spoken linguistic material and guide the eye towards the bottom of the screen anticipating the subtitle. A simultaneously presented subtitle is premature, surprises the eye with its flash and confuses the brain for about ½ a second, while its attention oscillates between the inserted subtitled text and the spoken linguistic material, not realising where it should focus. \citep{Karamitroglou1998}
\end{quote}

The ITC and BBC guidelines, on the other hand, insist on \isi{synchronicity}, referencing unnamed \isi{eye tracking} research: “Research in eye movement has shown that hearing impaired viewers make use of visual cues from the faces of television speakers. Therefore \isi{subtitle appearance} should coincide with speech onset” (\citealt{Ford_williams2009}:~12; cf. \citealt{Itc1999}:~11). While this reasoning might be completely justified for a hearing-impaired audience, a combination of either both strategies or the exclusive adherence to Karamitroglou’s instructions might be better suited for a hearing audience. Titles might stand longer if scenes or cuts allow for it, but the \isi{subtitle disappearance} or “lagging-out time” (\citealt{Itc1999}) should not exceed 1.5--2~seconds or 12 frames, otherwise viewers might distrust the translation (\citealt{Itc1999}; \citealt{Ford_williams2009}:~12). If possible, however, “\isi{subtitle disappearance} should coincide roughly with the end of the corresponding speech segment, since subtitles remaining too long on the screen are likely to be re-read by the viewer” (\citealt{Itc1999}:~11) and the distribution between subtitles “must consider cuts and sound bridges” (\citealt{Ivarsson1998}:~157--159) in order to “underline surprise or suspense” (\citealt{Ivarsson1998}:~157--159). Ford Williams emphasises that these rules of \isi{synchronicity} also apply for off-screen speakers and narrators in the case of a hearing-impaired audience “since viewers with a certain amount of residual hearing make use of auditory cues to direct their attention to the \isi{subtitle area}” (\citeyear{Ford_williams2009}:~12).

Various possible strategic solutions are given by the analysed guidelines and other authors. In order to deal with time and space constraints, \isi{interlingual} subtitles are usually shortened. This can be achieved by several basic strategies that can also occur in combination: paraphrasing, summarising, simplification, and omission (\citealt{Diaz_cintas2007b}:~206) as well as smaller modifications such as altering syntactic structures \citep{Karamitroglou1998}. Paraphrasing is usually combined with omissions (\citealt{Leisner2009}:~45), just as summaries and simplifications. Elements that can be left out include redundancies such as intrasemiotic repetitions or intersemiotic visible elements (\citealt{Gottlieb1998}:~247; \citealt{Ivarsson1998}:~157--159), “common comprehensible phrases” (\citealt{Ivarsson1998}:~157--159), “padding expressions” (such as “you know” or “well”, \citealt{Karamitroglou1998}), “tautological cumulative adjectives/adverbs” (\citealt{Karamitroglou1998}) and “responsive expressions” (\citealt{Karamitroglou1998}). These decisions will always be case-dependent:

\begin{quote}
A decision as to which pieces of information to omit or to include should depend on the relative contribution of these pieces of information to the comprehension and appreciation of the target film as a whole. […] The subtitler should attempt to keep a fine balance between retaining a maximum of the original text (essential for the comprehension of the linguistic part of the target film), and allowing ample time for the eye to process the rest of the non-linguistic aural and visual elements (essential for the appreciation of the \isi{aesthetic} part of the target film). (\citealt{Karamitroglou1998})
\end{quote}

\subsection{Content}\label{sec:1.2.2}

The number of challenges that arise with the content of spoken language and its inter- and \isi{intralingual translation} in the form of subtitles is high and the following list everything but exhaustive. One of the main and most basic challenges is the textualisation of spoken language that leads to the loss of various typical characteristics such as dialects, sociolects, idiolects, colloquial language, and swear and taboo words (\citealt{Jungst2010}:~51f.; \citealt{Ford_williams2009}:~5), but also intonation, emotions, accents, difficult and inaudible speech, or hesitation and interruption (\citealt{Ford_williams2009}:~21ff.). Even the impact and perception of silence changes (\citealt{Ford_williams2009}:~21ff.). These characteristics are not only lost due to the textualisation and time and space constraints, but also intentionally ignored in order to achieve a better \isi{readability} and less distraction from the image. It can be assumed, however, that – in case of a hearing or only slightly hearing-impaired audience – some of these characteristics are still perceived auditorily, e.g. pauses, false starts, corrections, interruptions, slips, dialects, and colloquial language (\citealt{Leisner2009}:~41). The transfer of sociolects, dialects, and idiolects should be handled with care and always follow an analysis of the intended effect as a \isi{literal translation} or transcription might have the opposite effect (\citealt{Diaz_cintas2007b}:~191f.) – the same goes for taboo and swear words. While these are characteristics of spoken language, other challenges occur during \isi{interlingual} translation due to speech containing e.g. cultural specifics or \isi{humour}.

\largerpage
While it is tempting to leave out as much “superfluous” (\citealt{Ivarsson1998}:~157) and repetitive information as possible, this should not be done considering hearing-impaired viewers (\citealt{Ivarsson1998}:~157--159; \citealt{Ford_williams2009}:~4). Dialects and accents should not be transcribed or translated phonetically or using “syntactic transcription of the spoken form” \citep{Karamitroglou1998}, but rather presented by using characteristic vocabulary or brackets (\citealt{De_linde1999}:~13). The exception are dialects or forms that “already appeared in a written form in printed materials” (e.g. “biblical forms”, \citealt{Karamitroglou1998}). Swear and taboo words “should not be censored unless their frequent repetition dictates their reductions for reasons of text economy” (\citealt{Karamitroglou1998}). Additionally, Karamitroglou sees no harm in using well-known acronyms, apostrophes, and symbols, as long as they are “immediately recognisable and comprehensible” (\citealt{Karamitroglou1998}).

The rendering of music has been discussed widely, e.g. by Neves (\citeyear{neves2009}:~164f.), Jüngst (\citeyear{Jungst2010}:~137), and \citet{Krammer2001}. Most guidelines emphasise that “songs must be subtitled where relevant” (\citealt{Ivarsson1998}:~157--159; cf. \citealt{Ford_williams2009}:~4, 31--33). The ITC guidelines (\citeyear{Itc1999}:~16) provide further details:
\begin{quote}
At the very minimum, the title of the music playing should be given. Where possible the words of a song should be included.~This is especially important where the programme is to be viewed by younger people. Pop programmes, opera and songs connected to the story line are particularly important areas. Song lyrics should be subtitled verbatim; but, if the pace of the song is very rapid, whole couplets or verses may be omitted.
\end{quote}
Concerning \isi{noise transcription} and indication, the challenge is not only to decide what noises should be represented in the subtitles, but also how. While hard-of-hearing and postlingually \isi{deaf} audiences will understand \textit{wuff} as indication of a barking dog, viewers born \isi{deaf} will most likely not, or only with a considerably delay, make the connection. But as people that were born \isi{deaf} still have a concept of noises (\citealt{neves2009}:~155), the main goal must be to only subtitle noises that are not obvious from the image and also relevant for the plot in the clearest non-ambiguous way possible (\citealt{Jungst2010}:~134; \citealt{Ford_williams2009}:~34--35; \citealt{Itc1999}:~15). While “context and genre […] must be taken into consideration” (\citealt{Itc1999}:~15), “descriptive statements are normally preferable to onomatopoeic spellings” (\citealt{Itc1999}:~15) that is usually only targeted at children and not used for adults.


Paralanguage poses an additional challenge as meaning cannot always be accessed through a speaker’s facial expressions – common solutions so far have been descriptions in brackets (\citealt{Jungst2010}:~134) while possibly more intuitive solutions such as smileys and emoticons are being researched (\citealt{neves2009}:~161; \citealt{secara2016}).

Interlingual translation additionally includes challenges such as the transfer of cultural specifics and \isi{humour}. Cultural specifics are “extralinguistic references to items that are tied-up with a country’s culture, history, or geography and tend therefore to pose serious translation challenges” (\citealt{Diaz_cintas2007b}:~200). In contrast to other modes of translation, translators cannot add footnotes or any extensive explanation to subtitles and have to solve both intralinguistic features such as language-specific grammatical forms, metaphors, and idioms as well as extralinguistic features such as references to society, culture, geography, and history (\citealt{nedergaard-larsen1993}:~211).

 
Karamitroglou emphasises that “there is no standard guideline for the transfer of culture-specific linguistic elements” (\citeyear{Karamitroglou1998}) but rather a range of strategies (based on \citealt{pedersen2005}:~9; cf. \citealt{nedergaard-larsen1993}; \citealt{Diaz_cintas2007}):

\sloppy
\begin{itemize}
\item \textit{Omission} (\citealt{nedergaard-larsen1993}:~219, 231; \citealt{pedersen2005}:~9; \citealt{Diaz_cintas2007}:~206): In the case that a culturally specific element cannot be sustained due to the characteristics of subtitles or the lack of an appropriate equivalent in the target culture, it can be omitted. Some translators might compensate by adding another cultural specific elsewhere.
\item \textit{Transposition} \citep{Karamitroglou1998}, \textit{loan} (\citealt{Leisner2009}:~49ff.), or \textit{retention} (\citealt{pedersen2005}:~9): Cultural specifics such as names of streets or places can be kept, along with those that are indispensible for the plot.
\item \textit{Transposition/Loan with explanation} (\citealt{Karamitroglou1998}; \citealt{Leisner2009}:~49ff.): Subtitles rarely offer sufficient space for additional explanations. If, however, the space and time constraints allow for an additional element, an explanatory adjective can be used.
\item \textit{Direct translation} (\citealt{pedersen2005}:~9): If an institution or concept exists in the target culture as well and carries the same name, it can be directly translated (cf. \citealt{nedergaard-larsen1993}:~227).
\item \textit{Imitation} \citep[9]{pedersen2005} or \textit{literal translation} (\citealt{Leisner2009}:~49ff.): Literal translation of all the elements of a cultural specific – therefore "imitating" the semantic structure – that can be used for institutions or ranks. As there might already be an official equivalent in the target language, this can lead to irritation in the audience and should therefore only be used to a limited extent.
\item \textit{Official Equivalent} \citep{pedersen2005}, \textit{cultural transfer}, or \textit{adaptation} (\citealt{Leisner2009}:~49ff.)\textit{:} Culture-specific elements can be translated with equivalents in the target culture.
\item \textit{Neutralisation} or \textit{Specification} (\citealt{pedersen2005}:~4ff.; \citealt{Leisner2009}:~49ff.): A plain explanation for a cultural specific can be given, e.g. replacing a metaphor that is well-known in the source language with the actual term or concept. Pedersen further differentiates between \textit{explicitation} (i.e. writing out an abbreviation or acronym) and \textit{addition} (adding information on the connotation) (\citealt{pedersen2005}:~4ff.).
\item \textit{Chunking}: Leißner (\citeyear{Leisner2009}:~49ff.) defines \isi{chunking} as the translation of a \isi{culture-specific element} with a term of the same register (also comparable to \textit{Substitution} [\citealt{pedersen2005}:~9]):
\begin{itemize}
\item \textit{Chunking up} (more general term),
\item \textit{Chunking down} (more specific term),
\item \textit{Lateral chunking} (more familiar term from same register).
\end{itemize}
\end{itemize}

\fussy
While culture-specific elements are easily defined and recognised, \isi{humour}, on the other hand, is subjective, not universal, and therefore hard to define. As it is often culturally specific, it might be seen as either an independent challenge in audiovisual translation or a subcategory of culture-specific elements as it is likely for people from the same cultural background to laugh about similar things (\citealt{Leisner2009}:~54). As knowledge of the source language does not guarantee understanding of a \isi{joke}, it is sometimes necessary to adjust it to the target culture. Zabalbeascoa (\citeyear{Zabalbeascoa1996}:~251) and Díaz Cintas and colleagues (\citeyear{Diaz_cintas2007b}:~221) give several categories of jokes: bi- and international jokes, national-culture-and-institutions jokes, national-sense-of-\isi{humour} jokes, language-dependant jokes, visual jokes, and complex jokes. In order to deliver “humorous sequences” (\citeyear{Ford_williams2009}:~29), Ford Williams underlines the importance of retaining “as much of the \isi{humour} as possible” (\citeyear{Ford_williams2009}:~29):
\begin{quote}
\begin{itemize}
\item[1.] Try wherever possible to keep punchlines separate from the preceding text.
\item[2.] Where possible, allow viewers to see actions and facial expressions which are part of the \isi{humour} by leaving the screen clear or by editing. Try not to use reaction shots containing no speech in order to gain time.
\item[3.] Never edit characters' catchphrases.
\item[4.] Puns should be clearly indicated in your subtitle. [...] (\citealt{Ford_williams2009}: 29)
\end{itemize}
\end{quote}

While these guidelines offer advice, they are not specific strategies. Díaz Cintas et al. (\citealt{Diaz_cintas2007b}:~215f.) and Zabalbeascoa (\citeyear{Zabalbeascoa1996}:~332) emphasise that \isi{humour} should not be transferred at all costs, especially not at the expense of coherence and idiomatic phrases. The subtitle’s humourous effect should be as close as possible to that of the statement in the source language, but also as readable and comprehensible as possible. The purpose of a \isi{joke} should be defined first (\citealt{reis1984}; \citealt{stolze1997}:~180f.), as it is not always the creation of \isi{humour}, and paraphrasing or the use of a similar rhetoric tool might be the better solution (\citealt{Diaz_cintas2007b}:~215). While most mentioned strategies are similar to those listed for culture-specific elements (i.e. “adaption” [\citealt{Veiga2009}:~163], “substitution” [\citealt{Veiga2009}:~163], “omission” [\citealt{Diaz_cintas2007}:~216], and “compensation” [\citealt{seifferth2009}:~37]), the particular challenge of translating puns is highlighted then and again, especially by Delabastita (\citeyear{Delabastita1996}:~134). He lists the following strategies in dealing with source language puns:

\begin{quote}
\textit{Pun} $\rightarrow$ \textit{Pun}: the source-text pun is translated by a target-language pun, which may be more or less different from the original \isi{wordplay} in terms of formal structure, semantic structure, or textual function

\textit{Pun} $\rightarrow$ \textit{Non-pun}: the pun is rendered by a non-punning phrase which may salvage both senses of the \isi{wordplay} but in a non-punning conjunction, or select one of the senses at the cost of suppressing the other; of course, it may also occur that both components of the pun are translated ‘beyond recognition’

\textit{Pun} $\rightarrow$ \textit{Related rhetorical device}: the pun is replaced by some wordplay-related rhetorical device (repetition, alliteration, rhyme, referential vagueness, irony, paradox, etc.) which aims to recapture the effect of the source-text pun

\textit{Pun} $\rightarrow$ \textit{Zero}: the potion of text containing the pun is simply omitted

\textit{Pun ST = Pun TT}: the translator reproduces the source-text pun and possibly its immediate environment in its original formulation, i.e. without actually ‘translating’ it

\textit{Non-pun} $\rightarrow$ \textit{Pun}: the translator introduces a pun in textual positions where the original text has no \isi{wordplay}, by way of compensation to make up for source-text puns elsewhere, or for any other reason

\textit{Zero} $\rightarrow$ \textit{Pun}: totally new textual material is added, which contains \isi{wordplay} and which has no apparent precedent or justification in the source text except as a compensatory device

\textit{Editorial techniques}: explanatory footnotes or endnotes, comments provided in translators’ forewords, the ‘anthological’ presentation of different, supposedly complementary solutions to one and the same source-text problem, and so forth. (\citealt{Delabastita1996}:~134)
\end{quote}

\largerpage
While the presented strategies enable subtitlers to transfer challenging contents into the target language and culture, yet another constraint limits the range of possible solutions: As viewers continuously have access to both the source and the target version of the dialogue, they inevitably compare these and thereby become a constant “critical lay person” (\citealt{Jungst2010}:~53, author’s translation). The so-called (acoustic) “\isi{feedback effect}” (\citealt{Diaz_cintas2007}:~55; also “gossiping effect” [\citealt{Tornqvist1995} 1995:~49]) describes this dilemma: When the audience recognises “linguistic items of the original” \citep{Karamitroglou1998}, it expects “the exact, literal, translationally equivalent items […] to appear in the subtitles as well” \citep{Karamitroglou1998}. When viewers get the impression that something was not actually said that way or at all (\citealt{nagel2009}:~65), it raises “suspicions that the translation of the original text is not ‘properly’ or ‘correctly’ rendered in the subtitles” \citep{Karamitroglou1998}.

The goal in any case should be a minimal irritation of the audience while maintaining the intended meaning and effect of the source item. Karamitroglou suggests that, in general terms and depending on context, “linguistic items of the original that can be easily recognised and comprehended by the viewers should not only be retained if they appear in a context of unrecognisable items […] but they should also be translated word-for-word” \citep{Karamitroglou1998}.

In addition to \isi{acoustic feedback} effects, there can also be visual feedback effects – e.g. when a viewer does not understand the content but perceives the duration of the speech act. If the subtitle is obviously shorter it might be perceived as censorship (\citealt{Jungst2010}:~127). The same goes for words that might be lip-read and are not subtitled accordingly (\citealt{Jungst2010}:~127). This is also reflected in the “Code for Good Subtitling Practice”: “There must be a close correlation between film dialogue and the presence of subtitles” (\citealt{Ivarsson1998}:~157--159).

\subsection{Layout}\label{sec:1.2.3}

The \isi{layout} of subtitles is a broad field with on the one hand widely discussed aspects such as the use of specific characters, the number of lines and the right position for a \isi{line break}, but also less explored features such as \isi{aesthetics}, \isi{placement}, and \isi{user experience}.

\largerpage
While punctuation  {depends on the language } and can differ immensely between source and target language, the use of specific characters – in this case in English and German – should always be used for clarity and in a coherent way.\footnote{As there is great national variation, especially concerning e.g. the use of italics, subtitle professionals should keep it simple and avoid variation.} Punctuation should be used in a limited way and all used elements should have a clearly defined function to prevent irritation and therefore a possible loss of information. Following elements can be found in the guidelines:

\begin{itemize}
\item \textit{Single Dot}: Signals the end of the sentence and motivates the audience to direct its \isi{gaze} back to the image \citep{Karamitroglou1998}. Along with \textit{question marks} and \textit{exclamation marks}, they are used the same way as in any written text \citep{Karamitroglou1998}.
\item \textit{Comma}: The comma is used as usual within a subtitle but should be omitted at the end of a subtitle. This allows for better clarity and the change to the next subtitle creates a break anyway \citep{Karamitroglou1998}.
\item \textit{Dash}: Dashes are reserved as a distinguishing element for different speakers combined in one subtitle. Being a linguistic element strongly associated with written language, the dash should be avoided in other contexts \citep{Karamitroglou1998}.
\item \textit{Three Dots}: The ITC guideline states that “sequences of dots (three at the end of a to-be-continued subtitle, and two at the beginning of a continuation) are used to mark the fact that a segmentation is taking place” (\citeyear{Itc1999}:~8) and that “many viewers have found this technique helpful” (\citeyear{Itc1999}:~8). Karamitroglou states a similar fact on “sequence dots” or “ending triple dots” (\citeyear{Karamitroglou1998}) and that the brain “takes more time to process” \citep{Karamitroglou1998} continuous subtitles without any punctuation at the end of the preceding subtitle. They should therefore not be used to “indicate ongoing thoughts or an unfinished utterance” \citep{Karamitroglou1998}. He calls their counterpart at the beginning of the next sentence “linking dots” or “starting triple dots” \citep{Karamitroglou1998} and emphasises that they should always be used in combination. While this has been common practice for quite some time, more and more subtitle producers omit these dots as they seem to trust their hearing viewers to recognise connected subtitles, or prefer to rather use the space for actual content. For hearing-impaired audiences, however, this might still be an appropriate practice.
\item \textit{Italics}: Italics represent so-called “distant voices” (\citealt{Leisner2009}:~34), e.g. narrators, inner monologues, speakers on the telephone, etc. Karamitroglou defines this as the indication of an “off-screen source of the spoken text” (\citeyear{Karamitroglou1998}). He also states that they can be used for “retaining foreign-language words in their original foreign-language version” \citep{Karamitroglou1998}.
\item \textit{Single and double quotation marks}: They embrace alleged information and quoted information and should be used cautiously \citep{Karamitroglou1998}.
\end{itemize}

The following linguistic elements have been deemed unsuited for subtitles due to their strong association with written language:

\begin{itemize}
\item \textit{Uppercase letters}: While some argue that uppercase letters can be used to indicate screaming or increased volume (\citealt{Itc1999}:~13; \citealt{Leisner2009}:~35), it should generally be avoided due to the associated slower \isi{reading speed}. The ITC guidelines suggest to instead use colour for “emphasis of an individual word” (\citeyear{Itc1999}:~13).
\item \textit{Boldface and underlining}: These design options are rarely useful for complete sentences or subtitles. Karamitroglou even sees them as “not permitted in subtitling” (\citeyear{Karamitroglou1998}).
\item \textit{Colons and semicolons}: While Leißner states that these should be avoided due to their strong association with written language and their similarity to each other (\citeyear{Leisner2009}:~35), Karamitroglou only permits their use at the end of subtitles to avoid creating longer pauses than intended (\citeyear{Karamitroglou1998}).
\item \textit{Parentheses and brackets}: Both Leißner and Karamitroglou see parentheses and brackets as a means of explaining jokes or culture-specific elements but recommend a cautious use due to the strong association with written language (\citealt{Karamitroglou1998}; \citealt{Leisner2009}:~35).
\item \textit{Special characters}: Special characters can stand out too much on the screen and might have a negative impact on the \isi{reading speed}. So if recognition of a rarely used special character might take too long, their meaning should be written out. Well-known characters such as the
% EUR 
{\euro}
symbol in Europe might be used cautiously.
\end{itemize}

The use of numerals and the decision whether to write them out or not depends highly on context, available time and space, and the respective situation. Ford Williams (\citeyear{Ford_williams2009}:~36) offers a detailed overview of possible situations and solutions.

When \isi{subtitle layout} is mentioned, it usually refers to the preference of one or two lines and the location of the \isi{line break} as well as the balance between the two lines. In 2012, Gottlieb called \isi{subtitle layout} “one of the relatively few aspects of subtitling tested empirically” (\citeyear{Gottlieb2012}:~66) and names studies by d’Ydewalle and De (\citeyear{Dydewalle2007}) and Perego (\citeyear{perego2010}). While Ivarsson and Carroll (\citeyear{Ivarsson1998}:~157--159) state a maximum subtitle length of two lines, the ITC guidelines and Ford Williams promote up to three lines “if the subtitler is confident that no important picture information will be obscured” (\citealt{Itc1999}:~7). Concerning segmentation, the guidelines could not be more contradictory. The question is whether to distribute a long one-line subtitle evenly on two lines or not. Karamitroglou prefers two lines and states that “the eye and the brain of the viewers render a two-line subtitle as more bulky and, as a result, accelerate the reading process” (\citeyear{Karamitroglou1998}). Opposing this view, Ford Williams claims that “one line takes less time to read […] and it causes less disruption to the picture” (\citeyear{Ford_williams2009}:~13; cf. \citealt{Itc1999}:~10). Ivarsson and Carroll also prefer the long one-line subtitle as this would avoid the break during switching to the second line.

While subtitles should “ideally […] be self-contained” (\citealt{Ivarsson1998}: 157--159) and “start and end at logical points in a sentence” (\citealt{Ford_williams2009}: 10), splitting a sentence into two subtitles often cannot be avoided. The distribution within two-line subtitles should be based on logical, grammatical, and semantic constituents. For example, determiners should not be separated from their nouns (\citealt{Ivarsson1998}:~157--159; \citealt{Itc1999}:~9; \citealt{Diaz_cintas2007}; \citealt{Ford_williams2009}:~10). Karamitroglou demands a segmentation “at the highest syntactic nodes possible” (\citeyear{Karamitroglou1998}). Concerning the balance between the two lines of “unequal length” (\citealt{Ivarsson1998}:~157--159), “the upper line should preferably be shorter to keep as much of the image as free as possible” (\citealt{Ivarsson1998}:~157--159). Karamitroglou emphasises the aim of the two lines being “proportionally as equal in length as possible, since the viewers’ eye is more accustomed to reading text in a rectangular than a triangular format” (\citeyear{Karamitroglou1998}). Ivarsson and Carroll demand left-justification as this is supposed to “reduce unnecessary eye movement” (\citealt{Ivarsson1998}:~157--159). Both the ITC guidelines and Karamitroglou see a need for “compromise between linguistic and geometric considerations” (\citealt{Itc1999}:~9; \citealt{Karamitroglou1998}), with both giving priority to “linguistic considerations” (\citealt{Itc1999}:~9).

Regarding the \isi{typographic design} of subtitles, Karamitroglou demands a “pale white” (\citeyear{Karamitroglou1998}) as a bright white would “render them [the subtitles] tiring to the viewers’ eye” (\citealt{Karamitroglou1998}; cf. \citealt{Ford_williams2009}:~18). Another regularly used colour in television and DVD subtitles is yellow. To guarantee a maximum contrast, “text should normally be presented in a black box” (\citealt{Itc1999}:~5; cf. \citealt{Ford_williams2009}:~18; \citealt{Leisner2009}:~32), even though this covers the image additionally. As it is nevertheless often used in SDH on television, the ITC guidelines define an appropriate set of suitable colours: “The most legible text colours on a black background are white, yellow, cyan and green. Use of magenta, red and blue should be avoided” (\citealt{Itc1999}:~5; cf. \citealt{Ford_williams2009}:~18). An alternative to black or grey boxes are shadows behind the letters or outlines (cf. \citealt{Diaz_cintas2007b}:~84). Karamitroglou, however, demands a “grey, see-through ‘ghost box’ […] since it has been proven that it is easier for the eye to read against a fixed rather than a varying/moving background” (\citeyear{Karamitroglou1998}) and it does not block the view on the image completely. Typefaces used should be \isi{sans-serif} (\citealt{Karamitroglou1998}; \citealt{Diaz_cintas2007b}:~84; \citealt{Ford_williams2009}:~20) and proportionally distributed \citep{Karamitroglou1998}.

The position of subtitles is established in the lower part of the screen (\citealt{Karamitroglou1998}; \citealt{Itc1999}; \citealt{Diaz_cintas2007b}; \citealt{Diaz_cintas2007}:~8; \citealt{Ford_williams2009}). They are usually placed around 10\,\% from the borders to compensate for various playback devices that might cut a part of the image. Karamitroglou suggests a \isi{placement} of “at least 1/12 of the total screen height above the bottom of the screen, so that the eye of the viewer does not have to travel a long distance” (\citeyear{Karamitroglou1998}). The same amount of space should be left free to the left and right of the first and last character of each subtitle line \citep{Karamitroglou1998}. The reason for placing the subtitles in the lower area is that it is often free of elements relevant for the plot (\citealt{Leisner2009}:~30) respectively “occupied by image action which is of lesser importance to the general \isi{aesthetic} appreciation of the target film” \citep{Karamitroglou1998}. According to Díaz Cintas et al., subtitles should only be moved if necessary, e.g. if they would cover something or to avoid a weak contrast and reduced \isi{legibility} (\citeyear{Diaz_cintas2007b}:~81f.). The ITC guidelines also underline the importance of not covering plot-relevant areas in the image:
\begin{quote}
\textstyleannotationreference{T}he normally accepted position for subtitles is towards the bottom of the screen, but in obeying this convention it is most important to avoid obscuring ‘on-screen’ captions, any part of a speaker’s mouth or any other important activity. (\citealt{Itc1999}:~10)
\end{quote}
So far, the only alternative position used in traditional subtitling is at the top of the screen \citep{Karamitroglou1998} and should only be used in “extreme cases” \citep{Karamitroglou1998}.

While traditional subtitles are normally centred, semi-live and live subtitles are sometimes left-oriented (\citealt{Diaz_cintas2007b}:~88). For centred subtitles, the “distance the eyes should move is the same, no matter where the \isi{line break} is inserted” (\citealt{Gottlieb2012}:~23; cf. \citealt{Ivarsson1998}:~157--159). The ITC guide, however, demands that the subtitles be “displayed horizontally in the direction of the appropriate speaker, or source of sound effect” (\citeyear{Itc1999}:~10) by placing text “justified left, centre or right depending on \isi{speaker position}” (\citealt{Itc1999}:~5; cf. \citealt{Diaz_cintas2007}:~14; \citealt{Ford_williams2009}:~18--19).

In addition to these guidelines, which are suitable for both inter- and \isi{intralingual} subtitles, some guidelines are only intended for SDH – for example those on \isi{speaker identification}. Ford Williams suggests the use of colours to “distinguish speakers from each other” (\citeyear{Ford_williams2009}:~15, 18--19; cf. \citealt{Jungst2010}:~129), suitable colours being yellow, cyan, and green (\citealt{Itc1999}:~15; \citealt{Ford_williams2009}:~18). Colours can be assigned to film characters either “throughout the programme” (\citealt{Itc1999}:~13) or “in terms of scenes” (\citealt{Itc1999}:~13). Other possibilities are the already mentioned placements below speakers and adding character names (\citealt{Itc1999}:~13; \citealt{remael2007}:~31; \citealt{Jungst2010}:~129). The \isi{horizontal placement} below speakers, however, poses an additional challenge:
\begin{quote}
The main problem here is when characters move about while speaking. In such cases, the \isi{caption} should be positioned at the discretion of the subtitler to identify the position of the speaker as clearly as possible. (\citealt{Itc1999}:~13)
\end{quote}
As the strategy of \isi{horizontal placement} below speakers is being used again on recent Blu-ray releases (see Section \ref{sec:4.1}), there seem to be strategies to handle these challenges as well. \chapref{placement} gives an overview over those strategies in recent commercial films.

\section{Subtitle quality and shortcomings}\label{sec:1.3}

\largerpage
While the discussion of time and space constraints and content-related challenges such as \isi{humour} and culture-specific elements revealed several strategic solutions, challenges originating from the \isi{placement} and \isi{layout} of subtitles did not quite have the same effect. Problems with contrast, collisions, and interference seem to be widely accepted as unpleasant, but unavoidable features of subtitles. Strategies so far only cover bold black boxes (rarely used in \isi{interlingual} translation), shadows, and thick borders to counter weak contrasts. The only regularly used alternative to the bottom-centre position seems to be the suboptimal position at the top, and \isi{speaker identification} is only done for SDH, using colours and sometimes \isi{horizontal placement}.

Rarely addressed are issues such as the distance between subtitle and \isi{focus point} in the image, viewers not used to subtitles (especially in \isi{dubbing} and English-speaking countries), collisions of subtitles with other text elements, \isi{typographic} challenges (and possibilities), and the overall visual impact of additional text elements in film. The wide range of content-related strategies should be balanced by presentation and layout-related strategies. And as many strategies, i.e. concerning timing, are already based on \isi{eye tracking} studies (i.e. \isi{reading behaviour}, image processing and exploration etc.) this appears to be the appropriate tool to study text elements in film further (see \chapref{eyetracking}).

More recent challenges arise from further automation such as \isi{machine translation} (cf. \citealt{Armstrong2006}; \citealt{melero2006}; \citealt{Volk2008}; \citealt{Flanagan2009}; \citealt{Volk2010}; \citealt{Fishel2012}; \citealt{muller2013}) combined with post-editing (cf. \citealt{De_sousa2011}), \isi{subtitle placement} (see \sectref{sec:3.4}), and crowd sourcing as well as user-generated subtitling (cf. \citealt{orrego_carmona2015}).

