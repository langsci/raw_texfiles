\chapter{Variation aus gebrauchsbasierter Perspektive}
\label{variationallg}

In diesem Kapitel wird sprachliche Variation aus gebrauchsbasierter Perspektive beleuchtet. Dabei steht die Frage im Vordergrund, wie Stabilität und Variation in einer Sprache theoretisch modelliert werden kann. Um diese Frage zu beantworten, werden Frequenz, Prototypizität und (Form-)\-Schematizität als Faktoren eingeführt, die Einfluss auf Sprachstabilität, -variation und -wandel nehmen. Dabei wird auf grammatische Variation fokussiert. Der Einfluss von Frequenz, Prototypizität und (Form-)Schematizität wird in den folgenden Abschnitten diskutiert. 

\section{Frequenz}\label{steuerungfreq}
\begin{sloppypar}
Der gebrauchsbasierte Ansatz sieht Frequenz als einen grundlegenden Einflussfaktor für die Evolution und den Erwerb eines Sprachsystems (\cites[x]{Kemmer.2000}[1--2]{Diessel.2017}; siehe hierzu ausführlich \cite{Tomasello.2009} für eine Modellierung des Spracherwerbs aus gebrauchsbasierter Perspektive). Wie bereits in der Einleitung dargelegt wurde, setzt der Ansatz Sprachsysteme mit mentalen Repräsentationen gleich. Diese entstehen aus dem Sprachgebrauch, genauer gesagt aus konkreten Verwendungen von Konstruktionen (Form-Funktions-Paaren): Aus den Verwendungen (z.~B. \textit{Die Katzen trinken Milch}, \textit{die Kinder schlürfen Suppe}, \textit{die Hasen essen Karotten}) werden gemeinsame Eigenschaften (X\textsubscript{NP\_Nom} X\textsubscript{VVFIN} X\textsubscript{NP\_Akk}, +~Nahrungsaufnahme) der Konstruktionen abstrahiert (\cites[20--29]{Tomasello.1992}[168--170]{Ellis.2002b}[220]{Langacker.2008}). Frequenz ist schon für die Grundkonzeption des Ansatzes relevant, denn die mentale Repräsentation einer häufig verwendeten Konstruktion ist gefestigter als die einer selten genutzten (\cite[380]{Bybee.1997}). Zudem ist eine Konstruktion, die Spre\-\mbox{cher\_in}\-nen in vielen verschiedenen Verwendungen begegnet, abstrakter und somit schematischer als eine, die auf wenige Kontexte beschränkt ist (\cite[67--68]{Goldberg.2019}; Konstruktionen und ihre Abstraktionsgrade werden in \sectref{konstruktion} diskutiert). Frequenz stärkt somit die mentale Repräsentation einer Konstruktion und erleichtert dadurch deren Aktivierung, sodass sie einen grundlegenden Einfluss auf Grammatik nimmt (\cite[1--2]{Diessel.2017}). 
\end{sloppypar}


Die Zipfsche Verteilung verdeutlicht, wie stark Sprache durch Frequenz beeinflusst wird: Wenn man Wörter eines Texts nach ihrer Frequenz ordnet und anhand der Frequenz Ränge verteilt, ist die Wahrscheinlichkeit für das Auftreten eines Worts umgekehrt proportional zu seinem Rang (\cites[22--27]{Zipf.1972}[13]{Ellis.2012}). Das zweithäufigste Wort (Rang~2) ist also nur halb so häufig wie das häufigste Wort (Rang~1) und das dritthäufigste Wort (Rang~3) ist nur noch ein Drittel so häufig wie das häufigste Wort. Aus der Zipfschen Verteilung folgt, dass in einer Sprache nur wenige hochfrequente Wörter existieren, aber viele wenig frequente. Abbildung~\ref{figurzipf} zeigt exemplarisch die Frequenz der einzelnen Token in der Einleitung dieser Dissertation, die nach ihrem Rang sortiert sind.\footnote{Die Skripte zur Erstellung der Grafik sind im digitalen Anhang dokumentiert. Für die Aufbereitung der Daten wurde das Paket \textit{NLTK} (\cite{NLTK.2020}) genutzt.} 

\begin{figure}
\includegraphics[width=8cm]{figures/Kap3/frequenzeinleitung.png}
\caption{Frequenz der Token in der Einleitung nach ihrem Rang\label{figurzipf}}
\end{figure}

Auf Rang~1 und damit das häufigste Token ist \textit{und} (106 Belege), gefolgt von \textit{die} (85 Belege) und \textit{der} (83 Belege) und \textit{auf} (55 Belege). Auf Rang~5 folgt mit 53 Belegen das Substantiv \textit{Variation}, dessen Häufigkeit sich aus dem Thema der Dissertation ergibt. Die Ränge stehen nicht ganz in einem umgekehrt proportionalem Verhältnis zueinander, allerdings ist ein deutlicher Frequenzabfall von Rang~1 zu Rang~5 zu beobachten. Ab Rang~45 weisen die Token nur noch maximal zehn Belege pro Rang auf.

Die Zipfsche Verteilung lässt sich nicht nur für einzelne Token beobachten, sondern auch für Phoneme, Konstruktionen\footnote{\label{gold}\textcite[75]{Goldberg.2006} stellt fest, dass einzelne verbale Konstruktionen von der Verwendung mit einem bestimmten Verb dominiert werden: Im Korpus von \textcite{Bates.1988}, in dem Äußerungen von Müttern an 28 Monate alte Kinder aufgenommen wurden, macht \textit{to put} 38 \% der Verwendungen innerhalb der caused-motion-Konstruktion aus (\textit{David puts the cheese into the fridge}).} und idiomatische Phrasen (\cite[235]{Ellis.2008}). Die Frequenzkurve in Abbildung~\ref{figurzipf} illustriert zudem, dass grammatische Elemente häufiger sind als lexikalische (\cite[58--59]{Gervain.2008}), denn die häufigsten drei Token in der Kurve stellen grammatische Elemente dar. Frequenz kann somit den Zugriff auf syntaktische Muster ermöglichen: Die Abfolge frequent--infrequent weist bpsw. auf ein Grammem hin, dem ein Lexem folgt (bspw. Determinierer~+~Bezugsnomen). \textcite{Gervain.2008} zeigen mithilfe eines \textit{head turn paradigms}\footnote{Bei dem \textit{head turn paradigm} werden Kindern Stimuli aus Lautsprechern vorgespielt, die sich links und rechts vom Kind befinden. Dabei wird die Zeitspanne gemessen, in der das Kind seinen Kopf in Richtung des Lautsprechers dreht, aus dem der Stimulus zu hören ist (\cite[4]{Gervain.2013}). Im Experiment von \textcite[68--69]{Gervain.2008} wurde den Kindern in der Eingewöhnungsphase eine artifizielle Sprache vorgespielt, die aus einer Abfolge aus häufigen und seltenen Elementen bestand. Die artifizielle Sprache begann dabei entweder mit einem frequenten (frequent-infrequent) oder einem infrequenten Element (infrequent-frequent). In der Testphase wurde sowohl die bereits bekannte Sprache als auch eine neue vorgespielt, die jeweils die andere Reihenfolge aufwies (\cite[69--70]{Gervain.2008}). Dabei wurde getestet, ob es einen Unterschied in der Zeitspanne gibt, in der die Kinder den Kopf zum Stimulus drehen. Dies war bei dem Experiment der Fall: Kinder mit Italienisch als L1 schauten länger zum frequenzinitialen Stimulus, während Kinder mit Japanisch als L1 länger  zum frequenzfinalen Stimulus blickten (\cite[70]{Gervain.2008}). Die Präferenz für einen Stimulus reflektiert die Reihenfolge von frequenten und infrequenten Elementen im Italienischen bzw. Japanischen.}, dass Kinder mit acht Monaten bereits zwischen frequenten und infrequenten Wörtern unterscheiden und so syntaktische Muster erkennen können. Zusätzlich zur Frequenz nutzen Kinder hierfür prosodische Hinweise im Input (\cite{Gervain.2013}). Die frühe Sensitivität für Frequenz von Kindern ist ein Hinweis darauf, dass Spracherwerb unter anderem über statistisches Lernen (\textit{statistical learning}) funktioniert (\cite[2003]{Saffran.2003}, siehe hierzu auch \sectref{Statistik}). 

Im Folgenden wird zunächst der Unterschied zwischen Typen- und Tokenfrequenz eingeführt. Typen- und Tokenfrequenz sind grundlegend für diese Arbeit. Sie werden im späteren Verlauf der Arbeit zentral sein, da die Unterscheidung zwischen Typen- und Tokenfrequenz genutzt wird, um den Einfluss der Frequenz auf Variation zu modellieren. Im Anschluss an die Unterscheidung zwischen Typen- und Tokenfrequenz setzt sich \sectref{korrelation} kritisch mit Frequenzeffekten auseinander. Dabei werden Frequenzeffekte in der Prozessierung vorgestellt und die Korrelation von Frequenz mit anderen Faktoren (bspw. Kontextdiversität) problematisiert: Durch die Korrelation mit zahlreichen Faktoren kann Frequenz zwar als ein guter Prädiktor für menschliches Verhalten angesehen werden, aber nicht zwingend als Erklärung für dieses Verhalten dienen. Im Anschluss daran wird in \sectref{Statistik} ein Ausweg aus diesem Problem aufgezeigt. Frequenz wird als ein wichtiger Einflussfaktor innerhalb des statistischen Lernens modelliert: Statistisches Lernen beruht auf Wahrscheinlichkeiten und Frequenz nimmt Einfluss auf die Wahrscheinlichkeit für das Auftreten einer Struktur. Auf diese Weise kann der Einfluss von Frequenz samt korrelierenden Faktoren modelliert und anhand der Modellierung Vorhersagen über den Einfluss von Frequenz auf Variation gemacht werden.

\subsection{Typen- und Tokenfrequenz}\label{typ} 

Die Zipfsche Verteilung verdeutlicht, wie grundlegend Frequenz den Sprachgebrauch beeinflusst: Es existieren nur wenige hochfrequente Elemente, aber viele niedrigfrequente. Frequenz nimmt daher mittelbar durch den Sprachgebrauch auch Einfluss auf die mentale Repräsentation sprachlicher Einheiten. Frequenz kann dabei mit \textcite[54]{Divjak.2015} gefasst werden als "`a practical term that was, and still is, used to capture how frequently a stimulus (such as a word or a phrase) is encountered and processed in the environment"'. In dieser Definition wird deutlich, dass der zu zählende\footnote{Neben dem Ermitteln der Frequenz durch Zählen eines Elements in einem Korpus oder mehreren Korpora erwähnen \textcite[54]{Divjak.2015} die Frequenzeinschätzung von L1-Sprecher\_innen. Die Ergebnisse der beiden Methoden stellen sie als objektiv bzw. subjektiv dar. Hierbei ist zu beachten, dass auch die Wahl des Korpus Frequenzen verzerren kann, sodass die Frequenzbestimmung aufgrund eines Korpus nicht notwendigerweise als objektiv gelten kann.}  Stimulus stets zu definieren ist. Vor diesem Hintergrund stellt sich also die Frage, welche Einheiten gezählt werden: So können bspw. \textit{bist} und \textit{ist} als zwei Zähleinheiten gefasst werden, da es sich um verschiedene Wortformen handelt, oder als eine einzelne Zähleinheit, da beide Wortformen Teil des Paradigmas von \textit{sein} sind. Hierbei ist die Unterscheidung zwischen Typen- und Tokenfrequenz grundlegend (\cite[378]{Bybee.1997}).

Tokenfrequenz meint die Häufigkeit, mit der Sprecher\_innen einer bestimmten Wortform begegnen wie bspw. \textit{lachte}. Auf dieser Zählweise beruht die Frequenzkurve in Abbildung~\ref{figurzipf}. Typenfrequenz blickt hingegen auf die Anzahl verschiedener Elemente, die innerhalb eines Musters, Paradigmas, einer Kategorie oder Konstruktion\footnote{Sprachliche Kategorien und Konstruktionen stehen in einem engen Verhältnis: Konstruktionen sind Form-Funktions-Paare. Der Terminus \textit{Kategorie} hebt auf Gemeinsamkeiten zwischen mehreren Konstruktionen oder mehreren Verwendungen einer Konstruktion ab. Die Verbindung der Buchstabenkombination <Katze> mit der Bedeutung \SchmittSingleQuot{vierbeiniges Tier, das miaut} ist daher eine Konstruktion, aber auch eine Kategorie, weil unter dem Form-Funktions-Paar <Katze> und  \SchmittSingleQuot{vierbeiniges Tier, das miaut} mehrere Entitäten zusammengefasst werden, auf die die Funktion zutrifft. Dasselbe gilt für die Verbindung der Buchstabenkombination <Substantiv> mit Wörtern, die bestimmte syntaktische und morphologische Eigenschaften aufweisen.  \textit{Konstruktion} wird in der vorliegenden Arbeit genutzt, wenn die Interaktion zwischen Form und Funktion im Vordergrund steht. \textit{Kategorie} findet Verwendung, wenn die gemeinsamen Eigenschaften relevant sind.} auftreten können (\cite[166]{Ellis.2002b}). Das Tempusparadigma von \textit{lachen} enthält bspw. die Elemente \textit{lachte}, \textit{lache}, \textit{gelacht}. Formen innerhalb eines Flexionsparadigmas können also Token eines Types sein. Allerdings lassen sich auch schwache Verben (\textit{lachen}, \textit{machen}) als Token des Types \textsc{schwaches Verb} auffassen (zum Einfluss der Typen- und Tokenfrequenz auf die Variation in der Konjugation siehe \sectref{freqverb}).\footnote{Einen Überblick zu weiteren Zählmethoden bietet \textcite[15--21]{Krause.2016}. Dabei differenziert sie Zählmethoden für die Tokenfrequenz eines Lemmas und eines Basislemmas: Bei der Tokenfrequenz eines Lemmas gelten \textit{abweisen} und \textit{verweisen} als zwei Lemmata; bei der Tokenfrequenz des Basislemmas hingegen als Token des Lemmas \textit{weisen} (\cite[15--18]{Krause.2016}). Innerhalb der Typenfrequenz weist sie auf die Notwendigkeit hin, intraparadigmatische Frequenzen zu bestimmen. Dabei gilt es zu ermitteln, a) wie viele Formen eines Paradigmas eine bestimmte Eigenschaft aufweisen (bspw. \textit{e} als Stammvokal) und b) wie häufig eine bestimmte Form innerhalb des Paradigmas (bspw. der Imperativ) genutzt wird. Beide Frequenztypen können Einfluss auf die analoge Anpassung unregelmäßiger Verben hin zum regelmäßigen Paradigma haben (\cite[19--21]{Krause.2016}). Sie werden daher in den Abschnitten~\ref{konjugation} und \ref{deklination} zur Variation in der Konjugation und Deklination wieder aufgegriffen.}  Die Unterscheidung von Typen- und Tokenfrequenz ist für diese Arbeit grundlegend, da sowohl die Typen- als auch die Tokenfrequenz Stabilität und Variation beeinflussen: Wie anhand der Ausführungen ersichtlich werden wird, ist Variation für tokeninfrequente Mitglieder einer typeninfrequenten Kategorie am wahrscheinlichsten, wenn eine typenfrequente Kategorie existiert, der sie sich in ihrem Verhalten anschließen können.

\textcite[384]{Bybee.1997} gehen davon aus, dass die Typenfrequenz einer  Kategorie  deren Produktivität determiniert. Sie definieren Produktivität dabei als "`likelihood that a pattern will be applied to new forms"' (\cite[384]{Bybee.1997}). Die Interaktion von Typenfrequenz und Produktivität machen sie an drei Punkten fest:

\begin{enumerate}
\item Je mehr Elemente eine Kategorie hat, desto unwahrscheinlicher ist es, dass die Kategorie nur mit einem einzigen Element assoziiert wird, sondern dass eine generelle Kategorie mit den Elementen geformt wird, die zu der Kategorie gezählt werden. Für die typenfrequenten regelmäßigen Verben ist es also unwahrscheinlich, dass nur das Exemplar \textit{lachen} mit regelmäßiger Flexion durch Dentalsuffix verknüpft ist. Vielmehr ist davon auszugehen, dass eine allgemeine Kategorie geformt wird. \textcite[384]{Bybee.1997} betonen dabei, dass Typenfrequenz nicht diskret einzuteilen, sondern graduell ist, da die Typenfrequenz einer Kategorie von einem einzigen Type (\textit{sein}) bis zu einer hohen Anzahl von Types schwanken kann. 

\item Je mehr Elemente eine Kategorie enthält, desto abstrakter muss die Kategorie sein. Daher ist es für eine Kategorie mit vielen Elementen wahrscheinlicher, dass neue Elemente zu der Kategorie hinzu kommen (\cite[384]{Bybee.1997}). Die Konstruktion X\textsubscript{NP\_Nom} \textit{werden} X\textsubscript{VVPP} (\textit{er wird getragen}, \textit{wir werden gefragt}) lässt bspw. jedes transitive Verb zu. Die Kategorie ist daher abstrakt. Die Konstruktion X\textsubscript{NP\_Nom} \textit{bekommen} X\textsubscript{VVPP} (\textit{Die Kinder bekommen eine Geschichte vorgelesen}/\textit{Ich bekomme das Geld überwiesen}) ist dagegen semantisch eingeschränkt, bspw. sind keine abstrakten Subjekte möglich (\cite[133--134]{Wegener.1985}), sodass der Verb-Slot dieser Konstruktion weniger produktiv ist als der Verb-Slot der \textit{werden}-Passiv-Konstruktion.

\item Hohe Typenfrequenz bedeutet auch, dass eine Kategorie häufig genutzt wird. Dementsprechend wird ihre mentale Repräsentation gestärkt, sodass die Kategorie leichter aufzurufen ist und mit neuen Elementen genutzt werden kann. Die mentale Repräsentation wird dabei vor allem durch die tokeninfrequenten Mitglieder einer Kategorie gestärkt (\cite[62]{Bybee.2013}): Die Prozessierung der tokeninfrequenten Mitglieder setzt voraus, dass die Kategorie aktiviert wird, sodass sie gestärkt wird. Tokenfrequente Mitglieder können hingegen prozessiert werden, ohne die gesamte Kategorie aufzurufen und dadurch zu stärken. Tokenfrequente Mitglieder einer Kategorie können deren mentale Repräsentation somit nur bedingt stärken (\cite[62]{Bybee.2013}). 
\end{enumerate}

\textcite[62]{Bybee.2013} ergänzt diese Punkte mit dem Hinweis darauf, dass in einem exemplar-basierten Lernmodell (\textit{exemplar based model}, siehe \sectref{exemplar}) hohe Typenfrequenz einer Kategorie bedeutet, dass auch mehr Ankerpunkte für neue Vertreter der Kategorie existieren. Auch dies verdeutlicht den eingeschränkten Einfluss von Tokenfrequenz auf Produktivität: Die hohe Tokenfrequenz eines Vertreters führt nicht zu neuen Anknüpfungspunkten. Wie \textcite[384]{Bybee.1997} verknüpft auch \textcite[62--63]{Goldberg.2019} Typenfrequenz mit Produktivität, indem sie die Abdeckung (\textit{coverage}) einer Kategorie als Einflussfaktor auf Produktivität vorschlägt. Dabei konzeptualisiert \textcite[16]{Goldberg.2019} Kategorien über Cluster: Vertreter einer Kategorie weisen Ähnlichkeiten in ihrer mentalen Repräsentation auf. Aufgrund dieser Ähnlichkeiten werden sie geclustert und so als Einheit wahrgenommen (\cite[36--37]{Goldberg.2019}). Cluster können dabei nicht nur durch semantische Ähnlichkeit, sondern bspw. auch durch phonologische\footnote{In exemplarbasierten Modellen wird sowohl von phonetischen als auch phonologischen Clustern ausgegangen (\cite[27--29]{Johnson.2007}). Phonologische Cluster sind dabei als Generalisierung phonetischer Cluster zu sehen  (\cite{Johnson.2005, Kirchner.2010}). Im Folgenden wird der Terminus \textit{phonologisch} genutzt, der somit bereits eine Generalisierung beinhaltet.} und kontextuelle Ähnlichkeit entstehen (auf die exemplarbasierte Entstehung der Cluster wird in \sectref{exemplar} näher eingegangen). 
\textcite[16--17]{Goldberg.2019} situiert die Cluster daher in einem hyperdimensionalen konzeptuellen Raum (\textit{hyperdimensional conceptual space}).

   
Mithilfe des Konzepts der Abdeckung lässt sich evaluieren, wie gut potentielle neue Vertreter zu einer Kategorie passen: Für potentielle Vertreter wird überprüft, wie gut die neue Kategorie, die aus den bereits beobachteten Vertretern und dem neuen Vertreter besteht, durch das Cluster im hyperdimensionalen Raum abgedeckt wird: Wenn der Neuzugang zu wenig Ähnlichkeit zu den bereits attestierten Exemplaren bspw. hinsichtlich der phonologischen Form aufweist, ist die neue Kategorie nur lückenhaft abgedeckt, weil zwischen den neuen und den alten Exemplaren verbindende Exemplare fehlen.\footnote{Das Konzept der Abdeckung funktioniert daher ähnlich wie Familienähnlichkeit (siehe hierzu genauer \sectref{standard}).} Wenn der Neuzugang dagegen viel Ähnlichkeit mit bereits bestehenden Exemplaren aufweist, ist die Kategorie gut abgedeckt. Abbildung \ref{fuellung} veranschaulicht das Prinzip anhand der Verben der Ablautreihe 3a und schwachen Verben.

\begin{figure}
\includegraphics[width=\textwidth]{figures/Kap3/Fuellung.png}  
\caption{Beispiel für Kategorien mit lückenhafter und lückenloser Abdeckung}
\label{fuellung}
\end{figure}

Die Verben der Ablautreihe 3a haben mit /ɪ/ gefolgt von einem Nasal und einem weiteren Konsonanten ähnliche phonologische Eigenschaften und clustern daher stark (ausführlich zu den phonologischen Eigenschaften der Verben und dem sich daraus ergebenden Form-Schema siehe \sectref{schemaverb}). Für ein potentiellesneues Verb (\textit{googeln}) ergibt sich daher eine Kategorie, die lückenhaft abgedeckt ist: \textit{Googeln} ähnelt den Verben der Ablautreihe 3a bis auf die Zweisilbigkeit und den gemeinsamen Endkonsonanten -\textit{n} nicht. Dies ist bei den schwachen Verben anders. Da die Vertreter dieser Flexionsklasse ein hochvariables Cluster bilden, kann \textit{googeln} Teil des Clusters werden, ohne dass die Abdeckung der Kategorie sich verschlechtert.

Neben der Typenfrequenz nehmen also weitere Faktoren Einfluss auf die lückenlose Abdeckung der neuen Kategorie und somit auf die Produktivität: die Variabilität der bereits beobachteten Exemplare und die Ähnlichkeit des potentiellen neuen Exemplars mit den alten. Dabei korrelieren Typenfrequenz und die Variabilität einzelner Exemplare einer Kategorie zu einem bestimmten Grad: Mitglieder einer Kategorie, die 1.000 Mitglieder hat, werden wahrscheinlich eine höhere Variabilität aufweisen als Mitglieder einer Kategorie, die nur zehn Mitglieder aufweist (\cite[65]{Goldberg.2019}). Jedoch kann eine (relativ) typenfrequente Kategorie auch wenig variabel sein, wie bspw. die Verben der Ablautreihe 3a mit der Form [\#\_ɪ + Nasal + (C)]. Diese kann dann weniger leicht auf Exemplare ausgeweitet werden, die außerhalb der bereits beobachteten Variabilität liegen (\cite[67]{Goldberg.2019}). Außerdem interagieren Variabilität und Ähnlichkeit miteinander: Je variabler die Mitglieder einer Kategorie sind, desto wahrscheinlicher ist es, dass ein neues Exemplar Ähnlichkeit zu bereits attestierten Exemplaren aufweist.

Als weiteren Einflussfaktor auf Produktivität lässt sich die Existenz einer alternativen Formulierung anführen, die dasselbe ausdrückt und leichter zu aktivieren ist als die potentielle neue Formulierung (\cite[70]{Goldberg.2019}; siehe hierzu genauer \sectref{Statistik}). Produktivität wird somit von zwei Faktoren beeinflusst: Abdeckung der Cluster (Typenfrequenz, Variabilität und Ähnlichkeit) und Wettbewerb in der Aktivierung (\cite[117]{Goldberg.2019}).

Konstruktionen, deren Form jeweils mit derselben Funktion assoziiert ist,\footnote{Diese Assoziation von einer Funktion mit mehreren Formen wird in \sectref{konstruktion} als Form-Schematizität bezeichnet und näher ausgeführt.} unterscheiden sich i.~d.~R. in ihrer Abdeckung voneinander. Dies ist bspw. bei verschiedenen Flexionsklassen der Fall. Die Flexionsklassen haben verschiedene Formen (wie bspw. \textit{lachte} und \textit{sank}), aber die Funktion der Formen ist jeweils gleich (in diesem Fall \SchmittSingleQuot{Vergangenheit}). Dabei weist eine Flexionsklasse eine hohe Abdeckung auf (schwache Verben), während die andere Fle\-xions\-klas\-se eine niedrige Abdeckung aufweist (starke Verben). Die Flexionsklasse mit hoher Abdeckung hat ein transparentes Flexionsmuster, das für alle Token des Types gilt: Die Funktion \SchmittSingleQuot{Vergangenheit} ist für alle Token mit der Form -\textit{t} verbunden. Das Verhalten innerhalb der typeninfrequenten Klasse (z.~B. /iː/ und /uː/ oder /a/ und /ʊ/ als Ablaute im Präteritum und Partizip~II) ist hingegen nicht verallgemeinerbar, sondern auf spezifische Token (wie z.~B. \textit{rufen}, \textit{rief}, \textit{gerufen}) oder Token mit phonologischen Gemeinsamkeiten (Verben der Ablautreihe 3a) beschränkt. Verben mit phonologischen Gemeinsamkeiten, die dasselbe Flexionsverhalten aufweisen, werden in \sectref{konstruktion} diskutiert und als Form-Schema bezeichnet.

Die Generalisierbarkeit eines Flexionsmusters korreliert somit mit der Abdeckung der Kategorie (\cite[67--68]{Goldberg.2019}). Die Abdeckung legt dabei den Inhalt der Generalisierung fest (\cite[136]{Goldberg.2019}). Im Fall der schwachen Verben ist der hyperdimensionale Raum hinsichtlich der Phonologie und Semantik weit abgedeckt und abgesehen vom Dentalsuffix und der Bedeutung [+Vergangenheit] nicht restringiert. Diese Restriktionen sind der Inhalt der Generalisierung.  Eine solch umfassende Generalisierung ist für typeninfrequente Flexionsklassen nicht möglich, da sie nur wenige Types mit geringer Variabilität enthalten. Das Ablautmuster der Verben der Ablautreihe 3a ist bspw. an eine spezifische, prototypisch organisierte phonologische Form gekoppelt und daher nur auf Verben mit dieser Form generalisierbar (\cite[132--133]{Bybee.1985}; siehe \sectref{konstruktion} zu Form-Schemata).

Die hohe Tokenfrequenz starker Verben ermöglicht Unregelmäßigkeit (\cite[166]{Ellis.2002b}). Durch die ständige Nutzung ist die mentale Repräsentation frequenter Formen \textit{entrenched} (gefestigt): Je häufiger eine Aktivität ausgeführt wird, desto stärker wird sie mental \textit{en\-trenched}, sodass jede Ausführung die nächste Ausführung erleichtert (\cites[380]{Bybee.1997}[13]{Schneider.2014}). \textcite[x]{Kemmer.2000} bezeichnen \textit{entrenchment} daher als "`cognitive routinization"'. Aufgrund der hohen Frequenz sind die Formen also trotz Unregelmäßigkeit leicht zu prozessieren. Unregelmäßige Formen bringen zudem den Vorteil mit sich, dass sie kurz und gut unterscheidbar sind (\cites[42--43]{Werner.1989}[226--227]{Nubling.2000}). Diese Eigenschaften erleichtern wiederum eine ökonomische Prozessierung hochfrequenter Elemente (\cite[174]{Nowak.2013}). Zudem ist davon auszugehen, dass die Wortformen frequenter Verben weniger stark untereinander verbunden sind als die Wortformen niederfrequenter Verben (\cite[117--124]{Bybee.1985}): Die Formen \textit{gehen} und \textit{ging} sind also weniger stark miteinander verbunden als \textit{lachen} und \textit{lachte}. Frequente Verben haben in dieser Betrachtung ein weniger eng zusammenhängendes Paradigma als infrequente Verben. \textcite[715]{Bybee.2006b} bezeichnet dies als Autonomie-Effekt: Hochfrequente Elemente einer Konstruktion entwickeln einen autonomen Chunk und aktivieren die Ursprungskon\-struk\-tion nicht, weshalb hochfrequente Vertreter die Produktivität einer Kategorie nicht stärken (\cite[62]{Bybee.2013}). Auch nach dem Konzept der Abdeckung von \textcite{Goldberg.2019} tragen frequente Elemente generell nur eingeschränkt zur Produktivität einer Konstruktion bei, weil sie die Abdeckung der Kategorie nicht erhöhen. Die Tokenfrequenz stärkt lediglich die mentale Repräsentation des frequenten Elements (\cite[68]{Goldberg.2019}).\footnote{Allerdings können frequente Formen im Spracherwerb als Analogievorlagen dienen und somit zur Produktivität von Kategorien beitragen (\cite[242]{Ellis.2016}). Dabei ist davon auszugehen, dass tokenfrequente Elemente im Spracherwerb zur analogischen Erweiterung einer noch rudimentären Kategorie dienen. Je mehr die Kategorie gefestigt und abstrahiert wird, desto geringer ist der Einfluss der Tokenfrequenz einzuschätzen.}

Bei schwachen und starken Verben lässt sich der unterschiedliche Kohärenzgrad des Paradigmas auch in der Phonologie erkennen. Die Formen starker Verben weisen weniger phonologische Ähnlichkeiten auf als schwache Verben. Daher kann auf lautlicher Ebene kein kohärentes Cluster entstehen, sodass die einzelnen Wortformen eher als unabhängig voneinander wahrgenommen werden können. Abbildung \ref{clusterverb} veranschaulicht dies anhand der Verben \textit{sagen} und \textit{biegen}. 

\begin{figure}
\includegraphics[width=\textwidth]{figures/Kap3/stverben.png}  
\caption{Cluster der Verbformen bei schwachen und starken Verben}
\label{clusterverb}
\end{figure}

Wie aus Abbildung \ref{clusterverb} deutlich wird, clustern die Verbformen des schwachen Verbs \textit{sagen} nicht nur semantisch, sondern auch lautlich. Dies ist bei dem starken Verb \textit{biegen} nur bedingt der Fall: Durch den Ablaut ändert sich die Form deutlich. Das Dentalsuffix -\textit{t} beeinflusst die Form hingegen nur leicht. Noch deutlicher wird der Unterschied bei hochfrequenten Verben mit Suppletivparadigmen wie bspw. \textit{sein}, bei denen zwar eine semantische Beziehung zwischen den einzelnen Wortformen besteht, aber keine phonologische (\cite[171]{Bybee.2007}).\footnote{\textcite[118--129]{Bybee.1985} argumentiert nicht über gebrauchsbasierte Cluster, geht aber prinzipiell ähnlich in ihrer Argumentation vor. Sie geht in ihrem dynamischen Modell lexikalischer Repräsentation davon aus, dass zwischen Wortformen ein morphologisches Verhältnis besteht, das sich durch semantische und phonologische Verbindungen ergibt (\cite[118--129]{Bybee.1985}). Die semantischen und phonologischen Verbindungen ließen sich auch als Cluster aus ähnlichen Exemplaren fassen. Die semantische Verbindung zwischen Wortformen eines Paradigmas wird durch die Relevanzskala beeinflusst (\cite[79--81]{Bybee.1991}): Relevante Kategorien verändern die Semantik stärker als weniger relevante Kategorien. Eine Änderung einer relevanten Kategorie (Tempus) führt somit zu einer weniger engen Verbindung als die Änderung einer weniger relevanten Kategorie (Person). Schwächere semantische Verbindungen können in den phonologischen Verbindungen gespiegelt werden bspw. durch eine Änderung des Stammvokals über Ablautung (\cite[170]{Bybee.2007}). Auch dies lässt sich durch Cluster fassen: Aufgrund des Ablauts und der großen Änderung in der Semantik ist das Cluster weniger kohärent als Cluster mit gleich bleibendem Vokal und nur geringer Änderung der Semantik. Neben Semantik und Phonologie beeinflusst die Tokenfrequenz das morphologische Verhältnis: Die Verbindung zwischen Wortformen eines Lexems ist bei hochfrequenten Lexemen loser als bei niedrigfrequenten. Ausführlich zum dynamischen Modell lexikalischer Repräsentation siehe \textcite{Bybee.1985}.} Aufgrund der geringen bis nicht vorhandenen phonologischen Beziehung sind hochfrequente Wortformen weniger stark mit ihrer Grundform assoziiert als niedrigfrequente und werden somit auch weniger stark analysiert (\cite[118]{Bybee.1985}). \textcite[117--118]{Bybee.1985} beschreibt diese Autonomie hochfrequenter Formen als lexikalische Stärke.

Für die Autonomie hochfrequenter Elemente ist zudem relevant, dass die einzelnen Verwendungen des hochfrequenten Elements in einer Konstruktion ein gesondertes Subcluster bilden (\cite[69--70]{Goldberg.2019}). Dieses Subcluster kann daher als eigenständiges Cluster angesehen werden. Effekte der Autonomie hochfrequenter Elemente lassen sich  auch innerhalb von Konstruktionen beobachten: Elemente, die häufig in einem Slot einer Konstruktion genutzt werden, können die Variabilität in anderen Slots der Konstruktion erhöhen. Als Beispiel nennt \textcite[69]{Goldberg.2019} \textit{to make} als frequentes Verb in der Resultativ-Konstruktion, das viele Adjektive zulässt (\textit{to make someone/onself sick/ill/happy/crazy}). Das weniger frequente \textit{eat} ist in dieser Konstruktion hingegen auf die Verwendung mit \textit{ill} beschränkt (\textit{to eat oneself ill}), auch das semantisch verwandte Adjektiv \textit{sick} ist nicht möglich (\cite[69]{Goldberg.2019}). Die erhöhte Variabilität in einem Slot, die durch ein hochfrequentes Element in einem anderen Slot bedingt ist, führt somit auch zu einer größeren Produktivität.

\begin{sloppypar}
Der Einfluss der Tokenfrequenz auf mentale Repräsentationen wurde im obigen Absatz bereits angesprochen. Zusätzlich zum Autonomie-Effekt diskutieren \textcite[378--384]{Bybee.1997} den konservierenden Effekt: Die Bedeutung hochfrequenter Wörter verändert sich kaum (\cite[12--13]{Ellis.2012}), zudem sind hochfrequente Wortformen vor analogischem Ausgleich (\textit{analogical leveling}) ge\-schützt. Daher behalten hochfrequente unregelmäßige Verben ihre Flexion bei (\textit{schlafen, schlief, geschlafen}; \textit{sleep, slept}), während infrequente unregelmäßige Verben zur regelmäßigen Flexion wechseln (\textit{gequollen/gequellt}; \textit{wept/weeped}) (\cites[119--120]{Bybee.1985}[280]{Bybee.1997}; siehe hierzu auch \sectref{freqverb} zur Variation in der Konjugation). Dabei ist zu betonen, dass der Blick auf reine Tokenfrequenz nicht ausreicht, um das Ausbleiben eines Flexionswechsels zu erklären. Wie aus den obigen Erläuterungen deutlich wurde, basiert der Frequenzeffekt auf \textit{entrenchment}: Durch die ständige Nutzung entsteht eine gefestigte mentale Repräsentation, die alle Vorkommnisse eines Tokens clustert. Aber auch die Token selbst können zu einer Kategorie geclustert werden (wie bspw. die Verben der Ablautreihe 3a), die dann wiederum Einfluss auf Variation nehmen kann. Sowohl Tokenfrequenz als auch die Effekte, die durch Cluster von ähnlichen Exemplaren bedingt sind und in \sectref{steuerungschema} als Form-Schemata diskutiert werden, haben einen konservierenden Einfluss auf Flexion. 
\end{sloppypar}
 

Der konservierende Effekt von Tokenfrequenz ist nicht auf die Morphologie beschränkt, sondern zeigt sich auch in der Syntax: Während Modalverben aufgrund ihrer Frequenz in Fragesätzen weiterhin Inversion aufzeigen (\textit{May I ask you a question}?), ist dies bei Vollverben nicht der Fall (*\textit{Read you a book?}) (\cite[619--621]{Bybee.2002}). \textcite[728--729]{Bybee.2006b} stellt zudem fest, dass die \textit{no}-Negation (\textit{It looks like nothing to me}), die weniger produktiv ist als die \textit{not}-Negation (\textit{It doesn't look like anything to me}), sich in frequenten Konstruktionen weiterhin hält, wie bspw. in Existenzaussagen mit \textit{be} (\textit{There was no work to do} statt \textit{There wasn't work to do}). 



Für die Abgrenzung von Autonomie- und Konservierungseffekten stellt sich die Frage, ab welcher Frequenz welcher Effekt greift. Der Autonomie-Effekt ist auf extrem frequente Elemente begrenzt und greift somit für frequentere Elemente als der Konservierungseffekt (\cite[715]{Bybee.2006b}):\footnote{\textcite{Bybee.2006b} unterscheidet zwar zwischen hochfrequenten und extrem frequenten Elementen, geht aber nicht darauf ein, wie sie diese unterscheidet: "`I refer to high and low frequency and to extreme high frequency without specifying exactly what these values mean in numerical terms"' (\cite[715]{Bybee.2006b}).} Die Verwendungen extrem frequenter Elemente bilden ein größeres Cluster als die Verwendungen weniger frequenter Elemente. Das Cluster hat somit auch eine größere Variabilität, die die Autonomie fördert. 

Neben der Autonomie und der Konservierung be\-obachten \textcite[378--384]{Bybee.1997} Reduktion als Effekt hoher Tokenfrequenz. Der reduzierende Effekt  ist bspw. in der Phonologie sichtbar: Häufige Kombinationen werden kontrahiert (\textit{no thing > nothing}, \textit{does not > doesn't}; \textit{zu dem} > \textit{zum}). Zudem sind Lautwandelphänomene bei hochfrequenten Wörtern früher zu beobachten als bei infrequenten (\cite[46--47]{FenkOczlon.1990}): So werden /t/ und /d/ nach einem Konsonanten in hochfrequenten englischen Wörtern (\textit{and}, \textit{went}) eher getilgt als in niedrigfrequenten (\cite[69--71]{Bybee.2000}). Am deutlichsten ist der reduzierende Einfluss der Tokenfrequenz in der Grammatikalisierung zu beobachten: Elemente, die aufgrund von Grammatikalisierung an Frequenz gewinnen (\cite[188]{Detges.2002}), verlieren an phonologischer Substanz (\textit{going to} > \textit{gonna}) (\cite[378--380]{Bybee.1997}). Die phonologische Reduktion hat einen weiteren Effekt: Sie führt zu einer geringeren akustischen Salienz dieser Elemente und damit vor allem im L2-Spracherwerb zu Schwierigkeiten in der Lernbarkeit, sodass lexikalische Elemente leichter erworben werden als grammatische (\cite[236]{Ellis.2008}).\footnote{\textcite[307]{Ellis.2002} geht davon aus, dass grammatische, wenig saliente Elemente durch lexikalische, salientere Elemente blockiert werden. Als Beispiel nennt er \textit{today} und die Endung -\textit{s} (als Marker für die dritte Person Singular Präsens), beide weisen laut \textcite[307]{Ellis.2002} auf Präsens hin, aber \textit{today} hat eine höhere Wahrscheinlichkeit, wahrgenommen zu werden.} 

 

Auch \textcite[20--29]{Zipf.1968} beobachtet, dass Kürze und Frequenz zusammenhängen: Häufig vorkommende Wörter sind sprachübergreifend kürzer als seltene. Wie \textcite{Bybee.1997} sieht \textcite[30]{Zipf.1968} die Kürze frequenter Einheiten als einen Effekt ihrer Frequenz: Da die Einheiten so oft genutzt werden, ist Kürze ein Vorteil, weil Zeit und Aufwand gespart wird (\cite[39]{FenkOczlon.1990}). Den Kürzungseffekt frequenter Einheiten kann man dabei auch im Kleinen beobachten: Bei der zweiten Verwendung eines Worts in einem Kontext wird dieses kürzer gesprochen als in der ersten Verwendung (\cite{Fowler.1987}). Bereits genutzte Wörter können reduziert werden, da sie durch das erstmalige Nutzen bereits aktiviert sind und durch den Kontext gestützt werden (\cite[489]{Fowler.1987}; dieser Effekt wird als Rezenzeffekt in \sectref{korrelation} noch einmal aufgegriffen). Hörer\_innen sind dabei sensitiv für die Längenunterschiede zwischen erster und zweiter Verwendung (\cite[501]{Fowler.1987}). Wiederholungen schneller zu sprechen, ist also nicht nur eine Produktionsstrategie, sondern markiert auch Wiederholungen als solche (\cite[11--12]{Bybee.2001}).



Reduktion lässt sich nicht nur auf phonologischer Ebene, sondern auch in der Syntax beobachten. Elemente, die häufig zusammen verwendet werden, wie bspw. \textit{going to}, werden nicht mehr als Bestandteile einer komplexen Phrase aufgefasst, sondern als ein einzelnes Element prozessiert und inzwischen auch produziert (\textit{gonna}) (\cite[68--69]{BlumenthalDrame.2012}): "`Items that are used together fuse together"' (\cite[112]{Bybee.2002b}). Somit geht die interne syntaktische Struktur von hochfrequenten Phrasen verloren. In diesem Zusammenhang lässt sich die phonologische Reduktion von \textit{going to} zu \textit{gonna} auch als Reaktion auf die Prozessierung hochfrequenter Phrasen als ein einzelnes Element verstehen. Zwischen den Einheiten ist eine "`ever-increasing cognitive connection"' (\cite[13]{Schneider.2014}) entstanden. Bei \textit{going to} und \textit{gonna} kann man zwar noch eine Beziehung von \textit{gonna} zu \textit{going to} herstellen, die Reduktion kann aber soweit fortgeschritten sein, dass ohne historisches Wissen keine Beziehung mehr zwischen Fusion und ursprünglicher syntaktischer Struktur hergestellt werden kann, bspw. bei \textit{oje}, das auf \textit{Oh mein Jesus} zurückgeht (\cite{Nubling.2001}). Dieser Prozess wird als \textit{chunking}\footnote{\textcite[14--15]{Diessel.2017} verwendet neben \textit{chunking} auch den Terminus \textit{Automatisierung}, ohne einen Bedeutungsunterschied zu machen. \textcite[13]{Schneider.2014} differenziert zwischen Automatisierung und \textit{chunking}: Automatisierung setzt für sie erst ein, wenn eine phonologische Reduktion der Chunks zu beobachten ist.} bezeichnet (\cite[13]{Schneider.2014}): Häufig zusammen auftretende Einheiten werden als eine große, hierarchisch gegliederte Einheit verarbeitet. Grundlage für das \textit{chunking} ist \textit{entrenchment} (\cite[13]{Schneider.2014}). \textit{Entrenchment}\footnote{Der Terminus \textit{entrenchment} geht auf \textcite[59--60]{Langacker.1987} zurück. Die Idee von \textit{chunking} aufgrund von Frequenz ist jedoch weit älter: \textcite[11]{BlumenthalDrame.2012} merkt an, dass bereits Saussure frequenzbasierte Chunks diskutiert.} wurde bereits in Bezug auf einzelne Formen eingeführt: Eine Einheit kann je nach Häufigkeit des Gebrauchs mehr oder weniger \textit{entrenched} sein. Das gleiche Prinzip lässt sich auf mehrere Einheiten anwenden: Diese sind stärker miteinander assoziiert, wenn sie häufig gemeinsam auftreten. 



\textit{Chunking} hat einen kognitiven Vorteil: Da das Arbeitsgedächtnis nur eine bestimmte Anzahl von Elementen gleichzeitig verarbeiten kann, bietet es sich an, häufig zusammen auftretende Einheiten als eine Einheit zu verarbeiten, sodass mehr Informationen im Arbeitsgedächtnis genutzt werden können (\cites[328]{Bybee.2006}[54--55]{Bybee.2013}[15]{Diessel.2017}). \textit{Chunking} erleichtert daher Prozessierung: "`When you do not have to put together every utterance from scratch, you need a minimum of on-line processing"' (\cite[11]{BlumenthalDrame.2012}). Dieser Vorteil ergibt sich erst durch Wiederholung, sodass Chunks inhärent mit Frequenz verbunden sind (\cite[717]{Bybee.2006b}). \textit{Chunking} zeigt sich auch in der Wahrnehmung von Sprecher\_innen: Kollokationen (wie bspw. \textit{absolute silence}) werden als natürlicher wahrgenommen als semantisch gleichwertige Kombinationen, die aber nicht \textit{entrenched} sind (\textit{pure silence}) (\cite{Dabrowska.2014b}).

 

Nicht nur \textit{chunking} und phonologische Reduktion, sondern auch die semantische Verblassung, die im Zuge der Grammatikalisierung einsetzt, lässt sich als Frequenzeffekt modellieren (\cite[379--380]{Bybee.1997}): Hochfrequente Wörter können semantisch verblassen (\cite[174]{Detges.2002}) und aufgrund der Verblassung noch häufiger genutzt werden, sodass ein Kreislauf einsetzt. Ein Beispiel für semantische Verblassung durch Frequenz ist die Entstehung neuer Negationsmarker (\cite[380]{Bybee.1997}): Diese sind zunächst stark expressiv, durch häufige Verwendung schleift sich die Expressivität ab, sodass nur noch die Negation als semantisches Merkmal übrig bleibt. Auch hier zeigt sich, dass Salienz und Frequenz miteinander interagieren. Durch die frequenzbedingte semantische sowie phonologische Reduktion des Negationsmarkers verringert sich dessen kognitive und physiologisch bedingte Salienz (ausführlich zu den Salienzbegriffen siehe \cite{Auer.2014}): Der Wegfall der Expressivität verringert das Potential, sich von anderen Ausdrucksformen zu unterscheiden (kognitive Salienz), und die phonologische Reduktion verringert das Potential, sensorisch zugänglich zu sein (physiologisch bedingte Salienz). Die verringerte Salienz des Negationsmarkers führt dazu, dass der Negationsmarker durch expressive Mittel verstärkt wird, welche wiederum selbst durch häufige Nutzung ihre Expressivität und damit Salienz verlieren (\cite{Jespersen.1917}, zur Interaktion von Frequenz und Expressivität siehe \cite[176--186]{Detges.2002}). 

\begin{sloppypar}
Der frequenzbedingte Reduktionseffekt verdeutlicht die fundamentale Rolle, die Frequenz für die Grammatikalisierung spielt. Aufgrund dieser Rolle wird Grammatikalisierung auch als Ritualisierung oder Routinisierung bezeichnet (\cites[603--604]{Bybee.2002}[189]{Detges.2002}). Ritualisierung ist hier als Konsequenz von Wiederholung gemeint, die zu Gewohnheit, Automatisierung, Reduktion und Emanzipation der Struktur von der ursprünglichen führt (\cite[4--8]{Haiman.1994}).
\end{sloppypar}

Es zeigt sich, dass sowohl die Typen- als auch die Tokenfrequenz einen fundamentalen Einfluss auf mentale Repräsentationen haben. Die Typenfrequenz von Kategorien ist eng mit deren Produktivität verknüpft. Zusätzlich zur Typenfrequenz beeinflussen Variabilität und Ähnlichkeit die Produktivität. Variabilität und Ähnlichkeit sind dabei eng mit Typenfrequenz verzahnt. Die Tokenfrequenz nimmt  kaum Einfluss auf die Produktivität einer Kategorie. Hohe Tokenfrequenz kann jedoch zu Autonomie, Konservierung und Reduktion aufgrund von \textit{entrenchment} führen. Für die weitere Arbeit sind vor allem die Generalisierbarkeit von Flexionsverhalten aufgrund von hoher Typenfrequenz und der festigende und damit konservierende Einfluss von hoher Tokenfrequenz relevant. Der Einfluss von Typen- und Tokenfrequenz auf Variation wird anhand der drei Variationsphänomene in Kapitel \ref{Fallstudien} näher untersucht. Dabei wird vorrangig die Generalisierbarbeit aufgrund von Typenfrequenz sowie  \textit{entrenchment} durch hohe Tokenfrequenz relevant sein. Im empirischen Teil der Arbeit wird der konservierende Einfluss von Tokenfrequenz psycholinguistisch überprüft.   

Der nächste Abschnitt gibt einen vertiefenden Einblick in Frequenzeffekte. Dabei werden Frequenzeffekte in der Prozessierung und die Interaktion von Frequenz mit Salienz und Rezenz diskutiert. Zusätzlich wird auch die Korrelation von Frequenz mit anderen Faktoren wie der Kontextdiversität und Abfolgewahrscheinlichkeit betrachtet. In diesem Zusammenhang wird die Frage diskutiert, welche Probleme entstehen, wenn Frequenz als Erklärung für Prozessierungsunterschiede herangezogen wird. 

\subsection{Frequenzeffekte und Korrelation mit anderen Faktoren}
\label{korrelation}
    
Frequenz wird als einer der besten Prädiktoren angesehen, um das Verhalten von Menschen vorherzusagen (\cite[55]{Divjak.2015}). Da frequente Wörter mental gefestigt sind, können sie schneller und leichter prozessiert als infrequente: Bei \textit{lexical decision tasks} erkennen Proband\_innen schneller, dass es sich um ein real existierendes Wort handelt, wenn dieses frequent ist (\cites[489--491]{Rubenstein.1970}[150--152]{Whaley.1978}).\footnote{\textcite[488--489]{Rubenstein.1970} kontrollieren auf Wortlänge, \textcite[144--148]{Whaley.1978} tut dies nicht,  inkludiert aber die Wortlänge in die Analyse. So kann \textcite[148--152]{Whaley.1978} zeigen, dass sowohl Frequenz als auch Wortlänge Einfluss auf die Reaktionszeiten nehmen. Zudem nutzt \textcite[146]{Whaley.1978} verschiedene Frequenzmaße, sodass nicht nur die reine Wortwiederholung, sondern auch Kontextdiversität berücksichtigen werden kann.} In Eyetrackingstudien lässt sich beobachten, dass frequente Wörter kürzer fokussiert werden als infrequente (\cite{Rayner.1986}). \textcite[56]{Divjak.2015} stellen zudem fest, dass die Prozessierung frequenter Wörter weniger störungsanfällig ist als die Prozessierung infrequenter Wörter: Hochfrequente Wörter werden bei Störgeräuschen besser verstanden als infrequente (\cite{Pollack.1959}). Der Einfluss der Frequenz zeigt sich auch mittelbar im Design psycholinguistischer Studien: Um einen konfundierenden Frequenzeffekt auszuschließen, wird auf Frequenz kontrolliert (\cite[54]{Divjak.2015}). 



Die Sensitivität von Menschen für Frequenz zeigt sich auch in Einschätzungsstudien. Proband\_innen sind bspw. gut darin, die Frequenz einzuschätzen, mit der Silben und Wörter genutzt werden: Die Einschätzung korreliert jeweils mit der tatsächlichen Frequenz (\cite{Shapiro.1969, Rubin.1974}). Außerdem können Pro\-\mbox{band\_in}\-nen  gut einschätzen, wie häufig ihnen in einem Experiment ein bestimmter Stimulus präsentiert wurde (\cite{Hasher.1984}). \textcite[323]{Flexser.1975} präsentieren eine Liste mit 117 Pseudowörtern, die in ihrer Tokenfrequenz von eins bis sechs variieren. Die Proband\_innen werden im Anschluss gebeten, zu schätzen, wie häufig die einzelnen Pseudowörter in der Liste vorkamen. Dabei korreliert die Schätzung der Proband\_innen mit der tatsächlichen Frequenz der Pseudowörter, unabhängig davon, ob die Proband\_innen vorab wussten, dass sie am Ende Frequenzschätzungen abgeben sollen (\cite[323--324]{Flexser.1975}).

 

Neben der Sensitivität für die Frequenz von Wörtern und Silben können \textcite{Frisch.2001} eine Sensitivität für die Häufigkeit von Lautkombinationen nachweisen: Sie arbeiten mit ausgedachten Wörtern, die häufige und seltene Lautkombinationen einer Sprache enthalten. Lässt man Proband\_innen beurteilen, ob die Testwörter theoretisch mögliche Wörter in einer Sprache sind, erzielen die Wörter hohe Werte, die häufige Lautkombinationen einer Sprache enthalten (\cite[162--163]{Frisch.2001}). Sie stellen dabei interessante individuelle Unterschiede in den Bewertungen fest: Je größer der Wortschatz von Proband\_innen, desto eher schätzen Proband\_innen Testwörter mit seltenen Lautkombinationen als möglich ein (\cite[166]{Frisch.2001}). Die Wahrscheinlichkeit für die Existenz eines Wortes wird also anhand der Häufigkeit von mental repräsentierten Lautkombinationen beurteilt, daher ist sie vom individuellen Wortschatz abhängig (\cite[175]{Frisch.2001}). Auf der Idee, dass Sprecher\_innen aktuell zu verarbeitenden Input mit Wahrscheinlichkeiten vergleichen, die auf ihren vorherigen Spracherfahrungen basieren, baut der bayesianische Ansatz für Sprachverarbeitungs- und Lernmodelle auf, der im folgenden Abschnitt ausführlich vorgestellt wird.

Sowohl die schnelle Prozessierung als auch die Frequenzeinschätzung von Sprecher\_innen verdeutlichen, dass frequente Wörter mental stark gefestigt (\textit{entrenched}) sind. Das \textit{entrenchment} frequenter Wörter zeigt sich aber auch darin, dass sie eine höhere Resilienz haben als infrequente Wörter: Frequente semantische Konzepte, die auf dem Basislevel operieren (bspw. \textit{Hund}, \textit{Pferd}; siehe hierzu genauer \sectref{steuerungprot}), werden von Patienten mit semantischer Demenz bewahrt und sogar übergeneralisiert (bspw. wird auf alle größeren Tiere mit \textit{Pferd} referiert), wohingegen für weniger frequente
 Konzepte nur noch ein rudimentäres Konzept zu bestehen scheint (\cite[12]{Rogers.2003}). Diese Beobachtung lässt sich gut mit \textcite[255]{Goldinger.1998} vereinbaren, der anhand einer Computersimulation zeigt, dass frequente Wörter abstrakter repräsentiert sind als infrequente Wörter. Er testet dies anhand des Vorteils für gleichbleibende Stimmen (\textit{same voice advantage})\footnote{Nicht nur dieselbe Stimme, sondern auch derselbe Raum bringt Vorteile: Proband\_innen fällt es leichter, Wörter von einer Liste wiederzugeben, wenn sie sich im selben Raum befinden, indem sie die Liste zuvor gelesen haben (\cite[14]{Goldberg.2019}).}: Für wenig frequente Wörter lässt sich ein Vorteil für gleichbleibende Stimmen beobachten. Wenn man ein Wort hört, das mehrfach von derselben Person gesagt wird, kann man dieses besser erkennen, als wenn das Wort von verschiedenen Personen gesagt wird. Für frequente Wörter besteht dieser Effekt nicht (\cite[153]{Ellis.2002b}). Hört man ein neues Wort, koppelt man dieses also zunächst an die Stimme der Person, die es produziert hat. Dieses spezifische Detail verschwindet jedoch, je häufiger man ein Wort hört (\cite[254--255]{Goldinger.1998}). Der Effekt stützt ein exemplarbasiertes Modell der Kategorienbildung, nach dem Kategorien anhand konkreter Exemplare abstrahiert werden (\cite[153]{Ellis.2002b}). Diese Idee wurde bereits durch Goldbergs Cluster-Modell in \sectref{typ} eingeführt und wird in \sectref{exemplar} zu Kategorienbildung durch exemplarbasiertes Lernen vertieft. 



Für exemplarbasiertes Lernen sprechen auch Prozessierungseffekte, die sich für Wörter beobachten lassen, die ähnlich aufgebaut, aber unterschiedlich frequent sind: Reaktionszeiten sind für infrequente Wörter bei \textit{lexical decision tasks} erhöht, wenn zuvor ein hochfrequenter orthographischer Nachbar präsentiert wurde, z.~B. \textit{blue} vor \textit{blur} (\cite{Grainger.1989, Grainger.1990}). Derselbe Effekt lässt sich auch durch Eyetracking beobachten (\cite{Grainger.1989}). Dies verdeutlicht einerseits, dass ähnliche Exemplare sich in ihrer Prozessierung beeinflussen und andererseits, dass Wörter nicht entweder aktiviert werden oder nicht, sondern dass Aktivierung graduell ist, da sie von der Frequenz des Wortes sowie der Anzahl ähnlicher Wörter und deren Frequenz abhängt (\cite[150--152]{Ellis.2002b}). 



Der Einfluss orthographischer Ähnlichkeit lässt sich auch in der Flexion beobachten. Englische regelmäßige Verben werden schneller gebildet, wenn keine unregelmäßigen Verben existieren, die orthographisch ähnlich sind: \textit{walk, walked} wird also schneller gebildet als \textit{bake, baked}, weil \textit{bake} Ähnlichkeit zu den unregelmäßigen Verben \textit{make, made} und \textit{take, took} aufweist (\cite[102--104]{Seidenberg.1992}; siehe \cite[371--387]{Daugherty.1994} für eine Studie, in der derselbe Effekt in einer Datensimulation beobachtet wird). Die Unterschiede in der Schnelligkeit der Produktion lassen auf Unterschiede in der Prozessierung schließen: Die Fähigkeit, ein Verb einer Klasse zuzuordnen, ist eingeschränkt aufgrund der Ähnlichkeit zu Verben, die einer anderen Klasse angehören. 

Hieran zeigt sich der Einfluss von \textit{cue validity} (Signalgüte) auf Prozessierung: Wenn ähnliche Strukturen miteinander konkurrieren, weisen diese eine geringe \textit{cue validity} auf, weshalb die Strukturen schwer zu differenzieren und damit zu erlernen sind (\cite[153]{Ellis.2002b}, siehe \sectref{steuerungschema} für weitere Ausführungen zu \textit{cue validity}). Die herabgesenkte \textit{cue validity} von regelmäßigen Verben, die unregelmäßigen Verben ähneln, weist zurück auf das Prinzip der Abdeckung nach Goldberg (2019) und voraus auf Form-Schemata (siehe \sectref{steuerungschema}): Die regelmäßigen Verben ähneln zwar den unregelmäßigen Verben in der Form, gehören aber dennoch einer anderen Flexionsklasse an. Dies kann vereinzelt zu Variation führen, indem die Flexionsklasse der Form angepasst und bspw. statt der regelmäßigen Form \textit{baked} die Form \textit{book} in Analogie zu \textit{took} gebildet wird.
 
Wie der letzte Abschnitt bereits verdeutlicht, treten Frequenzeffekte nicht isoliert auf, sondern interagieren mit anderen Faktoren. Dies zeigt auch die in \sectref{typ} diskutierte Interaktion von Frequenz und Salienz. \textcite[6--8]{Pfander.2016} weisen darauf hin, dass Frequenz auch mit Rezenz interagiert: Je kürzer der Zeitabschnitt zwischen der Wiederholung ein und desselben Elements ist, desto höher ist die Aktivierung des Elements.\footnote{In der Psychologie ist der Rezenzeffekt als Priming bekannt (\cite[14--15]{Ellis.2012}). Um Rezenzeffekte zu messen, wird m. W. allein die Zeit zwischen der Wiederholung eines Elements gemessen und nicht berücksichtigt, wie komplex die Struktur zwischen der Erstnennung und der Wiederholung ist.} Die in \sectref{typ} erwähnte schnellere Produktion des zweiten Vorkommens eines Elements in einem bestimmten Kontext (\cite{Fowler.1987}) lässt sich auch als Rezenzeffekt beschreiben. \textcite[7]{Pfander.2016} gehen davon aus, dass der Effekt sich direkt aus der Struktur unseres Erinnerungsvermögens ableitet. Für den Effekt spielt neben der Länge des Zeitabschnitts die Häufigkeit des sich wiederholenden Elements in einem bestimmten Zeitabschnitt eine Rolle: Je häufiger ein Element in einem Zeitabschnitt genutzt wird, desto stärker wird es aktiviert (\cite[6--8]{Pfander.2016}). Außerdem wird Rezenz von der generellen Frequenz des Elements beeinflusst: Der Rezenzeffekt ist für Elemente mit geringer Tokenfrequenz höher, da das Auftreten von Elementen mit geringer Tokenfrequenz überraschender und somit salienter ist als das Auftreten von Elementen mit hoher Tokenfrequenz (\cite[6--8]{Pfander.2016}). An dieser Stelle zeigt sich, dass auch Salienz mit Rezenz verwoben ist.  

Zusätzlich zur Interaktion von Frequenz mit anderen Faktoren ist zu beachten, dass der Einfluss der Frequenz auf Prozessierung  mit anderen Eigenschaften korreliert, die mit einem Wort assoziiert sind. Dies sind bspw. das Erwerbsalter von Wörtern sowie deren Vertrautheit\footnote{Vertrautheit wird ermittelt, indem Proband\_innen Wörter nach deren Vertrautheit mit dem Wort bewerten. Es ist somit ein intersubjektives Maß (\cites[261]{Gernsbacher.1984}[298]{McDonald.2001}).}: Früh erlernte und vertraute Wörter sind in der Regel frequenter als spät erlernte und wenig vertraute Wörter (\cites{Gernsbacher.1984}[298--299]{McDonald.2001}).\footnote{\textcite{Morrison.1995} und \textcite{Morrison.2000} untersuchen, inwiefern das Erwerbsalter unabhängig von der Frequenz Einfluss auf die Reaktionszeiten in \textit{word naming} und \textit{lexcial decision tasks} nimmt. Sie kontrollieren u.~a. auf  Frequenz und messen dennoch einen Effekt für das Erwerbsalter (\cites[120--121]{Morrison.1995}[176]{Morrison.2000}). Umgekehrt ist bei kontrolliertem Erwerbsalter kein Frequenzeffekt zu beobachten (\cite[120--121]{Morrison.1995}). \textcite[4--10]{Zevin.2002} weisen darauf hin, dass letzteres Ergebnis in Folgestudien nicht repliziert wurde: Auch wenn auf Erwerbsalter kontrolliert wurde, waren Frequenzeffekte zu messen. \textcite[298]{McDonald.2001} stellen die Notwendigkeit, Frequenz und Erwerbsalter zu trennen, in Frage und weisen auf das Konzept der kumulativen Frequenz von \textcite{Lewis.2001} hin, das Erwerbsalter und Frequenz gleichermaßen berücksichtigt. Kumulative Frequenz misst, wie oft ein Wort insgesamt gelesen oder gehört wurde: Ein häufiges Wort lesen und hören Sprecher\_innen öfter als seltene Wörter; genauso wurden Wörter mit frühem Erwerbsalter öfter gehört oder gelesen als Wörter mit spätem Erwerbsalter (\cite[191]{Lewis.2001}).}      
Neben diesen Worteigenschaften korrelieren einige Kontexteigenschaften mit Frequenz, nämlich die Größe der syntaktischen und morphologischen Familie (\textit{syntactic} und \textit{morphological family size}) sowie die Kontextdiversität bzw. Dispersion\footnote{Die \textit{syntactic family size} ist die Menge an verschiedenen Wörtern, die auf ein bestimmtes Wort folgen (\cite[176]{Baayen.2012}). Um die \textit{morphological family size} eines Worts zu bestimmen, wird die Anzahl an verschiedenen Wörtern ermittelt, in denen das Wort als Konstituente genutzt wird, z.~B. \textit{Haus} in \textit{Haustür}, \textit{Mietshaus}, \textit{Hausbau} (\cite[177]{Baayen.2012}). Die Kontextdiversität bzw. Dispersion gibt an, ob Wörter durchweg in verschiedenen Korpora genutzt werden (\cite[175]{Baayen.2012}). Durch den Blick auf Kontexte kann somit auch die Registerspezifität (bspw. unabhängig von Registern oder auf formelle Register beschränkt) von Wörtern berücksichtigt werden. Für einen Überblick zu verschiedenen Operationalisierungen von Kontextdiversität siehe \textcite[58--60]{Divjak.2015}.} (\cite[189--191]{Baayen.2012}). Die Häufigkeit eines Worts ist zwar der beste einzelne Prädiktor für das Verhalten in \textit{lexical decision tasks} (\cite[178--179]{Baayen.2012}), anhand einer Principal-Components-Analyse kann \textcite[181--191]{Baayen.2012} jedoch zeigen, dass die pure Wortwiederholung nur einen kleinen Anteil der beobachteten Varianz in den Daten erklären kann. Die meiste Va\-rianz in den Daten wurde von einer Komponente erklärt, die vornehmlich Maße für Kontext\-eigenschaften enthält (wie bspw. Größe der jeweiligen syntaktischen oder morphologischen Familie sowie Dispersion) (\cite[191]{Baayen.2012}). 



Auch \textcite[308]{McDonald.2001} diskutieren das Verhältnis von Wortfrequenz und Kontext, wobei sie Kontext als kontextuelle Distinktivität konzeptualisieren. Sie stellen fest, dass Wortfrequenz und Kontext negativ korrelieren: Je frequenter ein Wort ist, desto weniger distinkt sind die Kontexte, in denen es genutzt wird. Die Korrelation ist aber nicht perfekt: Es können auch frequente Wörter nur in spezifischen Kontexten genutzt werden, bspw. Zahlwörter. Diese werden meist zusammen mit anderen Zahlwörtern oder Maßeinheiten genutzt (\cite[301]{McDonald.2001}). In einer \textit{lexical decision task} können \textcite[310--312]{McDonald.2001} zeigen, dass die kontextuelle Distinktivität Einfluss auf das Antwortverhalten nimmt: Je höher diese ist (in je weniger Kontexten ein Wort genutzt wird), desto höher sind die Reaktionszeiten. Sie stellen zudem fest, dass Frequenzeffekte verschwinden, wenn auf Kontextdistinktivität kontrolliert wird. \textcite[318--319]{McDonald.2001} sehen in der kontextuellen Distinktivität eine bessere Erklärung für behaviorale Daten als Frequenz, da für die kontextuelle Distinktivität die Umgebung eines Worts explizit einbezogen wird und dieses Maß somit einen realistischeren Zugang zum Sprachgebrauch bietet. 

Neben der Kontextdiversität und -distinktivität nimmt auch die Abfolgewahrscheinlichkeit (\textit{transitional probability}) einzelner Elemente Einfluss auf die Prozessierung: Wie \textcite{Saffran.1996} zeigen, sind acht Monate alte Kinder bereits im Stande, Abfolgewahrscheinlichkeiten von Silben zu bestimmen. Diese können sie nutzen, um Wortgrenzen festzustellen: Die Wahrscheinlichkeit für die Lautabfolge \textit{klei-ne} ist größer als die Wahrscheinlichkeit für die Lautabfolge \textit{ne-maus}, weswegen Kinder erkennen können, dass in der Äußerung \textit{kleine Maus} sowohl \textit{kleine} als auch \textit{Maus} Wörter sind, aber nicht *\textit{nemaus}. \textcite{McDonald.2003} zeigen zudem, dass  Fixationszeiten beim Lesen von Abfolgewahrscheinlichkeiten beeinflusst werden. Es ist somit davon auszugehen, dass Sprecher\_innen beim Lesen auf Abfolgewahrscheinlichkeiten zurückgreifen. Abfolgewahrscheinlichkeiten sind dabei inhärent mit Frequenz verbunden, da häufigere Abfolgekombinationen auch eine höhere Wahrscheinlichkeit haben, aufzutreten. Zudem bieten sie eine Möglichkeit, den Einfluss des Kotexts auf Prozessierung zu operationalisieren. 

Die hier diskutierten Studien verdeutlichen, dass eine Operationalisierung der Frequenz als pure Wortwiederholung problematisch sein kann, da sie den Blick auf weitere Effekte wie bspw. den Ko- und Kontext versperrt (\cite[58--60]{Divjak.2015}). Den grundlegenden Einfluss des Kontexts auf mentale Repräsentation betont auch \textcite[17]{Goldberg.2019}, die davon ausgeht, dass Tokenfrequenz und die Kontexte, in denen ein Wort vorkommen kann, dessen mentale Repräsentation beeinflussen.     

\begin{sloppypar}
Frequenzeffekte lassen sich jedoch auch isolieren: \textcite{Gardner.1987} untersuchen  in einer \textit{lexical decision task} das Antwortverhalten von Menschen aus verschiedenen sozialen Gruppen (Jurastudent\_innen, Krankenpfleger\_innen und Ingenieur\_innen). In die \textit{lexical decision task} sind jeweils Wörter aus Fachtexten der unterschiedlichen Disziplinen eingeflochten (ausführlich zum methodischen Vorgehen siehe \cite[25--26]{Gardner.1987}). \textcite[26--28]{Gardner.1987} stellen dabei fest, dass die Proband\_innen niedrigere Reaktionszeiten für Wörter aus ihrer Disziplin aufwiesen als für Wörter aus anderen Disziplinen. In diesem Zusammenhang zeigt sich wie bei der Studie zur phonotaktischen Struktur von Wörtern, dass die individuelle Erfahrung von Sprecher\_innen einen Einfluss auf die mentale Repräsentation von Sprache nimmt, denn sie beeinflusst die Frequenz, mit der Sprecher\_innen bestimmte Konstruktionen wahrnehmen und somit auch, wie stark diese mental gefestigt sind. Dies führt zu dem Schluss, dass individuelle Unterschiede zwischen den Grammatiken existieren, die Sprecher\_innen im Spracherwerb konstruieren. \textcite[xviii]{Kemmer.2000} sehen darin die Basis für soziolinguistische Variation: Da Sprecher\_innen, die viel miteinander agieren, ähnlichere Sprachgebrauchsmuster aufweisen als Sprecher\_innen, die selten interagieren, entsteht ein gruppenspezifischer Sprachgebrauch und daher auch gruppenspezifische mentale Repräsentationen. 
\end{sloppypar}

Es zeigt sich, dass Frequenz ein guter Prädiktor für menschliches Verhalten ist, jedoch aufgrund der Korrelation mit anderen Faktoren (z.~B. Kontextdiversität) nicht immer als Erklärung für das Verhalten genutzt werden kann. Dieser Aspekt muss stets berücksichtigt werden, wenn der Einfluss von Frequenz auf Variation betrachtet wird. Um den Einfluss der Frequenz sauber fassen zu können, modelliert der folgende Abschnitt Frequenz als einen grundlegenden Einflussfaktor auf statistisches Lernen: Sie nimmt Einfluss auf die Wahrscheinlichkeit, mit der Menschen einem bestimmten Stimulus begegnen.

\subsection{Frequenz und statistisches Lernen}
\label{Statistik}

Insgesamt stützen die hier beschriebenen Frequenzeffekte ein konnektionistisches Modell (\textit{connectionist model}) des Spracherwerbs. Dieses Modell geht davon aus, dass Sprache erworben wird, indem Unterschiede und Gemeinsamkeiten bspw. zwischen regelmäßigen und unregelmäßigen Verbklassen im Input durch Lernalgorithmen generalisiert werden: 

\begin{quote} 
On this [connectionist, E.S.] account, generally instantiated as a feedforward network employing a learning algorithm, differences in behavior between the two regularity classes develop through a single processor's experience with data that are heterogeneous with respect to item frequency, phonological similarity, and other factors. These networks learn inductively, and are driven to develop a set of weighted connections that associates each input-output pair. As a result, they abstract generalizations from the data. Their subsequent behavior is based on the productive application of such generalizations (\cite[183]{Hare.2001}).
\end{quote}

Das eigene Sprachverhalten ist somit das Resultat von Generalisierungen aus dem sprachlichen Input.\footnote{Siehe \textcite{Elman.1992} für eine ausführliche Diskussion zum Nutzen des konnektionistischen Ansatzes für die Modellierung kognitiver Prozesse.} Als Grundlage dient lediglich eine basale Netzwerkstruktur, die mit Beispielen gefüllt wird. Aus ihnen wird schließlich ein System abstrahiert, das im Idealfall die Muster aus dem Input generieren kann (\cite[xiii]{Kemmer.2000}). \textcite[xiii]{Kemmer.2000} betonen, dass das Modell somit wie das menschliche Gehirn funktioniert, da sowohl das Modell als auch das Gehirn keine zentrale Prozessierungseinheit haben. Im Gehirn ist jedes Neuron eine Prozessierungseinheit, die Verbindungen zwischen anderen Neuronen aktiviert oder hemmt. Informationen ergeben sich erst durch die Verbindung zwischen den Neuronen, genauso ergeben sich im Modell sprachliche Informationen erst durch Aktivierungsmuster (\cite[xiii]{Kemmer.2000}). 

 
Die Grundlage für den konnektionistischen Ansatz legen \textcite{Rumelhart.1986}, die den Erwerb der regelmäßigen und unregelmäßigen Konjugation im Englischen simulieren. Der Erwerb der Konjugationsklassen verläuft bei Kindern in einer Kurve, die wie ein U geformt ist (\textit{u-shaped curve}): Zunächst nutzen Kinder nur Präteritalformen von hochfrequenten und damit i.~d.~R. unregelmäßigen Verben (\cite[219--220]{Rumelhart.1986}). Im Anschluss an diese Phase erwerben Kinder die regelmäßige Konjugation. Sie konjugieren dabei nicht nur bekannte Wörter nach der regelmäßigen Konjugation, sondern wenden sie produktiv auf unbekannte Verben an. Zudem übergeneralisieren sie die regelmäßige Konjugation (auch auf Formen, die sie zuvor unregelmäßig gebildet haben), sodass in dieser Phase kaum unregelmäßige Verbformen zu beobachten sind. Im dritten Stadium koexistieren schließlich beide Konjugationen (\cite[219--220]{Rumelhart.1986}). Diesen Verlauf können \textcite{Rumelhart.1986} gut mit ihrem Modell simulieren. Zunächst werden zehn hochfrequente, vornehmlich unregelmäßige Verben in das Netzwerk eingespeist. Aufgrund der großen Unterschiede zwischen den unregelmäßigen Verben wird die Beziehung zwischen Infinitiv- und Präteritalform im Netzwerk für jedes Verb separat betrachtet. In der zweiten Phase werden 420~mittelfrequente, vornehmlich regelmäßige Verben eingespeist. Aufgrund der Gemeinsamkeiten zwischen den regelmäßigen Verben kann das Netzwerk nun Verbindungen zwischen den Verben ziehen. Da zwischen den meisten eingespeisten Verben Verbindungen herstellbar sind, übergeneralisiert das Modell die regelmäßige Konjugation auf unregelmäßige Verben. Schließlich eliminiert das Modell die Übergeneralisierung und zeigt für die unregelmäßigen Verben auch unregelmäßige Formen (\cite[230--231, 240--246]{Rumelhart.1986}).\footnote{Für eine ausführliche Erläuterung des Modells siehe \textcite[220--240]{Rumelhart.1986}. In dem Modell wurden auch phonologische Gemeinsamkeiten zwischen unregelmäßigen Verben berücksichtigt, siehe hierfür \textcite[245--266]{Rumelhart.1986}. Zu Kritik an dem Modell siehe \textcite{Pinker.1988} und \textcite[232--233]{Pinker.1991}. Siehe \textcite{Plunkett.1991} sowie \textcite{Daugherty.1994} für weitere Ansätze, um regelmäßige und unregelmäßige Konjugation mithilfe eines konnektionistischen Modells zu simulieren. \textcite[136--138]{Bybee.1988} diskutiert Unterschiede und Gemeinsamkeiten zwischen diesem Modell und ihrem Modell der lexikalischen Verbindungen und Stärke (siehe \sectref{typ}).} Das Modell verdeutlicht, dass Typenfrequenz und Regelmäßigkeit Hand in Hand gehen, denn erst die Typenfrequenz ermöglicht es, ein Muster zu abstrahieren (siehe \sectref{typ}). 

\textcite{Pinker.1991} gehen im Gegensatz zum konnektionistischem Ansatz davon aus, dass regelmäßige und unregelmäßige Verben unterschiedlich prozessiert werden. Diese Annahme fußt auf der Beobachtung, dass nur bei unregelmäßigen Verben die Frequenz der Vergangenheitsformen einen Einfluss auf die Prozessierung hat, nicht aber bei regelmäßigen Verben (\cite[232--233]{Pinker.1991}). \textcite[233--234]{Pinker.1991} schlagen deshalb vor, von zwei verschiedenen Mechanismen auszugehen (\textit{dual mechanism model}): Für unregelmäßige Verbformen halten sie einen konnektionistischen Ansatz für angemessen, aber nicht für regelmäßige Verben. Für diese gehen sie vom klassischen Ansatz der regelbasierten Grammatik aus: Flektierte Formen werden regelbasiert gebildet und die durch die Regel generierten Formen nicht mental gefestigt, weshalb bei regelmäßigen Verben keine Frequenzeffekte für einzelne Verbformen zu beobachten sind. 

Der (fragliche) Einfluss der Frequenz von Präteritalformen regelmäßiger Verben auf die Prozessierung wurde im Rahmen der sogenannten \textit{past tense debate} diskutiert und überprüft. Für das Deutsche lassen sich -- in Einklang mit den Vorhersagen des \textit{dual mechanism}-Ansatzes -- frequenzbedingte Unterschiede für starke Verbformen, aber nicht für schwache feststellen (\cite{Clahsen.1997, Clahsen.2001, Clahsen.2004}, die Studien werden in \sectref{freqverb} zu Variation in der Konjugation erneut aufgegriffen). Für das Englische stellen  \textcite{Alegre.1999}  Frequenzeffekte für regelmäßige Verben ab einer Frequenz von sechs pro Million Token fest und plädieren daher für eine schwache Auslegung des \textit{dual-mechanism}-Modells, während \textcite{Hare.2001} keinen Unterschied zwischen regelmäßigen und unregelmäßigen Verben messen.  

Als Evidenz für das \textit{dual mechanism model} werden zudem Ergebnisse von EEG- (Elektroenzephalografie), PET- (\textit{positron-emission tomography}) und fMRI- (\textit{functional magnetic resonance imaging}) Studien gesehen, die Unterschiede in der Verarbeitung von regelmäßigen und unregelmäßigen Formen nahelegen: Unregelmäßige Verbformen zeigen insgesamt eine größere Aktivierung als regelmäßige, zudem wurden Unterschiede in der Aktivierung der Hirnregionen festgestellt; wobei die Ergebnisse der Studien hierbei kein eindeutiges Bild ergeben (siehe  \textcite{Jaeger.1996}; \textcite{Indefrey.1997};  \textcite{Penke.1997}; \textcite{Beretta.2003}; \textcite{Krott.2013} zu unregelmäßigen und regelmäßigen Verben im Deutschen und Englischen und \textcite{Weyerts.1997}; \textcite{Bartke.2005} zu regelmäßigen und unregelmäßigen Pluralformen\footnote{Hierbei wird von -\textit{s} als regelmäßiger Flexion ausgegangen, da Kinder diese Flexion übergeneralisieren, Erwachsene den Plural von Namen und neuer unbekannter Wörter mit -\textit{s} bilden und -\textit{s} anders als andere Pluralformen keine Frequenzeffekte hervorruft (\cite[958]{Weyerts.1997}). Das Verhalten von Erwachsenen lässt sich aber auch als Wortkörperschonung für periphere Substantive sehen (\cite[150--154]{Ackermann.2017}). Auch \textcite[79]{Kopcke.2017} sehen den \textit{s}-Plural aufgrund seiner Verwendung in spezifischen Kontexten nicht als Default an. Zudem zeigen \textcite[19--21]{Kopcke.2021} in einem Experiment, dass bei der Beurteilung der Pluralität von Pseudowörtern kein Unterschied zwischen Versuchitems auf -\textit{n} und auf -\textit{s} feststellbar sind. Sie sehen -\textit{s} daher als einen Notplural an, da -\textit{s} (bis auf den Ausschluss von Substantiven auf -\textit{s}) fast keine phonetischen Anforderungen an das Substantiv stellt. Zudem stellt aufgrund der komplexen Pluralbildung im Deutschen die Opposition von regelmäßig (-\textit{s}) und unregelmäßig (alle anderen Formen) eine starke Vereinfachung dar. \textcite[33--35]{Bartke.2005} weisen darauf hin, dass sich auch für andere Pluralformen Regelmäßigkeiten beobachten lassen, wie etwa bei -\textit{e}, das den vorherrschenden Pluralmarker bei Maskulina und Neutra darstellt. Die Ergebnisse ihrer EEG-Studie zeigen Unterschiede zwischen -\textit{e} als vorherrschenden Pluralmarker für Maskulina und Neutra und -\textit{n} als typeninfrequenten Marker: Das typenfrequente Suffix -\textit{e} ruft bei Maskulina und Neutra eine weniger starke Aktivierung hervor als das typeninfrequente Suffix -\textit{n} (\cite[40--47]{Bartke.2005}). Dies entspricht den Studien zu Konjugation, in denen für unregelmäßige Verben eine stärkere Aktivierung festgestellt wurde als für regelmäßige.} sowie \textcite[47--68]{BornkesselSchlesewsky.2009} für einen Überblick zu Prozessierungsunterschieden zwischen regelmäßiger und unregelmäßiger Flexion). Zudem unterscheiden sich die Flexionsklassen in Bezug auf Priming-Effekte: Während sich für die regelmäßige Klasse Priming-Effekte nachweisen lassen (\textit{tanzen} kann \textit{getanzt} primen), ist dies bei unregelmäßigen Paradigmen nicht der Fall (\cite[47--68]{BornkesselSchlesewsky.2009}).

M.~E. lassen die hier vorgestellten Unterschiede in der Verarbeitung nicht zwingend auf das \textit{dual mechanism model} schließen. So schließt der konnektionistische Ansatz Unterschiede zwischen regelmäßiger und unregelmäßiger Flexion nicht aus (siehe die oben zitierte Definition von \cite{Hare.2001}), sondern geht davon aus, dass sich diese "`through a single processor's experience"' (\cite[183]{Hare.2001}) entwickeln. Unterschiede in der Prozessierung können also auch Ergebnis desselben Mechanismus sein. So lassen sich bspw. die ausbleibenden Priming-Effekte durch Cluster erklären: Diese hängen bei unregelmäßigen Verben aufgrund der starken phonologischen Veränderungen weniger stark zusammen, weswegen die Formen auch weniger stark geprimt werden können (siehe \sectref{typ}). Hierzu passt, dass \textcite{Smolka.2013} graduelle Unterschiede im Priming von regelmäßigen und unregelmäßigen Verben feststellen. \textcite[6--9]{Smolka.2013} unterscheiden zwischen regelmäßigen Verben mit Dentalsuffix (\textit{lachen - gelacht}), unregelmäßigen Verben mit Ablaut, der dem Infinitivstammvokal gleicht  (\textit{fahren - gefahren}),  sowie unregelmäßigen Verben mit Ablaut, der sich vom Infinitivstammvokal unterscheidet (\textit{schwimmen - geschwommen}).\footnote{\textcite[6--9]{Smolka.2013} sehen Verben mit Identität zwischen Infinitivstammvokal und Ablaut als weniger unregelmäßig an als Verben, deren Ablaut sich vom Infinitivstammvokal unterscheidet. Aus typenfrequentieller Sicht sind jedoch die Verben mit gleichem Ablaut wie Infinitivstammvokal (Ablaut\-alternanz ABA) unregelmäßiger als die Verben mit ungleichem Ablaut und Infinitivstammvokal (Ablaut\-alternanzen ABB und ABC), da mehr Verben die Ablautalternanzen ABB oder ABC aufweisen, siehe \textcite[159--161]{Nowak.2018} sowie \sectref{freqverb} zu Frequenzeffekten bei der Variation in der Konjugation.} Für die Verben stellen \textcite[11--13]{Smolka.2013} unterschiedliche Aktivierungsmuster fest: Während die regelmäßigen Verben eine Aktivierung in Frontal-, Temporal- und Parietallappen zeigten, war die Aktivierung bei den Verben mit \textit{n}-Suffix und Vokalidentität zwischen Ablaut und Infinitivstammvokal geschwächt. Bei \textit{n}-Suffix und anderem Ablaut als dem Infinitivstammvokal war keine Aktivierung zu erkennen. Dies lässt darauf schließen, dass die Vokalveränderung Priming-Effekte blockiert. 
 
Auch die ausbleibenden Frequenzeffekte bei den Präteritalformen regelmäßiger Verben lassen sich ohne Rückgriff auf das \textit{dual mechanism model} erklären. \textcite{Ellis.1998} gehen davon aus, dass das Ausbleiben auf das "`power law of practice"' zurückgeht (\cite[307]{Ellis.1998}): Je häufiger eine mentale Aufgabe erledigt werden muss, desto schneller wird diese auch erledigt. Die meisten Verben werden regelmäßig konjugiert,\footnote{Interessanterweise gehen bspw. \textcite[6]{Clahsen.1993} und \textcite[72]{Beretta.2003} davon aus, dass regelmäßige Verben im Deutschen weniger typenfrequent seien als unregelmäßige. Die dieser Annahme zugrunde liegende Zählung kritisiert \textcite[435--438]{Bybee.1995}: Darin wurde die Anzahl an starken Verben erhöht, indem nicht die Basislemmafrequenz, sondern die Lemmafrequenz ermittelt wurde und so Partikelverben auf Basis von \textit{schreiben} als unterschiedliche Types gelten.} deswegen kann die Vergangenheit von regelmäßigen Verben schnell gebildet werden, unabhängig davon, wie häufig die Vergangenheitsform eines speziellen regelmäßigen Verbs ist. \textcite[307]{Ellis.1998} setzen in diesem Zusammenhang Regelmäßigkeit mit Typenfrequenz gleich: "`Regularity is just [type, E.S.] frequency with another name"' (\cite[307]{Ellis.1998}). Die Unterschiede zwischen regelmäßigen und unregelmäßigen Verben lassen sich nach \textcite[309]{Ellis.1998} somit durchaus mit dem konnektionistischen Modell vereinen. Um den Einfluss des \textit{power law of practice} zu testen, lassen \textcite[311--316]{Ellis.1998} Proband\_innen regelmäßige und unregelmäßige Pluralformen in einer artifiziellen Sprache bilden. Am Anfang des Spracherwerbs zeigen sich Frequenzeffekte für regelmäßige und unregelmäßige Formen: Frequente Formen werden in beiden Flexionsklassen akkurater und schneller gebildet. Mit der Zeit verschwindet der Frequenzeffekt jedoch für die regelmäßigen Formen (\cite[313--315]{Ellis.1998}).

Insgesamt lassen sich die empirischen Befunde, die als Beleg für das \textit{dual mechanism model} ausgelegt wurden, also durchaus mit dem konnektionistischen Ansatz verbinden. Gegen die Annahme zweier separater Mechanismen sprechen zudem die in \sectref{korrelation} vorgestellten Ergebnisse von \textcite{Seidenberg.1992}, nach denen die Produktion regelmäßiger Verbformen durch die Existenz unregelmäßiger, ähnlich klingender Verbformen beeinflusst wird. 

Der hier vorgestellte konnektionistische Ansatz lässt sich mit bayesianischen Lernmodellen verbinden (\cite[334]{Norris.2006}). Diese statistischen Modelle basieren auf bedingten Wahrscheinlichkeiten und fragen somit danach, wie wahrscheinlich bspw. ein Ereignis ist unter der Voraussetzung, dass ein anderes Ereignis eingetreten ist; bspw. gegeben, dass ein Metalldetektor bei einer Person ausschlägt, wie wahrscheinlich ist es, dass die Person tatsächlich metallische Gegenstände bei sich trägt? Das Beispiel ist angelehnt an \textcite[330--331]{Norris.2006} und \textcite[120--123]{Carstensen.2010}. In Bezug auf Sprache (und automatisierte Spracherkennung) lässt sich bspw. fragen: Wenn ein bestimmter Input gegeben ist, welches Wort ist am wahrscheinlichsten? Jemand hört/sieht also einen bestimmten Input und möchte herausfinden, welches Wort bzw. welche mentale Repräsentation hierzu am besten passt (\cite[330]{Norris.2006}). Diese abhängige Wahrscheinlichkeit lässt sich nach Bayes' Theorem wie folgt berechnen (\cite[123]{Carstensen.2010}):

\[ P_{A|I} = \frac{P_{I|A} * P_{A}}{P_{I|A} * P_{A} + P_{I|\neg A} * P_{\neg A}} \]

$P_{A|I}$ ist die Wahrscheinlichkeit für ein bestimmtes Wort $A$ gegeben den Input~$I$. Im Zähler stehen zwei Wahrscheinlichkeiten. $P_{I|A}$ ist die umgekehrte Wahrscheinlichkeit zu $P_{A|I}$: Dieser Wert gibt an, wie wahrscheinlich es ist, dass ein Input auf das Wort~$A$ passt. $P_{A}$ ist die Wahrscheinlichkeit für Wort~$A$ unabhängig vom Input.  Der Nenner benennt die Wahrscheinlichkeit für alle weiteren Szenarios, die unter dem gegebenen Input möglich sind: Zum einen findet sich hier noch einmal die Wahrscheinlichkeit des Inputs in Abhängigkeit von Wort~$A$ multipliziert mit der Wahrscheinlichkeit für Wort~$A$. Zum anderen wird aber auch ein anderes Szenario in Betracht gezogen: Hierbei wird die Wahrscheinlichkeit für den Input betrachtet unter der Voraussetzung, dass ein anderes Wort als Wort~$A$ verwendet wurde ($= P_{I|\neg A}$). Diese wird wiederum multipliziert mit der Wahrscheinlichkeit für ein anderes Wort als Wort~$A$, unabhängig vom Input ($P_{\neg A}$) (\cite[330]{Norris.2006}).
 
Die Formel wird verständlicher, wenn wir uns das Metalldetektorbeispiel einmal näher ansehen. Nehmen wir an, dass der Metalldetektor bei 80 \% der Personen, die metallische Gegenstände mit sich tragen, ausschlägt. Außerdem schlägt der Detektor bei 5 \% der Personen fälschlicherweise aus, die keine metallischen Gegenstände mit sich tragen. Die Wahrscheinlichkeit für den Ausschlag gegeben, dass die Person Metall mit sich trägt ($= P_{A|M}$), beträgt also 80 \%. Die Wahrscheinlichkeit für einen Ausschlag gegeben, dass die Person kein Metall mit sich trägt  ($= P_{A|\neg M}$), liegt bei 5~\%. Zudem nehmen wir an, dass von 100 Personen tatsächlich nur zehn Metall mit sich tragen, wenn sie durch den Metalldetektor gehen. Bevor jemand durch den Metalldetektor geht, liegt die Wahrscheinlichkeit dafür, dass er\_sie Metall bei sich trägt, also bei 10~\% ($= P_{M}$). Die Wahrscheinlichkeit, dass eine Person kein Metall bei sich hat ($P_{\neg M}$), ist dementsprechend $1 - P_{M} = 90\ \%$. Wie wahrscheinlich ist es nun, dass eine Person Metall bei sich trägt, nachdem der Metalldetektor ausgeschlagen hat?
\[ P_{M|A} = \frac{P_{A|M}*P_{M}}{P_{A|M}*P_{M} + P_{A|\neg M}*P_{\neg M}} 
= \frac{0{,}8*0{,}1}{0{,}8*0{,}1 + 0{,}05*0{,}9} 
= 0{,}64 \]

Die Wahrscheinlichkeit dafür, dass eine Person tatsächlich Metall bei sich trägt, wenn der Metalldetektor ausschlägt, ist 64 \%. Durch die neue Evidenz (in diesem Fall über den Metalldetektor) korrigieren wir die vorherige (priore) Wahrscheinlichkeit (10 \%) also deutlich nach oben und gehen von einer neuen, posterioren Wahrscheinlichkeit aus.

Nehmen wir an, dass nur eine Person von 1.000 Personen Metall bei sich trägt. Die priore Wahrscheinlichkeit $P_{M}$ ist nun also mit 0,1 \% weitaus geringer als in dem oben diskutieren Beispiel. Wie wahrscheinlich ist es nun, dass jemand Metall mit sich trägt, gegeben, dass der Metalldetektor ausschlägt?

\[ P_{M|A} = \frac{0{,}8*0{,}001}{0{,}8*0{,}001 + 0{,}05*0{,}999} = 0{,}015 \]

Die Wahrscheinlichkeit dafür, dass eine Person tatsächlich Metall bei sich trägt, wenn der Detektor ausschlägt, beträgt nur noch 1,5 \%. Obwohl der Detektor also reliabel arbeitet (zumindest werden die Schwellenwerte 5 \% und 80 \% für fälschlicherweise positiv bzw. negativ eingestufte Ergebnisse bspw. in \cite[53--59]{Field.2012} genutzt und empfohlen), ist die Wahrscheinlichkeit dafür, dass jemand Metall bei sich trägt, wenn der Detektor ausschlägt, sehr gering. Das liegt daran, dass die priore Wahrscheinlichkeit dafür, dass jemand Metall bei sich trägt, mit 0,1 \% bereits gering war. Die posteriore Wahrscheinlichkeit (in diesem Fall die bedingte Wahrscheinlichkeit für Metall gegeben den Ausschlag) wird also direkt beeinflusst von der prioren Wahrscheinlichkeit (\cite[156--157]{Mitchel.1997}). Bayes' Theorem erlaubt es daher, die priore Wahrscheinlichkeit mit neuen Informationen abzugleichen und daraus eine posteriore Wahrscheinlichkeit zu ermitteln. Dabei berücksichtigt die posteriore Wahrscheinlichkeit für eine Hypothese die vorherige Wahrscheinlichkeit für die Hypothese zusammen mit dem Wahrscheinlichkeitsverhältnis (\textit{likelihood ratio}), dass die neue Information mit den vorherigen Hypothesen ($P_{A|M}/P_{A|\neg M}$) konsistent ist (\cite[330]{Norris.2006}).

An dieser Stelle wird auch deutlich, weshalb bayesianische Modelle als Sprach\-lern- und Sprachverarbeitungsmodelle\footnote{Für eine ausführliche Erläuterung eines bayesianischen Ansatzes zur Worterkennung siehe \textcite{Jurafsky.1996} sowie \textcite{Norris.2006}. Darin werden auch Berechnungen vorgeschlagen, die in Hinblick auf ein gegebenes Wort die Wahrscheinlichkeit für einen bestimmten Input ermitteln. \textcite{Baayen.2011} schlagen einen modifizierten Ansatz vor, der ebenfalls als bayesianisch angesehen werden kann (\cite[70]{Baayen.2011}).} nützlich sind: Wenn wir kommunizieren, müssen wir ständig den Input, den wir bekommen, mit unserem Wissen abgleichen. Dabei muss die priore Wahrscheinlichkeit bspw. für ein Wort mit beobachteten Daten abgeglichen und in Reaktion darauf die posteriore Wahrscheinlichkeit ermittelt werden. Zudem erlauben es bayesianische Modelle, Frequenz als Teil der prioren Wahrscheinlichkeit für eine bestimmte Struktur zu modellieren. Nehmen wir an, eine Person hört ein Wort und möchte herausfinden, zu welcher mentalen Repräsentation das gesprochene Wort am besten passt. Es stellt sich also die Frage danach, welches Wort am wahrscheinlichsten ist unter einem bestimmten Input ($P_{W|I}$). Um diese Wahrscheinlichkeit zu berechnen, benötigen wir die umgekehrte bedingte Wahrscheinlichkeit $P_{I|W}$ für den Input gegeben das Wort, die Wahrscheinlichkeit $P_{I|\neg W}$ für den Input gegeben andere Wörter und die Wahrscheinlichkeit für das Auftreten des Worts unabhängig vom Input ($P_{W}$) sowie die Wahrscheinlichkeit für das Auftreten eines anderen Worts unabhängig vom Input ($P_{\neg W}$), also die prioren Wahrscheinlichkeiten. 




$P_{W}$ und $P_{\neg W}$ sind abhängig von der Tokenfrequenz: Je häufiger ein Wort ist, desto wahrscheinlicher ist seine Nutzung (\cite[330]{Norris.2006}). Die priore Wahrscheinlichkeit hängt aber nicht nur von Frequenz ab, sondern auch von anderen Faktoren. So kann bspw. syntaktisches Wissen die Wahrscheinlichkeit für Wörter in einem Satz beeinflussen (\cite[331]{Norris.2006}). Zudem zeigen \textcite{McDonald.2003}, dass Abfolgewahrscheinlichkeiten Einfluss auf das Leseverhalten nehmen und somit ebenfalls als Teil der prioren Wahrscheinlichkeit angesehen werden können. Die umgekehrte bedingte Wahrscheinlichkeit $P_{I|W}$ wird bspw. dadurch beeinflusst, wie eindeutig der Input auf das gesuchte Wort passt (\cite[330]{Norris.2006}). Wenn bspw. der Anfang des Inputwortes nicht zu verstehen ist oder es noch nicht zu Ende gesprochen wurde, ergeben sich neben dem tatsächlichen Wort andere mögliche Wörter, die auf das Inputwort passen könnten. Diese stellen die Wahrscheinlichkeit für den Input gegeben andere Wörter dar ($P_{I|\neg W}$). Kann das Inputwort hingegen zweifelsfrei erkannt und andere konkurrierende Wortformen ausgeschlossen werden, ist die Wahrscheinlichkeit für das Inputwort gegeben das Wort 100 \% und dementsprechend die Wahrscheinlichkeit für das Inputwort gegeben ein anderes Wort 0~\%. Dann beeinflussen die priore Wahrscheinlichkeiten (und damit die Frequenz der Wörter) die posteriore Wahrscheinlichkeit nicht mehr, da sie sich wegkürzen bzw. mit 0 multipliziert werden (\cite[331]{Norris.2006}):
\[P_{W|I} = \frac{P_{I|W}*P_{W}}{P_{I|W}*P_{W} + P_{I|\neg W}*P_{\neg W}} = \frac{1*P_{W}}{1*P_{W} + 0*P_{\neg W}} = \frac{1*P_{W}}{1*P_{W}}= 1 \]

Das Modell blockiert infrequente Strukturen daher nicht generell, sondern Frequenz beeinflusst nur ambige Strukturen, die bspw. noch nicht komplett prozessiert wurden: Da in dem probabilistischen Ansatz die Rolle der Frequenz als priore Wahrscheinlichkeit integriert ist, nimmt  sie nicht alleine Einfluss auf die Sprachprozessierung. Nehmen wir an, dass ein\_e Sprecher\_in kein Wissen über die Frequenz des Wortes hat, so wird lediglich die Wahrscheinlichkeit dafür, dass der Input mit dem Wort konsistent ist, betrachtet und das Wort gewählt, das dem Input am besten entspricht (\cite[330]{Norris.2006}). Die Frequenz verändert als priore Wahrscheinlichkeit die posteriore Wahrscheinlichkeit dahingehend, dass bei ambigem Input frequentere Wörter wahrscheinlicher sind als infrequente Wörter (\cite[157]{Jurafsky.1996}, \cite[331]{Norris.2006}). Je weniger frequent ein Wort ist, desto mehr Input wird benötigt, damit $P_{I|W}$ groß genug wird, um das Wort zu erkennen (\cite[334]{Norris.2006}). Neben der Frequenz können weitere Faktoren wie bspw. der Kontext als Teil der prioren Wahrscheinlichkeit Einfluss auf die posteriore Wahrscheinlichkeit nehmen.

Der bayesianische Ansatz kann zur Modellierung des Einflusses der Typen- und Tokenfrequenz bspw. auf Konjugation herangezogen werden: Auch hier ist die Typen- bzw. die Tokenfrequenz die priore Wahrscheinlichkeit für das Auftreten einer Struktur. Je höher die Typen- oder Tokenfrequenz ist, desto höher die priore Wahrscheinlichkeit für eine bestimmte Konjugationsklasse oder eine bestimmte Flexionsform. In einem bayesianischen Modell kann der Einfluss der Frequenz dabei nicht nur beobachtet, sondern auch erklärt werden: Sie ist relevant, da sie Einfluss auf die priore Wahrscheinlichkeit für das Auftreten einer bestimmten Struktur nimmt (\cite[157]{Jurafsky.1996}).
 
Auch Prozessierungsprobleme lassen sich mithilfe des bayesianischen Ansatzes erklären. Beispielsweise lösen Verletzungen in der Kongruenz von Numerus, Kasus und Genus Probleme in der Prozessierung aus (\cites{Osterhout.1994}{Kaan.2003}[150--151]{Gouvea.2010}). Diese Schwierigkeiten zeigen sich in EEG-Studien im P600-Effekt, einem ereigniskorrelierten Potential (EKP), das einen positiven Ausschlag rund 600 ms nach Onset des Stimulus benennt (\cites[169--172]{Kaan.2000}[155--156]{Gouvea.2010}). Kongruenzverletzungen lösen zusätzlich einen LAN-Effekt (\textit{left anterior negativity}) aus (\cite[878]{Roehm.2005}). Dieser tritt nicht nur bei Verletzungen von Verbkongruenzen (\textit{Every morning he *mow the lawn}) auf, sondern auch bei Abweichungen von der Phrasenstruktur (\textit{The students enjoyed Bill's *of review of play}) (\cites{Hahne.1999}[150--151]{Gouvea.2010}).  Auch semantisch auffällige Sätze können Schwierigkeiten in der Prozessierung evozieren, die sich bspw. im N400-Effekt zeigen. Dieser Effekt wird bspw. durch Sätze hervorgerufen, deren Bedeutung nicht zu unserem Weltwissen passt, wie bspw. \textit{Die Pizzen sitzen auf dem Baum} (\cite[540]{Kutas.1983}). Die Prozessierungsprobleme lassen sich in einem bayesianischen Modell gut fassen: Die erwähnten Strukturen haben gemein, dass sie Abweichungen von kanonischen Verwendungen darstellen. Somit ist die priore Wahrscheinlichkeit für diese Strukturen gering, da sie so gut wie nie im sprachlichen Input vorkommen, und gleichzeitig existiert eine andere, konkurrierende Struktur mit hoher priorer Wahrscheinlichkeit.   


 Wie neue Evidenz die Prozessierung sprachlicher Strukturen beeinflusst, lässt sich anhand von Holzwegsätzen (\textit{garden path sentences}) gut zeigen. Holzwegsätze lösen einen P600-Effekt aus und führen außerdem zu einer Erhöhung der Lesezeit (\cite{Tabor.2000}). Sie sind semantisch ambig und verleiten Leser\_innen zunächst zu einer Interpretation, die sich im Verlauf des Satzes als semantisch unsinnig oder ungrammatisch herausstellt, sodass der Satz neu prozessiert werden muss. \textcite{Fine.2013} präsentieren Proband\_innen Holzwegsätze, in denen die Ambiguität durch einen reduzierten Nebensatz ausgelöst wird (siehe Beispiel \ref{holz}, das \cite[2283]{Fine.2013} entnommen wurde). \textit{Warned} in Beispiel~\ref{holz} könnte sowohl das finite Verb des Hauptsatzes (Beispiel \ref{holz1}) als auch des Relativsatzes sein (Beispiel \ref{holz2}). Dabei wird die Interpretation als Verb des Hauptsatzes präferiert, bis der\_die Leser\_in zum eigentlichen finiten Verb des Hauptsatzes (\textit{conducted}) kommt. Die ursprüngliche Interpretation der ambigen Struktur geht an dieser Stelle nicht mehr auf, sodass die Interpretation korrigiert werden muss. Dementsprechend sind an dieser Stelle hohe Lesezeiten messbar (\cite[2279--2280]{Fine.2013}).   

\begin{exe}
\ex\label{holz} \textit{The experienced soldiers warned about the dangers conducted the midnight raid.}
\begin{xlist}
\ex\label{holz1} \textit{The experienced soldiers warned about the dangers *conducted the midnight raid.}\\
$\rightarrow$ präferierte Lesart ohne Relativsatz.
\ex\label{holz2} \textit{The experienced soldiers [warned about the dangers] conducted the midnight raid.}\\
$\rightarrow$ dispräferierte Lesart mit reduziertem Relativsatz.
\ex\label{holz3} \textit{The experienced soldiers [who were warned about the dangers] conducted the midnight raid.}\\
$\rightarrow$ disambiguierter Satz mit nicht-reduziertem Relativsatz.
\end{xlist}
\end{exe}

Die Präferenz für eine Lesart ergibt sich aus der Frequenz der Konstruktionen: \textit{Warned} dient häufiger als finites Verb des Hauptsatzes als des Nebensatzes (\cite[2280]{Fine.2013}). Die priore Wahrscheinlichkeit für \textit{warned} in einem Hauptsatz ist also höher als für \textit{warned} in einem Nebensatz. Wenn Sprecher\_innen eine ambige Struktur prozessieren, gehen sie nach dem bayesianischen Ansatz zunächst von der wahrscheinlicheren Konstruktion aus. Diese Strategie geht bei Holzwegsätzen nicht auf, weswegen Prozessierungsschwierigkeiten entstehen. 

\textcite{Fine.2013} überprüfen, ob sie durch Verschiebungen in der Frequenz der Konstruktionen die Präferenz für eine Lesart ändern können. Dafür lassen \textcite[2280--2281]{Fine.2013} Proband\_innen Holzwegsätze sowie disambiguierte Sätze wie in Beispiel \ref{holz3} lesen. Dabei nimmt die anfänglich erhöhte Lesezeit für Holzwegsätze im Lauf des Experiments ab. Die Proband\_innen haben also die neue Evidenz aus dem sprachlichen Input genutzt, um die priore Wahrscheinlichkeit für \textit{warn} in einem Relativsatz zu aktualisieren. In einem weiteren Experiment zeigen \textcite[2281--2283]{Fine.2013}, dass nun umgekehrt längere Lesezeiten für Sätze entstehen, in denen \textit{warn} im Hauptsatz verwendet wird: Der Satz \textit{The experienced soldiers warned about the dangers before the midnight raid} evoziert also längere Lesezeiten ab \textit{before}, da die priore Wahrscheinlichkeit für eine Verwendung von \textit{warned} im Relativsatz nun höher ist als für eine Verwendung von \textit{warned} im Haupsatz. Basierend auf der prioren Wahrscheinlichkeit erwarten die Proband\_innen ein finites Verb vor \textit{before the midnight raid} und müssen nun korrigieren, was sich in hohen Lesezeiten widerspiegelt. Die Ergebnisse deuten also darauf hin, dass die Proband\_innen die neuen statistischen Verhältnisse im Input nutzen, um ihre Erwartungen an den weiteren Input anzupassen.

Dies zeigt auch eine Studie von \textcite{Hanulikova.2012}: Wird ein nicht-kanoni\-sches Genus (bspw. *\textit{die Tisch}) von L1-Sprecher\_innen des Deutschen produziert, führt dies bei Hörer\_innen zu einem P600-Effekt. Dieser Effekt bleibt jedoch aus, wenn dieselbe Abweichung von L2-Sprecher\_innen produziert wird. Auch hier kann bayesianisch argumentiert werden: Hören L1-Sprecher\_innen des Deutschen Input von L2-Sprecher\_innen ist die priore Wahrscheinlichkeit für Genusabweichungen höher als wenn sie Input von L1-Sprecher\_innen hören (\cite[879--880]{Hanulikova.2012}). Einen vergleichbaren Effekt messen \textcite{Hahne.1999}. In ihrer EEG-Studie variieren sie die Anzahl an Abweichungen von der kanonischen Phrasenstruktur. Bei den abweichenden Sätzen folgte in einem Passivsatz auf eine Präposition statt der zu erwartenden Nominalphrase ein Vollverb im Partizip~II (\textit{Die Gans wurde im gefüttert}). Eine der beiden Konditionen enthält mit 20 \% nur wenige Abweichungen, die andere mit 80 \% viele. \textcite[196--199]{Hahne.1999} konnten nur in der Kondition mit wenigen ungrammatischen Stimuli einen P600-Effekt messen, unabhängig von der Kondition war ein LAN-Effekt zu beobachten. Wenn also die priore Wahrscheinlichkeit für ungrammatische Sätze hoch war, riefen diese keinen P600-Effekt mehr hervor. Die Prozessierung sprachlicher Strukturen scheint somit stark von prioren Wahrscheinlichkeiten geprägt zu sein.

Die Interpretation des P600-Effekts als eine Reaktion darauf, dass eine geläufigere und somit wahrscheinlichere Konstruktion existiert als die prozessierte, teilt auch \textcite[83--84]{Goldberg.2019}: Sie weist darauf hin, dass auch Rechenfehler (2+2 = 5) und Rechtschreibfehler (\textit{The toddler ist too years old}) P600-Effekte evozieren. In beiden Fällen existiert eine präferierte Alternative; dasselbe gilt für die oben beschriebenen strukturellen Auffälligkeiten, die P600-Effekte auslösen. 

\begin{sloppypar}
P600-Effekte geben einen Hinweis auf das Wirken eines statistischen Vorkaufsrechts (\textit{statistical preemption}) in der Prozessierung (\cite[83--84]{Goldberg.2019}): Wenn bereits eine konventionelle Weise existiert, um etwas auszusagen, dann ist die Wahrscheinlichkeit höher, dass diese genutzt wird als die unkonventionelle Weise (\cite[86]{Goldberg.2019}). Auf diese Art können Kinder Übergeneralisierungen verlernen: Wenn ein Kind die Wortform \textit{Ball} nicht nur mit der Bedeutung \SchmittSingleQuot{Ball}, sondern aufgrund der Eigenschaft [+rund] auch mit der Bedeutung \SchmittSingleQuot{Knopf} verknüpft hat, kann es diese Assoziation verlernen, indem es die Wortform \textit{Knopf} in Kontexten hört, in denen statt der Bedeutung \SchmittSingleQuot{Ball} die Bedeutung \SchmittSingleQuot{Knopf} gemeint ist. Begegnet dem Kind die Wortform \textit{Knopf} in diesen Kontexten immer wieder, kann die Wortform \textit{Knopf} die Wortform \textit{Ball} statistisch ausstechen, denn \textit{Knopf} ist in diesen Kontexten häufig und \textit{Ball} selten bis inexistent. Derselbe Mechanismus ist auf Konstruktionsebene zu beobachten.
\end{sloppypar}

Das statistische Vorkaufsrecht ist ein wichtiger Aspekt des fehlerbasierten Lernens (\textit{error-driven learning}) (\cite[94]{Goldberg.2019}). Ein weiterer Aspekt des fehlerbasierten Lernens ergibt sich dadurch, dass wir versuchen, Vorhersagen darüber zu treffen, was als Nächstes gesagt werden wird, wenn wir Sprache prozessieren (\cite[91]{Goldberg.2019}). Entspricht unsere Erwartung nicht dem Inhalt (das Kind sieht einen Knopf und erwartet, dass \textit{Ball} gesagt wird, aber die Bezugsperson sagt \textit{Knopf}), gibt es ein Fehlersignal (\cite[91]{Goldberg.2019}). Aufgrund des Fehlersignals haben überraschende, unvorhergesehene und somit saliente Informationen einen großen Einfluss auf unsere Erinnerung (\cite[116]{Goldberg.2019}). Das Fehlersignal kann daher genutzt werden, um zukünftige Vorhersagen zu verbessern und zukünftige Fehlersignale gering zu halten.\footnote{L2-Sprecher\_innen können Formen schlechter vorhersagen als L1-Sprecher\_innen (\cite[115--116]{Goldberg.2019}). Zudem funktioniert das statistische Vorkaufsrecht zwischen Konstruktionen bei L2-Sprecher\_innen nicht so gut wie bei L1-Sprecher\_innen: Neue Strukturen werden von L2-Sprecher\_innen unabhängig davon, ob die Struktur im Wettbewerb zu einer anderen steht, weniger akzeptiert als bekannte Strukturen (\cite[116]{Goldberg.2019}). L2-Sprecher\_innen können daher weniger von fehlerbasiertem Lernen profitieren als L1-Sprecher\_innen.} Die Wahrscheinlichkeit für ein Wort in einem bestimmten Kontext wird immer wieder überprüft und (wenn es ein Fehlersignal gibt) aktualisiert. Zusätzlich wird das statistische Vorkaufsrecht und damit auch fehlerbasiertes Lernen durch Selbstsicherheit (\textit{confidence}) beeinflusst (\cite[88]{Goldberg.2019}). Je häufiger ein\_e Sprecher\_in ein Verb in einer bestimmten Konstruktion, aber nicht in einer anderen, hört (bspw. \textit{explain this to me} statt \textit{explain me this}), desto sicherer wird der\_die Sprecher\_in, dass für das jeweilige Verb eine Konstruktion die andere aussticht. Dies führt dazu, dass die unkonventionelle Form vermieden wird.

Die Wahrscheinlichkeit dafür, dass eine Konstruktion die andere statistisch aussticht und so das Vorkaufsrecht erhält, hängt laut \textcite[85]{Goldberg.2019} von dem Vorkommen der Konstruktion in Kontexten ab, in denen auch eine andere Konstruktion möglich wäre. Der Beispielsatz \textit{?explain me this} hat danach eine geringe Wahrscheinlichkeit, die \textit{to}-Dativ-Konstruktion auszustechen, weil die meisten Verwendungen von \textit{explain} in der \textit{to}-Dativ-Konstruktion (\textit{explain this to me}) stehen und sie somit gebräuchlicher ist als die ditransitive Konstruktion. Für andere Verben sind beide Konstruktionen gleich häufig (\textit{tell the boy a story/tell a story to the boy}), sodass die Konstruktionen sich nicht statistisch ausstechen können. Eine Konstruktion kann die andere jedoch kontextabhängig ausstechen: Wenn der Rezipient durch ein Pronomen ausgedrückt wird, sticht die ditransitive Konstruktion (\textit{tell him a story}) die \textit{to}-Dativ-Konstruktion statistisch aus (\textit{tell a story to him)}, da sie in diesem Diskurskontext  häufiger vorkommt (\cite[86]{Goldberg.2019}). Die Häufigkeit lässt sich dabei aus der Informationsstruktur ableiten: Der Rezipient (\textit{him}) ist bereits im Kontext bekannt und steht daher idealerweise vor der neuen Information (\textit{a story}) (\cite[42--43]{Goldberg.2019}).

Im Gegensatz zum reinen Blick auf Frequenz mit der Annahme, dass wenig frequente Konstruktionen weniger akzeptabel sind, erlaubt diese statistische Perspektive einen genaueren Blick auf Akzeptabilität. Wird durch die infrequente Form eine andere kontextuelle Funk\-tion ausgedrückt, kann kein Abgleich mit existierenden Konstruktionen stattfinden (\cite[75--76]{Goldberg.2019}). Deshalb ist die transitive Verwendung von \textit{to sneeze} in \textit{She sneezed the tissue over the table} akzeptabel, obwohl \textit{sneeze} i.~d.~R. nicht transitiv genutzt wird. Die intransitive Konstruktion (\textit{She sneezed}) hat eine andere Bedeutung, weswegen sie nicht mit der anderen Konstruktion konkurriert (\cite[76]{Goldberg.2019}). Evidenz für dieses Prinzip liefern \textcite{Perek.2017}: In einem Experiment wurden Proband\_innen zwei Szenen gezeigt und mithilfe von zwei verschiedenen Konstruktionen beschrieben. Die Konstruktionen waren jeweils mit einer der Szenen assoziiert (Szene~A: ein Hase schlägt eine Katze, die nur leicht weghüpft; Szene~B: ein Hase schlägt eine Katze, die aus dem Bild springt). \textcite[283--286]{Perek.2017} ließen Proband\_innen sechs Verben lernen: drei Verben wurden nur in Konstruktion~A und in der mit ihr assoziierten Szene genutzt, zwei nur in Konstruktion~B in der mit ihr assoziierten Szene. Das letzte Verb wurde immer in derselben Konstruktion genutzt, aber in beiden Szenen präsentiert. Anschließend sollten die Proband\_innen neue Beschreibungen der Szenen bewerten und selbst produzieren. Dabei zeigte sich, dass die Proband\_innen eine mentale Verbindung zwischen den Szenen und den Konstruktionen geschaffen hatten. Unabhängig vom Verb wurde also Konstruktion A nur in der mit ihr assoziierten Szene genutzt, dasselbe galt für Konstruktion B (\cite[286--312]{Perek.2017}). Obwohl die Verben also zuvor nur mit einer Konstruktion präsentiert wurden, scheuten die Proband\_innen sich nicht davor, die Verben für die andere Szene in der mit der Szene assoziierten Konstruktion zu nutzen. Nur bei dem Verb, das unabhängig von der Szene immer in derselben Konstruktion verwendet wurde, beharrten die Proband\_innen auf dieser Konstruktion unabhängig von der Szene.  Das Verb wurde also von den Proband\_innen nur in der Konstruktion genutzt, in der es ihnen zuvor präsentiert wurde. Dies lässt sich mit dem statistischen Vorkaufsrecht erklären: Im Fall der Verben, die nur auf eine Szene beschränkt waren, greift das statistische Vorkaufsrecht nicht, da die Proband\_innen nur Evidenz für die Verwendung der Verben in einer mit der Szene assoziierten Konstruktion hatten.  Bei dem Verb, das unabhängig von der Szene in einer bestimmten Konstruktion genutzt wurde, greift das Vorkaufsrecht hingegen: Unabhängig von der Szene wird im Input eine Konstruktion bevorzugt, sodass diese die andere aussticht (\cite[286--312]{Perek.2017}).\footnote{Für weitere empirische Studien zum statistischen Vorkaufsrecht siehe \textcite[77--84]{Goldberg.2019}.}  

Insgesamt verdeutlicht die Diskussion, dass Frequenz einen grundlegenden Einfluss auf den Sprachgebrauch, die Prozessierung und somit auf die mentale Repräsentation von Sprache hat. Frequenz gilt dabei als einer der besten Prädiktoren für menschliches Verhalten (\cite[55]{Divjak.2015}). Allerdings korreliert Frequenz mit anderen Faktoren, sodass sie zwar ein guter Prädiktor ist, jedoch keine gute Erklärung für die Distribution der Daten liefern kann, wie die Studie von \textcite{Baayen.2012} verdeutlicht. Frequenzeffekte sind deshalb nicht als pure Wortwiederholung und somit als isoliert zu betrachten, stattdessen sollten zusätzlich bspw. Verwendungskontexte berücksichtigt werden. So sind Fachbegriffe wie \textit{Typenfrequenz} und \textit{Tokenfrequenz} zwar in der Regel seltene Wörter, fallen sie aber in einem linguistischen Kontext, ist eine schnellere Verarbeitung zu erwarten als würden sie in einem alltäglichen Gespräch genutzt werden. Zudem ist stets zwischen Typen- und Tokenfrequenz zu unterscheiden: Hohe Typenfrequenz hängt direkt mit der Produktivität einer Kategorie zusammen. Mitglieder typenfrequenter Kategorien haben i.~d.~R. eine höhere Variabilität als Mitglieder typeninfrequenter Kategorien, weshalb typenfrequente Kategorien eine größere Abdeckung haben als typeninfrequente Kategorien. Potentielle Neuzugänge können daher eine größere Ähnlichkeit zu bereits bestehenden Exemplaren aufweisen. Dies lässt sich bspw. bei Flexionsklassen beobachten: Aufgrund der vielen Mitglieder und der Variabilität der Mitglieder lassen typenfrequente Flexionsklassen eine Generalisierung zu, die Sprecher\_innen dazu führt, ein regelmäßiges Verhalten zu erkennen. Dies ist bei typeninfrequenten Klassen nur bedingt der Fall, sodass diese als unregelmäßig wahrgenommen werden.

Die typeninfrequente Klasse (bspw. unregelmäßige Verben) enthält vornehmlich tokenfrequente Mitglieder. Die Unregelmäßigkeit typeninfrequenter Klassen ergibt sich dabei aus der Tokenfrequenz der wenigen Mitglieder: Tokenfrequente Formen sind stark \textit{entrenched} und daher leicht zu aktivieren (\cite[380]{Bybee.1997}, \cite[13]{Schneider.2014}). Deswegen stellt Unregelmäßigkeit für frequente Verben keinen Nachteil, sondern einen Prozessierungsvorteil dar, denn sie führt zu kurzen und gut differenzierten Formen (\cite[174]{Nowak.2013}). Zudem ergibt sich aus hoher Tokenfrequenz ein Autonomie-Effekt, sodass die Formen hochfrequenter Verben weniger stark verbunden sind als die Formen niedrigfrequenter Verben (\cites[117--124]{Bybee.1985}[715]{Bybee.2006b}). Der Autonomie-Effekt zeigt sich auch darin, dass eine hohe Tokenfrequenz zu einem Flexionsklassenwechsel führen kann (\cite[17--18]{Nubling.2000}, siehe \sectref{freqverb}). Tokenfrequenz hat zudem einen konservierenden Effekt: Tokenfrequente Mitglieder einer typeninfrequenten Flexionsklasse halten sich in dieser Klasse, während die tokeninfrequenten zur typenfrequenten Klasse abwandern (\cite[280]{Bybee.1997}, siehe \sectref{freqverb}). Neben Autonomie und Konservierung kann hohe Tokenfrequenz zu Reduktion und Fusion führen: Hochfrequente Elemente, die oft zusammen genutzt werden, werden als eine Einheit wahrgenommen und verschmolzen.  

Die diskutierten Frequenzeffekte lassen auf ein konnektionistisches Sprachmodell schließen: So nimmt nicht nur die reine Worthäufigkeit Einfluss auf Reaktionszeiten, sondern auch die Existenz orthographischer Nachbarn. Zudem zeigt sich, dass Sprecher\_innen sensitiv für Abfolgewahrscheinlichkeiten sind. In einem probabilistischen Ansatz wie dem bayesianischen kann Frequenz als Faktor modelliert werden, der unter anderen Faktoren Einfluss auf die priore Wahrscheinlichkeit einer bestimmten Struktur nimmt, die anhand neuer Evidenz angepasst werden kann. Die Modellierung als priore Wahrscheinlichkeit liefert eine Erklärung für den Einfluss der Frequenz: Frequenz kann bei ambigen Strukturen als priore Wahrscheinlichkeit Einfluss auf die Prozessierung nehmen. Ihr Einfluss kann aber auch ausgehebelt werden. Zudem lässt sich das Modell nutzen, um einen statistischen Wettbewerb zwischen ähnlichen Konstruktionen zu modellieren: Gibt es einen frequenteren Weg, um einen Inhalt auszudrücken, sticht dieser den weniger frequenten Weg aus. Eine wenig frequente Konstruktion kann aber dennoch genutzt werden, wenn sie einen anderen Verwendungskontext hat als eine frequentere Konstruktion, sodass sie nicht von dieser ausgestochen werden kann.

Im weiteren Verlauf der Arbeit wird Frequenz als ein Faktor verstanden, der Einfluss auf die priore Wahrscheinlichkeit und damit auf das statistische Vorkaufsrecht von Konstruktionen nimmt. Auf diese Weise ist Frequenz kein leicht messbarer Prädiktor, sondern ein Faktor, dessen Einfluss auf Prozessierung erklärbar ist. Im weiteren Verlauf der Arbeit wird das Spiel zwischen Typen- und Tokenfrequenz und das sich daraus ergebende statistische Vorkaufsrecht sowie \textit{entrenchment} durch Tokenfrequenz relevant sein. Im empirischen Teil wird der konservierende Einfluss der Tokenfrequenz psycholinguistisch überprüft. 

Im folgenden Abschnitt wird Prototypizität als Faktor vorgestellt, der Einfluss auf Variation nimmt. Hierfür wird zunächst diskutiert, wie Prototypizität die Bildung von Kategorien und die Organisation mentaler Repräsentationen beeinflusst. 

\section{Prototypizität}\label{steuerungprot}

Neben der Frequenz ist die Prototypizität kognitiver Kategorien ein grundlegendes Konzept im gebrauchsbasierten Ansatz. Prototypisch organisierte Kategorien basieren auf einzelnen, ähnlichen Exemplaren, die im sprachlichen Input wahrgenommen und zu einer Kategorie abstrahiert werden (\cite[56]{Ellis.2014}). Wie der Abschnitt zeigen wird, nimmt Prototypizität Einfluss auf Variation und Stabilität in einem Sprachsystem. 

Das Konzept der Prototypizität stammt ursprünglich aus der Kognitionspsychologie und wurde dort vornehmlich von Rosch entwickelt (siehe \cite{Rosch.1973, Rosch.1975, Rosch.1975b, Rosch.1975c, Rosch.1976, Rosch.1976b, Rosch.2004}). Im Fokus standen zunächst vornehmlich lexikalische Kategorien.\footnote{Um die Vielfalt der untersuchten Kategorien zu verdeutlichen, folgt hier eine beispielhafte Liste: Farben und Formen (\cite{Rosch.1973}); Früchte, Gemüse, Möbel, Fahrzeuge, Waffen, Werkzeuge, Vögel, Sportarten, Spielzeug und Kleidung (\cite{Rosch.1975b, Rosch.1975c, Rosch.1976b}); Tassen, Schüsseln und Vasen (\cite{Labov.2004}).} Dieser Fokus zeigt sich auch in der Linguistik: Mit der Entwicklung der Prototypensemantik stehen auch hier lexikalische Kategorien und ihre Semantik im Vordergrund. Prototypizität lässt sich aber als generelles Ordnungsprinzip von kognitiven Kategorien ausmachen (\cite[57--58]{Lakoff.1987}) und greift daher auch für grammatische Kategorien (\cites{Bybee.1983}[173--238]{Taylor.1995}[78--80]{Bybee.2010}).

Der Abschnitt verfolgt zwei Ziele: Einerseits soll Prototypizität definiert und andererseits ihr genereller Einfluss auf Variation und Stabilität erläutert werden. \sectref{standard} stellt Prototypizität zunächst als Ordnungsprinzip sprachlicher Kategorien vor, dabei werden auch die Grundannahmen der Prototypensemantik diskutiert. In diesem Abschnitt steht zudem die Frage im Vordergrund, wie weit Prototypizität den Aufbau sprachlicher Kategorien erklären kann. Im anschließenden \sectref{proteffekt} werden Prototypeneffekte bei lexikalischen und grammatischen Kategorien diskutiert, hieraus wird der Einfluss der Prototypizität auf Variation und Stabilität in einem Sprachsystem modelliert. Abschließend werden in \sectref{exemplar} prototyp- und exemplarbasierte Kategorisierungsansätze verglichen und prototypisch organisierte Kategorien als Resultat einer exemplarbasierten Kategorisierung modelliert. Diese Modellierung ist die Grundlage für die weitere Betrachtung prototypisch organisierter Kategorien in dieser Arbeit: Kategorien sind in dieser Betrachtung graduell aufgebaut mit prototypischen und peripheren Vertretern. Dabei werden prototypische Verteter anders verarbeitet als periphere. Die Gradualität lässt sich nutzen, um die Reihenfolge von Variationsfällen zu prognostizieren. Die Unterschiede in der Verarbeitung dienen als Erklärungsansatz für Variation. Während Variation für prototpyische Vertreter unwahrscheinlich ist, ist sie für periphere wahrscheinlich.

\subsection{Prototypizität sprachlicher Kategorien}
\label{standard}

Die Prototypizität sprachlicher Kategorien ist eine grundlegende Annahme der Prototypensemantik. Die Standardversion der Prototypensemantik sieht Prototypen als "`typische, gute und hervorstechende Vertreter einer Kategorie"' (\cite[33]{Schmid.2000}). So ist bspw. ein Gefäß aus Porzellan, das so hoch wie breit ist, einen Henkel hat und zum Kaffee- oder Teetrinken verwendet wird, ein prototypischer Vertreter der Kategorie \textsc{Tasse}. Die Bezeichnung \textit{Prototyp} geht dabei auf das Exemplar zurück, das vor einer Serienproduktion entwickelt wird. Der Prototyp ist hier Vorbild für die folgenden hergestellten Exemplare (\cite[31]{Kleiber.1993}). Genauso bildet der Prototyp einer Kategorie in der Prototypensemantik das Zentrum derselben, während die anderen Vertreter der Kategorie sich um den Prototyp herum gruppieren.

Die zentrale Idee der Prototypensemantik ist nicht allein die Annahme eines Prototyps, sondern die Idee, dass die Zugehörigkeit zu einer Kategorie graduell ist (\cite[15]{MangasserWahl.2000b}). Langackers Definition eines Prototyps trägt dem Prinzip der Gradualität explizit Rechnung: "`A prototype is a typical instance of a category, and other elements are assimilated to the category on the basis of their perceived resemblance to the prototype; there are degrees of membership based on degrees of similarity"' (\cite[371]{Langacker.1987}).\footnote{\textcite[371]{Langacker.1987} nutzt diese Definition, um Prototypen von der Kategorisierung durch Schemata abzugrenzen. \textcite{Langacker.1987} definiert ein Schema als eine Charakterisierung, die auf alle Mitglieder der von ihr definierten Kategorie zutrifft. Hier ist somit keine Gradualität vorgesehen (\cite[530]{Taylor.1990}). Schemata sind dabei hierarchisch organisiert. Diese Organisation ergibt sich aus Weiterentwicklungen des Prototyps (\cite[66]{Taylor.1995}): Wenn wir eine Eiche, eine Buche und einen Ahorn sehen, können wir daraus das Schema \textit{Baum$_1$} abstrahieren. Dies dient nun als Prototyp für die Kategorie \textsc{Baum}. Eine Tanne lässt sich aufgrund der graduellen Zugehörigkeit als Baum ansehen, ist aber nicht kompatibel mit dem Schema \textit{Baum$_1$}, da Tannen keine Blätter haben. Da aber Tannen aufgrund der Ähnlichkeit zum Prototyp mit Bäumen assoziiert sind, extrahieren wir ein zweites Schema \textit{Baum$_2$}, das Gemeinsamkeiten von \textit{Baum$_1$} und Tannen enthält: Ein Baum hat einen Stamm und Äste. Dies kann zu einem noch abstrakteren Schema \textit{Baum$_3$} führen, in dem bspw. auch Syntaxbäume enthalten sind, da hier nur noch das Konzept des Verästelns relevant ist. Auf die gleiche Weise können auch konkretere Subschemata entstehen wie bspw. das Schema \textit{Fruchtbaum} (\cite[66]{Taylor.1995}). \textcite[66]{Taylor.1995} sieht Kategorisierung durch Schemata und Kategorisierung durch Prototypen als Aspekte des gleichen Phänomens an: "`In the former case [schemas, E.S.], an entity happens to be fully compatible with an abstract representation, in the latter case [prototypes, E.S.], it is only partially compatible."' Im Folgenden wird allein auf das Konzept der Prototypen näher eingegangen. Schemata spielen im Verlauf der Arbeit nur als abstrakte Form-Funktion-Paare (siehe \sectref{steuerungschema}) eine Rolle.} Es können also randständige Vertreter einer Kategorie existieren, wie bspw. Tassen ohne Henkel.

Wie lexikalische Kategorien lassen sich auch grammatische Kategorien als prototypisch organisiert auffassen: \textcite[59--67]{Lakoff.1987} sieht phonologische, morphologische und syntaktische Kategorien als prototypisch organisiert an.\footnote{\textcite[59--61]{Lakoff.1987} weist darauf hin, dass die Idee der Markiertheit von Formen als Prototypeneffekt gedacht werden kann. Dabei dient ein Vertreter oder eine Subkategorie als Referenzpunkt (z.~B. Singular). Aufgrund des Status als Referenzpunkt gilt der Vertreter bzw. die Subkategorie als unmarkierter Default.} \textcite[175--182]{Taylor.1995} diskutiert Wörter und Affixe als prototypisch organisierte Kategorien. Zudem wendet er die Prototypentheorie auf Phoneme (\cite[223--229]{Taylor.1995}) sowie auf morphologische und syntaktische Konstruktionen an  (\cites[192--198]{Taylor.1998}[570--575]{Taylor.2015}; genauer zu Konstruktionen siehe \sectref{konstruktion}).

Die Prototypizität grammatischer Kategorien lässt sich anhand von Wortarten verdeutlichen (\cites[181--184]{Taylor.1998}[8--9]{Hundt.2000}). Prototypische Eigenschaften der Wortart Adjektiv sind die Flexion, die Steigerbarkeit und die Möglichkeit, es attributiv, prädikativ und adverbial zu verwenden. Adjektive, die diesen Eigenschaften voll entsprechen, sind bspw. \textit{schön}, \textit{schnell} und \textit{kreativ}. Adjektive wie \textit{schwanger} verfügen hingegen nicht über alle Eigenschaften, da sie nicht gesteigert werden können. Adverbien wie \textit{heute} lassen sich nach dieser Auffassung als Adjektive auffassen, die mit anderen Adjektiven nur die Eigenschaft teilen, dass sie adverbial verwendbar sind.\footnote{Für eine Analyse von Quantoren und Adjektiven als prototypische Kategorien siehe \textcite{Hundt.2000}.} Vergleichbar argumentiert \textcite[569--570]{Taylor.2015} für eine prototypische Organisation von Substantiven: So kann bspw. \textit{Musik} als ein unprototypisches Substantiv gelten, da \textit{Musik} nicht pluralisierbar ist. Wie bei lexikalischen Kategorien lässt sich somit auch für grammatische Kategorien eine graduelle Zugehörigkeit der Vertreter postulieren.

Prototypisch organisierte Kategorien zeigen sich auch in der Flexionsmorphologie. Hierbei lässt sich einerseits nach der prototypischen phonologischen Form von Wörtern fragen, die ein bestimmtes Flexionsverhalten aufweisen (\cite[111--135]{Bybee.1985}; siehe hierzu auch \sectref{konstruktion} zu Form-Schemata) und andererseits nach den Flexionseigenschaften, die verschiedene Flexionsklassen voneinander trennen: Je mehr Eigenschaften der einen Flexionsklasse aufgegeben werden, desto mehr Eigenschaften der anderen Flexionsklasse kommen hinzu. Dies ist anhand der schwachen und gemischt-deklinierten Maskulina leicht zu verdeutlichen: -\textit{n} im Plural ist ein Merkmal der schwachen Deklination. Somit können Substantive mit gemischter Flexion als periphere Vertreter der schwachen Flexion modelliert werden, da sie nur im Plural schwache Flexionsmerkmale aufweisen (siehe hierzu ausführlich \sectref{protmask}). Dieselbe Logik greift für Konjugationsklassen: Hier kann bspw. \textit{mahlen} als Verb gesehen werden, dessen Flexionsverhalten nur peripher der starken Konjugation zuzurechnen ist, da \textit{mahlen} mit dem Ablaut im Perfekt (\textit{gemahlen}) nur ein starkes Konjugationsmerkmal aufweist, aber ansonsten schwache Flexionsmerkmale wie bspw. ein Präteritum mit Dentalsuffix (\textit{mahlte}) (\cite[80]{Bittner.1996}, \cite[153--156]{Nowak.2013}; siehe hierzu ausführlich \sectref{protverb}). Auch in Bezug auf Flexionsklassen lässt sich somit eine graduelle Zugehörigkeit beobachten.

Die Idee der graduellen Zugehörigkeit zu einer Kategorie steht im Kontrast zum aristotelischen Kategorienbegriff, bei dem notwendige und hinreichende Bedingungen die Zugehörigkeit zu einer Kategorie klar definieren. Nach dieser Logik kann eine Entität entweder Vertreter einer Kategorie sein oder nicht: Ein Adjektiv muss bspw. steigerbar sein. Eine ungerade Zahl muss eine Zahl und ungerade sein. Die einzelnen notwendigen Bedingungen sind dabei hinreichend dafür, die Kategorie zu definieren (\cite[11--13]{Kleiber.1993}; ausführlich zum aristotelischen Kategorienbegriff siehe \cite[11--28]{Kleiber.1993} sowie \cite[21--29]{Taylor.1995}). Prototypisch aufgebaute Kategorien sind dagegen flexibel und bieten daher einen Vorteil in der Kognition: Man kann ein Wort als Adjektiv bezeichnen, das attributiv genutzt werden kann, obwohl es nicht steigerbar ist. Die Kategorie selbst muss deshalb nicht infrage gestellt werden (\cite[53--54]{Taylor.1995}). Prototypisch organisierte Kategorien können somit einerseits dem Wunsch nach klaren Kriterien nachkommen, da der Prototyp viele Eigenschaften der betreffenden Kategorie auf sich vereint, andererseits erlauben sie Flexibilität, da auch Entitäten zur Kategorie zählen können, die nur einige Eigenschaften mit dem Prototyp teilen (\cite[54]{Taylor.1995}).\largerpage

Aus der Gradualität prototypisch organisierter Kategorien ergibt sich zum einen die Unschärfe prototypisch organisierter Kategorien, da sie nicht erfassen, ob eine Entität ein Vertreter der Kategorie ist, sondern inwiefern die Entität ein Vertreter der Kategorie ist (\cite[106]{Kleiber.1993}, \cite[33]{Schmid.2000}). Zum anderen ist Typizität eine Konsequenz aus der Gradualität. Die Typizität gibt an, wie typisch ein Vertreter für eine Kategorie ist (\cite[33]{Schmid.2000}). Der Prototyp ist dabei immer der Vertreter mit der höchsten Typizität. Typizität und Unschärfe sind zwar ähnliche Konzepte, da beide aus der Gradualität der prototypisch organisierten Kategorien erwachsen, dennoch meinen die Ausdrücke nicht dasselbe: Ein Vertreter einer Kategorie kann untypisch sein, dieser Kategorie aber dennoch klar zugeordnet werden. So sind Pinguine untypische Vögel, deren Status als Vogel dadurch jedoch nicht infrage gestellt wird (\cite[563]{Taylor.2015}). Niedrige Typizität und Unschärfe einer Kategorie können allerdings korrelieren, da bei untypischen Vertretern einer Kategorie unklar sein kann, ob man sie noch der Kategorie zurechnen sollte. Aus der Unschärfe prototypisch organisierter Kategorien ergibt sich auch, dass Vertreter zwei Kategorien angehören können: So kann ein rundes Gefäß aus Porzellan ohne Henkel, das etwas größer ist als eine Tasse, ein Becher oder eine (kleine) Vase sein.\footnote{Der Kontext kann hier desambiguieren (siehe die Erläuterungen unten zum Experiment von \cite{Labov.2004}). Fehlt der Kontext jedoch, kann auf das Objekt sowohl mit \textit{Becher} als auch mit \textit{Vase} referiert werden.}

Die Gradualität von Kategorien wird durch Familienähnlichkeit gestützt. Das Konzept der Familienähnlichkeit nach \textcite{Wittgenstein.2004} geht davon aus, dass zwei Vertreter einer Kategorie nicht dieselben Eigenschaften teilen müssen, solange sie Eigenschaften mit einem anderen Vertreter der Kategorie teilen (\cite[38--40]{Taylor.1995}). Palmen und Syntaxbäume teilen keine Eigenschaften miteinander, aber beide teilen Eigenschaften mit einer Eiche: Die Palme hat einen Stamm und Syntaxbäume verästeln sich wie eine Eiche. Somit sind beide über Familienähnlichkeit verbunden. Die Familienähnlichkeit der Kategorien ergibt sich \textcite[90--91]{Bybee.2010} zufolge aus der Kategorienerweiterung mittels Analogie: Aus lokalen Analogien werden Analogieketten.\footnote{Wenn einzelne Exemplare einer Konstruktion, die durch Analogieketten verbunden sind, eine breite Semantik haben, führt dies zu einer hohen Schematizität  der Konstruktion (siehe \sectref{konstruktion} zu Schemata in der Konstruktionsgrammatik), sodass neue Mitglieder leicht aufgenommen werden können.} Ähnlich funktioniert das Konzept der Abdeckung von Goldberg, das in \sectref{typ} diskutiert wurde. Die Analogieketten basieren auf Prototypen, die als kognitiver Bezugspunkt dienen (\cite[38--39]{Kleiber.1993}, \cite[89]{Goldberg.2006}, \cite[242]{Ellis.2016}). Prototypische Vertreter sind aufgrund ihrer Tokenfrequenz und Kontextdiversität mental stark gefestigt.\footnote{Neben dem hohen Grad an \textit{entrenchment} trägt auch die Salienz prototypischer Vertreter dazu bei, dass sie leicht aktivierbar sind und somit als Analogievorlagen genutzt werden können (\cite[242]{Ellis.2016}).}  Sie eignen sich daher als Analogievorlagen, die ein abstraktes Muster ermöglichen (\cite[90--91]{Bybee.2010}).\largerpage

Die grundsätzliche Ablehnung kategorialer Grenzen in der Standardversion der Prototypensemantik kann nicht vollständig aufrecht erhalten werden. Anhand der Familienähnlichkeit kann man bspw. die Behauptung aufstellen, dass Mäuse eine Art von Vögeln sind: Mäuse teilen sich Eigenschaften mit Fledermäusen, denn beide sind klein und haben Fell. Fledermäuse teilen sich wiederum eine Eigenschaft mit Vögeln, da sie fliegen können. Mäuse und Fledermäuse werden aber dennoch nicht unter die Kategorie \textsc{Vogel} gefasst. Somit muss es trotz Familienähnlichkeit eine Grenze geben, an der eine Kategorie endet. Dieses Problem kann leicht gelöst werden, indem man Prototypizität selbst als prototypisch organisiert betrachtet (\cite[109--110]{Kleiber.1993}, \cite[65]{Taylor.1995}): Prototypische prototypisch organisierte Kategorien gehen somit ineinander über wie bspw. Tassen und Schüsseln (\cite{Labov.2004}), bei peripheren prototypisch organisierten Kategorien ist dies nicht der Fall, wie bspw. bei Vögeln und Mäusen (\cite[56]{Lakoff.1987}).

Genauso ist die grundsätzliche Ablehnung notwendiger Bedingungen in Frage zu stellen, denn es ist eine notwendige Bedingung für die Kategorie \textsc{Katze}, Teil der Kategorie \textsc{Tier} zu sein (\cite[89--91]{Kleiber.1993}). Dies ist jedoch nicht problematisch, wenn man notwendige, aber keine hinreichenden Bedingungen ansetzt (\cite[90--91]{Kleiber.1993}): Die notwendigen Bedingungen führen also nicht zwangsläufig dazu, dass eine Entität zu einer Kategorie gehört.\footnote{Allerdings existieren Kategorien, bei denen dies der Fall ist, wie bspw. ungeraden Zahlen: Hier sind zwei notwendige Bedingungen hinreichend für die Zugehörigkeit zur Kategorie.} \textcite[128]{Jackendoff.2004} geht davon aus, dass für die Kategorisierung sowohl notwendige Bedingungen (eine Tasse muss ein Gefäß sein) als auch graduelle (die Höhe/Breite einer Tasse) sowie typische (Tassen sind aus Porzellan) eine Rolle spielen. Die graduellen Bedingungen haben dabei einen zentralen Punkt, um den sie sich gruppieren.\footnote{Aufgrund dieser Eigenschaft nennt \textcite[128]{Jackendoff.2004} die graduellen Bedingungen Zentralitätsbedingungen (\textit{centrality conditions}).} Die typischen Bedingungen einer Kategorie können im Gegensatz zu den notwendigen Bedingungen auch Ausnahmen erlauben. Sie führen dazu, dass Kategorien nach Familienähnlichkeit gestaffelt sind (\cite[128]{Jackendoff.2004}). Für einzelne Kategorien stehen jeweils unterschiedliche Bedingungen im Mittelpunkt: Bei der Kategorie \textsc{Rot} sind dies bspw. die graduellen Be\-dingungen, bei der Kategorie \textsc{Tasse} dagegen die typischen (\cite[128]{Jackendoff.2004}).\largerpage

Ein weiteres Problem der Standardversion der Prototypensemantik ist die viel diskutierte Frage, was einen Prototyp zum Prototyp macht (\cite[13]{Barenfanger.2002}). Definiert man den Prototyp in Hinblick auf die Typizität,\footnote{\label{freq}Neben diesem Ansatz werden Vertrautheit, Frequenz und das Erwerbsalter als Einflussfaktoren diskutiert (\cite[41--43; 51--54]{Kleiber.1993}, \cite[52--53]{Taylor.1995}, \cite[100]{Rosch.2004}): Hierbei wäre immer das Exemplar mit dem höchsten Grad an Vertrautheit, der höchsten Frequenz und dem geringsten Erwerbsalter der Prototyp. Offensichtlich korrelieren die Faktoren, da Vertrautheit von \textcite[42]{Kleiber.1993} definiert wird als "`das Exemplar [...], das den Sprechern am vertrautesten ist; d.~h. dem sie am häufigsten begegnen (können)"', hier spielt also auch Frequenz eine Rolle. Vor allem die Gleichsetzung des frequentesten Vertreters mit dem prototypischen Vertreter wird kritisch diskutiert, dabei wird davor gewarnt, Prototypizität mit Frequenz gleichzusetzen (siehe \cite[42]{Kleiber.1993}, \cite[52]{Taylor.1995}, \cite[50]{Schmid.2000} und \cite[567--568]{Taylor.2015}). Aufgrund dieses kritischen Umgangs der Standardversion der Prototypensemantik mit Frequenz bezeichnet \textcite[365]{FenkOczlon.1991} die Prototypensemantik als frequenzfeindlich. Generell wirft die Modellierung von Vertrautheit, Frequenz und Erwerbsalter als singuläre Einflussfaktoren auf Prototypizität Probleme auf, weswegen hier nur die Typizität als Einflussfaktor ausführlich vorgestellt wird. Definiert man Prototypen über Typizität, können die singulären Einflussfaktoren jedoch dennoch eine Rolle spielen, da sie Einfluss auf die Typizität nehmen. Dies ist insbesondere für die Frequenz der Fall, wie aus den folgenden Erläuterungen deutlich werden wird.} ist der Prototyp der Prototyp, da er die typischen Eigenschaften einer Kategorie auf sich vereint (\cite[42]{Kleiber.1993}). Diese Definition ist auf den ersten Blick wenig hilfreich, da sich nun die Frage stellt, was typische Eigenschaften sind (\cite[42]{Kleiber.1993}). Zudem kann damit zirkulär argumentiert werden: Der Prototyp ist prototypisch, weil er die meisten typischen Eigenschaften aufweist, und die typischen Eigenschaften sind typisch, weil der Prototyp sie aufweist.

Der Fokus auf Typizität kann prototypisch organisierte Kategorien dennoch präzisieren, da er zu einer Begriffsverschiebung führt (\cite[43]{Kleiber.1993}): Es wird nicht mehr das beste Exemplar gesucht, sondern die Eigenschaften, die als typisch für eine Kategorie gelten. Der Prototyp wird somit zu einer "`aus typischen Attributen zusammengesetzten Entität"' (\cite[43]{Kleiber.1993}) und ist mit dieser Definition auch nicht mehr mit einer Entität gleichzusetzen, sondern "`a schematic representation of the conceptual core of a category"' (\cite[59]{Taylor.1995}). Diese Sichtweise favorisieren sowohl \textcite[43]{Kleiber.1993} als auch \textcite[59--60]{Taylor.1995} gegenüber der Definition des Prototyps als bestes Exemplar: Selbst wenn man den Prototyp als bestes Exemplar sieht, muss die Repräsentation des Prototyps ein Stück weit abstrakt sein, sodass der Prototyp in verschiedenen Situationen erkannt werden kann (\cite[60]{Taylor.1995}).\largerpage

Als Antwort auf die Frage, welche Eigenschaften typisch sind, lässt sich der Einflussfaktor Frequenz\footnote{Wie in Fußnote \ref{freq} bereits angesprochen, stehen Vertreter\_innen der Standardversion der Prototypensemantik Frequenz skeptisch gegenüber, da befürchtet wird, dass Frequenz und Prototyp gleichgesetzt werden. Modelliert man Frequenz als Einflussfaktor auf Typizität, verschiebt sich die Argumentation jedoch dahingehend, dass typische Eigenschaften einer Kategorie frequent sind. Diese Modellierung ist bereits nah an dem examplarbasierten Ansatz des Kategorienlernens, der in \sectref{exemplar} vorgestellt wird.} anführen: Hierbei ist von einer Kombination aus Ty\-pen- und Tokenfrequenz auszugehen. So stellen \textcite[85]{Ellis.2014} fest, dass der prototypische Vertreter einer Konstruktion die höchste Frequenz (Tokenfrequenz) aufweist und die meisten Gemeinsamkeiten (Typenfrequenz) mit anderen Mitgliedern der Kategorie auf sich vereint. Der prototypische Vertreter wird daher schneller prozessiert, denn "`like Rome, all ways lead to it"' (\cite[85]{Ellis.2014}). Auch \textcite[88]{Goldberg.2006} und \textcite[79--80]{Bybee.2010} sehen den prototypischen Vertreter einer Kategorie als den häufigsten Vertreter an.\footnote{Diese Annahme ist aus Sicht einer rein prototypbasierten Kategorisierung problematisch, da Frequenz und Prototypizität eng verquickt werden (siehe hierzu \cite[42]{Kleiber.1993}, \cite[52]{Taylor.1995}, \cite[50]{Schmid.2000} und \cite[567--568]{Taylor.2015}). Sie ist aber mit exemplarbasiertem Lernen vereinbar (siehe \sectref{exemplar}).} So geht \textcite[88]{Goldberg.2006} davon aus, dass Konstruktionen sich um ein oder zwei Wörter zentrieren (bspw. um \textit{put} als Prototyp der caused-motion-Konstruktion, siehe Fußnote \ref{gold} in \sectref{steuerungfreq}), die sie als semantischen Prototyp bezeichnet.

Die frequenten Vertreter einer Kategorie bedingen, dass auch die Eigenschaften der Vertreter frequent vorkommen. Die frequent in einer Kategorie vorkommenden Eigenschaften sind dann auch die typischen Eigenschaften der Kategorie (\cite[52]{Kleiber.1993}). Prototypizität wird somit durch tokenfrequente Vertreter und durch die Tokenfrequenz der Eigenschaften der frequenten Vertreter gestützt. Daher kommt zusätzlich die Typenfrequenz ins Spiel: Für die Kategorisierung ist nicht nur eine einzige Eigenschaft der frequenten Vertreter relevant, sondern mehrere. Prototypische Vertreter werden daher doppelt durch Frequenz gestützt: Tokenfrequenz stützt die Vertreter und ihre Eigenschaften. Zusätzlich stützt Typenfrequenz prototypische Vertreter dadurch, dass sie viele Eigenschaften der Kategorie auf sich vereinen. Daneben ist auch die Typenfrequenz der Kategorie relevant: Erst wenn sich viele Vertreter bestimmte Eigenschaften teilen, kann daraus eine Kategorie mit prototypischer Struktur abstrahiert werden.\largerpage

Frequenz alleine ist jedoch zu ungenau, um das Entstehen einer Kategorie zu modellieren, denn nur weil eine Eigenschaft in einer Kategorie häufig ist, bedeutet dies noch nicht, dass diese Eigenschaft die Kategorie gut von einer anderen unterscheidet: [+belebt] kommt sowohl in der Kategorie \textsc{Vogel} als auch in der Kategorie \textsc{Fisch} häufig vor. Das Konzept der \textit{cue validity}, das in \sectref{korrelation} kurz diskutiert wurde, berücksichtigt dies, indem \textit{cue validity} die Frequenz einer Eigenschaft in einer Kategorie mit der Frequenz einer Eigenschaft in anderen Kategorien vergleicht (\cite[575]{Rosch.1975c}, \cite[52--53]{Kleiber.1993}). \textit{Cue validity} ist somit ein Maß für die Distinktivität einer Eigenschaft: [+Flügel] hat eine höhere \textit{cue validity} als [+belebt], da (fast) nur Vögel Flügel haben. Die Eigenschaft [+Kiemen] hat eine noch höhere \textit{cue validity}, da diese Eigenschaft nur Fische\footnote{Interessanterweise existiert in der Biologie zwar die Kategorie \textsc{Fisch}, diese stellt aber anders als die Kategorie \textsc{Vögel} kein Taxon dar, da Fische keinen gemeinsamen Ursprung haben (\cite[3]{Helfman.2009}).} aufweisen (\cite[52--53]{Lakoff.1987}). Eine hohe \textit{cue validity} kann dazu führen, dass eine Eigenschaft als salient wahrgenommen wird, da sie nur in einer bestimmten Kategorie erscheint.\footnote{\textit{Cue validity} kann außerdem dazu genutzt werden, die Distinktivität einer Kategorie zu evaluieren. Kategorien auf der Basisebene (z.~B. Stuhl) haben generell eine höhere \textit{cue validity} als Kategorien, die der Basisebene übergeordnet (z.~B. Möbel) oder untergeordnet (z.~B. Klappstuhl) sind (\cite[428]{Rosch.1976}). Für weitere Merkmale der Basisebene und der übergeordneten Ebene siehe \textcite[51--52]{Lakoff.1987}. Wie prototypische Vertreter einer Kategorie verfügt die Basisebene über die höchste \textit{cue validity}: Die Basiskategorie hat Vertreter, die viele gemeinsame Attribute aufweisen und gleichzeitig die wenigsten Attribute mit Vertretern anderer Kategorien gemein haben (\cite[64]{Kleiber.1993}). Die Basisebene ist somit distinktiver als die anderen Ebenen. Deshalb wird die Basisebene auch als primäre Kategorie gesehen, auf deren Basis die anderen Kategorien abgeleitet werden (\cite[13]{Lakoff.1987}). Die Distinktivität einer Kategorie hängt eng mit ihrer Lernbarkeit zusammen (\cite[153]{Ellis.2002b}). Für empirische Evidenz siehe \textcite{Taraban.1996}, die die Distinktivität von Substantiven mit bestimmten Genera manipulieren. Je distinktiver die Eigenschaften von Substantiven mit einem bestimmten Genus von den Eigenschaften der Substantive mit einem anderen Genus sind, desto leichter ist die Kategorie zu erlernen, unabhängig davon, wie ähnlich sich die Substantive eines Genus untereinander sind.}
Typenfrequenz und \textit{cue validity} lassen sich dabei kombinieren: Prototypische Vertreter einer Kategorie teilen die meisten Eigenschaften mit anderen Vertretern dieser Kategorie, haben aber umgekehrt nur wenige Eigenschaften mit Vertretern anderer Kategorien gemein. Anders ausgedrückt maximieren prototypische Vertreter ihre \textit{cue validity}, indem sie die meisten Eigenschaften mit der größten \textit{cue validity} auf sich vereinen (\cite[564]{Taylor.2015}).

Auf Basis der oben dargelegten Überlegungen zur Typizität wurde die Prototypensemantik revidiert (\cite[111--114]{Kleiber.1993}). Während die Standardversion der Prototypensemantik davon ausgeht, dass der Prototyp eine Kategorie konstituiert und strukturiert, lehnt die erweiterte Version dies ab und geht davon aus, dass es sich beim Prototyp um einen Effekt handelt (\cite[111--114]{Kleiber.1993}): Der Prototyp ist also kein Exemplar, sondern durch typische Eigenschaften ergeben sich Prototypeneffekte, wie bspw. eine schnellere Prozes\-sierung (weitere Effekte werden in \sectref{proteffekt} vorgestellt). Eine Kategorie wird in dieser Perspektive durch die Anzahl der typischen Eigenschaften und durch die \textit{cue validity} dieser Eigenschaften bestimmt (\cite[53]{Kleiber.1993}). Zudem geht die erweiterte Version der Prototypensemantik davon aus, dass auch prototypisch organisierte Kategorien prototypisch gegliedert sind, es also mehr oder weniger prototypisch organisierte Kategorien gibt. Somit wird auch die Annahme der generell unscharfen Grenzen aufgegeben: Prototypische prototypisch organisierte Kategorien haben unscharfe Grenzen (wie bspw. die Kategorien \textsc{Adjektiv} und \textsc{Adverb}), aber unprototypische prototypisch organisierte Kategorien weisen scharfe Grenzen auf (wie bspw. die Kategorie \textsc{Vogel}). Mit der Standardversion hat die erweiterte Version weiterhin Prototypeneffekte und Familienähnlichkeit als grundlegende Prinzipien gemeinsam. Anders als in der Standardversion sind die Prototypeneffekte jedoch eine Folge der Kategorienstruktur, die nach dem Prinzip der Familienähnlichkeit organisiert ist. Der Prototyp ist also eine Art Epiphänomen und nicht die Ursache dieser Effekte (\cite[56]{Lakoff.1987}, \cite[113]{Kleiber.1993}, \cite[254--256]{Blutner.1995}). Dies betont auch \textcite[101]{Rosch.2004} selbst: "`To speak of a prototype at all is simply a convenient grammatical fiction; what is really referred to are judgments of degree of prototypicality."'

Abbildung \ref{protstandard} fasst die Unterschiede zwischen Standard- und erweiterter Version der Prototypensemantik zusammen.

\begin{figure}
\includegraphics[width=\textwidth]{figures/Kap3/erweitertvsstandard.pdf}  
\caption{Vergleich zwischen Standardversion und erweiterter Version der Prototypensemantik}
\label{protstandard}
\end{figure}

Im weiteren Verlauf der Arbeit wird Prototypizität im Sinne der erweiterten Version der Prototypensemantik relevant sein: Dabei ist im Kern wichtig, dass Kategorien graduell organisiert sind. Einige Mitglieder einer Kategorie vereinigen viele typische Merkmale der Kategorie auf sich und stellen daher prototypische Vertreter der Kategorie dar. Andere Mitglieder vereinigen nur wenige Eigenschaften der Kategorie auf sich und sind daher periphere Mitglieder der Kategorie. Dabei lässt sich für prototypische Vertreter ein Prozessierungsvorteil ausmachen. Dieser Effekt wird im folgenden Abschnitt näher erläutert. Dabei wird herausgearbeitet, inwiefern Prototypizität Einfluss auf Variation nimmt: Variation ist bei prototypischen Vertretern unwahrscheinlich, da diese mental gefestigt sind, in der Peripherie ist sie dagegen aufgrund der geringeren Festigung wahrscheinlich. Diese Hypothese wird im empirischen Teil der Arbeit psycholinguistisch überprüft. Um den Einfluss der Prototypizität auf die Prozessierung genauer modellieren zu können, werden im folgenden Abschnitt die empirische Evidenz und Erklärungen für Prototypeneffekte näher betrachtet.

\subsection{Prototypeneffekte}
\label{proteffekt}

Empirische Evidenz für die Existenz von Prototypeneffekten liefern zahlreiche Experimente. So werden prototypische Vertreter einer Kategorie am häufigsten genannt, wenn man Proband\_innen dazu auffordert, einen Vertreter einer Kategorie zu nennen (bspw. \textit{Nenne einen Vogel!}) (\cite[38--39]{Kleiber.1993}, \cite[45]{Taylor.1995}). Proband\_innen sind in der Evaluation von An-X-is-an-Y-Aussagen (bspw. \textit{Eine Amsel ist ein Vogel}) schneller, wenn ein prototypischer Vertreter einer Kategorie genannt wird (bspw. \textit{Amsel} für die Kategorie \textsc{Vogel}), als wenn es sich um einen peripheren Vertreter (bspw. \textit{Pinguin}) handelt (\cite[100]{Rosch.2004}). Zudem existiert empirische Evidenz dafür, dass Kinder prototypische Vertreter einer Kategorie früher erlernen als randständige (\cite[100]{Rosch.2004}). Prototypische Vertreter einer Kategorie sind zudem salienter als randständige Vertreter (\cite[566]{Taylor.2015}).

Wie \textcite{Lakoff.1973} zeigt, lässt sich der Status von Entitäten innerhalb einer Kategorie als prototypisch oder peripher durch Heckenausdrücke verbalisieren, die ausdrücken, zu welchem Grad eine Entität Teil einer Kategorie ist (\textit{This is a typical cup/This is basically a cup}). Zudem nimmt Prototypizität Einfluss auf die Wortabfolge im Satz (\cite{Kelly.1986}). Prototypische Vertreter werden vor peripheren genannt: Proband\_innen tauschen in Testsätzen wie \textit{The child's errand was to buy a lemon and apple at the fruit stand} die Wortfolge, sodass der prototypische Vertreter \textit{apple} vor dem peripheren Vertreter \textit{lemon} genannt wird. Wenn hingegen der prototypische Vertreter zuerst genannt wird, behalten Proband\_innen die Reihenfolge bei (\cite[66--67]{Kelly.1986}). Zudem werden die Sätze als natürlicher bewertet, in denen der prototypische Vertreter zuerst genannt wird (\cite[68]{Kelly.1986}). 

\textcite[197--199]{Rosch.1975b} bestimmt mithilfe des Goodness-of-example-Designs,\footnote{\textcite[34--37]{Schmid.2000} kritisiert das Versuchsdesign, da bereits durch die Aufgabe präsupponiert wird, dass typische und weniger typische Vertreter einer Kategorie existieren. Zudem unterstellt \textcite[198]{Rosch.1975b} in der Aufgabenstellung, dass es eine intersubjektive Vorstellung davon gibt, was der prototypische Vertreter einer Kategorie ist: "`Think of dogs. You all have some notion of what a `real dog', a `doggy dog' is. To me a retriever or a German shepherd is a very doggy dog while a Pekinese is a less doggy dog"' (\cite[198]{Rosch.1975b}). Außerdem kritisiert \textcite[74]{Poitou.2004}, dass in Roschs Arbeiten implizit auf die denotative Bedeutung fokussiert wird. Dies wird in einer Anweisung deutlich, in der konnotative Komponenten explizit ausgeschlossen werden: "`But try not to just free associate -- for example, if bicycles just happen to remind you of your father, don't write down father"' (\cite[578]{Rosch.1975c}).} welche Vertreter als prototypisch wahrgenommen werden und welche als peripher: Dabei werden amerikanischen Student\_innen verschiedene Kategorien (u.~a. \textsc{Früchte}, \textsc{Vögel} und \textsc{Gemüse}) präsentiert und zusätzlich mögliche Vertreter\footnote{Diese wurden anhand einer Studie von \textcite{Battig.1969} ausgewählt: In dieser Studie sollen Proband\_innen Vertreter von Kategorien benennen. \textcite[197--199]{Rosch.1975b} übernahm pro Kategorie die Vertreter, die von über zehn Versuchspersonen genannt worden waren; zusätzlich wurden zufällig weitere Vertreter ausgesucht, die von weniger als zehn Personen genannt wurden.} der Kategorie. Die Proband\_innen werden gebeten, auf einer Skala von 1~(gutes Beispiel) bis~7 (schlechtes Beispiel) zu bewerten, wie sehr ein Vertreter in eine Kategorie gehört. Auf diese Weise möchte Rosch intersubjektive Prototypen ausmachen. In neun von zehn Kategorien wurde das Exemplar, das durchschnittlich als bester Vertreter gewertet wurde, von 95~\% der Proband\_innen mit der Bestzahl~1 bewertet (\cite[198]{Rosch.1975b}). Die intersubjektiven Prototypen nutzt \textcite[199--206]{Rosch.1975b}, um zu überprüfen, ob prototypische Vertreter einer Kategorie anders wahrgenommen werden als andere Vertreter. So kann sie mithilfe einer same-different-match-Aufgabe\footnote{In einer same-different-match-Aufgabe werden Proband\_innen gebeten, zu bewerten, ob zwei Wörter oder Bilder der gleichen Kategorie angehören oder nicht, z.~B. \textit{Apfel} und \textit{Banane} oder \textit{Apfel} und \textit{Stuhl}. Zusätzlich zu dieser Aufgabe wird bei einigen der Paaren mit einem Prime gearbeitet, um zu testen, inwiefern der Kategorienname Vertreter der Kategorie primt. Ausführlich zum methodischen Vorgehen und zu den Ergebnissen siehe \textcite{Rosch.1975b}.} zeigen, dass prototypische Vertreter generell schneller kategorisiert werden und dass Kategoriennamen den prototypischen Vertreter der Kategorie primen, nicht aber periphere Vertreter.\largerpage

Nicht nur für lexikalische, sondern auch für grammatische Kategorien lassen sich Prototypeneffekte beobachten: Elemente mit prototypischen Eigenschaften einer Kategorie werden stabil genutzt. Die stabile Verwendung des Prototyps spiegelt sich im frühen Erwerb: Als erstes Exemplar wird das prototypische und frequenteste Verb in einer Konstruktion (bspw. \textit{give} in der ditransitiven Konstruktion) erworben (\cites{Ellis.2009}[58]{Ellis.2014}). In der Peripherie grammatischer Kategorien sind hingegen Schwankungen möglich (\cite[67--68]{Agel.2008}). Diese lassen sich bspw. in der Peripherie von Form-Schemata beobachten, siehe hierzu \sectref{schemaeffekt}. Anders als prototypische Elemente weisen periphere Elemente weniger gemeinsame Eigenschaften mit anderen Vertretern der Kategorie auf und sind somit auch weniger stark mit der Kategorie assoziiert.

 Schwankungen in der Peripherie entstehen zum einen dadurch, dass periphere Vertreter den prototypischen Eigenschaften der Kategorie angepasst werden; so wird bspw. das ursprünglich nicht-flektier\-bare Farbadjektiv \textit{lila} flektiert (\textit{eine lilane Hose}) (\cite[67--68]{Agel.2008}). Zum anderen entstehen Schwankungen, weil die Peripherie zum Anziehungsbereich von zwei Kategorien zählt. Dies ist bspw. bei \textit{brauchen} der Fall, das in der Peripherie zwischen Voll- und Modalverb steht und daher zwischen Infinitivformen mit und ohne \textit{zu} schwankt (\textit{Das brauchst du nicht (zu) machen}) (\cite[11]{Eisenberg.1990}). Dasselbe gilt für die Präposition \textit{wegen}: \textit{Wegen} ist eine Sekundärpräposition, die jedoch Eigenschaften von Primärpräpositionen angenommen hat (\cites[100--101]{Schmitt.2019b}[74]{Vieregge.2019}). Der periphere Status zwischen zwei Kategorien zeigt sich unter anderem darin, dass \textit{wegen} sowohl mit Genitiv (als typischen Kasus für Sekundärpräpositionen) als auch mit Dativ (als typischen Kasus für Primärpräpositionen) stehen kann. Die beiden Kasus evozieren vergleichbare Lesezeiten (\cite[115--120]{Schmitt.2019b}), wohingegen \textit{wegen}~+~Nominativ zu hohen Lesezeiten führt: \textit{Wegen}~+~Nominativ wurde in der Studie als ungrammatische Kontrollkondition genutzt, da der Nominativ als Präpositionalkasus ausgeschlossen ist.\footnote{Hierbei ist zu beachten, dass Präpositionen ohne Kasusforderung wie \textit{außer} durchaus Nominativformen aufweisen können, die sich aber nicht aus der Rektion der Präposition, sondern aufgrund von Verb\-kongruenz ergeben: \textit{\textbf{Alle} essen Koriander außer \textbf{ich}} (\cite[46--47]{DiMeola.2000}).}\largerpage

Modelliert man die Wahrscheinlichkeit der Kasus bei \textit{wegen} in einem bayesianischen Modell, ist die priore Wahrscheinlichkeit für Genitiv und Dativ aufgrund des peripheren Status von \textit{wegen} zwischen Primär- und Sekundärpräposition vergleichbar groß, während sie für den Nominativ gering ist, da der Nominativ prototypischerweise zur Markierung des Subjekts verwendet wird. Hier ist das statistische Vorkaufsrecht nach \textcite[74--94]{Goldberg.2019} relevant: Der Nominativ kommt häufig vor, um Subjekte zu markieren, wird aber nie als Rektionskasus genutzt. Genitiv und Dativ werden hingegen häufig als Rektionskasus genutzt, weshalb sie den Nominativ statistisch ausstechen (ausführlich zum statistischen Vorkaufsrecht siehe \sectref{Statistik}). Da \textit{wegen} sowohl Eigenschaften von Sekundär- als auch von Primärpräpositionen aufweist und sich somit jeweils in der Peripherie der Präposi\-tionsarten befindet, kann bei \textit{wegen} keiner der Rektionskasus den anderen ausstechen, sodass sowohl Genitiv als auch Dativ möglich sind.

 \textcite[198]{Taylor.1998} stellt fest, dass periphere Vertreter einer Konstruktion eher idioma\-tische Einschränkungen aufweisen als prototypische Vertreter einer Konstruktion. Konstruktionen sind in der Peripherie somit weniger produktiv, wobei periphere Verwendungen einer Konstruktion nicht zwangsläufig weniger akzeptabel sind als prototypische Verwendungen (\cite[198]{Taylor.1998}). So führt \textcite[xvii]{Tomasello.1998} einen großen Anteil der kreativen Verwendung von Sprache darauf zurück, dass Wörter in einer Konstruktion genutzt werden, die keinen prototypischen Verwendungskontext für das Wort darstellt. Als Beispiel nennt er \textit{Mary kicked John the football}, da \textit{to kick} normalerweise nicht für Besitzwechsel genutzt wird und daher auch nicht in der ditransitiven Konstruktion. In der vorliegenden Verwendung kann aber ein Besitzwechsel konstruiert werden, sodass eine Verwendung in der Konstruktion möglich ist (\cite[xvii]{Tomasello.1998}).\footnote{Die Interpretation als Übergabe ergibt sich durch die Verwendung des Verbs in der ditransitiven Konstruktion, sodass die Konstruktion selbst Bedeutung trägt (\cite[xviii]{Tomasello.1998}; in \sectref{konstruktion} werden Konstruktionen ausführlich diskutiert). Konstruktionen können somit Elemente in ihre Slots zwingen (\cite[198]{Taylor.1998}, \cite[37]{Goldberg.2019}), daher diskutieren \textcite{AudringBooij.2016} Effekte dieser Art unter dem Stichwort \textit{coercion} (Zwang).}

Die eingeschränkte Produktivität in der Peripherie von Konstruktionen zeigt sich in P600-Effekten bei EEG-Studien. So können Sätze P600-Effekte auslösen, in denen das Subjekt kein prototypisches Agens ist (\cite[157]{Gouvea.2010}), wie bspw. \textit{the hearty meal was devouring the kids}, in dem mit dem nicht-belebten Substantiv \textit{meal} ein untypisches Agens verwendet wird (zur prototypischen Organisation der Agensrolle siehe \cite[64--66]{Lakoff.1987}). Auch dieser Effekt kann bayesianisch modelliert werden: Das Substantiv \textit{meal} ist als Agens weniger semantisch erwartbar als bspw. ein Substantiv mit belebtem Referenten, sodass die priore Wahrscheinlichkeit für \textit{meal} als Agens vergleichsweise gering ist.

Die Integration der empirisch nachweisbaren Prototypeneffekte in die Theorie prototypisch organisierter Kategorien stellt eine Herausforderung dar. Einen Versuch legt \textcite[198]{Rosch.1975b} vor, die für ihre Modellierung lexikalischer Kategorien das Ordnungsprinzip der Typizität nutzt, indem sie anhand der Bewertungen aus dem oben erwähnten goodness-of-example-Experiment Typizitätsskalen erstellt, die die Distanz von einzelnen Vertretern einer Kategorie zum Prototyp angeben: Ein Rotkehlchen hat den Wert~1,02 und stellt somit den prototypischen Vertreter der Kategorie \textsc{Vogel} dar, während ein peripherer Vertreter wie bspw. ein Pinguin einen Wert von~4,53 aufweist.\footnote{\textcite[458--459]{Lakoff.1973} setzt diese unterschiedlichen Werte der Typizität mit Zugehörigkeit gleich: Pinguine sind für ihn also weniger vogelig als Rotkehlchen. Diese Gleichsetzung wird in der erweiterten Version der Prototypensemantik aufgegeben (\cite[112]{Kleiber.1993}).} \textcite[7--9]{Poitou.2004b} kritisiert Typizitätsskalen, da die Typizität bei verschiedenen Kategorien auf unterschiedliche Eigenschaften zurückzuführen ist. So sind in der Kategorie \textsc{Vogel} die Vögel prototypisch, die man frequenterweise antrifft. Umgekehrt ist in der Kategorie \textsc{Edelstein} der Stein prototypisch, der am seltensten ist. \textcite[9]{Poitou.2004b} nennt als Beispiel einen lupenreinen Smaragd, der prototypischer ist als ein Smaragd mit Einschlüssen. Allerdings ist davon auszugehen, dass lupenreine Edelsteine im Diskurs einen größeren Stellenwert einnehmen als fehlerhafte Edelsteine und daher darin auch häufiger verhandelt werden. Ein anderer Kritikpunkt Poitous an Typizitätskalen ist zentraler: Es ist problematisch, dass Typizitätsskalen Kategorien auf einer einzigen Skala abbilden wollen (\cite[1--3]{Poitou.2004b}). Wenn Proband\_innen aufgefordert werden, Mitglieder einer Kategorie zu nennen, beeinflusst nicht nur die Typizität die Reihenfolge der Nennungen, sondern bspw. auch die Lautstruktur der vorher genannten Vertreter einer Kategorie. So kann es sein, dass auf \textit{Nektarine} aufgrund des ähnlichen Auslauts \textit{Apfelsine} und \textit{Clementine} genannt werden: Die Substantive bilden ein lautliches Cluster, das aktiviert wird, wenn ein Vertreter des Clusters genutzt wird (\cite[62--65]{Goldberg.2019}). Typizitätsskalen stellen somit eine Vereinfachung der Kategorienstruktur dar und können nur einen ersten Einblick in die Struktur von Kategorien bieten (\cite[2--3]{Poitou.2004b}).

Die von \textcite{Poitou.2004b} angesprochene Problematik zeigt sich auch darin, dass die durch das goodness-of-example-Design erarbeiteten Typizitätsskalen nicht universell sind: So werden bei \textcite[232]{Rosch.1975b} Blauhäher (\textit{blue jay}) und Hüttensänger (\textit{bluebird}) mit Werten von~1,29 und~1,31 als sehr typische Vertreter der Kategorie \textsc{Vogel} identifiziert. Diese Vögel sind in Nordamerika beheimatet; es ist somit davon auszugehen, dass das Experiment andere Ergebnisse hervorbringt, wenn es mit Proband\_innen durchgeführt wird, die in anderen Erdteilen sozialisiert wurden. Zudem sind Experimente dieser Art kontextabhängig: Wenn der Kontext spezifiziert wird (etwa Vögel auf dem Bauernhof), werden andere Prototypen genannt als ohne spezifischen Kontext (\cite[35--36]{Schmid.2000}).

Der Einfluss des Kontexts auf die Kategorisierung wird auch in einem der bekanntesten Experimente zur prototypischen Struktur lexikalischer Kategorien von \textcite{Labov.2004} deutlich. \textcite{Labov.2004} zeigt Proband\_innen Zeichnungen von tassenähnlichen Objekten und bittet sie, die darin dargestellten Objekte zu benennen. Die Objekte variieren u.~a. in Breite und Höhe (für eine genauere Beschreibung des methodischen Vorgehens siehe \cite[76--78]{Labov.2004}). Je breiter das dargestellte Objekt ist, desto eher benennen die Proband\_innen dieses als \textit{bowl} statt als \textit{cup}; je länglicher ein Objekt ist, desto wahrscheinlicher benennen die Proband\_innen das Objekt zunächst als \textit{mug} statt als \textit{cup} und schließlich als \textit{vase} (\cite[78--79]{Labov.2004}). Zusätzlich wird der Kontext manipuliert, in dem die Objekte bewertet werden sollen: Im neutralen Kontext wird lediglich nach dem Objekt gefragt, im Essen-Kontext sollen die Proband\_innen sich vorstellen, dass das Objekt mit Kartoffelbrei gefüllt ist, und im Blumen-Kontext, dass das Objekt Blumen enthält und auf einem Fensterbrett steht. Der Kontext beeinflusst die Benennung der Proband\_innen: Im Vergleich zum neutralen Kontext sagen die Proband\_innen im Essen-Kontext bereits bei schmaleren Objekten, dass es sich dabei um eine Schüssel und nicht um eine Tasse handelt (\cite[78--79]{Labov.2004}). Im Blumen-Kontext benennen die Proband\_innen Objekte als \textit{vase}, die im neutralen Kontext \textit{cup} genannt werden (\cite[79--80]{Labov.2004}). Zudem benennen die Proband\_innen das Objekt in diesem Kontext unabhängig von seiner Gestalt nicht als \textit{mug}.

Das Experiment verdeutlicht, dass für die Zuordnung zu einer Kategorie nicht nur die Form eines Gegenstands relevant ist, sondern auch dessen Zweck. Zur Tasse gehört bspw. der Zweck, Kaffee oder Tee daraus zu trinken; eine Suppe daraus zu essen, ist hingegen eine randständige Funktion. Die hier skizzierten Interaktionen zwischen Kontext, Semantik und Phonologie können durch Typizitätsskalen nicht modelliert werden (\cite[2--3]{Poitou.2004b}). Somit ist ein bloßer Blick auf Typizität nicht ausreichend, um Kategorien zu umfassen. Um einen Kategorien umfassend modellieren zu können, ist ein exemplarbasierter Ansatz nötig. Dieser Ansatz geht davon aus, dass alle Eigenschaften (inklusive dem Äußerungskontext) eines Exemplars mental repräsentiert werden und Eigenschaften einer Kategorie erst durch die Überlappung von Eigenschaften einzelner Exemplare der Kategorie entstehen (\cite[62--73]{Goldberg.2019}).

Der Abschnitt zeigt, dass prototypische Vertreter einer Kategorie anders verarbeitet werden als periphere. Dies wird für die Betrachtung der Variationsphänomene essentiell sein: Prototypizität kann damit als Erklärung für Variation genutzt werden. Es ist davon auszugehen, dass prototypische Vertreter einer Kategorie wenig Variation aufweisen, während periphere zugänglich für Variation sind (\cite[67--68]{Agel.2008}). Dieser Einfluss wird für die einzelnen Variationsphänomene näher in den Blick genommen und im empirischen Teil der Arbeit psycholinguistisch überprüft. Der Einfluss von Prototypizität kann genauso wie der Einfluss von Frequenz bayesianisch modelliert und somit über Wahrscheinlichkeiten gefasst werden. Gleichzeitig zeigen sich die Grenzen von prototypisch organisierten Kategorien: Kategorien sind vielfältig gestaltet, sodass sie sich nicht anhand von einer einzigen Dimension modellieren lassen. Daher wird im folgenden Abschnitt der exemplarbasierte Ansatz zur Kategorienenstehung in den Blick genommen und mit prototyp\-basierten Kategorien verglichen. Das Ergebnis der Diskussion ist eine Modellierung von prototypisch organisierten Kategorien als Ergebnis exemplarbasierten Lernens. Diese Definition wird dem Rest der Arbeit zugrunde gelegt.

\subsection{Prototyp- und exemplarbasierte Kategorien}
\label{exemplar}
 
Im gebrauchsbasierten Ansatz wird statt der prototypbasierten Kategorisierung eine exemplarbasierte Kategorisierung als grundlegendes Konzept angesetzt (\cite[68]{Bybee.2013}). Die exemplarbasierte Kategorisierung bildet einen Gegensatz zur Standardversion der Prototypensemantik, in der davon ausgegangen wird, dass eine Kategorie durch den Prototyp repräsentiert wird, der die zentralen Tendenzen der Kategorie auf sich vereint (siehe \sectref{standard}). Wie dieser Abschnitt zeigen wird, lässt sich die exemplarbasierte Kategorisierung jedoch gut mit der erweiterten Version der Prototypensemantik vereinen, die Vertreter nach ihrer Typizität unterscheidet und nicht von einem Prototyp als Exemplar ausgeht, sondern ihn als einen Effekt sieht. So wurden in \sectref{standard} bereits einige Grundprinzipien des exemplarbasierten Lernens in Hinblick auf die erweiterte Version der Prototypensemantik diskutiert.

In der Standardversion der Prototypensemantik findet Kategorisierung im Vergleich zum Prototyp statt (\cite[208]{Ross.1999}) und der Prototyp wird daher als einzige zusammenfassende Repräsentation einer Kategorie konzeptualisiert. Dies ist jedoch eine zu einseitige Sicht auf Kategorisierung. Kategorisierung ist nicht allein vom Prototyp abhängig, sondern bspw. auch von der Ähnlichkeit der zu kategorisierenden Entität mit kurz zuvor erlernten Vertretern der Kategorie (\cite{Whittlesea.1987}, \cite[208]{Ross.1999}, \cite[46]{Goldberg.2006}).

 Das menschliche Erinnerungsvermögen basiert zudem nicht allein auf prototypischen Eigenschaften, sondern ist assoziativ (\cite[52]{Goldberg.2019}). Dies zeigt bspw. der Vorteil für gleichbleibende Stimmen (\cite[255]{Goldinger.1998}): Wörter werden nicht nur für sich mental repräsentiert, sondern mit dem Menschen assoziiert, der sie gesprochen hat (siehe \sectref{korrelation} zum Vorteil gleichbleibender Stimmen). Außerdem umfasst das menschliche Erinnerungsvermögen nicht nur einzelne Eigenschaften, sondern auch, wie viele Werte eine Eigenschaft hat: Erdbeeren sind rot, daher kann die Eigenschaft \textsc{Farbe} in Bezug auf Erdbeeren nur einen Wert haben. Äpfel können dagegen auch grün sein, die Eigenschaft \textsc{Farbe} hat hier also mindestens zwei Werte. Zudem verfügen wir über ein implizites Wissen darüber, wie die Werte verschiedener Eigenschaften untereinander korrelieren: Paprikaschoten können süß und bitter sein sowie rot, orange, gelb oder grün. Dabei korreliert die Farbe mit dem Grad der Bitterkeit (\cite[211--212]{Ross.1999}). Diese Korrelation wird in der Standardversion der Prototypensemantik nicht erfasst. Die erweiterte Version der Prototypensemantik könnte sie berücksichtigen, da der Blick auf typische Eigenschaften auch die Korrelation zwischen Eigenschaften ermöglicht. Sie beschränkt sich jedoch auf Typizitäts\-skalen, deren Problematik bereits in \sectref{proteffekt} diskutiert wurde.

Im Gegensatz zur Standardversion der Prototypensemantik geht der exemplarbasierte Ansatz davon aus, dass eine Kategorie durch Token geformt wird, die als gleich angesehen werden (\cite[53]{Bybee.2013}): Hört man eine Wortform, werden die Eigenschaften dieser Wortform (Form, Funktion, Kontext) mental repräsentiert.\footnote{Dabei hinterlässt bereits die erste Verarbeitung eines Exemplars eine Erinnerungsspur, da ansonsten jede Verarbeitung als die erste gelten müsste (\cites[722--723]{Bybee.2006b}[56]{Bybee.2013}[13--14, 54]{Goldberg.2019}).} Hört man die Wortform noch einmal, wird die neue Repräsentation ergänzt. Die neue Repräsentation überlappt mit der alten, aber sie ist nicht dieselbe; z.~B. könnte die Wortform von einer anderen Person gesagt werden und daher leicht anders klingen als die zuerst gehörte Wortform. Die Repräsentationen der Wortformen ergeben schließlich ein emergentes Cluster, "`which constitutes what we think of as a coherent word meaning (or lemma)"' (\cite[16]{Goldberg.2019}). Im exemplarbasierten Ansatz hat somit jedes Exemplar (Token) Einfluss auf die mentale Repräsentation einer Kategorie (Type): Immer wenn eine mentale Repräsentation durch Kodierung oder Dekodierung aktiviert wird, ändert sich die Repräsentation (\cites[722]{Bybee.2006b}[52]{Bybee.2013}[51--52]{Goldberg.2019}). Abbildung \ref{cluster}, die an die Abbildung in \textcite[16]{Goldberg.2019} angelehnt ist, veranschaulicht diesen Prozess.\largerpage[2]

\begin{figure}
\includegraphics[width= 0.8 \textwidth, height=0.3\textwidth]{figures/Kap3/cluster.png}  
\caption{Stärkung der mentalen Repräsentation eines Worts durch Wiederholung}
\label{cluster}
\end{figure}

Der linke Teil der Abbildung zeigt die mentale Repräsentation einer Wortform: Informationen, die als informativ{\interfootnotelinepenalty=10000\footnote{Was dabei als informativ wahrgenommen wird, hängt von zahlreichen Einflussfaktoren innerhalb der Verwendungssituation ab: Wenn ein Elternteil bspw. \textit{Ball} sagt und dabei auf einen Ball zeigt, wird durch die Zeigegeste klar, dass der Ball wichtig ist und nicht das daneben liegende Buch. Wenn das Elternteil \textit{heiß} sagt und das Kind gleichzeitig das heiße Wasser spürt, kann der Temperaturwechsel als relevant empfunden und mit dem Wort verknüpft werden. Dabei können auch Dinge als relevant eingestuft werden, die nicht relevant sind, und so z.B. \textit{heiß} mit Wasser anstelle der Temperatur verknüpft werden. Da eine Repräsentation aber nicht anhand von einer einzigen Gebrauchssituation gebildet werden, sondern anhand von vielen, werden falsche Verbindungen i.d.R. nicht verstärkt und somit im Lauf der Zeit als unwichtig empfunden.}} für den Gebrauch der Wortform wahrgenommen werden, sind dabei dunkel hervorgehoben (\cite[16]{Goldberg.2019}). Die Repräsentation enthält detaillierte Informationen über Form, Bedeutung und Kontext. Wenn das Wort immer wieder gehört wird, werden die wiederkehrenden Aspekte in der Repräsentation gestärkt, wohingegen singuläre Aspekte nicht gestärkt werden. Hieraus ergibt sich ein Cluster, das im rechten Teil der Abbildung dargestellt ist. Nach demselben Prinzip werden Exemplare, die ähnlich sind, miteinander assoziiert. Sie bilden ein Cluster (eine Kategorie), das es ermöglicht, gemeinsame Informationen der einzelnen Exemplare zu abstrahieren und strukturiert zu repräsentieren (\cite[54]{Bybee.2013}). 



Im exemplarbasierten Ansatz funktioniert Kategorisierung auf Basis wiederkehrender Ähnlichkeit der zu klassifizierenden Entität zu den bestehenden Exemplaren einer Kategorie (\cite[212--213]{Ross.1999}, \cite[51--52]{Goldberg.2019}): Um bspw. als Frucht eingestuft werden zu können, muss eine Entität wiederkehrend Ähnlichkeit zu bereits existierenden Exemplaren der Kategorie \textsc{Frucht} aufweisen. Die Kategorisierung wird dabei vorrangig von den Vertretern einer Kategorie mit der größten Ähnlichkeit zueinander beeinflusst. Das Kriterium der Ähnlichkeit zwischen Exemplaren legt bereits an, dass sich die Struktur von Kategorien im exemplarbasierten Ansatz -- genau wie  im prototypbasierten Ansatz -- durch Familienähnlichkeit ergibt (\cite[327]{Bybee.2006}). Zudem beeinflusst Variabilität die Kategorisierung:  Die Variabilität der bereits bestehenden Exemplare einer Kategorie nimmt Einfluss darauf, wie groß die Ähnlichkeit des zu kategorisierenden Exemplars zu den bereits existierenden sein muss (\cite[62--64]{Goldberg.2019}, siehe \sectref{typ} für weitere Ausführungen zu Goldbergs Konzept der Abdeckung, das die Einflussfaktoren Typenfrequenz, Ähnlichkeit und Variabilität beinhaltet).\largerpage

Aufgrund der Familienähnlichkeit sind auch im exemplarbasierten Ansatz Prototypeneffekte möglich: Einige Vertreter der Kategorie sind typischer als andere, weil typische Exemplare mehr Ähnlichkeiten zu anderen Exemplaren der Kategorie aufweisen als untypische (\cite[213]{Ross.1999}). Da eine Amsel also mehr Ähnlichkeiten zu anderen Vögeln aufweist, ist sie typisch; der Pinguin ist dagegen untypisch, weil er weniger Ähnlichkeiten zu anderen Vögeln aufweist (\cite[213]{Ross.1999}). Dies ist auch die exemplarbasierte Erklärung dafür, dass typische Vertreter einer Kategorie schneller prozessiert werden als untypische. 



Für die Kategorisierung werden im exemplarbasierten Ansatz aber nicht nur semantische Ähnlichkeiten einbezogen, sondern bspw. auch kontextuelle und phonologische Ähnlichkeiten (\cite[716]{Bybee.2006b}). \textcite[15]{Goldberg.2019} verdeutlicht die Notwendigkeit eines so umfassenden Ansatzes anhand eines Beispiels: Beim Verb \textit{schreiben} ist es egal, ob hastig geschrieben wird oder welche Wörter geschrieben werden. Dennoch ist davon auszugehen, dass diese Informationen in der mentalen Repräsentation einzelner Verwendungen des Verbs \textit{schreiben} berücksichtigt werden. Für \textit{schreiben} sind die Informationen zwar irrelevant, aber für Hyponyme von \textit{schreiben} essentiell: So ist die Art des Schreibens bzw. das geschriebene Wort Teil der Bedeutung von \textit{krakeln} (\SchmittSingleQuot{hässlich schreiben}) und \textit{unterschreiben} (\SchmittSingleQuot{den eigenen Namen schreiben}). Zudem kann das Verhältnis einzelner Informationen zueinander nur dann bestimmt werden, wenn diese in die mentale Repräsentation des Vertreters eingeflossen sind (\cite[214--215]{Ross.1999}): Die Farbe einer Paprika und ihr Bitterkeitsgrad können nur verknüpft werden, wenn die Informationen auch mental repräsentiert sind. Wir verfügen dementsprechend implizit über Korrelationen zwischen Eigenschaften von Vertretern einer Kategorie. Dies kann die Kategorisierung beeinflussen, auch wenn sich Sprecher\_innen der Korrelation nicht bewusst sind (\cite[214--215]{Ross.1999}).

Die Modellierung von Kategorien als Cluster verschiedener mentaler Repräsentationen ist ein Vorteil des exemplarbasierten Ansatzes. Durch die Annahme von mehrfachen Repräsentationen kann der selektive Zugang zu Wissen über Kategorien berücksichtigt werden. Wenn wir eine Kategorie aufrufen, werden nicht alle, sondern nur die im gegebenen Kontext relevanten Eigenschaften der Kategorie aktiviert.  Dies wird auch im obigen Beispiel zu \textit{schreiben}, \textit{unterschreiben} und \textit{krakeln} deutlich, denn auch für das Verb \textit{schreiben} können Kontexte existieren, in denen relevant ist, wie geschrieben wird. Unser Wissen über Kategorien ist daher sensitiv für Inhalte (\cite[52]{Goldberg.2019}). Zudem werden im exemplarbasierten Ansatz Eigenschaften nicht einfach unabhängig voneinander aufsummiert, sondern relational genutzt (\cite[216]{Ross.1999}). Dies ermöglicht es, dass Informationen über die Vertreter der Kategorie und ihr Verhältnis zueinander abgerufen werden können, wenn es nötig ist.  

Wie bereits in \sectref{standard} erläutert, wird Tokenfrequenz als Einflussfaktor auf Prototypizität von Vertreter\_innen der Standardversion der Prototypensemantik kritisch betrachtet (siehe \cite[42]{Kleiber.1993}, \cite[52]{Taylor.1995}, \cite[50]{Schmid.2000} und \cite[567--568]{Taylor.2015}), weswegen der prototypbasierte Ansatz als frequenzfeindlich bezeichnet wird (\cite[365]{FenkOczlon.1991}). Diese Frequenzfeindlichkeit wird erst durch den Fokus auf typische Eigenschaften relativiert. Im exemplarbasierten Ansatz ist Frequenz ein grundlegender Einflussfaktor auf Kategorisierung: Kategorien werden als analogische Sets ähnlicher Exemplare mental repräsentiert, weil die Exemplare häufig genutzt werden (\cite[326]{Bybee.2006}, \cite[13]{Diessel.2017}). Informationen über Kategorien können daher verloren gehen, wenn diese nicht durch Wiederholung gestärkt werden (\cite[54]{Bybee.2013}). 


\begin{sloppypar}
Exemplare mit hoher Tokenfrequenz sind im exemplarbasierten Ansatz die zentralen Einheiten einer Kategorie (\cite[61]{Bybee.2013}): Sie formen den semantischen Slot innerhalb einer Konstruktion (zu Konstruktionen siehe \sectref{konstruktion}). Zudem sind typenfrequente und produktive Kategorien um einen frequenten Vertreter gruppiert. Evidenz für diese Annahme sieht \textcite[727]{Bybee.2006b} in Kategorien mit geringer Typenfrequenz und geringer Produktivität, die keinen hochfrequenten Vertreter haben. Für diese These spricht außerdem, dass frequente und prototypische Verben in Verb-Argument-Konstruktionen als Erstes erworben werden (\cite[5]{Ellis.2013}). 
\end{sloppypar}


Zudem konnte in einem Experiment, das mit Mustern aus Punkten und somit nicht sprachbasiert arbeitet, der prototypische Vertreter besser als solcher erkannt werden, wenn er häufiger als andere Muster gezeigt wurde (\cite[87--88]{Goldberg.2006}). Daher ist davon auszugehen, dass das Lernen von Kategorien durch einen Vertreter mit prototypischen Eigenschaften erleichtert wird, der häufig im Input erscheint (\cite[87]{Goldberg.2006}). Tokenfrequenz scheint die Produktivität einer Kategorie somit zumindest mittelbar zu beeinflussen, da sie bei der Entstehung einer Kategorie eine Analogievorlage ermöglicht, die zur Erweiterung und zur Abstraktion der Kategorie führt (ausführlich zum Einfluss der Tokenfrequenz auf Produktivität siehe \sectref{typ}).\footnote{Die Annahme eines frequenten Mitglieds als Zentrum einer Kategorie scheint der Verbindung zwischen Tokenfrequenz und Autonomie zu widersprechen (siehe \sectref{typ}). Die Autonomie beschränkt \textcite[715]{Bybee.2006b} allerdings auf extrem frequente Elemente. Eine klare Grenze zwischen hoch- und extrem frequenten Exemplaren nennt sie dabei nicht.} Zudem scheinen frequente Vertreter einer Kategorie und Vertreter mit semantischer Ähnlichkeit zum frequenten Vertreter höhere Akzeptanzwerte aufzuweisen als infrequente und dem frequenten Vertreter unähnliche Exemplare \parencites[727--728]{Bybee.2006b}[325--327]{Bybee.2006}. Vertreter mit semantischer Ähnlichkeit zum frequenten Vertreter sind somit akzeptabler als Vertreter ohne semantische Ähnlichkeit. Dies verdeutlicht, dass die Ausweitung einer zu erlernenden Kategorie nicht allein an tokenfrequenten Vertretern hängt: Auch die Variabilität der Kategorie und die Ähnlichkeit des potentiellen neuen Vertreters zu bereits existierenden Exemplaren spielen eine Rolle. \textcite[62--65]{Goldberg.2019} fasst dies unter dem Konzept der Abdeckung, siehe hierzu \sectref{typ}.

Die Einflussfaktoren Ähnlichkeit und Frequenz ermöglichen Hierarchien in der Kategorisierung (\cite[716]{Bybee.2006b}): Exemplarbündel mit ähnlicher phonologischer Form und ähn\-licher Bedeutung werden als Wort oder Phrase geclustert, z.~B. das Verb \textit{schenken} oder die Phrase \textit{Ich schenke dir ein Buch}. Je nachdem, wie variabel das Cluster ist, können neue Exemplare als dem Cluster angehörig wahrgenommen werden (\cite[62]{Goldberg.2019}). Hieraus kann eine abstraktere Konstruktion entstehen, wenn wiederum einzelne Wörter oder Phrasen bspw. mit ähnlicher Bedeutung als Cluster repräsentiert werden, z.~B. Verben mit der Bedeutung \SchmittSingleQuot{Übergabe}. Daraus kann dann mit der ditransitiven Konstruktion ein noch abstrakteres Cluster abstrahiert werden. Die Abstraktheit der Konstruktion ergibt sich, weil nur die geteilten Eigenschaften einzelner Exem\-plare verstärkt werden. In der Folge werden auch nur bestimmte Aspekte der Exemplare als Teil der Konstruktion gesehen (\cite[65]{Bybee.2013}). Für Verben mit der Bedeutung \SchmittSingleQuot{Übergabe} sind die Teilbedeutungen \SchmittSingleQuot{dauerhaft} und \SchmittSingleQuot{umsonst} von \textit{schenken} bspw. irrelevant. 



Mit diesem Ansatz lässt sich das Entstehen neuer Konstruktionen aus bestehenden Konstruktionen gut modellieren: Ein Vertreter einer Konstruktion wird mit einer für die Konstruktion besonderen Bedeutung genutzt. Wird derselbe oder ein ähnlicher Vertreter der Konstruktion wiederholt mit dieser Bedeutung verwendet, formt sich daraus ein Cluster, sodass sich eine neue Konstruktion entwickelt (\cite[63]{Bybee.2013}).  Die Entstehung neuer Konstruktionen ist somit vornehmlich durch Frequenz bedingt: Wenn ein Vertreter einer Konstruktion frequenter verwendet wird als andere, kann der Vertreter als eine eigene Einheit wahrgenommen werden und sich somit von der Ursprungskonstruktion lösen (\cite[720]{Bybee.2006b}, \cite[68--70]{Goldberg.2019}; das Phänomen wurde in \sectref{typ} als Autonomie-Effekt diskutiert). In der Folge weist der Vertreter weniger Ähnlichkeit zur Ursprungskonstruktion auf und bildet ein eigenes Cluster. \textcite[719--721]{Bybee.2006b} nennt \textit{going to} als Beispiel, das zu \textit{gonna} reduziert wird und so seine Verbindung zum Verb \textit{go} verliert. Zudem geht die semantische Verbindung zum Vollverb \textit{go} verloren, da keine Bewegung mehr ausgedrückt wird, sondern eine Intention bzw. Futur. 

Wie bereits durch die Einführung des exemplarbasierten Ansatzes deutlich wurde, stellen sich die oben skizzierten Probleme der prototypbasierten Ansätze für den exemplarbasierten Ansatz nicht: Da er von Exemplaren ausgeht, ist eine Klassifizierung von potentiellen neuen Exemplaren aufgrund der Ähnlichkeit zu einem bestimmten, in der Kategorie vorhandenen Exemplar abgedeckt (\cite[214]{Ross.1999}). Das bereits vorhandene Exemplar muss dabei nicht unbedingt prototypische Eigenschaften der Kategorie aufweisen. Auf diese Weise können auch marginale Eigenschaften als Vorlage für Erweiterungen der Kategorie dienen und spezifische Informationen über einzelne Kategorievertreter Teil der Repräsenta\-tion werden (\cite[717]{Bybee.2006b}). Kategorisierung hängt in diesem Ansatz von individuellen Erinnerungen ab (\cite[13]{Diessel.2017}) und nicht wie beim prototypbasierten Lernen von Generalisierungen. Der exemplarbasierte Ansatz kann damit experimentelle Daten besser erklären als ein streng ausgelegter prototypischer Ansatz (\cite[215]{Ross.1999}).


  
Problematisch für den exemplarbasierten Ansatz ist, dass er nicht erklären kann, warum bestimmte Einheiten als Vertreter einer Kategorie angesehen werden (\cite[47]{Goldberg.2006}). Anders als der prototypbasierte Ansatz geht der exemplarbasierte Ansatz zudem davon aus, dass Abstraktionen (wie bspw. \textit{Vögel haben Flügel}) nicht für die Kategorisierung genutzt werden, was die Frage offen lässt, warum Menschen dann die Fähigkeit haben, Eigenschaften zu abstrahieren (\cite[215]{Ross.1999}). \textcite[46]{Goldberg.2006} weist jedoch darauf hin, dass auch Exemplare eine Abstraktion beinhalten: Die Eigenschaften des Exemplars werden gewichtet, sodass die Eigenschaften, die in einem bestimmten Kontext relevanter sind als andere, mehr Beachtung finden. Eigenschaften, die nicht beachtet werden, werden nicht mental repräsentiert, sodass die Repräsentation immer abstrakter ist als das konkrete Exemplar. Zudem merkt \textcite[46]{Goldberg.2006} an, dass Eigenschaften auch wieder vergessen werden können, sodass auch deshalb die Repräsentation des Exemplars immer abstrakter ist als das Exemplar selbst. Somit ist auch im exemplarbasierten Ansatz Abstraktion angelegt.

Abbildung \ref{Vergleichexempl} zeigt Gemeinsamkeiten und Unterschiede von exemplar- und prototypbasierten Kategorien. Es zeigt sich, dass die erweiterte Version der Prototypensemantik bereits einige Eigenschaften mit dem exemplarbasierten Ansatz teilt. Der exemplarbasierte Ansatz zeichnet sich im Gegensatz zu den prototypbasierten Ansätzen durch seine Mehrdimensionalität und den Fokus auf einzelne Exemplare aus.

\begin{figure}
\includegraphics[width=\textwidth]{figures/Kap3/exemplarvsprototyp.pdf}  
\caption{Vergleich zwischen exemplarbasierten und prototypbasierten Kategorien}
\label{Vergleichexempl}
\end{figure}

Die hier diskutierten Ansätze können miteinander kombiniert werden, sodass die Vorteile beider Ansätze (Abstraktion und prototypische Staffelung der prototypischen Kategorien; Mehrdimensionalität der exemplarbasierten Kategorien) zum Tragen kommen: Eine Kategorie ist exemplarbasiert, wenn sie nur wenige Vertreter enthält. Wenn weitere Mitglieder hinzukommen, werden Abstraktionen über die Eigenschaften der Mitglieder geformt, die dann als abstrakte Repräsentation der Kategorie genutzt werden (siehe \cite[216--222]{Ross.1999} für empirische Evidenz zu kombinierten Ansätzen). Prototypisch organisierte Kategorien können somit als ein Resultat einer exemplarbasierten Kategorisierung gesehen werden. In diesem Ansatz ist der Prototyp ein Effekt (wie bereits in der erweiterten Version der Prototypensemantik in \sectref{standard}), der sich aus den Mitgliedern der Kategorie ergibt, die sich am ähnlichsten sind. Diese dienen als kognitiver Referenzpunkt, der eine Kategorisierung neuer Entitäten erlaubt (\cite[13]{Diessel.2017}). Die Organisation der Kategorie ist aber nicht allein durch die prototypische Struktur beeinflusst, da bestimmte Eigenschaften je nach deren kontextueller Relevanz berücksichtigt werden können. 

Betrachtet man prototypische Effekte auf diese Weise, können sie auch als ein Resultat von Frequenz betrachtet werden. Einerseits spielt Tokenfrequenz eine Rolle, da häufig auftretende Vertreter die Kategorisierung beeinflussen: Die Frequenz, mit der ein Vertreter auftritt, und die Wahrscheinlichkeit, dass dieser Vertreter als Prototyp wahrgenommen wird, korrelieren stark (\cite[85]{Goldberg.2006}). Andererseits spielt Typenfrequenz eine Rolle, da Vertreter mit vielen ähnlichen Eigenschaften die Kategorisierung beeinflussen.\footnote{Den Einfluss modelliert \textcite[51--73]{Goldberg.2019} unter dem Konzept der Abdeckung.} Vertreter mit prototypischen Eigenschaften werden somit in zweifacher Weise mental gestärkt: Zum einen ist der Vertreter mit prototypischen Eigenschaften i.~d.~R. tokenfrequent, zum anderen teilt er viele Eigenschaften mit anderen Vertretern der Kategorie und ist daher qua seiner Eigenschaften typenfrequent (\cite[85]{Ellis.2014}). Die Kombination aus Token- und Typenfrequenz bildet Lernpräferenzen ab: \textcite{Elio.1984} zeigen in einem Experiment, dass Kategorien besser gelernt werden, wenn zunächst nur die frequenten, prototypischen Vertreter berücksichtigt werden und erst im Anschluss die Kategorie erweitert wird. 



Der Einfluss der Frequenz wird ergänzt durch die Ähnlichkeit einzelner Exemplare zueinander. Die Ähnlichkeit zwischen den Exemplaren kann zu typischen Eigenschaften abstrahiert werden. Neben der Ähnlichkeit zwischen einzelnen Exemplaren ist die \textit{cue validity} der Eigenschaften relevant: Je distinkter die ähnlichen Exemplare in ihren Eigenschaften gegenüber anderen Exemplaren sind, desto eher werden sie auch als gesonderte Gruppe angesehen.  Bei der Kategorisierung spielen daher Typen- und Tokenfrequenz sowie die Ähnlichkeit der Vertreter zueinander und deren \textit{cue validity} eine Rolle. Daher sind Eigenschaften prototypisch, die von vielen frequenten Vertretern der Kategorie geteilt werden und distinkt gegenüber Eigenschaften anderer Kategorien sind. 

Im Folgenden werden prototypisch organisierte Kategorien als Resultat eines exemplarbasierten Lernens gesehen. Als prototypisch gelten dabei die Vertreter einer Kategorie, die häufig auftreten sowie die größte Ähnlichkeit zu anderen Vertretern der Kategorie aufweisen und somit eine hohe \textit{cue validity} haben: Sie teilen die meisten distinktiven Eigenschaften mit weiteren Vertretern der Kategorie und die wenigsten distinktiven Eigenschaften mit Vertretern anderer Kategorien. 



Prototypizität wird im weiteren Verlauf der Arbeit in zweifacher Weise relevant sein. Zum einen wird Prototypizität als Erklärungsansatz für Variation genutzt, denn Variation tritt vorrangig in der Peripherie einer Kategorie oder im Übergangsbereich zwischen zwei Kategorien auf (\cite[67--68]{Agel.2008}). So können die Funktionen zweier Konstruktionen in einem prototypisch organisierten Verhältnis zueinander stehen. Dies ist bspw. bei der Selektion von \textit{haben} und \textit{sein} der Fall: \textit{Haben} ist mit transitiven und atelischen Sätzen ohne Bewegungsverbsemantik assoziiert, \textit{sein} mit intransitiven Sätzen, die telisch sind und/oder Bewegungssemantik aufweisen (\cite[316--319]{Gillmann.2016}). Im Übergangsbereich der Funktionen sind Schwankungen zwischen \textit{haben} und \textit{sein} zu beobachten, wie bspw. in Sätzen mit Bewegungsverb, in denen das Objekt als Patiens oder als Instrument interpretiert werden kann (\textit{Ich bin/habe das Auto gefahren}) (siehe \sectref{selproto} zum Einfluss der Prototypizität auf die Auxiliarselektion für ausführliche Erläuterungen). Im empirischen Teil der Arbeit wird anhand der Selektion von haben und sein überprüft, ob sich Unterschiede in der Verarbeitung von prototypischen und peripheren Strukturen messen lassen. Zudem sind Form-Schemata prototypisch organisiert. So bildet die Form [Dreisilbigkeit, Pänultimabetonung, Schwa-Endung, + menschlich] ein Form-Schema innerhalb der Maskulina (\cite[168--176]{Kopcke.1995}). In der Peripherie des Form-Schemas sind Schwankungen möglich: Das Substantiv \textit{Bär} schwankt bspw. zwischen schwachen und starken Formen (\textit{des Bären/Bärs}), da das Substantiv nicht den prosodisch-phonologischen Eigenschaften des Form-Schemas entspricht (\cite[69]{Kopcke.2005}). Form-Schemata und deren Prototypizität werden im folgenden \sectref{steuerungschema} vorgestellt. Der Einfluss von Form-Schemata auf die Variation in der Konjugation und Deklination wird in den Abschnitten~\ref{schemaverb} und \ref{schemamask} diskutiert. Im empirschen Teil der Arbeit wird der Einfluss des Form-Schemas schwacher Maskulina auf die Prozessierung überprüft.

 
\begin{sloppypar}
Zum anderen wird Prototypizität genutzt, um die Reihenfolge von Schwankungsfällen bei Flexionsklassenwechseln zu erklären und zu prognostizieren. Dies baut auf der Beobachtung auf, dass die Eigenschaften von Flexionsklassen prototypisch gestaffelt sind: Je mehr Eigenschaften der einen Flexionsklasse aufgegeben werden, desto mehr Eigenschaften der anderen Flexionsklasse kommen hinzu. Somit ist zu erwarten, dass Eigenschaften einer Flexionsklasse, die nur wenige Mitglieder aufweisen (wie bspw. Imperativhebung), zuerst aufgegeben werden, während Eigenschaften, die viele Mitglieder aufweisen (Ablaut im Perfekt) als letztes aufgegeben werden. Zudem lassen sich anhand dieses Prinzips Verben und Substantive danach klassifizieren, ob sie ein für ihre Flexionsklasse prototypisches oder unprototypisches Flexionsverhalten aufweisen. Die Prototypizität von Flexionsklassen wird in den Abschnitten~\ref{protverb} und \ref{protmask} relevant sein, die die prototypisch organisierten Flexionseigenschaften starker und schwacher Verben sowie schwacher und starker Maskulina behandeln. 
\end{sloppypar}

\section{(Form-)Schematizität}\label{steuerungschema}\largerpage[-1]

Der Einfluss von (Form)-Schemata auf Variation ist bereits im letzten Abschnitt zu Prototypizität angeklungen. Im folgenden Abschnitt wird der Einfluss von (Form-)Schemata auf Variation ausführlich diskutiert. Hierfür wird zunächst der dieser Arbeit zugrundeliegende Schemabegriff definiert. 


Das Konzept der Schemata wird in verschiedenen wissenschaftlichen Disziplinen wie etwa der Psychologie, Kognitionspsychologie und Linguistik (\cite[447--450]{Bucker.2015}) genutzt. Dabei wird der Terminus aber nicht deckungsgleich verwendet. Als allgemeine Grundlage für den in dieser Arbeit relevanten Schemabegriff wird in \sectref{kognition} ein Ansatz aus der Kognitionspsychologie diskutiert, der Schemata als Wissenseinheiten auffasst. Darauf aufbauend wird in \sectref{konstruktion} der für diese Arbeit relevante Schemabegriff der Konstruktionsgrammatik vorgestellt und erweitert. Der Schemabegriff der Konstruktionsgrammatik verknüpft Schemata und Konstruktionen, indem Schemata als Konstruktionen gesehen werden, die eine abstrakte und somit hochschematische Form aufweisen (\cite{Goldberg.2006}). Neben Schemata in diesem Sinn werden die Termini \textit{Form-Schematizität} und \textit{Form-Schemata} neu eingeführt und von Schemata und Schematizität abgegrenzt. Unter \textit{Form-Schematizität} werden Konstruktionen gefasst, bei denen eine Funktion mit zwei (oder mehr) Formen verknüpft ist (bspw. [+Vergangenheit] mit den Formen Dentalsuffix, [\#\_aŋk] wie in \textit{trank} und [\#\_ɪt] wie in \textit{ritt}). Dabei ist eine der Formen hochschematisch (Dentalsuffix), während die anderen nicht-schematisch oder teilschematisch sind. Die Verbindung aus teilschematischer Form und Funktion wird dabei unter dem Terminus \textit{Form-Schema} gefasst. 


(Form)-Schemata bilden damit den dritten Faktor, der Einfluss auf Variation Einfluss nimmt. Dabei nimmt (Form-)Schematizität in verschiedener Weise Einfluss auf die hier diskutierten Variationsphänomene: In Hinblick auf \textit{haben} und \textit{sein} konkurrieren zwei Schemata miteinander, da \textit{haben} und \textit{sein} mit verschiedenen Funktionen verknüpft sind, die prototypisch organisiert sind. Bei der Variation in der Deklination und Konjugation ist hingegen eine Funktion mit verschiedenen Formen verknüpft. Diese Formen können teilschematisch sein und damit Form-Schemata bilden. Die Form-Schemata erhöhen die Wahrscheinlichkeit, dass die mit dem Form-Schema assoziierte Form genutzt wird. Der grundlegende Einfluss von Form-Schemata auf Variation wird in \sectref{schemaeffekt} näher diskutiert.

\subsection{Grundlegender Schemabegriff}
\label{kognition}

Innerhalb der Kognitionspsychologie wird mit einer sehr breiten Definition des Terminus \textit{Schema} gearbeitet (\cite{Rumelhart.1980}, \cite[25--26]{Barlow.1994}): \textcite[33]{Rumelhart.1980} sieht Schemata als "`building blocks of cognition"', dabei geht er davon aus, dass Schemata Wissenseinheiten darstellen und in allen Wissensdomänen relevant sind. \textcite{Rumelhart.1980} diskutiert beispielsweise das Schema \textsc{Einkaufen}, zu dem die Variablen \textsc{Ware}, \textsc{Käufer\_innen} und \textsc{Ver\-käu\-\mbox{fer\_in}\-nen }gehören. Eine ähnliche Auffassung von Schemata findet sich im Scenes and Frames-Modell nach \textcite{Fillmore.1977} (\cite[448--449]{Bucker.2015}). Schemata enthalten aber nicht nur Wissen an sich, sondern auch Anwendungsinformationen über dieses Wissen (\cite[34]{Rumelhart.1980}). So gehört zum Schema \textsc{Einkaufen} das Wissen, dass dieses Schema bspw. im Supermarkt angewandt werden kann. Als grundlegende Eigenschaften von Schemata sieht \textcite[34--41]{Rumelhart.1980} sechs Aspekte an:\pagebreak

\begin{enumerate}
\item Schemata haben Variablen
\item	Schemata betten ein
\item	Schemata repräsentieren Wissen auf allen Ebenen
\item Schemata repräsentieren Wissen, keine Definitionen
\item	Schemata sind aktive Prozesse
\item	Schemata sind Erkennungsvorrichtungen, deren Prozessierung evaluiert, wie gut sie zu den prozessierten Daten passen (\textit{goodness of fit})\\
(Übersicht nach \cite[26]{Barlow.1994})
\end{enumerate}

Die Variablen eines Schemas sind nach \textcite[35]{Rumelhart.1980} die mit dem Schema assoziierten Entitäten. So lässt das Schema \textsc{Einkaufen} eine\_n Verkäufer\_in und eine Kasse erwarten. Schemata können dabei selbst wiederum Schemata enthalten (\cite[37--40]{Rumelhart.1980}). So lässt sich etwa das Schema \textsc{Bezahlen} innerhalb des Schemas \textsc{Einkaufen} ausmachen (\cite[39--40]{Rumelhart.1980}). Schemata betten also ein. Sie sind nicht auf eine bestimmte Wissensebene begrenzt, sondern strukturieren auf allen Ebenen. Zudem hebt \textcite[40]{Rumelhart.1980} hervor, dass es sich bei Schemata um Wissen, nicht um Definitionen handelt. Schemata stellen aktive Prozesse dar, d.~h. sie sind keine festgeschriebenen und unveränderlichen Muster, sondern existieren aufgrund ihrer Anwendung. Ein Schema ist in diesem Sinne "`a procedure whose function it is to determine whether, and to what degree, it accounts for the pattern of observations"' (\cite[39]{Rumelhart.1980}). Der Hinweis auf die Passungsgüte (\textit{goodness of fit}), anhand derer Schemata evaluiert werden, ist ebenfalls grundlegend: Schemata basieren nicht auf einer distinkten Einteilung, sondern sind probabilistisch aufgebaut. Je ähnlicher eine Situation dem Schema ist, desto wahrscheinlicher ist die Aktivierung des Schemas (\cite[39]{Rumelhart.1980}). Schemata lassen sich somit gut mit einem bayesianischen Modell vereinen (siehe \sectref{Statistik}).



 \textcite[38]{Rumelhart.1980} geht davon aus, dass sich Schemata verselbstständigen können, sodass wir in einer Situation nicht mehr wissen, ob unsere Annahmen über die Situation aufgrund unserer Sinneswahrnehmung getroffen werden oder ob sie auf das Schema zurückgehen, von dem wir ausgehen, dass es in dieser Situation greift.\footnote{Für die Anwendung des Schemabegriffs nach Rumelhart auf sein in \sectref{Statistik} diskutiertes konnektionistisches \textit{parallel distributed processing model} siehe \textcite{Rumelhart.1986}.} So kann bspw. \textcite{Bar.2004} zeigen, dass Proband\_innen dasselbe Objekt je nach Bildkontext eindeutig als Föhn oder als Bohrer erkennen. Der Einfluss von Schemata wird auch in falschen Erinnerungen deutlich: Wenn Proband\_innen Wörter wie \textit{nurse, sick, hospital} hören, erinnern sich einige fälsch\-licherweise daran, auch \textit{doctor} gehört zu haben (\cite{Brainerd.2002}, \cite[100]{Goldberg.2019}). Die Wörter sind Teil eines Schemas (etwa \textsc{Krankheit}). Die falsche Erinnerung deutet darauf hin, dass das Schema aufgerufen wurde und daher weitere Vertreter des Schemas aktiviert wurden. 

Der kognitionspsychologische Zugriff auf Schemata kann für die grundlegende Ausrichtung des Schemabegriffs in dieser Arbeit fruchtbar gemacht werden. So werden die Variablen der (Form-)Schemata von starken Verben und schwachen Maskulina in den Abschnitten \ref{schemaverb} und \ref{schemamask} erarbeitet. Die Einbettung von Schemata zeigt, dass es nicht ausreicht, nur von einem einzigen Schema auszugehen, sondern dass Schemata Teil eines Makro-Schemas sein können (\cite[14--21]{Nesset.2008}, \cite[344--345]{Booij.2012}). Dieser Gedanke wird für Form-Schemata im Allgemeinen sowie für das Form-Schema schwacher Maskulina in \sectref{schemamask} relevant sein. Da in der vorliegenden Arbeit sprachliche Variationsphänomene verhandelt werden, ist lediglich der dritte Punkt (Schemata repräsentieren Wissen auf allen Ebenen) auf sprachliches Wissen einzuschränken (\cite[26]{Barlow.1994}). 



Die Idee der aktiven Prozesse deckt sich mit dem gebrauchsbasierten Ansatz, der dieser Arbeit zugrunde liegt: Schemata werden als Teil der allgemeinen kognitiven Fähigkeiten von Menschen aufgefasst, mithilfe derer Kategorien strukturiert werden. Der probabilistische Ansatz von Schemata verankert die Möglichkeit von Variation bereits in der Grundlage des Schemabegriffs: Schemata können einerseits Variation hemmen, wenn eine Struktur komplett zum Schema passt, aber andererseits auch zu Variation führen, wenn eine Struktur nur teilweise zum Schema passt oder Eigenschaften zweier Schemata aufweist. Hier zeigt sich, dass auch Prototypizität, die in \sectref{steuerungprot} vorgestellt wurde, für Schemata relevant ist. Im folgenden Abschnitt wird der Schema-Begriff geschärft, indem Schemata im Sinne der Konstruktionsgrammatik vorgestellt werden und die Unterscheidung zwischen Schematizität und Form-Schematizität eingeführt wird. Diese Unterscheidung wird auch verdeutlichen, warum eine separate Betrachtung von Prototypizität und Schematizität notwendig ist, um Variation umfassend modellieren zu können.

\subsection{Abgrenzung von Schematizität und Form-Schematizität}
\label{konstruktion}

Bevor Schemata aus Sicht der Konstruktionsgrammatik vorgestellt und um Form-Schemata erweitert werden können, müssen zunächst Konstruktionen näher in den Blick genommen werden. Konstruktionen sind Form-Funktions-Paare (\cite[467]{Lakoff.1987}). Mit dem sprachgebrauchsbasierten Ansatz ist anzunehmen, dass diese aus dem Gebrauch entstehen und daher erlernte Form-Funktions-Paare sind (\cite[5]{Goldberg.2006}).\footnote{\textcite[467]{Lakoff.1987} sowie \textcite[205]{Goldberg.1998} knüpfen Konstruktionen an Nicht-Vor\-her\-sag\-bar\-keit: Nur Form-Funktions-Paare, deren Form oder Funktion nicht vorhersagbar ist, sind Konstruktionen. \textit{Esser} ist in dieser Definition keine Konstruktion, da sich Form und Funktion anhand der Konstruktion \textit{ess} als Verbstamm und der Konstruktion -\textit{er} als Derivationssuffix vorhersagen lassen. \textit{Trinker} ist hingegen eine Konstruktion, da die Bedeutung \SchmittSingleQuot{abhängig von Alkohol sein} sich nicht aus dem Verbstamm \textit{trink} und dem Derivationssuffix -\textit{er} ergibt (\cite[185--186]{Stefanowitsch.2011}). \textcite[5]{Goldberg.2006} grenzt sich hiervon ab: "`[P]atterns are stored as constructions even if they are fully predictable as long as they occur with sufficient frequency"'. Diese Definition von Konstruktionen wird als Teil der gebrauchsbasierten kog\-nitiven Konstruktionsgrammatik gesehen (\cite[17]{Boas.2013}). Aus einer gebrauchsbasierten Perspektive ist davon auszugehen, dass auch ein Form-Funktions-Paar wie \textit{Esser} mental repräsentiert wird. Dies zeigt sich bspw. daran, dass Kollokationen wie \textit{ein guter Esser} existieren, in denen \textit{Esser} nicht ausgetauscht  werden kann (?\textit{ein guter Essender}) (\cite[185--186]{Stefanowitsch.2011}). Anhand der Tokenfrequenz wäre \textit{Esser} somit als Konstruktion zu bezeichnen.  Allerdings bleibt der Einfluss der Tokenfrequenz mit "`sufficient frequency"' bei \textcite[5]{Goldberg.2006} ähnlich wie bereits bei \textcite[715]{Bybee.2006b} in Bezug auf Konservierung und Autonomie unspezifiziert (siehe \sectref{typ}). Nicht nur Tokenfrequenz gibt einen Hinweis darauf, dass auch vorhersagbare Form-Funktions-Paare mental repräsentiert werden. Dies ist bereits im gebrauchsbasierten Ansatz angelegt: Um zu erkennen, dass ein Form-Funktions-Paar anhand der Bestandteile vorhersagbar ist, müssen zunächst mehrere mentale Repräsentationen existieren, von denen diese Erkenntnis abgeleitet werden kann. Um den konzeptionellen Unterschied zwischen vorhersagbaren und nicht-vorhersagbaren Form-Funktions-Paaren terminologisch fassen zu können, schlägt \textcite[569]{Stefanowitsch.2009} vor, nur Form-Funktions-Paare mit nicht-vorhersagbarer Komponente als \textit{Konstruktion} zu bezeichnen, vorhersagbare Form-Funktions-Paare hingegen als \textit{Muster}. Da diese Unterscheidung in dieser Arbeit jedoch nicht vordergründig verhandelt wird, werden mit \textcite[5]{Goldberg.2006} sowohl vorhersagbare als auch nicht-vorhersagbare Form-Funktions-Paare als Konstruktionen bezeichnet.} Dabei ist die Idee essentiell, dass Konstruktionen selbst Bedeutung tragen (\cite[203--205]{Goldberg.1998}, \cite[56--57]{Ellis.2014}, \cite[34--35]{Goldberg.2019}). Wie die Lexeme einer Sprache ein Lexikon formen, formen Konstruktionen ein Konstruktikon (\cite[36]{Goldberg.2019}).\footnote{Dabei stellen Lexeme ebenfalls Konstruktionen dar, da sie Form-Funktions-Paare sind. Genauso wie Lexeme können auch komplexere Konstruktionen Priming-Effekte auslösen (\cite{Johnson.2013}, \cite[33]{Goldberg.2019}): Proband\_innen sind in einer \textit{lexical decision task} bei der Beurteilung von Verben wie \textit{give} schneller, wenn ihnen zuvor eine semantisch kongruente Konstruktion mit Pseudowörtern (z. B. \textit{He daxed her the norp}) präsentiert wurde. Die Reaktionszeiten sind dagegen verlangsamt, wenn zuvor eine semantisch inkongruente Konstruktion präsentiert wurde. Dies ist unabhängig von der Frequenz des Verbs der Fall (\cite[1447--1451]{Johnson.2013}).} Dass Konstruktionen Bedeutung tragen, kann man anhand von Pseudowörtern leicht nachvollziehen: Das Verb \textit{kaschnitzen} existiert nicht, dennoch kann im Satz \textit{Ich kaschnitze im Raum herum} aufgrund der Konstruktion (X\textsubscript{NP\_Nom} X\textsubscript{VVFIN} im Raum herum) eine Bewegungssemantik erkannt werden. Die Semantik ergibt sich in diesem Fall also erst durch die Verwendung in der Konstruktion. Wie bereits in \sectref{proteffekt} deutlich wurde, können Konstruktionen auch real existierende Wörter in ihre Slots zwingen (\cite[198]{Taylor.1998}, \cite[37]{Goldberg.2019}), sodass ein eigentlich intransitives Verb transitiv genutzt werden kann (wie bspw. \textit{niesen} in \textit{Ich habe die Serviette vom Tisch geniest}). In dieser Hinsicht weisen Konstruktionen Ähnlichkeiten zu Schemata in der Kognitionspsychologie auf (siehe \sectref{kognition}).

\begin{sloppypar}
Konstruktionen und Schematizität sind miteinander verbunden, da die Bestandteile von Konstruktionen mehr oder weniger schematisch sein können: "`On the low end of the schematic scale, positions in constructions can be completely fixed; higher schematicity is a function of the range of variation within the category"' (\cite[80]{Bybee.2010}). Schematizität stellt dabei die substantielle Bedeutung einer Kategorie dar und kann sich auf semantische und phonologische Eigenschaften sowie "`more holistic patterns"' beziehen (\cite[80]{Bybee.2010}). Eine Redewendung wie \textit{Da brat mir doch einer 'nen Storch} ist demnach nicht schematisch, da die einzelnen Bestandteile der Konstruktion fest definiert sind. Dagegen ist die ditransitive Konstruktion hochschematisch, da sie sich aus variablen Bestandteilen zusammensetzt: \textit{Ich gebe dir ein Buch, Er klaut der Katze die Milch} und \textit{Ich schenke dir Essen} sind Instanzen der Konstruktion, deren Form sich mit X\textsubscript{NP\_Nom} X\textsubscript{VVFIN} X\textsubscript{NP\_Dat} X\textsubscript{NP\_Akk} formalisieren lässt. Hochschematische Konstruktionen wie bspw. die ditransitive Konstruktion werden als Schemata bezeichnet (\cite[5]{Booij.2010}, \cite[80]{Bybee.2010}). Schemata sind somit eine Teilmenge von Konstruktionen.  
\end{sloppypar}


Zwischen nicht- und hochschematischen Konstruktionen lassen sich teilschematische Konstruktionen ansiedeln. Hierunter fallen Konstruktionen mit offenen Slots, die aber Restriktionen aufweisen wie bspw. \textit{Das ist mir [egal, Wurst, Jacke wie Hose, schnurz]}. Die Produktivität eines Slots mit Restriktionen hängt dabei davon ab, wie ähnlich das potentielle neue Exemplar zu bestehenden Exemplaren im Slot ist (\cite[8]{BlumenthalDrame.2012}, \cite[17]{Diessel.2017}).\footnote{Diese Beobachtung lässt sich gut mit exemplarbasierten Kategorien verbinden: Bei Konstruktionen mit festen und offenen Slots enthält jedes Exemplar die Eigenschaften des festen Slots, dieser wird somit durch Tokenfrequenz gefestigt und hierdurch zum festen Slot (\cite[59]{Bybee.2013}). Beim offenen Slot herrscht hingegen Variation. Wenn zwischen den Exemplaren, die in diesem offenen Slot auftreten können, bspw. semantische Ähnlichkeiten existieren, wird hieraus eine Kategorie geformt (\cite[718]{Bybee.2006b}). In der Folge hat auch der offene Slot semantische Restriktionen.} Dieses Prinzip zeigt sich bspw. beim \textit{am}-Progressiv, der u.~a. mit \textit{activities} (\textit{Ich bin am Arbeiten}), aber (derzeit) nicht mit \textit{states} genutzt werden kann (\textit{*Ich bin am Wissen}) (\cite[181--184]{Flick.2016}).



Die Schematizität von Konstruktionen entsteht durch Gebrauch: Durch die häufige Verwendung werden die gemeinsamen Eigenschaften von Elementen in der Konstruktion gestärkt, als Cluster gebündelt und abstrahiert, weshalb ein Schema entsteht (\cite[xxiii]{Kemmer.2000}, \cite[218--220]{Langacker.2014}). \textcite[xxiii]{Kemmer.2000} fassen Schemata daher als "`cognitive representation[s] comprising a generalization over perceived similarities among instances of usage"'. Durch die Generalisierung sind hochschematische Konstruktionen produktiv. Teilschematischen Konstruktionen kann hingegen nur bedingt Produktivität zugesprochen werden, da potentielle Neuzugänge der teilschematischen Form entsprechen müssen und daher restringiert sind (\cite[67--69]{Bybee.2010}). 


 \textcite[62]{Bybee.2013} schlägt vor, Schematizität und Produktivität als separate Einflussfaktoren zu betrachten, da Schematizität und Produktivität zwar miteinander korrelieren, aber teilschematische Konstruktionen dennoch innerhalb der Restriktionen produktiv sein können (\cite[62]{Bybee.2013}). Als Beispiel nennt \textcite[62]{Bybee.2013} die \textit{to drive some\-one crazy}-Konstruktion, in der der \textit{crazy}-Slot produktiv ist, so lange Synonyme von \textit{crazy} genutzt werden (\textit{to drive someone mad}). Diesbezüglich lässt sich gut mit Goldbergs exemplarbasiertem Modell der Abdeckung argumentieren (siehe \sectref{typ} und \ref{exemplar}): Da die Adjektive \textit{crazy} und \textit{mad} die Eigenschaft [+verrückt] teilen, sind beide kompatibel mit der Konstruktion. Durch die Überlappung der Eigenschaft wird der Adjektiv-Slot zudem spezifiziert und auf Adjektive mit der Eigenschaft [+verrückt] beschränkt (\cite[72]{Goldberg.2019}). Dementsprechend können Cluster mit geringer Variabilität produktiv sein, solange die neuen Mitglieder sich innerhalb der beobachteten Variabilität befinden, wie im Beispiel der \textit{to drive someone crazy}-Konstruktion (\cite[67--69]{Bybee.2010}, \cite[65]{Goldberg.2019}).  Der Einfluss von Typenfrequenz und Ähnlichkeit auf Produktivität, der bereits in \sectref{typ} diskutiert wurde, zeigt sich an dieser Stelle erneut: Die Offenheit eines Slots ist einerseits abhängig von seiner Typenfrequenz, d.~h. von der Anzahl an verschiedenen Elementen, die in dem Slot verwendet werden können, und andererseits von der Ähnlichkeit der im Slot genutzten Elemente (\cite[8]{BlumenthalDrame.2012}).  Ähnlich argumentiert \textcite[16]{Diessel.2017}, der als Bedingung für die analogische Ausweitung von Schemata einerseits die Stärke der Aktivierung des Schemas (die von der Typenfrequenz abhängig ist) ansetzt und andererseits die Ähnlichkeit der Formen, die im Schema auftreten. 

In diesem Abschnitt wurden Konstruktionen bislang in Hinblick auf Syntax diskutiert, aber die konstruktionsgrammatische Idee ist nicht darauf beschränkt, sondern umfasst "`all levels of grammatical analysis"' (\cite[5]{Goldberg.2006}). Sie lässt sich daher auch auf Morphologie anwenden. So kann das Konjugationsverhalten unregelmäßiger Verben als nicht- sowie teilschematische Konstruktionen modelliert werden, da nur Verben mit einer bestimmten phonologischen Form ein bestimmtes (unregelmäßiges) Flexionsverhalten aufweisen können (\cite{Bybee.1982, Bybee.1983}, \cite[66--69]{Bybee.2010}). Die phonologische Form kann vollständig spezifiziert sein wie bspw. bei einem unregelmäßigen Verb wie \textit{sein}, dann liegt eine nicht-schematische Form vor. Die Form kann aber auch nur teilweise spezifiziert sein wie bei den Verben der Ablautreihe 3a und somit teilschematisch sein (\cite[450]{Bucker.2015}). Die regelmäßige Konjugation ist hingegen eine hochschematische Konstruk\-tion, da jedes Verb unabhängig von seiner phonologischen Form regelmäßig flektiert werden kann (\cite[67]{Bybee.2010}). Dieser Blick auf Konjugation wird von \textcite[86]{Bybee.1991} vorbereitet: Sie diskutiert die Teilschematizität der unregelmäßigen Konjugation und schlägt vor, (scheinbar) regelgeleitete Morphologie als schematische Konstruktion zu betrachten. 



Hierbei ist hervorzuheben, dass das Verhältnis zwischen Konstruktionen und Schematizität in Bezug auf Flexionsklassen anders gelagert ist als bei den oben diskutierten syntaktischen Konstruktionen. Während bei den oben diskutierten Konstruktionen eine Funktion mit einer mehr oder weniger abstrakten Form verbunden ist, ist bei den Flexionsklassen eine Funktion (z.~B. [+Ver\-gangenheit]) mit zwei oder mehr Formen verbunden.\footnote{Die Formen sowie die Funktion werden jeweils durch eckige Klammern ([]) als Teil des Schemas gekennzeichnet.} Eine der Formen ist hochschematisch und daher kaum gefüllt ([Dentalsuffix]),\footnote{Auch schwache Verben können teilschematisch motiviert sein (\cite[135]{Goldberg.2019}): So sind Verben, die auf /f/ enden, im Englischen regelmäßig (\textit{coughed, laughed, stuffed}); in \sectref{schemamask} wird diese Idee in Bezug auf starke und schwache Maskulina aufgegriffen.} die anderen Formen sind nicht- oder teilschematisch, da sie komplett (z.~B. [war]) oder weitgehend festgelegt sind (z.~B. [\#\_ a + ŋ + (C)]  wie in \textit{sank} in Bezug auf Verben der Ablautreihe 3a). Passt ein Verb nicht oder nur teilweise zu den nicht- oder teilschematischen Formen, kann es die Funktion [+Vergangenheit] stets mit der schematischen Form [Dentalsuffix] ausdrücken. 



Sieht man Konstruktionen als Resultat exemplarbasierten Lernens (siehe \sectref{Statistik}), ergibt es Sinn, dass nicht immer nur eine, sondern auch zwei (oder mehr) Formen mit einem Inhalt assoziiert sein können: Regelmäßiges Konjugationsverhalten kann anhand der Vielzahl und phonologischen Vielfalt von Verben, die dieses Verhalten aufweisen, generalisiert werden (\cite[67--68]{Goldberg.2019}; siehe \ref{typ}). Aber auch ein Flexionsverhalten, das vom Default-Verhalten abweicht, kann bis zu einem bestimmten Grad generalisiert werden: "`[C]lustering of `exceptions' leads speakers to generalize the behavior of exceptional cases"' (\cite[93]{Goldberg.2019}).  Die Generalisierung der Ausnahmen entsteht dabei aufgrund der partiellen Überschneidung der Eigenschaften einiger Exemplare (\cite[171]{Bybee.2007}, \cite[121]{Goldberg.2019}). So lässt sich aufgrund der Gemeinsamkeiten der Verben der Ablautreihe 3a die teilschematische Form [\#\_ a + ŋ + (C)] für den Inhalt [+Vergangenheit] abstrahieren. Die Teilschematizität schränkt das Abstraktionspotential und damit die Produktivität zwar ein, gleichzeitig führt sie aber auch zu einem Gangeffekt: "`[A] high concentration of verbs sharing phonetic properties is more likely to attract new members than one of comparable numbers without clear phonetic definition"' (\cite[69]{Bybee.2010}). Die Generalisierung teilschematischer Formen trägt daher zur "`Stabilität, Produktivität und Binnendifferenzierung [einer] Funktionsklasse"' bei (\cite[449]{Bucker.2015}). 

 
Da bei Flexionsklassen zwei (oder mehr) Formen mit einer Funktion verknüpft sind, können einzelne Verben nicht in eine Form gezwungen werden. Dies ist nur dann möglich, wenn lediglich eine Form mit einer Funktion verknüpft ist, sodass Elemente, die normalerweise nicht in einer bestimmten Form vorkommen, dennoch in diese gezwungen werden können, wenn sie zur Funktion passt (\cite[198]{Taylor.1998}, \cite[37]{Goldberg.2019}).

In Hinblick auf Variation sind bezüglich der Assoziation aus mehreren Formen und einer Funktion insbesondere die teilschematischen Formen relevant: Die Beziehung der teilschematischen Formen zur Funktion ist durch Familienähnlichkeit strukturiert (\cite[263]{Bybee.1983}). Es besteht also wie bei Schemata in der Kognitionspsychologie keine distinkte Einteilung, stattdessen stellt sich die Frage nach der Passungsgüte (\textit{goodness of fit}): Je besser eine Verbform zur Form [\#\_ a + ŋ + (C)] passt, desto wahrscheinlicher ist die Assoziation der Verbform mit [+Vergangenheit]. Passt ein Verb nur peripher zu dieser teilschematischen Form, kann es zu Schwankungen zwischen der teilschematischen und der schematischen Form mit Dentalsuffix kommen (z.~B. \textit{sann/sinnte}) (siehe \sectref{schemaeffekt} zu Form-Schema-Effekten und \sectref{schemaverb} und \ref{schemamask} zu Form-Schematizität als Einflussfaktor auf die Konjugation und Deklination). Die Assoziation zwischen einer teilschematischen Form und der Funktion ist somit prototypisch organisiert und probabilistisch (\cite[39]{Rumelhart.1980}, \cite[262--264]{Bybee.1983}). Abbildung~\ref{formschema} stellt am Beispiel der teilschematischen Form [\#\_ a + ŋ + (C)] das Verhältnis von hoch- und teilschematischer Form zur Funktion dar.  

\begin{figure}
\includegraphics[width=\textwidth]{figures/Kap3/formschema.png}
\caption{Verhältnis von hoch- und teilschematischer Form zur Funktion}
\label{formschema}
\end{figure} 

Die Assoziation zwischen Funktion und Formen lässt sich bayesianisch fassen, indem bspw. gefragt wird, wie wahrscheinlich die Assoziation mit [+Vergangenheit] ist, wenn eine bestimmte Wortform gegeben ist. Dabei ist eine Assoziation mit der schematischen Form immer möglich. Die Assoziation mit der teilschematischen Form hat eine höhere priore Wahrscheinlichkeit als die Assoziation mit der hochschematischen Form, wenn die gegebene Wortform die meisten Eigenschaften der teilschematischen Form mit hoher \textit{cue validity} aufweist und daher einen prototypischer Vertreter der teilschematischen Form darstellt. Diese Definition deckt sich mit der Definition eines Prototyps in \sectref{exemplar}. Die Assoziation zwischen einer teilschematischen Form und der Funktion [+Vergangenheit] blockiert die Assoziation der hochschematischen Form mit der Funktion nicht komplett, da man bspw. *\textit{sinkte} als Präteritalform erkennen kann, jedoch führt die Assoziation dazu, dass eine konventionelle Form existiert, die die unkonventionelle Form statistisch aussticht (zum statistischen Vorkaufsrecht siehe \cite[74--94]{Goldberg.2019} sowie \sectref{Statistik}).  Erfüllt die Form nur einige Eigenschaften der teilschematischen Form, ist die Assoziation mit der Funktion geschwächt, sodass auch die hochschematische Form genutzt werden kann (\textit{sann} > \textit{sinnte}), da die teilschematische Form die schematische nicht mehr so leicht dominieren kann. An dieser Stelle ist also Variation möglich.



Hinsichtlich der Assoziation von mehreren Formen mit einer Funktion ist von ineinander verschachtelten Schemata auszugehen. Die Assoziation einer teilschematischen Form wie bspw. [\#\_ a + ŋ + (C)] mit der Funktion [+Vergangenheit] führt zu einer Assoziation der dazugehörigen Wortformen mit einem bestimmten grammatischen Verhalten: Da die Form  [\#\_ a + ŋ + (C)] mit [+Vergangenheit] assoziiert ist, ist auch die Form [\#\_ ɪ + ŋ + (C)] mit dem Konjugationsverhalten der Verben der Ablautreihe 3a verbunden. Wir haben es somit mit einem Makro-Schema zu tun: Die Assoziation einer teilschematischen Form mit einer Funktion (z.~B. [\#\_ a + ŋ + (C)] mit [+Vergangenheit])  ermöglicht die Assoziation des gesamten Lexems mit einem bestimmten Flexionsverhalten. Das Makro-Schema (Lexem und Flexionsverhalten) lässt sich stets dahingehend herunterbrechen, dass die Flexionsformen mit einer bestimmten Funktion (z.~B.~[+Vergangenheit], [+Partizip~II]) verbunden sind (\cite[161]{Schmitt.2019}), weswegen die hochschematische Form statistisch ausgestochen wird (\cite[83--84]{Goldberg.2019}).  Das Form-Schema der Verben der Ablautreihe 3a wird in \sectref{schemaverb} näher erläutert. Form-Schemata können auch komplexer sein, als es bei den Verben der Ablautreihe 3a der Fall ist. Sie können auch semantische Merkmale enthalten, wie die Diskussion um das Form-Schema schwacher Maskulina in \sectref{schemamask} zeigt. Hierbei ist von ineinander verschachtelten Schemata auszugehen: Die phonologischen Eigenschaften Dreisilbigkeit, Pänultimabetonung, Schwa sind mit hoher Belebtheit assoziiert und dieses Schema wiederum ist mit schwacher Deklination verknüpft und bildet damit ein Form-Schema. Dieses spezielle Form-Schema wird ausführlich in \sectref{schemamask} vorgestellt. Darin wird auch diskutiert, welche Eigenschaften des Form-Schemas Einfluss auf die Deklination nehmen. 


Makro-Schemata können nicht nur in Bezug auf die teilschematische, sondern auch in Bezug auf nicht- und hochschematische Formen angesetzt werden. Die nicht-schematische Form \textit{war} ist mit [+Vergangenheit] assoziiert, auch hier sticht die Assoziation andere Formen statistisch aus und assoziiert \textit{sein} mit unregelmäßiger Flexion. Genauso führt die Verknüpfung der hochschematischen Form [Dentalsuffix] mit [+Vergangenheit] zur Assoziation eines Verbs mit regelmäßiger Flexion. Makro-Schemata lassen sich in diesem Hinblick als Resultat exemplarbasierten Lernens fassen: Zunächst werden eine Wortform und eine Funktion verknüpft, dann das Lexem und ein bestimmtes grammatisches Verhalten. An beiden Punkten ist eine Erweiterung auf Wörter mit ähnlichen Eigenschaften möglich: Dadurch, dass Wörter mit ähnlichen Eigenschaften wiederholt dieselbe Funktion aufweisen, kann eine (teil-)sche\-matische Repräsentation der Form abstrahiert werden (\cite[161]{Schmitt.2019}). \textcite[18--21]{Nesset.2008} verfolgt mit \textit{second-order} Schemata einen ähnlichen Ansatz: Schemata wie die oben genannten Verbindungen aus Form und Funktion bei Vergangenheit und Partizip~II, die \textcite[18--21]{Nesset.2008} \textit{first-order} Schemata nennt, können zu einem \textit{second-order} Schema zusammengeführt werden, sodass paradigmatische Beziehungen entstehen. \textcite{Kopcke.2017} und \textcite{Kopcke.2021} zeigen in einem Experiment zur Wahrnehmung von Pseudowörtern als Singular- oder Pluralform, dass Proband\_innen sich in der Bewertung sowohl auf \textit{first-order} als auch auf \textit{second-order} Schemata im Sinne Nessets verlassen. Kinder mit Deutsch als L1 verlassen sich dabei zunächst verstärkt auf \textit{first-order} Schemata, bevor sie sich auf \textit{second-order} Schemata stützen. Dies spricht dafür, dass \textit{second-order} Schemata auf Basis von \textit{first-order} Schemata abstrahiert werden.  
  

Nicht nur in Bezug auf zwei Formen, die mit einer Funktion assoziiert sind, kann es zu Variation kommen (\textit{sann/sinnte}). Auch in Hinblick auf Konstruktionen, bei denen nur eine Form mit einer Funktion assoziiert ist, ist dies möglich. So können die Funktionen zweier Schemata prototypisch gestaffelt und die jeweiligen Pole der Funktionen daher mit unterschiedlichen Formen assoziiert sein. Dies lässt sich bspw. bei der Auxiliarselektion von \textit{haben} und \textit{sein} beobachten, die u.~a. durch Transitivität beeinflusst wird (siehe hierzu ausführlich \sectref{selproto}). Transitive Sätze selegieren \textit{haben}, intransitive (in telischen Sätzen und Sätzen mit Bewegungssemantik) \textit{sein} (\cite[316--319]{Gillmann.2016}). Wir haben es also mit zwei separaten Schemata zu tun, die einem Makro-Schema ([+Perfekt]) angehören. Variation tritt auf, wenn die Funktion nicht eindeutig transitiv oder intransitiv ist, wie bspw. bei einem Objekt, das sowohl als Patiens als auch als Instrument interpretiert werden kann (\textit{Ich habe/bin den Porsche gefahren};  \cite[282]{Gillmann.2016}). Abbildung \ref{schemahaben} stellt die prototypisch organisierte Beziehung zwischen den beiden Funktionen schematisch dar, die zu Variation in der Form führen. 

\begin{figure}
\includegraphics[width=\textwidth]{figures/Kap3/schemahaben.png}
\caption{Prototypisch organisierte Beziehung zwischen zwei Funktionen separater Schemata}
\label{schemahaben}
\end{figure} 


Im Folgenden werden zwei Arten von Schematizität unterschieden. Der Terminus \textit{Schematizität} wird genutzt, um auf die Abstraktheit der Form bei Konstruktionen zu referieren; als \textit{Schema} werden dabei hochschematische, also abstrakte Konstruktionen bezeichnet (\cite[5]{Booij.2010}, \cite[80]{Bybee.2010}).  Wenn zwei (oder mehr) Formen, die sich durch ihren Schematizitätsgrad unterscheiden, um die Assoziation mit einer Funktion konkurrieren, wird dies unter dem Terminus \textit{Form-Schematizität} gefasst. Dabei werden teilschematische Konstruktionen in Abgrenzung zur hochschematischen Konstruktion (sowie von nicht-schematischen Konstruktionen wie \textit{war} und [+Vergangenheit]) \textit{Form-Schema} genannt. Bei der Form-Schematizität stehen sich somit Schema (hochschematische Form) und Form-Schema (teilschematische Form) gegenüber.\footnote{Die Benennung der teilschematischen Konstruktion als \textit{(Form-)Schema} lehnt sich an \textcite[129]{Bybee.1985} an. Sie führt den Terminus \textit{Schema} in Bezug auf Flexionsklassen ein, um teilschematische Konstruktionen zu bezeichnen. Dies ist gegenläufig zur Benennung hochschematischer Konstruktionen als \textit{Schema}  (\cite[5]{Booij.2010}, \cite[80]{Bybee.2010}) und m.~E. darauf zurückzuführen, dass die Assoziation zwischen Form und Funktion zunächst nur für unregelmäßige Verben diskutiert wurde (bspw. von \cite{Bybee.1983}). Die Idee, regelmäßige Verben als Assoziation zwischen einer abstrakten Form und einer Funktion zu sehen, entstand meines Wissens erst später und findet sich bspw. bei \textcite[86]{Bybee.1991}.}   


Schemata und Form-Schemata sind eng mit Prototypizität verknüpft. Schemata können in prototypischer Beziehung zueinander stehen, wie bei der Selektion von \textit{haben} und \textit{sein}. Genauso  zeigt sich bei Form-Schemata eine prototypische Organisation. Dennoch ist es wichtig, Prototypizität und (Form-)Schematizität zu unterscheiden: (Form)-Schemata und sind Form-Funktionspaare, während Prototypizität ein Ordnungsprinzip darstellt, das sich auf (Form)-Schemata anwenden lässt. Wenn zwei separate Schemata durch die prototypische Beziehung zwischen zwei Funktionen verbunden sind und daher im Übergangsbereich der Funktionen Schwankungen zwischen den Formen der Schemata zu beobachten sind, wird dies in der vorliegenden Arbeit als prototypisch bedingte Konkurrenz zwischen zwei ansonsten separaten Schemata gesehen und als Effekt der Prototypizität verhandelt. Bei Form-Schemata geht es dagegen um die prototypisch-organisierte Assoziation zwischen einer teilschematischen Form, die mit einer anderen Form um eine Funktion konkurriert. 

 
Schemata wurden anhand der Schematizität von Konstruktionen bereits ausführlich vorgestellt und diskutiert; im weiteren Verlauf dieses Abschnitts sowie in Abschnitt~\ref{schemaeffekt} wird daher auf Form-Schemata fokussiert.       


Wichtig bei der Betrachtung von Schemata und Form-Schemata ist der unterschiedliche Status von Typenfrequenz. Für Form-Schemata ist typenfrequenz essentiell, da nur eine relativ typenfrequente Form innerhalb der typeninfrequenten Flexion stark genug mit der jeweiligen Funktion assoziiert sein kann, um die typenfrequente konkurrierende Form statistisch auszustechen. Bei Schemata spielt Typenfrequenz hingegen eine untergeordnete Rolle: Da hier zwei Formen jeweils mit zwei separaten Funktionen assoziiert sind, kann die typenfrequente die typeninfrequente nicht so leicht statistisch ausstechen. Die typenfrequente Fom ist mit einer anderen Funktion assoziiert und damit greift das statistische Vorkaufsrecht nicht. Genau wie Schemata können auch Form-Schemata komplex sein und selber ein Schema enthalten. Die Unterscheidung, ob separate Schemata oder Form-Schemata vorliegen, hängt immer daran, ob eine Funktion oder mehrere Funktionen mit den verschiedenen Formen verbunden sind. Bei \textit{haben} und \textit{sein} haben wir es mit zwei Funktionen zu tun, was man leicht daran erkennen kann, dass Verben in das Schema gezwungen werden können, wenn sie transitiv bzw. intransitiv verwendet werden, auch wenn sie eigentlich mit dem jeweils anderen Schema assoziiert sind. Dies zeigt sich bspw. bei \textit{heizen}: \textit{Heizen} ist zwar intransitiv, aber weder ein Bewegungsverb noch telisch, daher bildet es das Perfekt mit \textit{haben} (\textit{Ich habe geheizt}). Wird es jedoch metaphorisch verwendet, um auf schnelles Fahren zu verweisen, wechselt das Auxiliar aufgrund der Bewegungssemantik zu \textit{sein} (\textit{Ich bin durch die Gegend geheizt}). Dasselbe Prinzip zeigt sich bei Verben, die aufgrund ihrer Telizität normalerweise mit \textit{sein} verknüpft sind wie bspw. \textit{verderben}. Sobald diese transitiv genutzt werden, weisen diese \textit{haben} als Auxiliar auf (\textit{Das Salz hat die Suppe verdorben}). Im Gegensatz dazu können weder einzelne Verben noch einzelne Maskulina können in ein Form-Schema gezwungen werden. Das liegt daran, dass nicht zwei Funktionen wie z.B. transitiv und intransitiv gegenüber stehen, sondern teilschematische Formen mit einer hochschematischen um eine Funktion konkurrieren. 

\textcite{Kopcke.1993} beschäftigt sich mit Form-Schematizität in der Pluralbildung des Deutschen. Die Pluralbildung im Deutschen lässt sich als Form-Schematizität auffassen, da auch hier eine Funktion [+Plural] mit mehreren Formen (z.~B. -\textit{e}, -\textit{s}) assoziiert ist (\textit{Autos}, \textit{Tische}). \textcite{Kopcke.1993} arbeitet nicht mit der Unterscheidung von Schema und Form-Schema, sondern sieht jeweils die Verbindung aus Form und Funktion als Schema, die er als "`ausdrucksseitige Gestalt, der eine spezifische Regelhaftigkeit in dem Sinne anhaftet, daß sie ein bestimmtes Konzept [...] wiederholt ausdrucksseitig repräsentiert"' definiert (\cite[72]{Kopcke.1993}). 


\textcite[82--83]{Kopcke.1993} geht davon aus, dass den verschiedenen Formen, die mit einer Funktion assoziiert sein können, eine unterschiedliche Signalstärke zukommt. Formen mit höherer Signalstärke geben einen besseren Hinweis auf die Funktion als Formen mit niedriger Signalstärke. Indem \textcite[82--83]{Kopcke.1993} die Signalstärke von Typen- und Tokenfrequenz, akustischer Salienz und \textit{cue validity} beeinflusst sieht,\footnote{Zusätzlich zu diesen Eigenschaften geht \textcite[83]{Kopcke.1993} davon aus, dass Form-Schematizität durch Ikonizität befördert werden. Hierbei greift er auf die Natürlichkeitsmorphologie nach \textcite{Wurzel.1984} zurück, indem er davon ausgeht, dass Plural durch ein Mehr an Form ikonisch dargestellt wird (\cite[83]{Kopcke.1993}). Diese Eigenschaft ist jedoch m. E. nicht auf Form-Schematizität im Allgemeinen übertragbar, weswegen der Verbindung zwischen Ikonizität und Signalstärke hier nicht weiter auf den Grund gegangen wird.} nimmt er implizit die in \sectref{standard} diskutierten Einflussfaktoren auf Typizität auf.   



\textcite[82]{Kopcke.1993} selbst erläutert den Einfluss der Typen- und Tokenfrequenz nicht, allerdings führt er sie in späteren Publikationen aus. So argumentiert er, dass -\textit{en} als Pluralmarker typen- und tokenfrequenter  und damit prototypischer ist als andere Pluralmarker (\cite[83]{Kopcke.2017}). Auch aus \sectref{typ} wird deutlich, dass frequente Exemplare sowie Exemplare mit frequent auftretenden Eigenschaften als prototypisch (für Form-Schemata) gelten können. So schreiben \textcite[67]{Bybee.2010} und \textcite[75]{Poitou.2004} Form-Schemata\footnote{Weder \textcite{Bybee.2010} noch \textcite{Poitou.2004} nutzen den Terminus \textit{Form-Schema}. \textcite{Poitou.2004} verwendet auch den Terminus \textit{Schema} nicht, sondern \textit{Prototyp}. Beide referieren jedoch auf Form-Funktions-Paare mit teilschematischer Form, die in dieser Arbeit als Form-Schema modelliert werden.} mit vielen Vertretern eine höhere Produktivität und Anziehungskraft zu als Form-Schemata mit wenigen Vertretern. Akustische Salienz definiert \textcite[82]{Kopcke.1993} relativ unspezifisch mit "`Bestimmung des Ausmaßes, mit dem eine morphologische Markierung vom Hörer identifizierbar ist"'. Als Beispiel nennt er segmentierbare Pluralmarkierungen wie -\textit{s} oder -\textit{er}, denen er aufgrund ihrer Segmentierbarkeit sowie der Positionierung am Ende des Worts eine höhere Salienz zuschreibt als dem Umlaut, der lediglich ein Begleitphänomen ist (\cite[82]{Kopcke.1993}).  

 
\begin{sloppypar}
Die \textit{cue validity} benutzt \textcite[82]{Kopcke.1993} deckungsgleich wie in \sectref{typ} erläutert. Je zuverlässiger eine Form eine Funktion repräsentiert, desto größer ist deren \textit{cue validity}: "`A category has high cue validity if the features associated with it frequently occur with members of the category, and rarely occur with members of other categories"' (\cite[266]{Bybee.1983}). So ist die \textit{cue validity} von -\textit{s} geringer als die \textit{cue validity} von -\textit{er}, da -\textit{s} auch den Genitiv markiert (\cite[82--83]{Kopcke.1993}).\footnote{\textcite[83]{Kopcke.1993} geht jedoch davon aus, dass die Genitivmarkierung nur einen geringen Störfaktor darstellt, da der Artikel die Konstruktion i.~d.~R. desambiguiert (\textit{des Autos} vs. \textit{die Autos}). In der Diskussion um \textit{cue validity} scheint \textcite{Kopcke.1993} nur auf Konkurrenzformen innerhalb der Flexion einzugehen. Betrachtet man auch Wortbildung, stellt sich die Frage, ob die \textit{cue validity} von -\textit{er} ebenfalls herabgesenkt ist, weil es auch als Wortbildungselement genutzt wird.}  In Bezug auf unregelmäßige Verben im Englischen stellen \textcite[266]{Bybee.1983} fest, dass /ʌŋ/ und /ʌŋk/ eine hohe \textit{cue validity} für Vergangenheit aufweisen, da nur zwei Verben in ihrer Grundform auf /ʌŋk/ (\textit{flunk} und \textit{dunk}) enden. /ʌŋ/ hat dabei eine noch größere \textit{cue validity}, da keine Verben und nur wenige Substantive und Adjektive  (z.~B. \textit{tongue}, \textit{lung}, \textit{dung}) /ʌŋ/ aufweisen. 
\end{sloppypar}

Der Abschnitt hat Schemata und Form-Schemata als verwandte Konzepte herausgearbeitet. Schemata sind abstrakte und damit hochschematische Konstruktionen. Konkurrieren zwei (oder mehr) Formen um die Assoziation mit einer Funktion, wird dies als Form-Schematizität bezeichnet. Eine der Formen ist hochschematisch, die anderen teil- oder nicht-schematisch. Die Verbindung aus teilschematischer Form und Funktion wird dabei als Form-Schema bezeichnet. Form-Schemata lassen sich somit als probabilistische Assoziationen zwischen einer teilschematischen Form und einer Funktion fassen, die eine Assoziation einer hochschematischen Form mit derselben Funktion statistisch aussticht (zum statistischen Vorkaufsrecht siehe \cite[74--94]{Goldberg.2019} sowie \sectref{Statistik}). Der teilschematischen Form kommt dabei eine hohe \textit{cue validity} zu, sodass die Form eng mit der Funktion assoziiert ist.


Form-Schemata nehmen Einfluss auf Variation: Prototypische Vertreter des Form-Schemas weisen keine Variation auf, da sie die hochschematische Form statistisch ausstechen können. In der Peripherie der teilschematischen Form kann es dagegen zu Schwankungen kommen, da das statistische Vorkaufsrecht hier nicht mehr vollständig greift. Dieser Effekt wird bei der Betrachtung der Variation in der Deklinatino und Konjugation eine zentrale Rolle spielen. Im folgenden Abschnitt werden Effekte genauer vorgestellt, die durch Form-Schemata ausgelöst werden.

\subsection{Form-Schema-Effekte}
\label{schemaeffekt}

\textcite{Bybee.1983} überprüfen den Einfluss des Form-Schemas [\#\_ʌ + velarer und\slash oder nasaler Konsonant] und [+Vergangenheit] auf die Flexion im Englischen. In ihrer Studie sollen Proband\_innen Vergangenheitsformen von Pseudoverben bilden. Dabei nehmen \textcite{Bybee.1983} an, dass der Ablaut auf /ʌ/ für Pseudoverben am wahrscheinlichsten ist, die in ihrer Grundform /s/CC am Silbenanfang, /ɪ/ als Stammvokal und einen velaren Nasal in der Silbencoda haben (wie das Verb \textit{string}).  Diese spezifische Form lässt sich durch die Verben der Klasse~II\footnote{\textcite[252]{Bybee.1983} arbeiten mit zwei Verbklassen: Klasse~I enthält Verben mit dem Ablautmuster x - \ae\ - ʌ, Klasse II Verben mit dem Ablautmuster x - ʌ - ʌ. Diese Klasseneinteilung beruht nicht auf Ablautreihen. Beide Klassen gehen m.~E. auf die Ablautreihe 3a zurück. Dies verdeutlichen Verben der Ablautreihe 3a wie \textit{singen} und \textit{spinnen}. Sie sind kognat mit den Verben \textit{sing} und \textit{spin}, die Klasse~I bzw. Klasse~II angehören.} erklären (\cite[257--258]{Bybee.1983}): Die meisten Verben der Klasse~II haben s-haltige Konsonantencluster, /ɪ/ als Stammvokal und /ŋ/.\footnote{Neun von achtzehn Verben der Klasse~II beginnen mit einem s-haltigen Konsonantencluster. \textcite{Bybee.1983} gehen nicht explizit darauf ein, warum sie /ɪ/ als Stammvokal annehmen, allerdings findet sich dieser Vokal auffällig häufig bei real existierenden Verben der Klasse~II (\cite[252]{Bybee.1983}). Auch hinsichtlich der Silbencoda ist davon auszugehen, dass /ŋ/ besser in das Form-Schema passt als /ŋk/, da /ŋ/ häufiger in Klasse~II zu beobachten ist (\cite[257]{Bybee.1983}).} Die Ergebnisse des Pseudowortexperiments bestätigen die Hypothese: Pseudoverben mit /s/CC am Silbenanfang, /ɪ/ als Stammvokal und einem velaren Nasal in der Silbencoda weisen im Experiment mit 44 \% den größten Anteil an Ablautungen auf /ʌ/ auf.\footnote{Leider schlüsseln \textcite{Bybee.1983} nicht auf, auf welche Flexionsformen die restlichen Prozente entfallen. Aufgrund der Aufschlüsselungen zu einzelnen Bestandteilen des Form-Schemas ist davon auszugehen, dass sich diese auf das Dentalsuffix -\textit{ed} und den Ablaut /\ae/ verteilen.} Die Produktivität des Form-Schemas kann zudem diachron nachvollzogen werden (\cite[263, 265--266]{Bybee.1983}): Anders als andere Klassen unregelmäßiger Verben des Englischen hat die Klasse~II Verben angezogen (bspw. \textit{to hang}).  

Die einzelnen Slots der Form (Silbenanfang, Vokal, Silbencoda) haben einen unterschiedlich großen Einfluss auf die Kompatibilität eines Verbs mit dem Form-Schema. So hat der velare Nasal einen größeren Einfluss als das Anfangscluster: Wird statt des velaren Nasals ein anderer (weder velarer noch nasaler) Konsonant (/v/, /t/, /d/, /p/ oder /d/) verwendet, fällt die /ʌ/-Ablautrate auf 4~\%, während sie sich bei Ersetzung des Anfangsclusters durch einen einfachen Konsonanten bei 24~\% hält (\cite[261]{Bybee.1983}). Die Silbencoda scheint das Flexionsverhalten also stärker zu beeinflussen als der Anfang. Als Erklärung hierfür führen \textcite[264]{Bybee.1983} an, dass Flexion im Englischen durch Suffixe ausgedrückt wird und die Silbencoda in der Flexion somit mehr im Fokus steht als der Silbenanfang.



 Einen noch geringeren Einfluss als der Silbenanfang hat allerdings der Vokal: /\ae/ als Stammvokal evoziert ähnlich häufig den Ablaut auf /ʌ/ wie der als ideal angenommene Vokal /ɪ/. \textcite[255--256]{Bybee.1983} gehen davon aus, dass die Zielform (\textit{strung}) für das Form-Schema eine größere Rolle als die Ursprungsform (\textit{string}) spielt. Aufgrund der Ablautung beeinflusst der Stammvokal das Form-Schema daher kaum.\footnote{\textcite[255--256]{Bybee.1983} nennen diese Modifikation daher \textit{product oriented}, weil allein das Produkt im Vordergrund steht.  \textit{Product oriented} wird dabei als Gegensatz zu \textit{source oriented} verwendet. Bei dieser Modifikation steht die paradigmatische Beziehung von zwei Formen zueinander im Vordergrund (\cite[171]{Bybee.2007}). Hierbei kommt wiederum Nessets Unterscheidung von \textit{first-} und \textit{second-order} Schemata zutragen: \textit{First-order} Schemata sind \textit{product oriented}, da allein die Beziehung von Funktion und Form im Vordergrund steht und nicht die Beziehung der Ursprungsform zur flektierten Form. \textit{Second-order} Schemata sind dagegen \textit{source oriented}, weil hier die Beziehung zwischen den Wortformen relevant ist. \textit{Second-order} Schemata entstehen aus \textit{first-order} Schemata (\cite[77]{Kopcke.2021}), starke und schwache Konjugation gehen somit nicht auf unterschiedliche Modifikationen zurück, sondern auf denselben Prozess, wobei sich schwache Formen lediglich leichter zu \textit{second-order} Schemata generalisieren lassen als starke Formen.  } 



Den geringen Einfluss des Vokals begründen \textcite{Bybee.1983} auch diachron, da ursprünglich nur Verben mit dem Stammvokal /ɪ/ den Ablaut auf /ʌ/ bildeten, inzwischen aber auch andere Stammvokale möglich sind wie bspw. /iː/ und /{\textbottomtiebaraɪ}/ (\textit{to sneak}, \textit{to strike}) (\cite[255]{Bybee.1983}). Zudem zeigen Konsonantenveränderungen, die Proband\_innen innerhalb des Pseudowortexperiments von \textcite{Bybee.1983} vornahmen, dass die Zielform für das Form-Schema wichtiger zu sein scheint als die Ursprungsform: So wurden zu dem Stimulus \textit{to spriv} die Vergangenheitsformen \textit{sprung} und \textit{sprug} gebildet. Hier wurde die Silbencoda von /v/ zu /ŋ/ bzw. /g/ verändert und somit dem Form-Schema angepasst (\cite[263]{Bybee.1983}).



Neben dem unterschiedlichen Einfluss einzelner Slots (Silbenanfang, Stammvokal, Silbencoda) zeigt sich, dass die Slots selbst prototypisch organisiert sind (\cite[260]{Bybee.1983}). In der Silbencoda ist der velare Nasal /ŋ/ am besten kompatibel mit dem Form-Schema, da er zu 37~\% Ablautung auf /ʌ/ hervorruft. Wenn bspw. mit der Nasalität eine Eigenschaft entfällt, ist der Konsonant weniger geeignet: /k/ und /g/ führen zu weniger Ablautungen (14~\%). Ähnlich verhalten sich die nicht-velaren Nasale /n/ und /m/ mit 15~\% Ablautung auf /ʌ/. Entfällt sowohl die Eigenschaft [+velar] als auch [+nasal], ist die Kompatibilität weiter herabgesetzt: /p/, /b/ und /v/ rufen nur zu 2 \% Ablautung auf /ʌ/ hervor (\cite[260]{Bybee.1983}). 



Die Passungsgüte innerhalb einzelner Slots lässt sich also sehr exakt anhand von Lauteigenschaften (wie bspw. Nasalität) bestimmen. Dabei nehmen die Slots an sich und die Passungsgüte innerhalb der Slots Einfluss auf die Kompatibilität eines Verbs mit dem Form-Schema. Zudem haben die Slots nicht nur einzeln einen Einfluss auf die Wahrscheinlichkeit der Ablautung auf /ʌ/, sondern wirken sich auch gemeinsam auf die Ablautung auf /ʌ/ aus: Je mehr prototypische Vertreter der einzelnen Slots vorhanden sind, desto wahrscheinlicher wird die Ablautung auf /ʌ/ (\cite[261--261]{Bybee.1983}). Auch hier zeigt sich die prototypische Organisation von (Form-)Schemata (\cite[135]{Bybee.1988}). 



  \textcite{Kopcke.2021} zeigen in Pseudowortstudien die Form-Schematizität von Pluralformen im Deutschen auf. Dabei stellen sie zum einen fest, dass den unterschiedlichen Pluralformen unterschiedliche Signalvalidität zukommt. So ist -\textit{en} ein besserer Marker für Plural als ein Nullmarker, weil die meisten Substantive im Deutschen eine Pluralmarkierung aufweisen. Pseudowörter auf -\textit{en} werden daher eher pluralisch interpretiert als solche ohne Pluralmarkierung (\cite[10--19]{Kopcke.2021}). Zudem stellen sie fest, dass ihre Proband\_innen nicht nur auf \textit{first-order} Schemata zurückgreifen, sondern auch auf \textit{second-order} Schemata. Werden die Versuchswörter mit dem Artikel \textit{die} präsentiert, werden Substantive auf -\textit{e} seltener als Plural angesehen, als wenn die Versuchswörter ohne \textit{die} präsentiert werden: Die Kombination aus \textit{die} und Substantiv fördert die Assoziation mit einem Femininum. Für ein Femininum ist die Opposition aus auf Schwa endenden Singular und einer Pluralform auf -\textit{en} wahrscheinlich, daher wird die Pluralinterpretation für -\textit{e} bei \textit{die} + Pseudosubstantiv dispräferiert (\cite[18]{Kopcke.2021}). Die Studie zeigt zudem, dass bei ambigen Formen (z.B. Formen auf -\textit{e} und mit Umlaut und -\textit{e}) die Reaktionszeiten im Vergleich zu stark mit Singular oder Plural assoziierten Formen (-\textit{en}, -\textit{s} für Plural, Nullmarkierung für Singular) erhöht sind (\cite[19]{Kopcke.2021}).   

Aufgrund der prototypischen Struktur haben Form-Schemata sowohl einen variationshemmenden als auch einen variationstreibenden Effekt in der Flexionsmorphologie. Einerseits hemmen Form-Schemata Variation, weil Vertreter eines Form-Schemas sich gegenseitig stützen. Für tokeninfrequente Verben des Englischen mit /s/CC am Silbenanfang, /ɪ/ als Stammvokal und einem velaren Nasal in der Silbencoda ist Variation hin zur regelmäßigen Konjugation auf -\textit{ed} somit weniger wahrscheinlich als für andere unregelmäßige Verben mit ähnlicher Frequenz, die aber keinem Form-Schema angehören. In diesem Sinne sind Form-Schemata eine Art Gegenspieler zur Typenfrequenz (siehe \sectref{steuerungfreq}), welcher die typeninfrequente Flexionsklasse vor dem Abbau bewahrt. Gleichzeitig kann man Form-Schemata als typenfrequentes Cluster innerhalb einer typeninfrequenten Klasse sehen: Erst wenn viele Vertreter einer typeninfrequenten Klasse eine bestimmte Form aufweisen, können sie sich gegenseitig stützen und neue Mitglieder anziehen.

 
\begin{sloppypar}
Form-Schemata können andererseits Variation befeuern: Zum einen kann eine Form nur teilweise dem Form-Schema entsprechen. Die Assoziation zwischen Form und Funktion ist in diesem Fall weniger stark, weswegen die Funktion auch mithilfe der hochschematischen Form (also bspw. durch Dentalsuffix) ausgedrückt werden kann, da sie nicht mehr statistisch ausgestochen wird. Zum anderen können Formen existieren, die zwar formal zum Form-Schema passen, allerdings dennoch die Funktion mithilfe der hochschematischen Form ausdrücken. In diesem Fall kann es aufgrund der Ähnlichkeit zu den Vertretern des Form-Schemas zu Schwankungen in der Form kommen, wie bspw. bei  \textit{winken}, das eigentlich schwach flektiert, aber aufgrund der Ähnlichkeit zu Verben der Ablautreihe 3a mit \textit{gewunken} auch ein starkes Partizip aufweist (siehe hierzu genauer \sectref{schemaverb}). Neben der Entwicklung hin zur teilschematischen Form besteht auch die Möglichkeit, die Form so zu verändern, dass die Passungsgüte zu dem anziehenden Form-Schema verringert wird. Dies ist bspw. bei schwachen Maskulina wie \textit{Friede} der Fall, die einen geringen Belebtheitsgrad aufweisen und somit nicht zum Form-Schema passen, aber bezüglich der prosodisch-phonologischen Eigenschaften dem Form-Schema schwacher Maskulina entsprechen. Sie nehmen -\textit{n} im Nominativ an (\textit{der Frieden}) (\cite[173]{Kopcke.1995}) und werden hierdurch dem Form-Schema unähnlicher, da sie nicht mehr auf Schwa enden (siehe hierzu ausführlich \sectref{schemamask}).\footnote{Als weiteres Beispiel lassen sich die Pluralmarker des Deutschen nennen (\cite[119--120]{Kopcke.1993}). Im Frühneuhochdeutschen existierten zahlreiche Feminina, deren Nominativ Singular auf -\textit{n} endete (\textit{die küchen}, \textit{die lügen}, \textit{die reden}). Da -\textit{n} sich als Pluralmarkierung für Feminina durchsetzte, führt die \textit{n}-haltige Nominativform im Singular zur irreführenden Assoziation mit der Funktion [+Plural]. Daher wurde -\textit{n} in den Singularformen zum Neuhochdeutschen hin getilgt (\textit{die Küche}, \textit{die Lüge}, \textit{die Rede}), sodass die Singularform nicht mehr einer Form gleicht, die mit Plural assoziiert ist (\cite[119]{Kopcke.1993}). Auf diese Weise wurde auch die \textit{cue validity} von -\textit{n} als Marker für Plural gestärkt.}
\end{sloppypar}

Der Abschnitt hat Schemata und ihren Einfluss auf Variation betrachtet. Dabei wurden zwei Arten von Schemata ausgearbeitet: Der erste Typus von Schemata sind abstrakte Konstruktionen. Hier kann es aufgrund der prototypischen Organisation zu Variation kommen, bspw. wenn die Funktionen zweier Schemata prototypisch organisiert sind, wie bei der Auxiliarselektion von \textit{haben} und \textit{sein}. Dies wird in der Arbeit als Prototypeneffekt gefasst, da die Schemata abseits der prototypischen Verbindung der Funktionen separat sind. Für den Abschnitt war daher vornehmlich der zweite Typus von Schemata relevant: Form-Schemata. Form-Schemata sind Verbindungen einer Funktion (z.~B. [+Vergangenheit]) mit einer teilschematischen Form (z.~B. [\#\_ a + ŋ + (C)]). Dabei ist die Funktion jedoch nicht nur mit der teilschematischen Form, sondern mit mehren Formen mit unterschiedlichem Schematizitätsgrad verbunden, im Fall der Funktion [+Vergangenheit] bspw. auch mit der hochschematischen Form [Dentalsuffix]. Es liegt somit Form-Schematizität vor. Form-Schemata nehmen vorranging innerhalb von typeninfrequenten Flexionsklassen Einfluss auf Variation: Sie stabilisieren die Flexion der typeninfrequenten Klasse, da sie eine Typenfrequenz innerhalb der Typeninfrequenz darstellen. Der Einfluss von Form-Schemata zeigt sich dabei auch bei Pseudowörtern. Aufgrund ihres probabilistischen Aufbaus können Form-Schemata auch zu Variation führen, bspw. wenn ein Verb nur teilweise zur Form des Form-Schemas passt. Hier kann es zu Schwankungen hin zur hochschematischen Form kommen (\textit{sann} > \textit{sinnte}).  Außerdem kann das Form-Schema neue Mitglieder anziehen, wie starke Partizip-II-Formen des ursprünglich schwachen Verbs \textit{winken} zeigen, dessen phonologische Eigenschaften zum Form-Schema der Verben der Ablautreihe~3a passen. Der Einfluss von Form-Schemata auf die Variation in der Konjugation und Deklination wird in den Abschnitten~\ref{konjugation} und \ref{deklination} näher erläutert. Im empirischen Teil der Arbeit wird der Einfluss von Form-Schemata auf die Variation überprüft, indem Substantive mit periphere und prototypischer Form des Form-Schemas schwacher Maskulina gegenübergestellt werden. Der folgende Abschnitt fasst den Einfluss von Frequenz, Prototypizität und Schematizität auf Variation zusammen und diskutiert, wie die Einflussfaktoren interagieren.


\section{Zusammenfassung: Variation aus gebrauchsbasierter Perspektive}\label{zusvar}
\begin{sloppypar}
Im gebrauchsbasierten Ansatz sind mentale Repräsentationen und damit auch Sprachsysteme eine Konsequenz des Sprachgebrauchs, sodass Frequenz einen grundlegenden Einfluss auf Variation hat. Wie fundamental Frequenz den Sprachgebrauch formt, wird bspw. anhand der Zipfschen Verteilung deutlich: Im Sprachgebrauch existieren wenige hochfrequente Elemente und viele niedrigfrequente (\cite[22--27]{Zipf.1972}, \cite[13]{Ellis.2012}). Der grundlegende Einfluss der Frequenz zeigt sich außerdem darin, dass sie den Einfluss von Prototypizität und (Form-)\-Schematizität auf Variation erst ermöglicht.
\end{sloppypar}
 

Frequenz kann Variation fördern und hemmen. Hierbei ist zunächst festzustellen, dass tokenfrequente Elemente generell gefestigter und damit leichter zu aktivieren sind als tokeninfrequente (\cite[380]{Bybee.1997}, \cite[13]{Schneider.2014}). Hohe Tokenfrequenz führt also zu Stabilität, geringe kann zu Variation führen. Existieren mehrere Kategorien (bspw. Flexionsklassen) mit unterschiedlicher Typenfrequenz\footnote{Im Sinne der Form-Schematizität lässt sich diese Konstellation auch als Assoziation zwischen mehreren Formen mit unterschiedlichem Schematizitätsgrad und einer Funktion fassen.}, ist zudem ein Zusammenspiel aus Token- und Typenfrequenz zu beobachten. Die typenfrequentere Kategorie ist produktiv\footnote{Produktivität hängt dabei aber nicht allein an Typenfrequenz, sondern ist zusätzlich von der Variabilität der Vertreter einer Kategorie und der Ähnlichkeit eines potentiellen neuen Vertreters zu bereits bestehenden Exemplaren in der Kategorie abhängig. Alle drei Faktoren (Typenfrequenz, Variabilität, Ähnlichkeit) fasst \textcite[62--63]{Goldberg.2019} unter dem Prinzip der Abdeckung.} (\cite[384]{Bybee.1997}), weist ein regelmäßiges Verhalten auf und die Mitglieder der Klasse sind i.~d.~R. nicht tokenfrequent. Im Gegensatz dazu sind typeninfrequente Kategorien i.~d.~R. nicht produktiv\footnote{Mit Ausnahme von Form-Schemata, die produktiv sein können, wenn der potentielle Neuzugang den bereits vorhandenen Exemplaren ähnelt (\cite[6]{Bybee.2010}, \cite[62--63]{Goldberg.2019}).} und flektieren unregelmäßig. Die Mitglieder von typeninfrequenten Kategorien weisen zudem eine hohe Tokenfrequenz auf (\cite[380]{Bybee.1997}, \cite[166]{Ellis.2002b}). Diese fördert Unregelmäßigkeit: Durch die hohe Tokenfrequenz sind die unregelmäßigen Formen mental stark gefestigt. Zudem sind die Wortformen eines hochfrequenten Worts weniger stark miteinander verknüpft als die Wortformen eines infrequenten Worts (\cite[117--118]{Bybee.1985}, \cite[715]{Bybee.2006b}). Gleichzeitig führt die hohe Tokenfrequenz aufgrund des \textit{entrenchments} zu einem konservierenden Effekt und macht einen Wechsel in die typenfrequente Klasse unwahrscheinlich \parencites[117]{Bybee.1985}[619--621]{Bybee.2002}. 



Verliert ein Vertreter der typeninfrequenten Kategorie an Frequenz, ist die mentale Repräsentation der unregelmäßigen Formen weniger stark gefestigt und ein Wechsel in die typenfrequente Klasse wird wahrscheinlicher. Typenfrequenz gibt somit bei konkurrierenden Flexionsklassen die Variationsrichtung vor: Mitglieder der typeninfrequenten Klasse wechseln zur typenfrequenten. Tokenfrequenz kann innerhalb der typeninfrequenten Klasse einen konservierenden Effekt haben: Mitglieder mit hoher Tokenfrequenz bleiben in der typeninfrequenten Klasse. Tokenfrequenz kann neben der Konservierung auch zu Autonomie und Reduktion führen: Häufige Elemente können sich von der Ursprungskonstruktion lösen und häufig zusammen auftretende Elemente können als ein einziges Element wahrgenommen (\textit{chunking}) und in der Folge phonologisch verschmolzen werden (\cite[378--384]{Bybee.1997}). 



Die hier beschriebenen Frequenzeffekte lassen sich gut in einem konnektionistisches Modell vereinen, in dem Wortformen untereinander verbunden sind. Hierbei liegt exemplarbasiertes Lernen zugrunde. Regelmäßiges Flexionsverhalten kann somit als eine Generalisierung gesehen werden, die anhand von vielen Exemplaren mit hoher Variabilität vollzogen wird. Den Inhalt der Generalisierung stellen dabei die wiederkehrenden Eigenschaften der Exemplare dar, wie bspw. die Form [Dentalsuffix] oder die Funktion [+Vergangenheit] (\cite[67--68]{Goldberg.2019}). Das konnektionistische Modell verdeutlicht zudem, dass eine Operationalisierung von Tokenfrequenz als reine Wortwiederholung nicht ausreicht, um deren Einfluss zu modellieren \parencites[150--152]{Ellis.2002b}[57--58]{Divjak.2015}, sondern dass bspw. auch die Frequenz anderer ähnlicher Wörter betrachtet werden muss und die Frequenz, mit der Wörter gemeinsam auftreten. 


\begin{sloppypar}
Frequenzeffekte lassen sich als priore Wahrscheinlichkeit in ein bayesianisches Modell integrieren. Dies verdeutlicht das bayesianisch konzipierte statistische Vorkaufsrecht nach \textcite[74--94]{Goldberg.2019}: Frequente Strukturen haben eine hohe priore Wahrscheinlichkeit aufzutreten und können daher konkurrierende Strukturen mit geringerer Frequenz statistisch ausstechen (\cite[74--94]{Goldberg.2019}).\footnote{Dies ist nur der Fall, wenn beide Strukturen mit gleicher Funktion und im gleichen Kontext genutzt werden. Ist die infrequente Struktur mit einer anderen Funktion oder einem anderen Kontext assoziiert als die frequente Struktur, greift das statistische Vorkaufsrecht nicht, da die Strukturen nicht miteinander konkurrieren (\cite[74--94]{Goldberg.2019}).} Das statistische Vorkaufsrecht kann dabei als Erklärung für das Zusammenspiel aus Typen- und Tokenfrequenz bei Konjugations- und Deklinationsklassen herangezogen werden: Die Formen der typenfrequenten, regelmäßigen Klasse sind theoretisch für jedes Verb bzw. Substantiv möglich. Gehört ein Verb oder Substantiv der typeninfrequenten Klasse an und ist tokenfrequent, haben die unregelmäßigen Formen aber aufgrund der Tokenfrequenz eine höhere priore Wahrscheinlichkeit als regelmäßige Formen und können diese statistisch ausstechen. Bei geringer Tokenfrequenz greift das Vorkaufsrecht nur noch eingeschränkt, da die priore Wahrscheinlichkeit für die unregelmäßigen Formen aufgrund der geringen Frequenz herabgesenkt ist. Im empirischen Teil der Arbeit wird der Einfluss von Tokenfrequenz auf Variation anhand von starken Verben mit unterschiedlicher Tokenfrequenz überprüft.
\end{sloppypar}
 
Neben der Frequenz beeinflusst Prototypizität kognitive Kategorien und damit auch Variation. Prototypisch organisierte Kategorien sind Ergebnis eines exemplarbasierten Lernens: Zunächst werden einzelne Exemplare einer Kategorie durch Gebrauch erlernt, Verbindungen zwischen ihnen gezogen und die Kategorie anschließend anhand der Gemeinsamkeiten der Exemplare abstrahiert (\cite[206--209]{Goldberg.1998}, \cite[216--222]{Ross.1999}). Als Ankerpunkt für eine analogische Ausweitung der Kategorie dienen vorrangig prototypische Exemplare: Exemplare mit ähnlichen Eigenschaften wie die prototypischen Exemplare werden als der Kategorie zugehörig betrachtet (\cite[89]{Goldberg.2006}, \cite[242]{Ellis.2016}, \cite[51--73]{Goldberg.2019}).\footnote{Dies schließt eine Erweiterung der Kategorie anhand von anderen Vertretern nicht aus, die prototypischen Vertreter haben nur eine höhere Wahrscheinlichkeit, als Ausgangspunkt für Analogien zu fungieren.} Hierdurch entsteht die Familienähnlichkeit prototypisch organisierter Kategorien. Aufgrund der Familienähnlichkeit ergeben sich Prototypeneffekte: Vertreter mit typischen Eigenschaften werden bspw. schneller prozessiert, als Erste genannt und lassen sich durch den Kategoriennamen primen (\cite{Rosch.1975b}, \cite[38--39]{Kleiber.1993}, \cite[45]{Taylor.1995}, \cite[85]{Ellis.2014}).

 
Prototypizität fördert und hemmt Variation: Prototypische Vertreter sind in ihrer Verwendung stabil, während bei peripheren Vertretern Variation wahrscheinlich ist. Dies liegt an der probabilistischen Struktur prototypisch organisierter Kategorien: Je mehr Eigenschaften ein Element hat, die als typisch für die Kategorie wahrgenommen werden, desto wahrscheinlicher ist es, dass das Element als Teil der Kategorie wahrgenommen wird. Daher ist für ein Element auch eine stabile Verwendung wahrscheinlicher, wenn es mehr Eigenschaften der Kategorie erfüllt. Hier wird wiederum der Einfluss von Frequenz deutlich. Dieser zeigt sich auch darin, dass Vertreter mit typischen Eigenschaften einer Kategorie frequenter sind als Vertreter mit peripheren Eigenschaften (\cite[85]{Ellis.2014}). Tokenfrequenz scheint also die Vertreter mit typischen Eigenschaften zu stützen. Außerdem werden die typischen Eigenschaften durch Typenfrequenz hervorgebracht: Erst wenn sich viele Vertreter bestimmte, distinkte Eigenschaften teilen, kann daraus eine Kategorie mit prototypischer Struktur abstrahiert werden. Dabei ist die \textit{cue validity} der Eigenschaften relevant: Je mehr Eigenschaften eines Elements nur in einer Kategorie vorkommen, aber nicht in einer anderen, desto eher kann man das Element eindeutig einer Kategorie zuordnen (\cite[575]{Rosch.1975c}, \cite[52]{Kleiber.1993}).  



Die prototypische Struktur von Kategorien findet sich auch in Flexionsklassen: Das Verhalten von Flexionsklassen ist prototypisch und graduell organisiert. Es lässt sich daher nutzen, um Vorhersagen über die Reihenfolge zu machen, in der Schwankungen auftreten. Dabei werden zunächst periphere Eigenschaften der Flexion der typeninfrequenten Klasse aufgegeben, dann prototypische. Auch hier zeigt sich, dass Variation in der Peripherie wahrscheinlicher ist als für Prototypen. Der Einfluss von Prototypizität auf Variation wird im empirischen Teil der Arbeit anhand der Selektion von \textit{haben} und \textit{sein} überprüft.   

Neben Frequenz und Prototypizität nimmt (Form-)Schematizität Einfluss auf Variation. Dabei ist zwischen zwei Arten von Schema und Schematizität zu unterschieden. Der Terminus \textit{Schematizität} meint den Abstraktheitsgrad von Konstruktionen. Als Schemata werden Konstruktionen bezeichnet, die eine hochschematische Form aufweisen (\cite[5]{Booij.2010}, \cite[80]{Bybee.2010}). Unter dem Terminus \textit{Form-Schematizität} werden Konstruktionen verhandelt, bei denen zwei (oder mehr) Formen mit einer Funktion verknüpft sind. Eine Form ist dabei hochschematisch, die anderen teilschematisch oder nicht-schematisch.\footnote{Hierbei ist jeweils von einem Makro-Schema auszugehen: Eine Verbform (z.~B. Dentalsuffix) ist mit der Funktion [+Vergangenheit] verknüpft und in der Folge das gesamte Lexem mit einem bestimmten (in diesem Beispiel regelmäßigen) Flexionsverhalten.} Eine solche Verteilung lässt sich bei Flexionsklassen beobachten: Die hochschematische Form stellt dabei die typenfrequente, regelmäßige Klasse dar. Aufgrund der vielen und vielfältigen Mitglieder kann ein regelmäßiges Flexionverhalten abgeleitet werden (\cite[67--68]{Goldberg.2019}).  Die Assoziation aus einer teilschematischen Form und einer Funktion wird als Form-Schema bezeichnet. Form-Schemata sind typisch für typeninfrequente, unregelmäßige Klassen.\footnote{Form-Schemata sind für die typenfrequente Klasse jedoch nicht ausgeschlossen, siehe hierzu \sectref{schemamask}, in dem Form-Schemata starker Maskulina diskutiert werden.} Sie entstehen wie die hochschematische Form durch exemplarbasiertes Lernen. Da das Cluster jedoch aus sehr ähnlichen Lexemen besteht, sind die über die Lexeme hinweg beobachtbaren Eigenschaften Teil der Generalisierung, sodass eine teilschematische Form abstrahiert wird (\cite[121]{Goldberg.2019}). Ergebnis des exemplarbasierten Lernens ist die prototypisch organisierte Form von Form-Schemata: Je mehr Eigenschaften ein Element mit der Form des Form-Schemas gemein hat, desto wahrscheinlicher ist die Assoziation mit der Funktion und desto eher kann das Form-Schema die hochschematische Form statistisch ausstechen (\cite{Rumelhart.1980, Bybee.1983, Kopcke.1993}).  Das Prinzip der prototypisch aufgebauten Kategorien zeigt sich somit auch bei Form-Schemata. Aufgrund der prototypisch organisierten Form sind Form-Schemata probabilistisch und können deshalb gut bayesianisch modelliert werden. Zudem lassen sich Form-Schemata als Effekt der Typenfrequenz fassen, da viele Vertreter benötigt werden, um die teilschematische Form zu abstrahieren \parencites[430]{Bybee.1995}[67--69]{Bybee.2010}[67]{Goldberg.2019}. 


\begin{sloppypar}
Form-Schemata haben einen variationshemmenden Effekt. Sie stechen die konkurrierende, hochschematische Form statistisch aus und stützen daher Mitglieder typeninfrequenter Flexionsklassen. Dieser Effekt wird im empirischen Teil der Arbeit anhand des Form-Schemas schwacher Maskulina überprüft. Umgekehrt kann ein Form-Schema Variation auslösen, wenn die Verknüpfung von hochschematischer Form und Funktion für Elemente gilt, die der teilschematischen Form des Form-Schemas ähneln wie bei \textit{winken} (\cite{Kopcke.1999}). In diesem Fall kann es zu Schwankungen weg von der hochschematischen Form und hin zu der teilschematischen kommen (\textit{gewinkt > gewunken}).
\end{sloppypar}

\begin{sloppypar}
Nicht nur Form-Schemata beeinflussen Variation, sondern auch separate Schemata, deren Funktionen prototypisch organisiert sind (z.~B. [\textit{haben}] und [+Transitivität, −Telizität, −Bewegungssemantik] sowie [\textit{sein}] und [−Transitivität, +Telizität oder +Bewegungssemantik], siehe hierzu ausführlich \sectref{selproto}). An den prototypischen Enden der Funktionen ist die Assoziation eindeutig, zu Schwankungen kann es jedoch im Übergangsbereich zwischen den Funktionen kommen. Hier könnten beide Schemata greifen und somit beide Formen genutzt werden. Dies wird in der vorliegenden Arbeit als Prototypizitätseffekt verhandelt, da die Schwankung nicht zwischen zwei Formen, die mit einer Funktion verbunden sind, stattfindet, sondern zwischen zwei Schemata. 
\end{sloppypar}

Insgesamt zeigt das Kapitel, dass Frequenz, Prototypizität und (Form-)Sche\-ma\-ti\-zi\-tät grundlegenden Einfluss auf Variation ausüben. Der Einfluss der Frequenz ist dabei am prominentesten. Er zeigt sich deutlich im \textit{entrenchment} tokenfrequenter Elemente, das zu einer stabilen mentalen Repräsentation und Verwendung der Elemente führt. Bei Flexionsklassen reicht ein Blick auf Tokenfrequenzen nicht aus, da hier Typen- und Tokenfrequenz relevant sind: Variation ist bei tokeninfrequenten Mitgliedern der typeninfrequenten Klasse wahrscheinlich, da die Formen der typeninfrequenten Klasse aufgrund der geringen Tokenfrequenz weniger gefestigt sind und daher die konkurrierenden Formen der typenfrequenten Klasse nicht mehr statistisch ausstechen können. 


Prototypizität beeinflusst Variation, da prototypische Vertreter einer Kategorie i.~d.~R. stabil genutzt werden, während periphere Mitglieder Variation aufweisen können. Dies zeigt sich bspw. bei Schemata wie der Auxiliarselektion von \textit{haben} und \textit{sein}, deren Funktionen prototypisch verknüpft sind. Zudem ermöglicht es Prototypizität, Flexionsklassen graduell mit peripheren und prototypischen Eigenschaften zu modellieren. Auf diese Weise können Schwankungen von der typeninfrequenten zur typenfrequenten Flexionsklasse prognostiziert werden. Diese beginnen mit der Aufgabe von peripheren Eigenschaften und können bis hin zur Aufgabe von prototypischen Eigenschaften reichen. 

 
Der Einfluss der Prototypizität auf Variation ist auch essentiell für Form-Sche\-ma\-ta. Form-Schemata stützen als relativ typenfrequente, wenig variable Cluster in der typeninfrequenten  Klasse das Flexionsverhalten der typeninfrequenten Klasse. Auf diese Weise kann die hochschematische Form der typenfrequenten Klasse auch bei relativ geringer Tokenfrequenz statistisch ausgestochen werden. Form-Schemata sind probabilistisch aufgebaut, sodass prototypische Vertreter eines Form-Schemas stabil flektieren, während Schwankungen bei peripheren Vertretern hin zum regelmäßigen, typenfrequenten Flexionsverhalten wahrscheinlich sind. Der Einfluss der Frequenz, Prototypizität und Form-Schematizität und ihr Zusammenwirken wird im nächsten Kapitel in Hinblick auf Variation in der Konjugation, Deklination und der Auxiliarselektion bei \textit{haben} und \textit{sein} näher betrachtet.
