\chapter{General discussion} \label{sec:chapter-discussion}

In this book I investigated two research questions on fragments with experimental methods: First, which syntactic structure underlies fragments? And second, why do speakers use fragments at all? The results of my experiments contribute both to the research on fragments and to that on information-theoretic\is{Information theory} constraints on language production and processing.

The experiments on the syntax of fragments in the first part of this book constitute the first systematic investigation of a series of predictions derived from currently competing theories of fragments. Previously, many of these theories were founded only on partially conflicting introspective data that had not been empirically verified with experiments or corpus studies\is{Corpus}. The experiments in Chapter \ref{sec:chapter-experiments-syntax} furthermore provide relatively theory-independent insights into the form that fragments can take: Fragments can be non-constituents, they exhibit case connectivity\is{Case connectivity} and short answer fragments\is{Fragment, short answer} tend to match the form of their antecedent. These properties have to be taken into account by future theoretical research on fragments.

In the second part of this book, I developed an information-theoretic\is{Information theory} account of fragment usage, which explains when fragments are preferred over full sentences and which words are preferably omitted in fragments. The central predictions of this account are confirmed by two experiments. From the perspective of the research on fragments, this constitutes the first attempt to answer the almost unexplored question of why people use fragments at all that is empirically supported by actual linguistic data. From a psycholinguistic perspective, the finding that omissions in fragments are constrained by UID\is{Uniform Information Density} extends the evidence for UID\is{Uniform Information Density} in two ways. First, I find UID\is{Uniform Information Density} effects on the omission of content words, whereas previous research focused mostly on semantically relatively vacuous function words. Second, I show that not only linguistic context\is{Context, linguistic}, but also script-based\is{Script knowledge} extralinguistic context\is{Context, extralinguistic} modulates the predictability and consequently the reduction of words and utterances. Previous research on UID\is{Uniform Information Density} estimated surprisal\is{Shannon information} almost exclusively based on local linguistic context\is{Context, linguistic}, i.e. \textit{n}-gram\is{N-gram language model} surprisal\is{Shannon information}. In contrast to this, I developed a method to quantify effects of extralinguistic context\is{Context, extralinguistic} based on script knowledge\is{Script knowledge} and a new approach to estimating surprisal\is{Shannon information}.

\section{Results on the syntax of fragments}
The first goal of my research was to investigate what structure underlies fragments. Although diverse and mutually exclusive accounts of fragments have been proposed previously, most of these theories have been supported only by introspective data, but not by empirical evidence from corpus studies\is{Corpus} or experiments. The experiments in Chapter \ref{sec:chapter-experiments-syntax} constitute the first systematic investigation of a series of theoretical predictions of competing theories of fragments. These studies investigated two research questions on the syntax of fragments. Firsst, are fragments underlyingly sentential? And, second, are fragments generated by movement and deletion\is{Movement and deletion account}?

These questions differentiate between the main generative\is{Generative grammar} accounts of fragments: the nonsentential account\is{Nonsentential account} by \citet{barton.progovac2005}\is{Nonsentential account}, the in situ deletion\is{In situ deletion account} account by \citet{reich2007} and the movement and deletion\is{Movement and deletion account} account by \citet{merchant2004}. Since these theories make differing predictions on which fragments are grammatical, distinguishing between the theories is not only relevant from a theoretical perspective: The investigation of the usage of fragments also requires to know which utterances can be derived by grammar, because UID\is{Uniform Information Density} accounts only for variation within the limits of grammar \citep{jaeger2010}. In what follows I briefly summarize the main results and their implications for the theoretical analysis of fragments, before I review syntactic properties of fragments that are supported by my experiments and which must be taken into account by any theory of fragments and any empirical study on their usage.

\subsection{Fragments are underlyingly sentential}
\subsubsection{Case connectivity indicates unarticulated structure in fragments}

Experiments \ref{exp:case}--\ref{exp:scripts-rating-case} suggest that fragments contain unarticulated linguistic material, as sentential accounts of fragments assume. This is evidenced by structural case\is{Structural case} connectivity effects\is{Case connectivity} on DP\is{Determiner phrase} fragments. Structural case\is{Structural case} marks the relationship between words and, unlike inherent\is{Inherent case} case, it does not encode a specific \texttheta-role. In the case of the German\il{German} accusative\is{Accusative case} which I tested in my experiments it marks a DP\is{Determiner phrase} as the direct object of the verb. If a DP\is{Determiner phrase} fragment can appear in structural case\is{Structural case}, this suggests that there is a silent verb in such DP\is{Determiner phrase} fragments, because otherwise the accusative\is{Accusative case} cannot be checked. Relying on structural case\is{Structural case} as evidence for unarticulated structure is especially convenient because the presumable unacceptability\is{Acceptability rating task} of structural case\is{Structural case} marking is a crucial property of fragments according to the nonsentential account\is{Nonsentential account} by  \citet{barton.progovac2005}.

The experiments provide evidence for case connectivity\is{Case connectivity} and hence support a sentential account of fragments: Experiment \ref{exp:case} shows that accusative\is{Accusative case} DP\is{Determiner phrase} fragments are more acceptable than nominative\is{Nominative case} DP\is{Determiner phrase}s in contexts where accusative\is{Accusative case} is licensed in a full sentence. Experiment \ref{exp:case-production} validates this finding with a production study\is{Production task} that confirms that accusative\is{Accusative case} is indeed more likely than nominative\is{Nominative case} in the contexts tested in experiment \ref{exp:case}. Experiment \ref{exp:scripts-rating-case} rules out the possibility of a mixed account\is{Mixed account} of fragments, according to which fragments can be derived both by ellipsis and as genuine nonsententials, depending on whether context provides sufficient evidence for ellipsis resolution or not. Finally, experiment \ref{exp:pstranding-defaultcase}, whose main objective was testing an alternative explanation of the P-stranding generalization, also disconfirms the prediction of the nonsentential account\is{Nonsentential account} that prepositional case\is{Prepositional case}-marked DP\is{Determiner phrase} fragments are degraded as compared to default case\is{Default case}-marked ones.

\subsubsection{Implications for the theoretical analysis of fragments}

Among the theories of fragments that I discussed, case connectivity\is{Case connectivity} provides evidence for a sentential account of fragments. This conclusion crucially hinges on the assumption that structural case\is{Structural case} marking is a valid diagnostic of unarticulated structure. From the perspective of \citet{barton.progovac2005}, this assumption could be questioned by arguing that the German\il{German} accusative\is{Accusative case} is inherent\is{Inherent case} case too, because it often marks DPs\is{Determiner phrase} that receive a patient \texttheta-role. \citet{progovac.etal2006} actually claim this for Serbian\il{Bosnian/Croatian/Serbian}, but the tests that they adduce for this language yield the opposite result in German\il{German}. Furthermore, the more instances of case are analyzed as inherent\is{Inherent case} case in order to explain case connectivity\is{Case connectivity} under a nonsentential accounts\is{Nonsentential account}, the less data are explained by the distinction between structural and inherent\is{Inherent case} case that rules out some cases on fragments (e.g. nominative\is{Nominative case} in English\il{English} and Korean\il{Korean} according to \citet{barton.progovac2005}). 

The conclusion that accusative\is{Accusative case} case marking on DP\is{Determiner phrase} fragments indicates unarticulated structure also relies on the generative\is{Generative grammar} concept of case checking\is{Case feature}. Nonsentential accounts\is{Nonsentential account} of fragments that operate in different syntactic frameworks, like HPSG\is{HPSG} \citep{ginzburg.sag2000, fernandez.ginzburg2002, schlangen2003}, explain case connectivity\is{Case connectivity} by linking the morphosyntactic properties of a short answer fragment\is{Fragment, short answer} to that of the \textit{wh}-phrase in a QuD\is{Question under Discussion} by conindexation. From this perspective, fragments do not contain any unarticulated structure and the derivation of DP fragments does not involve the PF-deletion of a verbal head, but for it to be interpreted correctly, it must match the properties of the \textit{wh}-phrase. Such accounts make in principle very similar predictions to in situ deletion\is{In situ deletion account}, which also relies on a (potentially implicit) QuD\is{Question under Discussion} in order to determine which parts of the sentence can be omitted. Empirically testing the exact predictions of the HPSG\is{HPSG} account and teasing them apart from those of in situ deletion\is{In situ deletion account} is relatively complicated, since HPSG\is{HPSG} accounts assume that different types of fragments are based on categorically different constructions instead of a single deletion mechanism.

\subsection{Fragments are not obligatorily moved}
\is{Movement and deletion account|(}
Experiments \ref{exp:pstranding-german}--\ref{exp:mvb} investigated potential evidence for movement in fragments\is{Movement and deletion account}. As has been proposed by \citet{merchant2004}, I interpret restrictions on left dislocation which constrain the form of fragments in a way that cannot be explained by in situ deletion\is{In situ deletion account} as evidence for movement. I investigated effects of three (presumable) movement restrictions\is{Movement restriction}: The ban on extraction of the complement of prepositions (P-stranding) in German\il{German}, the impossibility to front complement clauses\is{Complement clause} that lack an overt complementizer and restrictions on multiple prefield\is{Prefield} constituents in German\il{German}. Taken together, these experiments do not provide evidence for movement so that, given the results on sententiality in the previous experiments, the data support an in situ deletion\is{In situ deletion account} account of fragments. Furthermore, in the discussion of the German\il{German} data I showed that the movement and deletion account suffers from serious theoretical problems concerning the placement of the E feature\is{E feature} in this language.

\subsubsection{Preposition omission does not evidence movement in fragments}
\is{Preposition omission|)}
Experiments \ref{exp:pstranding-german} and \ref{exp:pstranding-english} support the data on preposition omission\is{Preposition omission} which are reported in \citet{merchant2004} and \citet{merchant.etal2013} for German\il{German} and English\il{English}: Omitting the preposition in short answers\is{Fragment, short answer} is degraded in German\il{German} but felicitous in English\il{English}. However, the production study\is{Production task} in experiment \ref{exp:pstranding-production} provides evidence for a general tendency for the form of the answer to match that of the question. Hence the preference for realizing the preposition in German\il{German} short answers\is{Fragment, short answer} can be explained by the form of the question alone, without having to assume that the generation of the answer involves P-stranding too. There are at least two ways to account for this parallelism. One the one hand, it might be due to the facilitation of language production by re-using contextually available structures \citep{levelt.kelter1982}, but it might also reflect congruence between questions and answers \citep{reich2002a}. This is expected specifically under accounts that emphasize the relevance of QuD\is{Question under Discussion}s to the licensing of fragments, like the in situ deletion\is{In situ deletion account} account by \citet{reich2007} and the HPSG\is{HPSG} account by \citet{ginzburg.sag2000}. Finally, the German\il{German} prepositional case\is{Prepositional case}-marked DP\is{Determiner phrase} short answers\is{Fragment, short answer} were degraded in context of PP\is{Preposition phrase} questions, but not rejected across the board, like unnatural multiple prefield\is{Prefield} configurations in experiment \ref{exp:mvb}. Since \citet{lemkeaccepted} also reports that some of these mismatches between the category of \textit{wh}-phrase and answer are relatively acceptable, it is at least questionable whether the penalty for preposition omission\is{Preposition omission} can be attributed to the unavailability of P-stranding\is{Preposition stranding} in German\il{German}.\is{Preposition omission|)}

\subsubsection{Mismatches between left dislocation and fragments}
\is{Complementizer omission|(}Experiments \ref{exp:ccs-german} and \ref{exp:ccs-english} investigated effects of complementizer omission\is{Complementizer omission} on the acceptability\is{Acceptability rating task} of topicalized complement clauses\is{Complement clause} and the corresponding fragments. They show that the preference for overt complementizers in fragments is relatively weak in German\il{German} and absent in English\il{English} when properties of the materials which concern the acceptability\is{Acceptability rating task} of the corresponding complement clause\is{Complement clause}s in complete sentences are more tightly controlled. A further surprising result of the experiments is that, unlike what has been reported in the literature for more than 40 years \citep{morgan1973, stowell1981, webelhuth1992, merchant2004}, in none of my experiments fronting complementizer-less\is{Complementizer omission} clauses was degraded as compared to complement clause\is{Complement clause}s with overt complementizers. Since there is no evidence for the movement restriction\is{Movement restriction} that presumably constrains the form of fragments, it cannot explain even the subtle preference for realizing the complementizer in German\il{German} fragments. Experiment \ref{exp:mvb} on German\il{German} multiple prefield\is{Prefield} constituents reveals further mismatches between left dislocation and fragments, since strongly degraded prefield\is{Prefield} configurations that involve a subject and another argument DP\is{Determiner phrase} result in acceptable fragments.\is{Complementizer omission|)}\is{Movement and deletion account|)}

\subsubsection{Implications for the theoretical analysis of fragments}
None of my experiments provides clear evidence for movement in fragments\is{Movement and deletion account}. The conclusions in \citet{merchant.etal2013} can either be explained by independently motivated processing constraints (in the case of P-stranding), are based on a presumed movement restriction\is{Movement restriction} that is not reflected in my experiments (in the case of complement clause\is{Complement clause} topicalization) or not supported by the data (in the case of multiple prefield\is{Prefield} constituents). I conclude that this supports an in situ deletion\is{In situ deletion account} account of fragments, which is derivationally simpler and hence to be preferred in the absence of specific evidence for movement.

\subsection{Implications for (generative) syntactic theories}
Taken together, the experiments on the syntax of fragments support an in situ deletion\is{In situ deletion account} account of fragments. The nonsentential account\is{Nonsentential account} cannot explain the case marking data and the experiments on potential movement restrictions\is{Movement restriction} found no clear evidence for obligatory movement in fragments\is{Movement and deletion account}. The conclusion that -- within a generative\is{Generative grammar} framework -- fragments must be analyzed as underlyingly sentential implies that syntax does not need to be modified so as to generate bare XPs as a well-formed output. Instead, fragments can be derived from regular sentences by ellipsis. The experiments on movement in fragments\is{Movement and deletion account} suggest that this ellipsis applies to regular sentences rather than obligatory left dislocations. Consequently, at least in fragments, ellipsis does not need to be triggered by the E feature\is{E feature} proposed by \citet{merchant2004}. It is rather licensed by a contextually salient antecedent and it can ultimately be triggered by information-theoretic\is{Information theory} processing constraints, as experiments \ref{exp:scripts-rating} and \ref{exp:scripts-production} show.

\section{Results on the usage of fragments}
\subsection{Results on the form of fragments}

The experiments on the syntax of fragments were primarily designed to test the predictions of the specific theories that I investigated, but from a theory-neutral perspective they provide evidence for several properties of fragments that must be taken into account by any theory of fragments. 

\begin{itemize}\itemsep0em
 \item There is clear evidence for case connectivity\is{Case connectivity}. DP\is{Determiner phrase} fragments appear in the same case as they do in the corresponding full sentence (or the \textit{wh}-phrase in a preceding, potentially implicit, QuD\is{Question under Discussion}). In discourse-initial fragments\is{Fragment, discourse-initial}, where an implicit QuD\is{Question under Discussion} must be retrieved, case may still vary depending on which QuD\is{Question under Discussion} the speaker has in mind.
 \item Fragments tend toward matching the properties of the corresponding \textit{wh}-phrase in the antecedent, such as a QuD\is{Question under Discussion}. This concerns not only case connectivity\is{Case connectivity}, but also the omission of the preposition\is{Preposition omission} in PP\is{Preposition phrase} fragments. In languages where the preposition in the antecedent cannot be stranded, like German\il{German}, omitting it in the answer is degraded.
 \item Fragments can be non-constituents. This is indicated by the acceptability\is{Acceptability rating task} of fragment answers in experiment \ref{exp:mvb} on multiple prefield\is{Prefield} constituents.
 \item Fragments are not subject to specific movement restrictions\is{Movement restriction}. This is most clearly shown by experiment \ref{exp:mvb}, where heavily degraded prefield\is{Prefield} configurations result in acceptable fragments.
\end{itemize}

The findings discussed in this section are also relevant to any empirical investigation of the usage of fragments in order to exclude ungrammatical fragments from the set of possible utterances. As for the experiments presented here, in experiment \ref{exp:scripts-rating}, which investigated relative preferences of (un)predictable sentences and fragments, all fragments exhibited case connectivity\is{Case connectivity}. Similarly, the merger of PPs\is{Preposition phrase} to a single lexical item in the preprocessing of the production data\is{Production task} collected in the production experiment \ref{exp:scripts-production} accounted for the strong tendency not to omit prepositions in German\il{German} PP fragments.

\subsection{The usage of fragments is constrained by UID}

\subsubsection{An information-theoretic account of fragment usage}

In Chapter \ref{sec:chapter-infotheory} I developed an information-theoretic\is{Information theory} account of the usage of fragments that explains when speakers use fragments and if they do so, which ones are preferred. In previous research this issue has been almost completely ignored. The only exception is the game-theoretic\is{Game theory} approach by \citet{bergen.goodman2015}, which however is based on a highly simplified example that comprises only four utterances, does not predict \textit{which} words are omitted in fragments and has not been tested at actual linguistic data. 

The UID\is{Uniform Information Density}-based account of fragment usage that I propose predicts that, taking the full sentence as a starting point, the choice between omitting and realizing words within that sentence is constrained by UID\is{Uniform Information Density}, i.e. the tendency to transmit information at a rate close to, but not exceeding channel capacity\is{Channel capacity}. This goal is achieved by omitting predictable words and realizing words that reduce the surprisal\is{Shannon information} of following ones. Taken together, this leads to a higher ratio of fragments in predictive contexts, because predictability-driven omissions are overall more likely in such environments. 

In Chapter \ref{sec:chapter-infotheory-experiments} I presented two experiments that support these predictions. The acceptability rating\is{Acceptability rating task} experiment \ref{exp:scripts-rating} shows that fragments are more acceptable when they refer to predictable messages than when they encode unpredictable ones. The production\is{Production task} experiment \ref{exp:scripts-production} provides evidence for the two more fine-grained predictions of UID\is{Uniform Information Density} on the word level: Uninformative\is{Shannon information} words are omitted in order to avoid inefficient troughs in the information density\is{Information density} profile of the utterance and additional redundancy is inserted in order to reduce peaks which might otherwise exceed the hearer's processing resources\is{Processing effort}.

\subsubsection{Comparison of UID to other approaches to optional omissions}
The experimental results are in line with the three predictions of UID\is{Uniform Information Density} on the usage of fragments. Some of them, however, might also be explained by other accounts of optional reduction which do not share the theoretical assumptions that UID\is{Uniform Information Density} implies, such as a parallel parser\is{Parser, parallel}\is{Parser, human}, audience design\is{Audience design} and communication through a noisy channel\is{Noisy channel}. In what follows I discuss to what extent these accounts (source coding\is{Source coding}, availability-based production\is{Availability-based production}, information structure\is{Information structure}, game theory\is{Game theory}) account for the full empirical picture: Some of them are able to explain part of the data, but UID\is{Uniform Information Density} provides a unifying account of the complete empirical picture. This does not neglect possible effects of other factors than information-theoretic\is{Information theory} optimization on omissions in fragments, but it shows that UID\is{Uniform Information Density} explains all of the predictability effects that my experiments on fragment usage reveal, whereas other frameworks account for only a part thereof.

\textit{Source coding}\is{Source coding|(} is in line with UID\is{Uniform Information Density} in predicting that frequent messages will receive shorter encodings on average. UID\is{Uniform Information Density} however derives this from properties of the channel\is{Noisy channel} in \citeauthor{shannon1948}'s communication model, whereas for source coding only properties of the source, i.e. the frequency of messages, matter. Assigning shorter encodings  to frequent messages reduces the average utterance length and increases the efficiency of communication. The crucial difference between source coding and UID\is{Uniform Information Density} is that only UID\is{Uniform Information Density} predicts the insertion of additional redundancy in order to reduce information\is{Shannon information} peaks in the ID profile\is{Information density}. In contrast, from a source coding perspective, maximizing encoding density is most efficient. The stronger preference for fragments to encode predictable messages that has been evidenced by experiment \ref{exp:scripts-rating} could be interpreted as the result of source coding.  However, from a source coding perspective there is no benefit in introducing additional redundancy into the signal, but the production experiment \ref{exp:scripts-production} suggests that speakers do so. Therefore, source coding fails to explain the complete empirical picture.\is{Source coding|)} 

\textit{Availability-based production}\is{Availability-based production|(} \citep{ferreira.dell2000} has been taken to explain some effects of predictability on the omission of function words by speaker-centered production preferences, without taking the processing\is{Processing effort} perspective into account. The general idea is that the choice between omitting and realizing optional words is driven by the effort to retrieve words from memory and the tendency to avoid disfluencies. From this perspective, inserting optional words before unpredictable words whose retrieval causes more effort contributes to keep speech fluent, whereas from the UID\is{Uniform Information Density} perspective the trigger for such insertions is the adaptation of the signal to the channel, that is, the cognitive resource\is{Processing effort} of the hearer. The result of experiment \ref{exp:scripts-production} that words that reduce the surprisal\is{Shannon information} of following words more strongly are more often realized is in principle in line with availability-based production. However, availability-based production does not explain why predictable words are more likely to be omitted.\is{Availability-based production|)}

To my knowledge, the relationship between \textit{information structure}\is{Information structure|(} and information theory\is{Information theory} has not been explicitly looked into yet, but there is probably a close relationship between surprisal\is{Shannon information} and information-theoretic concepts such as topic, focus and givenness. For instance, given expressions and specifically topics might be more likely to be talked about, and foci often mark new information, which might be on average less likely. The notion of focus is central to the in situ deletion\is{In situ deletion account} account of fragments that my experiments in the first part of this book support. It is hence reasonable to assume that information structure has an effect on the usage and form of fragments. This might raise the concern that information-theoretic surprisal\is{Shannon information} estimates actually reflect a distinction between information-structural concepts so that information structure alone is able to explain the distribution of omissions in fragments. However, information structure alone can explain when fragments are licensed, but not when they are preferred over a full sentence. Not all given words are actually omitted, as can be trivially shown by e.g. congruent sentential answers to \textit{wh}-questions. Nevertheless, it might be a promising topic of future research to tease apart effects of information theory\is{Information theory} and information structure in experimental studies.\is{Information structure|)}

\textit{Game-theoretic\is{Game theory|(} approaches} avoid an inherent\is{Inherent case} theoretical problem to UID\is{Uniform Information Density}: They model not only how utterances are assigned to messages, but also the reverse procedure, that is, how interpretations (messages) are assigned to utterances. In Section \ref{sec:fragments-game} I sketched how the usage of fragments could be modeled in a game-theoretic framework like the Iterated Best Response\is{Iterated Best Response model} model by \citet{franke2009}. Despite its advantages, a game-theoretic account alone probably cannot explain the whole range of data in the production study\is{Production task}, because, unlike UID\is{Uniform Information Density}, game-theoretic accounts do not predict an upper bound on densification. Therefore, just like I argued above for source coding\is{Source coding}, the evidence for the insertion of redundancy in order to smooth peaks that experiment \ref{exp:scripts-production} seems to contradict the predictions of the game-theoretic account. As I noted above, a careful investigation of the game-theoretic approach requires a large and correspondingly annotated data set that is currently not available.\is{Game theory|)}

\section{Implications for predictability effects on language processing}
The results of the experiments in Chapter \ref{sec:chapter-infotheory-experiments} have implications for a broader range of research on script knowledge\is{Script knowledge} and predictability effects on language processing. From a methodological perspective, they showed that script-based\is{Script knowledge} probabilistic event chain\is{Event chain}s can be used to manipulate and quantify effects of extralinguistic context\is{Context, extralinguistic} on the predictability of utterances. The method of surprisal\is{Shannon information} estimation that I applied to my production data\is{Production task} allows for the quantification of effects of extralinguistic context\is{Context, extralinguistic} on the word level and provides a solution to a circularity issue that has previously complicated the estimation of surprisal\is{Shannon information} on elliptical data. From a theoretical perspective, my experiments extend previous evidence for UID\is{Uniform Information Density} in two ways: They show that UID\is{Uniform Information Density} constraints the omission of content words and that extralinguistic context\is{Context, extralinguistic} determines surprisal\is{Shannon information}. This in turn has broader implications for the research on predictability effects and language processing, since it provides indirect evidence for assumptions about language production and processing that are implied by UID\is{Uniform Information Density}.

\subsection{Script-based event chains as a model of context}

\is{Script knowledge|(}In experiments \ref{exp:scripts-rating} and \ref{exp:scripts-production} I based my materials on probabilistic event chain\is{Event chain}s extracted from the DeScript corpus\is{Corpus} of script knowledge\is{Script knowledge} \citep{wanzare.etal2016} in order to determine the likelihood of target utterances. Previous studies that investigated effects of script knowledge\is{Script knowledge} relied on stimuli constructed according to researcher intuitions and/or based on norming studies, which are specific to a particular experiment (see the references in Section \ref{sec:infotheory-scripts}).

Script\is{Script knowledge} corpora\is{Corpus} like DeScript \citep{wanzare.etal2016} are a valuable resource for constructing empirically founded models of script knowledge\is{Script knowledge}. Due to the large number of contributors to such corpora\is{Corpus}, they provide a reasonable approximation to the representation of scripts in the memory of a larger population. This is crucial to experimental studies that investigate effects of script knowledge\is{Script knowledge}, because script knowledge\is{Script knowledge} manipulations presuppose that subjects possess the relevant script knowledge\is{Script knowledge}. The use of probabilistic event chain\is{Event chain}s rather than deterministic ones takes into account both the uncertainty about the next event and differing script\is{Script knowledge} representations between subjects. This is desirable, since interlocutors in actual conversations must consider the possibility that their script\is{Script knowledge} representations differ to some extent.

Experiment \ref{exp:scripts-rating} confirms the validity of the script-based\is{Script knowledge} manipulation of predictability. In the rating experiment \ref{exp:scripts-rating}, utterances referring to predictable events were perceived as more natural. This was specifically the case when subjects possessed the relevant script knowledge\is{Script knowledge}, which was assessed with a questionnaire following the main experiment. Event chain\is{Event chain}s extracted from script\is{Script knowledge} corpora\is{Corpus} thus are a promising method for constructing materials in research on script knowledge\is{Script knowledge}: They are psychologically realistic representations of an average speaker's script knowledge\is{Script knowledge} and reduce the amount of cloze and norming studies required for stimulus generation.\is{Script knowledge|)}

\subsection{Surprisal estimation in elliptical data}
For the analysis of the production data\is{Production task} from experiment \ref{exp:scripts-production} I developed a method of surprisal\is{Shannon information} estimation that is specifically suitable for elliptical data. The approach is based on the insight by \citet{hale2001} that the surprisal\is{Shannon information} of a word is proportional to the cumulated probability mass of the parses\is{Parser, parallel} that it disconfirms. Unlike \citet{hale2001}, however, it allows for omissions to occur before and after each word in the actually produced utterance. 

This approach avoids a circularity issue that affects \textit{n}-gram\is{N-gram language model} surprisal\is{Shannon information} estimated from corpora that contain elliptical data: Since I estimate surprisal based on the probability of complete structures, the omission of a word does not affect its own surprisal\is{Shannon information}. Furthermore, the method is psychologically realistic, because omitted words preceding a target word in the complete structures have no effect on the target word's predictability: Only the realized words that are available to the hearer modulate surprisal\is{Shannon information}. %

This method requires to know which nonelliptical utterances are possible in a specific situation and how likely they are. In experiment \ref{exp:scripts-production} I collected a data set that constrained by extralinguistic context\is{Context, extralinguistic} stories based on which the likelihood of utterances can be estimated, and which contains the relevant omissions. In order to estimate the surprisal\is{Shannon information} of both omitted and realized words, a procedure to reconstruct all omissions within this data set is also necessary. In the case of my data set, omissions were reconstructed manually. This required a large extent of annotation work. Future research might extend this approach to larger data sets in case the preprocessing procedure can be at least in part automatized.

\subsection{UID constrains the omission of content words}
Previous evidence for UID\is{Uniform Information Density} focused mostly the omission of semantically relatively vacuous function words. Investigating closed-class function words like relative pronouns \citep{levy.jaeger2007} and complementizers \citep{jaeger2010} has several methodological advantages over focusing on content words: Both realized function words and instances of omissions are easy to find in corpora\is{Corpus} and in case of omissions reconstructing the missing expression is relatively straightforward. The surprisal\is{Shannon information} of the target word itself can be equated with that of the syntactic construction that it encodes (e.g. a relative or complement clause\is{Complement clause}) and that of the surrounding words can be estimated with \textit{n}-gram models\is{N-gram language model} \citep{levy.jaeger2007}. 

Content words in contrast require a sophisticated preprocessing approach, a strategy for the reconstruction of omissions and a different method for surprisal\is{Shannon information} estimation that is psychologically realistic and not affected by omissions in the actual data. This surprisal\is{Shannon information} estimation method in turn requires a particular data set, which contains a sufficiently large number of utterances produces in the same context to calculate reasonable surprisal\is{Shannon information} estimates. I proposed solutions to these issues and was able to show that the central predictions hold not only for the omission of function words, but also for that of content words.

\subsection{Effects of extralinguistic context on predictability}
\is{Context, extralinguistic|(}In principle, information-theoretic\is{Information theory} approaches to language predict that the likelihood of a word depends on a variety of sources, which comprise both linguistic and extralinguistic context\is{Context, extralinguistic}. Previous research in the field however estimated the likelihood of utterances and words only based on linguistic, and specifically very local intrasentential, context. At most, context comprised some utterances preceding a target word \citep[see e.g.][]{tily.piantadosi2009, kravtchenko2014}, who used guessing experiments \citep{shannon1951} to quantify this context's effect on predictability. Most of the time however, surprisal\is{Shannon information} is estimated with \textit{n}-gram models\is{N-gram language model}, take only a few words preceding the target word into account.

Experiments \ref{exp:scripts-rating} and \ref{exp:scripts-production} constitute to my knowledge the first investigation of effects of extralinguistic context\is{Context, extralinguistic} on the predictability and the omission of words. Experiment \ref{exp:scripts-rating} indicates that utterances that refer to events which are predictable in a script-based\is{Script knowledge} extralinguistic context\is{Context, extralinguistic} are more likely to be reduced. Experiment \ref{exp:scripts-production} shows that even unigram\is{Unigram language model} surprisal\is{Shannon information} calculated on the utterances for a single scenario only is a significant predictor of omission: Words that are more likely to appear in an utterance in that scenario are more often omitted. This shows that not only local linguistic context\is{Context, linguistic}, but also script-based\is{Script knowledge} extralinguistic context\is{Context, extralinguistic} determines the likelihood of words and of their omission.\is{Context, extralinguistic|)}

\subsection{Psycholinguistic implications of UID}
Extending the available evidence for UID\is{Uniform Information Density} to omissions of content words and effects of extralinguistic context\is{Context, extralinguistic} indirectly supports more general assumptions about language production and processing that UID\is{Uniform Information Density} presupposes. 

\subsubsection{Predictability is related to processing effort}
\is{Processing effort|(}The assumption that processing predictable words requires less effort is crucial to the interpretation of UID\is{Uniform Information Density} that I take, which interprets channel capacity\is{Channel capacity} as an upper bound to the processing resources\is{Processing effort} of the hearer. From an empirical perspective, it is relatively uncontroversial that predictable words are easier to process\is{Processing effort}, which is indicated for instance by faster reading times \citep{demberg.keller2008, levy2008, smith.levy2013, brothers.kuperberg2019} and a reduced N400 in ERP\is{ERP} studies \citep{frank.etal2015, delogu.etal2017}. In my experiments I did not explicitly measure processing effort, but since it is indexed by surprisal\is{Shannon information}, the optimization of utterances with respect to UID\is{Uniform Information Density} ensures a uniform distribution of processing effort.\is{Processing effort|)}

\subsubsection{The human parser is parallel}
\begin{sloppypar}
\is{Parser, parallel|(}\is{Parser, human|(}The relationship between predictability and processing effort\is{Processing effort} is theoretically explained by the derivation of surprisal\is{Shannon information} from the work done by the human parser\is{Parser, human} \citep{hale2001, levy2008}, which consists in the rejection of structures that a word disconfirms. Processing effort is proportional to the probability mass of the rejected parses, hence unlikely words are harder to process. This assumption presupposes that the human parser\is{Parser, human} is fully parallel. Serial\is{Parser, serial} or bounded parallel parser\is{Parser, parallel}\is{Parser, human}s, do not keep the complete set of possible parses, so it is impossible to calculate how large the share of the probability mass of the rejected parses is. \citet{levy2008} however notes that the assumption of a fully parallel parser\is{Parser, parallel}\is{Parser, human} might not be psychologically realistic, since it involves the calculation of an extremely large amount of low-probability structures which never become likely throughout the parsing process. Still though, \citet[1135--1136]{levy2008} argues that even if it is assumed that the human parser\is{Parser, human} is not fully parallel, computational surprisal\is{Shannon information} estimates still provide a reasonable approximation to processing effort\is{Processing effort}, as long as only those parses that are assigned very low probabilities during the parsing process are ignored.\is{Parser, human|)}\is{Parser, parallel|)}
\end{sloppypar}

\subsubsection{Speakers perform audience design}
\is{Audience design|(}Since optimization with respect to UID\is{Uniform Information Density} consists in the adaptation of the signal to the channel, whose capacity\is{Channel capacity} I interpret as an upper bound to the hearer's cognitive resources, UID\is{Uniform Information Density} presupposes audience design\is{Audience design}. The result of this optimization will differ depending on properties of the hearer and the situation. For instance, if the hearer's processing resources\is{Processing effort} are reduced by an interfering effortful task, the speaker will choose a less dense encoding. Predictability effects do not necessarily evidence audience design\is{Audience design}: For instance, source coding\is{Source coding} predicts that more likely expressions are more often reduced even though it takes only statistical properties of the source into account. Similarly, availability-based production\is{Availability-based production} explains the distribution of optional omissions only with production effort. As I argued above in the comparison of the predictions of UID\is{Uniform Information Density} to other approaches to optional deletion, unlike UID\is{Uniform Information Density}, neither source coding\is{Source coding} nor availability-based production\is{Availability-based production} are able to explain the full empirical picture.\is{Audience design|)}

\section{Implications for other reduction phenomena}
The question of why speakers sometimes prefer a reduced form over a syntactically complete one is not only relevant to fragments, but also to other omission and reduction phenomena. This holds for antecedent-based ellipses\is{Antecedent-based ellipsis} like verb phrase ellipsis\is{Verb phrase ellipsis} \citep{sag1976, williams1977}, sluicing\is{Sluicing} \citep{ross1969} or gapping\is{Gapping} \citep{ross1970}, but also for the omission of topics\is{Topic drop}, subjects\is{Subject drop} and objects\is{Object drop} and pronominalization. For all of these phenomena, UID\is{Uniform Information Density} predicts that the more predictable an expression is, the more likely it will be omitted, provided that the omission is permitted by grammar, and that omission is dispreferred when it reduces information density peaks on following material.

For some of these phenomena there is evidence for predictability effects on the choice of encodings  that are in line with UID\is{Uniform Information Density}. \citet{tily.piantadosi2009} find that more predictable referents are more often pronominalized, and \citet{kravtchenko2014} observes that predictable subjects are more often omitted in Russian\il{Russian}. More recently, \citet{schafer.etalunderreview} show that verb phrase ellipsis\is{Verb phrase ellipsis} is more strongly preferred the longer, i.e. the more redundant, a VP\is{Verb phrase} is.

A further question that predictability effects on omissions raise is whether UID\is{Uniform Information Density} explains only whether a specific ellipsis occurs provided that it is licensed, or whether some licensing conditions on ellipsis actually reflect UID\is{Uniform Information Density} effects. For instance, \citet{chung2006} proposes a syntactic identity condition on sluicing\is{Sluicing} that requires that all words that are omitted in the sluice must be given in the antecedent. This intends to account for the acceptability\is{Acceptability rating task} of preposition omission\is{Preposition omission} under sluicing\is{Sluicing} \Next[a], but not under sprouting \Next[b].

\ex. \a. John danced with somebody, but I don't know who \sout{John danced with}.
     \b. John danced, but I don't know who \sout{John danced with}.

Two recent studies suggest that this can be explained by predictability: \citet{poppels.kehler2019a} show that the acceptability\is{Acceptability rating task} of sluices\is{Sluicing} that violate \citeauthor{chung2006}'s constraint increases the more accessible the QuD\is{Question under Discussion} that contains the antecedent to the sluice is. This suggests that predictable words can be omitted whereas unpredictable ones cannot. In a self-paced reading experiment on similar full forms to \Last in German\il{German}, \citet{lemke.etalaccepted} find structurally mismatching sluices\is{Sluicing} are read faster in the sluicing condition than under sprouting which also indicates that the redundant \textit{John danced with} is simply more predictable in the sluicing condition than under sprouting. Future research will show whether the result that UID\is{Uniform Information Density} constrains omissions in fragments can be extended to other instances of ellipsis and whether it can explain away specific identity conditions that have been postulated for some ellipsis phenomena.
