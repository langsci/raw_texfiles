\addtocontents{toc}{\protect\enlargethispage{\baselineskip}}\chapter{Solving Communication Games}
\section{Solving Locutionary Global Games} \label{sec:solving locutionary global games}

Assuming common knowledge of the objective locutionary global game $LG_u(\varphi)\allowbreak = \{g_1, g_2, g_{12}, g'_1, g'_2, g'_{12}\}$ from \sectref{sec:generation game} to keep things simple, I now look at how this game can be solved. When there is common knowledge, $LG^{\cal A}_u(\varphi) = LG^{\cal B}_u(\varphi) = LG_u(\varphi)$, so solving the objective game automatically implies a solution to the subjective games. As I said in that section, $f_u$ is a solution function that maps games into their solutions and  $f_u[LG_u(\varphi)] = \{f_u(g_1), f_u(g_2), f_u(g_{12}),\allowbreak f_u(g'_1), f_u(g'_2),\allowbreak f_u(g'_{12})\} = \{\sigma_1, \sigma_2, \sigma_1\sigma_2, t_1, t_2, t_1t_2\}$. The solution to the syntactic games can be trivially obtained in this example so I will focus on the semantic games.

\begin{figure}[h] 
\input{figures/pix4varphi1algebraictruncated.tex}
\caption{Semantic lexical game $g_1$}
\label{fig:semantic lexical game g1 again}
\end{figure}

Recall the first local semantic game $g_1 = g_u(\varphi_1)$ shown again in Figure~\ref{fig:semantic lexical game g1 again}. In $g_1$, $\cal A$ utters $\varphi_1 = \Expression{bill}$ and $\cal B$ has to choose between $\sigma_1 = \emph{Bill Smith}$ or $\sigma'_1 = \emph{Bill Jones}$. The prior $\rho_1 = P(\sigma_1 \cond x_2, y_1, y_2; u)$ where the $x_2$ is a variable ranging across the possible corresponding meanings $\sigma_2$, $\sigma'_2$, and the $y_1$, $y_2$ are variables standing for the possible corresponding parse trees $t_1$, $t_2$, respectively. Likewise, the other prior 
$\rho_{1'} = P(\sigma'_1 \cond x_2, y_1, y_2; u)$. Thus, there are different \emph{versions} of essentially the same game $g_1$ when $x_2$, $y_1$, or $y_2$ take on different values whenever this is possible. In addition to choosing utterances and interpretations, the agents also have to choose the particular values of the conditioning variables in the prior probabilities, that is, they have to choose between the two versions of the game. This is what makes all the local games interdependent.

In solving such games, the players have to identify all the possible strategies they could adopt and then choose the best one based on what the other player might do. A strategy is just a specification of what an agent would do at each of their information sets and of what version of the game they would choose. $\cal A$ has two information sets, one at $s_1$ and the other at $s_{1'}$, so he has to specify what he would do at both of these. However, he has just one choice of action, $\varphi_1$, in each set so there is no real choice. On the other hand, he can choose between the two versions of $g_1$ essentially by choosing $x_2 = \sigma_2$ or $x_2 = \sigma'_2$, as the other conditioning variables $y_1$ and $y_2$ take on just one value $t_1$ and $t_2$ respectively, and as the parameter $u$ is fixed. So his two strategies are $(\varphi_1, \varphi_1, \sigma_2)$ and $(\varphi_1, \varphi_1, \sigma'_2)$ where the $\varphi_1$ is repeated in each strategy because that is the action in both $s_1$ and $s_{1'}$. Since $\varphi_1$ is the only possible action, it can just be ignored, and we can simply say he has a choice between $\sigma_2$ and $\sigma'_2$. $\cal B$ has just one information set, the elongated oval, but she has two choices, $\sigma_1$ and $\sigma'_1$, in that set and she has the same two versions of the game to choose from so her strategies are $(\sigma_1, \sigma_2)$, $(\sigma_1, \sigma'_2)$, $(\sigma'_1, \sigma_2)$, and $(\sigma'_1, \sigma'_2)$. A strategy profile is a combination of a strategy of $\cal A$'s and a strategy of $\cal B$'s. All of their strategies listed above are called \emph{pure} strategies; \emph{mixed} strategies involve a probability distribution on pure strategies. The description of a strategy here is a generalization of the usual definition because of the need to include the choice of version or of the values of the conditioning variables. This is another reason why such games are called games of \emph{partial} information.

One way to solve such a game is to look for strategy profiles that no player will want to deviate from unilaterally. Such an equilibrium strategy, called a Nash equilibrium as we saw in \sectref{sec:agents},\footnote{Strictly speaking, the right solution concept is not quite a Nash equilibrium\is{equilibrium!Nash} but a Perfect Bayesian equilibrium\is{equilibrium!Perfect Bayesian} but, in the simple structure of a single partial information game, this nuance can be safely ignored. See \citet[Section~3.3.5]{parikh:le}.} will implicitly involve each agent taking account of what the other agent might do. As I said in \sectref{sec:communication as rational activity}, the key idea in decision-making is that an agent should maximize his expected utility modulo what the other agent does. So we have to compare the expected utilities of different strategies for each agent and choose the ones that neither will want to deviate from unilaterally. Because $g_1$ is part of the family of interdependent games $LG_u(\varphi) = \{g_1, g_2, g_{12}, g'_1, g'_2, g'_{12}\}$ and because each agent will want to choose the version of $g_1$ that the other chooses and that is compatible with the solutions to the other local games, there is an additional compatibility condition that is imposed on the solution that requires that both players play the same version of each game and that this version have conditioning variable values that agree with the choices made by $\cal B$ in the other games. For example, since there is a choice in $g_1$ between two values of the conditioning variable $x_2$, either $x_2 = \sigma_2$ or $x_2 = \sigma'_2$, the value chosen in equilibrium by both players must match with the interpretation chosen in $g_2$, where $\cal B$ has a choice between interpreting the utterance of $\varphi_2$ as $\sigma_2$ or $\sigma'_2$ as shown in Figure~\ref{fig:semantic lexical game g2}. And such a requirement must be satisfied in all six interdependent games. This means that while it is correct to see each player as choosing the optimal version of each local game by specifying the values of the conditioning variables in the prior probability distribution, each of them will optimally want this choice to agree with the interpretive choices made by $\cal B$ in the other local games. So there are fewer degrees of freedom than might initially appear to be the case.

\subsection{The two versions of $g_1$}

To be completely clear about the choice of version in each agent's strategy, I show the versions explicitly in Figures~\ref{fig:semantic lexical game g1 version1} and \ref{fig:semantic lexical game g1 version2}. The prior probability functions $\rho_1$ and $\rho_{1'}$ have been replaced by the actual probabilities with different combinations of the conditioning variables.

\begin{figure}[h] 
\input{figures/pix4varphi1algebraictruncatedversion1.tex}
\caption{The first version of the semantic lexical game $g_1$}
\label{fig:semantic lexical game g1 version1}
\end{figure}

\begin{figure}[h] 
\input{figures/pix4varphi1algebraictruncatedversion2.tex}
\caption{The second version of the semantic lexical game $g_1$}
\label{fig:semantic lexical game g1 version2}
\end{figure}


Consider Figure~\ref{fig:semantic lexical game g1 version1} which shows the first version of $g_1$. Assuming this first version is being played by both players as the compatibility condition requires, we investigate which strategy profile is best. This leaves just one real choice to be made: $\cal B$ has to decide between $\sigma_1$ and $\sigma'_1$. If $\cal B$ opts for $\sigma_1$ then $\cal A$'s expected utility will be $P(\sigma_1 \cond \sigma_2, t_1, t_2; u)a_{\cal A} + P(\sigma'_1 \cond \sigma_2, t_1, t_2; u)c'_{\cal A}$ by tracing the paths followed by starting with $s_1$ through to the relevant terminal node resulting from the branch labeled $\sigma_1$ and the payoff $a_{\cal A}$ received there and by starting with $s_{1'}$ through to the relevant terminal node resulting from the branch labeled $\sigma_1$ and the payoff $c'_{\cal A}$ received there. If $\cal B$ opts for $\sigma'_1$ then $\cal A$'s expected utility will be $P(\sigma_1 \cond \sigma_2, t_1, t_2; u)c_{\cal A} + P(\sigma'_1 \cond \sigma_2, t_1, t_2; u)a'_{\cal A}$. $\cal B$ receives the same expected utilities with $\cal A$ replaced by $\cal B$ in the above expressions.

As I said on page~\pageref{page:probability comparisons} in \sectref{sec:generation game}, $P(\sigma_1 \cond \sigma_2, t_1, t_2; u) > P(\sigma'_1 \cond \sigma_2, t_1, t_2; u)$ owing to the compatibility between the conditioning variables and parameter and the conditioned variable in the first probability as opposed to the second. If, in addition, it is assumed that the unprimed payoffs are identical to the corresponding primed payoffs for both players, that is, if $a_{\cal A} = a'_{\cal A}$, $c_{\cal A} = c'_{\cal A}$, $a_{\cal B} = a'_{\cal B}$, and $c_{\cal B} = c'_{\cal B}$\footnote{Actually, all that is required is that $a_{\cal A} - c_{\cal A} = a'_{\cal A} - c'_{\cal A}$ and $a_{\cal B} - c_{\cal B} = a'_{\cal B} - c'_{\cal B}$ as can be seen from transposing terms in the inequality $P(\sigma_1 \cond \sigma_2, t_1, t_2; u)a_{\cal A} + P(\sigma'_1 \cond \sigma_2, t_1, t_2; u)c'_{\cal A} > P(\sigma_1 \cond \sigma_2, t_1, t_2; u)c_{\cal A} + P(\sigma'_1 \cond \sigma_2, t_1, t_2; u)a'_{\cal A}$ and in the corresponding inequality for $\cal B$. This essentially makes the game a coordination game of the kind considered in \sectref{sec:agents}. \label{foot:symmetric payoffs}} because these payoffs are endogenously generated by the agents trying to coordinate with $\cal A$'s intentions to convey $\sigma_1$ and $\sigma'_1$ in $s_1$ and $s_{1'}$ and because there is no preference for any particular result in the ongoing conversation in $u$, it follows that $P(\sigma_1 \cond \sigma_2, t_1, t_2; u)a_{\cal B} + P(\sigma'_1 \cond \sigma_2, t_1, t_2; u)c'_{\cal B} > P(\sigma_1 \cond \sigma_2, t_1, t_2; u)c_{\cal B} + P(\sigma'_1 \cond \sigma_2, t_1, t_2; u)a'_{\cal B}$ and so $\cal B$'s $\sigma_1$ strategy is better than her $\sigma'_1$ strategy.\footnote{As was discussed on page~\pageref{page:payoff comparisons}, the $a$ payoffs are always greater than the corresponding $c$ payoffs, primed and unprimed, for both players because they represent the correct interpretation with respect to what $\cal A$ is conveying.} In fact, if $\cal B$ chooses $\sigma_1$ in the first version of $g_1$ then \emph{both} agents will receive a higher expected payoff than if she chooses $\sigma'_1$. So, with respect to the first version, $(\varphi_1, \sigma_1)$ is a Nash equilibrium as neither player will want to deviate unilaterally from it, $\cal A$ because there is nothing to deviate to given his single choice of utterance $\varphi_1$ and $\cal B$ because $\sigma'_1$ yields a lower expected utility to her. Therefore, all this part of the solution process involves is comparing two prior probabilities. Indeed, as I suggested earlier, their values could well be 5/6 and 1/6 and it would just be a matter of seeing which one is larger. This computation is quite undemanding, either for the human brain or for an artificial agent. 

Exactly the same reasoning shows that in the second version of $g_1$ it is $\sigma'_1$ that gives the higher expected utility to $\cal B$ (and to $\cal A$ as well) because $P(\sigma_1 \cond \sigma'_2, t_1,\allowbreak t_2; u) < P(\sigma'_1 \cond \sigma'_2, t_1, t_2; u)$ as was established earlier. So $(\varphi_1, \sigma'_1)$ will be a Nash equilibrium in this version as neither player will want to deviate unilaterally from it. In fact, I had suggested that these probabilities could be 1/4 and 3/4, respectively. 

So, depending on which version is chosen by $\cal A$ and $\cal B$, either $\sigma_1$ or $\sigma'_1$ will be the equilibrium choice for $\cal B$ (and $\varphi_1$ is the only possible choice for $\cal A$). A more formal way of putting this is that the equilibrium of $g_1$ will be either $(\varphi_1, \sigma_1, \sigma_2)$ or $(\varphi_1, \sigma'_1, \sigma'_2)$ where the choice of the conditioning variable between $\sigma_2$ and $\sigma'_2$ has been made explicit. Of course, the compatibility condition mentioned above means that this latter choice will be fixed in solving $g_2$. This makes the interdependence among the games crystal clear. I repeat that the trees $t_1$ and $t_2$ do not play any real role in this example as they are the only choices for the parses of $\varphi_1$ and $\varphi_2$. However, if we wish to make their role explicit as well, we can say that the choice of equilibrium in $g_1$ is between $(\varphi_1, \sigma_1, \sigma_2, t_1, t_2)$ and $(\varphi_1, \sigma'_1, \sigma'_2, t_1, t_2)$. Since only the real choices need to be mentioned, it is possible to drop $\varphi_1$, $t_1$ and $t_2$ from these Nash equilibria and write just $(\sigma_1, \sigma_2)$ and $(\sigma'_1, \sigma'_2)$. Here, the first component of the equilibrium, $\sigma_1$ or $\sigma'_1$, is selected in $g_1$ and the second component of the equilibrium, $\sigma_2$ or $\sigma'_2$, is chosen in $g_2$ rather than $g_1$ owing to the compatibility condition. A choice of $\sigma_2$ in $g_2$ favors a choice of $\sigma_1$ in $g_1$ and a choice of $\sigma'_2$ in $g_2$ favors a choice of $\sigma'_1$ in $g_1$.

As the reader might anticipate, a similar scenario obtains with the two versions of $g_2$. In one version, $\sigma_2$ will be the best option for $\cal B$ based on the inequality $P(\sigma_2 \cond \sigma_1, t_1, t_2; u) > P(\sigma'_2 \cond \sigma_1, t_1, t_2; u)$ and, in the other version, $\sigma'_2$ will be the best option based on the inequality $P(\sigma_2 \cond \sigma'_1, t_1, t_2; u) < P(\sigma'_2 \cond \sigma'_1, t_1, t_2; u)$. This time, by similar reasoning, we can conclude that $(\sigma_2, \sigma_1)$ and $(\sigma'_2, \sigma'_1)$ are the two Nash equilibria the players have to choose between. Here, the first component of the equilibrium, $\sigma_2$ or $\sigma'_2$, is selected in $g_2$ and the second component of the equilibrium, $\sigma_1$ or $\sigma'_1$, is chosen in $g_1$ rather than $g_2$ owing to the compatibility condition again. A choice of $\sigma_1$ in $g_1$ favors a choice of $\sigma_2$ in $g_2$ and a choice of $\sigma'_1$ in $g_1$ favors a choice of $\sigma'_2$ in $g_2$.

\subsection{Looking for Pareto-Nash equilibria}

These observations allow us to say that $\sigma_1$ and $\sigma_2$ are compatible with each other and $\sigma'_1$ and $\sigma'_2$ are compatible with each other. An alternative way of putting this is that the first versions of $g_1$ and $g_2$ are compatible with each other and the second versions of $g_1$ and $g_2$ are compatible with each other. In yet other words, we have two Nash equilibria in $g_1$ and we have two Nash equilibria in $g_2$ with the unprimed contents mutually implying each other and the primed contents mutually implying each other. How do we choose between these two sets of compatible pairs? One way to eliminate one pair of Nash equilibria is by bringing in the Pareto criterion and looking for what I have called Pareto-Nash equilibria in \sectref{sec:agents}, something \citet{spence:srism} also recommends in a different context.\footnote{Another possibility is to consider what are called risk-dominant Nash equilibria\is{equilibrium!risk-dominant} but they yield the same result under the assumptions we have made and are less intuitive. See \citet{hs:gtesg} and \citet[Section~3.3.5]{parikh:le}. More recently, so-called \emph{iterated best response} reasoning has been considered by \citet{franke:sa} and \citet{jager:gtsp}. While such reasoning can occur in games where agents consciously reason about one another, it is highly implausible in the context of communication which takes only milliseconds. Besides, as J\"{a}ger communicated to me, it is $NP$-complete. As we will soon see, while it is necessary to go through the Pareto-Nash calculations that I am describing, their final result is dramatically simple to compute and also does not involve each agent consciously reasoning about the other explicitly. In particular, while Pareto-Nash equilibrium is also $NP$-complete, in our context of communication, its complexity class is just $P$.

Some theorists feel queasy about employing the Pareto criterion\is{equilibrium!Pareto-Nash} or even allowing agents to choose among Nash equilibria on the ground that agents can choose between strategies but cannot choose between strategy profiles, since the latter also include the other agent's choice. I have discussed this and related issues at some length in \citet[footnote~9, pages~40--41]{parikh:ul} and in \citet[Section~3.3.5]{parikh:le} but here are some further observations. The central worry seems to be that some element of cooperation between the agents is required for the agents to choose Pareto-Nash equilibria in coordination games of the kind we are concerned with here. This may well be true. Earlier, I have suggested that such cooperation could result from one aspect of Grice's Cooperation Principle,\ia{Grice, Paul@Grice, Paul} which is being assumed in any case.

Agents can nevertheless sometimes choose different equilibria, and when they do, there is miscommunication.\is{miscommunication} I discuss this kind of error in \sectref{sec:solving generation games} in some detail. Often, it will lead to clarification requests, as \citet{benz:eip} points out, and then the right equilibrium gets explicitly selected. It is unlikely, however, that both agents will get stuck jointly in a suboptimal equilibrium because the speaker knows what he intends to convey and his payoffs and probabilities will reflect this and make his choice optimal.

Given the alternatives -- risk-dominance or epistemic reasoning of the iterated best response kind -- assuming an element of cooperation in the choice of equilibria which, as we shall soon see, amounts to no more than choosing the maximal options, seems rather innocuous. Many game theorists such as Spence are not unduly troubled by this. I had mentioned in \citet[108--109]{parikh:pgpi} that the calculations in \citet{vanrooy:sgshs} showing the inadequacy of the Pareto criterion were flawed, as kindly conveyed to me by van Rooij himself. \label{foot:Pareto criterion}} The Pareto criterion states that a Nash equilibrium is Pareto-efficient if it is at least as good as the other Nash equilibrium for both players and is strictly better for at least one player. For $(\sigma_1, \sigma_2)$ to be the unique Pareto-Nash equilibrium of $g_1$, we require that:

\noindent either
\begin{align*}
      & P(\sigma_1 \cond \sigma_2, t_1, t_2; u)a_{\cal A} + P(\sigma'_1 \cond \sigma_2, t_1, t_2; u)c'_{\cal A}\\
    > & P(\sigma_1 \cond \sigma'_2, t_1, t_2; u)c_{\cal A} + P(\sigma'_1 \cond \sigma'_2, t_1, t_2; u)a'_{\cal A} 
\end{align*}
and
\begin{align*}
         & P(\sigma_1 \cond \sigma_2, t_1, t_2; u)a_{\cal B} + P(\sigma'_1 \cond \sigma_2, t_1, t_2; u)c'_{\cal B}\\
    \geq & P(\sigma_1 \cond \sigma'_2, t_1, t_2; u)c_{\cal B} + P(\sigma'_1 \cond \sigma'_2, t_1, t_2; u)a'_{\cal B} 
\end{align*}

\noindent or
\begin{align*}
         & P(\sigma_1 \cond \sigma_2, t_1, t_2; u)a_{\cal A} + P(\sigma'_1 \cond \sigma_2, t_1, t_2; u)c'_{\cal A}\\
    \geq &  P(\sigma_1 \cond \sigma'_2, t_1, t_2; u)c_{\cal A} + P(\sigma'_1 \cond \sigma'_2, t_1, t_2; u)a'_{\cal A}
\end{align*}
and
\begin{align*}
          & P(\sigma_1 \cond \sigma_2, t_1, t_2; u)a_{\cal B} + P(\sigma'_1 \cond \sigma_2, t_1, t_2; u)c'_{\cal B}\\
        > & P(\sigma_1 \cond \sigma'_2, t_1, t_2; u)c_{\cal B} + P(\sigma'_1 \cond \sigma'_2, t_1, t_2; u)a'_{\cal B}
\end{align*}

\noindent Likewise, for $(\sigma_2, \sigma_1)$ to be a Pareto-Nash equilibrium of $g_2$, we require that:

\noindent either
\begin{align*} 
        & P(\sigma_2 \cond \sigma_1, t_1, t_2; u)a_{\cal A} + P(\sigma'_2 \cond \sigma_1, t_1, t_2; u)c'_{\cal A}\\
        > & P(\sigma_2 \cond \sigma'_1, t_1, t_2; u)c_{\cal A} + P(\sigma'_2 \cond \sigma'_1, t_1, t_2; u)a'_{\cal A}
\end{align*}
and
\begin{align*}
        & P(\sigma_2 \cond \sigma_1, t_1, t_2; u)a_{\cal B} + P(\sigma'_2 \cond \sigma_1, t_1, t_2; u)c'_{\cal B}\\
        \geq & P(\sigma_2 \cond \sigma'_1, t_1, t_2; u)c_{\cal B} + P(\sigma'_2 \cond \sigma'_1, t_1, t_2; u)a'_{\cal B}
\end{align*}

\noindent or
\begin{align*}
         & P(\sigma_2 \cond \sigma_1, t_1, t_2; u)a_{\cal A} + P(\sigma'_2 \cond \sigma_1, t_1, t_2; u)c'_{\cal A}\\
    \geq & P(\sigma_2 \cond \sigma'_1, t_1, t_2; u)c_{\cal A} + P(\sigma'_2 \cond \sigma'_1, t_1, t_2; u)a'_{\cal A} 
\end{align*}
and
\begin{align*}
        & P(\sigma_2 \cond \sigma_1, t_1, t_2; u)a_{\cal B} + P(\sigma'_2 \cond \sigma_1, t_1, t_2; u)c'_{\cal B}\\
       > & P(\sigma_2 \cond \sigma'_1, t_1, t_2; u)c_{\cal B} + P(\sigma'_2 \cond \sigma'_1, t_1, t_2; u)a'_{\cal B}
\end{align*}

There are so many symbols in these inequalities that it is hard to decipher what they amount to. It is convenient to let $P(\sigma_1,\sigma_2 \cond t_1, t_2; u) = j$, $P(\sigma_1,\sigma'_2 \cond t_1, t_2; u) = k$, $P(\sigma'_1,\sigma_2 \cond t_1, t_2; u) = l$, and $P(\sigma'_1,\sigma'_2 \cond t_1, t_2; u) = m$ in order to see the probabilities more clearly. This implies:

\begin{align*}P(\sigma_1 \cond \sigma_2, t_1, t_2; u)   & = \frac{P(\sigma_1, \sigma_2 \cond t_1, t_2; u)}{P(\sigma_2 \cond t_1, t_2; u)} = \frac{P(\sigma_1, \sigma_2 \cond t_1, t_2; u)}{P(\sigma_1, \sigma_2 \cond t_1, t_2; u) + P(\sigma'_1, \sigma_2 \cond t_1, t_2; u)}      \\ & = \frac{j}{j + l}\end{align*}
\begin{align*}P(\sigma_1 \cond \sigma'_2, t_1, t_2; u)  & = \frac{P(\sigma_1, \sigma'_2 \cond t_1, t_2; u)}{P(\sigma'_2 \cond t_1, t_2; u)} = \frac{P(\sigma_1, \sigma'_2 \cond t_1, t_2; u)}{P(\sigma_1, \sigma'_2 \cond t_1, t_2; u) + P(\sigma'_1, \sigma'_2 \cond t_1, t_2; u)} \\ & = \frac{k}{k + m}\end{align*}
\begin{align*}P(\sigma'_1 \cond \sigma_2, t_1, t_2; u)  & = \frac{P(\sigma'_1, \sigma_2 \cond t_1, t_2; u)}{P(\sigma_2 \cond t_1, t_2; u)} = \frac{P(\sigma'_1, \sigma_2 \cond t_1, t_2; u)}{P(\sigma_1, \sigma_2 \cond t_1, t_2; u) + P(\sigma'_1, \sigma_2 \cond t_1, t_2; u)}     \\ & =  \frac{l}{j + l}\end{align*}
\begin{align*}P(\sigma'_1 \cond \sigma'_2, t_1, t_2; u) & = \frac{P(\sigma'_1, \sigma'_2 \cond t_1, t_2; u)}{P(\sigma'_2 \cond t_1, t_2; u)} = \frac{P(\sigma'_1, \sigma'_2 \cond t_1, t_2; u)}{P(\sigma_1, \sigma'_2 \cond t_1, t_2; u) + P(\sigma'_1, \sigma'_2 \cond t_1, t_2; u)} \\ & =  \frac{m}{k + m}\end{align*} 
\begin{align*}P(\sigma_2 \cond \sigma_1, t_1, t_2; u)   & = \frac{P(\sigma_1, \sigma_2 \cond t_1, t_2; u)}{P(\sigma_1 \cond t_1, t_2; u)} = \frac{P(\sigma_1, \sigma_2 \cond t_1, t_2; u)}{P(\sigma_1, \sigma_2 \cond t_1, t_2; u) + P(\sigma_1, \sigma'_2 \cond t_1, t_2; u)}        \\ & =  \frac{j}{j + k}\end{align*} 
\begin{align*}P(\sigma_2 \cond \sigma'_1, t_1, t_2; u)  & = \frac{P(\sigma'_1, \sigma_2 \cond t_1, t_2; u)}{P(\sigma'_1 \cond t_1, t_2; u)} = \frac{P(\sigma'_1, \sigma_2 \cond t_1, t_2; u)}{P(\sigma'_1, \sigma_2 \cond t_1, t_2; u) + P(\sigma'_1, \sigma'_2 \cond t_1, t_2; u)}   \\ & =  \frac{l}{l + m}\end{align*} 
\begin{align*}P(\sigma'_2 \cond \sigma_1, t_1, t_2; u)  & = \frac{P(\sigma_1, \sigma'_2 \cond t_1, t_2; u)}{P(\sigma_1 \cond t_1, t_2; u)} = \frac{P(\sigma_1, \sigma'_2 \cond t_1, t_2; u)}{P(\sigma_1, \sigma_2 \cond t_1, t_2; u) + P(\sigma_1, \sigma'_2 \cond t_1, t_2; u)}     \\ & =  \frac{k}{j + k} \end{align*}
\begin{align*}P(\sigma'_2 \cond \sigma'_1, t_1, t_2; u) & = \frac{P(\sigma'_1, \sigma'_2 \cond t_1, t_2; u)}{P(\sigma'_1 \cond t_1, t_2; u)} = \frac{P(\sigma'_1, \sigma'_2 \cond t_1, t_2; u)}{P(\sigma'_1, \sigma_2 \cond t_1, t_2; u) + P(\sigma'_1, \sigma'_2 \cond t_1, t_2; u)} \\ & =  \frac{m}{l + m}\end{align*} 


\noindent Now we can substitute these simpler and more transparently interrelated fractions into the inequalities above. The first set of inequalities becomes: \label{page:Pareto-Nash inequalities}

\noindent either
\[ \frac{j}{j + l}a_{\cal A} + \frac{l}{j + l}c'_{\cal A} > \frac{k}{k + m}c_{\cal A} + \frac{m}{k + m}a'_{\cal A} \]
and
\[ \frac{j}{j + l}a_{\cal B} + \frac{l}{j + l}c'_{\cal B} \geq \frac{k}{k + m}c_{\cal B} + \frac{m}{k + m}a'_{\cal B} \]
\noindent or
\[ \frac{j}{j + l}a_{\cal A} + \frac{l}{j + l}c'_{\cal A} \geq \frac{k}{k + m}c_{\cal A} + \frac{m}{k + m}a'_{\cal A} \]
and
\[ \frac{j}{j + l}a_{\cal B} + \frac{l}{j + l}c'_{\cal B} > \frac{k}{k + m}c_{\cal B} + \frac{m}{k + m}a'_{\cal B} \]

\noindent The second set of inequalities becomes:

\noindent either

\[ \frac{j}{j + k}a_{\cal A} + \frac{k}{j + k}c'_{\cal A} > \frac{l}{l + m}c_{\cal A} + \frac{m}{l + m}a'_{\cal A} \]
and
\[ \frac{j}{j + k}a_{\cal B} + \frac{k}{j + k}c'_{\cal B} \geq \frac{l}{l + m}c_{\cal B} + \frac{m}{l + m}a'_{\cal B} \]

\noindent or
\[ \frac{j}{j + k}a_{\cal A} + \frac{k}{j + k}c'_{\cal A} \geq \frac{l}{l + m}c_{\cal A} + \frac{m}{l + m}a'_{\cal A} \]
and
\[ \frac{j}{j + k}a_{\cal B} + \frac{k}{j + k}c'_{\cal B} > \frac{l}{l + m}c_{\cal B} + \frac{m}{l + m}a'_{\cal B} \]
~\\
\noindent Recalling that $a_{\cal A} = a'_{\cal A} > c'_{\cal A} = c_{\cal A}$ and $a_{\cal B} = a'_{\cal B} > c'_{\cal B} = c_{\cal B}$, cross-multiplying and simplifying, and combining the two sets of inequalities, we get:
\[ (jk > lm\ \hbox{and}\ jl > km)\ \hbox{for}\ {\cal A}\ \hbox{and}\ (jk \geq lm\ \hbox{and}\ jl \geq km)\  \hbox{for}\ {\cal B} \]

\noindent or 
\[ (jk \geq lm\ \hbox{and}\ jl \geq km)\ \hbox{for}\ {\cal A}\ \hbox{and}\ (jk > lm\ \hbox{and}\ jl > km)\  \hbox{for}\ {\cal B} \]

\noindent This further simplifies to:
\begin{equation} 
jk > lm\ \ \hbox{and}\ \ jl > km\ \ \hbox{for both agents} \label{eq:funda}
\end{equation}

\noindent Now Equation~\ref{eq:funda} can be simplified in two different ways. First, multiplying the two inequalities, we get:

\[ j^2kl > m^2kl \]

\noindent which implies:

\[ j > m \]


\noindent As $j = P(\sigma_1,\sigma_2 \cond t_1, t_2; u)$ and $m = P(\sigma'_1,\sigma'_2 \cond t_1, t_2; u)$, this tells us that for $(\sigma_1, \sigma_2)$ to be a Pareto-Nash equilibrium of $g_1$ and for $(\sigma_2, \sigma_1)$ to simultaneously be a Pareto-Nash equilibrium of $g_2$, we must have:
\[ P(\sigma_1,\sigma_2 \cond t_1, t_2; u) > P(\sigma'_1,\sigma'_2 \cond t_1, t_2; u) \]

\noindent As already noted above, $P(\sigma_1 \cond \sigma_2, t_1, t_2; u) > P(\sigma'_1 \cond \sigma_2, t_1,\allowbreak t_2; u)$ and $P(\sigma_1 \cond \sigma'_2, t_1,\allowbreak t_2; u) < P(\sigma'_1 \cond \sigma'_2, t_1, t_2; u)$. This implies:
\[ P(\sigma_1,\sigma_2 \cond t_1, t_2; u) > P(\sigma'_1,\sigma_2 \cond t_1, t_2; u) \]

\noindent and
\[ P(\sigma_1,\sigma_2 \cond t_1, t_2; u) > P(\sigma_1,\sigma'_2 \cond t_1, t_2; u) \]

\noindent So $P(\sigma_1,\sigma_2 \cond t_1, t_2; u)$ is the maximum among \[\Bigl\{P(\sigma_1,\sigma_2 \cond t_1, t_2; u), P(\sigma'_1,\sigma_2 \cond t_1, t_2; u), P(\sigma_1,\sigma'_2 \cond t_1, t_2; u), \break P(\sigma'_1,\sigma'_2 \cond t_1, t_2; u)\Bigr\}\text{.}\] Looking back to Figure~\ref{fig:semantic sentential game g12}, this simply means that for $(\sigma_1, \sigma_2)$ to be a Pareto-Nash equilibrium of $g_1$ and for $(\sigma_2, \sigma_1)$ to be a Pareto-Nash equilibrium for $g_2$, all that is required is that the prior probability $\rho_{12} = P(\sigma_1,\sigma_2 \cond t_1, t_2; u)$ be the maximum among the four priors in the product game $g_{12}$. This result could also be obtained by solving $g_{12}$ directly for its Nash equilibrium which can be seen to be $\sigma_1\sigma_2$ by similar computations. Importantly, in examples with syntactic ambiguity we would need to consider the full mixed semantic-syntactic sentential product mentioned on page~\pageref{page:mixed products} and compute its Nash equilibrium.\footnote{See \chapref{ch:syntactic ambiguity}.}

Keep in mind that this is the result when these pairs form the unique Pareto-Nash equilibria of their respective games. There is no guarantee that this will always happen. It is quite possible, in a particular locutionary game, to have $P(\sigma_1,\sigma_2 \cond t_1, t_2; u) = P(\sigma'_1,\sigma'_2 \cond t_1, t_2; u)$. In such cases, the best that can be said is that \emph{both} sets of solutions are plausible contents of the communication. This can certainly happen, and does, for example, with puns. But, in the communication at hand, it can safely be asserted that: 

\[ P(\sigma_1,\sigma_2 \cond t_1, t_2; u) > P(\sigma'_1,\sigma'_2 \cond t_1, t_2; u) \]

\noindent and that $P(\sigma_1,\sigma_2 \cond t_1, t_2; u)$ is the \emph{strict} maximum of \[\Bigl\{P(\sigma_1,\sigma_2 \cond t_1, t_2; u), P(\sigma'_1,\sigma_2 \cond t_1, t_2; u), P(\sigma_1,\sigma'_2 \cond t_1, t_2; u), \break P(\sigma'_1,\sigma'_2 \cond t_1, t_2; u)\Bigr\}\] given the nature of $u$. This is because the implicit shared goal of $u$ is to discuss the local election and so it gives a bigger boost to $P(\sigma_1,\sigma_2 \cond t_1, t_2; u)$ than to $P(\sigma'_1,\sigma'_2 \cond t_1, t_2; u)$. In other words, when it is warranted by $u$, the Pareto-Nash inequalities will naturally yield a strict or unique maximum, and when it is not warranted, they will not.

An alternative manipulation of Equation~\ref{eq:funda} implies:
\[ jk + jm > jm + lm\ \ \hbox{and}\ \ jl + jm > jm + km \]

\noindent and so:
\[ \frac{j}{j + l} > \frac{m}{k + m}\ \ \hbox{and}\ \ \frac{j}{j + k} > \frac{m}{l + m} \]

\noindent which is just:
\[ P(\sigma_1 \cond \sigma_2, t_1, t_2; u) > P(\sigma'_1 \cond \sigma'_2, t_1, t_2; u)\ \hbox{and}\ P(\sigma_2 \cond \sigma_1, t_1, t_2; u) > P(\sigma'_2 \cond \sigma'_1, t_1, t_2; u) \]

\noindent Therefore $P(\sigma_1 \cond \sigma_2, t_1, t_2; u)$ is the maximum among the four priors 
\[\Bigl\{P(\sigma_1 \cond \sigma_2, t_1, t_2; u), P(\sigma'_1 \cond \sigma_2, t_1, t_2; u),\break P(\sigma_1 \cond \sigma'_2, t_1, t_2; u), P(\sigma'_1 \cond \sigma'_2, t_1, t_2; u)\Bigr\}\]
in the two versions of $g_1$ and $P(\sigma_2 \cond \sigma_1, t_1, t_2; u)$ is simultaneously the maximum among the four priors \[\Bigl\{P(\sigma_2 \cond \sigma_1, t_1, t_2; u), P(\sigma'_2 \cond \sigma_1, t_1, t_2; u), P(\sigma_2 \cond \sigma'_1, t_1, t_2; u), P(\sigma'_2 \cond \sigma'_1, t_1, t_2; u)\Bigr\}\]
in the two versions of $g_2$.

\subsection{A theorem}

Thus, $LG_u(\varphi) = \{g_1, g_2, g_{12}, g'_1, g'_2, g'_{12}\}$ can be solved in two equivalent ways. We can confine our attention to just the lexical games and select the maximum priors across all versions in each game, ensuring that the priors are compatible, that is, that the conditioning variable in one is a conditioned variable in the other and vice versa. Or we can choose the maximum priors in the full mixed semantic-syntactic sentential product game. In the simple example at hand, the parse trees $t_1$ and $t_2$ did not play any real role so we were able to manage with just the semantic sentential product, but when they do, then the full mixed semantic-syntactic sentential product needs to be accessed. I record this important observation below.\footnote{Important statements are displayed as theorems rather than facts or propositions even though their proofs are not particularly complex. I do not actually give proofs of any of the theorems but I hope the example considered makes them plausible.}

\begin{theorem}

The locutionary global game induced by an utterance can be solved either by solving just the lexical games in it or by solving just the full mixed sentential game or by solving appropriate intermediate phrasal games.
\label{thm:one}
\end{theorem} 

From both a psycholinguistic and computational viewpoint as well, all that has to be done is to work with either the conditional probabilities of the lexical games or the joint probabilities of the product games and select the corresponding maximum values. This gives us the solution to the locutionary global game in a completely rigorous and foundational way assuming nothing more than the rationality of agents.

The foregoing calculations show that there is a certain kind of overdetermination at work. First, the conditions for $\cal A$'s best actions yield the same results as the conditions for $\cal B$'s best actions so they are, in a sense, superfluous. And we know that $\cal A$ makes his choice of probability distributions or versions based on $\cal B$'s choices in the other games. However, this \emph{is} a nontrivial decision and it is $\cal A$ who decides to let it depend on $\cal B$'s choices in the other local games. The results therefore show that $\cal A$'s making his choices compatible with $\cal B$'s is in fact optimal from $\cal A$'s viewpoint. Incidentally, the same decision procedure in her choice of probability distribution or version works optimally for $\cal B$ as well.

\subsection{The compact form}\is{game!compact form|(}

The information contained in the locutionary global game $LG_u(\varphi) = \{g_1, g_2,\allowbreak g_{12},\allowbreak g'_1,\allowbreak g'_2, g'_{12}\}$ is scattered across six separate local games. But these games are highly interconnected and have a reciprocity through their prior probabilities. Is there a way to capture these dependencies in a more compact way? The answer is yes, as determined by the game theorist Ennio Stacchetti\ia{Stacchetti, Ennio} during a private discussion about $LG_u(\varphi)$. He came up with a single representation that compactly marshals all the information dispersed among the six local games, assuming that $\cal A$'s and $\cal B$'s choice of version or probability distribution is compatible with $\cal B$'s choices in the other games. I call the former representation the \emph{distributed} form of $LG_u(\varphi)$ and Stacchetti's representation the \emph{compact} form of $LG_u(\varphi)$. The existence of the compact form shows that it is right to think of $LG_u(\varphi)$ as a single game. I have tried to motivate this a little via the various calculations above. The compact form is shown in Figure~\ref{fig:compact form}.\footnote{This representation can also be referred to as a normal or strategic form. It is in fact both, a compact form and a normal form, the first because of its relation to the distributed form and the second because it is itself related to a so-called extensive form which is different from the distributed form. In other words, the distributed form can be translated into a single extensive form as well. Thus, we have the distributed form $\sim$ the compact form $\equiv$ the normal form $\sim$ the extensive form.}

\begin{figure}[h]
\renewcommand{\arraystretch}{2.0}
\resizebox{\textwidth}{!}{\begin{tabular}{c|c|c|c}
\multicolumn{1}{c}{$t_1$, $t_2$} & \multicolumn{1}{c}{$\sigma_2$} & \multicolumn{1}{c}{$\sigma'_2$} \\[.5ex]
 \cline{2-3}
$\sigma_1$ & $P(\sigma_1 \cond \sigma_2, t_1, t_2; u), P(\sigma_2 \cond \sigma_1, t_1, t_2; u), 1, 1$ & $P(\sigma_1 \cond \sigma'_2, t_1, t_2; u), P(\sigma'_2 \cond \sigma_1, t_1, t_2; u), 1, 1$ & \qquad \\[.5ex]
 \cline{2-3}
 $\sigma'_1$ & $P(\sigma'_1 \cond \sigma_2, t_1, t_2; u), P(\sigma_2 \cond \sigma'_1, t_1, t_2; u), 1, 1$ & $P(\sigma'_1 \cond \sigma'_2, t_1, t_2; u), P(\sigma'_2 \cond \sigma'_1, t_1, t_2; u), 1, 1$ & \qquad \\[.5ex]
% \cline{2-3}
% $\varphi_1\varphi''_1$ & 9.7, 12.7 & -8.3, -12.5 & \qquad \\[.5ex]
% \cline{2-3}
% $\varphi'_1\varphi''_1$ &  7, 10 & 7, 10 & \qquad \\[.5ex]
 \cline{2-3}
% \multicolumn{4}{c}{$x =$ one million}
 \end{tabular}}
 \caption{The compact form of $LG_u(\varphi)$} \label{fig:compact form}
\end{figure}

In this new, more abstract representation of $LG_u(\varphi)$, the players are no longer $\cal A$ and $\cal B$ but may be said to be the four lexical variables $x_1$, $x_2$, $y_1$, $y_2$ corresponding to the semantic and syntactic contents of the two words \Expression{bill} and \Expression{ran} in the sentence $\varphi$ uttered in $u$. (Alternatively, the words could be said to be the players but each word would be taken as having two avatars, one semantic and one syntactic.) Readers new to game theory may feel that the players in a game have to be \emph{agents} as ordinarily conceived but  it is possible to allow games to have a more abstract kind of agency with more abstract kinds of players as we have here.

Recall that $x_1$ stood for either $\sigma_1$ or $\sigma'_1$ and these are the two strategies available to the player $x_1$. Similarly, $x_2$ has the two strategies $\sigma_2$ and $\sigma'_2$. These two sets of strategies are shown on the left and on top of the payoff matrix. The other two players $y_1$ and $y_2$ have just single strategies $t_1$ and $t_2$ so they are shown in the upper left corner of Figure~\ref{fig:compact form} in order to avoid having to present a four-dimensional matrix with the third dimension labeled $t_1$ and the fourth $t_2$. Instead of a four-dimensional matrix, multiple two-dimensional matrices can also represent the strategies of these players were they to have some real choice. In general, for a sentence with $n$ words there would be a $2n$-dimensional matrix because there would be $n$ semantic variables and $n$ syntactic variables. The payoffs for the various combinations of strategies are shown in the cells of the matrix. For example, in the first cell, we have the vector $(P(\sigma_1 \cond \sigma_2, t_1, t_2; u), P(\sigma_2 \cond \sigma_1, t_1, t_2; u), 1, 1)$ which indicates that the payoff to $x_1$ is the first component, the payoff to $x_2$ is the second component, and the payoffs to $y_1$ and $y_2$ are just 1 and 1 because the relevant conditional probabilities $P(t_1 \cond \sigma_1, \sigma_2, t_2; u) = 1$ as shown in Figure~\ref{fig:syntactic lexical game g1'} and $P(t_2 \cond \sigma_1, \sigma_2, t_1; u) = 1$ as shown in Figure~\ref{fig:syntactic lexical game g2'}.

The somewhat complicated mass of symbols in Figure~\ref{fig:compact form} can be simplified if we drop the players $y_1$, $y_2$ as they are just silent bystanders and make the substitution of letters for conditional probabilities I had suggested above. The result is shown in Figure~\ref{fig:compact form 2}.

\begin{figure}[h]
\renewcommand{\arraystretch}{2.0}
\begin{tabular}{c|c|c|c}
\multicolumn{1}{c}{} & \multicolumn{1}{c}{$\sigma_2$} & \multicolumn{1}{c}{$\sigma'_2$} \\[.5ex]
 \cline{2-3}
$\sigma_1$ & $\frac{j}{j+l}, \frac{j}{j + k}$ & $\frac{k}{k+m}, \frac{k}{j + k}$ & \qquad \\[.5ex]
 \cline{2-3}
 $\sigma'_1$ & $\frac{l}{j + l}, \frac{l}{l + m}$ & $\frac{m}{k+m}, \frac{m}{l + m}$ & \qquad \\[.5ex]
 \cline{2-3}
 \end{tabular}
 \caption{The compact form of $LG_u(\varphi)$ with simpler symbols} \label{fig:compact form 2}
\end{figure}

This is now a familiar sort of game with a payoff matrix for two players. From the distribution of payoffs, it can be immediately seen that there must be at least one pure strategy Nash equilibrium. This is because a Nash equilibrium implies that neither player would want to deviate unilaterally from it. If no such Nash equilibrium existed, there would have to be a cycle with strategy profile $(\sigma_1,\sigma_2)$ dominated by $(\sigma'_1,\sigma_2)$ for the first player (that is, the first player would deviate unilaterally from its strategy $\sigma_1$ to another strategy $\sigma'_1$), which in turn would be dominated by $(\sigma'_1,\sigma'_2)$ for the second player, which would itself be dominated by $(\sigma_1,\sigma'_2)$ for the first player again, which would finally be dominated by $(\sigma_1,\sigma_2)$ for the second player. In other words, there would be no ``resting place'' or Nash equilibrium. This would happen if the following inequalities among payoffs held, where the symbol ``$\prec_i$'' for $i = 1, 2$ stands for ``dominated by for player $i$'':
\[\renewcommand{\arraystretch}{2.0}\begin{array}{lcrl}
(\sigma_1,\sigma_2) \prec_1 (\sigma'_1,\sigma_2)   & \ \hbox{implies} & \frac{j}{j + l} & < \frac{l}{j + l}\\
(\sigma'_1,\sigma_2) \prec_2 (\sigma'_1,\sigma'_2) & \ \hbox{implies} & \frac{l}{l + m} & < \frac{m}{l + m}\\
(\sigma'_1,\sigma'_2) \prec_1 (\sigma_1,\sigma'_2) & \ \hbox{implies} & \frac{m}{k + m} & < \frac{k}{k + m}\\
(\sigma_1,\sigma'_2) \prec_2 (\sigma_1,\sigma_2)   & \ \hbox{implies} & \frac{k}{j + k} & < \frac{j}{j + k}\\
\end{array}\]

\noindent all of which together imply $j < l < m < k < j$, a contradiction. This means there cannot be such a cycle. It should be clear by symmetry considerations that such an argument will apply to any compact form. I record this below.

\begin{theorem} \label{thm:two}
Every compact form of a locutionary global game has at least one Nash equilibrium in pure strategies.
\end{theorem}


For $(\sigma_1, \sigma_2)$ to be a Nash equilibrium, we must have:
\[ \frac{j}{j + l} \geq \frac{l}{j + l} \]
and
\[\frac{j}{j + k} \geq \frac{k}{j + k} \]

\noindent These inequalities imply $j \geq l$ and $j \geq k$. For $(\sigma'_1, \sigma'_2)$ to be a Nash equilibrium, we must have:

\[ \frac{m}{k + m} \geq \frac{k}{k + m} \]
and
\[\frac{m}{l + m} \geq \frac{l}{l + m} \]

\noindent These inequalities imply $m \geq k$ and $m \geq l$. If both $(\sigma_1, \sigma_2)$ and $(\sigma'_1, \sigma'_2)$ are Nash equilibria -- as we saw earlier -- then in order for the former to be the unique Pareto-Nash equilibrium, we must have: 

\noindent either
\[ \frac{j}{j + l} > \frac{m}{k + m} \]
and
\[\frac{j}{j + k} \geq \frac{m}{l + m} \]
or
\[ \frac{j}{j + l} \geq \frac{m}{k + m} \]
and
\[\frac{j}{j + k} > \frac{m}{l + m} \]

\noindent This implies either $jk > lm$ and $jl \geq km$ or $jk \geq lm$ and $jl > km$, both of which imply $j > m$, exactly as we had when we considered the distributed form. But notice how much easier it was to obtain the result.

So far, I have considered just the four lexical variables $x_1$, $x_2$, $y_1$, $y_2$ derived from the words in the sentence as players but there are, in fact, potentially phrasal and sentential variables too. These are $x_{12} = x_1 \odot x_2$ and $y_{12} = y_1 \star y_2$. The four possible strategies of $x_{12}$ are $\sigma_1\sigma_2$, $\sigma_1\sigma'_2$, $\sigma'_1\sigma_2$, and $\sigma'_1\sigma'_2$ and the single strategy of $y_{12}$ is $t_1t_2$. But since these choices of the sentential variables are in fact determined by the choices of the four lexical players, these sentential players have no \emph{real} choice beyond the lexical choices. And, indeed, this is reflected in the fact that the payoffs the semantic sentential variables receive from the four strategy choices -- $P(\sigma_1,\sigma_2 \cond t_1, t_2; u) = j$, $P(\sigma_1,\sigma'_2 \cond t_1, t_2; u) = k$, $P(\sigma'_1,\sigma_2 \cond t_1, t_2; u) = l$, and $P(\sigma'_1,\sigma'_2 \cond t_1, t_2; u) = m$ -- are also ordered by the requirements we have displayed above for various equilibria. For example, as we just saw, if $(\sigma_1, \sigma_2)$ is a Pareto-Nash equilibrium of the compact form, then $P(\sigma_1,\sigma_2 \cond t_1, t_2; u) = j$ is automatically the maximum among \begin{multline*}
    \Bigl\{P(\sigma_1,\sigma_2 \cond t_1, t_2; u), P(\sigma_1,\sigma'_2 \cond t_1, t_2; u), P(\sigma'_1,\sigma_2 \cond t_1, t_2; u), P(\sigma'_1,\sigma'_2 \cond t_1, t_2; u)\Bigr\} \\ = \{j, k, l, m\}\text{.}\end{multline*}
This leads to an insight that is parallel to Theorem~\ref{thm:one} above.

\begin{theorem} \label{thm:three}
The compact form of a locutionary global game contains all the information required to determine its equilibrium. There is no need to consider nonlexical players.
\end{theorem}

\noindent Theorems~\ref{thm:two} and \ref{thm:three} immediately imply the next observation.

\begin{theorem}
Every locutionary global game has at least one Nash equilibrium in pure strategies. \label{thm:existence of Nash}
\end{theorem}

\noindent This result does not imply that mixed strategies may never appear as equilibria. When there is more than one Nash equilibrium in pure strategies, there may not be a unique Pareto-Nash equilibrium in pure strategies, in which case a unique mixed strategy equilibrium may be optimal.
\is{game!compact form|)}

\subsection{The main theorems}\label{sec:maintheorem}

In general, a sentence $\varphi$ can be expressed as $\varphi_1 \circ \varphi_2 \circ \ldots \circ \varphi_n = \varphi_1 \varphi_2 \ldots \varphi_n$ where each $\varphi_i$ is a word and there are $n$ words in the sentence. If $\varphi$ is uttered in some utterance situation $u$, then each word $\varphi_i$ has a range of possible referential meanings given by the Semantic Constraint. The variable $x_i$ stands for these possible meanings of $\varphi_i$ and all such $x_i$ together form the \emph{meaning vector} $x = (x_1, x_2, \ldots, x_n)$. Likewise, the possible parse trees $y_j$ of each word $\varphi_j$ can be collected in the \emph{parse vector} $y = (y_1, y_2, \ldots, y_n)$. Here, the range of each variable $y_j$ is given by the Syntactic Constraint.

The meaning and parse vectors $x$ and $y$ together form the \emph{content vector} $z = (x, y)$ with $2n$ components. This vector ranges over all the possible lexical meanings and parses of $\varphi$ uttered in $u$. Note that $y_j = z_{n + j}$. Also, $z_{-k} = (z_1, z_2, \ldots, z_{k-1},\allowbreak z_{k+1}, \ldots, z_{2n})$. That is, $z_k$ is dropped from $z$ in $z_{-k}$. Finally, $z^{\star}$ represents the equilibrium meaning and parse of all the lexical items.

We are now ready to state the central result of this section based on all the calculations above. 

\begin{theorem}
Given an utterance and its locutionary global game (with symmetric payoffs), its lexical meanings and parses are given by the following equivalent characterizations:
\begin{equation}
z^\star = \argmax_{z} P(z_k \cond z_{-k}; u) = \argmax_{z} P(z; u), \quad k = 1, \dots, 2n \label{eq:simple}
\end{equation}

\noindent When there is more than one solution, each solution is given an equal probability.\footnote{By Theorem~\ref{thm:existence of Nash}, a solution always exists.} The meaning and parse of the whole utterance can be obtained by computing the products of the lexical meanings and parses.
\label{thm:simple equation}
\end{theorem}


\noindent Equation~\ref{eq:simple} is called the Fundamental Equation of Equilibrium Linguistics. It provides a constraint on the beliefs of speakers and addressees in communication. The term $\argmax_{z} P(z_k \cond z_{-k}; u)$ after the first equality sign and the term $\argmax_{z} P(z; u)$ after the second equality sign refer implicitly to the lexical\linebreak games and to the full mixed semantic-syntactic sentential product game in the locutionary global game. Equation~\ref{eq:simple} improves upon the equation in \citet[Section~7.4]{parikh:le} where the equivalence between the two ways of calculating $z^\star$ remained implicit. In principle, all a computing agent has to do is to run through the finite number of alternatives one by one until one or more vectors $z^{\star}$ is found to solve the system. It would be very easy to extend it to the Phonetic Constraint and to phonetic contents. At the start of this section, I mentioned the solution function $f_u$ which allows us to write $f_u[LG_u(\varphi)] = \{f_u(g_1), f_u(g_2), f_u(g_{12}), f_u(g'_1),\allowbreak f_u(g'_2),\allowbreak f_u(g'_{12})\} = \{\sigma_1, \sigma_2, \sigma_1\sigma_2, t_1, t_2, t_1t_2\}$. This function is an equivalent way of expressing $z^{\star}$.

The Fundamental Equation treats semantic, syntactic, (and phonetic) contents in a completely homogeneous manner. This is what justifies calling them all \emph{contents} of the utterance. It also shows how the pipeline view of meaning -- first phonetics, then syntax, then semantics, and last pragmatics -- is\is{meaning!pipeline view of} completely transcended and replaced by a circular system of simultaneous equations. As I will show in \sectref{sec:compositionality/context}, this is one way in which Equilibrium Linguistics generalizes Frege's principle of compositionality\is{compositionality} because Frege assumed that semantics reflects syntax but not the other way around. In Equilibrium Linguistics, all three contents -- semantics, syntax, and phonetics -- reflect one another. I do not show this right away as it is better to first complete the analysis fully and then discuss the philosophical consequences that emerge.

I had assumed earlier that $a_{\cal A} = a'_{\cal A}$, $c_{\cal A} = c'_{\cal A}$, $a_{\cal B} = a'_{\cal B}$, and $c_{\cal B} = c'_{\cal B}$, making the games coordination games. This is what allowed us to essentially ignore the payoffs and this is why we got the pure probabilistic result above. However, in general, these payoffs may not be symmetric because different outcomes corresponding to correct or incorrect interpretations may be valued differently by each agent. It is not difficult to bring the payoffs back in by simply scaling the conditional probabilities by appropriate factors in accordance with the inequalities for Pareto-Nash equilibria on page~\pageref{page:Pareto-Nash inequalities} as shown in Figure~\ref{fig:scaled compact form 2}.\largerpage


%\begin{figure}[htbp]
%\begin{center}
%\renewcommand{\arraystretch}{2.0}
%\begin{tabular}{c|c|c|c}
%\multicolumn{1}{c}{} & \multicolumn{1}{c}{$\sigma_2$} & \multicolumn{1}{c}{$\sigma'_2$} \\[.5ex]
% \cline{2-3}
%$\sigma_1$ & $P(\sigma_1 \cond \sigma_2, t_1, t_2; u)a_{\cal B} + P(\sigma'_1 \cond \sigma_2, t_1, t_2; u)c'_{\cal B}, P(\sigma_2 \cond \sigma_1, t_1, t_2; u)a_{\cal B} + P(\sigma'_2 \cond \sigma_1, t_1, t_2; u)c'_{\cal B}$ & $P(\sigma_1 \cond \sigma'_2, t_1, t_2; u)a_{\cal B} + P(\sigma'_1 \cond \sigma'_2, t_1, t_2; u)c'_{\cal B}, P(\sigma'_2 \cond \sigma_1, t_1, t_2; u)a'_{\cal B} + P(\sigma_2 \cond \sigma_1, t_1, t_2; u)c_{\cal B}$ & \qquad \\[.5ex]
% \cline{2-3}
% $\sigma'_1$ & $\frac{l}{j + l}a'_{\cal B} + \frac{j}{j+l}c_{\cal B}, \frac{l}{l + m}a'_{\cal B} + \frac{l}{l + m}c_{\cal B}$ & $\frac{m}{k+m}a'_{\cal B} + \frac{k}{k+m}c_{\cal B}, \frac{m}{l + m}a'_{\cal B} + \frac{l}{l + m}c_{\cal B}$ & \qquad \\[.5ex]
% \cline{2-3}
% \end{tabular}
% \vspace{.05in}
% \caption{The scaled compact form of $LG_u(\varphi)$} \label{fig:scaled compact form 2}
% \end{center} 
%\end{figure}


\begin{figure}[h]
\renewcommand{\arraystretch}{2.0}
\begin{tabular}{c|c|c|c}
\multicolumn{1}{c}{} & \multicolumn{1}{c}{$\sigma_2$} & \multicolumn{1}{c}{$\sigma'_2$} \\[.5ex]
 \cline{2-3}
$\sigma_1$ & $\frac{j}{j+l}a_{\cal B} + \frac{l}{j+l}c'_{\cal B}, \frac{j}{j + k}a_{\cal B} + \frac{k}{j + k}c'_{\cal B}$ & $\frac{k}{k+m}a_{\cal B} + \frac{m}{k+m}c'_{\cal B}, \frac{k}{j + k}a'_{\cal B} + \frac{j}{j + k}c_{\cal B}$ & \qquad \\[.5ex]
 \cline{2-3}
 $\sigma'_1$ & $\frac{l}{j + l}a'_{\cal B} + \frac{j}{j+l}c_{\cal B}, \frac{l}{l + m}a_{\cal B} + \frac{m}{l + m}c'_{\cal B}$ & $\frac{m}{k+m}a'_{\cal B} + \frac{k}{k+m}c_{\cal B}, \frac{m}{l + m}a'_{\cal B} + \frac{l}{l + m}c_{\cal B}$ & \qquad \\[.5ex]
 \cline{2-3}
 \end{tabular}
 \caption{The scaled compact form of $LG_u(\varphi)$} \label{fig:scaled compact form 2}
\end{figure}


I will not analyze this scaled form of the locutionary game but just state the corresponding equation that results. Figure~\ref{fig:scaled compact form 2} reflects $\cal B$'s payoffs rather than $\cal A$'s though a corresponding matrix exists for $\cal A$ even though he has no choice of utterance. Let $V^{\cal B}_k(z, z'_k)$ be $\cal B$'s payoffs in the lexical game $g_k$ (or $g'_{(k-n)}$ if $k > n$ and the game is syntactic rather than semantic) and $V^{\cal B}(z, z')$ be her payoffs in the full mixed sentential game: these payoffs vary with different values of the vectors $z$ and $z'$, both of which represent full independent content vectors for $\varphi$. This notation compactly captures all the different individual payoffs such as $a_{\cal B}$, $a'_{\cal B}$, $c_{\cal B}$, and $c'_{\cal B}$ and need not be  symmetric, even allowing for variations across the different lexical games.
 

\begin{theorem}
Given a locutionary global game, the lexical meanings and parses of an utterance are given by the following equivalent characterizations:
\begin{equation}\label{eq:simple with payoffs}
\begin{split}
z^\star & = \argmax_{z_{-k}, z'_k} \sum_{z_k} P(z_k \cond z_{-k}; u)V^{\cal B}_k(z, z'_k)\\
        & = \argmax_{z'} \sum_{z} P(z; u)V^{\cal B}(z, z'), \quad k = 1, \dots, 2n 
\end{split}
\end{equation}

\noindent When there is more than one solution, each solution is given an equal probability. The meaning and parse of the whole utterance can be obtained by computing the products of the lexical meanings and parses.

\label{thm:compatibility with payoffs}

\end{theorem}

\noindent Equation~\ref{eq:simple with payoffs} may be called the Fundamental Equation of Equilibrium Linguistics with Payoffs. It expresses a more general result of our analysis and can also be put in matrix form. Generally Equation~\ref{eq:simple} suffices although in certain contexts as pointed out in \sectref{sec:cl} we have to resort to Equation~\ref{eq:simple with payoffs}.

This completes my discussion of how locutionary global games are solved. The description has taken a few pages but the results are strikingly simple and in accord with our intuitions. All that needs to be done is to find the interpretations with the highest probabilities in a \emph{compatible} manner where by ``compatible'' I mean the property that $\argmax_{z} P(z_k \cond z_{-k}; u) = \argmax_{z} P(z; u)$ as described by Equation~\ref{eq:simple}. One aspect of this -- identifying the \emph{most likely} contents -- is certainly common in both human and artificial contexts. But the second aspect -- maximizing these probabilities in a \emph{compatible} manner -- is less evident. That communication involves semantic, syntactic, and phonetic contents mutually determining one another via such an intricate probabilistic structure is remarkable.

Just to be clear that not every probability distribution is compatible, Figure~\ref{fig:incompatible distribution} shows a distribution $P(z_1, z_2)$ with two variables $z_1$, $z_2$ and three values in the range of each variable that is not.

\begin{figure}[h]
\renewcommand{\arraystretch}{1.8}
\begin{tabular}{|c|c|c|c|}					 \hline
$z_1$, $z_2$	& 		$\sigma_2$ & $\sigma'_2$ & $\sigma''_2$					\\\hline
$\sigma_1$					& 0.20 & 0.15 & 0.10		\\	\hline
$\sigma'_1$					& 0.15 & 0.15 & 0.00		\\	\hline
$\sigma''_1$				& 0.10 & 0.00 & 0.15		\\  \hline
\end{tabular}
\caption{An incompatible distribution} \label{fig:incompatible distribution}
\end{figure}

%\[ \left( \begin{array}{ccc}
%0.20 & 0.15 & 0.10 \\
%0.15 & 0.15 & 0.00 \\
%0.10 & 0.00 & 0.15 
%\end{array} \right) \]
%\\

For example, $z_1$ could range over the contents $\sigma_1$, $\sigma'_1$, $\sigma''_1$ corresponding to the three rows and $z_2$ could range over the contents $\sigma_2$, $\sigma'_2$, $\sigma''_2$ corresponding to the three columns. For this distribution, \[\argmax_{z} P(z) = (\sigma_1, \sigma_2)\text{ but }\argmax_{z} P(z_k \cond z_{-k}) = (\sigma''_1, \sigma''_2)\text{,}\] as can be checked by inspection. That is, the maximum of the joint distribution occurs at the first row and first column and the maximum of the conditional distributions occurs at the third row and third column. Such a distribution is ruled out by Theorem~\ref{thm:simple equation}.

Why do compatible probability distributions arise in communication? Recall from page~\pageref{page:intention} in \sectref{sec:generation game} that each prior probability is \emph{not} the conditional probability of some content but is rather the conditional probability of a speaker's \emph{conveying} that content. That is, these prior distributions govern the \emph{intentions} and \emph{actions} of rational agents, of what they would and would not choose to convey or interpret if they were conveying or interpreting certain other things as well. So compatibility describes the two-sided \emph{logic} of rational intention and action. It is co-extensive with rationality itself in the context of communication. Earlier, I had mentioned that in many settings agents are not perfectly rational but because the structures involved in locutionary global games are relatively simple and because the payoffs are also assumed to be symmetric, there is little scope for limited agents to falter. Even when scaled compact forms as shown in Figure~\ref{fig:scaled compact form 2} are used to derive the more general Equation~\ref{eq:simple with payoffs}, there is no reason for rationality to fail.

Equally important, these probability distributions have nothing to do with language per se. The same property would hold in any communication involving images, gestures, and other symbol systems. It may even apply beyond communication to appropriately linked subsystems of a larger system, as I conjecture in \citet[Section~7.1.4]{parikh:le}.

Theorem~\ref{thm:simple equation} provides a theoretical foundation for and generalization of various observations in both psycholinguistics and statistical natural language processing, as I discuss in \chapref{ch:psycholinguistics and cl}. On the other hand, to the best of my knowledge, the philosophy of language and theoretical linguistics and artificial intelligence do not appear to have entertained anything close to such ideas about how locutionary meanings and other contents might be derived from first principles. They usually just say such meanings are ``conventional'' and turn their attention to deriving implicatures using some version of Grice's conversational maxims. The problem of rigorously deriving content is a \emph{philosophical} and \emph{theoretical} problem, not just some detail to be relegated to empirical investigation.

Where do all these probabilities come from? For human interpretation, they would come partly from the grammar and partly from the utterance situation and wider discourse situation and would be based on both objective and subjective factors.\footnote{See \citet{mssn:cdcrdpc} for some recent work on how contextual information is processed by the brain involving a recurrent neural network model and experiments with monkeys. See also \url{http://engineering.stanford.edu/news/stanford-researchers-surprised-find-how-neural-circuits-zero-specific-information-needed-decisi}. These findings, which are still in their infancy, are relevant for all the games in the book as they all make use of contextually derived probabilities.} People are generally quite good at rough probability estimates (as in figuring whether it is likely to rain by looking at the sky) and all they need to determine here is whether certain probabilities are higher than others. No precise numerical estimates are required. For an artificial agent, these probabilities would come from the grammar and from suitable corpora.

To a certain degree, all these probabilities rely on background knowledge of one kind or another, some of which may be present in the encyclopedic knowledge associated with the conventional meaning of a word and some of which may be present in one or more knowledge or belief bases in the agent's head. Some linguists may feel that the explanation has just been pushed back to some unknown probabilities but the problem of determining such probabilities is common to all action, not just communicative action, as should be clear from the \emph{very} wide applicability and, indeed, applications of decision and game theory. Rather than say, as Chomsky\ia{Chomsky, Noam@Chomsky, Noam} has chosen to, that this makes the entire realm of human choice and behavior a mystery, one has to approach it in the usual way of science, which is to first divide the problem into two parts and then to tackle each separately. In the case of communication, I have shown how the problem of deriving locutionary meaning can be reduced to some probabilistic computations. Now, as computer scientists frequently do in limited domains, distributed and interconnected knowledge bases can be set up and it would become very clear how such probabilities can emerge from such data. If an agent knows that black clouds make rain likely and he sees black clouds, it follows that the probability of rain is high. That is all. Indeed, it is not even necessary to build an actual knowledge or belief base in the case of human communication; it suffices merely to assume that it exists and that neuroscience will, in time, enable us to understand how it figures in decision-making. Building satisfactory conversational agents based on Equilibrium Semantics does require constructing and \emph{scaling} the knowledge base sufficiently but I think it is possible to say that the problem of determining locutionary meaning has been solved. I touch upon this point briefly again in \sectref{sec:cl}.

An alternative response to this issue of explaining how such parameters arise is to say that the complaint misunderstands the scientific problem. In physics, for example, the solution to the problem of projectile motion is divided into two parts: the relevant equation of motion and the initial or boundary conditions (e.g.\ the initial velocity). The scientific problem is determining the equation of motion. In different situations, the initial or boundary conditions will be determinable with more or less precision but no one thinks it is reasonable to say that the problem has just been pushed back to some unknown parameters.

I reproduce a paragraph from my dissertation, \emph{Language and Strategic Inference} (\citeyear[5]{parikh:diss}):

\begin{quote}
We will argue for this thesis by developing a detailed account of one
strategic inference in isolation.  Any complete utterance, that is,
any utterance that attempts to express a proposition, will involve
many separate acts and strategic inferences.  For example, part of a
communication will typically involve a referential act, an act of
referring to some object, and the communication of this reference to
the addressee.  Each bit of information communicated will require its
own strategic inference(s).  Thus, any complete utterance involves an
entire system of simultaneous strategic inferences.  These inferences
have to be simultaneous in general because they codetermine each other
in general.  For example, an utterance of ``Bill has the book'' will
require inferring the designata of each of the four words in the
sentence, (not to mention its internal structure), in order to 
determine the proposition expressed.  No word has
any particular priority in this determination. That is, there may be
interactions among the various strategic inferences.  And the
embedding circumstances play a vital role in each inference.
Mathematically, this amounts to a system of simultaneous equations.

\end{quote}
 
%\footnote{For example, they would come partly from \emph{extended} PAS statistics where, by ``extended'' I mean to include all the conditioning variables. This could be further extended by \emph{class-based} models. AMPLIFY THIS}

Earlier, I didn't know how to work out this idea. Now, several years later, I do.

As the Interpretation Game $UG_u(\varphi) = G^{\cal B}_u(\varphi) = LG^{\cal B}_u(\varphi) \cup IG^{\cal B}_u(\varphi) = LG_u(\varphi) \cup IG_u(\varphi) = G_u(\varphi)$ owing to our assumption of equality of the subjective and objective games and common knowledge of them, we have solved the locutionary part of the Interpretation Game the addressee faces. Its illocutionary part will be addressed in \partref{part:IV}. The Generation Game is just a little more complicated as multiple sentences may need to be evaluated and their costs taken into account.


\section{My former partial information games} \label{sec:old partial information game}

Readers familiar with my earlier books will have noticed that a game like the one in Figure~\ref{fig:semantic lexical game g1 again} would ordinarily have been shown as in Figure~\ref{fig:old semantic lexical game g1}.

\begin{figure}[h] 
\input{figures/pix4varphi1algebraic.tex}
\caption{Semantic lexical game $g_1$}
\label{fig:old semantic lexical game g1}
\end{figure}

In this game, there are two more branches with alternative utterances $\varphi'_1$ at $s_1$ and $\varphi''_1$ at $s_{1'}$. These are both \emph{unambiguous} with respect to the ambiguity in $\varphi_1 = \Expression{bill}$. So $\varphi'_1 = \Expression{bill smith}$ and $\varphi''_1 = \Expression{bill jones}$ represent one set of possibilities for these alternatives. As they are unambiguous, there is only one interpretation of each possible, either $\sigma_1$ or $\sigma'_1$. As they are costlier but involve correct interpretations, the resulting payoffs $b_{\cal A}$, $b_{\cal B}$ and $b'_{\cal A}$, $b'_{\cal B}$ are somewhat lower than the corresponding $a$ payoffs and higher than the corresponding $c$ payoffs.

The games I have drawn in this and the previous chapter do not have such alternative utterances for two reasons. When deriving locutionary meaning, if we allow an alternative like $\varphi'_1 = \Expression{bill smith}$, then this alternative itself needs to be interpreted word by word, leading to a possible regress and further disambiguations, which is unrealistic. In \citet[88 and 120--121]{parikh:le}, I suggested dealing with such alternatives \emph{holophrastically} but this is unnecessary. Alternative \emph{contents} are anyway considered by both agents in the Content Selection Game and the speaker \emph{does} occasionally consider more than one alternative sentence (or subsentential expression) in the Generation Game so further alternatives \emph{within} the partial information game are not required. Secondly, such costs are best considered \emph{outside} the locutionary global game $LG_u(\varphi)$ but within the Generation Game $GG_u$. This makes it possible to include more sources of cost.

This dropping of alternative utterances may seem superficially like a small change but it results in \emph{very} different solution processes for these new games of partial information, as readers familiar with the earlier solution processes will no doubt have realized. This is what makes possible the two parts of the Fundamental Equation~\ref{eq:simple} and all the theorems in \sectref{sec:solving locutionary global games}. Earlier, such finer calculations of equilibria were not possible.

Another consequence of this truncated form of the game without the alternatives is that such alternative utterances no longer need to be part of the definition of speaker meaning. The subjective global game $G^{\cal A}_u(\varphi)$ in Definition~\ref{def:means} in \sectref{sec:speaker meaning and word meaning} contains just the sentence $\varphi$.

Others using game theory in this field (e.g.\ \citealt{benz:gtp}),\ia{Benz, Anton@Benz, Anton} largely following the form of my earlier games of partial information above, have also used this idea of alternative utterances, apparently without realizing that these alternatives would themselves need to be evaluated using the same methods that are being applied to the main sentence, which could lead to an undesirable regress. To avoid this, they would once again have to follow my suggestion of locating alternative contents in the Content Selection Game and alternative sentences in the Generation Game outside the local games of partial information.

\section{An interesting complication}\label{sec:complication}
While the results of \sectref{sec:solving locutionary global games} are quite powerful, they depend on a condition that has been left implicit.\footnote{I did this deliberately to simplify the discussion as will become clear in this section.} Consider an utterance of the following sentence:

\begin{exe}
\ex The boy saw the girl with a telescope. ($\mu$)
\end{exe}

\noindent As is well known, the prepositional phrase \Expression{with a telescope} can attach either to the verb \Expression{saw} (i.e.\ to the verb phrase \Expression{saw the girl}) or to the noun \Expression{girl} and so $\mu$ is syntactically ambiguous. But there is no syntactic ambiguity at the level of lexical categories if they are expressed as in an ordinary CFG. The product of the optimal lexical parses obtained via Theorem~\ref{thm:simple equation} would then always yield \emph{two} sentential parses even though the situation $u$ in which $\mu$ is uttered may suffice to disambiguate between them.

%In other words, if we were to carry out the computation enjoined by Theorem~\ref{thm:simple equation} at a purely lexical level -- $z^\star = \argmax_{z} P(z_k \cond z_{-k}; u)$ -- we would get \emph{two} optimal parses instead of one even though the situation $u$ in which $\mu$ is uttered may suffice to disambiguate between them and even if $\argmax_{z} P(z; u)$ yields just a single optimal parse. That is, strictly speaking, $\argmax_{z} P(z_k \cond z_{-k}; u) \neq \argmax_{z} P(z; u)$ because the left-hand side gives us two solutions and the right-hand side gives us just one.

This incomplete disambiguation can be completed by adding sufficient detail to the lexical categories so that the preposition \Expression{with} has two distinct representations rather than just one. These representations may be described as \emph{grammatical roles}: when the preposition attaches to the verb \Expression{saw} (or the verb phrase \Expression{saw the girl}), the role is that of an \emph{instrument}, and when the preposition attaches to the noun \Expression{girl}, the role is that of \emph{accompaniment}. Such roles and other refinements of lexical categories arise naturally in feature-based grammars of the kind described in \citet{shieber:iubag}  and \citet{steedman:sp}.

Here are some examples of feature structures from \citet[Chapter~3]{shieber:iubag}: \is{feature structures}

\begin{quote}
\begin{avm}
\[ cat: & NP \]
\end{avm}

\begin{avm}
\[ cat: & NP \\
agreement: & \[ number: & singular \\
                    person: & third\\
                    \] 
\]
\end{avm}
\end{quote}

Here the first feature structure is just our plain vanilla category of a noun phrase. The second one shows the added feature of \emph{agreement}. The value of this second feature is itself a feature structure with features \emph{number} and \emph{person} and corresponding values \emph{singular} and \emph{third}. This means the noun phrase is singular and third person and would have to combine with an appropriate category and feature structure to form a larger expression. The first feature structure above carries less information than the second about the noun phrase in question and is said to subsume the latter, leading to a natural lattice structure. The second, more informative feature structure also shows how feature structures can possess a nesting relationship.

In our example of the two roles for the preposition \Expression{with}, we could define the following two different feature structures for such words:

\begin{quote}
\begin{avm} \[ role: & instrument  \] \end{avm}

\begin{avm} \[ role: & accompaniment \] \end{avm}
\end{quote}

\noindent These different structures would differentiate syntactically between the two uses of the preposition at the \emph{lexical} level as required.

Feature structures can be and often are as finely articulated at the lexical level as required. This feature-based way of describing a context-free grammar then allows all syntactic ambiguities to be represented at the lexical level and so the ``lexical computations'' of Theorem~\ref{thm:simple equation} -- $z^\star = \argmax_{z} P(z_k \cond z_{-k}; u)$ -- suffice to give us exactly one solution when warranted.

Even when the sentence is indefinitely long, as in ${\cal A}_1$ \Expression{saw that} ${\cal A}_2$ \Expression{saw that \ldots\ that} ${\cal A}_n$ \Expression{saw the girl with a telescope} for any $n \in \mathbb{N}$, the features can be recursively defined to allow an indefinite degree of differentiation at the lexical level for different attachments of the preposition \Expression{with} so that the lexical computations of Theorem~\ref{thm:simple equation} can still go through as required. In other words, all that is needed for the earlier results to hold is a sufficiently detailed feature-based representation of the grammar $G$. This is the condition that was left implicit in \sectref{sec:solving locutionary global games}.

What happens when $G$ is not feature-based (or, in other words, the feature structures are minimal) and there is a lack of differentiation at the lexical level for sentences like $\mu$ and similar sentences? In that case, the \emph{compatibility} of the probability distribution as specified above will have to be generalized so that it applies to nonlexical levels as well.

Assume there is an utterance of a sentence $\varphi$ as before. $K = \{1, 2, \ldots, n, n + 1, \ldots, 2n\}$ is the set of semantic and syntactic indices of $z_k$ which stand for the \emph{possible} lexical meanings and parses of $\varphi$ uttered in $u$. Let the index set $K_{\varphi} \subset K$ be a \emph{variable} set that ranges over the indices of the possible meanings and parses of $\varphi$ at a lexical, phrasal, and sentential level. For example, in a simple sentence such as ``John loves Mary,'' $K_{\varphi} \in \{ \{1\}, \{2\}, \{3\}, \{2, 3\}, \{1, 2, 3\}, \{4\}, \{5\}, \{6\}, \{5, 6\},\allowbreak \{4, 5,\allowbreak 6\} \}$ where the indices \{1\}, \{2\}, \{3\} correspond to the three semantic indices of the three words in the sentence, the set $\{2, 3\}$ corresponds to the semantic indices of the phrase \Expression{loves mary}, the set $\{1, 2, 3\}$ corresponds to the semantic indices of the whole sentence, and the indices \{4\}, \{5\}, \{6\} correspond to the three syntactic indices of the three words in the sentence, the set $\{5, 6\}$ corresponds to the syntactic indices of the phrase \Expression{loves mary}, the set $\{4, 5, 6\}$ corresponds to the syntactic indices of the whole sentence. Clearly, the range of variation of $K_\varphi$ will be determined by each possible parse of $\varphi$ and is thus determined by the grammar $G$. If we write $K^l_G(\varphi)$ for this range for the $l$th parse out of $L$ possible parses (e.g.\ $K^1_G(\varphi) = \{ \{1\}, \{2\}, \{3\}, \{2, 3\}, \{1, 2, 3\}, \{4\}, \{5\}, \{6\}, \{5, 6\}, \{4, 5, 6\} \}$ for the simple example where $L = 1$ possible parse), we can then say $K_\varphi \in K^l_G(\varphi)$ for the $l$th of $L$ possible parses. That is, the index set $K_\varphi$ is always a member of a particular range of variation $K^l_G(\varphi)$ based on which parse is being considered.

Define $z_{K_\varphi} = \{z_{k}\ |\ k \in K_\varphi\}$ and define $z_{K_\varphi^\prime}$ to be its complement with respect to $K$. Again, for the simple example above, if $K_\varphi = \{2, 3\}$ then $z_{K_\varphi} = \{z_2, z_3\}$ and $z_{K_\varphi^\prime} = \{z_1, z_4, z_5, z_6\}$. In this case, $P(z_{K_\varphi} \cond z_{K_\varphi^\prime}; u) = P(z_2, z_3 \cond z_1, z_4, z_5, z_6; u)$. Likewise, if $K_\varphi = \{4, 5, 6\}$ then $z_{K_\varphi} = \{z_4, z_5, z_6\}$, $z_{K_\varphi^\prime} = \{z_1, z_2, z_3\}$, and $P(z_{K_\varphi} \cond z_{K_\varphi^\prime}; u)\allowbreak = P(z_4, z_5, z_6 \cond z_1, z_2, z_3; u)$.

While the two paragraphs above are notationally cumbersome, the basic idea is very simple. Earlier, we found just the lexical level adequate when the grammar was feature-based. When it is not, we need to access the indices at a phrasal and sentential level as well so that the computations of Theorem~\ref{thm:simple equation} can be extended to nonlexical levels in a way that provides a generalized notion of compatibility. What the more general statement of Theorem~\ref{thm:generalized compatibility} requires is to run through the relevant indices at phrasal and sentential levels as well and the indices that are relevant at such levels are the ones that are dictated by the possible parses being considered.

\begin{theorem}\label{thm:generalized compatibility}
Given an utterance and its locutionary global game (with symmetric payoffs), when the relevant grammar is not feature-based, its lexical meanings and parses are given by the following equivalent characterizations:
\begin{equation}
z^\star = \argmax_{z} P(z_{K_\varphi} \cond z_{K_\varphi^\prime}; u) = \argmax_{z} P(z; u), \quad K_\varphi \in K^l_G(\varphi),\ l \in L
\label{eq:complex}
\end{equation}

\noindent When there is more than one solution, each solution is given an equal probability.\footnote{Again, by Theorem~\ref{thm:existence of Nash}, a solution always exists.} The meaning and parse of the whole utterance can be obtained by appropriately computing the products of the lexical, phrasal, or sentential meanings and parses.
\end{theorem}

\noindent I urge the reader to mentally run through the more complex computations involved with this extended idea of compatibility. Notice that the term \[\argmax_z P(z_{K_\varphi} \cond z_{K_\varphi^\prime}; u)\] in Equation~\ref{eq:complex} does not involve any mixed semantic-syntactic products whereas the term $\argmax_{z} P(z; u)$ does so that there is still a reduction in computational effort by the equality of the two. If we call indefinitely articulated feature-based grammars complex and ordinary context-free grammars simple and if we call the lexical computations of Theorem~\ref{thm:simple equation} simple and the generalized computations of Theorem~\ref{thm:generalized compatibility} complex, then there is a nice and intuitive inverse relationship between grammars and computations that follows from these two theorems. Let the grammar of a language be $G$ and the corresponding computations of optimal meanings and parses be $\kappa$.

\begin{theorem}
$G$ and $\kappa$ are inversely related in their complexity: when $G$ is simple, $\kappa$ is complex, and when $G$ is complex, $\kappa$ is simple.
\end{theorem}

For the rest of the book, I will assume we have a sufficiently articulated feature-based grammar $G$ and that the computations $\kappa$ are therefore simple. In \chapref{ch:syntactic ambiguity}, I will attend to an example of syntactic ambiguity in detail, something I have not addressed so far but there all the ambiguities will be present at the lexical level itself so that issues of the kind raised by sentences like $\mu$ will not arise. For the present, we have to complete our discussion of our primary example $\varphi = \Expression{bill ran}$ and I return to this below.



\section{Solving Generation Games} \label{sec:solving generation games}
As we saw in \sectref{sec:generation game} and Figure~\ref{fig:GG}, the speaker may consider more than one sentence and therefore more than one locutionary global game. Each such game has a value $v_u^{\cal A}[LG_u(\varphi)] = a_{\cal A} + a_{\cal A}$. Likewise, each corresponding illocutionary game will have some value and it is the total value $v_u^{\cal A}[G_u(\varphi)]$ that is computed. Each global game $G_u(\varphi)$ comes with a cost $k^{\cal A}_u(\varphi)$ and so the net value to $\cal A$, $v_u^{\cal A}(\varphi) = v_u^{\cal A}[G_u(\varphi)] - k^{\cal A}_u(\varphi)$, is determined. Then, the sentence with the highest net value is chosen.

The cost $k^{\cal A}_u(\varphi)$ is a crucial factor that controls what is actually uttered.\footnote{I had first pointed this out in \citet{parikh:diss}.} Incidentally, considerations of cost are entirely absent in \citet{lewis:c} and also in so-called cheap talk games\is{game!cheap talk} in economics (e.g.\ \citealt{cs:sit,farrell:ctce,farrell:mcctg,fr:ct,kartik:sclc,bb:lb}) and this is just one reason why they are unsuitable for modeling linguistic communication.\footnote{The setup in Crawford and Sobel\ia{Crawford, V. P.@Crawford, V. P.}\ia{Sobel, J.@Sobel, J.} is that there is a sender and a receiver. The sender observes a state which is equally likely to be either $0$ or $1$ (although the original account involves a continuous state space). He then reports the state to the receiver either truthfully or not. The receiver observes the report and makes a decision which can be any number. The receiver prefers decisions that are closest to the value of the state and the sender prefers decisions that are closest to the state plus a bias $b > 0$.

%\ia{Crawford, V. P.}\ia{Sobel, J.}  

%The solution concept is Perfect Bayesian equilibrium.

%What is an equilibrium? If $b\le 1/2$, there exists a trutelling
%equilibrium in which the sender reports the state truthfully and the
%receiver takes her most preferred action. If $b>1/2$, the unique
%equilibrium is babbling in which the sender's reports are not
%informative for the decision maker. The babbling equilibrium exists,
%by the way, for any value of $b$. in addition, if $b<1/2$, there could
%exist mixed strategy equilibria, in which the sender reports
%$\omega=1$ truthfully and mixes between reporting $\omega=0$
%truthfully or lying.

There are two ways to view such a setup. The shared language between sender and receiver either does not constrain interpretation at all or contains expressions that have only single conventional meanings but then allows any interpretation. 

Consider the first option. Suppose the sender observes a $0$ and sends a $0$. The receiver can interpret this expression ``$0$'' as either $0$ or $1$. This means there is \emph{no} shared conventional meaning that the expression has that constrains its possible interpretations the way the word ``bank'' limits its possible locutionary interpretations to either \emph{financial institution} or \emph{land alongside a river}. In other words, the expression ``$0$'' is implicitly taken to be conventionally meaningless. That is, the whole language (in this case, just ``$0$'' and ``$1$'') has no conventional meanings and its expressions can convey anything at all. As a result, whenever the sender has to convey a content, he can use any expression in the whole language.

Consider the second option for viewing the setup. Here, the expression ``$0$'' always has only the single conventional meaning $0$ but this conventional meaning can be a springboard for any further interpretation, $0$ or $1$. Therefore, any expression can again be used to convey any content \emph{via} a single conventional meaning and the whole language is again always available.

Whichever way the setup is viewed, such models do not investigate how a particular meaning arises from potentially ambiguous expressions that have a fixed set of conventional meanings. As \citet[265]{myerson:cnscp} rightly observes, such models treat (literal) meaning as endogenous to the setup rather than exogenous. The Semantic Constraint (i.e.\ the Conventional and Referential Constraints) mentioned in \sectref{sec:generation game} which allows an expression (e.g.\ ``bank'') to be conventionally ambiguous is therefore missed altogether. It is this constraint that \emph{restricts} the possible interpretations that are then disambiguated by the Flow Constraint. This is why the whole language is never available to the speaker when he wishes to convey a particular content. 

The real question in linguistic communication is not about the conditions under which ``bank'' will be treated as having a single meaning rather than having no shared meaning (the first option) or as conveying some meaning other than its single conventional meaning (the second option) but is about the conditions under which one of its shared conventional meanings (e.g.\ either \emph{financial institution} or \emph{land alongside a river}) will prevail. See also \sectref{sec:macro-semantics} on the utility of conventional meanings. I believe more recent work such as \citet{dt:mc} that considers costly communication has the same limitations.} Cost is based on a variety of factors, mostly objective ones such as the length and complexity of the sentence and the effort required to mentally process it and to physically produce it but also subjective ones especially related to the consequences of making certain information explicit and leaving certain information implicit. 

It is possible that the primary decision is between what to make explicit or leave implicit and objective factors such as length, complexity, and mental and physical effort play a relatively smaller role. Conversational style, habits of\linebreak speech, special contexts of speech and writing (e.g.\ poetry and fiction and nonfiction), and other aesthetic aspects are one factor that affect this primary decision and different communities and individuals may follow different patterns in how much is made explicit. This is a matter for sociolinguists and psycholinguists to dig deeper into. 

A second dimension involves the maintaining or altering of relationships as pointed out by \cite{pnl:lis} based on the Politeness Theory of \citet{bl:p} and referred to in \sectref{sec:theory of conversation}.\footnote{Pinker et al. study this problem from a similar angle but use a different, somewhat ad hoc setup in their explanations. They seem to conclude that indirect speech is used only when there is a risk of some kind of penalty (as in overtly or covertly bribing a police officer) or some kind of awkwardness in the relationship (as in directly or indirectly bribing the ma\^{i}tre d' of a restaurant) or an alteration of a relationship (as in overtly or covertly making a sexual overture). They overlook the fact that indirect speech is also used for the most mundane reasons: to reduce effort. And, contrary to their point about the role of common knowledge in influencing indirect speech (i.e.\ a direct statement becomes common knowledge whereas indirect speech doesn't), a great deal of indirect speech does in fact become common knowledge: ``can you pass the salt?'' or ``would you like to join me for coffee?'' uttered in appropriate contexts. It is the cancelability or defeasibility of indirect speech that makes people resort to it when, for example, they make a sexual overture because it allows an escape route. One can deny the overture even though it has become common knowledge. Of course, there are many cases where an overture may be merely suggested rather than communicated, in which case it does not become common knowledge. In either case, the overture can be canceled and this is what makes it relatively safe. All of this depends on (a ``thick description'' of) the context. Once again, see Gilbert Ryle's 1971 university lectures\ia{Ryle, Gilbert} and especially Clifford \citet{geertz:ic}.} This factor is extremely important and plays a role not only in how some content is communicated but even in the choice of what content to communicate. In other words, it affects both the Content Selection Game and the Generation Game and I will be examining how it enters into content selection in Sections~\ref{sec:expanded content selection game} and \ref{sec:a complete example} and \chapref{ch:vagueness}. In Generation Games, if a sentence is too explicit or too implicit, it will incur a cost and this may lead to its rejection owing to more suitable sentences. The utterance situation $u$ obviously plays a pivotal role in this evaluation.

For example, suppose Bill Smith is not just a mutual acquaintance of the two interlocutors but is also someone $\cal B$ holds in high regard. Then in order to please $\cal B$, $\cal A$ may choose to be more deferential and utter $\varphi' = \Expression{bill smith ran}$ rather than $\varphi = \Expression{bill ran}$. This would be so even though $\varphi'$ is slightly longer and possibly stylistically too formal. This is because the higher cost due to greater length and formality is offset by the reduction in cost due to $\cal A$'s managing to please $\cal B$ by his show of deference. Overall, $k^{\cal A}_u(\varphi) > k^{\cal A}_u(\varphi')$ and therefore $v_u^{\cal A}(\varphi) < v_u^{\cal A}(\varphi')$ because $v_u^{\cal A}[G_u(\varphi)] = v_u^{\cal A}[G_u(\varphi')]$ in this instance, and so $\varphi'$ would be uttered, not $\varphi$. This shows how factors like maintaining relationships and politeness toward one's interlocutors may alter the choice of sentence to convey even the same content $\sigma$. Indeed, a great deal about the use and even existence of honorifics and other such behavior can be explained in just this way. The example just discussed involves greater explicitness but greater implicitness may also be warranted in other situations where something like, say, a sexual overture has to be handled delicately or indirectly.

There is at least a third important dimension to what is made explicit. This is the avoidance of error\is{miscommunication} in contexts where error can be costly. If a sentence leaves too much implicit, the addressee may infer the wrong content and this may lead to an undesired action and outcome. In the example at hand, it may not matter too much to $\cal A$ if $\cal B$ interpreted $\varphi = \Expression{bill ran}$ as being about Bill Jones instead of Bill Smith or about running in a race instead of in the local election or both because they are involved in a casual conversation and misunderstandings could be easily corrected. But suppose that it did matter to $\cal A$. Then he might prefer to utter alternative sentences such as $\varphi' = \Expression{bill smith ran}$ or $\varphi'' = \Expression{bill ran in the election}$ or even $\varphi''' = \Expression{bill smith ran in the election}$. How might such a preference for a longer sentence requiring more physical effort, however small, be determined? That is, how does the speaker decide when mistakes matter and when they don't?

In circumstances where errors count, the overall cost $k^{\cal A}_u(\varphi)$ of a shorter, less explicit sentence will be relatively high despite its shorter length and so its net value $v_u^{\cal A}(\varphi) = v_u^{\cal A}[G_u(\varphi)] - k^{\cal A}_u(\varphi)$ will go down. This higher cost component in $k^{\cal A}_u(\varphi)$ arises by considering the wrong actions the addressee might pursue by inferring an erroneous content. In other words, it is possible to look at the Content Selection Game in \sectref{sec:content selection game}, see what payoff is delivered in it if the intended action $a$ is pursued by the addressee (e.g.\ $v_{\cal A}$), and compare this payoff with the diminished payoff that would be realized if an undesired action $a''$ -- something like acceptance of an erroneous interpretation -- were chosen (e.g.\ $v''_{\cal A}$).\footnote{As should be clear, this undesired action $a''$ has not been explicitly represented in Figure~\ref{fig:CS}. \label{foot:a''}} The difference between the two (i.e.\ $v_{\cal A} - v''_{\cal A}$) would give one the cost of error. This error would occur with some probability, say $q$, and so the new cost $K^{\cal A}_u(\varphi) = (1 - q)k^{\cal A}_u(\varphi) + q[k^{\cal A}_u(\varphi) + (v_{\cal A} - v''_{\cal A})] = k^{\cal A}_u(\varphi) + q(v_{\cal A} - v''_{\cal A}) > k^{\cal A}_u(\varphi)$ when $q > 0$ and $v_{\cal A} - v''_{\cal A} > 0$. This is just an average of the old cost without error and the old cost with error and is greater than the old cost without error. This higher cost could tip the balance in favor of a longer, more complex sentence that is more explicit, as there would be a negligible possibility of error with such sentences.

This makes it clear that mistakes count when $v_{\cal A} - v''_{\cal A} \gg 0$ or when $q \gg 0$ or both. In the example as described, $v_{\cal A} - v''_{\cal A} \ngg 0$ because a misunderstanding would be just mildly annoying and can be easily rectified. Also, $q \ngg 0$ because, as I showed, the different locutionary games $g_1$ and $g_2$ reinforce each other's equilibrium meanings (viz.\ $\sigma_1 = \emph{Bill Smith}$ for $g_1$ and $\sigma_2 = \emph{ran in an election}$ for $g_2$) which makes the likelihood of error small. As neither factor is significant, the overall cost $K^{\cal A}_u(\varphi) = k^{\cal A}_u(\varphi) + q(v_{\cal A} - v''_{\cal A}) \approx k^{\cal A}_u(\varphi)$ and so the speaker does not need to reconsider the short sentence $\varphi = \Expression{bill ran}$. Notice that the actual calculation involved is extremely simple as just the product $q(v_{\cal A} - v''_{\cal A})$ has to be evaluated and added to the cost if it is significant. Again, this is well within the psycholinguistic grasp of the speaker and can be carried out in milliseconds without materially altering the time for a person to generate a sentence.

There are situations where the added cost will be significant. To take \citegen{benz:eip} example,\ia{Benz, Anton@Benz, Anton|(} if there are two doctors that John might be seeing and he has to be picked up, it may not be enough to say ``Please pick up John at the doctor's'' as the identity of the doctor has been left implicit. This is so even though the speaker may be more likely to be referring to a particular doctor and this is common knowledge. While it is possible for the addressee to infer which doctor is intended in such circumstances, the cost of error is high because going to the wrong location to pick up John is very undesirable (i.e.\ $v_{\cal A} - v''_{\cal A} \gg 0$). The probability of error $q$ will depend on how much higher the relevant prior probability corresponding to the intended doctor is than the one corresponding to the unintended doctor in the locutionary game corresponding to the noun phrase ``the doctor's.'' If the former is close to $1$, $q$ will be small, but if it is close to 0.5, $q$ will be large. Whatever the value of $q$, the cost of error will be high owing to $v_{\cal A} - v''_{\cal A} \gg 0$ and so the speaker will usually take the trouble to spell out which doctor is intended explicitly. This means that the speaker will instead utter something like ``Please pick up John at Dr. X's'' which is perhaps a little costlier from a cognitive point of view as something more specific has to be processed, which takes more effort.

To be sure, agents are finite and partially rational and so they may not always carry out the additional calculations on every occasion where they are required. As ambiguity is rife in natural language, there could be errors in interpreting practically every word of an utterance and certainly this would be far too burdensome computationally. Perhaps some possibilities of error are processed at a more conscious level (e.g.\ those directly related to the addressee's action in the Content Selection Game which in turn is related to the conversational goal) and it is only such potential errors that are averted. So, even though I went through the calculations above for possible misinterpretations with $\varphi = \Expression{bill ran}$, the ambiguities in these words \emph{in the circumstances described} are likely to be handled nonconsciously by both agents and so no error-related calculations are likely to be carried out at all. In the case of the two doctors, the error calculations are likely as this is a possibility that would be semiconscious if not fully conscious. Such issues can be tested empirically to determine when speakers speak more explicitly and when not.\largerpage

%This is why, as I said in footnote~\ref{foot:a''}, the undesired action $a''$ was not made explicit in Figure~\ref{fig:CS} as such actions are often not countenanced at all.

If some possible misinterpretation is inadvertently missed by the speaker or if mistaken estimates for $v_{\cal A} - v''_{\cal A}$ and $q$ are used accidentally, the addressee might notice the possible misinterpretation in the Interpretation Game and ask for a clarification. Such clarifications are not a regular part of the original communication as Benz suggests: they are new utterances in their own right and can take a variety of forms and so cannot be included as mere ``feedback'' as they need to be disambiguated and interpreted themselves. Why are clarifications triggered? There could be a number of causes: the addressee may infer an unexpected meaning (e.g.\ \emph{Bill Jones ran in an election}) because she selects the wrong prior probabilities owing to a miscommunication, or she needs to be certain in order to carry out her action in the Content Selection Game because the locutionary game results in a mixed strategy solution or because an error would be costly (i.e.\ $v_{\cal B} - v''_{\cal B} \gg 0$ or her probability of error $q_{\cal B} \gg 0$ or both).\largerpage

Benz also misses the other two possibilities: \emph{neither} party may notice potential misinterpretations and the communication may go through smoothly as intended (such as going to the right location to pick up John even though it was left implicit) or an undesirable outcome can occur (such as going to the wrong location to pick up John).\footnote{The real-life case of Derek Bentley involving an armed robbery in the UK in 1952 where Bentley may have uttered the ambiguous ``Let him have it, Chris'' to his accomplice is cited by \citet{carston:lcspd} in a different context. The utterance is ambiguous between \emph{shoot the police officer} and \emph{give the police officer your gun}. See \url{http://en.wikipedia.org/wiki/Derek_Bentley_case}. It is not known whether Bentley actually uttered this sentence and, if he did, what he might have meant.} Benz overcompensates for errors and attempts to build a model that eliminates them completely. But this is unrealistic because mistakes can and do occur. Curiously, he does not apply his own ``error model'' to look at how speakers might be more explicit but confines his attention to whether ``clarification requests'' are generated. The key lack in his model is that there is no estimate of the \emph{magnitude} of error as a trigger either for more explicit sentences or for clarifications, there is just the \emph{intuitive} recognition that errors can occur because communication is probabilistic. There is, in other words, no actual model of error in his error model. This leads to the prediction that practically every utterance will result in ``clarification requests'' from addressees, even when they are intuitively not warranted. Nevertheless, Benz's observation about the possibility of error in communication, first noted by \citet{zaefferer:um}, is important, even though both Zaefferer and Benz focus exclusively on interpretation whereas its most important impact is on how it compels speakers to be relatively more explicit in some aspects of their utterances in certain circumstances.\footnote{There are other issues with \citegen{benz:eip} model but I cannot go into them here as it would require a detailed description of his model and would be a digression. One point is worth mentioning: he overlooks the fact that the prior probabilities in a game of partial information have to do with what the speaker intends to convey and not directly with the probability of the content as such. In the example of the doctor, the addressee may have to impute priors of 0.5 each (roughly, if fuzzy or interval probabilities are allowed) for the two doctors as there might be no way of telling which one is intended on a \emph{particular} occasion regardless of the fact that John frequents one of them more than the other. This latter fact can inform the probability estimate as part of the overall situation (see \sectref{sec:meaning and truth} for related considerations) but cannot be identified directly with the probability estimate. If after everything is considered an equiprobable prior distribution is selected, it would lead to a mixed strategy solution and the addressee would not know with certainty where to go to pick up John. That is, the payoff the speaker would receive from the locutionary game for the implicit utterance of ``Please pick up John at the doctor's'' would be reduced and this would further diminish the net value of the sentence $v_u^{\cal A}(\varphi) = v_u^{\cal A}[G_u(\varphi)] - k^{\cal A}_u(\varphi)$ thereby favoring a more explicit sentence with a pure strategy solution and higher overall net value. In such situations, not only does the cost go up but the value of the game goes down, both leading to a lower net value. \label{foot:benz}}
\ia{Benz, Anton@Benz, Anton|)}

This completes my discussion of how Generation Games are solved. As I have said in my earlier books, a comprehensive theory of cost is required but it is doubtful it can be easily erected as the relevant costs have many sources in general. Cost enters both in the choice of sentence which occurs in the Generation Game \emph{outside} the global games for each sentence and it enters also within the global games via Theorem~\ref{thm:compatibility with payoffs} that allows for non-symmetric payoffs. However, in particular contexts it is usually straightforward to know what costs to assign as is evident from the example of the doctor above as well as from the examples discussed in \sectref{sec:cl}. So it could be said that Equilibrium Semantics does offer a more or less complete locutionary theory modulo costs which can be assigned on a case by case basis just as with the prior probabilities. In any case, while the task is difficult, it is not insurmountable. I have identified practically all the major sources of cost in the foregoing and it is just a matter of tackling them one by one. I have also made plausible when costs are likely to be relatively high or low, which means it is just a matter of assigning appropriate magnitudes to them so that they can all be suitably combined.

I believe that treating natural language communication as cheap talk\is{game!cheap talk} has been a red herring. Also, without costs, everything would be expressed explicitly, which is absurd. It is possibly because economists have been more concerned with eliminating superfluous equilibria in economic settings that they have been led to ignore some of the issues involved in linguistic communication. We could now consider this motivating problem of economics -- how to oust unwanted equilibria in economic games -- and see how these aspects of language can help their goals. How, for example, do the right choices emerge in the job market signaling situation studied by \citet{spence:jms} when costly but beneficial interviews are part of the game?

However, my concern is with language, and language is truly rich not just in the quantitative sense assumed in cheap talk games but especially in the logical and rhetorical devices it affords that enable us to persuade one another of our beliefs and desires. But these resources do not come cheap, they come with costs and benefits. 

I repeat that I have looked at just the speaker's key decision about what to make explicit and what to leave implicit and have not modeled exactly how the actual words are selected together with their order and structure and pronunciation.

%An alternative strategy is to say that the global game $G_u(\varphi)$ is not uniquely given but that there is a \emph{higher-order} probability distribution on the possible global games. Restricting our attention to just the locutionary global game $LG_u(\varphi)$ for a moment, it is possible that the speaker is uncertain about whether $LG_u(\varphi)$ is the actual game or some other game $LG'_u(\varphi)$ is the actual game. This uncertainty is likely to be confined to just the prior probabilities of the various locutionary games in the distributed form or the pure probability payoffs in the compact form. That is, the speaker could be uncertain whether certain prior probabilities are higher or lower than the other corresponding prior probabilities. So, there could be some probability $q$ that the right game is $LG_u(\varphi)$ (i.e.\ that certain of its prior probabilities are higher) and a corresponding probability $1 - q$ that the right game is $LG'_u(\varphi)$ (i.e.\ that exactly the opposite prior probabilities are higher in games where there are just two initial situations). I had implicitly assumed that $q = 1$ in the foregoing but this need not always be the case. In the game $LG'_u(\varphi)$, it is the content \emph{Bill Jones} that would be selected or \emph{running in a race} or both depending on which particular locutionary games are saddled with this uncertainty. Since there are two lexical semantic games $g_1$ and $g_2$, one for $\varphi_1 = \Expression{Bill}$ and one for $\varphi_2 = \Expression{ran}$, it is possible that there are two sets of higher-order probabilities $q_1$, $q_2$ (and correspondingly $1 - q_1$ and $1 - q_2$) but I will assume these are the same to keep things simple. As I showed above, the value of $LG_u(\varphi)$ is $v_u^{\cal A}[LG_u(\varphi)] = a_{\cal A} + a_{\cal A}$. Keeping in mind that $\cal A$'s intention in both games $LG_u(\varphi)$ and $LG'_u(\varphi)$ is the same -- to convey the content \emph{Bill Smith ran in an election} -- the initial situations $s_1$ in $g_1$ and $s_2$ in $g_2$ will be factual whereas the other situations $s_{1'}$ in $g_1$ and $s_{2'}$ in $g_2$ will be counterfactual.\footnote{See Figures~\ref{fig:semantic lexical game g1} and \ref{fig:semantic lexical game g2} in Section~2.3.} This means that if $LG'_u(\varphi)$ is selected then incorrect interpretations $\sigma'_1$ or $\sigma'_2$ or both will result by tracing the paths from $s_1$ and $s_2$ to the payoffs $c_{\cal A}$ in either one or both of $g_1$ and $g_2$. If we introduce a superscript $h$ in $LG^{h}_u(\varphi)$ to distinguish it from the possible locutionary games over which the values are averaged, this means that $v_u^{\cal A}[LG^{h}_u(\varphi)] = qv_u^{\cal A}[LG_u(\varphi)] + (1 - q)v_u^{\cal A}[LG'_u(\varphi)] = q(a_{\cal A} + a_{\cal A}) + (1 - q)(c_{\cal A} + c_{\cal A})$ where I have assumed that the same probability $q$ applies to both $g_1$ and $g_2$. Since $c_{\cal A} < a_{\cal A}$, the former payoff corresponding to an incorrect interpretation, $q(a_{\cal A} + a_{\cal A}) + (1 - q)(c_{\cal A} + c_{\cal A}) < a_{\cal A} + a_{\cal A}$ when $q < 1$. This leads to a lowering of the value of the locutionary game corresponding to $\varphi$ in which case the net value also goes down. This could again tip the balance in favor of a longer, more complex sentence that is more explicit.


%errors - benz - basically, the probability is what A intends not the objective probability and in the absence of more information in the case of the two doctors, they must be taken to be 0.5 each. This leads to mixed strategies and non-uniqueness which is undesirable so a costlier sentence is chosen instead. The cost k of the ambiguous game is too high essentially. This cost must come from the possibility of the wrong action taken in CSG so this creates more interactions between the games. Consider not one but two expanded CSGs, one of them involving two different contents Bill Smith and Bill Jones and consider also the possibilities for ran. This leads to an unusual CSG where the actions - contents - are different but invisible. In this case, there are two or four responses accept \sigma, accept \sigma' and reject them. Etc. The cost component of k comes from the difference between the right and wrong actions being taken and so whether uncertainty can be tolerated. The speaker must decide if full certainty is warranted or not or whether possibility of error can be tolerated. Same for addressee. Also, higher-order probabilities may be introduced when considering local games and so can fuzzy probabilities so we don't need to consider exactly 0.5 probabilities to get mixed strategies. Also, clarification requests have to be treated as new utterances altogether.
%Another interpretation of Benz is that game prediction is sound just that HOPS are involved and so probabilities are uncertain.


\section{Solving Communication Games} \label{solving communication games}
Having solved the locutionary global game $LG(\varphi)$ and therefore the Interpretation Game $UG_u(\varphi) = UG_u$, and the Generation Game $GG(\sigma) = GG_u$, this leaves just the Content Selection Game $CSG_u$ in the overall Communication Game 
$\Gamma_u = (SG_u, CSG_u, GG_u(\sigma), UG_u(\varphi), G_u(\varphi)) = (SG_u, CSG_u, GG_u, UG_u, G_u)$.\footnote{I remind the reader again that the illocutionary global game component of the global game will be addressed in \partref{part:IV}.} The Setting Game $SG_u$ does not need to be solved explicitly as the content conveyed by the speaker and the action taken by the addressee will automatically contribute to its solution. In the example at hand, as mentioned in \sectref{sec:content selection game again}, $CSG_u$ is trivial as there is just one action $a$ that $\cal B$ can select in response to the interpretation $\sigma = \sigma^{\ell} \odot \sigma^{\iota} = \emph{Bill Smith ran in the local election}$ derived from the global game. The parse tree $t$ figures only in the latter and, as I said in \sectref{sec:macro-semantics}, the purpose grammatical structure serves is to facilitate communication by making disambiguation easier.

It is worth going back to the chart displayed in Sections~\ref{sec:micro-semantics} and~\ref{sec:communication game}.
\begin{enumerate}\setlength{\itemsep}{0pt}
\item[] \underline{Utterance Situation}
\item[] Setting Game
\item[$\functionarrow$] $\cal A$'s wish to elicit some response from $\cal B$
\item[$\functionarrow$] Content Selection Game
\item[$\functionarrow$] $\cal A$'s equilibrium content
\item[$\functionarrow$] Generation Game
\item[$\functionarrow$] $\cal A$'s equilibrium utterance
\item[$\functionarrow$] Interpretation Game
\item[$\functionarrow$] $\cal B$'s equilibrium content
\item[$\functionarrow$] Content Selection Game
\item[$\functionarrow$] $\cal B$'s equilibrium response
\item[$\functionarrow$] Back to the Setting Game
\end{enumerate}
Now, all the lines above involving various equilibria have been filled in. In other words, we have solved the Communication Game $\Gamma_u$ completely. The example considered was a very simple one but it allowed us to see all the moving parts involved in micro-semantics.

As I promised in \sectref{sec:content selection game}, I will now look at a slightly more complex Content Selection Game.

\section{An expanded Content Selection Game} \label{sec:expanded content selection game}

In \sectref{sec:content selection game}, I mentioned the possibility that $\cal B$ could have a choice between accepting and rejecting what $\cal A$ conveys. This leads to another branch issuing from the intermediate node in Figure~\ref{fig:CS} labeled $a'$ and corresponding payoffs $v'_{\cal A}$, $v'_{\cal B}$. If $v_{\cal A} = v'_{\cal A}$, it means $\cal A$ does not care whether $\cal B$ accepts or rejects his communication. In this case, there is nothing more to be done except that, once $\cal B$ has interpreted $\cal A$'s utterance as before, she will have a choice between $a$ and $a'$ and will choose the action that yields the greater payoff, either $v_{\cal B}$ or $v'_{\cal B}$. For example, if $\cal B$ is inclined to be skeptical about $\cal A$'s information, she may have $v'_{\cal B} > v_{\cal B}$ and may reject $\sigma$. Now, if $v_{\cal A} > v'_{\cal A}$ rather than $v_{\cal A} = v'_{\cal A}$, then $\cal A$ would care about $\cal B$'s acceptance and may strive to be more persuasive in imparting his content. One way for him to do this is to convey some additional supporting content that, say, he read $\sigma$ in a newspaper, which might give $\cal B$ a reason to believe him.\footnote{See \citet{cialdini:i}, for example.} Let $\sigma$ plus this additional supporting information be $\sigma'$. This leads to a new action for $\cal A$ represented by a new branch issuing from $s$ labeled $\sigma'$. This makes the overall tree structure of the game more complex, as shown in Figure~\ref{fig:expanded CS}.


\begin{figure}[h]
\begin{center}
\begin{picture}(150,125)(35,18)
%-------------------------------
%NODES
\put(54,72){\circle*{3}}

\put(54,72){\input{figures/unit2}}
\put(54,18){\input{figures/unit2}}

\put(108,99){\circle*{3}}
\put(108,45){\circle*{3}}
\put(54,72){\vector(2,1){54}}
\put(54,72){\vector(2,-1){54}}

%\put(108,72){\oval(15,84)}


\put(54,81){\makebox(0,0){$s$}}
\put(54,63){\makebox(0,0){$\rho$}}
%\put(108,108){\makebox(0,0){$t$}}
%\put(108,54){\makebox(0,0){$t'$}}

\put(183,118.5){\makebox(0,0){$v_{\cal A},v_{\cal B}$}}
\put(183,82.5){\makebox(0,0){$v'_{\cal A},v'_{\cal B}$}}
\put(183,64.5){\makebox(0,0){$v_{\cal A},v'_{\cal B}$}}
\put(183,28.5){\makebox(0,0){$v'_{\cal A},v_{\cal B}$}}

\put(81,94.5){\makebox(0,0){$\sigma$}}
\put(82,68){\makebox(0,0){$\sigma'$}}
\put(135,115.5){\makebox(0,0){$a$}}
\put(135,97.5){\makebox(0,0){$a'$}}
\put(135,61.5){\makebox(0,0){$a$}}
\put(135,43.5){\makebox(0,0){$a'$}}

\end{picture}
\caption{An expanded Content Selection Game} \label{fig:expanded CS}
\end{center}
\end{figure}


In this game, as assumed in the previous paragraph, $v_{\cal A} > v'_{\cal A}$ but $v'_{\cal B} > v_{\cal B}$ so there is a certain degree of conflict between $\cal A$ and $\cal B$. If $\cal A$ chooses $\sigma$, $\cal B$ would prefer $a'$ or rejection, and if $\cal A$ chooses the costlier $\sigma'$, $\cal B$ would choose $a$ or acceptance. In other words, the distribution of the payoffs -- notice that $v'_{\cal B}$ and $v_{\cal B}$ have been switched in the lower half of the tree and $\cal A$ would like $\cal B$ to choose $a$ with either choice of content -- is such that $\cal B$'s equilibrium action is $a'$ in the upper half of the tree and $a$ in the lower half of the tree, so $\cal A$ is compelled to convey $\sigma'$ rather than $\sigma$. That is, the equilibrium path in this game is $(\sigma', a)$ where the first member of the pair is $\cal A$'s equilibrium action and the second is $\cal B$'s. This means $\cal A$ is willing to convey more information in order to win $\cal B$'s acceptance and this additional information comes at an additional cost because it has either to be converted into a second sentence in the Generation Game or somehow conveyed as an implicature. As set up, the situation $u$ does not make it easy to convey this information as an implicature -- additional assumptions would be required -- and so a longer sentence than $\varphi = \Expression{bill ran}$ or a second sentence would have to be uttered by $\cal A$. It can safely be assumed that this additional cost of processing and speaking a little more is smaller than $v_{\cal A} - v'_{\cal A}$, the gain in utility $\cal A$ receives from acceptance by $\cal B$. Even though $\sigma$ and $\sigma'$ are invisible, they have been made perceptible via the linkage of the Content Selection Game with the Generation Game and the Interpretation Game.

This example shows how and why conflict, that is, slightly misaligned payoffs, and related features of the Content Selection Game can lead a speaker to utter a longer and costlier sentence or two. I pointed out in Sections~\ref{sec:micro-semantics} and \ref{sec:theory of conversation} that the maxims of Quantity and Manner do not work as Grice\ia{Grice, Paul@Grice, Paul} had envisaged because a speaker may be driven to convey additional information beyond what is strictly required and utter more than the most perspicuous choice of sentence in order to succeed at his endeavor to evoke a desired response from the addressee.

Content Selection Games can get even more complex and I will describe two such examples, one in \chapref{ch:vagueness} and the other in \sectref{sec:a complete example}. As can be seen, even this example introduced strongly evaluative dimensions of action of the kind broached by \citet{taylor:halpp} and discussed in \sectref{sec:human agency} because matters involving the relationship between $\cal A$ and $\cal B$ come into play. Indeed, just as many potentially conflicting factors ranging over aesthetic, relational, and error aspects were all assimilated into a single cost $k^{\cal A}_u(\varphi)$ in \sectref{sec:solving generation games}, so a very wide spectrum of cooperative and conflictual relationship-related elements all enter into the payoffs and prior probabilities of the Content Selection Game. That is, a very wide array of relationships is packed into relatively few numerical slots. Such relational features can be purely psychological or sociological or even anthropological.\is{anthropology}\is{sociology}\is{psychology}

For example, the reason why $\cal B$ is inclined to be skeptical about $\cal A$'s information could be almost anything: $\cal A$ is a known fibber or $\cal B$ is overly cautious or does not wish to be easily influenced or $\cal A$ has a vested interest in the information or they are themselves both members of certain political parties or whatever. But all these possibilities lead just to $\cal B$'s skepticism and to $v'_{\cal B} > v_{\cal B}$, that is all. This shows that the utterance situation can easily encompass much richer and more realistic and more nuanced scenarios of the kind we encounter every day.

What the apparatus of a Communication Game does, in and through the Setting Game, Content Selection Game, Generation Game, and Interpretation Game, is to offer a way to \emph{reduce} the great diversity of human and social phenomena to a few numbers and inequalities \emph{within a game-theoretic structure} and thereby make this variety scientifically manageable, as also argued in \chapref{ch:romantic tradition}. For some, like Taylor,\ia{Taylor, Charles@Taylor, Charles} this might appear reductionist and unacceptable but no \emph{relevant} aspect of the situation seems left out as far as predicting and explaining communicative behavior is concerned. If a concrete feel for the situation is desired, then one does have to return to the qualitative details of the situation. This is precisely the interplay between abstract and concrete inquiry that is a necessary feature of the social sciences as mentioned in \sectref{sec:information}.
