\chapter{Vagueness}\label{ch:vagueness}\is{vagueness|(}

Practically every word in a natural language is vague. And yet, the attention this fact has received in semantics on the whole is surprisingly scant, perhaps because quite new ideas and tools are required to accommodate it. Borderline cases and, indeed, borders that shift with context pose additional difficulties in understanding communication. Without an account of vagueness, any semantic theory is seriously incomplete.

There have been a number of recent attempts to understand vagueness including \citet{ks:v,kdj:gtrv,pbl:crelc,lipman:wlv,ek:vlu,jager:vl,hj:tc}; and \citet{bb:iv}. This is a large area and I focus mostly on foundational issues.

%

%Puglisi et al. (2008), Cultural route to the emergence of linguistic categories, PNAS 
% 
%
%Blume \& Board (2013), Intentional Vagueness, Erkenntnis 
%
%The game-theoretic tradition is mostly concerned with addressing the challenge raised by Barton Lipman in his (2009) manuscript "Why is Language Vague?" that the pressure to communicate should drive languages to have non-vague meanings. The research proposed here is obviously related to this discussion, and should explicitly position itself with respect to this literature. 
%
%4.) Similarly, there is a growing literature within theoretical linguistics that seeks to deal with different types of words/properties that give rise to different types of vagueness. The key publication to take into account here would be: 
%
%Kennedy, Vagueness and Grammar: The Semantics of Relative and Absolute Gradable Adjectives, Linguistics and Philosophy 
%
%It seems that the present sketch of the proposal would merely stipulate some of the differences that other game-theoretic / reasoning-based accounts are trying to explain. Examples in case are: 
%
%Chris Potts (2008), Interpretive Economy, Schelling Points, and Evolutionary Stability, Manuscript 
%
%Lassiter \& Goodman (2014), Context, Scale Structure, and Statistics in the Interpretation of Positive-Form Adjectives, Proceedings of SALT 

%Here are just a few references: Lasersohn, P.: Pragmatic halos. Language 75(3) (1999), Kennedy, C.: Vagueness and grammar: the semantics of relative and absolute gradable 
%adjectives. Linguistics and Philosophy 30(1) (2007), Sauerland, U., Stateva, P.: Two types of vagueness. 
%
% Lauer, Sven: 2012 On the pragmatics of pragmatic slack in A. Aguilar, R. Nouwen and A. Chernilovskaya (eds.), Proceedings of Sinn and Bedeutung (SuB) 16.

%Hampton, James \& Martin L. Jï¿½nsson (2012) "Typicality and compositionality: The logic of combining vague concepts," in M. Werning, W. Hintzen \& E. Machery (eds.), Oxford Handbook of Compositionality, pp. 385-402. 
%





I start by characterizing clear cases and borderline cases of a vague concept. Next I tackle the \emph{sorites paradox}. It is perhaps this classical puzzle that has occupied most writers on vagueness, especially philosophers and logicians. I then look briefly at the important subclass of vague concepts called essentially contested concepts. Last, I apply these insights to communication.

I approach these tasks by adapting models from cognitive psychology\is{psychology|(} as it appears that psychologists understand this domain better than philosophers or linguists owing to the psychologists' emphasis on experimental data. I also apply these adapted models in new philosophical and linguistic ways. With the right models, the sorites paradox yields to a natural and intuitive resolution. Essentially contested concepts become easier to understand. Once I describe vagueness, it can be readily incorporated into a larger theory of communication and meaning.\largerpage

I first clarify some basic terminology. Concepts are taken to be mental representations of collections of things and categories the collections themselves. Concepts correspond to properties or attributes or features, all terms referring to abstract entities. So an agent's vague concept \textit{bald} corresponds to a vague property of baldness. Since each agent will have a slightly different concept \emph{bald}, the corresponding vague property can be thought of in two ways: as a kind of social and abstract average of these individual representations{\interfootnotelinepenalty=10000\footnote{As I said in \sectref{sec:information}, properties are individuated from \emph{reality} by agents and so are social but abstract constructs that nevertheless have a certain objectivity. For example, the number $5$ can be thought of as being abstracted from collections of five objects just as the property of being blue can be thought of as being discriminated from blue objects.}} and as a kind of abstract individual counterpart to the concept, one for each agent. Both kinds of property are important, the average kind and the individual kind. Vague words such as \Expression{bald} have vague concepts conventionally attached to them that serve as their conventional meanings.

It has been taken for granted from classical times until \citet[Sections~66 and 67, pages~31--32]{wittgenstein:pi} questioned it that most concepts have clear definitions, that is, noncircular necessary and sufficient conditions. This implies every object is or is not a member of the corresponding category. As discussed by \citet{sm:cc}, this classical view and its variants are untenable primarily because most concepts are vague and have borderline cases.\footnote{The other important theoretical reason is that they are unable to account for typicality effects. And much of the experimental evidence disconfirms them.} Here is \citegen[21]{murphy:bbc} account of \emph{why} vagueness is ubiquitous:

\begin{quote}

The Necessity of Category Fuzziness

The existence of unclear examples can be understood in part as arising from the great variation of things in the world combined with the limitations on our concepts. We do not wish to have a concept for every single object -- such concepts would be of little use and would require enormous memory space. Instead, we want to have a relatively small number of concepts that are still informative enough to be useful \citep{rosch:pc}. The ideal situation would probably be one in which these concepts did pick out objects in a classical-like way. Unfortunately, the world is not arranged so as to conform to our needs.

\[\vdots\]

The gradation of properties in the world means that our smallish number of categories will never map perfectly onto all objects: the distinction between members and nonmembers will always be difficult to draw or will even be arbitrary in some cases. If the world existed as much more distinct clumps of objects, then perhaps our concepts could be formed as the classical view says they are. But if the world consists of shadings and gradations and of a rich mixture of different kinds of properties, then a limited number of concepts would almost have to be fuzzy.

\end{quote}

As described by \citet[Chapter~3]{murphy:bbc}, there are three new views that have emerged: the exemplar approach, the prototype approach, and the knowledge approach. The first uses the information provided by each encounter with an exemplar for a category separately; the second works with a \emph{summary representation} of a category derived from the experience of exemplars; and the third integrates concepts with the broader knowledge schemata in which they must reside via plausible reasoning. 

Because concepts are used in very diverse tasks, none of these approaches is able to account for all the empirical data. Indeed, as \citet[Chapter~13]{murphy:bbc} concludes, some amalgam of the three will probably be required for a ``Big Theory of Concepts'' as they also appear to be somewhat complementary in their explanatory adequacy. In other words, each approach focuses on a different source of information, and any one or more of these sources may be summoned for a particular task based on its suitability.

%\footnote{I apologize to the reader for this extremely abstract summary of a very large and fascinating field.}

I will adapt the first two approaches for my purposes. The third knowledge approach is, in a sense, not really an independent stand-alone approach but one that operates by combining knowledge effects with one or both of the other approaches. I construct the simplest models required for the tasks at hand and do not aim at more comprehensive versions.

\section{Basic setup}

Both the exemplar and prototype approaches rely on the idea that each exemplar of a concept has multiple properties that take on particular values. For example, the concept \emph{bald} may involve features such as the number of hairs on the scalp, the number of completely hairless patches on the scalp, the fraction of the scalp that is hairless, and so on;\footnote{Such a listing of features is an idealization as they are not entirely independent of one another. It is not clear, however, whether agents actually operate with completely independent attributes. Presumably, this depends on what they know and this is one way in which knowledge effects may enter.} each exemplar will instantiate these attributes with particular numbers. In other words, each concept is associated with an $n$-dimensional attribute space and each exemplar can be represented by a point in this space. Some dimensions may be continuous and some may be discrete.

%but this should not affect the basic idea.

Let $b_i$ with $i = 1, 2, \ldots, N$ be clear exemplars of \emph{bald} that an agent $\cal A$ has encountered in his experience. Likewise, let $b'_{i'}$ with $i' = 1, 2, \ldots, N'$ be clear exemplars of \emph{not bald}. A negative category such as the latter is a little unusual in that it contains not just persons with a full head of hair but also random items such as clocks and cars. There is no problem with this as all potential exemplars are assessed relative to the relevant attributes which come from the corresponding positive category. Thus, only persons with relatively full heads of hair will qualify as exemplars and items such as clocks and cars will be discarded as junk. A different way to think about negative categories is that in any particular situation where its exemplars are accessed, there will always be a default reference category that will automatically limit the possibilities to the relevant types of individuals. In the case of \emph{not bald}, the possibilities will be limited to persons; in the case of \emph{not tall} to men or women or basketball players, depending on the situation; and in the case of \emph{not chair}, the default category might be items of furniture.

Let $x_{ij}$ be the value of the $j$th attribute of $b_i$ and, similarly, let $x'_{i'j}$ be the value of the $j$th attribute of $b'_{i'}$. That is, $b_i = (x_{ij})$ and $b'_{i'} = (x'_{i'j})$, the right-hand side of both equalities being vectors with $j = 1, 2, \ldots, n$.

Now suppose $\cal A$ has to judge whether the candidate $a$ is bald or not bald or borderline bald in $u$. Then $a$ will also be a point in the same space with value $x_{aj}$ in the $j$th dimension. That is, $a = (x_{aj})$.

The basic idea underlying both approaches is to see how ``far'' $a$ is from all the exemplars taken separately or from an ``average'' exemplar (i.e.\ the prototype) and, based on this, to see how similar $a$ is to the other members in the category. This computation allows $\cal A$ to decide where $a$ stands with respect to \emph{bald}.


\subsection{The exemplar model}

This model has its roots in \citet{ms:ctcl,nosofsky:epsr}; and \citet{np:e}. I build upon the description in \citet[65--71]{murphy:bbc}. \citet{schiffer:vp} informally mentions the possibility of using weighted distance in the context of vagueness.

In order to get at the psychological distance between $a$ and $b_i$, we need to first note the following. For certain attributes such as the number of hairs on an individual's scalp, if $a$'s value $x_{a1}$ is less than $b_i$'s value $x_{i1}$ then the psychological difference between these values along this dimension is not $|x_{a1} - x_{i1}|$ but $0$ because $b_i$ is an \emph{exemplar} and $a$ has, so to speak, met the \emph{bar} set by $b_i$. Likewise, if the attribute is the number of completely hairless patches on the individual's scalp, and if $x_{a2} > x_{i2}$, then again the difference is $0$ by the same reasoning. There may, of course, be attributes where only an exact equality $x_{aj} = x_{ij}$ results in a zero difference.\footnote{For example, the category \emph{blue} is such because overshooting the relevant color frequency in either direction counts as a nonzero difference. With such attributes, only an exact equality results in a zero difference.} So we can define a psychological difference function $\delta(x_{aj}, x_{ij})$ which is either $0$ or $|x_{aj} - x_{ij}|$ based on the nature of the concept and attribute being considered.\footnote{There is some empirical warrant for such a result as reported in, for example, \citet{hes:ccpc}.}

Now define the weighted psychological distance between $a$ and $b_i$ as follows:

\[ d_u(a, b_i)\ = \ \sqrt{\ \sum_{j = 1}^{n}\ w_j(u)\ \delta(x_{aj}, x_{ij})^2} \]

\noindent Here, $w_j(u)$ are weights issuing from the situation $u$. The psychological distance that $\cal A$ perceives between a candidate and an exemplar thus varies with the situation he is in. This variation implies that certain attributes and therefore certain exemplars will play a more or less important role in $\cal A$'s judgment.

This distance function is \emph{not} a metric in the technical sense as it is not symmetric: $d_u(a, b_i)$ may not equal $d_u(b_i, a)$ because the underlying psychological difference function $\delta$ is not symmetric. Also, many different forms for it can be used; I have restricted myself to the commonest Euclidean variety.

Correspondingly, the weighted psychological distance between $a$ and $b'_{i'}$ will be:

\[ d_u(a, b'_{i'})\ = \ \sqrt{\ \sum_{j = 1}^{n}\ w'_j(u)\ \delta(x_{aj}, x'_{i'j})^2} \]

\citet{shepard:ulg} has shown that behavioral similarity between items is an exponentially decreasing function of their psychological distance.

\[ s_u(a, b_i) = e^{-c(u)d_u(a, b_i)} \] 

\noindent where $c(u) > 0$ is a situation-based parameter. Again, a larger or smaller $c(u)$ will determine the relative importance of items that are near and items that are far.

Analogously:

\[ s_u(a, b'_{i'}) = e^{-c'(u)d_u(a, b'_{i'})} \]


Finally, define the psychological probability that $a$ is bald rather than not bald for the agent $\cal A$ as follows:
~\\
\[ P(\emph{bald} \cond a; u) = \frac{\sum_{i = 1}^N s_u(a, b_i)}{\sum_{i = 1}^N s_u(a, b_i) + \sum_{i' = 1}^{N'} s_u(a, b'_{i'})} \]

\noindent Then:

\[ P(\emph{not bald} \cond a; u) = \frac{\sum_{i' = 1}^{N'} s_u(a, b'_{i'})}{\sum_{i = 1}^N s_u(a, b_i) + \sum_{i' = 1}^{N'} s_u(a, b'_{i'})} \]
~\\
Note that $P(\emph{bald} \cond a; u) + P(\emph{not bald} \cond a; u) = 1$. These psychological probabilities are measured with respect to the agent $\cal A$ as they are based on his exemplars. So they are agent-relative probabilities. But they are not ``subjective'' probabilities in the usual sense of being $\cal A$'s beliefs. 

%This means they are not open to the standard charges against epistemic probabilistic accounts of vagueness that are based on an agent's beliefs. 

%The probabilities depend on the situation $u$ which is a parameter, not a conditioning random variable. If desired, we can introduce weights $v_i(u)$, $v'_{i'}(u)$ for each pair of similarities $s_u(a, b_i)$, $s_u(a, b'_{i'})$ but I will not. They would allow us to weight different exemplars directly. 
%
%I will return to these identifications after describing the prototype model.

\subsection{The prototype model}

This model has its roots in \citet{rm:fr} but the account below is based on a certain natural construal of a summary representation of a category.

The only difference between the exemplar model and the prototype model is that the latter does not compute the psychological distance between the candidate and each exemplar separately as above but first averages the values of all the exemplars and then computes the distance from this average.

So we first define the average values as follows:

\[ \overline{x_j} = \frac{\sum_{i = 1}^N w_i(u) x_{ij}}{N} \]

\[ \overline{x'_j} = \frac{\sum_{i' = 1}^{N'} w'_i(u) x'_{i'j}}{N'} \]

This tells us that the prototypes for \emph{bald} and \emph{not bald} are just $\overline{b} = (\overline{x_j})$ and $\overline{b'} = (\overline{x'_j})$. The weights $w_i(u)$, $w'_i(u)$ are different from the earlier weights above described in the exemplar model, and are also indexed with respect to $i$ and not $j$ as before. These weights play an important role because sometimes extreme examples such as a completely hairless person count as prototypes. Such extreme exemplars can be selected as the relevant prototypical average by adjusting the weights suitably. Alternatively, they can be selected as the minimum or maximum of the relevant attribute values.\footnote{Generalized means are a family of functions for aggregating sets of numbers and we can draw upon any of these based on the nature of the concept and its attributes. See, for example, \url{http://en.wikipedia.org/wiki/Generalized_mean}.}

%with many categories such as \emph{bald}

We can use the same idea for the psychological difference as before except that it is measured with respect to the average values. So $\delta(x_{aj}, \overline{x_{j}})$ is either $0$ or $|x_{aj} - \overline{x_{j}}|$ based on the nature of the concept and attribute being considered and likewise with $\delta(x_{aj}, \overline{x'_{j}})$.

Now the weighted psychological distance from the prototype is defined as follows:

\[ d_u(a, \overline{b})\ = \ \sqrt{\ \sum_{j = 1}^{n}\ w_j(u)\ \delta(x_{aj}, \overline{x_j})^2} \]

\[ d_u(a, \overline{b'})\ = \ \sqrt{\ \sum_{j = 1}^{n}\ w'_j(u)\ \delta(x_{aj}, \overline{x'_{j}})^2} \]

This in turn leads to similarity.

\[ s_u(a, \overline{b}) = e^{-c(u)d_u(a, \overline{b})} \] 

\[ s_u(a, \overline{b'}) = e^{-c'(u)d_u(a, \overline{b'})} \]

And finally to the psychological probabilities for $\cal A$ as above.

\[ P(\emph{bald} \cond a; u) = \frac{s_u(a, \overline{b})}{s_u(a, \overline{b}) + s_u(a, \overline{b'})} \]

\[ P(\emph{not bald} \cond a; u) = \frac{s_u(a, \overline{b'})}{s_u(a, \overline{b}) + s_u(a, \overline{b'})} \]

As stated above, the key difference is that distances and similarities are measured with respect to a ``summary representation,'' an \emph{average} (or generalized mean) of all the exemplars.

Both models give us somewhat different ways to compute the same psychological probabilities $P(\emph{bald} \cond a; u)$ and $P(\emph{not bald} \cond a; u)$. I now put them to use.


\section{Characterizing vagueness}

Intuitively, if a candidate is sufficiently similar to clear exemplars of both \emph{bald} and \emph{not bald}, it is reasonable to think it is a borderline case. This suggests the following definitions:

\begin{definition}

A candidate $a$ is a borderline case of a concept $C$ for an agent $\cal A$ in situation $u$ if and only if $|P(C \cond a; u) - P(\emph{not}\ C \cond a; u)| < \epsilon_u$ where $0 < \epsilon_u < 1$ is $\cal A$'s threshold in $u$. If $a$ is not a borderline case, then it is classified as clearly belonging to $C$ if and only if $P(C \cond a; u) > P(\emph{not}\ C \cond a; u)$ and as clearly belonging to $\emph{not}\ C$ if and only if $P(C \cond a; u) < P(\emph{not}\ C \cond a; u)$.
\label{def:base} 
\end{definition}

%\footnote{I have deliberately suppressed the agent in specifying the probabilities and threshold to avoid notational clutter.}

\begin{definition}

A concept is vague for an agent $\cal A$ in situation $u$ if and only if it has borderline cases. Otherwise, it is precise or ``classical.''

\end{definition}

The decision to count an item as borderline or clear is \emph{derived from} agent-relative psychological probabilities but is not itself probabilistic or belief-based (e.g.\  $a$ is borderline with ``subjective'' probability $q$). So it is doubly immune to the charge against subjective probability views made by \citet[Chapter~5]{schiffer:tm}: it is not based on beliefs and it is deterministic. 

%It also does not follow the Luce Choice Rule as described by \citet[69]{murphy:bbc} which enjoins the agent to make judgments that are themselves probabilistic. This rule has some empirical support for a task such as classifying an animal as a dog, cat, or burro, but has probably not been tested against my way of using these probabilities to get at complementary categories such as \emph{bald} and \emph{not bald}.

The threshold $\epsilon_u$ is a kind of limiting value but it should not be confused with any \emph{direct} cutoff between clear and borderline cases as that would be assuming what has to be established. It operates at the more basic level of psychological probabilities and \emph{enables} us to draw a line between clear and borderline cases. Moreover, $\epsilon_u$ can be conceived as a precise number or a fuzzy number.\footnote{A fuzzy number $A$ is generally expressed as a function $A: \mathbb{R} \functionarrow [0,1]$ such that:

\[ A(x) = \left\{ \begin{array}{ll}
f(x) & \mbox{for $x \in [a,b]$} \\
1 & \mbox{for $x \in [b,c]$} \\
g(x) & \mbox{for $x \in [c,d]$} \\
0 & \mbox{for $x < a$ and $x > d$}
\end{array}
\right. \]

\noindent where $a \leq b \leq c \leq d$, $f$ is a continuous function that increases to $1$ at point $b$, and $g$ is a continuous function that decreases from $1$ at point $c$. See \citet[170]{ksy:fst}.} It should also be seen as something the agent does not know for himself in different situations. Lastly, it arises through communicative interactions and so agents in the same community tend to share it to a greater degree than intuition might suggest. Here, knowledge effects of the kind alluded to earlier when I described the knowledge approach to concepts may play an important role as such thresholds tend to partly arise also from the goals and interests of agents. 

$\cal A$'s cognitive system determines when a case is borderline or clear. It is not entirely a conscious decision. This is confirmed by the familiar feeling of being stymied when we are asked to make a conscious judgment about a borderline case. There is simply no way to reason \emph{decisively} about it based on the external facts. 

%In a sense, the exemplars and the thresholds are the inaccessible ``hidden variables'' of the decision process. Indeed, when we scrutinize a judgment we have arrived at we may become uncertain about it as there is \emph{no nonvague argument} available for the \emph{feeling} that $a$ is borderline. It is largely 
%subpersonal. And all this is intensified when the threshold is a fuzzy number rather than a precise number.

An item $a$ that is a borderline case for one agent need not be so for another agent. Likewise, the borderline cases of a concept shift with $u$ for the same agent because all aspects of the definition depend on $u$, the probabilities as well as the threshold. The same agent $\cal A$ may choose to call Bill bald in one situation but not in another as the sentence \Expression{Bill is bald} may be true for $\cal A$ in one situation, false for $\cal A$ in another, and indeterminate for $\cal A$ in a third. Consider the sentences \Expression{She won't date Bill -- he's bald} and \Expression{Bill isn't bald -- he needs a haircut.} In the first case, the situation $u$ is such that a less stringent membership condition for \emph{bald} is operative, either because relatively less-bald exemplars are weighted more or because the magnitude of the threshold $\epsilon_u$ is relatively smaller making the penumbra, the region of borderline cases, correspondingly smaller as well, or possibly because both factors apply simultaneously. In the second case, the situation $u$ is the opposite -- a more stringent membership condition is used. This explains what \citet{schiffer:vp} calls \emph{penumbral shift} in a natural way.

In order to obtain ``natural'' concepts of the kind that would be useful in thinking and communication, we must assume that the positive exemplars (i.e.\ the set $\{b_i\}$ for \emph{bald}) are so distributed that all members of their convex closure are instances of $C$. Otherwise, we would get strange and seemingly arbitrary outcomes for what belongs to $C$, what is borderline $C$, and what is not $C$. This requirement translates into a restriction on $\epsilon_u$: it must be sufficiently small. In other words, if $b = (b_i)$, $b' = (b'_{i'})$, the latter in each case being the vectors of positive and negative exemplars of \emph{bald}, then $0 < \epsilon_u < \zeta_u(b, b') < 1$ where $\zeta_u(b, b')$ is a function of the $N$ positive exemplars and $N'$ negative exemplars that derives from the convexity assumption. The same kind of condition is obviously not required for the negative exemplars as they can, in general, lie anywhere outside the convex closure of the positive exemplars in the $n$-dimensional attribute space. A candidate $a$ that is judged to belong to $C$ \emph{need not} lie within the convex closure. All that is required is that it be sufficiently close to it. Indeed, subsequently, $a$ would become a positive exemplar itself and the convex closure could be correspondingly enlarged. This suggests a dynamic model of concept learning that results in possibly expanded convex closures as more exemplars are encountered. After a while, the category would converge to a convex polytope in the attribute space with somewhat different boundaries for different situations $u$.

This convexity assumption is very similar to the convexity assumption made by \citet{gardenfors:cs} and \citet{wg:scsmm}. My approach of using exemplars to derive concepts seems to allow a clearer development of these ideas from a more foundational starting point. Also, their decision to banish the \emph{external} significance of language from their model seems unnecessary and raises too many problems (e.g.\ \citealt{putnam:mm}; \citealt[28--31]{bp:sa}). As I show presently, conventional meanings are mental representations but referential meanings are external entities such as the individuals and properties that make up propositions. It is possible to have one's cake and eat it too.

What may be true or false or indeterminate for one agent may not be so for another. There is \emph{no} agent-independent or objective truth value in other words. However, because the agents must belong to the same linguistic community and the exemplars each agent draws upon are often shared through communication, they may agree more often than expected. In fact, for a concept to be socially useful as most are, its exemplars must be \emph{sufficiently} shared among the community. This points to a community model of interacting agents where concepts are constantly being revised to have sufficient overlap.

The definitions above suggest that if the threshold is a precise, nonfuzzy number there is no \emph{higher-order vagueness}, the phenomenon that the borderline between clear and borderline cases is itself unclear, resulting in borderline borderline cases and so on ad infinitum. If we wish to allow for higher-order vagueness, the threshold can be identified with a fuzzy number. In this case, there is no precise cutoff between clear and borderline cases and higher-order vagueness can be admitted.\footnote{I believe my model is richer than \citegen{hampton:tgmv} because it allows for both graded membership in a category as well as fuzzy judgments of when a case is clear or borderline whereas \citet[377]{hampton:tgmv} only allows for the former while pointing to the latter as important experimental evidence. Something like Definition~\ref{def:base} would have to be added to his model.} The evidence seems to indicate that higher-order vagueness is real. This implies that the threshold $\epsilon_u$ must be a fuzzy number and not a precise number. 

%The foregoing implies an epistemic view of this as agents are typically unaware of their thresholds in particular situations.



%However, for my purposes here, I keep the matter open and continue to discuss both possibilities.

The mistake ``epistemicists'' such as \citet{williamson:v} seem to make is to assume the existence of sharp cutoffs between clear cases of a concept and its complement. That is, they not only reject higher-order vagueness but also first-order vagueness, which is completely unrealistic. 

%It is easy enough to \emph{derive} precise cutoffs between clear and borderline cases from underlying thresholds and thus allow for first-order vagueness without higher-order vagueness; further, for greater realism, by taking the underlying threshold to be a fuzzy number, we can accommodate higher-order vagueness as well.

Indeed, it is possible to \emph{characterize} higher-order vagueness by treating Definition~\ref{def:base} as a base case for an inductive definition. The key idea is to identify exemplars at each level, and therefore, psychological distance, similarity, and psychological probabilities at each level. For example, Definition~\ref{def:base} provides a precise or fuzzy account of first-order borderline cases. Then we can identify positive and negative exemplars for what is clearly borderline and what is clearly not borderline which, in turn, gives rise to psychological distance and similarity and psychological probabilities at the next level. The latter can then be used in a manner analogous to Definition~\ref{def:base} to define borderline borderline cases or, in other words, second-order vagueness. And so on to higher-order vagueness for all $n$. 

In the definition below, I assume that we have the exemplars for $n$th-order vagueness and therefore the $n$th-order psychological probabilities $P_n(C_n \cond a; u)$ and $P_n(\emph{not}\ C_n \cond a; u)$ where $C_n$ is the $n$th-order concept of being $n$th-order borderline $C$ and \emph{not} $C_n$ is the corresponding complementary concept. When $n = 0$, this is understood as just standing for the concepts $C$ and \emph{not} $C$.

\begin{definition}\label{def:hov}
A candidate $a$ is an $(n + 1)$st-order borderline case of a concept $C$ for an agent $\cal A$ in situation $u$ if and only if $|P_n(C_n \cond a; u) - P_n(\emph{not}\ C_n \cond a; u)| < \epsilon_{n,u}$ where $0 < \epsilon_{n,u} < 1$ is $\cal A$'s threshold in $u$. If $a$ is not an $(n + 1)$st-order borderline case, then it is classified as being clearly $n$th-order borderline or clearly not $n$th-order borderline according to whether $P_n(C_n \cond a; u)$ or $P_n(\emph{not}\ C_n \cond a; u)$ is greater.
\end{definition}

Combining this definition with Definition~\ref{def:base} yields a characterization of high\-er-order vagueness for all $n$. Now, the threshold $\epsilon_{n,u}$ has to be understood as fuzzy and this gives rise to a fuzzy \emph{fractal}\footnote{A fractal is an object or quantity that displays ``self-similarity'' on all scales. See \url{https://en.wikipedia.org/wiki/Fractal}.} set with no crisp boundaries even in the limit. There is some indirect evidence for the fractal nature of higher-order vagueness in \citet{haamp:re}. In practice, of course, an agent will not actually possess or construct the threshold $\epsilon_{n,u}$ for all $n$, only for first- and possibly second-order borderline cases as there is no practical utility in having such higher-order thresholds.

%A slightly different way to approach vagueness is described below.\footnote{The general idea was suggested to me by Gregory Murphy. I have fleshed out the details.}
%
%\begin{definition}
%
%$P(\emph{borderline}\ C \cond a; u) = 1 - |P(C \cond a; u) - P(\emph{not}\ C \cond a; u)|$.
%
%\end{definition}
%
%Now we have $P(C \cond a; u)$, $P(\emph{not}\ C \cond a; u)$, and $P(\emph{borderline}\ C \cond a; u)$.\footnote{There are overlaps among these probabilities so they do not sum to $1$.} These psychological probabilities can be used to define borderline cases in different ways. One possible decision rule is that $\cal A$ judges $a$ to be borderline $P(\emph{borderline}\ C \cond a; u) \times 100$ percent of the time. For example, if $P(\emph{borderline}\ C \cond a; u) = 0.6$ then $\cal A$ will judge $a$ to be borderline $C$ $60\%$ of the time.
%
%\begin{definition}
%
%A candidate $a$ is a borderline case of a concept $C$ for an agent $\cal A$ in situation $u$ $P(\emph{borderline}\ C \cond a; u) \times 100$ percent of the time. If $a$ is not judged to be a borderline case, then it is classified as clearly belonging to $C$ if and only if $P(C \cond a; u) > P(\emph{not}\ C \cond a; u)$ and as clearly belonging to $\emph{not}\ C$ if and only if $P(C \cond a; u) < P(\emph{not}\ C \cond a; u)$.
%\label{def:alt}
%\end{definition}
%
%This decision rule implies that there is no sharp cutoff between clear and borderline cases and so also leaves open the possibility of higher-order vagueness which can be defined in analogy with Definition~\ref{def:hov}. It also has the advantage of dispensing with the threshold $\epsilon_u$ and so manages with one less assumption. However, this definition faces certain problems as it may lead to odd results when a case that would ordinarily (e.g.\ by Definition~\ref{def:base}) be judged to be borderline is not so judged owing to the decision rule being probabilistic. Incidentally, to the extent Definition~\ref{def:alt} involves a probabilistic rule, it does follow something like the Luce Choice Rule referred to above.

%The alert reader will have noticed that the apparatus of similarity and similarity-based probabilities is in fact unnecessary for these definitions. One could directly define borderline and clear cases once the notion of psychological distance is available. However, I do not do this in order to more closely mimic the psychological literature for greater empirical accuracy and also to connect with other non-distance-based ways of capturing similarity as the latter seems like the fundamental idea. That is, instead of dispensing with similarity, we could dispense with distance, and define similarity on some different underlying basis.

Vague properties can now be easily characterized.


\begin{definition}
A property is vague if and only if it is based on the community's corresponding vague concepts, either as an average or as an individual counterpart.
\label{def:prop}
\end{definition}

Definition~\ref{def:prop} covers both types of property, the average kind and the individual kind. It is deliberately vague as there are somewhat messy issues relating to what happens if some members of the community have incorrect concepts and also if some members are vague and others are precise about the same concept. As should be obvious, the same sorts of observations, mutatis mutandis, hold for vague properties as for vague concepts. However, propositions involving average vague properties are objectively true or false or indeterminate as the latter are derived from the concepts of all the individuals in a community. But in general there is no way to know with certainty which of these truth values actually obtains as we have only approximate epistemic access to such a property.

Incidentally, the foregoing observations about how properties result from the averaging of individual concepts may provide a new way of defining properties as social constructs in a precise way. All sorts of averaging operations may be utilized for this purpose based on the particular property being defined.


\section{The sorites paradox}

The sorites paradox can be formulated for any vague property. It consists of the following type of argument:

\begin{enumerate}

\item A hairless person is bald.

\item For all $k$, if a person with $k$ hairs is bald, then a person with $k + 1$ hairs is bald.

\item Therefore, all persons are bald.

\end{enumerate}

Most proposed solutions to the paradox deny the second premise on either semantic or epistemic grounds. \citet[Chapter~5]{schiffer:tm} does an able job of dispelling such proposals. My resolution also denies the same premise but on \emph{psychological} grounds. First, consider an agent-relative concept-based (or individual property-based) restatement of this premise:

\begin{itemize}

\item For all $k$, if $\cal A$ judges a person with $k$ hairs to be bald then he would judge a person with $k + 1$ hairs to be bald.

\end{itemize}

The key to the resolution is that such judgments are made on the basis of \emph{multiple} exemplars or a category prototype which is also based on multiple exemplars. So it is quite possible for $\cal A$ to judge a person with $k$ hairs to be bald and then judge a person with $k + 1$ hairs to be only borderline bald for some definite or fuzzy $k^\star$. This would be true even if we restricted our attention to all the exemplars in the sequence, that is, $1, 2, 3, \ldots, k$ that have already been judged by $\cal A$ to be bald. As the value of $k$ increases, the distance from the early members of the series (or from the dynamically changing prototype) keeps growing, their similarity keeps dropping, and, at $k^\star$, $\cal A$ finds himself with a borderline case that is not clearly bald. This follows easily from Definition~\ref{def:base}.

I am \emph{not} saying that there is a definite cutoff between bald and not bald as many attempts at solution do; I am saying there is either a precise or fuzzy cutoff between clearly bald and borderline bald (and also between borderline bald and not bald). Whether $k^\star$ is a precise or fuzzy number depends on whether $\cal A$'s threshold $\epsilon_u$ is a precise or fuzzy number. Moreover, $\cal A$'s own cutoff will change with the situation $u$ in which he is asked to make the judgments because $\epsilon_u$ depends on $u$. Finally, different agents will have different cutoffs because their thresholds will generally be a little different.

The reason why the sorites argument seems plausible is that its formulation tricks us into consciously focusing on just a single exemplar: the previous case $k$ in the second premise. Because our judgments about vague concepts are typically subpersonal and nonconscious, we are not aware of the multiple exemplars $1, 2, 3, \ldots, (k - 1),\ \hbox{and}\ k$ (and we are not aware of the thresholds) that go into our judgments. Indeed, our judgments also lack the kind of firm conviction we have in judging that $2 + 2 = 4$ and we may waffle over the exact value of $k^\star$. So the sorites works by forcing us to make intermediate judgments in a conscious and unnatural way and then freeing us to judge the conclusion that all persons are bald in a nonconscious natural way.

Since properties are abstract social constructs built out of community members' individual concepts, it follows that the agent-independent property version of the sorites paradox will also have the same kind of resolution. That is, there will be some function of the individual $k^\star$ values for each agent that yields some social cutoff $K^\star$ although it will not be possible for anyone to know what its precise or fuzzy value is.

%If Definition~\ref{def:alt} is used instead, the argument is less smooth because $\cal A$ may judge a person with $k$ hairs to be borderline and then the next person with $k + 1$ hairs to be bald. And $\cal A$ may never judge a candidate to be borderline because that decision is probabilistic and may go directly from baldness to nonbaldness. But, barring these odd cases, the basic idea works because $P(\emph{borderline}\ C \cond a; u)$ keeps growing as the number of hairs grows.

%Since Definition~\ref{def:base} gives us a knockdown argument against the sorites and allows us to consider higher-order vagueness as well, it appears that it is to be preferred to Definition~\ref{def:alt}. In any case, the key point underlying both accounts is the same: new candidates are judged against multiple exemplars, not just the previous exemplar in the sequence.

\section{Essentially contested concepts} \label{sec:essentially contested concepts}

Because practically every word in a natural language is vague, practically every word is potentially evaluative, that is, it involves standards of judgment. These standards result from the \emph{exemplars} present in the definition of vagueness and the calculation of distance from them and also from the thresholds. This observation applies not only to weighty concepts like \emph{art},\footnote{The ensuing discussion has some  relevance for attempts to define art. See \citet{adajian:da}.} \emph{science},\footnote{The discussion that follows has some relevance for the demarcation problem in the philosophy of science. See \citet{popper:lsd}.} \emph{politics}, and \emph{good} but also to mundane ones like \emph{bald} and \emph{tall}. Such concepts are inherently contestable as pointed out by \citet{gallie:ecc} in a pioneering analysis because, in the context of my model, individual and group agents may have somewhat different exemplars, may consider somewhat different attributes for each exemplar, or may weight these dimensions differently, and, as a consequence, arrive at potentially quite different concepts with substantially less overlap than I have discussed so far. My use of the term is wider than Gallie's as he restricts it to traditional areas of philosophy such as ethics, aesthetics, and political philosophy where contests over the meaning of a word are endless and conceptual differences are greater. But admittedly transitory and less material contests also occur over everyday concepts such as \emph{bald} that can therefore be assimilated to the same idea.

Besides, not all of Gallie's necessary conditions seem essential to the core notion. He offers seven: the concept must be evaluative, internally complex, variously describable, and undergo penumbral shift; the parties to the contest must be aware of the contest and must share an original exemplar; and the contest itself must enable the original exemplar's ``achievement'' to be optimally developed or at least sustained. Of these, the first four result from my model of vagueness, and the last three can be dropped. In particular, a vague concept's attributes make it internally complex and also variously describable by altering either some attributes themselves or their values or their relative weights. It is also susceptible to penumbral shift. This suggests the following definition.

\begin{definition}

A concept is essentially contestable if and only if it is vague.

\end{definition}

Since most concepts are vague and therefore evaluative, language is an agonistic site of innumerable large or small potential contests against a background of \emph{partially} shared (conventional) meanings. The actual disputes that take place over the meaning and use of terms reflect the large or small differential \emph{interests} of the members of the linguistic community. Two individuals or groups may diverge over whether someone is bald or, more significantly, over whether some policy is democratic.\footnote{\citet{connolly:tpd} offers an illuminating discussion of the contests surrounding fundamental concepts in political theory such as \emph{politics}, \emph{interests}, \emph{power}, and \emph{freedom}. He goes on to show how these debates are constitutive of politics itself and therefore how conceptual revision is a necessary condition for political change.} Thus vagueness has an extremely important consequence: it gives language a \emph{normative}\is{normativity} and even a \emph{moral} dimension. While the gross structure of meanings classifies and partially constitutes the entities individuated by a society as described in \sectref{sec:information} and \chapref{ch:romantic tradition}, its fine structure as given by the definitions in this chapter corresponds to and partially constitutes the contrasting values that prevail in society. As \citet[Section~242, 88]{wittgenstein:pi} said: ``If language is to be a means of communication there must be agreement not only in definitions but also (queer as this may sound) in judgments.'' If communication is understood as an identity between content conveyed and content grasped, then Wittgenstein is fully right but, as I argued in \citet{parikh:ul, parikh:rs, parikh:le}, this identity condition is just an ideal limiting case that is seldom realized in practice. Less than ideal communication is in fact the norm. This entire book also reinforces the same point.

In \sectref{sec:language}, I described \citegen{taylor:tm} arguments for an expressive dimension of language. It should now be clear that the constitutive role he assigns to language is not restricted just to subject-referring emotions, social relationships, and moral values but is widespread as it applies equally to ordinary words such as \Expression{bald} and \Expression{tall}. The uses of such words, too, partially constitute their contents. This kind of constitution does \emph{not} make these contents \emph{linguistic}: they retain their abstract character. Moreover, vagueness in language is essential to human beings because, given the fuzzy nature of the world as described in the quote at this chapter's start, it allows us to agree and disagree in subtler and more efficient ways about such matters that can only be subjective or intersubjective but not objective, and the possibility of such flexible (dis)agreement is necessary to our emotions, concerns, relationships, and moral lives.

Lastly, because properties may be viewed as appropriately derived averages of the individual concepts in a community, it is not just vague language but also vague properties that are normative\is{normativity} in the sense discussed. Since most concepts are vague, most properties are vague, and thus we get the somewhat startling view that the individuated informational space or world described in \sectref{sec:information} is largely one based on human norms.\footnote{Vagueness is not the only language-related source of normativity. The Romantic conception of language provides another way for norms to arise through language. A third way is based on the speech act theory of \citet{austin:htdtww} and especially \citet{habermas:wup, habermas:ctm}.} As I said in \sectref{sec:classic example}, one of the benefits of approaching meaning via communication is that the normative character of language and the world emerge in an especially clear light.

%Interpersonal interaction raises moral issues and it is natural to expect that these will be expressed partly through language.

\section{Back to communication} \label{sec:back to communication}

Recall from \sectref{sec:communication game} that the Communication Game $\Gamma_u = (SG_u, CSG_u, GG_u(\sigma),\allowbreak UG_u(\varphi), G_u(\varphi)) = (SG_u, CSG_u, GG_u, UG_u, G_u)$. As I have addressed locutionary communication quite thoroughly already, I will confine myself to a few remarks about where vagueness may alter the foregoing analysis. It turns out that the conceptual difficulties it poses do not overly complicate our semantic frameworks. 

One somewhat new phenomenon that arises with vague concepts is how precise an agent needs to make his utterance to balance the conflicting demands of costs and benefits. If $\cal A$ makes the content more precise, then it may be more costly but may also yield greater benefits depending on the nature of his goals. This is similar but not identical to the issue of how much to explicitly disambiguate the lexical and structural ambiguities in a sentence as discussed in \sectref{sec:solving generation games}. There, the issue had to do with the particular \emph{sentence} that was optimal in $GG_u$ to capture the same optimal content from $CSG_u$. With vagueness, the issue is how precise to make the content itself and, therefore, the corresponding sentence. This requires us to look at $CSG_u$ rather than $GG_u$.

For example, the question before $\cal A$ might be whether he should convey the content $\sigma = \hbox{\emph{Bill is very bald}}$ or $\sigma' = \hbox{\emph{Bill is bald}}$ to $\cal B$ in some utterance situation $u$ based on some Setting Game $SG_u$. The former content would more tightly circumscribe the range of baldness conveyed and this may be desirable on account of the response $\cal A$ wishes to elicit from $\cal B$ in $u$ and the \emph{effect} it might have on $\cal B$ in $u$. 

Specifically, let the Setting Game $SG_u$ be one where $\cal B$ faces a decision about whether or not to date Bill and $\cal A$ has information that can help her. Assume it is common knowledge in $u$ that $\cal A$ is a well-wisher of $\cal B$ and that $\cal B$ prefers not to date Bill if he were very bald but would be okay with it if he were somewhat bald. Owing to this common knowledge, $\cal B$ generally trusts $\cal A$'s judgment and, other things being equal, would prefer not to go against his word. Further, assume Bill can be either very bald or just bald as far as $\cal B$ knows but $\cal A$ knows it is the former that is true.\footnote{It is the \emph{property} of being very bald that matters here, not the concept, and, as I said earlier, the property does allow objective truth.} Note the quite realistic and complicated preferences and knowledge the two agents have in the situation. This somewhat involved scenario together with the decision problem $SG_u$ induces the Content Selection Game $CSG_u$ shown in Figure~\ref{fig:vague CS}.\largerpage

\begin{figure}[h] 
\input{figures/pixvaguecontent.tex} 
\caption{A Content Selection Game with vague contents}
\label{fig:vague CS}
\end{figure}

Now, there are two initial situations $s$ and $s'$ in the center of the diagram instead of just one as we had in Figures~\ref{fig:CS} and \ref{fig:expanded CS}. The first of these is factual and is a part of $u$ and contains the fact that Bill is very bald. The second situation is also a part of $u$ and includes the counterfactual possibility that Bill is just bald. $\cal A$ knows $s$ is factual but $\cal B$ does not and so both agents have to consider both initial situations. In the absence of any further information, the prior probabilities $\rho$, $\rho'$ can both be taken to be $0.5$.\footnote{There is a certain subtlety involved here because $\cal A$ knows that $s$ is factual and therefore that $\rho = 1$ for him. One could say either that the game is played prior to his knowing this (the usual assumption in standard game theory) or, what I prefer, that they have common knowledge of $\cal B$'s belief of equiprobability. That is, $\cal A$ adopts $\cal B$'s ignorance for the sake of the situation.} In both situations, $\cal A$ can convey either $\sigma$ or $\sigma'$ assuming that when Bill is bald, that is, in $s'$, $\cal A$ could be said to \emph{exaggerate} Bill's baldness if he were to choose $\sigma$. These choices lead to two ovals or information sets (as we had in the earlier partial information games) and then to $\cal B$'s possible responses $a = \hbox{\emph{don't date Bill}}$ and $a' = \hbox{\emph{date Bill}}$.

The preferences described informally above together with the slightly greater cost of $\sigma$ translate into the numerical payoffs shown in Figure~\ref{fig:vague CS}. It is a little tedious to go through how each pair of numbers is arrived at so I will explain just two pairs. Consider the path $s$, $\sigma$, $a$ on the upper right. Here, in the unnamed terminal situation that results, $\cal A$ has accurately conveyed that Bill is very bald as that is the fact in $s$ and $\cal B$ has chosen not to date Bill. Both parties are happy with the outcome given their preferences and so both get positive payoffs of $+7$ and $+5$, respectively. Now consider the path $s$, $\sigma'$, $a$ on the upper left. Here, $\cal A$ has chosen the slightly vaguer and cheaper content $\sigma'$ but $\cal B$'s decision remains the same so $\cal A$ gets a slightly higher payoff of $+8$. On the other hand, $\cal B$ has chosen not to date Bill despite receiving the content that Bill is just bald (rather than very bald) so, while she is happy with the outcome since $s$ contains the fact that Bill is very bald, she is also a little conflicted because she has gone against $\cal A$'s judgment that Bill is just bald (and that, in effect, it is okay to date Bill). So she gets a positive payoff of $+3$ which is a little lower than she got in the first case. All the other payoff numbers can be analyzed in a similar way. Perhaps the key thing to note is that there is a combination of cooperation and conflict in this Content Selection Game.\footnote{It is possible to complicate the model further by noting that the property of being bald or very bald is an average of the individual properties of the members of the community and so is epistemically inaccessible. This would make the payoffs depend on the \emph{beliefs} of the two agents and would require the psychological games of \citet{gps:pgsr}.}

I have gone into some detail to show how the preferences and payoffs are determined by psychological and social factors in the utterance situation of an intricate and nuanced sort. I repeat what I said in \sectref{sec:expanded content selection game}: a great diversity of human and social phenomena get resolved into relatively few numerical slots, the prior probabilities and the various payoffs. In this instance, however, the game tree has grown more complex with many more branches and so there are more numbers than before to be set.\largerpage

This completes the description of the relevant $CSG_u$ in $\Gamma_u$. Its more complex form has nothing to do with vagueness per se. It all depends on $u$ and I happened to include a choice between a relatively more precise statement and a less precise one as this kind of occurrence is not uncommon. The (Nash) solution to this $CSG_u$ is that $\cal A$ should choose to convey $\sigma = \hbox{\emph{Bill is very bald}}$ in $s$, which is the situation that matters since it is factual. As yet, $\cal B$ does not even know $CSG_u$ exists as nothing has been uttered. But when $\cal A$ does utter something like $\varphi = \Expression{Bill is very bald}$ as part of $GG_u(\sigma)$ and $\cal B$ interprets the utterance via $UG_u(\varphi)$ as conveying $\sigma$, she can then construct and play $CSG_u$. When she does this, her part of the (Nash) solution will be to respond with $a = \hbox{\emph{don't date Bill}}$. $\cal A$ will thus get a payoff of $+7$ and $\cal B$ of $+5$ by playing $CSG_u$.

I have mentioned both full rationality and partial rationality. In the partial information games that constitute the (locutionary and illocutionary) global game, full rationality is likely to operate as those games essentially involve comparing probabilities based on Equation~\ref{eq:simple} from \sectref{sec:maintheorem}. Even here, there are further simplifications that I will describe in the next chapter that make it easier to be fully rational. But when more complex calculations of the kind shown in Figure~\ref{fig:vague CS} are involved and when they have to be done in real time, resource bounds are likely to kick in, making full rationality harder to employ. In such circumstances, there will be a variety of measures the agent may adopt: using a fragmentary or approximate form of $CSG_u$; using a different model of payoffs and solutions as dictated, for example, by a theory such as \citegen{kt:pt} prospect theory; using heuristics to solve the game; or a combination of these. As the theory of partial rationality is still in its infancy, it is best to simply display the full model and outline the solution without trying to anticipate how it would be implemented. On the addressee's side, often she may see only the fragment of the game issuing from the actual content conveyed but there will be times when she might want to think about what alternative contents the speaker could have conveyed but chose not to.

How the issue of common knowledge of $CSG_u$ should be dealt with is unclear. One could baldly assume it despite all the partial information the agents are likely to have about the game. As handling the alternative possibilities is messy, I will just leave the matter unresolved with the warning that realism about the details is going to be quite thorny. This is where games with unaware players of the kind studied by \citet{hr:egpup, hr:gscgpup} are likely to be of use.

There is no need to go through $GG_u(\sigma)$ and $UG_u(\varphi)$ in detail. Both involve four constraints: Phonetic, Syntactic, Semantic, and Flow. I will confine myself to the Semantic Constraint that says that every word in an utterance is transformed by a conventional map into its conventional meaning(s) and then further transformed by a referential map into its referential meaning(s). 

So far, the conventional meanings of a word have been its conventionally associated and more or less \emph{shared} properties. But, as mentioned in \chapref{ch:picture of communication}, sharing a language partly involves sharing its conventional meanings but now, in light of our discussion of vagueness, it becomes clear that there is at best an overlap among, rather than common knowledge of, the concepts (or the corresponding individual, not average, properties) associated with a word. 

It is convenient to say that each conventional meaning for an agent is the word's conventionally associated concept (rather than individual property), and each referential meaning is the corresponding individual or property into which the former is mapped relative to the utterance situation $u$.
\[ \hbox{word} \longrightarrow \hbox{conventional meaning(s)} \stackrel{u}\longrightarrow \hbox{referential meaning(s)} \]

\noindent Symbolically expressed for each agent separately, this becomes:
\[ \omega \longrightarrow C^{\omega} \stackrel{u}\longrightarrow P^\omega \]

\noindent assuming the concept $C^{\omega}$ is converted into the corresponding property $P^\omega$ in $u$. The $u$ on top of the second arrow implies that it is an argument of the referential map together with the conventional meaning. This schema combines the internal and external significance of language as claimed earlier. It allows agents to compute referential meanings based on the conventional meanings in their heads and to convey abstract propositions that are not in their heads.

Consider now an utterance by $\cal A$ to $\cal B$ in $u$ of the sentence $\varphi = \Expression{Bill is very}$\linebreak$\Expression{bald}$. Then the two maps above will apply to each of the four words in the utterance. As our interest is in \Expression{bald}, we get the picture:\label{page:vague communication}


\[ \Expression{bald} \longrightarrow C^{\Expression{bald}} \stackrel{u}\longrightarrow P^\Expression{bald} \]

\noindent Each concept and property can be understood as marked by the relevant agent $\cal A$ or $\cal B$ implying that there are actually \emph{two} such arrow diagrams for the word, one for each agent. The vague concept $C^{\Expression{bald}}$ can be more or less any of the many situated concepts that $\cal A$ (or $\cal B$) has used in the past or it can be some average of these. Further, in the current situation $u$, it gets transformed via a new $u$-relative concept into its corresponding vague property. That is, the concept $C^{\Expression{bald}}$ that is the conventional meaning \emph{shifts} to a related concept $C'^{\Expression{bald}}$ relative to $u$ and thence to the corresponding property. This shift is required to accommodate the different kinds of uses of \Expression{bald} that may occur -- for example, in the sentences \Expression{She won't date Bill -- he's bald} and \Expression{Bill isn't bald -- he needs a haircut.} Here, the penumbra of the same agent's concept shifts in accord with the use by accessing different exemplars or attributes or weights. The transformation of $C^{\Expression{bald}}$ to the shifted concept $C'^{\Expression{bald}}$ also depends on truth as discussed in \sectref{sec:meaning and truth}. Working out the details is likely to be a bit involved but the broad contours of penumbral shift, the change of truth value of the same sentence in different situations, do not seem to raise any special problems once the general context-sensitivity of language is accounted for. This can be displayed as an extended Semantic Constraint as follows:
\[ \Expression{bald} \longrightarrow C^{\Expression{bald}} \stackrel{u}\longrightarrow C'^{\Expression{bald}} \stackrel{u}\longrightarrow P^\Expression{bald} \]

The property that is the referential meaning can be taken to be either the \emph{intersubjectively derived} average property or the subjective property and, in the former case, it can be assumed that each agent has just a partial and ``vague'' understanding of the content of the utterance. Also, with an actual utterance of $\varphi$, there would be more than two diagrams as the word \Expression{bald} is \emph{ambiguous} besides being vague. For example, it can also mean \emph{plain} or \emph{blunt} as in \Expression{a bald statement}. So there will be two or more conventional meanings, each of which will be mapped into their respective referential meanings for each agent. But we can ignore this complexity here. I will also omit consideration of the use of \Expression{very} with \Expression{bald} but it can be said in passing that it makes the threshold $\epsilon_u$ more stringent.

A third question to ask is what made it possible for $\cal A$ to choose $\sigma$ and utter $\varphi$ in the first place. In order to do so, he would have had to determine that Bill \emph{is} (very) bald and to make that determination he would have had to resort to the earlier calculations. That is, he would have ascertained that $|P(C'^{\Expression{bald}} \cond \hbox{Bill}; u) - P(\emph{not}\ C'^{\Expression{bald}} \cond \hbox{Bill}; u)| \geq \epsilon_u$ and that $P(C'^{\Expression{bald}} \cond \hbox{Bill}; u) > P(\emph{not}\ C'^{\Expression{bald}} \cond \hbox{Bill}; u)$, applying Definition~\ref{def:base} to the shifted concept. Because the threshold is more likely to be fuzzy, and fuzzy numbers involve membership functions, the calculation will involve some situated rule based on interval arithmetic for deciding what degree of membership is sufficient for counting someone very bald. In other words, such calculations are an integral part of content selection and natural language generation. Since most words in language are vague, this shows that speakers have quite a bit to do and it is something of a psycholinguistic mystery how so much is accomplished so quickly. Perhaps the human brain's parallel processing just is very fast with such probabilistic comparisons. On $\cal B$'s side, she simply has to access her concept $C^{\Expression{bald}}$ and then her shifted concept $C'^{\Expression{bald}}$ and corresponding property $P^\Expression{bald}$, although in circumstances where the truth of the proposition conveyed matters in determining it as described in \sectref{sec:meaning and truth}, she would have to go through the same arithmetic with her own threshold.

The rest of the analysis for such an example is identical to what we have seen with nonvague language. Thus, once one has the right approach to vagueness, its apparent hurdles seem to melt away.

I have construed the exemplar and prototype approaches of cognitive psychology in certain ways to characterize vagueness, approach the sorites paradox in a new way, analyze essentially contested concepts, and describe certain relevant aspects of vague communication. The models appear to have some empirical support as well though I want to emphasize the \emph{kind} of reasoning that is involved in addressing these problems. More realistic models of vagueness will doubtless become available but the underlying structure of explanation I have offered is not likely to change materially. For example, the explanation for the sorites based on the presence of multiple exemplars as opposed to a single exemplar is likely to survive further refinements of the underlying models of vagueness.


\section{Communication and categorization}

I want to now briefly point out that I have so far applied ideas of categorization to communication but it is possible to go in the reverse direction as well. There could be a two-way interaction between the study of category formation and language use. One could apply my model of communication to categorization and, in particular, compare the exemplar and prototype approaches in a domain where these competing ideas have not been compared before, namely their potential to explain the use of vague concepts in communication. This could ground psychological categorization in a broader context of linguistic interaction, which could further our understanding of its social nature. This integration of mathematical models of category formation and a mathematical theory of communication is a contribution to both fields separately as well as to the growing interdisciplinary effort to bridge pure psychological and language-related research.  

Incidentally, this model also provides a basic scaffolding for formulating computational models of vague utterance generation and interpretation that can be applied to building dialogue and conversational agents, question-answering systems, and related areas in artificial intelligence.

I cannot address these matters here but do briefly discuss the generation of conventional word meanings in \partref{part:V}.

\is{psychology|)}\is{vagueness|)}

%A lot of recent research in the evolution of language is concerned with the question how (vague) categories/meanings can arise from repeated linguistic interactions. Strengthening the connection with this strand of research would, in my opinion, further enrich the proposal. 
