\chapter{Defining Communication Games} \label{ch:defining communication games}

%\hfill \begin{minipage}{2.8in}
%
%       \small
%
%
%What we've got here is (a) failure to communicate.
%       
%
%       \setlength{\parindent}{.8em} % this will indent subsequent paragraphs
%
%\vspace{1ex}
%
%       \hfill --- \emph{Cool Hand Luke}
%
%       \end{minipage}
%
%\bigskip



\noindent I start by illustrating the four parts of a Communication Game with a very simple example.

\section{The Setting Game} \label{sec:setting game}

Consider the following situation or setting $u$. Bill Smith, a politician, and Bill Jones, a runner, are acquaintances of $\cal A$ and $\cal B$, who are discussing a local election. This is their implicit, more or less shared goal that both agents are able to extract from the exchange. In such an open-ended conversation, there is a very loosely specified Setting Game, a dialogue with alternating discourses by $\cal A$ and $\cal B$.

\section{The Content Selection Game} \label{sec:content selection game}

The implicit goal and the Setting Game induce $\cal A$ to simply continue the conversation without affecting $\cal B$ in any very specific way or eliciting any very particular response from her. The only reaction he wishes to draw is that she tacitly accept the information he conveys and continue talking. Since there is nothing conflictual here, let us say that she considers just one response $a$, which is to accept the information he conveys and respond to it with her own contribution. More complicated scenarios are not uncommon. $\cal B$ may reject what $\cal A$ says and respond accordingly. But my goal is first to explain the basics of the model.

In such a loosely constrained dialogue game, all that is required is that $\cal A$ and $\cal B$ stick broadly to the topic though even this is not really true as topics in such free-floating conversations are likely to change unpredictably. Given this happy situation, $\cal A$ may want to convey to $\cal B$ that \emph{Bill Smith ran in the election}. Call this content $\sigma$. He may not bother to think about alternative contents, especially as $\sigma$ would be a perfectly fine thing to convey in $u$. This single pair of actions, conveying $\sigma$ and $a$, make the Content Selection Game shown in Figure~\ref{fig:CS} trivial.  

\begin{figure}[h] 
\input{figures/pix5content.tex}
\caption{Content Selection Game for conversation about local politics}
\label{fig:CS}
\end{figure}

The game has a situation $s$ at the start that is represented by a large black node. This situation is a part of $u$ and contains $\cal A$'s intention to evoke the response $a$ by conveying $\sigma$. Sometimes the whole content conveyed is not \emph{explicitly} intended as when someone says ``My weight is 150 lbs.'' and conveys that their weight is 150 lbs. \emph{on earth}. The weight being relative to earth may not have crossed the speaker's mind even in the relevant Content Selection Game let alone in the Generation Game. It is simplest to stipulate that the intention is situated or implicit in such cases. It is important to be aware of such intentions because contrary to what Grice thought and what most of his followers think, all that is conveyed is \emph{not} always explicitly intended, as was pointed out in \sectref{sec:speaker meaning and word meaning}.

The other label for the initial node is $\rho$ and this is just the (prior) probability of that node. It is the probability of $\cal A$'s intention to convey $\sigma$ and evoke $a$ and, derivatively, the probability of $s$. Given its nature, it is generally a shared subjective probability. Since there is just one initial situation $s$, $\rho = 1$, but when there are more initial situations, as happens in more complex settings, there will be multiple prior probabilities between 0 and 1 that sum to 1.

Next, there is an arrow issuing from $s$ that represents $\cal A$'s single choice of action, conveying $\sigma$. This leads to an unnamed intermediate situation from which issues another arrow representing $\cal B$'s single choice of response, the action $a$. Finally, in the unnamed terminal situation, $\cal A$ receives the payoff $v_{\cal A}$ and $\cal B$ receives the payoff $v_{\cal B}$. These payoffs are algebraically represented numbers standing for \emph{utilities}, which are themselves representations of the agents' preferences over the outcomes that are delivered through the terminal situation. Preferences and payoffs are determined in a variety of ways and are based partly on the benefits received, the costs incurred, and possibly other factors such as the other agent's payoffs. The benefits and costs are themselves fixed in many ways, some exogenous depending on the payoffs in the Setting Game and some endogenous depending on the other agent's intention.

As indicated above, it is possible to accommodate $\cal B$'s rejecting rather than accepting the information $\cal A$ conveys. Rejection may be called $a'$. Now there would be two arrows issuing from the intermediate node of Figure~\ref{fig:CS}, one labeled $a$ and the other $a'$, and there would be corresponding payoffs $v'_{\cal A}$, $v'_{\cal B}$ awaiting the players in the new terminal situation. This suggests two possible scenarios. One is that $v_{\cal A} = v'_{\cal A}$, which makes $\cal A$ indifferent to what $\cal B$ chooses. Another is that, based on what $v_{\cal B}$ and $v'_{\cal B}$ are, $\cal A$ might contemplate some alternative content $\sigma'$ if he feels that $\sigma$ may not achieve his desired result based on $v_{\cal A}$ and $v'_{\cal A}$. This leads to a new initial situation $s'$ where $\cal A$'s intention is to convey $\sigma'$. This makes the overall tree structure of the game more complex. I will consider such elaborations later. I note in passing that it is the psychology and sociology of the interaction that result in such complexities in the Content Selection Game and, correspondingly, in different choices of content and utterance and, therefore, in altered communication.

The entire game has been described as a succession of situations,\is{game!situated} first $s$, then the intermediate situation, and then the final situation. This idea can be developed formally and I have done so in my two earlier books. It enables games to be represented as structured sets of situations and thereby in terms of our informational universe as I observed in \sectref{sec:agents}. This reduction suggests a new way to understand games that I call \emph{situated} game theory and allows us to \emph{prove} that such interactive choice situations are \emph{games}. In other words, the construction provides an argument for using games and demonstrates the fit between the model and the facts assuming more basic and self-evident starting points like situations and possibilities for action. 

%I will not dwell much on its formal aspects here but it will be a leitmotif throughout. 

Recall from \sectref{sec:agents} that the agents need to share information about this and other games in order to be able to play them fully. At this stage, however, only $\cal A$ is aware of this game as it is all in his mind and nothing has been communicated yet. He considers the game, identifies his optimal action, and then converts this content into a sentence via the Generation Game that I have yet to describe. It is only after he utters the corresponding sentence and only after $\cal B$ interprets the utterance by playing the Interpretation Game that she becomes aware of the Content Selection Game. Thus, there is a time lag between $\cal A$'s having information about the Content Selection Game and $\cal B$'s having information about it, a factor that matters for the psycholinguistics of communication. Also, $\cal A$ may ponder alternatives that $\cal B$ may never imagine -- and vice versa -- so that their shared information is generally partial. Despite these important qualifications, I will assume the Content Selection Game is common knowledge between $\cal A$ and $\cal B$, as also mentioned in Section~\ref{sec:micro-semantics}. This common knowledge is part of the definition of the game when it is handled formally. In other words, it is not just the theorist who thinks about the game but also the agents, though in our situation the latter do it nonconsciously or semiconsciously. 

%The reason for omitting partial awareness from the model is that it needlessly complicates it and then its main contribution to communication gets obscured.

$\cal A$ now has to identify the optimal content for him to convey. As we saw in \sectref{sec:agents}, this is called \emph{solving} the game. The key idea is that each agent has to take account of what the other agent might do because it is their joint actions that affect their payoffs. In other words, when rational decision-makers interact, their individual decision problems have to be solved together, like a system of equations. In addition to making explicit the details of their interaction in a clear model, this circular process where each agent puts himself or herself in the other agent's shoes and tries to guess what the other agent will do and then chooses his or her best action lies at the heart of game theory.

In our very simple game, the agents do not have any \emph{real} choices; they just convey the one content $\sigma$ and respond with the one action $a$. So, the solution is trivial and $\cal A$ perforce picks $\sigma$ as his equilibrium action. (The action is \emph{conveying} $\sigma$, not $\sigma$, but we can slur over this nicety.) More generally, the agents would have to take account of the payoffs and prior probabilities and compute solutions by evaluating the expected utility of different \emph{strategies}, as explained in \sectref{sec:agents}. 

As I said in \sectref{sec:micro-semantics}, the Content Selection Game is very different from a standard signaling game because it does not contain any physical action for $\cal A$ to perform and because of its linkages with the other parts of  the whole Communication Game. All that it can do is enable $\cal A$ to identify what to convey to $\cal B$ in order to elicit action $a$ from her. This game induces a corresponding Generation Game as a way to achieve this goal. The two games are interdependent because the former relies on the latter for its realization and the latter depends on the former for its existence.


\section{The Generation Game} \label{sec:generation game}

Assuming $\cal A$ wants to convey $\sigma$, he searches for sentences that will do the job in $u$. He may find \Expression{Bill Smith ran in the election} by a kind of direct conversion of $\sigma$ but he may also be cleverer and wonder about \Expression{Bill ran}. The latter involves less physical effort, though it may require a little more mental effort because he has to check if $\cal B$ will be able to fill in the rest by using the context $u$. There are also intermediate possibilities such as \Expression{Bill ran in the election}. 

In practice, he has to construct a sentence from individual words that get identified from bits of partial content. Psycholinguistically speaking, the communication process does not happen with the whole content and the whole utterance being identified in that order, but happens with partial contents and partial utterances and partial interpretations in an ongoing sequential and partly circular process on both sides. This is why the sentences we utter are seldom optimally 
constructed -- their optimization is dynamic and sequential and occurs in chunks. Even when we write, we frequently have to revise our sentences to make them smoother and more graceful. Constructing good sentences is an art and most of us do not ever manage to solve this complex optimization problem fully. This is a consequence of our limited resources and finite rationality, though subjective factors of taste and style also play a role. However imperfect the final result, considerations of efficiency, social norms, and aesthetics guide us in our choices, whether spoken or written.

I'm not sure as yet how the details of this process -- the conversion of bits of content to parts of sentences -- might be modeled, so I will assume the whole content $\sigma$ is identified first through the Content Selection Game and candidate sentences are magically available to $\cal A$ to evaluate in the Generation Game. I will consider \Expression{Bill ran} first -- call it $\varphi$. In order to evaluate $\varphi$, $\cal A$ has to imagine uttering it and examine how $\cal B$ might interpret it given $\cal A$'s information about $u$. $\cal B$'s hypothetical interpretation involves four constraints:

\begin{itemize}
\item Phonetic Constraint
\item Syntactic Constraint
\item Semantic Constraint
\item Flow Constraint
\end{itemize}
All of these operate simultaneously and in a ``circular'' way. A key fact of natural language is pervasive ambiguity in all aspects of content -- phonetics, syntax, and semantics. The basic idea is that, owing to this ambiguity, the Phonetic Constraint generates all the possible words associated with the speech wave corresponding to $\varphi$ in $u$, the Syntactic Constraint generates all the possible parse trees of $\varphi$ in $u$, and the Semantic Constraint generates all the possible meanings associated with $\varphi$ in $u$. The Flow Constraint then disambiguates all these ambiguities simultaneously and identifies the optimal or intended content, that is, the words uttered, their parse, and their meaning. In practice, there are shortcuts which considerably simplify this process.

I will abstract from the first constraint and assume the actual words in the speech wave are immediately available to $\cal B$. In principle, an algebraic system corresponding to the phonetic properties of utterances can be constructed just as we built up $({\cal I}, \odot)$ and $({\cal T}, \star)$ for semantics and syntax. Showing how semantics and syntax work together to determine content is enough to suggest that a phonetic system can also be added to the mix to deliver its part of the content of an utterance because the principles used in this process can be seen to be quite general. The common idea is to generate all the possibilities and then disambiguate them in an interdependent way. It does not matter what the particular possibilities are, whether words associated with the speech wave from the Phonetic Constraint, parses from the Syntactic Constraint, or referential meanings from the Semantic Constraint. It does not even matter how they are generated, which will naturally be different for each of the three Constraints. That is why they are all \emph{contents} of the utterance. Indeed, the method can be extended even to different but related problems such as detecting spam or sentiments in a message, as will be shown in \sectref{sec:cl}. All of these are \emph{classification} problems, sorting inputs (i.e.\ utterances) into separate bins, each set of bins being a different kind of content. Identifying an utterance as spam or its sentiment as positive is just classifying it in terms of more abstract contents. And the interdependence among the three types of contents, phonetic, syntactic, and semantic, also occurs in a uniform way, just through conditioning variables in conditional probabilities, as will be seen presently.

For example, consider an utterance situation with a potentially ambiguous speech wave whose words could be either \Expression{I want to get up late} or \Expression{I want to get a plate}. The Phonetic Constraint would be tasked with generating these two possibilities. Once they are available, they can be added to the Flow Constraint via phonetic games of partial information that interact with similar syntactic and semantic games of partial information in the manner described below. The Flow Constraint disambiguates phonetic, syntactic, and semantic contents in exactly the same way. Once the interdependence between syntactic and semantic games is understood, it will be more or less obvious how phonetic games can be added to the system. 

%I do not discuss the Phonetic Constraint that identifies the possibilities in this book but this ought to be straightforward to do in a manner analogous to the Syntactic and Semantic Constraints.

The traditional way to interpret an utterance is to first obtain its words, then its parse, then its literal meaning, and finally its implied meaning. This pipeline view \is{meaning!pipeline view of} can be abbreviated as phonetics $\functionarrow$ syntax $\functionarrow$ semantics 
$\functionarrow$ pragmatics. In Equilibrium Linguistics, semantics and pragmatics are unified into just one process called semantics, and phonetics, syntax, and semantics codetermine each other. I describe the framework below for syntax and semantics. I first consider just the locutionary part of semantics which corresponds to that part of the meaning that derives directly from the words in an utterance. Illocutionary meaning -- modulation, free enrichment, implicature, and force -- is addressed in \partref{part:IV}. All that is assumed by Equilibrium Linguistics in addition to the (partial) rationality of agents is an ontology, a language, and a grammar for the language, expressed via the three systems $({\cal I}, \odot)$, $({\cal L}, \circ)$, and $({\cal T}, \star)$.

We are now ready to consider how $\cal A$ imagines $\cal B$ interpreting $\varphi$ in $u$ in light of his desire to convey $\sigma$ in $u$. Recall from \sectref{sec:setting game} that in $u$ there are two Bills, Bill Smith the politician and Bill Jones the runner, either of whom could be the potential referents of $\varphi_1 = \Expression{Bill}$ in $u$ since it is ambiguous. It is quite possible that $\cal A$ and $\cal B$ know yet other Bills, so there may be further possibilities but I will ignore these. Likewise, $\varphi_2 = \Expression{ran}$ in $u$ is also ambiguous since it could mean \emph{stood for election} or \emph{competed in a race},\footnote{Throughout, I will mean a certain kind of sporting event when I use ``race.''} two quite different kinds of running. In fact, my dictionary gives over twenty different meanings for the verb \Expression{run} of which the ones corresponding to an election are \emph{be a candidate for, stand for, be a contender for} and the ones corresponding to a race are \emph{compete, take part, participate}. The word \Expression{run} can also be a noun and has over ten different dictionary meanings. At the start, it cannot be known that the word is being used as a verb so all meanings would have to be entertained and the inappropriate ones eliminated via the Flow Constraint. In practice, the full range of theoretical possibilities is not included because agents seldom know all the different meanings a dictionary (i.e.\ the language) can offer. However, at a nonconscious level, it appears that several different meanings do get activated even though we are almost never aware of this.\footnote{See, for example, \citet{os:aladsc} and \citet{kawamoto:ndrla}. I will be saying more about this later. \label{foot:alternative meaning activation}} I will consider just the two meanings related to elections and races. Such facts about semantic ambiguity are captured formally by the Semantic Constraint. Only words have conventional meanings so this is all that is mentioned here. In a similar way, as we saw in Section~\ref{sec:algebraic system of trees}, $\varphi_1 = \Expression{Bill}$ has just one parse $t_1 = [_{\mathrm{NP}} [_{\mathrm{N}}\, \mathrm{Bill}]]$, $\varphi_2 = \Expression{ran}$ also has just one parse $t_2 = [_{\mathrm{VP}}[_{\mathrm{V}}\, \mathrm{ran}]]$, and so does $\varphi = \Expression{Bill ran}$ whose parse is $t_{12} = [_{\mathrm{S}}[_{\mathrm{NP}}\, \mathrm{Bill}][_{\mathrm{VP}}\, \mathrm{ran}]]$. These syntactic facts are captured formally by the Syntactic Constraint.

\subsection{The Syntactic Constraint}

We have already done the work of parsing the words and the sentence in \sectref{sec:algebraic system of trees} so all that is required here is to write down the results.
\begin{align*}
\varphi_1 &= \Expression{Bill} \longrightarrow [_{\mathrm{NP}} [_{\mathrm{N}}\, \mathrm{Bill}]] = t_1\\
\varphi_2 &= \Expression{ran} \longrightarrow [_{\mathrm{VP}}[_{\mathrm{V}}\, \mathrm{ran}]] = t_2\\
\varphi &=   \Expression{Bill ran} \longrightarrow [_{\mathrm{S}}[_{\mathrm{NP}}\, \mathrm{Bill}][_{\mathrm{VP}}\, \mathrm{ran}]] = t_{12}
\end{align*}

The Syntactic Constraint uses the elementary trees in $({\cal T}, \star)$ to derive the possible parses of each word, phrase, and the whole sentence. In this example, there is no syntactic ambiguity so there is just one syntactic content per word and for the whole sentence. I look at situations with syntactic ambiguity in \chapref{ch:syntactic ambiguity}.


\subsection{The Semantic Constraint}

The Semantic Constraint consists of two subconstraints, the Conventional Constraint and the Referential Constraint. The first maps words into their conventional meanings and the second maps each of these conventional meanings into their potential referents relative to $u$.

\ea \Expression{Bill}:\\
\begin{itemize}
\item Referential Use: $\varphi_1 \longrightarrow P^{\varphi_1} \stackrel{u}\longrightarrow \sigma_1$
\item Referential Use: $\varphi_1 \longrightarrow P^{\varphi_1} \stackrel{u}\longrightarrow \sigma'_1$
\end{itemize}
\z

As mentioned in \sectref{sec:information}, properties or relations corresponding to words are written formally as $R^{\omega}$ where $\omega$ is the relevant word. Since $P^{\varphi_1} = P^{\Expression{Bill}}$ is a property, I have used $P$ instead of $R$. It is the conventional meaning of the word \Expression{Bill} and, as I said in footnote~\ref{foot:kripke} in \sectref{sec:macro-semantics}, it is the property \emph{named `Bill'}. This part of the Semantic Constraint is the Conventional Constraint because it provides the map from a word to its conventional meanings.  

The Referential Constraint then maps each conventional meaning into potential referents. The situation $u$ gives rise to two distinct resource situations $r_u$ and $r'_u$, the first containing a \isi{causal chain} originating from Bill Smith and the second from Bill Jones. There are only these two possibilities given the Setting Game. 

This mapping is a bit complicated and I discuss it in \sectref{sec:solving Frege's puzzle} in the context of Frege's puzzle.\ia{Frege, Gottlob@Frege, Gottlob} For now, to keep things simple, just note that these two Bills are obtained via $e(P^{\varphi_1}, r_u) = \hbox{\emph{Bill Smith}}$ and $e(P^{\varphi_1}, r'_u) = \hbox{\emph{Bill Jones}}$ based on the definition of $e(P, s)$ on page~\pageref{page:e(P,s)} in \sectref{sec:information}. The first possibility is $\sigma_1 = b = \emph{Bill Smith}$ as mentioned on page~\pageref{page:Bill} and the second possibility is $\sigma'_1 = b' = \emph{Bill Jones}$. I will assume the two individuals $\sigma_1 = b$ and $\sigma'_1 = b'$ are given to us directly and return to how names work in more detail in the very last chapter where I discuss the \Expression{Hesperus is Phosphorus} example from \sectref{sec:classic example}. 

The symbol $u$ on top of the second arrow above is required to constrain the possibilities by the information in $u$. It is because of $u$ that \Expression{Bill} gets mapped into Bill Smith or Bill Jones and not any of the other countless Bills that doubtless abound. On the other hand, the first arrow in each case does \emph{not} have a $u$ on top of it because words acquire conventional meanings through communication as discussed in \sectref{sec:macro-semantics} and then, until a change in meaning occurs, they remain attached to the words independent of context.

Both uses of \Expression{Bill} are of the same kind and are called referential. There are other ways of using names, most commonly attributively but also generically and predicatively, just as with descriptions.\footnote{See \citet[Chapter~6]{parikh:le} for more details. For example, the name \Expression{January} in an appropriate use of the sentence \Expression{January has 31 days} may be used generically.}

\noindent\parbox{\textwidth}{\ea \Expression{ran}:\\
\begin{itemize}
\item Predicative Use: $\varphi_2 \longrightarrow P^{\varphi_2}_1 \stackrel{u}\longrightarrow \soa{P^{\varphi_2}_1} = \sigma_2$
\item Predicative Use: $\varphi_2 \longrightarrow P^{\varphi_2}_2 \stackrel{u}\longrightarrow \soa{P^{\varphi_2}_2} = \sigma'_2$
\end{itemize}
\z}

These predicative uses of \Expression{ran} involve two distinct conventional meanings as noted above and each is mapped into itself by the Referential Constraint. Specifically, $\soa{P^{\varphi_2}_1} = \sigma_2$ is the meaning \emph{stood for election} and $\soa{P^{\varphi_2}_2} = \sigma'_2$ is the meaning \emph{competed in a race}. Despite the Referential Map's being an identity map,  we write $P^{\varphi_2}_1$ $\longrightarrow$\hspace{-1.1em}\raisebox{1ex}{\scriptsize $u$}\hspace{.55em} $\soa{P^{\varphi_2}_1}$ instead of writing $P^{\varphi_2}_1$ $\longrightarrow$\hspace{-1.1em}\raisebox{1ex}{\scriptsize $u$}\hspace{.55em} $P^{\varphi_2}_1$ as the angled brackets serve to emphasize that a potential referent of \Expression{ran} is an infon, which in this case is just the property $P^{\varphi_2}_1$ written as $\soa{P^{\varphi_2}_1}$. I also use the term ``referent'' much more broadly: in Equilibrium Semantics, every word more or less \emph{refers} to its content via the Conventional and Referential Maps and so do speakers.\is{reference}

Notice that the word \Expression{ran} actually contains two bits of information: the possible referents of the verb \Expression{to run} and the time of running, some time prior to the time of utterance. In other words, strictly speaking, \Expression{ran} should generate the two possibilities $\sigma_2$ and $\sigma'_2$ as well as temporal infons $\sigma_3$ and $\sigma'_3$ (or continuous ranges of temporal infons). Indeed, if it is known to the interlocutors when the election under discussion took place, then this time can be more precisely fixed than simply being some interval in the past. I will ignore these complexities, both how a single word might generate two distinct sets of possibilities and how temporal possibilities might be narrowed by taking contextual information into account. They do not pose insuperable obstacles but do complicate the framework and my purpose is to delineate just the basic ideas. For that reason, I will drop $\sigma_3$ and $\sigma'_3$ and work just with the infons identified above.\footnote{The details involve conditioned infons dealt with in \citet{parikh:le}. Essentially, $\sigma_3$ and $\sigma'_3$ condition $\sigma_2$ and $\sigma'_2$ respectively.}

Thus, the Semantic Constraint, based on its two component constraints, provides the \emph{possible} referents of each word in the utterance. Larger units, such as phrases and the whole sentence, do not have conventional meanings. Their possible referents are derived by multiplication of the partial infons $\sigma_1$, $\sigma'_1$ and $\sigma_2$, $\sigma'_2$ via the unification operation $\odot$ as will become clear shortly.

Equilibrium Linguistics treats all values, whether syntactic, semantic, or phonetic, as \emph{contents} and treats them uniformly. The outcome of the three constraints is to produce the possible corresponding contents for each relevant part of the utterance.


\subsection{The Flow Constraint}

It is helpful to keep the coordination game in Figure~\ref{fig:coordination game G in normal form} in mind for this section.

The Flow Constraint \emph{disambiguates} among the possible contents thrown up by the Phonetic, Syntactic, and Semantic Constraints. There are four lexical games of which two are syntactic and two are semantic, corresponding to the two words in $\varphi$. (If we had included the Phonetic Constraint, there would also have been phonetic games except that, in this case, it is the lexical items that have to be determined from the speech wave.) It is convenient to start with the semantic games as these are more likely to be familiar. Recall that in the Generation Game $\cal A$ is trying to imagine how $\cal B$ might interpret an utterance of $\varphi$ in $u$. Figure~\ref{fig:semantic lexical game g1} shows the first semantic game of partial information he constructs in order to do this.

\begin{figure}[h] 
\input{figures/pix4varphi1algebraictruncated.tex}
\caption{Semantic lexical game $g_1$}
\label{fig:semantic lexical game g1}
\end{figure}

This game should not be confused with the Content Selection Game in Figure~\ref{fig:CS}, although there are superficial similarities because both structures involve communication. In the latter game, $\cal A$'s choice concerns the content $\sigma$ and $\cal B$'s choice concerns her response $a$. In the present game, based on the Content Selection Game, $\cal A$'s choice involves a hypothetical utterance of $\varphi_1$, the first word of the whole utterance $\varphi$, and $\cal B$'s move involves her possible interpretations of this word uttered in $u$. In terms of complexity, $g_1$ is slightly more complex than the game in Figure~\ref{fig:CS} as there are now two initial situations $s_1$ and $s_{1'}$ instead of just one. (Note that the prime is on the $1$ and not on the $s$. The reason for this will become clear presently.) Each initial situation is part of the utterance situation and includes an appropriate intention to convey some content. Recall from \sectref{sec:content selection game} that this intention may be implicit.

In $s_1$ in Figure~\ref{fig:semantic lexical game g1}, the speaker is assumed to be conveying $\sigma_1$, \emph{Bill Smith}, although because his action of uttering $\varphi_1 = \Expression{Bill}$ is semantically ambiguous between $\sigma_1$ and $\sigma'_1$, the addressee could potentially interpret the word as referring to $\sigma'_1$, \emph{Bill Jones}, as well. This choice is represented by two branches labeled $\sigma_1$ and $\sigma'_1$ emanating from the upper intermediate situation inside the elongated oval. That is, if $\cal A$ utters $\varphi_1$ in $s_1$, the resulting situation, the upper intermediate node inside the oval, offers $\cal B$ two choices of interpretation $\sigma_1$ and $\sigma'_1$. In the terminal situations that result from each choice, the payoffs for the two agents are $a_{\cal A}$ and $a_{\cal B}$ for making the right choice $\sigma_1$ as this is what $\cal A$ is conveying in $s_1$, and they are $c_{\cal A}$ and $c_{\cal B}$ for making the wrong choice $\sigma'_1$ as this is not what $\cal A$ is conveying in $s_1$. The $a$ payoffs are therefore greater than the corresponding $c$ payoffs as they represent the correct interpretation by $\cal B$. \label{page:payoff comparisons} 

%These payoffs are utilities as discussed earlier.

In $s_{1'}$ in the lower half of $g_1$, a similar choice presents itself to the addressee but this time the payoffs are reversed, because in this situation $\cal A$ would be conveying the other possible meaning $\sigma'_1$. Again, the primed $a$ payoffs are greater than the corresponding primed $c$ payoffs.

As we saw in \sectref{sec:agents}, the oval enclosing the two intermediate nodes is an \emph{information set}.\is{information set} It represents $\cal B$'s inability to distinguish between them as she has seen the same utterance $\varphi_1$ in both cases and cannot know if the originating situation was $s_{1}$ or $s_{1'}$ (since what $\cal A$ is conveying is not antecedently available to $\cal B$). So she is constrained to make the same choice in both situations: either she must choose $\sigma_1$ in both or $\sigma'_1$ in both. If the oval were not there, she could make different choices in the top half and the bottom half of the game tree. This constrains the possible solutions of the game. Depending on the other features present, such games are called games of \emph{imperfect}, \emph{incomplete}, or \emph{partial} information.\is{game!imperfect information}\is{game!incomplete information}\is{game!partial information} In this case, this is a game of partial information for reasons given below.

The symbol $\rho_1$ represents the prior conditional probability that $\cal A$ is conveying $\sigma_1$ \emph{given} that he is conveying the other meanings and parse trees of the rest of the sentence in the utterance situation $u$.\footnote{In retrospect, this idea could be seen as a generalization of the concept of selection restrictions, which are the semantic restrictions a word imposes on the environment in which it occurs. See \citet{chomsky:ats}. For example, a verb like ``eat'' generally requires that its subject refers to an animate entity and its object to something concrete. A violation of the selectional restrictions of a word results in an anomaly: in ``the mountain eats sincerity'' both restrictions are violated, rendering the sentence anomalous. Such restrictions are often not absolute as there are uses of ``eat'' such as ``the meeting ate up a lot of time,'' an example I owe to Tom Wasow.\ia{Wasow, Thomas} The question whether selectional restrictions\is{selectional restrictions} should be treated in syntax or semantics, or even outside grammar, as a matter of knowledge of the world, has been a point of debate. My idea for the prior probabilities was developed independently of this notion and it occurs entirely outside grammar.} In other words, $\rho_1 = P(\sigma_1 \cond x_2, y_1, y_2; u)$ where the $x_2$ is a variable ranging across the possible corresponding meanings $\sigma_2$, $\sigma'_2$, and the $y_1$, $y_2$ are variables standing for the possible corresponding parse trees $t_1$, $t_2$, respectively.\footnote{There is no syntactic ambiguity in this example and so $y_1$ just stands for $t_1$ and $y_2$ for $t_2$. If there had been other alternative parses, for example, some tree $t'_1$ as a possible parse of $\varphi_1$, then $y_1$ would have ranged over both $t_1$ and $t'_1$ just as $x_2$ ranges over $\sigma_2$ and $\sigma'_2$. Likewise with $y_2$. I will consider such an example in \chapref{ch:syntactic ambiguity}.} I have omitted writing other conditioning variables involving phrasal and sentential meanings and parse trees such as $x_{12} = x_1 \odot x_2$ and $y_{12} = y_1 \star y_2$ as their influence occurs through the corresponding component lexical items anyway. The situation $u$ is \emph{not} a random variable but a parameter that is held fixed. This notation is a slight abbreviation for the actual probability which is a conditional probability of a \emph{speaker's conveying a content} \label{page:intention} rather than just the conditional probability of a content per se. This is a very important difference because a speaker could be likely conveying a rare content and it is the former likelihood that matters. Note that $\rho_1$ is actually a \emph{function} of the conditioning variables and parameter $u$ and not a constant. 

Likewise, the other prior probability $\rho_{1'} = P(\sigma'_1 \cond x_2, y_1, y_2; u)$ and we must have $\rho_1 + \rho_{1'} = 1$ as there are only two possible meanings the speaker could be conveying. Since $\rho_{1'}$ is also a function of the conditioning variables and parameter $u$, there are different \emph{versions} of essentially the same game $g_1$ when $x_2$, $y_1$, or $y_2$ take on different values. These versions differ only in the numerical values of the prior conditioned probabilities; in all other respects, they are identical. Thus, for example, when $x_2 = \sigma_2$ the values of $\rho_{1}$ and $\rho_{1'}$ may be 5/6 and 1/6 and when $x_2 = \sigma'_2$ the values of $\rho_{1}$ and $\rho_{1'}$ may be 1/4 and 3/4. $g_1$ has just two versions. One reason why it is a game of partial information and not a game of incomplete information (or a signaling game, one kind of game of incomplete information) is that the prior probabilities are not fixed in advance.\is{game!incomplete information}\is{game!signaling}

If I had worked out how the Phonetic Constraint generates its possible contents, that is, the possible words in the speech wave, then these possibilities would just have been added to the conditioning variables just as the syntactic possibilities are. That is all the interdependence among phonetic, syntactic, and semantic contents consists in. So, in principle, it is easy to add phonetic contents into the mix once the details of the Phonetic Constraint are spelled out. I have done this for both the Syntactic and Semantic Constraints so augmenting the system with phonetic contents is a natural extension. There is a slight complication because in semantic and syntactic games one is interpreting words via meanings and parses and in phonetic games one is interpreting a speech wave via words, but this does not pose any insuperable technical problems.

Returning to Figure~\ref{fig:semantic lexical game g1}, $\cal A$ knows what his intention is and so he knows the real situation is $s_1$ and not $s_{1'}$. But because $\cal B$ does not know $\cal A$'s actual intention in advance -- as represented by the information set -- $\cal A$ realizes that $\cal B$ might think the real situation was $s_{1'}$. So $\cal A$ has to consider this counterfactual situation $s_{1'}$ as well. He has to portray the interaction as $\cal B$ would see it and, therefore, as both should see it. The prior probabilities indicate $\cal A$'s view of what chances $\cal B$ would assign to the two situations. But these chances depend on various conditioning variables which gives rise to different versions of the game. Which version to play is a further decision each agent has to make. That is, the speaker has to choose not just what to utter but also the probability distribution $(\rho_1, \rho_{1'})$ by specifying the values of the conditioning variables -- in this case, just whether $x_2 = \sigma_2$ or $x_2 = \sigma'_2$ since the variables $y_i$ can take on just one value each. Likewise, the addressee also has to choose not just an interpretation but also the probability distribution. Expressed concretely, both agents have to choose between the pair $\rho_1 = P(\sigma_1 \cond \sigma_2, t_1, t_2; u)$, $\rho_{1'} = P(\sigma'_1 \cond \sigma_2, t_1, t_2; u)$ and the pair $\rho_1 = P(\sigma_1 \cond \sigma'_2, t_1, t_2; u)$, $\rho_{1'} = P(\sigma'_1 \cond \sigma'_2, t_1, t_2; u)$. (I use the same symbols $\rho_1$, $\rho_{1'}$ for both pairs only to avoid having to specify the arguments of the functions these symbols really represent.) 

Now, $P(\sigma_1 \cond \sigma_2, t_1, t_2; u) > P(\sigma'_1 \cond \sigma_2, t_1, t_2; u)$ \label{page:probability comparisons} because $\sigma_2$ is compatible with $\sigma_1$ as Bill Smith, the politician, is more likely to be running in an election than Bill Jones, the runner. This is also reinforced by $u$ as the topic of conversation is the local election as mentioned in \sectref{sec:setting game}. In other words, the agents' common goal is to discuss the local election. On the other hand, $P(\sigma_1 \cond \sigma'_2, t_1, t_2; u) < P(\sigma'_1 \cond \sigma'_2, t_1, t_2; u)$ because now $\sigma'_2$ and $\sigma_1$ are incompatible as one involves running in a race and the other involves Bill Smith whereas $\sigma'_2$ and $\sigma'_1$ are compatible because Bill Jones is a runner. This is so despite the presence of $u$ which might bolster the former probability because incompatible meanings are much worse than an irrelevant remark. The parse trees $t_1$ and $t_2$ do not play any role as they are unique. Taking the earlier numerical values, both players have to choose between $(\rho_1, \rho_{1'}) = (5/6,1/6)$ and $(\rho_1, \rho_{1'}) = (1/4,3/4)$. These numbers are determined by a variety of objective and subjective factors that are exogenous but the choice between them is endogenous.

This semantic lexical game $g_1$ is obtained by applying the semantic game map $g_u$ to the word $\varphi_1$. That is, $g_u(\varphi_1) = g_1$. It is possible to construct $g_1$ entirely from the assumption that $\cal A$ is trying to imagine how $\cal B$ might interpret his uttering $\varphi_1$ as part of $\varphi$ in $u$, from the Semantic Constraint which provides its possible interpretations, from his intention to convey one or the other meaning which sets the payoffs to higher or lower values based on whether $\cal B$'s interpretation gets it right or not, and from internally determined inequalities among the partly objective and partly subjective probabilities such as $P(\sigma_1 \cond \sigma_2, t_1, t_2; u) > P(\sigma'_1 \cond \sigma_2, t_1, t_2; u)$. The map $g_u$ is available to $\cal A$ without any additional assumptions and all he has to do is apply it to $\varphi_1$.

I reiterate that $g_1$ has been entertained only in $\cal A$'s head so far. $\cal B$ has as yet no idea what is brewing in $\cal A$'s mind. Later, when $\cal A$ identifies an optimal utterance and utters it, $\cal B$ will construct a very similar game by applying a similar map $g_u$ to the utterance she hears. These games constructed by the two interlocutors may or may not be identical and when they are identical they may or may not have common knowledge of it. To mark the possibility that these games may diverge, I label them $g^{\cal A}_u(\varphi_1) = g^{\cal A}_1$ and $g^{\cal B}_u(\varphi_1) = g^{\cal B}_1$, the first called a speaker game and the second called an addressee game as mentioned in \sectref{sec:micro-semantics}. I should clarify that the prior probabilities in $g^{\cal A}_1$ represent $\cal A$'s view of $\cal B$'s assignments whereas in $g^{\cal B}_1$ they represent $\cal B$'s own assignments. To avoid unnecessary encumbrances, I will just drop the superscripts and leave the disambiguation to the context. When I need to discuss them both together, I will reintroduce the labels.

As an aside, I mention that a reader may wonder how a speaker's private intention which is part of $s_{1}$ or $s_{1'}$ can ever become common knowledge. This can happen because both share the word that has been uttered and they share the two possible interpretations of the word because they share the Semantic Constraint. This leads them to share the same game tree with $s_{1}$ and $s_{1'}$ as its initial situations as just explained. And the addressee would know that in $s_{1}$ the speaker must be intending to convey the first interpretation and in $s_{1'}$ the second. That is, she is confronted with two possibilities and she can infer that in the first there must be a certain intention and in the second there must be a different corresponding intention. The same question could arise with seemingly private preferences. As explained above, both agents would come to have the common knowledge that the $a$ payoffs are greater than the $c$ payoffs because the former represent the correct interpretation and the latter the incorrect interpretation.

Clearly, then, $g_1$ presents a choice situation for both agents to consider, as yet only in $\cal A$'s thought. While he does not have any choice of utterance -- he has to utter $\varphi_1$ -- he does have a choice of probability distribution. This choice depends on the optimal interpretation determined for $\varphi_2$, $\sigma_2$ or $\sigma'_2$, because $\cal A$ will want his choice to be compatible with this interpretation. Otherwise, he may choose one value and therefore one version of the game and $\cal B$ may choose another and, besides, the interpretations chosen for the parts of the whole utterance may not hang together. As the reader may anticipate, there will be a corresponding semantic lexical game $g_u(\varphi_2) = g_2$ that involves precisely a choice for $\cal B$ between $\sigma_2$ and $\sigma'_2$. So, the right solution for $g_1$ depends on the solution to $g_2$. But, as will be seen presently, the right solution for $g_2$ depends on the solution to $g_1$. In the same way, there will also be corresponding syntactic games $g'_u(\varphi_1) = g'_1$ and $g'_u(\varphi_2) = g'_2$ which involve just a trivial choice of trees $t_1$ and $t_2$ as these are the only possible parses of $\varphi_1$ and $\varphi_2$. In general, their solution will also influence the solution to $g_1$ and vice versa. Just as $\cal A$'s only real choice is between two prior probability distributions, so $\cal B$ has a choice of interpretation between $\sigma_1$ and $\sigma'_1$ and also a choice between the same two probability distributions. She will also want to make her choice of distribution compatible with $\cal A$'s and with her own choice of interpretation in $g_2$ as just observed.

\begin{figure}[h] 
\input{figures/pix5varphi1algebraictrees.tex}
\caption{Syntactic lexical game $g'_1$}
\label{fig:syntactic lexical game g1'}
\end{figure}

The syntactic lexical game $g'_1$ is shown in Figure~\ref{fig:syntactic lexical game g1'}. In it, the only initial situation is $s'_1$. This corresponds to the initial situations $s_1$ and $s_{1'}$ in Figure~\ref{fig:semantic lexical game g1}. If there had been an ambiguity in the parse of $\varphi_1$, say another tree $t'_1$, there would have been a second initial situation $s'_{1'}$ in Figure~\ref{fig:syntactic lexical game g1'}. Notice where the primes are placed, whether on the symbol $s$ itself or on the subscript $1$ or both. The prime on the symbol corresponds to the syntactic game and the prime on the subscript determines whether it is an alternative initial situation in the relevant game, semantic or syntactic.

In this game, there is no intention to convey the parse $t_1$ in $s'_1$ as there was in the previous game $g_1$. In semantic games, there is an intention whether explicit or implicit. In syntactic games, neither the speaker nor the addressee are likely to be aware of the parse of the corresponding word or expression. All that happens is the initial situation is a part of the utterance situation $u$ which includes a fact that the relevant parse tree is being transmitted or conveyed, just like a transfer of information from one hard disk to another.

The rest of the diagram should be straightforward to read. $\cal A$ has just the one choice of utterance $\varphi_1$ and $\cal B$ has just one choice of syntactic interpretation $t_1$. The payoffs received are the same as before because the interpretation is obviously correct with respect to what is being transmitted in $s'_1$.

The prior probability $\rho'_1 = P(t_1 \cond x_1, x_2, y_2; u)$ where the $x_1$ is either $\sigma_1$ or $\sigma'_1$, $x_2$ is either $\sigma_2$ or $\sigma'_2$ as before, and $y_2$ is just $t_2$ as there is no other parse tree corresponding to $\varphi_2$. It is also influenced by the parameter $u$. Since there is just one alternative $t_1$ in this game, $\rho'_1 = P(t_1 \cond x_1, x_2, y_2; u) = 1$ independent of what values the conditioning variables adopt.

This syntactic lexical game $g'_1$ is obtained by applying the syntactic game map $g'_u$ to the word $\varphi_1$. That is, $g'_u(\varphi_1) = g'_1$. Unlike the case of the semantic game $g_1$, $g'_1$ is constructed entirely nonconsciously or subpersonally by $\cal A$. This is also often true for semantic games but in those instances there may be a kind of semiconsciousness present. The syntactic game $g'_1$ uses the parsing alternatives provided by the Syntactic Constraint and other information analogous to the information used in constructing $g_1$. That is, the map $g'_u$ is available to $\cal A$ just as $g_u$ was and all that is required is for $\cal A$ to apply it to $\varphi_1$.

This game also presents a choice situation for both agents, as yet only in $\cal A$'s head. All the choices on both sides -- the utterance and the prior probability on the speaker's side and the interpretation and the prior probability on the addressee's side -- are trivial. So, the solution to this game is also trivial but it still does depend in an otiose way on the values of the conditioning variables $x_1$, $x_2$, and $y_2$ and so on the solutions to those games just as the solutions to those games depend on the solution to $g'_1$.

Now, we move to the next set of lexical games for the second word $\varphi_2 = \Expression{ran}$ shown in Figure~\ref{fig:semantic lexical game g2} and Figure~\ref{fig:syntactic lexical game g2'}. These diagrams should be relatively straightforward to understand.

\begin{figure}[h] 
\input{figures/Ch7pix4varphi2algebraic.tex}
\caption{Semantic lexical game $g_2$}
\label{fig:semantic lexical game g2}
\end{figure}

\begin{figure}[h] 
\input{figures/pix5varphi2algebraictrees.tex}
\caption{Syntactic lexical game $g'_2$}
\label{fig:syntactic lexical game g2'}
\end{figure}

In $s_2$ in Figure~\ref{fig:semantic lexical game g2}, the speaker is conveying $\sigma_2$, although because $\varphi_2$ is semantically ambiguous, the addressee could potentially interpret the word as conveying $\sigma'_2$ as well. This choice is represented by two branches labeled $\sigma_2$ and $\sigma'_2$ emanating from the upper intermediate situation in the oval. The payoffs follow the same pattern as in $g_1$. In $s_{2'}$ in the lower half of the same game, a similar choice presents itself to the addressee but this time the payoffs are reversed because in this hypothetical situation $\cal A$ is conveying the other possible meaning $\sigma'_2$. Again, the primed $a$ payoffs are greater than the corresponding primed $c$ payoffs.

The prior probabilities for $g_2$ are $\rho_2 = P(\sigma_2 \cond x_1, y_1, y_2; u)$ and $\rho_{2'} = P(\sigma'_2 \cond x_1,\allowbreak y_1,\allowbreak y_2; u)$ and these must sum to 1 as there are only two possible meanings the speaker could be conveying. Since these probabilities are also functions of the conditioning variables and parameter $u$, there are different \emph{versions} of essentially the same game $g_2$ when $x_1$ takes on different values as $y_1$ and $y_2$ are just $t_1$ and $t_2$ and $u$ is held fixed.

As I said above with $g_1$, $P(\sigma_2 \cond \sigma_1, t_1, t_2; u) > P(\sigma'_2 \cond \sigma_1, t_1, t_2; u)$ because the presence of $\sigma_1$ is compatible with $\sigma_2$ as Bill Smith is more likely to be running in an election than running in a race. This is also reinforced by $u$ as the topic or goal of conversation is the local election. On the other hand, $P(\sigma_2 \cond \sigma'_1, t_1, t_2; u) < P(\sigma'_2 \cond \sigma'_1, t_1, t_2; u)$ because now $\sigma_2$ and $\sigma'_1$ are incompatible as one involves running in an election and the other involves Bill Jones whereas $\sigma'_2$ and $\sigma'_1$ are compatible because Bill Jones is, in fact, a runner. This is so despite the presence of $u$ which might bolster the former probability because incompatible meanings are much worse than an irrelevant statement. Once again, the parse trees do not play any role except to confirm all the probabilities as they are unique. If we assume the same numerical values as before, both players could be choosing between $(\rho_2, \rho_{2'}) = (5/6,1/6)$, one version of $g_2$, and $(\rho_2, \rho_{2'}) = (1/4,3/4)$, another version of $g_2$. Again, the actual numbers themselves are determined by a variety of objective and subjective factors that are exogenous but the choice between them is endogenous.

The same kinds of choices and payoffs occur in Figure~\ref{fig:syntactic lexical game g2'} except that this time a trivial syntactic ambiguity has to be ``resolved'' as in $g'_1$. This time the only prior conditional probability is $\rho'_2 = P(t_2 \cond x_1, x_2, y_1; u) = 1$ as before.

The games $g_2$ and $g'_2$ are obtained by applying the same semantic and syntactic maps $g_u$ and $g'_u$ to $\varphi_2$. That is, $g_u(\varphi_2) = g_2$ and $g'_u(\varphi_2) = g'_2$. Again, as argued above, both maps are available to $\cal A$ and so the relevant games can be constructed without any further assumptions.

This completes the discussion of semantic and syntactic lexical games as constructed nonconsciously by $\cal A$. There are two semantic games and two syntactic games, each corresponding to the utterance of $\varphi_1$ or $\varphi_2$ in $u$. Moreover, as I have shown in detail, the games are \emph{interdependent} because the solution to each of them depends on the solutions to the others via the prior probabilities which are conditioned by these solutions. In this example, the syntactic games were trivial and solvable immediately and so their dependence on other games was redundant. Later in \chapref{ch:syntactic ambiguity}, I will look at a more complex example with syntactic ambiguities as well. Because in general one cannot know which version of a semantic or syntactic game is going to be optimal without solving all the other lexical games, they have to be solved together. In this sense, these interlocking games are circular not only because each individual game involves an interdependence between speaker and addressee but also because no game can be solved without solving all the games simultaneously. 

The next step is to consider the \emph{products} of these lexical games to form phrasal and sentential games. In the very simple two-word sentence at hand, there are no phrasal games because we get the sentential games at once. I show the semantic sentential game $g_{12} = g_1 \otimes g_2$ in Figure~\ref{fig:semantic sentential game g12}.

\begin{figure}[p] 
\input{figures/pixproduct12varphi1varphi2.tex}
\caption{Semantic sentential game $g_{12} = g_1 \otimes g_2$}
\label{fig:semantic sentential game g12}
\end{figure}

There are several new things in this game product. First, the tree diagram is a ``product'' of the trees of $g_1$ and $g_2$.\footnote{This game tree product is, of course, different from the parse tree product described in \sectref{sec:algebraic system of trees}.} Next, there are four initial situations $s_{12} = s_1 \cup s_2$, $s_{12'} = s_1 \cup s_{2'}$, $s_{1'2} = s_{1'} \cup s_{2}$, and $s_{1'2'} = s_{1'} \cup s_{2'}$. The latter situations $s_1$, $s_{1'}$, and $s_2$, $s_{2'}$ are the initial situations of the two semantic games $g_1$ and $g_2$ that are being multiplied. That is, the initial situations of the product are derived from the initial situations of the multiplicands as they should be and 2 x 2 = 4 such combinations are possible from the two initial situations of $g_1$ and the two initial situations of $g_2$.

I have abbreviated the sentence $\varphi = \varphi_1 \circ \varphi_2$ as $\varphi_1\varphi_2$ and the products $\sigma_1 \odot \sigma_2$, $\sigma_1 \odot \sigma'_2$, $\sigma'_1 \odot \sigma_2$, and $\sigma'_1 \odot \sigma'_2$ as $\sigma_1\sigma_2$, $\sigma_1\sigma'_2$, $\sigma'_1\sigma_2$, and $\sigma'_1\sigma'_2$, respectively. The speaker's single choice of utterance $\varphi_1\varphi_2$ is a concatenation of the individual utterances $\varphi_1$ and $\varphi_2$ from $g_1$ and $g_2$. And the addressee's possible interpretations are $\sigma_1\sigma_2$, $\sigma_1\sigma'_2$, $\sigma'_1\sigma_2$, and $\sigma'_1\sigma'_2$, where again the components are obtained from the respective games. The payoffs corresponding to the relevant branches in the multiplicands are added to give the payoffs in the relevant branch of the product. For example, the payoff for $\cal A$ in the topmost branch corresponding to the path $s_{12}$, $\varphi_1\varphi_2$, $\sigma_1\sigma_2$ is $a_{\cal A} + a_{\cal A}$, which is the sum of the $a_{\cal A}$ in $g_1$ corresponding to the path $s_1$, $\varphi_1$, $\sigma_1$ and the $a_{\cal A}$ in $g_2$ corresponding to the path $s_2$, $\varphi_2$, $\sigma_2$.

Finally, the four priors are $\rho_{12} = P(\sigma_1, \sigma_2 \cond y_1, y_ 2; u)$, $\rho_{12'} = P(\sigma_1, \sigma'_2 \cond y_1, y_2; u)$, $\rho_{1'2} = P(\sigma'_1, \sigma_2 \cond y_1, y_2; u)$, and $\rho_{1'2'} = P(\sigma'_1, \sigma'_2 \cond y_1, y_2; u)$  which must sum to 1 as they represent all the alternatives. Again, it should be easy to see how these probabilities are generated from the corresponding probabilities in the multiplicands $g_1$ and $g_2$ where the priors are $\rho_1 = P(\sigma_1 \cond x_2, y_1, y_2; u)$, $\rho_{1'} = P(\sigma'_1 \cond x_2, y_1, y_2; u)$  and $\rho_2 = P(\sigma_2 \cond x_1, y_1, y_2; u)$, $\rho_{2'} = P(\sigma'_2 \cond x_1, y_1, y_2; u)$. It is clear that $\rho_{12} > \rho_{1'2'}$ because both are conditioned by $t_1$, $t_2$, and $u$ and because $u$ is about the local election it pushes up the former and pushes down the latter. The parse trees $t_1$ and $t_2$ are both unique and play no role. The ``cross'' probabilities $\rho_{12'}$ and $\rho_{1'2}$ are both very much lower than the other two because they represent incompatible interpretations, either Bill Smith the politician running in a race or Bill Jones the runner running in an election. So $\rho_{12}$ is the highest among these four prior probabilities. A possible set of values could be $(\rho_{12}, \rho_{12'}, \rho_{1'2}, \rho_{1'2'}) = (0.5, 0.1, 0.1, 0.3)$. I will presently be showing how all these games are to be solved but I point out here that the prior probabilities play a key role.

The product game $g_{12} = g_1 \otimes g_2$ can also be obtained directly by applying the semantic map $g_u$ to the sentence $\varphi_1 \circ \varphi_2$. When this is done, it becomes evident that $g_{12} \equiv g_u(\varphi_1 \circ \varphi_2) = g_u(\varphi_1) \otimes g_u(\varphi_2) \equiv g_1 \otimes g_2$.

The syntactic sentential game $g'_{12} = g'_1 \otimes g'_2$ is shown in Figure~\ref{fig:syntactic sentential game g12'}.

\begin{figure}[h] 
\input{figures/pix5varphi1varphi2algebraictrees.tex}
\caption{Syntactic sentential game $g'_{12} = g'_1 \otimes g'_2$}
\label{fig:syntactic sentential game g12'}
\end{figure}

Each multiplicand has just one initial situation $s'_1$ or $s'_2$ and so there is just $1 = 1 \times 1$ initial situation $s'_{12} = s'_1 \cup s'_2$ in the product. The interpretation $t_1t_2 = t_1 \star t_2 = t_{12}$ as shown earlier. The payoffs are the sum of the corresponding payoffs in the component games as before. The prior probability $\rho'_{12} = P(t_1, t_2 \cond x_1, x_ 2; u) = 1$ as the reader should now be able to work out. This is a trivial game and even though the prior probability is conditioned by other variables that take on different values depending on the optimal solution to the semantic games $g_1$, $g_2$, and $g_{12}$, it is always just 1 so the game is solvable immediately. As with the semantic sentential game, this syntactic product can be obtained directly by applying the syntactic map $g'_u$ to $\varphi_1 \circ \varphi_2$ and so we have $g'_{12} \equiv g'_u(\varphi_1 \circ \varphi_2) = g'_u(\varphi_1) \otimes' g'_u(\varphi_2) \equiv g'_1 \otimes' g'_2$.

This is the Flow Constraint from the speaker's viewpoint. Recall that all the interlocking games constructed so far -- $g_1$, $g_2$, $g_{12}$ on the semantic side and $g'_1$, $g'_2$, $g'_{12}$ on the syntactic side -- actually carry a superscript $\cal A$ to mark this viewpoint. These are the games generated by the speaker when he considers the sentence $\varphi = \varphi_1\varphi_2 = \Expression{Bill ran}$ as a possible thing to utter in order to convey $\sigma_1\sigma_2 = \emph{Bill Smith stood (for election)}$ to $\cal B$ and thereby get across the whole content $\sigma = \emph{Bill Smith ran in the local election}$ in order to evoke the response $a$, acceptance, by $\cal B$. This content $\sigma_1\sigma_2$, if indeed it is the content of an utterance of $\varphi$ in $u$, something I have yet to show, would be called the \emph{locutionary meaning} of the utterance because it comes directly from the words uttered in the situation $u$. As I have said before, the sentence $\varphi$ has no meaning without a context and does not have a conventional meaning at all. As the Semantic Constraint makes clear, only words have conventional meanings and they, together with the situation $u$, yield the locutionary meaning and, indeed, also the illocutionary meaning of the utterance which is the meaning that comes largely from the context $u$ and only indirectly from the words uttered. This latter meaning, which includes things like free enrichment, modulation, figures of speech, implicature, and illocutionary force, will be addressed in \partref{part:IV}.

I will postpone showing how these six locutionary games are solved because I first want to develop the complete model of locutionary communication. For the moment, just assume that their joint solution is in fact $\sigma_1\sigma_2$ rather than $\sigma_1\sigma'_2$, $\sigma'_1\sigma_2$, or $\sigma'_1\sigma'_2$, the other possibilities shown in Figure~\ref{fig:semantic sentential game g12}. I will label this locutionary meaning $\sigma^{\ell} = \sigma_1\sigma_2 = \emph{Bill Smith stood (for election)}$. The full illocutionary meaning will be labeled $\sigma^{\iota}$ so that the complete meaning of the utterance will be $\sigma = \sigma^{\ell} \odot \sigma^{\iota} = \emph{Bill Smith ran in the local election}$.

On the other hand, it is obvious that the equilibrium or optimal parse of the utterance is just $t = t_{12} = t_1t_2$ as indicated in Figure~\ref{fig:syntactic sentential game g12'} as it is the only possibility. In more complex cases where syntactic ambiguities are present, the solution will be correspondingly more complex and syntax will also play a more active role in the overall determination of both locutionary and illocutionary contents and vice versa. Indeed, the syntactic and semantic (and phonetic) games all have to be solved together because they generally cannot be solved ``locally'' except when they are trivial. While the solution process involves a slightly elaborate description, it involves rather easy probabilistic computations that are straightforward to implement in our nonconscious (and semiconscious) neural processes.

The six interdependent \emph{local} games that have been constructed so far can also be collected into a locutionary global game $LG_u(\varphi) = \{g_1, g_2, g_{12}, g'_1, g'_2, g'_{12}\}$ and we can say that when $\cal A$ considers how $\cal B$ might interpret an utterance of $\varphi$ in $u$ in his head he will construct $LG_u(\varphi)$. This interdependence of the games of partial information is another reason why they are not games of incomplete information (or signaling games).\is{game!incomplete information}\is{game!signaling} If $f_u$ is a solution function that maps games into their solutions, we can also write, based on our assumption that the joint solution to the semantic locutionary games is $\sigma_1\sigma_2$ and to the syntactic locutionary games is $t_1t_2$, that $f_u[LG_u(\varphi)] = \{f_u(g_1), f_u(g_2), f_u(g_{12}), f_u(g'_1), f_u(g'_2), f_u(g'_{12})\} = \{\sigma_1,\allowbreak \sigma_2, \sigma_1\sigma_2, t_1, t_2, t_1t_2\}$. In other words, the solution to each local game, whether semantic or syntactic, is compatible with the solutions to all the other games because they must agree not only in the contents they deliver but also in the values of the conditioning variables that get set in the prior probability functions. For example, in the first lexical game $g_1$, the prior probability function $\rho_1 = P(\sigma_1 \cond x_2, y_1, y_2; u) = P(\sigma_1 \cond \sigma_2, t_1, t_2; u)$ \emph{in equilibrium}, which shows that the conditioning variables are $\sigma_2$, $t_1$, $t_2$ which all agree with the solutions to the other five games. Further, the equilibrium paths that will actually be followed in these six games will all begin with the actual situations, $s_1$, $s_2$, $s_{12}$ in the three semantic games and $s'_1$, $s'_2$, $s'_{12}$ in the syntactic games, because all the other initial situations are just counterfactual possibilities. And these paths will follow the branches that are consonant with the solutions listed above. If these paths are traced in all the trees then the payoffs actually delivered to the speaker would be $a_{\cal A}$, $a_{\cal A}$, $a_{\cal A} + a_{\cal A}$ in the three semantic games and $a_{\cal A}$, $a_{\cal A}$, $a_{\cal A} + a_{\cal A}$ in the three syntactic games. We can just take the maximum value $a_{\cal A} + a_{\cal A}$ of all these six numbers as the payoff that would be actually delivered to the speaker if he were to utter $\varphi$ in $u$. Precisely what we do is somewhat arbitrary: the payoffs could also be added up to yield $8a_{\cal A}$ or just the lexical payoffs could be added to yield $4a_{\cal A}$. This is because of the affine nature of utilities mentioned in footnote~\ref{foot:utility} in \sectref{sec:communication as rational activity}.

There is one important matter that remains to be specified with respect to the products of games. I considered the products of two semantic games and of two syntactic games but why can't one multiply a semantic game with a syntactic game? After all, both yield \emph{contents} and I have been saying that semantic and syntactic contents are to be treated uniformly. The answer is one can -- by forming ordered pairs of possible semantic and syntactic contents. For example, the ``pure'' semantic game $g_1$ in Figure~\ref{fig:semantic lexical game g1} would have $(\sigma_1,t_e)$ in place of just $\sigma_1$ and $(\sigma'_1,t_e)$ in place of just $\sigma'_1$ where $t_e$ is just the empty tree. Likewise, the ``pure'' syntactic game $g'_1$ in Figure~\ref{fig:syntactic lexical game g1'} would have $(\mathbf{1},t_1)$ in place of just $t_1$ where $\mathbf{1}$ is just empty or no information. Then we can perform the product $g_1 \otimes g'_1 = g_{11'}$ which would have $(\sigma_1,t_1)$ and $(\sigma'_1,t_1)$ as the interpretive choices for $\cal B$. This shows that the locutionary global game actually contains many more local games. Indeed, it is not enough to consider just ordered \emph{pairs} of contents but we need $2n$-tuples where $n$ is the number of words in the sentence. This is because we can also form products like $g_1 \otimes g'_2 = g_{12'}$ as well as $g_{12} \otimes g'_{12} = g_{121'2'}$, the full mixed sentential product.\label{page:mixed products}\largerpage

I will not bother to list all of them as there are too many permutations of the indices. In fact, the upper bound for the number of these games is $2^{2n} - 1 = 15$ when $n = 2$.{\interfootnotelinepenalty=10000\footnote{It is instructive to work out this formula to check one's understanding of these games. In general, there will be $2n$ indices, $1$, $2$, $3$, \ldots, $n$ for semantic lexical games and and $1'$, $2'$, $3'$, \ldots, $n'$ for syntactic lexical games. These indices form a set of $2n$ elements which has $2^{2n}$ subsets. And as there is no null subset involved, we subtract $1$, giving us the formula $2^{2n} - 1$. The reason it is an upper bound is that there will be many zero products and the corresponding games would be discarded.}} So one can see that the number of games grows quite rapidly with $n$, the length of the sentence. I will show in the next chapter that the only product of semantic and syntactic games that matters is the full mixed sentential product so I will ignore the other mixed products. Remarkably, the only games needed to understand an utterance turn out to be the pure lexical games, a vast computational simplification resulting from our rationality.

\subsection{Back to the Generation Game}\largerpage
Thus, our conclusion so far is that, based on the Content Selection Game induced by the Setting Game in $u$, $\cal A$ resolves to convey $\sigma$ in $u$ in order to evoke the response $a$ from $\cal B$, and then, in the Generation Game that is induced by the Content Selection Game, casts about for a sentence that would do the job, finds $\varphi$ as one such sentence by some assumed conversion process from $\sigma$ to $\varphi$, constructs $LG_u(\varphi)$ in his head as described by the Phonetic, Syntactic, Semantic, and Flow Constraints, solves it with the map $f_u$, checks that the equilibrium content is compatible with $\sigma$, and receives a value $v_u^{\cal A}[LG_u(\varphi)] = a_{\cal A} + a_{\cal A}$. We say the \emph{value} of $LG_u(\varphi)$ to $\cal A$ is $a_{\cal A} + a_{\cal A}$. This entire computation, or some approximate version of it, presumably takes only milliseconds to perform in a speaker's head and happens nonconsciously. In actual fact, it is not just $LG_u(\varphi)$ that is constructed but also $IG_u(\varphi)$, the global set of local illocutionary games corresponding to the illocutionary meanings of the utterance, whose description I have postponed to \partref{part:IV}. In other words, it is the global game $G_u(\varphi) = LG_u(\varphi) \cup IG(\varphi)$ that the speaker identifies when he contemplates uttering $\varphi$ and it is the global game's value $v_u^{\cal A}[G_u(\varphi)]$ that he computes. I realize this is a lot of terminology but once we have set it up, the discussion will flow very smoothly.

There is one other factor that enters into $\cal A$'s consideration of $\varphi$. That is the \emph{cost} of uttering $\varphi$, $k^{\cal A}_u(\varphi)$, which is based on a variety of factors, mostly objective ones such as the length and complexity of the sentence and the effort required to mentally process it and to physically produce it but also subjective ones especially related to the consequences of making certain information explicit and leaving certain information implicit. These subjective costs have to do partly with aesthetic things like conversational style but also with how making certain things explicit may affect the relationship with the addressee in positive or negative ways depending on whether these explicit things are polite or impolite and how leaving certain things implicit may result in costly errors. The mental processing involves playing the global game and determining its value. The \emph{net} value $\cal A$ would receive from uttering $\varphi$ is then $v_u^{\cal A}(\varphi) = v_u^{\cal A}[G_u(\varphi)] - k^{\cal A}_u(\varphi)$.\footnote{Here, I have used the same symbol $v_u^{\cal A}$ for a function of $\varphi$ and for a function of $G_u(\varphi)$ to avoid multiplying symbols needlessly. Also, note that this symbol is different from $v_{\cal A}$, the payoff to $\cal A$ shown in the Content Selection Game in Figure~\ref{fig:CS}.} This finally completes my description of what happens when $\cal A$ imagines uttering $\varphi$ in $u$. Essentially, he computes its net value $v_u^{\cal A}(\varphi)$ based on the value $v_u^{\cal A}[G_u(\varphi)]$ of the global game determined by the four Constraints and its cost $k^{\cal A}_u(\varphi)$. I will consider the details of costs in \sectref{sec:solving generation games}.

In the same way, $\cal A$ may compute the net values of other sentences he could utter in $u$ to convey $\sigma$, possibly 
$\varphi' = \Expression{Bill Smith ran}$ and $\varphi'' = \Expression{Bill}$ \Expression{ran in the election}. These net values would be determined by the global games $G_u(\varphi')$, $G_u(\varphi'')$ and the associated costs $k^{\cal A}_u(\varphi')$, $k^{\cal A}_u(\varphi'')$ of the two sentences. Each of these global games would involve the corresponding lexical, phrasal, and sentential semantic and syntactic speaker games (as well as the relevant illocutionary games) and their global solutions. 

On the other hand, the limits of rationality mentioned earlier may make him abandon his search for more sentences if he feels sufficiently satisfied with the best net value he has computed so far. This is a trial and error process as becomes especially clear when one is writing rather than speaking as then there is ample scope to try out different sentences to express roughly the same content. Indeed, when writing is considered, it becomes obvious that there is an interdependence between the Content Selection Game and the Generation Game because a new sentence with a slightly improved content may suggest itself in the Generation Game and then the new content would have to be evaluated in an altered Content Selection Game.

In any case, he considers one or more sentences and this leads to the choice he faces in the Generation Game $GG_u(\sigma)$ as shown in Figure~\ref{fig:GG}.

\begin{figure}[h] 
\input{figures/pix6.tex}
\caption{Partial Generation Game $GG_u(\sigma)$}
\label{fig:GG}
\end{figure}

This may appear superficially like a one-person decision problem but keep in mind that the net values are based on the values of the corresponding global games which involve both $\cal A$ and $\cal B$. $GG_u(\sigma)$ is so far just in $\cal A$'s head. His solving it involves choosing the sentence with the highest net value and, finally, publicly uttering it in $u$.

I will assume $\varphi$ is in fact the best sentence to utter in $u$ because it conveys the same content $\sigma$ as the other sentences with a lower cost. Its cost is lower because it is shorter and simpler than the other sentences and the physical and mental effort involved is therefore lower (even though there may not be any illocutionary games required for the other sentences because all the information has been made explicit in them). Also, if the ongoing conversation is about the local election, then aesthetic considerations might imply that repeating the information about the election explicitly is inelegant. For example, if $\cal B$ has just referred to the election explicitly in her prior utterance to $\cal A$, then the election is already very prominent in the context. These sorts of things lead to the use of pronouns, for instance. There may be no very weighty relationship-related dimensions involved and no politeness considerations in this kind of purely informational and casual exchange. I will consider such psychosocial factors in Sections~\ref{sec:expanded content selection game} and \ref{sec:a complete example} and \chapref{ch:vagueness} as the first task is to lay out the model in its simplest form.

I end this section by reiterating the point made in \sectref{sec:micro-semantics} that sharply separating the Content Selection Game from the Generation Game is just a useful idealization. The two games are interdependent because identifying the optimal content to convey leads to the search for the optimal sentence to utter and vice versa. For example, in considering $GG_u(\sigma)$, $\cal A$ may opt for something more tentative and less assertive such as $\eta = \Expression{I think Bill ran}$ based on his own and his addressee's psychology as well as on their interaction so far. This would take him back to an altered Content Selection Game with a slightly different content corresponding to $\eta$ and so on. And, indeed, bits of content and bits of language rather than entire sentences may go back and forth between the two games with alterations in both games as new possibilities arise. Speaking and writing are ultimately creative acts so there can be no complete closure to this process. That is part of the reason why I do not as yet have a model of how sentences are generated from contents: the map is partly open-ended as it depends on many factors including the speaker's mastery of the language.

To the best of my knowledge, most models in semantics, including my own earlier work, do not make the distinction between content selection and generation. Even computational studies of generation (e.g.\ \citealt[Chapter~24]{jm:slp2}) seem to omit the content selection problem and simply start with a given content. Thus, while the sharp separation referred to above is an idealization, the key point is to recognize that \emph{two} choices, not one, are involved, the choice of content and the choice of appropriate sentence to convey the content, whatever the particular manner in which the two are effected, whether separately as I have shown or together via an ordered pair in a single more complex game.

\section{The Interpretation Game} \label{sec:interpretation game}

Once $\cal A$ has publicly uttered $\varphi$, $\cal B$ presumably hears (or reads) it. Based on her using the same four Constraints -- Phonetic, Syntactic, Semantic, and Flow -- that the speaker has used, this leads to the public emergence of a game between $\cal A$ and $\cal B$. There are, in fact, three games: one is the actual game $G_u(\varphi)$ that comes into existence and the other two $G^{\cal A}_u(\varphi)$, $G^{\cal B}_u(\varphi)$ are $\cal A$'s and $\cal B$'s models of their interaction. That is, the local games contained in the global games have three aspects and each of them derives from the game maps $g_u$, $g^{\cal A}_u$, and $g^{\cal B}_u$. The ``objective'' map $g_u$ is not in either agent's private information but can be said to exist on account of the utterance. The construction of $G^{\cal B}_u(\varphi)$ is very similar to the construction of $G^{\cal A}_u(\varphi)$ above. Just as $\cal A$'s locutionary global game \[LG^{\cal A}_u(\varphi) = \{g^{\cal A}_1, g^{\cal A}_2, g^{\cal A}_{12}, g'^{{\cal A}}_1, g'^{{\cal A}}_2, g'^{{\cal A}}_{12}\}\] so $\cal B$'s locutionary global game is \[LG^{\cal B}_u(\varphi) = \{g^{\cal B}_1, g^{\cal B}_2,\allowbreak g^{\cal B}_{12}, g'^{{\cal B}}_1, g'^{{\cal B}}_2, g'^{{\cal B}}_{12}\}\] and the objective locutionary global game is \[LG_u(\varphi) = \{g_1, g_2,\allowbreak g_{12}, g'_1, g'_2, g'_{12}\}\text{.}\] $\cal B$ receives just this one sentence $\varphi$ and does not need to consider other alternatives such as $\varphi'$ or $\varphi''$ as $\cal A$ did in $GG_u(\sigma)$. So the Interpretation Game is just $UG_u(\varphi) = G^{\cal B}_u(\varphi)$.\footnote{I use the letter $U$ as a mnemonic for ``understanding'' as the letter $I$ has already been used for the illocutionary global game $IG(\varphi)$.} Thus, there is an asymmetry between $\cal A$'s and $\cal B$'s effort in communication: the speaker generally has to work harder. Incidentally, this slight time lag between $G^{\cal A}_u(\varphi)$ being played in $\cal A$'s head and $G_u(\varphi)$ appearing publicly and $G^{\cal B}_u(\varphi)$ emerging in $\cal B$'s head after the utterance and the possibility of there not being common knowledge is a third reason why these games of partial information are not games of incomplete information (or signaling games).\is{game!incomplete information}\is{game!signaling}

The objective game $G_u(\varphi)$ is made up of those parts of $\cal A$'s and $\cal B$'s subjective games $G^{\cal A}_u(\varphi)$ and $G^{\cal B}_u(\varphi)$ that are \emph{known} to each of them. For example, in each game in $G^{\cal A}_u(\varphi)$ there will be a part that involves $\cal A$'s own possible actions which would clearly be known to him. And there will be a part where he models $\cal B$'s possible actions which may or may not be accurately known to him. On the other hand, in each game in $G^{\cal B}_u(\varphi)$ there will be a part that involves $\cal B$'s own possible actions which would clearly be known to her. And there will be a part where she models $\cal A$'s possible actions which may or may not be accurately known to her. $G_u(\varphi)$ will then consist of the parts of each interlocutor's subjective games that are known to them, $\cal A$'s own possible actions from $G^{\cal A}_u(\varphi)$ and $\cal B$'s own possible actions from $G^{\cal B}_u(\varphi)$. This kind of setup for interpretation is more general than Grice's understanding, for example, as it makes possible a formal modeling of miscommunication and weaker flows of information in a natural way.

If all goes well, $G_u(\varphi) = G^{\cal A}_u(\varphi) = G^{\cal B}_u(\varphi)$ and, indeed, they all become (nonconscious) common knowledge between $\cal A$ and $\cal B$. So far, I have described just the locutionary global game $LG^{\cal A}_u(\varphi)$ in the previous section and said that the illocutionary global game $IG^{\cal A}_u(\varphi)$ will be developed in \partref{part:IV}. But it is the global game $G_u(\varphi) = LG_u(\varphi) \cup IG_u(\varphi)$ that unfolds publicly and $G^{\cal B}_u(\varphi) = LG^{\cal B}_u(\varphi) \cup IG^{\cal B}_u(\varphi)$ that is induced privately in $\cal B$. I will generally assume that the objective and subjective games are all identical and common knowledge as this is what happens when the communication succeeds. But there are situations where there is miscommunication or a weaker flow of information and this is then explained by the divergence among these three games or by the lack of common knowledge. 

Prior to the utterance, $\cal A$ merely believed (nonconsciously) that the emergent game $G_u(\varphi)$ would be common knowledge. When this belief turns out to be informationally caused,\footnote{Here ``information'' is used in Dretske's\ia{Dretske, Fred I.@Dretske, Fred I.} sense of being a true proposition. See \sectref{sec:information}.} that is, when it is knowledge, then $G_u(\varphi)$ will be common knowledge between $\cal A$ and $\cal B$. This would mean that $\cal B$'s corresponding (non-conscious) belief that $G_u(\varphi)$ is common knowledge would also be informationally caused. In this sense, common knowledge of the global game is not something that is exogenously assumed as is usually the case in applications of game theory but it is something that issues from the utterance of $\varphi$ in the ambient utterance situation $u$ when communication succeeds, and fails to obtain when there is miscommunication or when there is a flow of information that is weaker than full communication. There could be a variety of factors responsible for miscommunication, either differences in the prior probability estimates each agent uses in each local game belonging to the global game or differences in the Phonetic, Syntactic, or Semantic Constraint outputs (e.g.\ the addressee might consider an additional word or parse or meaning or might fail to consider some possibility owing to differences in the agents' knowledge of the language) or other differences in their subjective games. Whatever the factor, common knowledge of the game will then not obtain. I have considered miscommunication in some detail earlier so I will not deal with it in this book.\footnote{See \citet[Chapter~9]{parikh:ul} and \citet[Section~5.3]{parikh:le}.} In the case of weaker information flows, the content does get through but it does not become common knowledge. This happens when, for example, $\cal A$ suggests or hints something. I have also considered such weaker flows earlier though I will address them again briefly in \chapref{ch:classifying meaning}.\footnote{See \citet[Section~6.5]{parikh:ul} and \citet[Section~5.10]{parikh:le}.} Generally, I will just assume throughout that common knowledge does materialize.

Incidentally, common knowledge of $G_u(\varphi) = G^{\cal A}_u(\varphi) = G^{\cal B}_u(\varphi)$ is not so hard to come by because the utterance itself is generally public and therefore common knowledge, the language is sufficiently shared so that the Syntactic and Semantic Constraints are (nonconscious) common knowledge, and therefore the possible contents considered in the various local games are common knowledge, and the payoffs are determined endogenously from $\cal A$'s possible intentions which are given by the possible contents, which leaves just the prior probabilities. These are specified by a host of subjective and objective factors and need to be just roughly shared. However, they are the one item that can go awry and so when there is miscommunication it is more often than not because the probabilities were differently assessed by the interlocutors. As I said in \sectref{sec:agents}, there are sufficient grounds for saying that often enough there will be a situation $s \subset u$ such that (a) $s \vDash G_u(\varphi)$, (b) $s \vDash {\cal A}$ \hbox{knows} $s$, and (c) $s \vDash {\cal B}$ \hbox{knows} $s$, which means that often enough $\cal A$ and $\cal B$ will have common knowledge of $G_u(\varphi)$, especially its locutionary part $LG_u(\varphi)$, and, consequently, (partial) communication will succeed.

As before, I will postpone discussing the solution process to the Interpretation Game. Indeed, the solution process is a joint one between $\cal A$ and $\cal B$ and is carried out against the background of $G_u(\varphi)$, the objective global game. Given the assumed identity of the three global games, we can say for the moment that their joint solution is $\sigma^{\ell} = \sigma_1\sigma_2 = \emph{Bill Smith stood (for election)}$ and $t = t_{12} = t_1t_2 = [_{\mathrm{S}}[_{\mathrm{NP}}\, \mathrm{Bill}][_{\mathrm{VP}}\, \mathrm{ran}]]$ and the full meaning $\sigma = \sigma^{\ell} \odot \sigma^{\iota} = \emph{Bill Smith}$ \emph{ran in the local election}. In other words, both $\cal A$ and $\cal B$ derive the same semantic and syntactic content from the utterance.

After solving $UG_u(\varphi)$, $\cal B$ has understood the utterance. In a narrow sense of communication, this is all that is involved. But in a wider sense, she still has to respond to the content. When I defined communication in \sectref{sec:speaker meaning and word meaning}, it was the narrow sense that mattered as communication is not concerned with how the addressee responds to the utterance even though her possible responses in the interactive structure we have called the Content Selection Game influence the content and therefore the sentence $\cal A$ chooses to convey.

As I said in \citet[46]{parikh:diss}, the interpretive act by $\cal B$ in the Interpretation Game is not observable by $\cal A$. As a result, given just this much, $\cal A$ cannot tell if the communication was successful. It is only $\cal B$'s response in the Content Selection Game, if it is an observable act, that allows $\cal A$ to infer how $\cal B$ might have interpreted his utterance. Otherwise, he would need to wait for some public action such as an utterance by $\cal B$ in an ongoing conversation of the kind we are modeling or some other kind of perceptible action to infer how she might have understood him. Even with such observations, there will generally remain some uncertainty about $\cal B$'s precise interpretation just as $\cal B$ will remain unsure about precisely what $\cal A$ was conveying because there are often fundamental indeterminacies\is{indeterminacy} in communication as discussed in detail in \citet[Chapter~5]{parikh:le}. Such indeterminacies arise from a variety of sources as I pointed out there, from possibly different utterance situations the agents carve out (and concomitant differences in the games induced) as well as differences in their knowledge of the language that includes the phenomenon of \isi{vagueness} to be discussed in \chapref{ch:vagueness}. In other words, the divergences between what was conveyed and understood are related to uncertainties each agent has about the content in the other agent's mind.

I have tried to tread a fine line in the preceding paragraphs. On the one hand, common knowledge is, often enough, not that hard to come by, but, on the other, it also does often fall short of what is required for an exact identity between what is conveyed and what is understood. More of the locutionary content will generally be identical as opposed to the illocutionary content but even with the former there are differences that arise, especially on account of \isi{vagueness}.


\section{The Content Selection Game again} \label{sec:content selection game again}

Based on the content $\sigma$ that $\cal B$ infers from $G_u(\varphi)$, she constructs the Content Selection Game shown in Figure~\ref{fig:CS} in \sectref{sec:content selection game} for the first time. Until this point in time only $\cal A$ has played the game as a private matter. He has had to convert the optimal content $\sigma$ into a public utterance of $\varphi$ in $u$ in the Generation Game to convey $\sigma$ to $\cal B$. She then infers $\sigma$ from the utterance in the Interpretation Game and so comes to construct the Content Selection Game. This is part of the circularity in communication. In general, as I remarked in \sectref{sec:content selection game}, her model of the Content Selection Game may differ from $\cal A$'s and there will again be the same circumstance of an objective game and two subjective games. But, to simplify things, I assume common knowledge of a single game. In the trivial interaction at hand, $\cal B$ has just one action $a$, acceptance, to choose from, so she simply carries out that action. Even here, this response is invisible to $\cal A$ and so he has to wait for some other public action by $\cal B$ to infer not just the meaning she derived from his utterance but also whether she accepted this meaning or not. Of course, in this trivial game, $\cal A$ knows that his content will be accepted because that is the only available response.

When describing the Interpretation Game in the previous section, I had point\-ed to an asymmetry between $\cal A$ and $\cal B$. The speaker has to potentially consider multiple sentences in the Generation Game as indicated by Figure~\ref{fig:GG} but the addressee need consider just the single utterance selected by the speaker. This means the addressee never has to consider alternative \emph{utterances} as is commonplace in Gricean pragmatics (e.g.\ \citealt{horn:sploe, horn:qr}, \citealt{levinson:pragmatics, levinson:pm}). However, as will become clear in \partref{part:IV}, she does have to consider alternative \emph{contents} when the Content Selection Game presents more complex possibilities. The reason for this somewhat subtle difference is that while it is reasonable for addressees to reflect on \emph{what} a speaker may be conveying, it is idle for them to concern themselves with \emph{how} a speaker may be conveying it as many different ways of expressing the same content may exist. And, given the compositional nature of generation and interpretation, this can lead to an inefficient regress in processing, as I argue in \sectref{sec:old partial information game}. It is because much Gricean work is not fleshed out in as much detail as Equilibrium Semantics provides that it becomes possible to ignore this issue.

Once $\cal B$ has responded, the circle of communication is over and both agents return to the Setting Game where the whole enterprise began. All of this generally takes no more than a few seconds in thought and speech for $\cal A$ and comprehension and response for $\cal B$ although a writer may take more time to formulate his utterance and a reader may take more time to digest a sentence. All that has been accomplished here is that $\cal A$ has communicated $\sigma$ to $\cal B$ and she has accepted his communication.

Below, I will look at two slightly more complex Content Selection Games where both agents have a real choice of action.


\section{Back to the Setting Game} \label{sec:setting game again}

Once they are back in the Setting Game where they are discussing the local election and perhaps politics generally, $\cal A$'s wish to elicit a certain sort of response from $\cal B$ has been more or less fulfilled. They are now ready to begin the next round of their conversation where $\cal B$ might, on the basis of what she has just heard and the setting they are in, form her own wish to elicit a corresponding response from $\cal A$, leading to a new Content Selection Game. If we were interested in modeling dialogue, this is how it would have to be done, allowing for cross-references to the shared history the interlocutors build up. This shared history, and particularly the various objects the agents have referred to, become salient for future utterances in the dialogue via what is called an \emph{information state} which maintains a record of the past contents conveyed. There are naturally three such states -- one objective one and two subjective ones which may be more or less identical and common knowledge. 

I have implicitly described a simpler kind of dialogue where each participant utters just one sentence at a time but there is no difficulty in extending such a picture to alternating \emph{discourses} by each agent. It is possible to allow even more general settings where the agents might be performing other nonverbal actions such as gestures or interrupting the flow by a side exchange with some other party or by some other intervening acts. All such settings involve a sequence of utterance situations rather than a single one. Such sequences are called \emph{discourse} or \emph{dialogue} situations and are denoted by $d$.

I have so far not discussed the entire content conveyed in a communication, just the infon $\sigma$ and the parse tree $t$, the latter being transmitted nonconsciously. What actually happens is that an utterance describes a situation $c$ \emph{as} supporting or containing a content $\sigma$. That is, what is conveyed is the \emph{proposition} $p = (c \vDash \sigma)$ where $c$ is called the described situation.\footnote{I have used $c$ as a mnemonic for the situation supporting a content as the letter $d$ is reserved for the discourse or dialogue situation.} The content $\sigma$ is tied to some situation that is also communicated. For example, if $\cal A$ and $\cal B$ are talking about New York politics generally, then the situation of New York politics will be the described situation. If they are discussing just the local election, then the situation involving the local election will be the described situation. I have said above that the full content $\sigma = \sigma^{\ell} \odot \sigma^{\iota} = \emph{Bill Smith ran in the local election}$ and this implies that $\sigma^{\iota} = \emph{in the local election}$ is an illocutionary content of the utterance. This in turn suggests that the described situation is some larger situation, either covering New York politics ($c$) or even politics generally ($c'$) or possibly New York generally ($c''$). But I could equally have said that the described situation is one involving the local election ($c_0$) in which case there is no need for the illocutionary content $\sigma^{\iota}$ as it would be redundant. In other words, the described situation is generally quite indeterminate and is seldom fully shared by the agents. Further, whether something is an illocutionary content and occurs to the right of the turnstile in the proposition conveyed or whether it is just a part of the described situation and so occurs to the left of the turnstile is often indeterminate. That is, the proposition conveyed could be any of $c \vDash \sigma$ or $c' \vDash \sigma$ or $c'' \vDash \sigma$ or $c_0 \vDash \sigma^{\ell}$ or even other possibilities.

As I said in \sectref{sec:information}, it is agents who carve out situations and it is agents who determine the boundaries of what they are discussing. These boundaries are generally fuzzy and differently identified by the two agents. These differences are in fact quite productive as they lead the interlocutors to pursue different possibilities in what they contribute to the conversation as different contents suggest themselves to each agent. If one agent thinks they are discussing politics generally ($c'$), he may shift the discussion to the presidential election; if the other agent thinks they are discussing New York generally ($c''$), she may shift the discussion to the excesses of Wall Street. As such, the described situation also keeps changing through a conversation, getting larger or smaller or going off in a different direction altogether.

It is propositions that are true or false (or indeterminate) so that if the described situation had for some reason been a local election in Mumbai ($c'_0$) then the proposition $c'_0 \vDash \sigma^{\ell}$ that Bill Smith ran in the local election in Mumbai would have been false. Both versions of the proposition $c \vDash \sigma$ and $c_0 \vDash \sigma^{\ell}$ may well be true. This raises the question how the described situation is even roughly determined. Where does it come from? It is partly inferred from $u$ and the larger dialogue situation $d$, it partly issues from $\sigma$ itself, and it is partly just creatively constructed by each agent. There is considerable latitude in where its boundaries are fixed and what matters to the communication is just whether it supports the content $\sigma$ or not. I will say more about this when I look at how truth plays a role in meaning in \sectref{sec:meaning and truth}.

For the time being, I just point out that the utterance and dialogue situation are different from the described situation although both are part of the context as I said in \sectref{sec:agents}. This is a more general and, in my view, more accurate setup than the framework of a context set introduced by \citet{stalnaker:orc} which plays both roles of utterance situation and described situation and consequently has fewer degrees of freedom. As discussed in some detail in \citet[65--66]{parikh:le}, if $d$ is made up of a sequence of utterances each taking place in utterance situations $u_1$, $u_2$, \ldots , then, just as $u_1$ contributes to constructing $c_1$, $c_1$ in turn contributes to modifying $u_1$ to establish the next utterance situation $u_2$, which modifies $c_1$ and generates the next described situation $c_2$, and so on.


\section{The Communication Game} \label{sec:communication game}\largerpage

We have come full circle and we can now appreciate the explanation for $\cal A$'s utterance and $\cal B$'s response. First, there is the setting $u$ in which everything takes place. Part of this setting is the Setting Game which, in this case, is just a casual conversation between $\cal A$ and $\cal B$ about a local election. This induces the Content Selection Game for $\cal A$, maybe because it is $\cal A$'s turn to contribute something to the dialogue. $\cal A$ solves this game and identifies the equilibrium content $\sigma$ to convey to $\cal B$ in order to evoke some response $a$ in her, something as minimal as reception or acceptance in this example. After this selection, $\cal A$ plays the induced Generation Game and converts $\sigma$ into possible sentences he could utter in $u$ to convey this content. One of these is $\varphi$. He evaluates $\varphi$ by mentally building a model of the corresponding global game determined by the four Constraints, Phonetic, Syntactic, Semantic, and Flow, and computing its net value based on the global game's value and the cost of the utterance. After possibly evaluating other candidates as well, he chooses the optimal sentence and publicly utters it. Upon hearing the utterance, $\cal B$ builds her mental model of the global game called the Interpretation Game based on the same four Constraints and solves it. If the communication is to succeed, the three global games -- the objective game and the two subjective models of it -- have to be identical and common knowledge and $\cal B$ arrives at the content $\sigma$. Based on this, she plays the Content Selection Game and chooses her best response, just acceptance in this example. Finally, both return to the Setting Game for further rounds of the conversation.

Thus, $\cal A$, in attending to the Setting Game, starts with the Content Selection Game and then plays the Generation Game. $\cal B$ starts with the Interpretation Game and then plays the Content Selection Game. This double set of choices that both agents have to make -- selecting a content and then the utterance for the speaker and choosing an interpretation and then an action for the addressee -- are quite reasonable once one realizes that one choice in each set of choices would have been required even if telepathy were possible. However, in practice, all this happens nonconsciously and seamlessly, possibly going back and forth multiple times among the various games as small chunks rather than whole utterances are processed in real time.

This is more or less the full structure of communication. There can be many variations of it. It can be seen to be qualitatively quite rich but each part of it is relatively simple. That is, its building blocks are uncomplicated and easily understood but the interactions among them make the overall system quite complex. This is exactly what we should expect intuitively and, as will be seen below, the solution to all these games is also quite straightforward and readily implementable either in human neural structures or in artificial agents such as robots. 

We can now go back to the chart that was displayed in \sectref{sec:micro-semantics}.\largerpage

\begin{enumerate}[itemsep=0pt]
\item[] \underline{Utterance Situation} 
\item[] Setting Game
\item[\functionarrow] $\cal A$'s wish to elicit some response from $\cal B$
\item[\functionarrow] Content Selection Game
\item[\functionarrow] $\cal A$'s equilibrium content
\item[\functionarrow] Generation Game
\item[\functionarrow] $\cal A$'s equilibrium utterance
\item[\functionarrow] Interpretation Game
\item[\functionarrow] $\cal B$'s equilibrium content
\item[\functionarrow] Content Selection Game
\item[\functionarrow] $\cal B$'s equilibrium response
\item[\functionarrow] Back to the Setting Game
\end{enumerate}
It should now be very clear how this cycle of communication works for just a single utterance. It is useful to assign symbols to all the games involved, so we denote the Setting Game by $SG_u$ and the Content Selection Game by $CSG_u$. The Generation Game already has the name $GG_u(\sigma)$ and the Interpretation Game has the name $UG_u(\varphi)$. In general, there will be other contents $\cal A$ will contemplate in $CSG_u$ but it is just the optimal one $\sigma$ that induces the corresponding Generation Game $GG_u(\sigma)$. Likewise, there may be multiple candidate sentences $\cal A$ may consider in $GG_u(\sigma)$ but it is only the optimal utterance of $\varphi$ that induces the Interpretation Game $UG_u(\varphi)$. So we can leave these optimal arguments in there as part of the definition of the whole game called the Communication Game which has these four interlinked games as components. The Communication Game is then $\Gamma_u = (SG_u, CSG_u, GG_u(\sigma), UG_u(\varphi))$. But the content $\sigma$ and sentence $\varphi$ can also be suppressed if desired to yield just $\Gamma_u = (SG_u, CSG_u, GG_u, UG_u)$. Recall that the global games $G^{\cal A}_u(\varphi) = LG^{\cal A}_u(\varphi) \cup IG^{\cal A}_u(\varphi)$, $G^{\cal B}_u(\varphi) = LG^{\cal B}_u(\varphi) \cup IG^{\cal B}_u(\varphi)$ are part of $GG_u(\sigma)$ and $UG_u(\varphi)$, respectively. I have yet to describe the illocutionary game component of these global games which will be taken up in \partref{part:IV}. There is also an objective global game $G_u(\varphi) = LG_u(\varphi) \cup IG_u(\varphi)$ that is induced by $\cal A$'s public utterance of $\varphi$ which I have deliberately left out of the chart above and from the definition of $\Gamma_u$. It forms a kind of backdrop to the subjective games that the agents actually solve but what happens is determined by the objective game which is the actual game that gets played as the subjective games are just partial models of it. Of course, we will be largely concerned with situations where all three games are identical. If we wish, this missing objective game can be made explicit by defining $\Gamma_u = (SG_u, CSG_u, GG_u(\sigma), UG_u(\varphi), G_u(\varphi)) = (SG_u, CSG_u, GG_u, UG_u, G_u)$. Finally, each global game is made up of several local games that are either speaker games or addressee games or the corresponding objective games. These are called games of partial information and it is their joint solution that plays a crucial role in the process of communication.

At this stage, we are in a position to say that communication (in its wide sense) basically involves the playing of the Communication Game $\Gamma_u$ in some situation $u$. It is as simple or as complex as that, whichever way you wish to see it.
