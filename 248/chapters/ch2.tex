\chapter{Information and agents} \label{ch:information and agents}


\section{Information} \label{sec:information}

I started the first chapter with a quick description of an informational space.\is{ontology|(} I elaborate on it here.

\subsection{Philosophical background}
Reality is all the stuff that makes up the world, not only the tables and chairs in it but also a table's \emph{being} white and a chair's \emph{being} black. Perhaps \citet[5]{wittgenstein:tlp} put this insight most grandly: ``The world is the totality of facts, not of things.'' I include both facts and things as well as other entities. 

%While countless such items are very familiar to us, others are less so, and, in describing the furniture of the world, it is helpful to identify the abstract \emph{kinds} of things that constitute it.

Reality is sliced up differently by different living things, partly because they possess different kinds of bodies and partly because they have different concerns. That is, ants, dogs, and humans \emph{individuate} and \emph{discriminate} reality in different ways,\footnote{See \citet[Chapter 2]{devlin:li}. For some evidence of this, see \citet{carruthers:obsm}.} both at a basic categorial level that is constant across a species and at a more fine-grained level that varies with each agent. \emph{Individuation} involves an 
analog-to-digital conversion, possibly along with an application of symbols to reality.\footnote{When some information is in analog form, there is always more specific information about the object also present. Digital information is the most specific information about an object in a representation. If someone says a cup has coffee in it, this information is in digital form; when a picture of the cup is shown instead, the same information is in analog form because it conveys many more specific facts, such as the extent to which the cup is filled, what kind of cup it is, and so on. See \citet[177]{dretske:kfi}. The analog/digital distinction is related to but not the same as the continuous/discrete distinction. The former could perhaps be thought of as a generalization of the latter.} \emph{Discrimination} involves just an analog representation without any digital conversion.

So ants may see one facet of reality, dogs another, and humans a third, each based on a distinct perceptual and cognitive apparatus. And two persons may further individuate their shared ontologies in contrasting ways, as happens when one sees the proverbial glass as half full and the other as half empty. Ontologies depend on reality and so cannot be arbitrary and must also be compatible with one another. That is, if a real glass is in fact half filled with water, one cannot without error see it as only a third full, but one can see it as either half full or half empty. An informational space can be viewed as a coordinate system an agent uses to orient itself in reality. 

People find themselves in a ``world'' or \emph{environment} from the start, as the phenomenological\is{phenomenology} tradition\footnote{See \citet{spiegelberg:pm}. Also \citet[68--71]{husserl:tns} and \citet[Division One]{heidegger:bt}. Husserl's situatedness is more cognitive whereas Heidegger's encompasses the whole person.} has emphasized. This is not the entire world or all of reality but a small part of it. This observation seems obvious but the analytic tradition of Frege and Russell missed it and missed its profound consequences. First, in all social matters and especially in the domain of communication, this environment or \emph{context} or \emph{background} is indispensable. Even today, a century later, its presence in the study of meaning is stubbornly resisted by many. Less obvious is the fact that our informational space, a subspace of our environment, results from society's interaction with reality partly via communication.\footnote{This interaction among persons, language, and world was described in what I called equilibrium metaphysics in Section~7.6 of \emph{Language and Equilibrium}.} Third, this context of communication often has indeterminate boundaries and this results in many other uncertainties. Once individuated, each informational item is linked with others that form its context, although in formal domains such as mathematics and physics this context is more determinate. For example, a certain fact may be true of equilateral triangles and then this condition forms the context for the fact. In everyday life, the context is less determinate.\footnote{\citet[85--86]{taylor:rr} discusses this Heideggerian\ia{Heidegger, Martin@Heidegger, Martin} holism in the context of the evolution of modern epistemology.}\largerpage 

There is a premature rush among analytically minded researchers to secure the respectability of science and it is not realized that their abstractions often miss the essence of the problem. A glaring example of this is the fundamental difference between a sentence and an utterance, something \citet{wittgenstein:pi},\ia{Wittgenstein, Ludwig@Wittgenstein, Ludwig} \citet{austin:pp},\ia{Austin, J. L.@Austin, J. L.} and \citet{strawson:or, strawson:intcon} were the first to emphasize. When approaching the social sciences, one has to straddle both their abstract and concrete sides, and recognize that a complete science may not be possible because of the indeterminate and partly unstructured nature of context. And yet, as I will show, a remarkable degree of scientific success is possible if the task is approached in the right way. Surprisingly, philosophers especially, despite their desire to emulate the sciences, have often kept away from relatively new mathematical tools such as game theory and have continued to rely on commonsense insights. This is seldom the way of science. Earlier philosophers invented and used the then-most powerful methods of logic but most contemporary philosophers have largely avoided the more modern techniques of game theory.

As we move about, we encounter parts of this environment that we carve out as situations.\largerpage From situations, we extract states of affairs or \emph{infons}, informational complexes consisting of individuals having properties and standing in relations to other individuals. That is, situations are just more or less indeterminate collections of infons and there are often multiple situations within an agent's environment. There are further uniformities such as \emph{types} and \emph{parameters} that we abstract.\footnote{This book will not be dealing with such entities much, if at all, as I plan to use situation theory relatively informally here. They are described more fully in my previous book, \emph{Language and Equilibrium}.} Perceptual information is transformed into cognitive information in our ongoing experience that keeps identifying and classifying new situations as we act in the world. Our sensory/perceptual awareness of situations tends to be analogical and our partial classification of them by infons digital.\footnote{Most classical Indian philosophies held that ``perception must be of two kinds, each corresponding to a stage of its unfolding: at first a nonconceptual, nonlinguistic taking-in of whatever is presented to the senses, and then a conceptual, linguistic, predicative cognition in which the entities presented to the senses are knit together as qualifier and qualified.'' See \citet[31]{mohanty:hip}.} In practice, we extract a fair bit of digital information from our surroundings but a great deal is omitted.\footnote{During this conversion, there is always a \emph{loss} of information because not all that is taken in is digitized, and language can handle only the digitized part. When we want to describe seemingly ineffable aspects of our thoughts -- like the glimmer of an idea -- we have to digitize some of our analog information. That is why \emph{articulating} our ideas and experiences is seldom easy. Such a gap between word and world, possibly responsible for some of our sense of alienation, becomes most evident in the arts. Dance is relatively analog and literature is relatively digital, so when we try to capture our experience of dance in words, we sense correctly that we are losing a lot of information. That is why we say a picture is worth a thousand words.} These entities -- situations, infons, properties and relations, individuals, types, parameters, propositions, constraints -- form our partly shared informational space.\footnote{As \citet{quine:wo, quine:or, quine:so} has noted, the possible ontologies social groups can individuate are not unique. For example, \citet[4--5]{quine:so} says: ``English general and singular terms, identity, quantification, and the whole bag of ontological tricks may be correlated with elements of the native language in any of various mutually incompatible ways, each compatible with all possible linguistic data, and none preferable to another save as favored by a rationalization of the \emph{native} language that is simple and natural to \emph{us}.'' However, as I say in \citet[Section 7.6]{parikh:le}, it is not necessary to accept Quine's conclusions about \emph{radical} indeterminacy\is{indeterminacy!radical} because while many ontologies may be possible, only very few are \emph{optimal}, as equilibrium processes eliminate all the suboptimal ones. The ontologies that remain are therefore likely to be identifiable and inter-translatable, and radical indeterminacy can be avoided. Similarly, the classical Buddhist doctrine of \emph{dependent origination} maintains that reality is \emph{conventional}, that is, socially constructed and nonunique, and becoming aware of this conventionality is the key to attaining wisdom. See \citet[87--94]{garfield:fwmw} and also \citet{mohanty:cip}.} Such information enters the science of communication in two ways, via the context of communication and via the content of communication.

I generally use the word \textsc{information} for the entire ontological space, including both true and false propositions and also entities that are neither true nor false. \citet{dretske:kfi, dretske:er, dretske:its} and \citet{ip:wii} use it just for propositions that are true. Computer scientists, linguists, psychologists, and others use it for both true and false propositions. There is some warrant for both of these senses in ordinary usage, and my more inclusive meaning is a little nonstandard, but it is useful when accounting for titles of books such as \emph{The Problems of Philosophy}\ia{Russell, Bertrand@Russell, Bertrand} or \emph{Anna Karenina},\ia{Tolstoy, Leo@Tolstoy, Leo} or unfinished utterances, or pictures of objects such as an apple or a ball, or similar uses of symbols that are ``nonpropositional.'' My notion is coextensive with  ``content'' but this word usually involves some representation whereas ``information'' need not.\is{ontology|)}

%I will sometimes also use the word in just its propositional sense but it should be fairly clear from the context which is meant.


\subsection{Situation theory}\is{situation theory|(}

The version of \citegen{bp:sa} situation theory I offer here is my own, its main innovation being partial infons. I use it relatively  informally in this book so I give just an outline 
here.\footnote{The curious reader who wants to know more can refer to \citet{parikh:le}. It is interesting to compare situation theory with semantic nets\is{semantic nets} and studies by Sanskrit grammarians\is{Sanskrit grammarians} dating back to the first millennium BCE and up to the 18th century CE. As discussed by \citet{briggs:kr}, the latter two have a number of parallels. Situation theory is similar. For example, in an utterance of ``John cooked the food and burned his mouth,'' Sanskrit schemata and semantic nets represent the missing information (that cooking involves heating food and heated food when eaten can burn a mouth) explicitly in the analysis of the utterance. Situation theory handles it in the same way.} 

Consider an utterance of \Expression{Bill Smith ran} in some utterance situation $u$. To analyze it, we would need to represent the content of \Expression{Bill Smith}, the content of \Expression{ran}, the content of the whole sentence, and possibly other things. It is partial infons and full infons that enable us to do this.

Situation theory allows us to model partial information in a very fine-grained way. There are individuals $a_i$ and $n$-ary relations $R_i$. Basic infons are $(n+4)$-tuples $\soa{R;\ a_1;\ \ldots;\ a_n;\ l;\ t;\ 1}$ made up of individuals standing in relations at certain locations $l$ and times $t$ with the last item, the number $1$, being its polarity, indicating the relation holds.\footnote{The polarity can also be $0$ indicating the relation does not hold.} Partial infons such as $\soa{R;\ a_1;\ a_3}$ or even $\soa{a_1}$ are legitimate infons. Any arguments from the full infon $\soa{R;\ a_1;\ \ldots;\ a_n;\ l;\ t;\ 1}$ can be omitted. For example, the content  \emph{Bill Smith ran} can be expressed partially as $\soa{\emph{ran};\ \emph{Bill Smith}}$ or more formally as $\soa{R^{\Expression{ran}};\ b}$ \label{page:relation} where  $R^{\Expression{ran}}$ is a relation, $b$ \label{page:Bill} is an individual, and the location and time and polarity have been dropped. $\soa{\emph{Bill Smith}}$ or $\soa{b}$ is also a partial rendition of this content and is just the individual Bill Smith. This is the same as the identity between 7  and (7) in arithmetic. The angled brackets serve to gather the arguments.

Partial infons are not existentially quantified over the ``missing'' arguments because they are separate entities in their own right that can be merged with other appropriate partial infons in the right circumstances. In this sense, there are no missing arguments as such. More complex infons are formed from these basic infons via the operation of merging and they are all collected in the set $\cal I$. As I will not be much concerned with the internal structure of infons in this book, I will assume the operation of merging or unification parametrized by some situation $s$ on $\cal I$ is given. This operation $\odot_{s}$, abbreviated to $\odot$, is neither associative nor commutative and has the identity $\mathbf{1}$ which stands for no information and zero $\mathbf{0}$ which stands for contradictory information. The product $\sigma \odot \tau$ is often written $\sigma\tau$.\footnote{The interested reader is referred to my previous book, \citet[Chapter~2]{parikh:le}, for more details about $\odot$.}

The relation between a situation $s$ and an infon $\sigma$ that holds in it is written $s \vDash \sigma$  or $\sigma \in s$, and is described by saying $s$ supports $\sigma$ or $\sigma$ holds in $s$. The information expressed by $\vDash$ is special and $s \vDash \sigma$ is called an (Austinian)\ia{Austin, J. L.@Austin, J. L.} proposition. Only propositions can be true or false or indeterminate, the last in borderline cases involving vague terms as discussed in \chapref{ch:vagueness} or when the relevant infon is partial; infons by themselves do not admit of truth values. Utterances typically convey multiple propositions although these are usually multiple infons relative to a common described situation. I will show in \chapref{ch:free enrichment} how propositions actually have a more general form because the infons in them may occur probabilistically. 

%The rest of this section could be read later on an as-needed basis.



%\footnote{Expressing the referent of a name situation-theoretically is a bit more complicated as it involves transforming the conventional meaning of a name into the corresponding referential meaning, an individual. The interested reader is referred to \citet[85]{parikh:le}. I will not consider such details here. \label{foot:name}}


Recall that a partial order over $\cal I$, the space of infons, is a binary relation $\Rightarrow_{\ell}$ over $\cal I$ which is reflexive, antisymmetric, and transitive; that is, for all $\sigma$, $\tau$, and $\upsilon$ (i.e.\ the Greek letter upsilon) in $\cal I$, we have:

\begin{description}
\item[Reflexivity:] $\sigma \Rightarrow_{\ell} \sigma$
\item[Antisymmetry:] If $\sigma \Rightarrow_{\ell} \tau$ and $\tau \Rightarrow_{\ell} \sigma$ then $\sigma = \tau$
\item[Transitivity:] If $\sigma \Rightarrow_{\ell} \tau$ and $\tau \Rightarrow_{\ell} \upsilon$ then $\sigma \Rightarrow_{\ell} \upsilon$
\end{description}\largerpage

A partial order $\Rightarrow_{\ell}$ on $\cal I$ that captures the relation ``is at least as informative as'' or ``is at least as strong as'' is assumed. Certain infons are naturally more informative or stronger than others. For example, $\soa{P^{\emph{crimson}};\ a} \Rightarrow_{\ell} \soa{P^{\emph{red}};\ a}$ where $a$ is some physical object because anything crimson is also always red. So the first infon is stronger than the second. Likewise, $\soa{P^{\emph{spinster}};\ a} \Rightarrow_{\ell} \soa{P^{\emph{female}};\ a}$ where $a$ now stands for a person. It is also true that $\soa{R;\ a;\ b} \Rightarrow_\ell \soa{R;\ a}$. If $R$ is the relation of eating, then if $a$ is eating $b$, $a$ must be eating. Likewise, $\soa{R;\ a;\ 0} \Rightarrow_\ell \soa{R;\ a;\ b;\ 0}$ because if $a$ is not eating, then $a$ is not eating $b$. In each case, the infon on the left is more informative than the infon on the right. 

Intuitively, it is clear that if we have two items of information, say, that $a$ is red and $b$ is blue, then it is possible to combine these states of affairs in two obvious ways, by conjoining or disjoining them. With this in mind, the partially ordered set $({\cal I}, \Rightarrow_\ell)$ is further assumed to be a lattice, which is a partially ordered set in which every pair of elements has a unique supremum (called their join)\footnote{The supremum or least upper bound of a pair of elements, if it exists, is the least element of $\cal I$ that is greater than or equal to each element of the pair.} and a unique infimum (called their meet).\footnote{The infimum or greatest lower bound of a pair of elements, if it exists, is the greatest element of $\cal I$ that is less than or equal to each element of the pair.} Let $\vee$ and $\wedge$ be the induced join and meet operations. If $\tau = \sup\{\sigma,\sigma'\}$, then $\tau = \sigma \vee \sigma'$, and if $\tau = \inf\{\sigma,\sigma'\}$, then $\tau = \sigma \wedge \sigma'$. 

A lattice is complete if all of its subsets, finite or infinite, have both a join and a meet. There is no reason to restrict $\vee$ and $\wedge$ to finite subsets so we assume $({\cal I}, \Rightarrow_\ell)$ is complete. The supremum of $({\cal I}, \Rightarrow_\ell)$ is denoted by $\mathbf{1}$ and the infimum by $\mathbf{0}$.  Intuitively, $\mathbf{1}$ will hold in any situation because every situation supports ``no information'' vacuously, and $\mathbf{0}$ will not hold in any situation because no (coherent) situation can support contradictory information. $\mathbf{1}$ and $\mathbf{0}$ are just the identity and zero elements for $\odot$.

Since $\cal I$ now has the two binary operations $\vee$ and $\wedge$, we assume each distributes over the other. That is, it is assumed that $\sigma \wedge (\tau \vee \tau') = (\sigma \wedge \tau) \vee (\sigma \wedge \tau')$ and $\sigma \vee (\tau \wedge \tau') = (\sigma \vee \tau) \wedge (\sigma \vee \tau')$.

A valuation on $\cal I$ is a real-valued function $v: {\cal I} \functionarrow \mathbb{R}$ such that $v(\sigma) + v(\tau) = v(\sigma \vee \tau) + v(\sigma \wedge \tau)$. A positive valuation is one where $\sigma \Rightarrow_\ell \tau$ implies $v(\sigma) < v(\tau)$. A metric lattice is a lattice with a positive valuation and the corresponding metric is given by:
\[ \delta(\sigma, \tau) = v(\sigma \vee \tau) - v(\sigma \wedge \tau) \]

\noindent Valuations and therefore metrics always exist on distributive lattices and so one can define a metric $\delta$ on $\cal I$. Our interest will be in situated metrics that depend on some situation $s$. In other words, the valuation $v$ the metric would correspond to would be a situated valuation. I will use this kind of metric in \chapref{ch:translation}.

%If we have two infons $\tau = \soa{R;\ a;\ b}$ and $\tau' = \soa{R';\ a';\ b'}$, we would ideally want to have the distance $d_u(\tau, \tau')$ to equal $d_u(\soa{R}, \soa{R'}) + d_u(\soa{a}, \soa{a'}) + d_u(\soa{b}, \soa{b'})$, where each of the components are so-called \emph{basic} distances. Estimates of basic distances occur in a variety of ways. Some judgments may be primitive. Others may depend on a relation between, say, $\soa{R}$ and $\soa{R'}$, or $\soa{a}$ and $\soa{a'}$, and so on. Or these elements may share some property. And there may be yet other ways. But these are always situated estimates and they lead to judgments of similarity and dissimilarity which are captured via the metric.
%
%It is not clear to me at this time whether a valuation that allows distance to be broken down into basic distances in the way described is always available.

I will use the following concept in \chapref{ch:beyond illocutionary meaning}. A nonempty subset $\cal F$ of $\cal I$ is called a filter if\largerpage

\begin{enumerate}
\item $\sigma, \tau \in {\cal F}$ implies $\sigma \wedge \tau \in {\cal F}$,
\item $\sigma \in {\cal F}$, $\tau \in {\cal I}$ and $\sigma \Rightarrow_\ell \tau$ imply $\tau \in {\cal F}$. 
\end{enumerate}

%A subset $F$ of $\cal I$ is called an \emph{up-set} if, whenever $\sigma \in F$, $\tau \in {\cal I}$ and $\sigma \Rightarrow_\ell \tau$, we have $\tau \in F$. With this in mind, a filter on $\cal I$ can be more compactly described as a nonempty up-set closed under meet. The set of filters on $\cal I$ is ordered by inclusion. 

For all situations $s$ and all infons $\sigma$ and $\tau$, the following facts hold:\largerpage

\begin{enumerate}
\item $s \nvDash \mathbf{0}$ and $s \vDash \mathbf{1}$.
\item If $s \vDash \sigma$ and $\sigma \Rightarrow_\ell \tau$ then $s \vDash \tau$.
\item $s \vDash \sigma \wedge \tau$ if and only if $s \vDash \sigma$ and $s \vDash \tau$. 
\item $s \vDash \sigma \vee \tau$ if and only if $s \vDash \sigma$ or $s \vDash \tau$.
\end{enumerate}


Extensions are just the sets corresponding to properties or relations \emph{relative} to some situation. Perhaps the most common type of extension is $\{x \mid s \vDash \soa{P;\ x}\}$, which is the set of objects satisfying the property $P$ in situation $s$. We can define $e(P,s)$ \label{page:e(P,s)} to be the individual $a$ when the condition $s \vDash \soa{P;\ x}$ yields one object $a$ and the set $\{x \mid s \vDash \soa{P;\ x}\}$ otherwise. This entity $e(P,s)$ occurs frequently in the study of noun phrases.\footnote{See \chapref{ch:centrality of communication} and also \citet[Chapter~6]{parikh:le}.} When \emph{no} object has $P$ in $s$, $e(P,s)$ will be the empty set. More formally:
%= (\ x \mid s \vDash \soa{P;\ x}\ )
%Equivalently, $e(P,s) = a \in \{x \mid s \vDash \soa{P;\ x}\}$ when $\hbox{card}(\{x \mid s \vDash \soa{P;\ x}\}) = 1$, where ``card'' is the cardinality of the relevant set, and $e(P,s) = \{x \mid s \vDash \soa{P;\ x}\}$ otherwise.
%, which can be either an individual or a set depending on whether a single object has $P$ in $s$ or not,
\begin{equation}
e(P,s) = \left\{\begin{array}{@{}ll@{}}
a & \mbox{if there is exactly one object $a$ having $P$ in $s$} \\
\{x \mid s \vDash \soa{P;\ x}\} & \mbox{otherwise}
\label{eq:eps}			\end{array}
		\right.
\end{equation}

When one situation $s$ (or situation type $\mathbf{s}$) \emph{involves} another $s'$ (or $\mathbf{s'}$), there is a constraint\is{constraint} between them, written $s \Longrightarrow s'$ (or $\mathbf{s} \Longrightarrow \mathbf{s'}$). Constraints can be nomic, conventional, or of other types. They provide the mechanism through which agents perceive, infer, and act in the world and were introduced in \chapref{ch:why communication is central} to account for meaning. Equilibrium Semantics can be compactly expressed as a system of constraints.\is{situation theory|)}

%They can be represented as infons like $\soa{\Longrightarrow;\ s;\ s'}$.

\section{Agents} \label{sec:agents}

Our situated agents are finite in their capacities, have a range of concerns, and constantly face choices their environments make available. When concerns are articulated digitally as infons, they become \emph{goals}. All agents have a complex and shifting hierarchy of concerns and goals, from survival at the top that is generally always present to very particular ones at the bottom such as a desire\footnote{I use goal, desire, wish, purpose, and other synonyms interchangeably to relieve the tedium of repetition.} for ice cream in some situation. An agent's goals can be equivalently expressed as preferences between situations, for example one in which he is eating ice cream and another in which he is not. It is convenient to use both goals and preferences when discussing communication, remembering that we can translate between them. 

When the choices afforded by a situation become articulate and explicit, they form, together with the agent's beliefs and preferences, a situated choice problem for the agent. When it involves just the agent by himself, it is a situated decision problem, and when it involves other agents, it is a situated game.

A situated game\is{game!situated} is a structure involving a set of situations along with a set of players, a set of interlinked choices of action for each player in alternative situations, and each player's preferences (or payoffs) for every combination of choices the players may select. That is, a situated game is a multi-person interactive situated decision problem. Being (partly) rational, agents try to do the best they can given how the other players may choose, and such a jointly optimal choice for each player is called an equilibrium.\footnote{The words ``best'' and ``optimal'' are meant to be synonymous with ``equilibrium.'' It is common to distinguish between an optimal choice and an equilibrium choice in game theory because an optimal choice, if evaluated in the absence of what other players may do, can diverge from the equilibrium. I just mean the best a player can do \emph{given} the other players' (best) choices.\label{foot:optimal}}


\subsection{A simple example}

Suppose two agents or players $\cal A$ and $\cal B$ are trying to meet in Manhattan without being able to communicate with each other first. Assume they could meet either at Grand Central Station which is closer to both of them or at Penn Station which is further away. If they go to different stations, neither benefits. Such a situation can be captured by the matrix\is{game!normal form} in Figure~\ref{fig:coordination game G in normal form}.\footnote{Almost this very game was first considered by \citet{schelling:sc}. Throughout, I have used ``he'' for $\cal A$ and ``she'' for $\cal B$ as two-person game theory naturally lends itself to two pronouns, making it easier to differentiate between the agents.}

\begin{figure}
\begin{tikzpicture}
    \matrix (coordgame) [inner ysep=0pt,draw, matrix of math nodes, every node/.style={text width=3cm, align=center,anchor=base, inner ysep=.5\baselineskip}] {
        (2,2) & (0,0) \\
        (0,0) & (1,1) \\ 
    };
    \draw (coordgame.north) -- (coordgame.south);
    \draw (coordgame.west) -- (coordgame.east);
    \node[above=.5\baselineskip of coordgame-1-1,anchor=base] {Grand Central};
    \node[above=.5\baselineskip of coordgame-1-2,anchor=base] {Penn Station};
    \node[left=1em of coordgame-2-1.base west,anchor=base east,align=right,overlay] {Penn Station};
    \node[left=1em of coordgame-1-1.base west,anchor=base east,align=right,overlay] {Grand Central};
\end{tikzpicture}
\caption{A coordination game $G$ in normal form} \label{fig:coordination game G in normal form}
\end{figure}

In the game $G$, $\cal A$ has the two choices indicated in the two rows, either to go to Grand Central or to Penn Station, and $\cal B$ has the same two choices indicated in the two columns. Their respective payoffs\is{payoffs|(} are mentioned in the four cells of the matrix, the first number being $\cal A$'s payoff and the second being $\cal B$'s in each cell. If both agents go to Grand Central they get a payoff of $2$ units, if they both go to Penn Station they get $1$ unit, and if they end up at different stations they get $0$. Both $\cal A$ and $\cal B$ are rational and prefer more payoff units to less but each of them can only select their own action even though the outcome depends on what they both do. As we will see later, this is exactly the situation with communication where the outcome depends on both the speaker and the addressee. 

%and it is, indeed, the same with most other interactions between people as well

Thus, both players have to choose a course of action based on what the other player will choose. This sort of interactive choice structure represented as a payoff matrix is called a game in normal or strategic form. This particular game is also called a coordination game\is{game!coordination} because both agents have compatible payoffs and there is no conflict, that is, they do not value the same outcome differently. By varying the payoffs it is possible to generate a range of games even in this simple two-player, two-choice setting. In general, there can be more than two players and more than two choices of action for each player. In some sense, $G$ is one of the simplest nontrivial games where some interesting interactive phenomena occur.

Once a game like $G$ is set up the next step is to see how rational agents wanting to choose the best action would act given that the other agents want to do the same. The resulting optimal strategies are called the solution to the game. Studying the solution process formally involves a number of definitions of terms like \emph{strategy}, \emph{equilibrium}, and the like as well as somewhat subtle analyses. 

%It seems better to proceed informally for now to get the basic insights and later formalize them in the course of my model of communication.

The key idea behind one prominent kind of solution is that optimal actions should be such that no agent will want to deviate from them unilaterally. If $\cal A$ were to choose Grand Central then it is optimal for $\cal B$ to choose the same and vice versa. If $\cal A$ were to choose Penn Station then it is optimal for $\cal B$ to choose the same and vice versa. In other words, both $(\hbox{Grand Central}, \hbox{Grand Central}) = (\hbox{GC}, \hbox{GC})$ and $(\hbox{Penn Station}, \hbox{Penn Station}) = (\hbox{PS}, \hbox{PS})$ are pairs of actions that neither agent will want to deviate from unilaterally. They possess a kind of stability. On the other hand, both $(\hbox{GC}, \hbox{PS})$ and $(\hbox{PS}, \hbox{GC})$ are, in this sense, precarious pairs of choices because both agents will want to shift their strategy. Each can do better by a unilateral change to a different action. For example, with $(\hbox{GC}, \hbox{PS})$ $\cal A$ would benefit by shifting to Penn Station because $\cal A$ would then receive $1$ instead of $0$ and, likewise, $\cal B$ would benefit by shifting to Grand Central because $\cal B$ would then receive $2$ instead of $0$, assuming the two agents do not both shift simultaneously. If any single agent can do better by a unilateral change to a different strategy then that pair would not be selected as optimal. A pair of strategies that is immune to any such unilateral deviation by any agent is called a Nash\is{equilibrium!Nash} equilibrium.\footnote{See \citet{nash:ncg}, \citet[Chapter~3]{myerson:gt}, \citet[Chapter~9]{watson:s} or \citet[78]{parikh:le}.} 


%\is{equilibrium!Nash} I quote from \citet[78]{parikh:le}:
%
%``Let's suppose that each player $i$ of $n$ players has some set of pure
%strategies $Z_i = \{z_{i1}, \ldots, z_{ik}\}$, available to him, where each strategy
%$z_{ij}$ is a series of actions that specify the player's behavior completely with respect to the game. In the simple game we are looking at here, a strategy is just a single action, either going to Grand Central or to Penn Station. In other games, a strategy can be a whole series of actions. When it is necessary to refer to a strategy generically, we will use either $z_{ij}$ or $z_i$ depending on the context.
%
%A \emph{mixed strategy} $\zeta_i$ has the form:
%
%\[ \zeta_i = \pi_{1}z_{i1} + \ldots + \pi_{k}z_{ik} \]
%
%\noindent where the $\pi_{j}$ are probabilities and $\sum_{j = 1}^{k} \pi_{j} =
%1$. That is, the player chooses strategy $z_{ij}$ with probability
%$\pi_{j}$. If all the $\pi_{j}$ are $0$ except one, then $\zeta_i$ is called 
%a \emph{pure strategy}; otherwise, it is a \emph{mixed strategy}. 
%
%The vector $z = (z_1, \ldots, z_n)$ is called a pure strategy profile and the vector $\zeta = (\zeta_{1}, \ldots, \zeta_{n})$ is called a mixed strategy profile.
%
%Suppose, now, that $v_{i}(z_1, \ldots, z_n)$ is the payoff to player $i$ when the
%players use one of their pure strategies. We can define
%the expected payoff to player $i$ for a mixed strategy profile $\zeta$ as:
%
%\[ v_{i}(\zeta) = \sum_{z_{1} \in Z_{1}} \ldots \sum_{z_{n} \in Z_{n}}
%\pi_{z_{1}} \pi_{z_{2}} \ldots \pi_{z_{n}} v_{i}(z_{1}, \ldots, z_{n}) \]
%
%
%\noindent where we use $\pi_{z_i}$ to refer to the weight of $z_i$ in $\zeta_i$.
%
%Assuming that the $n$ players are making their choices
%independently, we get the expected payoff of $\zeta$ by averaging the payoffs to each of 
%the $n$-tuples of pure strategies.
%
%Now, we'll say that a mixed strategy profile $(\zeta^{\ast}_{1}, \ldots,
%\zeta^{\ast}_{n})$ is a \emph{mixed strategy Nash equilibrium} if, for each
%player $i = 1, \ldots, n$:
%
%\[ v_{i}(\zeta^{\ast}) \geq v_{i}(\zeta_{i}, \zeta^{\ast}_{-i}) \]
%
%\noindent where $\zeta_{i}$ is any mixed strategy for player $i$ and
%$\zeta^{\ast}_{-i}$ is the equilibrium strategy choices of the players other than $i$.
%
%This captures the insight that an equilibrium strategy does not permit worthwhile unilateral deviations. Crucially, every finite game has at least one Nash equilibrium, possibly
%more.  In particular:
%
%{\sl Nash Existence Theorem}. If each player in an $n$-player game has a
%finite number of pure strategies, then the game has a (not necessarily
%unique) Nash equilibrium in (possibly) mixed strategies.''}

$(\hbox{GC}, \hbox{GC})$ and $(\hbox{PS}, \hbox{PS})$ are Nash equilibria and such solutions always exist in a large class of games but they are often not unique. This requires ways to eliminate certain equilibria that are counterintuitive from a commonsense viewpoint. In $G$, both agents would be better off by selecting $(\hbox{GC}, \hbox{GC})$ rather than $(\hbox{PS}, \hbox{PS})$ because they would both receive higher payoffs, $(2, 2)$ rather than $(1, 1)$. Such Nash equilibria that make at least one player better off without making any other player worse off are called Pareto-Nash\is{equilibrium!Pareto-Nash} equilibria.\footnote{See \citet{parikh:diss, parikh:ul, parikh:le}.}

I will use both these equilibria extensively in the games I construct to model communication. The optimal utterances and interpretations of speakers and addressees form Pareto-Nash equilibria although the details are more complex as the games required to understand communication are subtler than $G$.

A different way to express $G$ is via the so-called extensive form\is{game!extensive form|(} where each agent's actions are laid out sequentially in an interactive decision tree as shown in Figure~\ref{fig:extensive form G}.

\begin{figure}
\begin{center}
\begin{picture}(150,125)(30,18)
%-------------------------------
%NODES
\put(54,72){\circle*{3}}

\put(54,72){\input{figures/unit2}}
\put(54,18){\input{figures/unit2}}

\put(108,99){\circle*{3}}
\put(108,45){\circle*{3}}
\put(54,72){\vector(2,1){54}}
\put(54,72){\vector(2,-1){54}}

\put(108,72){\oval(15,84)}


\put(54,81){\makebox(0,0){$s$}}
\put(108,108){\makebox(0,0){$t$}}
\put(108,54){\makebox(0,0){$t'$}}

\put(180,118.5){\makebox(0,0){$2,2$}}
\put(180,82.5){\makebox(0,0){$0,0$}}
\put(180,64.5){\makebox(0,0){$0,0$}}
\put(180,28.5){\makebox(0,0){$1,1$}}

\put(81,94.5){\makebox(0,0){$\hbox{GC}$}}
\put(81,66){\makebox(0,0){$\hbox{PS}$}}
\put(135,115.5){\makebox(0,0){$\hbox{GC}$}}
\put(135,97.5){\makebox(0,0){$\hbox{PS}$}}
\put(135,61.5){\makebox(0,0){$\hbox{GC}$}}
\put(135,43.5){\makebox(0,0){$\hbox{PS}$}}

\end{picture}

\caption{Extensive form for $G$} \label{fig:extensive form G}
\end{center}
\end{figure}

The nodes labeled $s$, $t$, and $t'$ are situations and the idea is that an initial situation consisting of various infons results in some action by $\cal A$ and leads to a new situation which is followed by a further action by $\cal B$ leading to a third situation where payoffs are distributed to the two agents. So, for example, $s$ may result in $\cal A$ going to Grand Central leading to a new situation $t$ and then $\cal B$ may also go to Grand Central leading to a third unlabeled situation where both agents receive a payoff of $2$. And similarly for the other three paths through the game tree. Figures~\ref{fig:coordination game G in normal form} and \ref{fig:extensive form G} capture the same choices and payoffs.

The new element in Figure~\ref{fig:extensive form G} is the oval enclosing the situations $t$ and $t'$. This oval is called an information set\is{information set} and represents the epistemic state of $\cal B$ after $\cal A$ has chosen his action, Grand Central or Penn Station. Because we assumed the two agents cannot communicate their choices, $\cal B$ does not know what $\cal A$ chose to do. She cannot distinguish between $t$ and $t'$. This translates into two requirements: there must be the same choices available to $\cal B$ at both $t$ and $t'$ because otherwise she could tell the two situations apart, and she must make the same choice in $t$ and $t'$ because she is in the dark about where she is in the information set.\footnote{There is a third requirement involving one situation in an information set not preceding another but I will ignore it as this possibility does not arise in the two-stage games we will be considering.} Every situation where a choice has to be made by either agent belongs to an information set. The oval represents $\cal B$'s information set. $\cal A$'s information set is trivial because he has just one choice situation $s$ and it alone belongs to an information set which we do not bother to identify. 

Consider Figure~\ref{fig:extensive form G'} where a slightly different game $G'$ is shown with the same choices and payoffs as $G$ but with different epistemic properties.

\begin{figure}[htbp]
\begin{center}
\begin{picture}(150,125)(34,18)
%-------------------------------
%NODES
\put(54,72){\circle*{3}}

\put(54,72){\input{figures/unit2}}
\put(54,18){\input{figures/unit2}}

\put(108,99){\circle*{3}}
\put(108,45){\circle*{3}}
\put(54,72){\vector(2,1){54}}
\put(54,72){\vector(2,-1){54}}

%\put(108,72){\oval(15,84)}


\put(54,81){\makebox(0,0){$s$}}
\put(108,108){\makebox(0,0){$t$}}
\put(108,54){\makebox(0,0){$t'$}}

\put(180,118.5){\makebox(0,0){$2,2$}}
\put(180,82.5){\makebox(0,0){$0,0$}}
\put(180,64.5){\makebox(0,0){$0,0$}}
\put(180,28.5){\makebox(0,0){$1,1$}}

\put(81,94.5){\makebox(0,0){$\hbox{GC}$}}
\put(81,66){\makebox(0,0){$\hbox{PS}$}}
\put(135,115.5){\makebox(0,0){$\hbox{GC}$}}
\put(135,97.5){\makebox(0,0){$\hbox{PS}$}}
\put(135,61.5){\makebox(0,0){$\hbox{GC}$}}
\put(135,43.5){\makebox(0,0){$\hbox{PS}$}}

\end{picture}

\caption{Extensive form for $G'$} \label{fig:extensive form G'}
\end{center}
\end{figure}

In $G'$ there is no oval which means $\cal A$'s choice of action is communicated to $\cal B$ and so she can distinguish between $t$ and $t'$ and make different choices in each of the two situations. Differently put, $\cal B$ now has two information sets, one containing $t$ and the other containing $t'$. If $\cal A$ chooses Grand Central, $\cal B$ would find herself in $t$ and knows this, and so can choose Grand Central, and if $\cal A$ chooses Penn Station, $\cal B$ would find herself in $t'$ and again knows this, and so can choose Penn Station. It is an easier game for both agents to solve as they don't need to anticipate each other's choices. This is one of the ubiquitous reasons communication is so useful because society consists of a large number of games and communication makes them easier to solve. But communication itself involves solving various games and so must be addressed first. $G$ and $G'$ are constructed from situations and so are situated games, structured sets of situations as I said above.\footnote{\citet{watson:s} is an introductory text on game theory. Also see the Appendix for more on situated games.}\is{game!extensive form|)}\is{payoffs|)}


\subsection{Common knowledge}
\is{common knowledge|(}

We have seen how the extensive form makes certain internal epistemic constraints on the agents explicit via information sets. Once knowledge and belief enter the scene, it becomes evident that both agents need to at least know the whole game $G$ itself. In fact, they need to have \emph{shared} knowledge of the choices and payoffs and of the interactive structure. The particular kind of shared knowledge required is called common knowledge.\footnote{The interested reader can see \citet[Section~5.3]{parikh:ul} where I discuss the motivation for common knowledge in detail.} It is interesting that this notion first arose outside of game theory in the context of communication itself, showing indirectly that there is some intimate link between games and communication.

There are two approaches to characterizing common knowledge. The orthodox idea, originating in \citet{schiffer:m} and standardly used in game theory following \citet{aumann:ad}, is that common knowledge of a fact $\sigma$ is iterated knowledge of $\sigma$: $\cal A$ knows $\sigma$, $\cal B$ knows $\sigma$, $\cal A$ knows $\cal B$ knows $\sigma$, $\cal B$ knows $\cal A$ knows $\sigma$, $\cal A$ knows $\cal B$ knows $\cal A$ knows $\sigma$, and so on. This remains the mainstream approach. The shared situation approach, originating in \citet[Chapter II, Section~1]{lewis:c} and made serviceable by \citet{b:tarkck, b:mtck}, is as follows: $\cal A$ and $\cal B$ have common knowledge of $\sigma$ just in case there is a situation $s$ such that (a) $s \vDash \sigma$, (b) $s \vDash {\cal A}$ \hbox{knows} $s$, and (c) $s \vDash {\cal B}$ \hbox{knows} $s$. Keep in mind that ``$\vDash$'' can be read simply as \emph{supports} or \emph{contains} and ``$\cal A$ knows $s$'' as \emph{$\cal A$ knows all the facts in $s$}. When a situation is relatively limited, it is quite common for an agent in that situation to know all the facts in it and thereby to know the situation itself.

%\footnote{Others who have contributed to common knowledge are .}

\citet[14]{gintis:gte} and others have argued against the possibility of common knowledge of the infinitely iterated kind for finite agents because it involves an infinite mental representation. I agree with them but when two ordinary human interlocutors are copresent, their copresence is surely common knowledge between them, and so this can only be explained by the shared situation approach, which involves only finite structures. If $\cal A$ knows $s$, then $\cal A$ knows each fact in $s$, and so $\cal A$ knows $\sigma$ and $\cal A$ knows $\cal B$ knows $s$. This means therefore that $\cal A$ knows $\cal B$ knows $\sigma$. If this is continued indefinitely, it follows that the situational concept implies the infinite chains of knowledge in the orthodox concept and so satisfies the intuitive requirement for common knowledge without its explicit mental representation. As \citet[53]{lewis:c} has said, ``Note that this is a chain of implications, not of steps in anyone's actual reasoning. Therefore there is nothing improper about its infinite length.'' So common knowledge can be made plausible for finite agents.\footnote{There is a mild cost to the shared situation approach. It requires the assumption of circular or non-well-founded situations where a situation may contain itself as a constituent. See \citet{be:liar}. See also \citet[Section~11.5]{fhmv:rk} for a fixed-point approach to common knowledge. \label{foot:nonwellfounded} And see \citet{clark:defref} for the iterated approach.}

%We are often not fully conscious of our common knowledge, especially when it involves communication.

Common knowledge can be either conscious, nonconscious, or semiconscious. It typically arises from perceptual and other situations we share with others and then is maintained by our ongoing actions and communication. When $\cal A$ communicates something to $\cal B$ on the basis of some initial common knowledge, then the content communicated and related facts also become common knowledge and the process continues with an expanded base. Part of such growing common knowledge is retained and becomes their shared background information which is no longer directly perceptual. As members of society, agents can count on such shared information as part of their common knowledge.\footnote{This has been a basic leitmotif of all my work. See, for example, \citet[Section~6.4]{parikh:ul}. It has also been a fundamental idea in dynamic semantics as represented in, for example, \citet{kamp:ttsr}, \citet{heim:diss}, and \citet{gs:dpl}. However, as I pointed out in \citet[5]{parikh:le}, ``most of these developments remain squarely within the tradition of Montague-inspired formal semantics\is{formal semantics} where the focus is on finding appropriate meaning representations rather than on \emph{deriving} intended and optimal meanings through use. Discourse representation theory,\is{discourse representation theory} file change semantics,\is{file change semantics} and dynamic logic\is{dynamic logic} are concerned more with the \emph{results} of the communicative process than with communication itself, with the \emph{what} rather than with the \emph{how}. They address what \citet{austin:pu} called the perlocutionary act\is{perlocutionary act} and effects\is{perlocutionary effect} of communication, not the locutionary\is{locutionary act} and illocutionary acts\is{illocutionary act} and the securing of uptake and understanding. As such, they do not appear to question the \emph{syntax-semantics-pragmatics} trichotomy\is{syntax} and pipeline view of meaning\is{meaning!pipeline view of} bequeathed by \citet{morris:fts} and \citet{grice:sitwow} despite their undoubted technical accomplishments.'' Also, the notion these accounts use is that of common ground which is a little different from common knowledge. See \citet{stalnaker:cg}.}

When common knowledge is used later, $\sigma$ will be substituted by, say, $g$ for the situated game under consideration. The agents will be said to have common knowledge of $g$ as a situated game is a structured set of situations and situations are collections of infons which makes a situated game a structured collection of infons. This structure can itself be expressed via infons because infons involve entities standing in relations. Thus, a situated game is just a large collection of infons and so agents having common knowledge of situated games is the same as agents having common knowledge of all the infons comprising them. 

%The advantages of treating games as situated objects are also discussed in detail.} 

%As will become clear in the next chapter, many different kinds of situated games occur in communication and this idea of common knowledge will apply to all of them.

I have defined common knowledge in terms of knowledge so a quick word about knowledge is in order. It is best explained as informationally caused belief, and belief as information carried in ``completely'' digitized form, as argued in \citet[86, Chapters~7 and 8]{dretske:kfi}.\footnote{In this sentence, the first use of ``information'' pertaining to knowledge stands for factual information and the second use of ``information'' pertaining to belief stands for propositional information that may be false.}

%Another way to explain our typical lack of awareness of some games we participate in is to note that knowledge and belief involve (completely) digitized information so that common knowledge could be something that is not entirely in digital form. Such analogical information isn't knowledge but it is presumably something an agent might still be able to use, especially nonconsciously. In other words, two communicating agents in a shared (perceptual) situation may have mutual analogical representations of the relevant games that they are unaware of. Nevertheless, I will continue to use common knowledge as the operative notion but with these caveats.
\is{common knowledge|)}

\subsection{Context}

Our being situated agents implies that there is always a context when we communicate. A core aspect of this context, called an utterance situation, plays a profound role in communication, both in particular instances and in the large-scale evolution of language. It is seldom precisely specified or specifiable as the boundaries of situations are generally indeterminate. It contains all the ambient information that agents can draw upon in deciding what to say and inferring what has been communicated. There are other situations that are also part of the context such as a described situation, multiple resource situations, and a discourse situation made up of a sequence of utterance situations, but I will not need them much here. I will also often use ``utterance situation'' and ``context'' interchangeably. A central part of an utterance situation is a certain set of games that will be introduced in the next chapter.

I have given a brief description of our informational space and situation theory and, based on this, of agents and games and common knowledge and utterance situations. With these preliminaries, we are now ready to take a synoptic look at communication.



%Often, however, knowledge or belief are too strong because agents may simply \emph{have} information about various states of affairs without being fully aware of them. Certainly, we seem to be at least partially unaware of the games we participate in when we communicate even though we have some if not all the requisite information about them. \emph{Having} information is a weaker notion than belief because belief requires the relevant information to be in digital form. So, common knowledge in Barwise's sense may be replaced by mutual information as follows: $\cal A$ and $\cal B$ have mutual information of $\sigma$ just in case there is a situation $s$ such that (a) $s \vDash \sigma$, (b) $s \vDash {\cal A}$ \hbox{has the information in} $s$, and (c) $s \vDash {\cal B}$ \hbox{has the information in} $s$. Even this weaker notion of mutual information may be too strong when applied to games of partial information and the rest of the communication game because agents may have mutual information of only fragments of the relevant game. In other words, more often than not, there is just \emph{partial} mutual information, but the notion defined here is sufficiently weak to avoid both explicit belief and also the infinite iterations of the orthodox approach. 


